[{"id": "1905.00052", "submitter": "Grigor Aslanyan", "authors": "Grigor Aslanyan, Aritra Mandal, Prathyusha Senthil Kumar, Amit\n  Jaiswal, Manojkumar Rangasamy Kannadasan", "title": "Personalized Ranking in eCommerce Search", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of personalization in the context of eCommerce search.\nSpecifically, we develop personalization ranking features that use in-session\ncontext to augment a generic ranker optimized for conversion and relevance. We\nuse a combination of latent features learned from item co-clicks in historic\nsessions and content-based features that use item title and price.\nPersonalization in search has been discussed extensively in the existing\nliterature. The novelty of our work is combining and comparing content-based\nand content-agnostic features and showing that they complement each other to\nresult in a significant improvement of the ranker. Moreover, our technique does\nnot require an explicit re-ranking step, does not rely on learning user\nprofiles from long term search behavior, and does not involve complex modeling\nof query-item-user features. Our approach captures item co-click propensity\nusing lightweight item embeddings. We experimentally show that our technique\nsignificantly outperforms a generic ranker in terms of Mean Reciprocal Rank\n(MRR). We also provide anecdotal evidence for the semantic similarity captured\nby the item embeddings on the eBay search engine.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 18:29:28 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Aslanyan", "Grigor", ""], ["Mandal", "Aritra", ""], ["Kumar", "Prathyusha Senthil", ""], ["Jaiswal", "Amit", ""], ["Kannadasan", "Manojkumar Rangasamy", ""]]}, {"id": "1905.00067", "submitter": "Sami Abu-El-Haija", "authors": "Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard,\n  Kristina Lerman, Hrayr Harutyunyan, Greg Ver Steeg, Aram Galstyan", "title": "MixHop: Higher-Order Graph Convolutional Architectures via Sparsified\n  Neighborhood Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing popular methods for semi-supervised learning with Graph Neural\nNetworks (such as the Graph Convolutional Network) provably cannot learn a\ngeneral class of neighborhood mixing relationships. To address this weakness,\nwe propose a new model, MixHop, that can learn these relationships, including\ndifference operators, by repeatedly mixing feature representations of neighbors\nat various distances. Mixhop requires no additional memory or computational\ncomplexity, and outperforms on challenging baselines. In addition, we propose\nsparsity regularization that allows us to visualize how the network prioritizes\nneighborhood information across different graph datasets. Our analysis of the\nlearned architectures reveals that neighborhood mixing varies per datasets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:18:43 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 09:55:19 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 14:36:18 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["Kapoor", "Amol", ""], ["Alipourfard", "Nazanin", ""], ["Lerman", "Kristina", ""], ["Harutyunyan", "Hrayr", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1905.00075", "submitter": "Colin B Clement", "authors": "Colin B. Clement, Matthew Bierbaum, Kevin P. O'Keeffe, Alexander A.\n  Alemi", "title": "On the Use of ArXiv as a Dataset", "comments": "7 pages, 3 tables, 2 figures, ICLR 2019 workshop RLGM submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arXiv has collected 1.5 million pre-print articles over 28 years, hosting\nliterature from scientific fields including Physics, Mathematics, and Computer\nScience. Each pre-print features text, figures, authors, citations, categories,\nand other metadata. These rich, multi-modal features, combined with the natural\ngraph structure---created by citation, affiliation, and co-authorship---makes\nthe arXiv an exciting candidate for benchmarking next-generation models. Here\nwe take the first necessary steps toward this goal, by providing a pipeline\nwhich standardizes and simplifies access to the arXiv's publicly available\ndata. We use this pipeline to extract and analyze a 6.7 million edge citation\ngraph, with an 11 billion word corpus of full-text research articles. We\npresent some baseline classification results, and motivate application of more\nexciting generative graph models.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:43:53 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Clement", "Colin B.", ""], ["Bierbaum", "Matthew", ""], ["O'Keeffe", "Kevin P.", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "1905.00076", "submitter": "Andrey Malinin", "authors": "Andrey Malinin, Bruno Mlodozeniec and Mark Gales", "title": "Ensemble Distribution Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of models often yield improvements in system performance. These\nensemble approaches have also been empirically shown to yield robust measures\nof uncertainty, and are capable of distinguishing between different\n\\emph{forms} of uncertainty. However, ensembles come at a computational and\nmemory cost which may be prohibitive for many applications. There has been\nsignificant work done on the distillation of an ensemble into a single model.\nSuch approaches decrease computational cost and allow a single model to achieve\nan accuracy comparable to that of an ensemble. However, information about the\n\\emph{diversity} of the ensemble, which can yield estimates of different forms\nof uncertainty, is lost. This work considers the novel task of \\emph{Ensemble\nDistribution Distillation} (EnD$^2$) --- distilling the distribution of the\npredictions from an ensemble, rather than just the average prediction, into a\nsingle model. EnD$^2$ enables a single model to retain both the improved\nclassification performance of ensemble distillation as well as information\nabout the diversity of the ensemble, which is useful for uncertainty\nestimation. A solution for EnD$^2$ based on Prior Networks, a class of models\nwhich allow a single neural network to explicitly model a distribution over\noutput distributions, is proposed in this work. The properties of EnD$^2$ are\ninvestigated on both an artificial dataset, and on the CIFAR-10, CIFAR-100 and\nTinyImageNet datasets, where it is shown that EnD$^2$ can approach the\nclassification performance of an ensemble, and outperforms both standard DNNs\nand Ensemble Distillation on the tasks of misclassification and\nout-of-distribution input detection.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:46:28 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:07:06 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 21:27:46 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Malinin", "Andrey", ""], ["Mlodozeniec", "Bruno", ""], ["Gales", "Mark", ""]]}, {"id": "1905.00080", "submitter": "Charles Weill", "authors": "Charles Weill, Javier Gonzalvo, Vitaly Kuznetsov, Scott Yang, Scott\n  Yak, Hanna Mazzawi, Eugen Hotaj, Ghassen Jerfel, Vladimir Macko, Ben Adlam,\n  Mehryar Mohri and Corinna Cortes", "title": "AdaNet: A Scalable and Flexible Framework for Automatically Learning\n  Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AdaNet is a lightweight TensorFlow-based (Abadi et al., 2015) framework for\nautomatically learning high-quality ensembles with minimal expert intervention.\nOur framework is inspired by the AdaNet algorithm (Cortes et al., 2017) which\nlearns the structure of a neural network as an ensemble of subnetworks. We\ndesigned it to: (1) integrate with the existing TensorFlow ecosystem, (2) offer\nsensible default search spaces to perform well on novel datasets, (3) present a\nflexible API to utilize expert information when available, and (4) efficiently\naccelerate training with distributed CPU, GPU, and TPU hardware. The code is\nopen-source and available at: https://github.com/tensorflow/adanet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:59:12 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Weill", "Charles", ""], ["Gonzalvo", "Javier", ""], ["Kuznetsov", "Vitaly", ""], ["Yang", "Scott", ""], ["Yak", "Scott", ""], ["Mazzawi", "Hanna", ""], ["Hotaj", "Eugen", ""], ["Jerfel", "Ghassen", ""], ["Macko", "Vladimir", ""], ["Adlam", "Ben", ""], ["Mohri", "Mehryar", ""], ["Cortes", "Corinna", ""]]}, {"id": "1905.00094", "submitter": "Jiakai Wei", "authors": "Jiakai Wei", "title": "Forget the Learning Rate, Decay Loss", "comments": "Asia Conference on Machine Learning and Computing. arXiv admin note:\n  text overlap with arXiv:1703.04782, arXiv:1611.07004 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the usual deep neural network optimization process, the learning rate is\nthe most important hyper parameter, which greatly affects the final convergence\neffect. The purpose of learning rate is to control the stepsize and gradually\nreduce the impact of noise on the network. In this paper, we will use a fixed\nlearning rate with method of decaying loss to control the magnitude of the\nupdate. We used Image classification, Semantic segmentation, and GANs to verify\nthis method. Experiments show that the loss decay strategy can greatly improve\nthe performance of the model\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 03:56:32 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Wei", "Jiakai", ""]]}, {"id": "1905.00122", "submitter": "Li Chen", "authors": "Li Chen, Carter Yagemann, Evan Downing", "title": "To believe or not to believe: Validating explanation fidelity for\n  dynamic malware analysis", "comments": "Accepted at the IEEE Computer Vision Pattern Recognition 2019\n  Explainable AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting malware into images followed by vision-based deep learning\nalgorithms has shown superior threat detection efficacy compared with classical\nmachine learning algorithms. When malware are visualized as images,\nvisual-based interpretation schemes can also be applied to extract insights of\nwhy individual samples are classified as malicious. In this work, via two case\nstudies of dynamic malware classification, we extend the local interpretable\nmodel-agnostic explanation algorithm to explain image-based dynamic malware\nclassification and examine its interpretation fidelity. For both case studies,\nwe first train deep learning models via transfer learning on malware images,\ndemonstrate high classification effectiveness, apply an explanation method on\nthe images, and correlate the results back to the samples to validate whether\nthe algorithmic insights are consistent with security domain expertise. In our\nfirst case study, the interpretation framework identifies indirect calls that\nuniquely characterize the underlying exploit behavior of a malware family. In\nour second case study, the interpretation framework extracts insightful\ninformation such as cryptography-related APIs when applied on images created\nfrom API existence, but generate ambiguous interpretation on images created\nfrom API sequences and frequencies. Our findings indicate that current\nimage-based interpretation techniques are promising for explaining vision-based\nmalware classification. We continue to develop image-based interpretation\nschemes specifically for security applications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 22:45:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Li", ""], ["Yagemann", "Carter", ""], ["Downing", "Evan", ""]]}, {"id": "1905.00124", "submitter": "Yahia Shabara", "authors": "Yahia Shabara, Eylem Ekici and C. Emre Koksal", "title": "Source Coding Based Millimeter-Wave Channel Estimation with Deep\n  Learning Based Decoding", "comments": "To be published in IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speed at which millimeter-Wave (mmWave) channel estimation can be carried\nout is critical for the adoption of mmWave technologies. This is particularly\ncrucial because mmWave transceivers are equipped with large antenna arrays to\ncombat severe path losses, which consequently creates large channel matrices,\nwhose estimation may incur significant overhead. This paper focuses on the\nmmWave channel estimation problem. Our objective is to reduce the number of\nmeasurements required to reliably estimate the channel. Specifically, channel\nestimation is posed as a \"source compression\" problem in which measurements\nmimic an encoded (compressed) version of the channel. Decoding the observed\nmeasurements, a task which is traditionally computationally intensive, is\nperformed using a deep-learning-based approach, facilitating a high-performance\nchannel discovery. Our solution not only outperforms state-of-the-art\ncompressed sensing methods, but it also determines the lower bound on the\nnumber of measurements required for reliable channel discovery.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 22:52:05 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 18:31:06 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 22:27:49 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Shabara", "Yahia", ""], ["Ekici", "Eylem", ""], ["Koksal", "C. Emre", ""]]}, {"id": "1905.00125", "submitter": "Bhanu Pratap Singh Rawat", "authors": "Bhanu Pratap Singh, Iman Deznabi, Bharath Narasimhan, Bryon Kucharski,\n  Rheeya Uppaal, Akhila Josyula, Madalina Fiterau", "title": "Multi-resolution Networks For Flexible Irregular Time Series Modeling\n  (Multi-FIT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing values, irregularly collected samples, and multi-resolution signals\ncommonly occur in multivariate time series data, making predictive tasks\ndifficult. These challenges are especially prevalent in the healthcare domain,\nwhere patients' vital signs and electronic records are collected at different\nfrequencies and have occasionally missing information due to the imperfections\nin equipment or patient circumstances. Researchers have handled each of these\nissues differently, often handling missing data through mean value imputation\nand then using sequence models over the multivariate signals while ignoring the\ndifferent resolution of signals. We propose a unified model named\nMulti-resolution Flexible Irregular Time series Network (Multi-FIT). The\nbuilding block for Multi-FIT is the FIT network. The FIT network creates an\ninformative dense representation at each time step using signal information\nsuch as last observed value, time difference since the last observed time stamp\nand overall mean for the signal. Vertical FIT (FIT-V) is a variant of FIT which\nalso models the relationship between different temporal signals while creating\nthe informative dense representations for the signal. The multi-FIT model uses\nmultiple FIT networks for sets of signals with different resolutions, further\nfacilitating the construction of flexible representations. Our model has three\nmain contributions: a.) it does not impute values but rather creates\ninformative representations to provide flexibility to the model for creating\ntask-specific representations b.) it models the relationship between different\nsignals in the form of support signals c.) it models different resolutions in\nparallel before merging them for the final prediction task. The FIT, FIT-V and\nMulti-FIT networks improve upon the state-of-the-art models for three\npredictive tasks, including the forecasting of patient survival.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 22:52:48 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Singh", "Bhanu Pratap", ""], ["Deznabi", "Iman", ""], ["Narasimhan", "Bharath", ""], ["Kucharski", "Bryon", ""], ["Uppaal", "Rheeya", ""], ["Josyula", "Akhila", ""], ["Fiterau", "Madalina", ""]]}, {"id": "1905.00135", "submitter": "Matej Ulicny", "authors": "Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot", "title": "Harmonic Networks with Limited Training Samples", "comments": null, "journal-ref": "European Signal Processing Conference (EUSIPCO) 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are very popular nowadays for image\nprocessing. CNNs allow one to learn optimal filters in a (mostly) supervised\nmachine learning context. However this typically requires abundant labelled\ntraining data to estimate the filter parameters. Alternative strategies have\nbeen deployed for reducing the number of parameters and / or filters to be\nlearned and thus decrease overfitting. In the context of reverting to preset\nfilters, we propose here a computationally efficient harmonic block that uses\nDiscrete Cosine Transform (DCT) filters in CNNs. In this work we examine the\nperformance of harmonic networks in limited training data scenario. We validate\nexperimentally that its performance compares well against scattering networks\nthat use wavelets as preset filters.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:35:30 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Ulicny", "Matej", ""], ["Krylov", "Vladimir A.", ""], ["Dahyot", "Rozenn", ""]]}, {"id": "1905.00136", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Sheng Lin, Zhengang Li, Hao Sun, Yanzhi Wang", "title": "ResNet Can Be Pruned 60x: Introducing Network Purification and Unused\n  Path Removal (P-RM) after Weight Pruning", "comments": "Submitted to ICML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art DNN structures involve high computation and great demand for\nmemory storage which pose intensive challenge on DNN framework resources. To\nmitigate the challenges, weight pruning techniques has been studied. However,\nhigh accuracy solution for extreme structured pruning that combines different\ntypes of structured sparsity still waiting for unraveling due to the extremely\nreduced weights in DNN networks. In this paper, we propose a DNN framework\nwhich combines two different types of structured weight pruning (filter and\ncolumn prune) by incorporating alternating direction method of multipliers\n(ADMM) algorithm for better prune performance. We are the first to find\nnon-optimality of ADMM process and unused weights in a structured pruned model,\nand further design an optimization framework which contains the first proposed\nNetwork Purification and Unused Path Removal algorithms which are dedicated to\npost-processing an structured pruned model after ADMM steps. Some high lights\nshows we achieve 232x compression on LeNet-5, 60x compression on ResNet-18\nCIFAR-10 and over 5x compression on AlexNet. We share our models at anonymous\nlink http://bit.ly/2VJ5ktv.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:40:51 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Lin", "Sheng", ""], ["Li", "Zhengang", ""], ["Sun", "Hao", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1905.00147", "submitter": "Lily Hu", "authors": "Lily Hu and Yiling Chen", "title": "Fair Classification and Social Welfare", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now that machine learning algorithms lie at the center of many resource\nallocation pipelines, computer scientists have been unwittingly cast as partial\nsocial planners. Given this state of affairs, important questions follow. What\nis the relationship between fairness as defined by computer scientists and\nnotions of social welfare? In this paper, we present a welfare-based analysis\nof classification and fairness regimes. We translate a loss minimization\nprogram into a social welfare maximization problem with a set of implied\nwelfare weights on individuals and groups--weights that can be analyzed from a\ndistribution justice lens. In the converse direction, we ask what the space of\npossible labelings is for a given dataset and hypothesis class. We provide an\nalgorithm that answers this question with respect to linear hyperplanes in\n$\\mathbb{R}^d$ that runs in $O(n^dd)$. Our main findings on the relationship\nbetween fairness criteria and welfare center on sensitivity analyses of\nfairness-constrained empirical risk minimization programs. We characterize the\nranges of $\\Delta \\epsilon$ perturbations to a fairness parameter $\\epsilon$\nthat yield better, worse, and neutral outcomes in utility for individuals and\nby extension, groups. We show that applying more strict fairness criteria that\nare codified as parity constraints, can worsen welfare outcomes for both\ngroups. More generally, always preferring \"more fair\" classifiers does not\nabide by the Pareto Principle---a fundamental axiom of social choice theory and\nwelfare economics. Recent work in machine learning has rallied around these\nnotions of fairness as critical to ensuring that algorithmic systems do not\nhave disparate negative impact on disadvantaged social groups. By showing that\nthese constraints often fail to translate into improved outcomes for these\ngroups, we cast doubt on their effectiveness as a means to ensure justice.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:03:07 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Hu", "Lily", ""], ["Chen", "Yiling", ""]]}, {"id": "1905.00158", "submitter": "Yujia Xie", "authors": "Yujia Xie, Minshuo Chen, Haoming Jiang, Tuo Zhao, Hongyuan Zha", "title": "On Scalable and Efficient Computation of Large Scale Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Transport (OT) naturally arises in many machine learning\napplications, yet the heavy computational burden limits its wide-spread uses.\nTo address the scalability issue, we propose an implicit generative\nlearning-based framework called SPOT (Scalable Push-forward of Optimal\nTransport). Specifically, we approximate the optimal transport plan by a\npushforward of a reference distribution, and cast the optimal transport problem\ninto a minimax problem. We then can solve OT problems efficiently using primal\ndual stochastic gradient-type algorithms. We also show that we can recover the\ndensity of the optimal transport plan using neural ordinary differential\nequations. Numerical experiments on both synthetic and real datasets illustrate\nthat SPOT is robust and has favorable convergence behavior. SPOT also allows us\nto efficiently sample from the optimal transport plan, which benefits\ndownstream applications such as domain adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:32:52 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 15:16:19 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 19:22:14 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Xie", "Yujia", ""], ["Chen", "Minshuo", ""], ["Jiang", "Haoming", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1905.00159", "submitter": "Yaroslav Koshka", "authors": "Yaroslav Koshka, M.A. Novotny", "title": "Towards Sampling from Nondirected Probabilistic Graphical models using a\n  D-Wave Quantum Annealer", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A D-Wave quantum annealer (QA) having a 2048 qubit lattice, with no missing\nqubits and couplings, allowed embedding of a complete graph of a Restricted\nBoltzmann Machine (RBM). A handwritten digit OptDigits data set having 8x7\npixels of visible units was used to train the RBM using a classical Contrastive\nDivergence. Embedding of the classically-trained RBM into the D-Wave lattice\nwas used to demonstrate that the QA offers a high-efficiency alternative to the\nclassical Markov Chain Monte Carlo (MCMC) for reconstructing missing labels of\nthe test images as well as a generative model. At any training iteration, the\nD-Wave-based classification had classification error more than two times lower\nthan MCMC. The main goal of this study was to investigate the quality of the\nsample from the RBM model distribution and its comparison to a classical MCMC\nsample. For the OptDigits dataset, the states in the D-Wave sample belonged to\nabout two times more local valleys compared to the MCMC sample. All the\nlowest-energy (the highest joint probability) local minima in the MCMC sample\nwere also found by the D-Wave. The D-Wave missed many of the higher-energy\nlocal valleys, while finding many \"new\" local valleys consistently missed by\nthe MCMC. It was established that the \"new\" local valleys that the D-Wave finds\nare important for the model distribution in terms of the energy of the\ncorresponding local minima, the width of the local valleys, and the height of\nthe escape barrier.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 02:00:07 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Koshka", "Yaroslav", ""], ["Novotny", "M. A.", ""]]}, {"id": "1905.00174", "submitter": "Azadeh Mozafari", "authors": "Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Wilson Le\\~ao and\n  Christian Gagn\\'e", "title": "Unsupervised Temperature Scaling: An Unsupervised Post-Processing\n  Calibration Method of Deep Networks", "comments": "arXiv admin note: text overlap with arXiv:1810.11586", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great performances of deep learning are undeniable, with impressive\nresults over a wide range of tasks. However, the output confidence of these\nmodels is usually not well-calibrated, which can be an issue for applications\nwhere confidence on the decisions is central to providing trust and reliability\n(e.g., autonomous driving or medical diagnosis). For models using softmax at\nthe last layer, Temperature Scaling (TS) is a state-of-the-art calibration\nmethod, with low time and memory complexity as well as demonstrated\neffectiveness. TS relies on a T parameter to rescale and calibrate values of\nthe softmax layer, whose parameter value is computed from a labelled dataset.\nWe are proposing an Unsupervised Temperature Scaling (UTS) approach, which does\nnot depend on labelled samples to calibrate the model, which allows, for\nexample, the use of a part of a test samples to calibrate the pre-trained model\nbefore going into inference mode. We provide theoretical justifications for UTS\nand assess its effectiveness on a wide range of deep models and datasets. We\nalso demonstrate calibration results of UTS on skin lesion detection, a problem\nwhere a well-calibrated output can play an important role for accurate\ndecision-making.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 03:43:29 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 02:52:23 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 15:23:22 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Mozafari", "Azadeh Sadat", ""], ["Gomes", "Hugo Siqueira", ""], ["Le\u00e3o", "Wilson", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1905.00180", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Sreeram Kannan and Radha Poovendran", "title": "Dropping Pixels for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable against adversarial examples. In this\npaper, we propose to train and test the networks with randomly subsampled\nimages with high drop rates. We show that this approach significantly improves\nrobustness against adversarial examples in all cases of bounded L0, L2 and\nL_inf perturbations, while reducing the standard accuracy by a small value. We\nargue that subsampling pixels can be thought to provide a set of robust\nfeatures for the input image and, thus, improves robustness without performing\nadversarial training.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 04:15:47 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Hosseini", "Hossein", ""], ["Kannan", "Sreeram", ""], ["Poovendran", "Radha", ""]]}, {"id": "1905.00229", "submitter": "Sascha Rosbach", "authors": "Sascha Rosbach, Vinit James, Simon Gro{\\ss}johann, Silviu Homoceanu\n  and Stefan Roth", "title": "Driving with Style: Inverse Reinforcement Learning in General-Purpose\n  Planning for Automated Driving", "comments": "Appeared at IROS 2019. Accepted version. Added/updated footnote,\n  minor correction in preliminaries", "journal-ref": "2019 IEEE/RSJ Int. Conf. on Intelligent Robots and Syst. (IROS),\n  Macau, China, 2019, pp. 2658-2665", "doi": "10.1109/IROS40897.2019.8968205", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior and motion planning play an important role in automated driving.\nTraditionally, behavior planners instruct local motion planners with predefined\nbehaviors. Due to the high scene complexity in urban environments,\nunpredictable situations may occur in which behavior planners fail to match\npredefined behavior templates. Recently, general-purpose planners have been\nintroduced, combining behavior and local motion planning. These general-purpose\nplanners allow behavior-aware motion planning given a single reward function.\nHowever, two challenges arise: First, this function has to map a complex\nfeature space into rewards. Second, the reward function has to be manually\ntuned by an expert. Manually tuning this reward function becomes a tedious\ntask. In this paper, we propose an approach that relies on human driving\ndemonstrations to automatically tune reward functions. This study offers\nimportant insights into the driving style optimization of general-purpose\nplanners with maximum entropy inverse reinforcement learning. We evaluate our\napproach based on the expected value difference between learned and\ndemonstrated policies. Furthermore, we compare the similarity of human driven\ntrajectories with optimal policies of our planner under learned and\nexpert-tuned reward functions. Our experiments show that we are able to learn\nreward functions exceeding the level of manual expert tuning without prior\ndomain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 09:18:47 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 14:13:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rosbach", "Sascha", ""], ["James", "Vinit", ""], ["Gro\u00dfjohann", "Simon", ""], ["Homoceanu", "Silviu", ""], ["Roth", "Stefan", ""]]}, {"id": "1905.00245", "submitter": "Charles Chen", "authors": "Charles Chen and Razvan Bunescu", "title": "Context-Dependent Semantic Parsing over Temporally Structured Data", "comments": "Accepted by NAACL 2019 (Oral presentation)", "journal-ref": "Proceedings of the 2019 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language Technologies\n  (NAACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new semantic parsing setting that allows users to query the\nsystem using both natural language questions and actions within a graphical\nuser interface. Multiple time series belonging to an entity of interest are\nstored in a database and the user interacts with the system to obtain a better\nunderstanding of the entity's state and behavior, entailing sequences of\nactions and questions whose answers may depend on previous factual or\nnavigational interactions. We design an LSTM-based encoder-decoder architecture\nthat models context dependency through copying mechanisms and multiple levels\nof attention over inputs and previous outputs. When trained to predict tokens\nusing supervised learning, the proposed architecture substantially outperforms\nstandard sequence generation baselines. Training the architecture using policy\ngradient leads to further improvements in performance, reaching a\nsequence-level accuracy of 88.7% on artificial data and 74.8% on real data.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:16:46 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Charles", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1905.00252", "submitter": "Francesco Lomio", "authors": "Francesco Lomio, Erjon Skenderi, Damoon Mohamadi, Jussi Collin, Reza\n  Ghabcheloo and Heikki Huttunen", "title": "Surface Type Classification for Autonomous Robot Indoor Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe the preparation of a time series dataset of inertial\nmeasurements for determining the surface type under a wheeled robot. The data\nconsists of over 7600 labeled time series samples, with the corresponding\nsurface type annotation. This data was used in two public competitions with\nover 1500 participant in total. Additionally, we describe the performance of\nstate-of-art deep learning models for time series classification, as well as\npropose a baseline model based on an ensemble of machine learning methods. The\nbaseline achieves an accuracy of over 68% with our nine-category dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:39:21 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Lomio", "Francesco", ""], ["Skenderi", "Erjon", ""], ["Mohamadi", "Damoon", ""], ["Collin", "Jussi", ""], ["Ghabcheloo", "Reza", ""], ["Huttunen", "Heikki", ""]]}, {"id": "1905.00261", "submitter": "Marcelo Cabral Ghilardi", "authors": "Marcelo C. Ghilardi, Leandro Dihl, Estev\\~ao Testa, Pedro Braga,\n  Jo\\~ao P. Pianta, Isabel H. Manssour, Soraia R. Musse", "title": "Automatic Dataset Augmentation Using Virtual Human Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Human Simulation has been widely used for different purposes, such as\ncomfort or accessibility analysis. In this paper, we investigate the\npossibility of using this type of technique to extend the training datasets of\npedestrians to be used with machine learning techniques. Our main goal is to\nverify if Computer Graphics (CG) images of virtual humans with a simplistic\nrendering can be efficient in order to augment datasets used for training\nmachine learning methods. In fact, from a machine learning point of view, there\nis a need to collect and label large datasets for ground truth, which sometimes\ndemands manual annotation. In addition, find out images and videos with real\npeople and also provide ground truth of people detection and counting is not\ntrivial. If CG images, which can have a ground truth automatically generated,\ncan also be used as training in machine learning techniques for pedestrian\ndetection and counting, it can certainly facilitate and optimize the whole\nprocess of event detection. In particular, we propose to parametrize virtual\nhumans using a data-driven approach. Results demonstrated that using the\nextended datasets with CG images outperforms the results when compared to only\nreal images sequences.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:01:39 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Ghilardi", "Marcelo C.", ""], ["Dihl", "Leandro", ""], ["Testa", "Estev\u00e3o", ""], ["Braga", "Pedro", ""], ["Pianta", "Jo\u00e3o P.", ""], ["Manssour", "Isabel H.", ""], ["Musse", "Soraia R.", ""]]}, {"id": "1905.00301", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Myriam Bontonou, Carlos Lassance, Ghouthi Boukli Hacene, Vincent\n  Gripon, Jian Tang, Antonio Ortega", "title": "Introducing Graph Smoothness Loss for Training Deep Learning\n  Architectures", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel loss function for training deep learning architectures\nto perform classification. It consists in minimizing the smoothness of label\nsignals on similarity graphs built at the output of the architecture.\nEquivalently, it can be seen as maximizing the distances between the network\nfunction images of training inputs from distinct classes. As such, only\ndistances between pairs of examples in distinct classes are taken into account\nin the process, and the training does not prevent inputs from the same class to\nbe mapped to distant locations in the output domain. We show that this loss\nleads to similar performance in classification as architectures trained using\nthe classical cross-entropy, while offering interesting degrees of freedom and\nproperties. We also demonstrate the interest of the proposed loss to increase\nrobustness of trained architectures to deviations of the inputs.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:09:04 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Bontonou", "Myriam", ""], ["Lassance", "Carlos", ""], ["Hacene", "Ghouthi Boukli", ""], ["Gripon", "Vincent", ""], ["Tang", "Jian", ""], ["Ortega", "Antonio", ""]]}, {"id": "1905.00328", "submitter": "Hugo Manuel Proen\\c{c}a", "authors": "Hugo M. Proen\\c{c}a and Matthijs van Leeuwen", "title": "Interpretable multiclass classification by MDL-based rule lists", "comments": null, "journal-ref": "Information Sciences 2019", "doi": "10.1016/j.ins.2019.10.050", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable classifiers have recently witnessed an increase in attention\nfrom the data mining community because they are inherently easier to understand\nand explain than their more complex counterparts. Examples of interpretable\nclassification models include decision trees, rule sets, and rule lists.\nLearning such models often involves optimizing hyperparameters, which typically\nrequires substantial amounts of data and may result in relatively large models.\nIn this paper, we consider the problem of learning compact yet accurate\nprobabilistic rule lists for multiclass classification. Specifically, we\npropose a novel formalization based on probabilistic rule lists and the minimum\ndescription length (MDL) principle. This results in virtually parameter-free\nmodel selection that naturally allows to trade-off model complexity with\ngoodness of fit, by which overfitting and the need for hyperparameter tuning\nare effectively avoided. Finally, we introduce the Classy algorithm, which\ngreedily finds rule lists according to the proposed criterion. We empirically\ndemonstrate that Classy selects small probabilistic rule lists that outperform\nstate-of-the-art classifiers when it comes to the combination of predictive\nperformance and interpretability. We show that Classy is insensitive to its\nonly parameter, i.e., the candidate set, and that compression on the training\nset correlates with classification performance, validating our MDL-based\nselection criterion.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:34:33 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:49:29 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Proen\u00e7a", "Hugo M.", ""], ["van Leeuwen", "Matthijs", ""]]}, {"id": "1905.00331", "submitter": "Tao Wang", "authors": "Taiping He, Tao Wang, Ralph Abbey, and Joshua Griffin", "title": "High-Performance Support Vector Machines and Its Applications", "comments": "ICDATA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machines (SVM) algorithm is a popular classification\ntechnique in data mining and machine learning. In this paper, we propose a\ndistributed SVM algorithm and demonstrate its use in a number of applications.\nThe algorithm is named high-performance support vector machines (HPSVM). The\nmajor contribution of HPSVM is two-fold. First, HPSVM provides a new way to\ndistribute computations to the machines in the cloud without shuffling the\ndata. Second, HPSVM minimizes the inter-machine communications in order to\nmaximize the performance. We apply HPSVM to some real-world classification\nproblems and compare it with the state-of-the-art SVM technique implemented in\nR on several public data sets. HPSVM achieves similar or better results.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:43:03 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["He", "Taiping", ""], ["Wang", "Tao", ""], ["Abbey", "Ralph", ""], ["Griffin", "Joshua", ""]]}, {"id": "1905.00332", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Diego P. P. Mesquita, Luis A. Freitas, Jo\\~ao P. P. Gomes, C\\'esar L.\n  C. Mattos", "title": "LS-SVR as a Bayesian RBF network", "comments": "14 pages, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show theoretical similarities between the Least Squares Support Vector\nRegression (LS-SVR) model with a Radial Basis Functions (RBF) kernel and\nmaximum a posteriori (MAP) inference on Bayesian RBF networks with a specific\nGaussian prior on the regression weights. Although previous works have pointed\nout similar expressions between those learning approaches, we explicit and\nformally state the existing correspondences. We empirically demonstrate our\nresult by performing computational experiments with standard regression\nbenchmarks. Our findings open a range of possibilities to improve LS-SVR by\nborrowing strength from well-established developments in Bayesian methodology.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:46:38 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 19:28:07 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mesquita", "Diego P. P.", ""], ["Freitas", "Luis A.", ""], ["Gomes", "Jo\u00e3o P. P.", ""], ["Mattos", "C\u00e9sar L. C.", ""]]}, {"id": "1905.00360", "submitter": "Nan Jiang", "authors": "Jinglin Chen, Nan Jiang", "title": "Information-Theoretic Considerations in Batch Reinforcement Learning", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-function approximation methods that operate in batch mode have\nfoundational importance to reinforcement learning (RL). Finite sample\nguarantees for these methods often crucially rely on two types of assumptions:\n(1) mild distribution shift, and (2) representation conditions that are\nstronger than realizability. However, the necessity (\"why do we need them?\")\nand the naturalness (\"when do they hold?\") of such assumptions have largely\neluded the literature. In this paper, we revisit these assumptions and provide\ntheoretical results towards answering the above questions, and make steps\ntowards a deeper understanding of value-function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:19:28 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Jinglin", ""], ["Jiang", "Nan", ""]]}, {"id": "1905.00365", "submitter": "Srikanth Namuduri", "authors": "Colleen M. Farrelly, Srikanth Namuduri, Uchenna Chukwu", "title": "Quantum Generalized Linear Models", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG quant-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generalized linear models (GLM) are link function based statistical models.\nMany supervised learning algorithms are extensions of GLMs and have link\nfunctions built into the algorithm to model different outcome distributions.\nThere are two major drawbacks when using this approach in applications using\nreal world datasets. One is that none of the link functions available in the\npopular packages is a good fit for the data. Second, it is computationally\ninefficient and impractical to test all the possible distributions to find the\noptimum one. In addition, many GLMs and their machine learning extensions\nstruggle on problems of overdispersion in Tweedie distributions. In this paper\nwe propose a quantum extension to GLM that overcomes these drawbacks. A quantum\ngate with non-Gaussian transformation can be used to continuously deform the\noutcome distribution from known results. In doing so, we eliminate the need for\na link function. Further, by using an algorithm that superposes all possible\ndistributions to collapse to fit a dataset, we optimize the model in a\ncomputationally efficient way. We provide an initial proof-of-concept by\ntesting this approach on both a simulation of overdispersed data and then on a\nbenchmark dataset, which is quite overdispersed, and achieved state of the art\nresults. This is a game changer in several applied fields, such as part failure\nmodeling, medical research, actuarial science, finance and many other fields\nwhere Tweedie regression and overdispersion are ubiquitous.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:29:04 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Farrelly", "Colleen M.", ""], ["Namuduri", "Srikanth", ""], ["Chukwu", "Uchenna", ""]]}, {"id": "1905.00397", "submitter": "Sungbin Lim", "authors": "Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, Sungwoong Kim", "title": "Fast AutoAugment", "comments": "8 pages, 2 figure", "journal-ref": null, "doi": null, "report-no": "NeurIPS/2019/12", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is an essential technique for improving generalization\nability of deep learning models. Recently, AutoAugment has been proposed as an\nalgorithm to automatically search for augmentation policies from a dataset and\nhas significantly enhanced performances on many image recognition tasks.\nHowever, its search method requires thousands of GPU hours even for a\nrelatively small dataset. In this paper, we propose an algorithm called Fast\nAutoAugment that finds effective augmentation policies via a more efficient\nsearch strategy based on density matching. In comparison to AutoAugment, the\nproposed algorithm speeds up the search time by orders of magnitude while\nachieves comparable performances on image recognition tasks with various models\nand datasets including CIFAR-10, CIFAR-100, SVHN, and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 17:33:36 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 16:44:21 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Lim", "Sungbin", ""], ["Kim", "Ildoo", ""], ["Kim", "Taesup", ""], ["Kim", "Chiheon", ""], ["Kim", "Sungwoong", ""]]}, {"id": "1905.00406", "submitter": "Xi Xiong", "authors": "Xi Xiong, Kaan Ozbay, Li Jin, and Chen Feng", "title": "Dynamic Origin-Destination Matrix Prediction with Line Graph Neural\n  Networks and Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern intelligent transportation systems provide data that allow real-time\ndynamic demand prediction, which is essential for planning and operations. The\nmain challenge of prediction of dynamic Origin-Destination (O-D) demand\nmatrices is that demands cannot be directly measured by traffic sensors;\ninstead, they have to be inferred from aggregate traffic flow data on traffic\nlinks. Specifically, spatial correlation, congestion and time dependent factors\nneed to be considered in general transportation networks. In this paper we\npropose a novel O-D prediction framework combining heterogeneous prediction in\ngraph neural networks and Kalman filter to recognize spatial and temporal\npatterns simultaneously. The underlying road network topology is converted into\na corresponding line graph in the newly designed Fusion Line Graph\nConvolutional Networks (FL-GCNs), which provide a general framework of\npredicting spatial-temporal O-D flows from link information. Data from New\nJersey Turnpike network are used to evaluate the proposed model. The results\nshow that our proposed approach yields the best performance under various\nprediction scenarios. In addition, the advantage of combining deep neural\nnetworks and Kalman filter is demonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 17:48:07 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 03:06:02 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 13:45:03 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Xiong", "Xi", ""], ["Ozbay", "Kaan", ""], ["Jin", "Li", ""], ["Feng", "Chen", ""]]}, {"id": "1905.00414", "submitter": "Simon Kornblith", "authors": "Simon Kornblith and Mohammad Norouzi and Honglak Lee and Geoffrey\n  Hinton", "title": "Similarity of Neural Network Representations Revisited", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has sought to understand the behavior of neural networks by\ncomparing representations between layers and between different trained models.\nWe examine methods for comparing neural network representations based on\ncanonical correlation analysis (CCA). We show that CCA belongs to a family of\nstatistics for measuring multivariate similarity, but that neither CCA nor any\nother statistic that is invariant to invertible linear transformation can\nmeasure meaningful similarities between representations of higher dimension\nthan the number of data points. We introduce a similarity index that measures\nthe relationship between representational similarity matrices and does not\nsuffer from this limitation. This similarity index is equivalent to centered\nkernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA\ncan reliably identify correspondences between representations in networks\ntrained from different initializations.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 17:57:26 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:26:27 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 16:19:38 GMT"}, {"version": "v4", "created": "Fri, 19 Jul 2019 14:59:45 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Kornblith", "Simon", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1905.00416", "submitter": "Jeremy Kepner", "authors": "Ryan A. Robinett and Jeremy Kepner", "title": "RadiX-Net: Structured Sparse Matrices for Deep Neural Networks", "comments": "7 pages, 8 figures, accepted at IEEE IPDPS 2019 GrAPL workshop. arXiv\n  admin note: substantial text overlap with arXiv:1809.05242", "journal-ref": null, "doi": "10.1109/IPDPSW.2019.00051", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sizes of deep neural networks (DNNs) are rapidly outgrowing the capacity\nof hardware to store and train them. Research over the past few decades has\nexplored the prospect of sparsifying DNNs before, during, and after training by\npruning edges from the underlying topology. The resulting neural network is\nknown as a sparse neural network. More recent work has demonstrated the\nremarkable result that certain sparse DNNs can train to the same precision as\ndense DNNs at lower runtime and storage cost. An intriguing class of these\nsparse DNNs is the X-Nets, which are initialized and trained upon a sparse\ntopology with neither reference to a parent dense DNN nor subsequent pruning.\nWe present an algorithm that deterministically generates RadiX-Nets: sparse DNN\ntopologies that, as a whole, are much more diverse than X-Net topologies, while\npreserving X-Nets' desired characteristics. We further present a\nfunctional-analytic conjecture based on the longstanding observation that\nsparse neural network topologies can attain the same expressive power as dense\ncounterparts\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 21:28:17 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Robinett", "Ryan A.", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1905.00420", "submitter": "Shuai Yang", "authors": "Wenqi Zhu, Yuesheng Zhu, Li Zhong, Shuai Yang", "title": "Restricted Connection Orthogonal Matching Pursuit For Sparse Subspace\n  Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2953638", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Subspace Clustering (SSC) is one of the most popular methods for\nclustering data points into their underlying subspaces. However, SSC may suffer\nfrom heavy computational burden. Orthogonal Matching Pursuit applied on SSC\naccelerates the computation but the trade-off is the loss of clustering\naccuracy. In this paper, we propose a noise-robust algorithm, Restricted\nConnection Orthogonal Matching Pursuit for Sparse Subspace Clustering\n(RCOMP-SSC), to improve the clustering accuracy and maintain the low\ncomputational time by restricting the number of connections of each data point\nduring the iteration of OMP. Also, we develop a framework of control matrix to\nrealize RCOMP-SCC. And the framework is scalable for other data point selection\nstrategies. Our analysis and experiments on synthetic data and two real-world\ndatabases (EYaleB & Usps) demonstrate the superiority of our algorithm compared\nwith other clustering methods in terms of accuracy and computational time.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:21:41 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhu", "Wenqi", ""], ["Zhu", "Yuesheng", ""], ["Zhong", "Li", ""], ["Yang", "Shuai", ""]]}, {"id": "1905.00421", "submitter": "Yufeng Yu", "authors": "Yufeng Yu, Yuelong Zhu, Dingsheng Wan, Qun Zhao, Huan Liu", "title": "A Novel Trend Symbolic Aggregate Approximation for Time Series", "comments": "9 pages,ACM_IMCOM2019_CFP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Symbolic Aggregate approximation (SAX) is a classical symbolic approach in\nmany time series data mining applications. However, SAX only reflects the\nsegment mean value feature and misses important information in a segment,\nnamely the trend of the value change in the segment. Such a miss may cause a\nwrong classification in some cases, since the SAX representation cannot\ndistinguish different time series with similar average values but different\ntrends. In this paper, we present Trend Feature Symbolic Aggregate\napproximation (TFSAX) to solve this problem. First, we utilize Piecewise\nAggregate Approximation (PAA) approach to reduce dimensionality and discretize\nthe mean value of each segment by SAX. Second, extract trend feature in each\nsegment by using trend distance factor and trend shape factor. Then, design\nmulti-resolution symbolic mapping rules to discretize trend information into\nsymbols. We also propose a modified distance measure by integrating the SAX\ndistance with a weighted trend distance. We show that our distance measure has\na tighter lower bound to the Euclidean distance than that of the original SAX.\nThe experimental results on diverse time series data sets demonstrate that our\nproposed representation significantly outperforms the original SAX\nrepresentation and an improved SAX representation for classification.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:03:51 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Yu", "Yufeng", ""], ["Zhu", "Yuelong", ""], ["Wan", "Dingsheng", ""], ["Zhao", "Qun", ""], ["Liu", "Huan", ""]]}, {"id": "1905.00424", "submitter": "Sijia Liu", "authors": "Sijia Liu, Parikshit Ram, Deepak Vijaykeerthy, Djallel Bouneffouf,\n  Gregory Bramble, Horst Samulowitz, Dakuo Wang, Andrew Conn, Alexander Gray", "title": "An ADMM Based Framework for AutoML Pipeline Configuration", "comments": null, "journal-ref": "published at AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the AutoML problem of automatically configuring machine learning\npipelines by jointly selecting algorithms and their appropriate\nhyper-parameters for all steps in supervised learning pipelines. This black-box\n(gradient-free) optimization with mixed integer & continuous variables is a\nchallenging problem. We propose a novel AutoML scheme by leveraging the\nalternating direction method of multipliers (ADMM). The proposed framework is\nable to (i) decompose the optimization problem into easier sub-problems that\nhave a reduced number of variables and circumvent the challenge of mixed\nvariable categories, and (ii) incorporate black-box constraints along-side the\nblack-box optimization objective. We empirically evaluate the flexibility (in\nutilizing existing AutoML techniques), effectiveness (against open source\nAutoML toolkits),and unique capability (of executing AutoML with practically\nmotivated black-box constraints) of our proposed scheme on a collection of\nbinary classification data sets from UCI ML& OpenML repositories. We observe\nthat on an average our framework provides significant gains in comparison to\nother AutoML frameworks (Auto-sklearn & TPOT), highlighting the practical\nadvantages of this framework.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:51:52 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:36:20 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 00:19:13 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 06:55:45 GMT"}, {"version": "v5", "created": "Fri, 6 Dec 2019 19:27:12 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Liu", "Sijia", ""], ["Ram", "Parikshit", ""], ["Vijaykeerthy", "Deepak", ""], ["Bouneffouf", "Djallel", ""], ["Bramble", "Gregory", ""], ["Samulowitz", "Horst", ""], ["Wang", "Dakuo", ""], ["Conn", "Andrew", ""], ["Gray", "Alexander", ""]]}, {"id": "1905.00441", "submitter": "Yandong Li", "authors": "Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, Boqing Gong", "title": "NATTACK: Learning the Distributions of Adversarial Examples for an\n  Improved Black-Box Attack on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful adversarial attack methods are vital for understanding how to\nconstruct robust deep neural networks (DNNs) and for thoroughly testing defense\ntechniques. In this paper, we propose a black-box adversarial attack algorithm\nthat can defeat both vanilla DNNs and those generated by various defense\ntechniques developed recently. Instead of searching for an \"optimal\"\nadversarial example for a benign input to a targeted DNN, our algorithm finds a\nprobability density distribution over a small region centered around the input,\nsuch that a sample drawn from this distribution is likely an adversarial\nexample, without the need of accessing the DNN's internal layers or weights.\nOur approach is universal as it can successfully attack different neural\nnetworks by a single algorithm. It is also strong; according to the testing\nagainst 2 vanilla DNNs and 13 defended ones, it outperforms state-of-the-art\nblack-box or white-box attack methods for most test cases. Additionally, our\nresults reveal that adversarial training remains one of the best defense\ntechniques, and the adversarial examples are not as transferable across\ndefended DNNs as them across vanilla DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 18:20:09 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 18:26:21 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 19:18:49 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Li", "Yandong", ""], ["Li", "Lijun", ""], ["Wang", "Liqiang", ""], ["Zhang", "Tong", ""], ["Gong", "Boqing", ""]]}, {"id": "1905.00448", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy", "title": "On Expected Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically investigate the (negative) expected accuracy as an alternative\nloss function to cross entropy (negative log likelihood) for classification\ntasks. Coupled with softmax activation, it has small derivatives over most of\nits domain, and is therefore hard to optimize. A modified, leaky version is\nevaluated on a variety of classification tasks, including digit recognition,\nimage classification, sequence tagging and tree tagging, using a variety of\nneural architectures such as logistic regression, multilayer perceptron, CNN,\nLSTM and Tree-LSTM. We show that it yields comparable or better accuracy\ncompared to cross entropy. Furthermore, the proposed objective is shown to be\nmore robust to label noise.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 18:53:48 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["\u0130rsoy", "Ozan", ""]]}, {"id": "1905.00455", "submitter": "Cameron Mura", "authors": "Sean Mullane, Ruoyan Chen, Sri Vaishnavi Vemulapalli, Eli J. Draizen,\n  Ke Wang, Cameron Mura, Philip E. Bourne", "title": "Machine Learning for Classification of Protein Helix Capping Motifs", "comments": "6 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biological function of a protein stems from its 3-dimensional structure,\nwhich is thermodynamically determined by the energetics of interatomic forces\nbetween its amino acid building blocks (the order of amino acids, known as the\nsequence, defines a protein). Given the costs (time, money, human resources) of\ndetermining protein structures via experimental means such as X-ray\ncrystallography, can we better describe and compare protein 3D structures in a\nrobust and efficient manner, so as to gain meaningful biological insights? We\nbegin by considering a relatively simple problem, limiting ourselves to just\nprotein secondary structural elements. Historically, many computational methods\nhave been devised to classify amino acid residues in a protein chain into one\nof several discrete secondary structures, of which the most well-characterized\nare the geometrically regular $\\alpha$-helix and $\\beta$-sheet; irregular\nstructural patterns, such as 'turns' and 'loops', are less understood. Here, we\npresent a study of Deep Learning techniques to classify the loop-like end cap\nstructures which delimit $\\alpha$-helices. Previous work used highly empirical\nand heuristic methods to manually classify helix capping motifs. Instead, we\nuse structural data directly--including (i) backbone torsion angles computed\nfrom 3D structures, (ii) macromolecular feature sets (e.g., physicochemical\nproperties), and (iii) helix cap classification data (from CAPS-DB)--as the\nground truth to train a bidirectional long short-term memory (BiLSTM) model to\nclassify helix cap residues. We tried different network architectures and\nscanned hyperparameters in order to train and assess several models; we also\ntrained a Support Vector Classifier (SVC) to use as a baseline. Ultimately, we\nachieved 85% class-balanced accuracy with a deep BiLSTM model.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:14:50 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mullane", "Sean", ""], ["Chen", "Ruoyan", ""], ["Vemulapalli", "Sri Vaishnavi", ""], ["Draizen", "Eli J.", ""], ["Wang", "Ke", ""], ["Mura", "Cameron", ""], ["Bourne", "Philip E.", ""]]}, {"id": "1905.00462", "submitter": "Bradley McDanel", "authors": "Bradley McDanel, Sai Qian Zhang, H. T. Kung, Xin Dong", "title": "Full-stack Optimization for Accelerating CNNs with FPGA Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a full-stack optimization framework for accelerating inference of\nCNNs (Convolutional Neural Networks) and validate the approach with\nfield-programmable gate arrays (FPGA) implementations. By jointly optimizing\nCNN models, computing architectures, and hardware implementations, our\nfull-stack approach achieves unprecedented performance in the trade-off space\ncharacterized by inference latency, energy efficiency, hardware utilization and\ninference accuracy. As a validation vehicle, we have implemented a 170MHz FPGA\ninference chip achieving 2.28ms latency for the ImageNet benchmark. The\nachieved latency is among the lowest reported in the literature while achieving\ncomparable accuracy. However, our chip shines in that it has 9x higher energy\nefficiency compared to other implementations achieving comparable latency. A\nhighlight of our full-stack approach which attributes to the achieved high\nenergy efficiency is an efficient Selector-Accumulator (SAC) architecture for\nimplementing the multiplier-accumulator (MAC) operation present in any digital\nCNN hardware. For instance, compared to a FPGA implementation for a traditional\n8-bit MAC, SAC substantially reduces required hardware resources (4.85x fewer\nLook-up Tables) and power consumption (2.48x).\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:30:57 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["McDanel", "Bradley", ""], ["Zhang", "Sai Qian", ""], ["Kung", "H. T.", ""], ["Dong", "Xin", ""]]}, {"id": "1905.00469", "submitter": "Tao Wang", "authors": "Tao Wang, Irene Cheng and Anup Basu", "title": "Fully Automatic Brain Tumor Segmentation using a Normalized Gaussian\n  Bayesian Classifier and 3D Fluid Vector Flow", "comments": "ICIP 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain tumor segmentation from Magnetic Resonance Images (MRIs) is an\nimportant task to measure tumor responses to treatments. However, automatic\nsegmentation is very challenging. This paper presents an automatic brain tumor\nsegmentation method based on a Normalized Gaussian Bayesian classification and\na new 3D Fluid Vector Flow (FVF) algorithm. In our method, a Normalized\nGaussian Mixture Model (NGMM) is proposed and used to model the healthy brain\ntissues. Gaussian Bayesian Classifier is exploited to acquire a Gaussian\nBayesian Brain Map (GBBM) from the test brain MR images. GBBM is further\nprocessed to initialize the 3D FVF algorithm, which segments the brain tumor.\nThis algorithm has two major contributions. First, we present a NGMM to model\nhealthy brains. Second, we extend our 2D FVF algorithm to 3D space and use it\nfor brain tumor segmentation. The proposed method is validated on a publicly\navailable dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:49:40 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Wang", "Tao", ""], ["Cheng", "Irene", ""], ["Basu", "Anup", ""]]}, {"id": "1905.00475", "submitter": "Wen Sun", "authors": "Zhao Song, Wen Sun", "title": "Efficient Model-free Reinforcement Learning in Metric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free Reinforcement Learning (RL) algorithms such as Q-learning\n[Watkins, Dayan 92] have been widely used in practice and can achieve human\nlevel performance in applications such as video games [Mnih et al. 15].\nRecently, equipped with the idea of optimism in the face of uncertainty,\nQ-learning algorithms [Jin, Allen-Zhu, Bubeck, Jordan 18] can be proven to be\nsample efficient for discrete tabular Markov Decision Processes (MDPs) which\nhave finite number of states and actions. In this work, we present an efficient\nmodel-free Q-learning based algorithm in MDPs with a natural metric on the\nstate-action space--hence extending efficient model-free Q-learning algorithms\nto continuous state-action space. Compared to previous model-based RL\nalgorithms for metric spaces [Kakade, Kearns, Langford 03], our algorithm does\nnot require access to a black-box planning oracle.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 20:10:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Song", "Zhao", ""], ["Sun", "Wen", ""]]}, {"id": "1905.00496", "submitter": "Myriam Bontonou", "authors": "Myriam Bontonou, Carlos Lassance, Jean-Charles Vialatte, Vincent\n  Gripon", "title": "A Unified Deep Learning Formalism For Processing Graph Signals", "comments": "2 pages, short version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks are very efficient at processing signals\ndefined on a discrete Euclidean space (such as images). However, as they can\nnot be used on signals defined on an arbitrary graph, other models have\nemerged, aiming to extend its properties. We propose to review some of the\nmajor deep learning models designed to exploit the underlying graph structure\nof signals. We express them in a unified formalism, giving them a new and\ncomparative reading.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 20:59:57 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Bontonou", "Myriam", ""], ["Lassance", "Carlos", ""], ["Vialatte", "Jean-Charles", ""], ["Gripon", "Vincent", ""]]}, {"id": "1905.00504", "submitter": "Chiranjib Saha", "authors": "Chiranjib Saha and Harpreet S. Dhillon", "title": "Machine Learning meets Stochastic Geometry: Determinantal Subset\n  Selection for Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless networks, many problems can be formulated as subset selection\nproblems where the goal is to select a subset from the ground set with the\nobjective of maximizing some objective function. These problems are typically\nNP-hard and hence solved through carefully constructed heuristics, which are\nthemselves mostly NP-complete and thus not easily applicable to large networks.\nOn the other hand, subset selection problems occur in slightly different\ncontext in machine learning (ML) where the goal is to select a subset of high\nquality yet diverse items from a ground set. In this paper, we introduce a\nnovel DPP-based learning (DPPL) framework for efficiently solving subset\nselection problems in wireless networks. The DPPL is intended to replace the\ntraditional optimization algorithms for subset selection by learning the\nquality-diversity trade-off in the optimal subsets selected by an optimization\nroutine. As a case study, we apply DPPL to the wireless link scheduling\nproblem, where the goal is to determine the subset of simultaneously active\nlinks which maximizes the network-wide sum-rate. We demonstrate that the\nproposed DPPL approaches the optimal solution with significantly lower\ncomputational complexity than the popular optimization algorithms used for this\nproblem in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:20:21 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Saha", "Chiranjib", ""], ["Dhillon", "Harpreet S.", ""]]}, {"id": "1905.00505", "submitter": "Arsenii Ashukha", "authors": "Andrei Atanov, Alexandra Volokhova, Arsenii Ashukha, Ivan Sosnovik,\n  Dmitry Vetrov", "title": "Semi-Conditional Normalizing Flows for Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a semi-conditional normalizing flow model for\nsemi-supervised learning. The model uses both labelled and unlabeled data to\nlearn an explicit model of joint distribution over objects and labels.\nSemi-conditional architecture of the model allows us to efficiently compute a\nvalue and gradients of the marginal likelihood for unlabeled objects. The\nconditional part of the model is based on a proposed conditional coupling\nlayer. We demonstrate performance of the model for semi-supervised\nclassification problem on different datasets. The model outperforms the\nbaseline approach based on variational auto-encoders on MNIST dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:26:48 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 17:06:49 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 15:05:02 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 10:07:33 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Atanov", "Andrei", ""], ["Volokhova", "Alexandra", ""], ["Ashukha", "Arsenii", ""], ["Sosnovik", "Ivan", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1905.00507", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu, Nishad Gothoskar, Scott Swingle, Wolfgang Lehrach,\n  Miguel L\\'azaro-Gredilla, Dileep George", "title": "Learning higher-order sequential structure with cloned HMMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable order sequence modeling is an important problem in artificial and\nnatural intelligence. While overcomplete Hidden Markov Models (HMMs), in\ntheory, have the capacity to represent long-term temporal structure, they often\nfail to learn and converge to local minima. We show that by constraining HMMs\nwith a simple sparsity structure inspired by biology, we can make it learn\nvariable order sequences efficiently. We call this model cloned HMM (CHMM)\nbecause the sparsity structure enforces that many hidden states map\ndeterministically to the same emission state. CHMMs with over 1 billion\nparameters can be efficiently trained on GPUs without being severely affected\nby the credit diffusion problem of standard HMMs. Unlike n-grams and sequence\nmemoizers, CHMMs can model temporal dependencies at arbitrarily long distances\nand recognize contexts with 'holes' in them. Compared to Recurrent Neural\nNetworks and their Long Short-Term Memory extensions (LSTMs), CHMMs are\ngenerative models that can natively deal with uncertainty. Moreover, CHMMs\nreturn a higher-order graph that represents the temporal structure of the data\nwhich can be useful for community detection, and for building hierarchical\nmodels. Our experiments show that CHMMs can beat n-grams, sequence memoizers,\nand LSTMs on character-level language modeling tasks. CHMMs can be a viable\nalternative to these methods in some tasks that require variable order sequence\nmodeling and the handling of uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:29:14 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 07:30:37 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 11:45:32 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 18:01:40 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dedieu", "Antoine", ""], ["Gothoskar", "Nishad", ""], ["Swingle", "Scott", ""], ["Lehrach", "Wolfgang", ""], ["L\u00e1zaro-Gredilla", "Miguel", ""], ["George", "Dileep", ""]]}, {"id": "1905.00510", "submitter": "Nagesh Uba", "authors": "Nagesh Kumar Uba", "title": "Land Use and Land Cover Classification Using Deep Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large datasets of sub-meter aerial imagery represented as orthophoto mosaics\nare widely available today, and these data sets may hold a great deal of\nuntapped information. This imagery has a potential to locate several types of\nfeatures; for example, forests, parking lots, airports, residential areas, or\nfreeways in the imagery. However, the appearances of these things vary based on\nmany things including the time that the image is captured, the sensor settings,\nprocessing done to rectify the image, and the geographical and cultural context\nof the region captured by the image. This thesis explores the use of deep\nconvolutional neural networks to classify land use from very high spatial\nresolution (VHR), orthorectified, visible band multispectral imagery. Recent\ntechnological and commercial applications have driven the collection a massive\namount of VHR images in the visible red, green, blue (RGB) spectral bands, this\nwork explores the potential for deep learning algorithms to exploit this\nimagery for automatic land use/ land cover (LULC) classification.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:38:54 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Uba", "Nagesh Kumar", ""]]}, {"id": "1905.00529", "submitter": "Xiang Wang", "authors": "Rong Ge, Zhize Li, Weiyao Wang, Xiang Wang", "title": "Stabilized SVRG: Simple Variance Reduction for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction techniques like SVRG provide simple and fast algorithms\nfor optimizing a convex finite-sum objective. For nonconvex objectives, these\ntechniques can also find a first-order stationary point (with small gradient).\nHowever, in nonconvex optimization it is often crucial to find a second-order\nstationary point (with small gradient and almost PSD hessian). In this paper,\nwe show that Stabilized SVRG (a simple variant of SVRG) can find an\n$\\epsilon$-second-order stationary point using only\n$\\widetilde{O}(n^{2/3}/\\epsilon^2+n/\\epsilon^{1.5})$ stochastic gradients. To\nour best knowledge, this is the first second-order guarantee for a simple\nvariant of SVRG. The running time almost matches the known guarantees for\nfinding $\\epsilon$-first-order stationary points.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:44:26 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ge", "Rong", ""], ["Li", "Zhize", ""], ["Wang", "Weiyao", ""], ["Wang", "Xiang", ""]]}, {"id": "1905.00531", "submitter": "Carlo Baldassi", "authors": "Carlo Baldassi", "title": "Recombinator-k-means: A population based algorithm that exploits\n  k-means++ for recombination", "comments": "26 pages, 9 figures (7 in main text), 11 tables (6 in main text)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple heuristic algorithm for efficiently optimizing the\nnotoriously hard \"minimum sum-of-squares clustering\" problem, usually addressed\nby the classical k-means heuristic and its variants. The algorithm, called\nrecombinator-k-means, is very similar to a genetic algorithmic scheme: it uses\npopulations of configurations, that are optimized independently in parallel and\nthen recombined in a next-iteration population batch by exploiting a variant of\nthe k-means++ seeding algorithm. An additional reweighting mechanism ensures\nthat the population eventually coalesces into a single solution. Extensive\ntests measuring optimization objective vs computational time on synthetic and\nreal-word data show that it is the only choice, among state-of-the-art\nalternatives (simple restarts, random swap, genetic algorithm with\npairwise-nearest-neighbor crossover), that consistently produces good results\nat all time scales, outperforming competitors on large and complicated\ndatasets. The only parameter that requires tuning is the population size. The\nscheme is rather general (it could be applied even to k-medians or k-medoids,\nfor example). Our implementation is publicly available at\nhttps://github.com/carlobaldassi/RecombinatorKMeans.jl.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:55:00 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 18:44:40 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 01:02:25 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Baldassi", "Carlo", ""]]}, {"id": "1905.00532", "submitter": "Andrea Bajcsy", "authors": "Andrea Bajcsy, Somil Bansal, Eli Bronstein, Varun Tolani, Claire J.\n  Tomlin", "title": "An Efficient Reachability-Based Framework for Provably Safe Autonomous\n  Navigation in Unknown Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world autonomous vehicles often operate in a priori unknown\nenvironments. Since most of these systems are safety-critical, it is important\nto ensure they operate safely in the face of environment uncertainty, such as\nunseen obstacles. Current safety analysis tools enable autonomous systems to\nreason about safety given full information about the state of the environment a\npriori. However, these tools do not scale well to scenarios where the\nenvironment is being sensed in real time, such as during navigation tasks. In\nthis work, we propose a novel, real-time safety analysis method based on\nHamilton-Jacobi reachability that provides strong safety guarantees despite\nenvironment uncertainty. Our safety method is planner-agnostic and provides\nguarantees for a variety of mapping sensors. We demonstrate our approach in\nsimulation and in hardware to provide safety guarantees around a\nstate-of-the-art vision-based, learning-based planner.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 23:55:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bajcsy", "Andrea", ""], ["Bansal", "Somil", ""], ["Bronstein", "Eli", ""], ["Tolani", "Varun", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1905.00534", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Yu-Hsiang Huang, Petar Veli\\v{c}kovi\\'c, Pietro Li\\`o,\n  Jian Tang", "title": "Drug-Drug Adverse Effect Prediction with Graph Co-Attention", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex or co-existing diseases are commonly treated using drug combinations,\nwhich can lead to higher risk of adverse side effects. The detection of\npolypharmacy side effects is usually done in Phase IV clinical trials, but\nthere are still plenty which remain undiscovered when the drugs are put on the\nmarket. Such accidents have been affecting an increasing proportion of the\npopulation (15% in the US now) and it is thus of high interest to be able to\npredict the potential side effects as early as possible. Systematic\ncombinatorial screening of possible drug-drug interactions (DDI) is challenging\nand expensive. However, the recent significant increases in data availability\nfrom pharmaceutical research and development efforts offer a novel paradigm for\nrecovering relevant insights for DDI prediction. Accordingly, several recent\napproaches focus on curating massive DDI datasets (with millions of examples)\nand training machine learning models on them. Here we propose a neural network\narchitecture able to set state-of-the-art results on this task---using the type\nof the side-effect and the molecular structure of the drugs alone---by\nleveraging a co-attentional mechanism. In particular, we show the importance of\nintegrating joint information from the drug pairs early on when learning each\ndrug's representation.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 00:10:20 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Deac", "Andreea", ""], ["Huang", "Yu-Hsiang", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""], ["Tang", "Jian", ""]]}, {"id": "1905.00547", "submitter": "George Cevora", "authors": "George Cevora", "title": "The relationship between Biological and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligence can be defined as a predominantly human ability to accomplish\ntasks that are generally hard for computers and animals. Artificial\nIntelligence [AI] is a field attempting to accomplish such tasks with\ncomputers. AI is becoming increasingly widespread, as are claims of its\nrelationship with Biological Intelligence. Often these claims are made to imply\nhigher chances of a given technology succeeding, working on the assumption that\nAI systems which mimic the mechanisms of Biological Intelligence should be more\nsuccessful.\n  In this article I will discuss the similarities and differences between AI\nand the extent of our knowledge about the mechanisms of intelligence in\nbiology, especially within humans. I will also explore the validity of the\nassumption that biomimicry in AI systems aids their advancement, and I will\nargue that existing similarity to biological systems in the way Artificial\nNeural Networks [ANNs] tackle tasks is due to design decisions, rather than\ninherent similarity of underlying mechanisms. This article is aimed at people\nwho understand the basics of AI (especially ANNs), and would like to be better\nable to evaluate the often wild claims about the value of biomimicry in AI.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:41:35 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Cevora", "George", ""]]}, {"id": "1905.00557", "submitter": "Mohammad Jafari", "authors": "Mohammad Jafari, Vahid Sarfi, Amir Ghasemkhani, Hanif Livani, Lei Yang\n  and Hao Xu", "title": "Adaptive Intelligent Secondary Control of Microgrids Using a\n  Biologically-Inspired Reinforcement Learning", "comments": "5 pages, 6 figures, 2019 IEEE Power & Energy Society General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a biologically-inspired adaptive intelligent secondary\ncontroller is developed for microgrids to tackle system dynamics uncertainties,\nfaults, and/or disturbances. The developed adaptive biologically-inspired\ncontroller adopts a novel computational model of emotional learning in\nmammalian limbic system. The learning capability of the proposed\nbiologically-inspired intelligent controller makes it a promising approach to\ndeal with the power system non-linear and volatile dynamics without increasing\nthe controller complexity, and maintain the voltage and frequency stabilities\nby using an efficient reference tracking mechanism. The performance of the\nproposed intelligent secondary controller is validated in terms of the voltage\nand frequency absolute errors in the simulated microgrid. Simulation results\nhighlight the efficiency and robustness of the proposed intelligent controller\nunder the fault conditions and different system uncertainties compared to other\nbenchmark controllers.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:00:08 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Jafari", "Mohammad", ""], ["Sarfi", "Vahid", ""], ["Ghasemkhani", "Amir", ""], ["Livani", "Hanif", ""], ["Yang", "Lei", ""], ["Xu", "Hao", ""]]}, {"id": "1905.00563", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Yifan Tian and Sameer Singh", "title": "Investigating Robustness and Interpretability of Link Prediction via\n  Adversarial Modifications", "comments": "Published at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing entities and relations in an embedding space is a well-studied\napproach for machine learning on relational data. Existing approaches, however,\nprimarily focus on improving accuracy and overlook other aspects such as\nrobustness and interpretability. In this paper, we propose adversarial\nmodifications for link prediction models: identifying the fact to add into or\nremove from the knowledge graph that changes the prediction for a target fact\nafter the model is retrained. Using these single modifications of the graph, we\nidentify the most influential fact for a predicted link and evaluate the\nsensitivity of the model to the addition of fake facts. We introduce an\nefficient approach to estimate the effect of such modifications by\napproximating the change in the embeddings when the knowledge graph changes. To\navoid the combinatorial search over all possible facts, we train a network to\ndecode embeddings to their corresponding graph components, allowing the use of\ngradient-based optimization to identify the adversarial modification. We use\nthese techniques to evaluate the robustness of link prediction models (by\nmeasuring sensitivity to additional facts), study interpretability through the\nfacts most responsible for predictions (by identifying the most influential\nneighbors), and detect incorrect facts in the knowledge base.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:30:17 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Tian", "Yifan", ""], ["Singh", "Sameer", ""]]}, {"id": "1905.00568", "submitter": "Mohammed Amer", "authors": "Mohammed Amer, Tom\\'as Maul", "title": "Weight Map Layer for Noise and Adversarial Attack Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are known for their good performance and\ngeneralization in vision-related tasks and have become state-of-the-art in both\napplication and research-based domains. However, just like other neural network\nmodels, they suffer from a susceptibility to noise and adversarial attacks. An\nadversarial defence aims at reducing a neural network's susceptibility to\nadversarial attacks through learning or architectural modifications. We propose\nthe weight map layer (WM) as a generic architectural addition to CNNs and show\nthat it can increase their robustness to noise and adversarial attacks. We\nfurther explain that the enhanced robustness of the two WM variants results\nfrom the adaptive activation-variance amplification exhibited by the layer. We\nshow that the WM layer can be integrated into scaled up models to increase\ntheir noise and adversarial attack robustness, while achieving comparable\naccuracy levels across different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 04:20:11 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 11:40:32 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Amer", "Mohammed", ""], ["Maul", "Tom\u00e1s", ""]]}, {"id": "1905.00569", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Mohammad Mahdi Khalili, Cem Tekin, Mingyan Liu", "title": "Group Retention when Using Machine Learning in Sequential Decision\n  Making: the Interplay between User Dynamics and Fairness", "comments": "In the 33rd Conference on Neural Information Processing Systems\n  (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models trained on data from multiple demographic groups\ncan inherit representation disparity (Hashimoto et al., 2018) that may exist in\nthe data: the model may be less favorable to groups contributing less to the\ntraining process; this in turn can degrade population retention in these groups\nover time, and exacerbate representation disparity in the long run. In this\nstudy, we seek to understand the interplay between ML decisions and the\nunderlying group representation, how they evolve in a sequential framework, and\nhow the use of fairness criteria plays a role in this process. We show that the\nrepresentation disparity can easily worsen over time under a natural user\ndynamics (arrival and departure) model when decisions are made based on a\ncommonly used objective and fairness criteria, resulting in some groups\ndiminishing entirely from the sample pool in the long run. It highlights the\nfact that fairness criteria have to be defined while taking into consideration\nthe impact of decisions on user dynamics. Toward this end, we explain how a\nproper fairness criterion can be selected based on a general user dynamics\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 04:30:08 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 20:05:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhang", "Xueru", ""], ["Khalili", "Mohammad Mahdi", ""], ["Tekin", "Cem", ""], ["Liu", "Mingyan", ""]]}, {"id": "1905.00571", "submitter": "Xiaolong Ma", "authors": "Wei Niu, Xiaolong Ma, Yanzhi Wang, Bin Ren", "title": "26ms Inference Time for ResNet-50: Towards Real-Time Execution of all\n  DNNs on Smartphone", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of a spectrum of high-end mobile devices, many\napplications that required desktop-level computation capability formerly can\nnow run on these devices without any problem. However, without a careful\noptimization, executing Deep Neural Networks (a key building block of the\nreal-time video stream processing that is the foundation of many popular\napplications) is still challenging, specifically, if an extremely low latency\nor high accuracy inference is needed. This work presents CADNN, a programming\nframework to efficiently execute DNN on mobile devices with the help of\nadvanced model compression (sparsity) and a set of thorough architecture-aware\noptimization. The evaluation result demonstrates that CADNN outperforms all the\nstate-of-the-art dense DNN execution frameworks like TensorFlow Lite and TVM.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 04:37:27 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Niu", "Wei", ""], ["Ma", "Xiaolong", ""], ["Wang", "Yanzhi", ""], ["Ren", "Bin", ""]]}, {"id": "1905.00572", "submitter": "Vladimir Eidelman", "authors": "Vlad Eidelman and Brian Grom", "title": "Argument Identification in Public Comments from eRulemaking", "comments": "ICAIL 2019, extended version with examples", "journal-ref": null, "doi": "10.1145/3322640.3326714", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Administrative agencies in the United States receive millions of comments\neach year concerning proposed agency actions during the eRulemaking process.\nThese comments represent a diversity of arguments in support and opposition of\nthe proposals. While agencies are required to identify and respond to\nsubstantive comments, they have struggled to keep pace with the volume of\ninformation. In this work we address the tasks of identifying argumentative\ntext, classifying the type of argument claims employed, and determining the\nstance of the comment. First, we propose a taxonomy of argument claims based on\nan analysis of thousands of rules and millions of comments. Second, we collect\nand semi-automatically bootstrap annotations to create a dataset of millions of\nsentences with argument claim type annotation at the sentence level. Third, we\nbuild a system for automatically determining argumentative spans and claim type\nusing our proposed taxonomy in a hierarchical classification model.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 05:04:03 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 03:22:31 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Eidelman", "Vlad", ""], ["Grom", "Brian", ""]]}, {"id": "1905.00586", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja", "title": "Estimating Kullback-Leibler Divergence Using Kernel Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a method called the Mutual Information Neural Estimator (MINE) that\nuses neural networks has been proposed to estimate mutual information and more\ngenerally the Kullback-Leibler (KL) divergence between two distributions. The\nmethod uses the Donsker-Varadhan representation to arrive at the estimate of\nthe KL divergence and is better than the existing estimators in terms of\nscalability and flexibility. The output of MINE algorithm is not guaranteed to\nbe a consistent estimator. We propose a new estimator that instead of searching\namong functions characterized by neural networks searches the functions in a\nReproducing Kernel Hilbert Space. We prove that the proposed estimator is\nconsistent. We carry out simulations and show that when the datasets are small\nthe proposed estimator is more reliable than the MINE estimator and when the\ndatasets are large the performance of the two methods are close.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 06:31:16 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 01:02:50 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ahuja", "Kartik", ""]]}, {"id": "1905.00587", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Wei Zhan and Masayoshi Tomizuka", "title": "Coordination and Trajectory Prediction for Vehicle Interactions via\n  Bayesian Generative Modeling", "comments": "Accepted by 2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination recognition and subtle pattern prediction of future trajectories\nplay a significant role when modeling interactive behaviors of multiple agents.\nDue to the essential property of uncertainty in the future evolution,\ndeterministic predictors are not sufficiently safe and robust. In order to\ntackle the task of probabilistic prediction for multiple, interactive entities,\nwe propose a coordination and trajectory prediction system (CTPS), which has a\nhierarchical structure including a macro-level coordination recognition module\nand a micro-level subtle pattern prediction module which solves a probabilistic\ngeneration task. We illustrate two types of representation of the coordination\nvariable: categorized and real-valued, and compare their effects and advantages\nbased on empirical studies. We also bring the ideas of Bayesian deep learning\ninto deep generative models to generate diversified prediction hypotheses. The\nproposed system is tested on multiple driving datasets in various traffic\nscenarios, which achieves better performance than baseline approaches in terms\nof a set of evaluation metrics. The results also show that using categorized\ncoordination can better capture multi-modality and generate more diversified\nsamples than the real-valued coordination, while the latter can generate\nprediction hypotheses with smaller errors with a sacrifice of sample diversity.\nMoreover, employing neural networks with weight uncertainty is able to generate\nsamples with larger variance and diversity.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 06:40:54 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.00599", "submitter": "Reza Malekian Ph.D.", "authors": "Schalk Wilhelm Pienaar, Reza Malekian", "title": "Human Activity Recognition Using LSTM-RNN Deep Neural Network\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using raw sensor data to model and train networks for Human Activity\nRecognition can be used in many different applications, from fitness tracking\nto safety monitoring applications. These models can be easily extended to be\ntrained with different data sources for increased accuracies or an extension of\nclassifications for different prediction classes. This paper goes into the\ndiscussion on the available dataset provided by WISDM and the unique features\nof each class for the different axes. Furthermore, the design of a Long Short\nTerm Memory (LSTM) architecture model is outlined for the application of human\nactivity recognition. An accuracy of above 94% and a loss of less than 30% has\nbeen reached in the first 500 epochs of training.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 07:39:28 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Pienaar", "Schalk Wilhelm", ""], ["Malekian", "Reza", ""]]}, {"id": "1905.00609", "submitter": "Bin Liu", "authors": "Bin Liu and Grigorios Tsoumakas", "title": "Synthetic Oversampling of Multi-Label Data based on Local Label\n  Distribution", "comments": null, "journal-ref": "ECML-PKDD 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-imbalance is an inherent characteristic of multi-label data which\naffects the prediction accuracy of most multi-label learning methods. One\nefficient strategy to deal with this problem is to employ resampling techniques\nbefore training the classifier. Existing multilabel sampling methods alleviate\nthe (global) imbalance of multi-label datasets. However, performance\ndegradation is mainly due to rare subconcepts and overlapping of classes that\ncould be analysed by looking at the local characteristics of the minority\nexamples, rather than the imbalance of the whole dataset. We propose a new\nmethod for synthetic oversampling of multi-label data that focuses on local\nlabel distribution to generate more diverse and better labeled instances.\nExperimental results on 13 multi-label datasets demonstrate the effectiveness\nof the proposed approach in a variety of evaluation measures, particularly in\nthe case of an ensemble of classifiers trained on repeated samples of the\noriginal data.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:13:05 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 14:33:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Liu", "Bin", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1905.00616", "submitter": "He Zhao", "authors": "He Zhao, Piyush Rai, Lan Du, Wray Buntine, Mingyuan Zhou", "title": "Variational Autoencoders for Sparse and Overdispersed Discrete Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many applications, such as text modelling, high-throughput sequencing, and\nrecommender systems, require analysing sparse, high-dimensional, and\noverdispersed discrete (count-valued or binary) data. Although probabilistic\nmatrix factorisation and linear/nonlinear latent factor models have enjoyed\ngreat success in modelling such data, many existing models may have inferior\nmodelling performance due to the insufficient capability of modelling\noverdispersion in count-valued data and model misspecification in general. In\nthis paper, we comprehensively study these issues and propose a variational\nautoencoder based framework that generates discrete data via negative-binomial\ndistribution. We also examine the model's ability to capture properties, such\nas self- and cross-excitations in discrete data, which is critical for\nmodelling overdispersion. We conduct extensive experiments on three important\nproblems from discrete data analysis: text analysis, collaborative filtering,\nand multi-label learning. Compared with several state-of-the-art baselines, the\nproposed models achieve significantly better performance on the above problems.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:28:17 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:09:47 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhao", "He", ""], ["Rai", "Piyush", ""], ["Du", "Lan", ""], ["Buntine", "Wray", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.00626", "submitter": "Eliza Wszola", "authors": "Eliza Wszola, Celestine Mendler-D\\\"unner, Martin Jaggi, Markus\n  P\\\"uschel", "title": "On Linear Learning with Manycore Processors", "comments": "Accepted to 2019 IEEE 26th International Conference on High\n  Performance Computing, Data, and Analytics (HiPC)", "journal-ref": null, "doi": "10.1109/HiPC.2019.00032", "report-no": null, "categories": "cs.PF cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new generation of manycore processors is on the rise that offers dozens and\nmore cores on a chip and, in a sense, fuses host processor and accelerator. In\nthis paper we target the efficient training of generalized linear models on\nthese machines. We propose a novel approach for achieving parallelism which we\ncall Heterogeneous Tasks on Homogeneous Cores (HTHC). It divides the problem\ninto multiple fundamentally different tasks, which themselves are parallelized.\nFor evaluation, we design a detailed, architecture-cognizant implementation of\nour scheme on a recent 72-core Knights Landing processor that is adaptive to\nthe cache, memory, and core structure. Our library efficiently supports dense\nand sparse datasets as well as 4-bit quantized data for further possible gains\nin performance. We show benchmarks for Lasso and SVM with different data sets\nagainst straightforward parallel implementations and prior software. In\nparticular, for Lasso on dense data, we improve the state-of-the-art by an\norder of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:01:10 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 07:52:01 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 08:06:31 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 15:48:28 GMT"}, {"version": "v5", "created": "Wed, 22 Jan 2020 07:31:02 GMT"}, {"version": "v6", "created": "Wed, 5 Feb 2020 06:35:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wszola", "Eliza", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Jaggi", "Martin", ""], ["P\u00fcschel", "Markus", ""]]}, {"id": "1905.00643", "submitter": "Sukarna Barua", "authors": "Sukarna Barua and Xingjun Ma and Sarah Monazam Erfani and Michael E.\n  Houle and James Bailey", "title": "Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality", "comments": "The first and original version of this paper was submitted to ICLR\n  2019 conference. Submission link: https://openreview.net/pdf?id=BJgYl205tQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are an elegant mechanism for data\ngeneration. However, a key challenge when using GANs is how to best measure\ntheir ability to generate realistic data. In this paper, we demonstrate that an\nintrinsic dimensional characterization of the data space learned by a GAN model\nleads to an effective evaluation metric for GAN quality. In particular, we\npropose a new evaluation measure, CrossLID, that assesses the local intrinsic\ndimensionality (LID) of real-world data with respect to neighborhoods found in\nGAN-generated samples. Intuitively, CrossLID measures the degree to which\nmanifolds of two data distributions coincide with each other. In experiments on\n4 benchmark image datasets, we compare our proposed measure to several\nstate-of-the-art evaluation metrics. Our experiments show that CrossLID is\nstrongly correlated with the progress of GAN training, is sensitive to mode\ncollapse, is robust to small-scale noise and image transformations, and robust\nto sample size. Furthermore, we show how CrossLID can be used within the GAN\ntraining process to improve generation quality.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:50:27 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Barua", "Sukarna", ""], ["Ma", "Xingjun", ""], ["Erfani", "Sarah Monazam", ""], ["Houle", "Michael E.", ""], ["Bailey", "James", ""]]}, {"id": "1905.00672", "submitter": "Jithin Sreedharan", "authors": "Krzysztof Turowski and Jithin K. Sreedharan and Wojciech Szpankowski", "title": "Temporal Ordered Clustering in Dynamic Networks: Unsupervised and\n  Semi-supervised Learning Algorithms", "comments": "14 pages, 9 figures, and 3 tables. This version is submitted to a\n  journal. A shorter version of this work is published in the proceedings of\n  IEEE International Symposium on Information Theory (ISIT), 2020. The first\n  two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In temporal ordered clustering, given a single snapshot of a dynamic network\nin which nodes arrive at distinct time instants, we aim at partitioning its\nnodes into $K$ ordered clusters $\\mathcal{C}_1 \\prec \\cdots \\prec\n\\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\\mathcal{C}_i$ arrived\nbefore nodes in cluster $\\mathcal{C}_j$, with $K$ being a data-driven parameter\nand not known upfront. Such a problem is of considerable significance in many\napplications ranging from tracking the expansion of fake news to mapping the\nspread of information. We first formulate our problem for a general dynamic\ngraph, and propose an integer programming framework that finds the optimal\nclustering, represented as a strict partial order set, achieving the best\nprecision (i.e., fraction of successfully ordered node pairs) for a fixed\ndensity (i.e., fraction of comparable node pairs). We then develop a sequential\nimportance procedure and design unsupervised and semi-supervised algorithms to\nfind temporal ordered clusters that efficiently approximate the optimal\nsolution. To illustrate the techniques, we apply our methods to the vertex\ncopying (duplication-divergence) model which exhibits some edge-case challenges\nin inferring the clusters as compared to other network models. Finally, we\nvalidate the performance of the proposed algorithms on synthetic and real-world\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 11:36:11 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 23:37:42 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2019 19:36:16 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 18:29:54 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Turowski", "Krzysztof", ""], ["Sreedharan", "Jithin K.", ""], ["Szpankowski", "Wojciech", ""]]}, {"id": "1905.00689", "submitter": "Alexandros Kouris", "authors": "Alexandros Kouris, Stylianos I. Venieris, Michail Rizakis,\n  Christos-Savvas Bouganis", "title": "Approximate LSTMs for Time-Constrained Inference: Enabling Fast Reaction\n  in Self-Driving Cars", "comments": "PREPRINT: Accepted for publication at the IEEE Consumer Electronics\n  Magazine (CEM). [Acceptance Date: 28-Oct-2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to recognise long-term dependencies in sequential data such as video\nstreams has made Long Short-Term Memory (LSTM) networks a prominent Artificial\nIntelligence model for many emerging applications. However, the high\ncomputational and memory demands of LSTMs introduce challenges in their\ndeployment on latency-critical systems such as self-driving cars which are\nequipped with limited computational resources on-board. In this paper, we\nintroduce a progressive inference computing scheme that combines model pruning\nand computation restructuring leading to the best possible approximation of the\nresult given the available latency budget of the target application. The\nproposed methodology enables mission-critical systems to make informed\ndecisions even in early stages of the computation, based on approximate LSTM\ninference, meeting their specifications on safety and robustness. Our\nexperiments on a state-of-the-art driving model for autonomous vehicle\nnavigation demonstrate that the proposed approach can yield outputs with\nsimilar quality of result compared to a faithful LSTM baseline, up to 415x\nfaster (198x on average, 76x geo. mean).\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 12:09:59 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 13:31:09 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kouris", "Alexandros", ""], ["Venieris", "Stylianos I.", ""], ["Rizakis", "Michail", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1905.00702", "submitter": "Ze Wang", "authors": "Jingyuan Wang, Junjie Wu, Ze Wang, Fei Gao and Zhang Xiong", "title": "Understanding Urban Dynamics via Context-aware Tensor Factorization with\n  Neighboring Regularization", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2019.2915231", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the world-wide emergence of mega-metropolises\nwith incredibly huge populations. Understanding residents mobility patterns, or\nurban dynamics, thus becomes crucial for building modern smart cities. In this\npaper, we propose a Neighbor-Regularized and context-aware Non-negative Tensor\nFactorization model (NR-cNTF) to discover interpretable urban dynamics from\nurban heterogeneous data. Different from many existing studies concerned with\nprediction tasks via tensor completion, NR-cNTF focuses on gaining urban\nmanagerial insights from spatial, temporal, and spatio-temporal patterns. This\nis enabled by high-quality Tucker factorizations regularized by both POI-based\nurban contexts and geographically neighboring relations. NR-cNTF is also\ncapable of unveiling long-term evolutions of urban dynamics via a pipeline\ninitialization approach. We apply NR-cNTF to a real-life data set containing\nrich taxi GPS trajectories and POI records of Beijing. The results indicate: 1)\nNR-cNTF accurately captures four kinds of city rhythms and seventeen spatial\ncommunities; 2) the rapid development of Beijing, epitomized by the CBD area,\nindeed intensifies the job-housing imbalance; 3) the southern areas with recent\ngovernment investments have shown more healthy development tendency. Finally,\nNR-cNTF is compared with some baselines on traffic prediction, which further\njustifies the importance of urban contexts awareness and neighboring\nregulations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 13:27:27 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 18:10:50 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Jingyuan", ""], ["Wu", "Junjie", ""], ["Wang", "Ze", ""], ["Gao", "Fei", ""], ["Xiong", "Zhang", ""]]}, {"id": "1905.00709", "submitter": "Niels Bruun Ipsen", "authors": "Niels Bruun Ipsen, Lars Kai Hansen", "title": "Phase transition in PCA with missing data: Reduced signal-to-noise\n  ratio, not sample size!", "comments": "Accepted to ICML 2019. This version is the submitted paper", "journal-ref": "International Conference on Machine Learning. 2019. pp. 2951-2960", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does missing data affect our ability to learn signal structures? It has\nbeen shown that learning signal structure in terms of principal components is\ndependent on the ratio of sample size and dimensionality and that a critical\nnumber of observations is needed before learning starts (Biehl and Mietzner,\n1993). Here we generalize this analysis to include missing data. Probabilistic\nprincipal component analysis is regularly used for estimating signal structures\nin datasets with missing data. Our analytic result suggests that the effect of\nmissing data is to effectively reduce signal-to-noise ratio rather than - as\ngenerally believed - to reduce sample size. The theory predicts a phase\ntransition in the learning curves and this is indeed found both in simulation\ndata and in real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:00:06 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ipsen", "Niels Bruun", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1905.00741", "submitter": "Janne Karttunen", "authors": "Janne Karttunen, Anssi Kanervisto, Ville Kyrki, Ville Hautam\\\"aki", "title": "From Video Game to Real Robot: The Transfer between Action Spaces", "comments": "Two first authors contributed equally. Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has proven to be successful for learning tasks in\nsimulated environments, but applying same techniques for robots in real-world\ndomain is more challenging, as they require hours of training. To address this,\ntransfer learning can be used to train the policy first in a simulated\nenvironment and then transfer it to physical agent. As the simulation never\nmatches reality perfectly, the physics, visuals and action spaces by necessity\ndiffer between these environments to some degree. In this work, we study how\ngeneral video games can be directly used instead of fine-tuned simulations for\nthe sim-to-real transfer. Especially, we study how the agent can learn the new\naction space autonomously, when the game actions do not match the robot\nactions. Our results show that the different action space can be learned by\nre-training only part of neural network and we obtain above 90% mean success\nrate in simulation and robot experiments.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:42:51 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:39:51 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Karttunen", "Janne", ""], ["Kanervisto", "Anssi", ""], ["Kyrki", "Ville", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1905.00751", "submitter": "Patrik Bachtiger", "authors": "Heather Mattie, Patrick Reidy, Patrik Bachtiger, Emily Lindemer,\n  Mohammad Jouni, Trishan Panch", "title": "A Framework for Predicting Impactability of Healthcare Interventions\n  Using Machine Learning Methods, Administrative Claims, Sociodemographic and\n  App Generated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not clear how to target patients who are most likely to benefit from\ndigital care management programs ex-ante, a shortcoming of current risk score\nbased approaches. This study focuses on defining impactability by identifying\nthose patients most likely to benefit from technology enabled care management,\ndelivered through a digital health platform, including a mobile app and\nclinician web dashboard. Anonymized insurance claims data were used from a\ncommercially insured population across several U.S. states and combined with\ninferred sociodemographic data and data derived from the patient-held mobile\napplication itself. Our approach involves the creation of two models and the\ncomparative analysis of the methodologies and performances therein. We first\ntrain a cost prediction model to calculate the differences in predicted\n(without intervention) versus actual (with onboarding onto digital health\nplatform) healthcare expenditure for patients (N = 1,242). This enables the\nclassification of impactability if differences in predicted versus actual costs\nmeet a predetermined threshold. A random forest machine learning model was then\ntrained to accurately categorize new patients as impactable versus not\nimpactable, reaching an overall accuracy of 71.9%. We then modify these\nparameters through grid search to define the parameters that deliver optimal\nperformance. A roadmap is proposed to iteratively improve the performance of\nthe model. As the number of newly onboarded patients and length of use\ncontinues to increase, the accuracy of predicting impactability will improve\ncommensurately as more advanced machine learning techniques such as deep\nlearning become relevant. This approach is generalizable to analyzing the\nimpactability of any intervention and is a key component of realising closed\nloop feedback systems for continuous improvement in healthcare.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 16:06:29 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 13:12:59 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mattie", "Heather", ""], ["Reidy", "Patrick", ""], ["Bachtiger", "Patrik", ""], ["Lindemer", "Emily", ""], ["Jouni", "Mohammad", ""], ["Panch", "Trishan", ""]]}, {"id": "1905.00752", "submitter": "Isaac Mativo", "authors": "Isaac Mativo, Yelena Yesha, Michael Grasso, Tim Oates, Qian Zhu", "title": "Hybrid Mortality Prediction using Multiple Source Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of artificial intelligence in clinical care to improve decision\nsupport systems is increasing. This is not surprising since, by its very\nnature, the practice of medicine consists of making decisions based on\nobservations from different systems both inside and outside the human body. In\nthis paper, we combine three general systems (ICU, diabetes, and comorbidities)\nand use them to make patient clinical predictions. We use an artificial\nintelligence approach to show that we can improve mortality prediction of\nhospitalized diabetic patients. We do this by utilizing a machine learning\napproach to select clinical input features that are more likely to predict\nmortality. We then use these features to create a hybrid mortality prediction\nmodel and compare our results to non-artificial intelligence models. For\nsimplicity, we limit our input features to patient comorbidities and features\nderived from a well-known mortality measure, the Sequential Organ Failure\nAssessment (SOFA).\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 03:32:57 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mativo", "Isaac", ""], ["Yesha", "Yelena", ""], ["Grasso", "Michael", ""], ["Oates", "Tim", ""], ["Zhu", "Qian", ""]]}, {"id": "1905.00753", "submitter": "Gang Huang", "authors": "Chao Wu, Jun Xiao, Gang Huang, Fei Wu", "title": "Galaxy Learning -- A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rapid development of artificial intelligence (AI, mainly driven by\nmachine learning research, especially deep learning) has achieved phenomenal\nsuccess in various applications. However, to further apply AI technologies in\nreal-world context, several significant issues regarding the AI ecosystem\nshould be addressed. We identify the main issues as data privacy, ownership,\nand exchange, which are difficult to be solved with the current centralized\nparadigm of machine learning training methodology. As a result, we propose a\nnovel model training paradigm based on blockchain, named Galaxy Learning, which\naims to train a model with distributed data and to reserve the data ownership\nfor their owners. In this new paradigm, encrypted models are moved around\ninstead, and are federated once trained. Model training, as well as the\ncommunication, is achieved with blockchain and its smart contracts. Pricing of\ntraining data is determined by its contribution, and therefore it is not about\nthe exchange of data ownership. In this position paper, we describe the\nmotivation, paradigm, design, and challenges as well as opportunities of Galaxy\nLearning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 11:05:26 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Wu", "Chao", ""], ["Xiao", "Jun", ""], ["Huang", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1905.00773", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu", "title": "Clustering Images by Unmasking - A New Baseline", "comments": "Accepted at ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel agglomerative clustering method based on unmasking, a\ntechnique that was previously used for authorship verification of text\ndocuments and for abnormal event detection in videos. In order to join two\nclusters, we alternate between (i) training a binary classifier to distinguish\nbetween the samples from one cluster and the samples from the other cluster,\nand (ii) removing at each step the most discriminant features. The\nfaster-decreasing accuracy rates of the intermediately-obtained classifiers\nindicate that the two clusters should be joined. To the best of our knowledge,\nthis is the first work to apply unmasking in order to cluster images. We\ncompare our method with k-means as well as a recent state-of-the-art clustering\nmethod. The empirical results indicate that our approach is able to improve\nperformance for various (deep and shallow) feature representations and\ndifferent tasks, such as handwritten digit recognition, texture classification\nand fine-grained object recognition.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:35:29 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1905.00780", "submitter": "Suraj Srinivas", "authors": "Suraj Srinivas, Francois Fleuret", "title": "Full-Gradient Representation for Neural Network Visualization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new tool for interpreting neural net responses, namely\nfull-gradients, which decomposes the neural net response into input sensitivity\nand per-neuron sensitivity components. This is the first proposed\nrepresentation which satisfies two key properties: completeness and weak\ndependence, which provably cannot be satisfied by any saliency map-based\ninterpretability method. For convolutional nets, we also propose an approximate\nsaliency map representation, called FullGrad, obtained by aggregating the\nfull-gradient components.\n  We experimentally evaluate the usefulness of FullGrad in explaining model\nbehaviour with two quantitative tests: pixel perturbation and\nremove-and-retrain. Our experiments reveal that our method explains model\nbehaviour correctly, and more comprehensively than other methods in the\nliterature. Visual inspection also reveals that our saliency maps are sharper\nand more tightly confined to object regions than other methods.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:41:31 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 09:43:43 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 11:47:37 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 13:59:05 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Srinivas", "Suraj", ""], ["Fleuret", "Francois", ""]]}, {"id": "1905.00789", "submitter": "Sheng Lin", "authors": "Sheng Lin, Xiaolong Ma, Shaokai Ye, Geng Yuan, Kaisheng Ma, Yanzhi\n  Wang", "title": "Toward Extremely Low Bit and Lossless Accuracy in DNNs with Progressive\n  ADMM", "comments": "Accepted by ICML workshop (ODML-CDNNR2019). arXiv admin note:\n  substantial text overlap with arXiv:1903.09769", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight quantization is one of the most important techniques of Deep Neural\nNetworks (DNNs) model compression method. A recent work using systematic\nframework of DNN weight quantization with the advanced optimization algorithm\nADMM (Alternating Direction Methods of Multipliers) achieves one of\nstate-of-art results in weight quantization. In this work, we first extend such\nADMM-based framework to guarantee solution feasibility and we have further\ndeveloped a multi-step, progressive DNN weight quantization framework, with\ndual benefits of (i) achieving further weight quantization thanks to the\nspecial property of ADMM regularization, and (ii) reducing the search space\nwithin each step. Extensive experimental results demonstrate the superior\nperformance compared with prior work. Some highlights: we derive the first\nlossless and fully binarized (for all layers) LeNet-5 for MNIST; And we derive\nthe first fully binarized (for all layers) VGG-16 for CIFAR-10 and ResNet for\nImageNet with reasonable accuracy loss.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:53:24 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Lin", "Sheng", ""], ["Ma", "Xiaolong", ""], ["Ye", "Shaokai", ""], ["Yuan", "Geng", ""], ["Ma", "Kaisheng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1905.00794", "submitter": "Kateryna Chumachenko", "authors": "Kateryna Chumachenko, Jenni Raitoharju, Alexandros Iosifidis, Moncef\n  Gabbouj", "title": "Speed-up and multi-view extensions to Subclass Discriminant Analysis", "comments": "accepted to Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107660", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a speed-up approach for subclass discriminant\nanalysis and formulate a novel efficient multi-view solution to it. The\nspeed-up approach is developed based on graph embedding and spectral regression\napproaches that involve eigendecomposition of the corresponding Laplacian\nmatrix and regression to its eigenvectors. We show that by exploiting the\nstructure of the between-class Laplacian matrix, the eigendecomposition step\ncan be substituted with a much faster process. Furthermore, we formulate a\nnovel criterion for multi-view subclass discriminant analysis and show that an\nefficient solution for it can be obtained in a similar to the single-view\nmanner. We evaluate the proposed methods on nine single-view and nine\nmulti-view datasets and compare them with related existing approaches.\nExperimental results show that the proposed solutions achieve competitive\nperformance, often outperforming the existing methods. At the same time, they\nsignificantly decrease the training time.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:59:54 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 13:24:38 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chumachenko", "Kateryna", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1905.00805", "submitter": "Wenhui Yu", "authors": "Wenhui Yu, Zheng Qin", "title": "Spectrum-enhanced Pairwise Learning to Rank", "comments": "11 pages; submitted to World Wide Web Conference (WWW 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enhance the performance of the recommender system, side information is\nextensively explored with various features (e.g., visual features and textual\nfeatures). However, there are some demerits of side information: (1) the extra\ndata is not always available in all recommendation tasks; (2) it is only for\nitems, there is seldom high-level feature describing users. To address these\ngaps, we introduce the spectral features extracted from two hypergraph\nstructures of the purchase records. Spectral features describe the\n\\textit{similarity} of users/items in the graph space, which is critical for\nrecommendation. We leverage spectral features to model the users' preference\nand items' properties by incorporating them into a Matrix Factorization (MF)\nmodel. In addition to modeling, we also use spectral features to optimize.\nBayesian Personalized Ranking (BPR) is extensively leveraged to optimize models\nin implicit feedback data. However, in BPR, all missing values are regarded as\nnegative samples equally while many of them are indeed unseen positive ones. We\nenrich the positive samples by calculating the similarity among users/items by\nthe spectral features. The key ideas are: (1) similar users shall have similar\npreference on the same item; (2) a user shall have similar perception on\nsimilar items. Extensive experiments on two real-world datasets demonstrate the\nusefulness of the spectral features and the effectiveness of our\nspectrum-enhanced pairwise optimization. Our models outperform several\nstate-of-the-art models significantly.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:25:56 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Yu", "Wenhui", ""], ["Qin", "Zheng", ""]]}, {"id": "1905.00820", "submitter": "Antonio H. Ribeiro", "authors": "Ant\\^onio H. Ribeiro, Koen Tiels, Jack Umenberger, Thomas B. Sch\\\"on,\n  Luis A. Aguirre", "title": "On the smoothness of nonlinear system identification", "comments": null, "journal-ref": "Automatica, vol. 121, 109158, Nov. 2020", "doi": "10.1016/j.automatica.2020.109158", "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We shed new light on the \\textit{smoothness} of optimization problems arising\nin prediction error parameter estimation of linear and nonlinear systems. We\nshow that for regions of the parameter space where the model is not\ncontractive, the Lipschitz constant and $\\beta$-smoothness of the objective\nfunction might blow up exponentially with the simulation length, making it hard\nto numerically find minima within those regions or, even, to escape from them.\nIn addition to providing theoretical understanding of this problem, this paper\nalso proposes the use of multiple shooting as a viable solution. The proposed\nmethod minimizes the error between a prediction model and the observed values.\nRather than running the prediction model over the entire dataset, multiple\nshooting splits the data into smaller subsets and runs the prediction model\nover each subset, making the simulation length a design parameter and making it\npossible to solve problems that would be infeasible using a standard approach.\nThe equivalence to the original problem is obtained by including constraints in\nthe optimization. The new method is illustrated by estimating the parameters of\nnonlinear systems with chaotic or unstable behavior, as well as neural\nnetworks. We also present a comparative analysis of the proposed method with\nmulti-step-ahead prediction error minimization.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:52:33 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:35:13 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Tiels", "Koen", ""], ["Umenberger", "Jack", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Aguirre", "Luis A.", ""]]}, {"id": "1905.00863", "submitter": "Jack Kosaian", "authors": "Jack Kosaian, K.V. Rashmi, Shivaram Venkataraman", "title": "Parity Models: A General Framework for Coding-Based Resilience in ML\n  Inference", "comments": "This paper is superseded by the ACM SOSP 2019 paper \"Parity Models:\n  Erasure-Coded Resilience for Prediction Serving Systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are becoming the primary workhorses for many\napplications. Production services deploy models through prediction serving\nsystems that take in queries and return predictions by performing inference on\nmachine learning models. In order to scale to high query rates, prediction\nserving systems are run on many machines in cluster settings, and thus are\nprone to slowdowns and failures that inflate tail latency and cause violations\nof strict latency targets. Current approaches to reducing tail latency are\ninadequate for the latency targets of prediction serving, incur high resource\noverhead, or are inapplicable to the computations performed during inference.\n  We present ParM, a novel, general framework for making use of ideas from\nerasure coding and machine learning to achieve low-latency, resource-efficient\nresilience to slowdowns and failures in prediction serving systems. ParM\nencodes multiple queries together into a single parity query and performs\ninference on the parity query using a parity model. A decoder uses the output\nof a parity model to reconstruct approximations of unavailable predictions.\nParM uses neural networks to learn parity models that enable simple, fast\nencoders and decoders to reconstruct unavailable predictions for a variety of\ninference tasks such as image classification, speech recognition, and object\nlocalization. We build ParM atop an open-source prediction serving system and\nthrough extensive evaluation show that ParM improves overall accuracy in the\nface of unavailability with low latency while using 2-4$\\times$ less additional\nresources than replication-based approaches. ParM reduces the gap between\n99.9th percentile and median latency by up to $3.5\\times$ compared to\napproaches that use an equal amount of resources, while maintaining the same\nmedian.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:22:13 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 11:36:10 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kosaian", "Jack", ""], ["Rashmi", "K. V.", ""], ["Venkataraman", "Shivaram", ""]]}, {"id": "1905.00875", "submitter": "Weidi Xie", "authors": "Zihang Lai and Weidi Xie", "title": "Self-supervised Learning for Video Correspondence Flow", "comments": "BMVC2019 (Oral Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this paper is self-supervised learning of feature embeddings\nthat are suitable for matching correspondences along the videos, which we term\ncorrespondence flow. By leveraging the natural spatial-temporal coherence in\nvideos, we propose to train a ``pointer'' that reconstructs a target frame by\ncopying pixels from a reference frame.\n  We make the following contributions: First, we introduce a simple information\nbottleneck that forces the model to learn robust features for correspondence\nmatching, and prevent it from learning trivial solutions, \\eg matching based on\nlow-level colour information. Second, to tackle the challenges from tracker\ndrifting, due to complex object deformations, illumination changes and\nocclusions, we propose to train a recursive model over long temporal windows\nwith scheduled sampling and cycle consistency. Third, we achieve\nstate-of-the-art performance on DAVIS 2017 video segmentation and JHMDB\nkeypoint tracking tasks, outperforming all previous self-supervised learning\napproaches by a significant margin. Fourth, in order to shed light on the\npotential of self-supervised learning on the task of video correspondence flow,\nwe probe the upper bound by training on additional data, \\ie more diverse\nvideos, further demonstrating significant improvements on video segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:45:16 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:55:38 GMT"}, {"version": "v3", "created": "Sat, 6 Jul 2019 11:43:28 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 21:59:59 GMT"}, {"version": "v5", "created": "Sat, 27 Jul 2019 22:59:37 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lai", "Zihang", ""], ["Xie", "Weidi", ""]]}, {"id": "1905.00877", "submitter": "Dinghuai Zhang", "authors": "Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong", "title": "You Only Propagate Once: Accelerating Adversarial Training via Maximal\n  Principle", "comments": "Accepted as a conference paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning achieves state-of-the-art results in many tasks in computer\nvision and natural language processing. However, recent works have shown that\ndeep networks can be vulnerable to adversarial perturbations, which raised a\nserious robustness issue of deep networks. Adversarial training, typically\nformulated as a robust optimization problem, is an effective way of improving\nthe robustness of deep networks. A major drawback of existing adversarial\ntraining algorithms is the computational overhead of the generation of\nadversarial examples, typically far greater than that of the network training.\nThis leads to the unbearable overall computational cost of adversarial\ntraining. In this paper, we show that adversarial training can be cast as a\ndiscrete time differential game. Through analyzing the Pontryagin's Maximal\nPrinciple (PMP) of the problem, we observe that the adversary update is only\ncoupled with the parameters of the first layer of the network. This inspires us\nto restrict most of the forward and back propagation within the first layer of\nthe network during adversary updates. This effectively reduces the total number\nof full forward and backward propagation to only one for each group of\nadversary updates. Therefore, we refer to this algorithm YOPO (You Only\nPropagate Once). Numerical experiments demonstrate that YOPO can achieve\ncomparable defense accuracy with approximately 1/5 ~ 1/4 GPU time of the\nprojected gradient descent (PGD) algorithm. Our codes are available at\nhttps://https://github.com/a1600012888/YOPO-You-Only-Propagate-Once.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:46:06 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 03:54:37 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 02:08:20 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 17:46:39 GMT"}, {"version": "v5", "created": "Wed, 3 Jul 2019 01:20:13 GMT"}, {"version": "v6", "created": "Fri, 1 Nov 2019 17:12:15 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhang", "Dinghuai", ""], ["Zhang", "Tianyuan", ""], ["Lu", "Yiping", ""], ["Zhu", "Zhanxing", ""], ["Dong", "Bin", ""]]}, {"id": "1905.00883", "submitter": "Emma Frejinger", "authors": "Ma\\\"elle Zimmermann and Emma Frejinger", "title": "A tutorial on recursive models for analyzing and predicting path choice\n  behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem at the heart of this tutorial consists in modeling the path\nchoice behavior of network users. This problem has been extensively studied in\ntransportation science, where it is known as the route choice problem. In this\nliterature, individuals' choice of paths are typically predicted using discrete\nchoice models. This article is a tutorial on a specific category of discrete\nchoice models called recursive, and it makes three main contributions: First,\nfor the purpose of assisting future research on route choice, we provide a\ncomprehensive background on the problem, linking it to different fields\nincluding inverse optimization and inverse reinforcement learning. Second, we\nformally introduce the problem and the recursive modeling idea along with an\noverview of existing models, their properties and applications. Third, we\nextensively analyze illustrative examples from different angles so that a\nnovice reader can gain intuition on the problem and the advantages provided by\nrecursive models in comparison to path-based ones.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:54:40 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 14:45:20 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Zimmermann", "Ma\u00eblle", ""], ["Frejinger", "Emma", ""]]}, {"id": "1905.00919", "submitter": "Mohamed Baza", "authors": "Ahmed Shafee, Mohamed Baza, Douglas A. Talbert, Mostafa M. Fouda,\n  Mahmoud Nabil, Mohamed Mahmoud", "title": "Mimic Learning to Generate a Shareable Network Intrusion Detection Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purveyors of malicious network attacks continue to increase the complexity\nand the sophistication of their techniques, and their ability to evade\ndetection continues to improve as well. Hence, intrusion detection systems must\nalso evolve to meet these increasingly challenging threats. Machine learning is\noften used to support this needed improvement. However, training a good\nprediction model can require a large set of labelled training data. Such\ndatasets are difficult to obtain because privacy concerns prevent the majority\nof intrusion detection agencies from sharing their sensitive data. In this\npaper, we propose the use of mimic learning to enable the transfer of intrusion\ndetection knowledge through a teacher model trained on private data to a\nstudent model. This student model provides a mean of publicly sharing knowledge\nextracted from private data without sharing the data itself. Our results\nconfirm that the proposed scheme can produce a student intrusion detection\nmodel that mimics the teacher model without requiring access to the original\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:14:24 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 17:39:51 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 20:14:47 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Shafee", "Ahmed", ""], ["Baza", "Mohamed", ""], ["Talbert", "Douglas A.", ""], ["Fouda", "Mostafa M.", ""], ["Nabil", "Mahmoud", ""], ["Mahmoud", "Mohamed", ""]]}, {"id": "1905.00921", "submitter": "Jihwan Lee", "authors": "Han Li, Jihwan Lee, Sidharth Mudgal, Ruhi Sarikaya, Young-Bum Kim", "title": "Continuous Learning for Large-scale Personalized Domain Classification", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain classification is the task of mapping spoken language utterances to\none of the natural language understanding domains in intelligent personal\ndigital assistants (IPDAs). This is a major component in mainstream IPDAs in\nindustry. Apart from official domains, thousands of third-party domains are\nalso created by external developers to enhance the capability of IPDAs. As more\ndomains are developed rapidly, the question of how to continuously accommodate\nthe new domains still remains challenging. Moreover, existing continual\nlearning approaches do not address the problem of incorporating personalized\ninformation dynamically for better domain classification. In this paper, we\npropose CoNDA, a neural network based approach for domain classification that\nsupports incremental learning of new classes. Empirical evaluation shows that\nCoNDA achieves high accuracy and outperforms baselines by a large margin on\nboth incrementally added new domains and existing domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:20:01 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Li", "Han", ""], ["Lee", "Jihwan", ""], ["Mudgal", "Sidharth", ""], ["Sarikaya", "Ruhi", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1905.00924", "submitter": "Jihwan Lee", "authors": "Jihwan Lee, Ruhi Sarikaya, Young-Bum Kim", "title": "Locale-agnostic Universal Domain Classification Model in Spoken Language\n  Understanding", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an approach for leveraging available data across\nmultiple locales sharing the same language to 1) improve domain classification\nmodel accuracy in Spoken Language Understanding and user experience even if new\nlocales do not have sufficient data and 2) reduce the cost of scaling the\ndomain classifier to a large number of locales. We propose a locale-agnostic\nuniversal domain classification model based on selective multi-task learning\nthat learns a joint representation of an utterance over locales with different\nsets of domains and allows locales to share knowledge selectively depending on\nthe domains. The experimental results demonstrate the effectiveness of our\napproach on domain classification task in the scenario of multiple locales with\nimbalanced data and disparate domain sets. The proposed approach outperforms\nother baselines models especially when classifying locale-specific domains and\nalso low-resourced domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:23:47 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Lee", "Jihwan", ""], ["Sarikaya", "Ruhi", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1905.00931", "submitter": "Taeho Jo", "authors": "Taeho Jo, Kwangsik Nho, Andrew J. Saykin", "title": "Deep Learning in Alzheimer's disease: Diagnostic Classification and\n  Prognostic Prediction using Neuroimaging Data", "comments": null, "journal-ref": "Frontiers in Aging Neuroscience 11 (2019): 220", "doi": "10.3389/fnagi.2019.00220", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown outstanding performance in identifying intricate\nstructures in complex high-dimensional data, especially in the domain of\ncomputer vision. The application of deep learning to early detection and\nautomated classification of Alzheimer's disease (AD) has recently gained\nconsiderable attention, as rapid progress in neuroimaging techniques has\ngenerated large-scale multimodal neuroimaging data. A systematic review of\npublications using deep learning approaches and neuroimaging data for\ndiagnostic classification of AD was performed. A PubMed and Google Scholar\nsearch was used to identify deep learning papers on AD published between\nJanuary 2013 and July 2018. These papers were reviewed, evaluated, and\nclassified by algorithm and neuroimaging type, and the findings were\nsummarized. Of 16 studies meeting full inclusion criteria, 4 used a combination\nof deep learning and traditional machine learning approaches, and 12 used only\ndeep learning approaches. The combination of traditional machine learning for\nclassification and stacked auto-encoder (SAE) for feature selection produced\naccuracies of up to 98.8% for AD classification and 83.7% for prediction of\nconversion from mild cognitive impairment (MCI), a prodromal stage of AD, to\nAD. Deep learning approaches, such as convolutional neural network (CNN) or\nrecurrent neural network (RNN), that use neuroimaging data without\npreprocessing for feature selection have yielded accuracies of up to 96.0% for\nAD classification and 84.2% for MCI conversion prediction. The best\nclassification performance was obtained when multimodal neuroimaging and fluid\nbiomarkers were combined. AD research that uses deep learning is still\nevolving, improving performance by incorporating additional hybrid data types,\nincreasing transparency with explainable approaches that add knowledge of\nspecific disease-related features and mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:49:24 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 13:57:09 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 20:39:00 GMT"}, {"version": "v4", "created": "Tue, 20 Aug 2019 23:23:17 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Jo", "Taeho", ""], ["Nho", "Kwangsik", ""], ["Saykin", "Andrew J.", ""]]}, {"id": "1905.00941", "submitter": "Fabio Pizzati", "authors": "Fabio Pizzati and Fernando Garc\\'ia", "title": "Enhanced free space detection in multiple lanes based on single CNN with\n  scene identification", "comments": "Will appear in the 2019 IEEE Intelligent Vehicles Symposium (IV 2019)", "journal-ref": "2019 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IVS.2019.8814181", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many systems for autonomous vehicles' navigation rely on lane detection.\nTraditional algorithms usually estimate only the position of the lanes on the\nroad, but an autonomous control system may also need to know if a lane marking\ncan be crossed or not, and what portion of space inside the lane is free from\nobstacles, to make safer control decisions. On the other hand, free space\ndetection algorithms only detect navigable areas, without information about\nlanes. State-of-the-art algorithms use CNNs for both tasks, with significant\nconsumption of computing resources. We propose a novel approach that estimates\nthe free space inside each lane, with a single CNN. Additionally, adding only a\nsmall requirement concerning GPU RAM, we infer the road type, that will be\nuseful for path planning. To achieve this result, we train a multi-task CNN.\nThen, we further elaborate the output of the network, to extract polygons that\ncan be effectively used in navigation control. Finally, we provide a\ncomputationally efficient implementation, based on ROS, that can be executed in\nreal time. Our code and trained models are available online.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 19:26:07 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 07:00:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Pizzati", "Fabio", ""], ["Garc\u00eda", "Fernando", ""]]}, {"id": "1905.00948", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Marko Mitrovic and Morteza Zadimoghaddam and Silvio\n  Lattanzi and Amin Karbasi", "title": "Submodular Streaming in All its Glory: Tight Approximation, Minimum\n  Memory and Low Adaptive Complexity", "comments": "Proceedings of the 36th International Conference on Machine Learning,\n  Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming algorithms are generally judged by the quality of their solution,\nmemory footprint, and computational complexity. In this paper, we study the\nproblem of maximizing a monotone submodular function in the streaming setting\nwith a cardinality constraint $k$. We first propose Sieve-Streaming++, which\nrequires just one pass over the data, keeps only $O(k)$ elements and achieves\nthe tight $(1/2)$-approximation guarantee. The best previously known streaming\nalgorithms either achieve a suboptimal $(1/4)$-approximation with $\\Theta(k)$\nmemory or the optimal $(1/2)$-approximation with $O(k\\log k)$ memory. Next, we\nshow that by buffering a small fraction of the stream and applying a careful\nfiltering procedure, one can heavily reduce the number of adaptive\ncomputational rounds, thus substantially lowering the computational complexity\nof Sieve-Streaming++. We then generalize our results to the more challenging\nmulti-source streaming setting. We show how one can achieve the tight\n$(1/2)$-approximation guarantee with $O(k)$ shared memory while minimizing not\nonly the required rounds of computations but also the total number of\ncommunicated bits. Finally, we demonstrate the efficiency of our algorithms on\nreal-world data summarization tasks for multi-source streams of tweets and of\nYouTube videos.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 19:58:57 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:49:53 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Mitrovic", "Marko", ""], ["Zadimoghaddam", "Morteza", ""], ["Lattanzi", "Silvio", ""], ["Karbasi", "Amin", ""]]}, {"id": "1905.00956", "submitter": "Svetlin Penkov", "authors": "Svetlin Penkov, Subramanian Ramamoorthy", "title": "Learning Programmatically Structured Representations with Perceptor\n  Gradients", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the perceptor gradients algorithm -- a novel approach to learning\nsymbolic representations based on the idea of decomposing an agent's policy\ninto i) a perceptor network extracting symbols from raw observation data and\nii) a task encoding program which maps the input symbols to output actions. We\nshow that the proposed algorithm is able to learn representations that can be\ndirectly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A*\nplanner. Our experimental results confirm that the perceptor gradients\nalgorithm is able to efficiently learn transferable symbolic representations as\nwell as generate new observations according to a semantically meaningful\nspecification.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 20:47:26 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Penkov", "Svetlin", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1905.00961", "submitter": "Fred Batty", "authors": "Fred Batty, Dmitry Kamenetsky", "title": "An Elo-based rating system for TopCoder SRM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Elo-based rating system for programming contests. We justify a\ndefinition of performance using the logarithm of a player's rank. We apply the\ndefinition to rating TopCoder SRM. We improve the accuracy, guided by\nexperimental results. We compare results with SRM ratings.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 02:01:40 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 14:15:00 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 15:18:37 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 17:10:41 GMT"}, {"version": "v5", "created": "Mon, 10 Feb 2020 16:22:55 GMT"}, {"version": "v6", "created": "Mon, 2 Mar 2020 09:25:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Batty", "Fred", ""], ["Kamenetsky", "Dmitry", ""]]}, {"id": "1905.00968", "submitter": "Christina Delimitrou", "authors": "Yu Gan, Yanqi Zhang, Kelvin Hu, Dailun Cheng, Yuan He, Meghna\n  Pancholi, and Christina Delimitrou", "title": "Leveraging Deep Learning to Improve the Performance Predictability of\n  Cloud Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance unpredictability is a major roadblock towards cloud adoption, and\nhas performance, cost, and revenue ramifications. Predictable performance is\neven more critical as cloud services transition from monolithic designs to\nmicroservices. Detecting QoS violations after they occur in systems with\nmicroservices results in long recovery times, as hotspots propagate and amplify\nacross dependent services. We present Seer, an online cloud performance\ndebugging system that leverages deep learning and the massive amount of tracing\ndata cloud systems collect to learn spatial and temporal patterns that\ntranslate to QoS violations. Seer combines lightweight distributed RPC-level\ntracing, with detailed low-level hardware monitoring to signal an upcoming QoS\nviolation, and diagnose the source of unpredictable performance. Once an\nimminent QoS violation is detected, Seer notifies the cluster manager to take\naction to avoid performance degradation altogether. We evaluate Seer both in\nlocal clusters, and in large-scale deployments of end-to-end applications built\nwith microservices with hundreds of users. We show that Seer correctly\nanticipates QoS violations 91% of the time, and avoids the QoS violation to\nbegin with in 84% of cases. Finally, we show that Seer can identify\napplication-level design bugs, and provide insights on how to better architect\nmicroservices to achieve predictable performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:25:56 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Gan", "Yu", ""], ["Zhang", "Yanqi", ""], ["Hu", "Kelvin", ""], ["Cheng", "Dailun", ""], ["He", "Yuan", ""], ["Pancholi", "Meghna", ""], ["Delimitrou", "Christina", ""]]}, {"id": "1905.00976", "submitter": "Somdeb Majumdar", "authors": "Shauharda Khadka, Somdeb Majumdar, Tarek Nassar, Zach Dwiel, Evren\n  Tumer, Santiago Miret, Yinyin Liu, Kagan Tumer", "title": "Collaborative Evolutionary Reinforcement Learning", "comments": "Added link to public Github repo. Minor editorial changes. Order of\n  authors modified to reflect ICML submission", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have been successfully applied to a\nrange of challenging control tasks. However, these methods typically struggle\nwith achieving effective exploration and are extremely sensitive to the choice\nof hyperparameters. One reason is that most approaches use a noisy version of\ntheir operating policy to explore - thereby limiting the range of exploration.\nIn this paper, we introduce Collaborative Evolutionary Reinforcement Learning\n(CERL), a scalable framework that comprises a portfolio of policies that\nsimultaneously explore and exploit diverse regions of the solution space. A\ncollection of learners - typically proven algorithms like TD3 - optimize over\nvarying time-horizons leading to this diverse portfolio. All learners\ncontribute to and use a shared replay buffer to achieve greater sample\nefficiency. Computational resources are dynamically distributed to favor the\nbest learners as a form of online algorithm selection. Neuroevolution binds\nthis entire process to generate a single emergent learner that exceeds the\ncapabilities of any individual learner. Experiments in a range of continuous\ncontrol benchmarks demonstrate that the emergent learner significantly\noutperforms its composite learners while remaining overall more\nsample-efficient - notably solving the Mujoco Humanoid benchmark where all of\nits composite learners (TD3) fail entirely in isolation.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:45:03 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 21:44:24 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Khadka", "Shauharda", ""], ["Majumdar", "Somdeb", ""], ["Nassar", "Tarek", ""], ["Dwiel", "Zach", ""], ["Tumer", "Evren", ""], ["Miret", "Santiago", ""], ["Liu", "Yinyin", ""], ["Tumer", "Kagan", ""]]}, {"id": "1905.00985", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Sangtae Ahn, Valentina Taviani, Anne Menini, Lior Wolf\n  and Christopher J. Hardy", "title": "Conditional WGANs with Adaptive Gradient Balancing for Sparse MRI\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent sparse MRI reconstruction models have used Deep Neural Networks (DNNs)\nto reconstruct relatively high-quality images from highly undersampled k-space\ndata, enabling much faster MRI scanning. However, these techniques sometimes\nstruggle to reconstruct sharp images that preserve fine detail while\nmaintaining a natural appearance. In this work, we enhance the image quality by\nusing a Conditional Wasserstein Generative Adversarial Network combined with a\nnovel Adaptive Gradient Balancing technique that stabilizes the training and\nminimizes the degree of artifacts, while maintaining a high-quality\nreconstruction that produces sharper images than other techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 22:26:06 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Malkiel", "Itzik", ""], ["Ahn", "Sangtae", ""], ["Taviani", "Valentina", ""], ["Menini", "Anne", ""], ["Wolf", "Lior", ""], ["Hardy", "Christopher J.", ""]]}, {"id": "1905.00987", "submitter": "Saket Gurukar", "authors": "Saket Gurukar, Priyesh Vijayan, Aakash Srinivasan, Goonmeet Bajaj,\n  Chen Cai, Moniba Keymanesh, Saravana Kumar, Pranav Maneriker, Anasua Mitra,\n  Vedang Patel, Balaraman Ravindran, and Srinivasan Parthasarathy", "title": "Network Representation Learning: Consolidation and Renewed Bearing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a natural abstraction for many problems where nodes represent\nentities and edges represent a relationship across entities. An important area\nof research that has emerged over the last decade is the use of graphs as a\nvehicle for non-linear dimensionality reduction in a manner akin to previous\nefforts based on manifold learning with uses for downstream database\nprocessing, machine learning and visualization. In this systematic yet\ncomprehensive experimental survey, we benchmark several popular network\nrepresentation learning methods operating on two key tasks: link prediction and\nnode classification. We examine the performance of 12 unsupervised embedding\nmethods on 15 datasets. To the best of our knowledge, the scale of our study --\nboth in terms of the number of methods and number of datasets -- is the largest\nto date.\n  Our results reveal several key insights about work-to-date in this space.\nFirst, we find that certain baseline methods (task-specific heuristics, as well\nas classic manifold methods) that have often been dismissed or are not\nconsidered by previous efforts can compete on certain types of datasets if they\nare tuned appropriately. Second, we find that recent methods based on matrix\nfactorization offer a small but relatively consistent advantage over\nalternative methods (e.g., random-walk based methods) from a qualitative\nstandpoint. Specifically, we find that MNMF, a community preserving embedding\nmethod, is the most competitive method for the link prediction task. While\nNetMF is the most competitive baseline for node classification. Third, no\nsingle method completely outperforms other embedding methods on both node\nclassification and link prediction tasks. We also present several drill-down\nanalysis that reveals settings under which certain algorithms perform well\n(e.g., the role of neighborhood context on performance) -- guiding the\nend-user.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 22:42:11 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 20:10:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Gurukar", "Saket", ""], ["Vijayan", "Priyesh", ""], ["Srinivasan", "Aakash", ""], ["Bajaj", "Goonmeet", ""], ["Cai", "Chen", ""], ["Keymanesh", "Moniba", ""], ["Kumar", "Saravana", ""], ["Maneriker", "Pranav", ""], ["Mitra", "Anasua", ""], ["Patel", "Vedang", ""], ["Ravindran", "Balaraman", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1905.00991", "submitter": "Francisco Jacob Avila-Camacho FJ Avila-Camacho", "authors": "Jose de Jesus Rubio, Ramon Silva Ortigoza, Francisco Jacob Avila,\n  Adolfo Melendez and Juan Manuel Stein", "title": "A Fuzzy Inference System for the Identification", "comments": "7 Pages, in Spanish", "journal-ref": "IEEE LATIN AMERICA TRANSACTIONS, VOL. 13, NO. 9, SEPTEMBER 2015", "doi": "10.1109/TLA.2015.7350026", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Odor identification is an important area in a wide range of industries like\ncosmetics, food, beverages and medical diagnosis among others. Odor detection\ncould be done through an array of gas sensors conformed as an electronic nose\nwhere a data acquisition module converts sensor signals to a standard output to\nbe analyzed. To facilitate odors detection a system is required for the\nidentification. This paper presents the results of an automated odor\nidentification process implemented by a fuzzy system and an electronic nose.\nFirst, an electronic nose prototype is manufactured to detect organic compounds\nvapor using an array of five tin dioxide gas sensors, an arduino uno board is\nused as a data acquisition section. Second, an intelligent module with a fuzzy\nsystem is considered for the identification of the signals received by the\nelectronic nose. This solution proposes a system to identify odors by using a\npersonal computer. Results show an acceptable precision.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 23:00:01 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Rubio", "Jose de Jesus", ""], ["Ortigoza", "Ramon Silva", ""], ["Avila", "Francisco Jacob", ""], ["Melendez", "Adolfo", ""], ["Stein", "Juan Manuel", ""]]}, {"id": "1905.01004", "submitter": "Saurabh Verma", "authors": "Saurabh Verma, Zhi-Li Zhang", "title": "Stability and Generalization of Graph Convolutional Neural Networks", "comments": "Accepted at The 25th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by convolutional neural networks on 1D and 2D data, graph\nconvolutional neural networks (GCNNs) have been developed for various learning\ntasks on graph data, and have shown superior performance on real-world\ndatasets. Despite their success, there is a dearth of theoretical explorations\nof GCNN models such as their generalization properties. In this paper, we take\na first step towards developing a deeper theoretical understanding of GCNN\nmodels by analyzing the stability of single-layer GCNN models and deriving\ntheir generalization guarantees in a semi-supervised graph learning setting. In\nparticular, we show that the algorithmic stability of a GCNN model depends upon\nthe largest absolute eigenvalue of its graph convolution filter. Moreover, to\nensure the uniform stability needed to provide strong generalization\nguarantees, the largest absolute eigenvalue must be independent of the graph\nsize. Our results shed new insights on the design of new & improved graph\nconvolution filters with guaranteed algorithmic stability. We evaluate the\ngeneralization gap and stability on various real-world graph datasets and show\nthat the empirical results indeed support our theoretical findings. To the best\nof our knowledge, we are the first to study stability bounds on graph learning\nin a semi-supervised setting and derive generalization bounds for GCNN models.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:04:51 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 05:50:52 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1905.01008", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi and Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Generative Adversarial Network for Wireless Signal Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel approach of spoofing wireless signals by using a\ngeneral adversarial network (GAN) to generate and transmit synthetic signals\nthat cannot be reliably distinguished from intended signals. It is of paramount\nimportance to authenticate wireless signals at the PHY layer before they\nproceed through the receiver chain. For that purpose, various waveform,\nchannel, and radio hardware features that are inherent to original wireless\nsignals need to be captured. In the meantime, adversaries become sophisticated\nwith the cognitive radio capability to record, analyze, and manipulate signals\nbefore spoofing. Building upon deep learning techniques, this paper introduces\na spoofing attack by an adversary pair of a transmitter and a receiver that\nassume the generator and discriminator roles in the GAN and play a minimax game\nto generate the best spoofing signals that aim to fool the best trained defense\nmechanism. The output of this approach is two-fold. From the attacker point of\nview, a deep learning-based spoofing mechanism is trained to potentially fool a\ndefense mechanism such as RF fingerprinting. From the defender point of view, a\ndeep learning-based defense mechanism is trained against potential spoofing\nattacks when an adversary pair of a transmitter and a receiver cooperates. The\nprobability that the spoofing signal is misclassified as the intended signal is\nmeasured for random signal, replay, and GAN-based spoofing attacks. Results\nshow that the GAN-based spoofing attack provides a major increase in the\nsuccess probability of wireless signal spoofing even when a deep learning\nclassifier is used as the defense.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:27:55 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 18:06:06 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shi", "Yi", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1905.01019", "submitter": "Marc Khoury", "authors": "Marc Khoury and Dylan Hadfield-Menell", "title": "Adversarial Training with Voronoi Constraints", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.00525", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a pervasive phenomenon of machine learning models\nwhere seemingly imperceptible perturbations to the input lead to\nmisclassifications for otherwise statistically accurate models. We propose a\ngeometric framework, drawing on tools from the manifold reconstruction\nliterature, to analyze the high-dimensional geometry of adversarial examples.\nIn particular, we highlight the importance of codimension: for low-dimensional\ndata manifolds embedded in high-dimensional space there are many directions off\nthe manifold in which an adversary could construct adversarial examples.\nAdversarial examples are a natural consequence of learning a decision boundary\nthat classifies the low-dimensional data manifold well, but classifies points\nnear the manifold incorrectly. Using our geometric framework we prove that\nadversarial training is sample inefficient, and show sufficient sampling\nconditions under which nearest neighbor classifiers and ball-based adversarial\ntraining are robust. Finally we introduce adversarial training with Voronoi\nconstraints, which replaces the norm ball constraint with the Voronoi cell for\neach point in the training set. We show that adversarial training with Voronoi\nconstraints produces robust models which significantly improve over the\nstate-of-the-art on MNIST and are competitive on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:34:44 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Khoury", "Marc", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "1905.01022", "submitter": "Di Sheng", "authors": "Di Sheng and Gy\\\"orgy Fazekas", "title": "A Feature Learning Siamese Model for Intelligent Control of the Dynamic\n  Range Compressor", "comments": "8 pages, accepted in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a siamese DNN model is proposed to learn the characteristics\nof the audio dynamic range compressor (DRC). This facilitates an intelligent\ncontrol system that uses audio examples to configure the DRC, a widely used\nnon-linear audio signal conditioning technique in the areas of music\nproduction, speech communication and broadcasting. Several alternative siamese\nDNN architectures are proposed to learn feature embeddings that can\ncharacterise subtle effects due to dynamic range compression. These models are\ncompared with each other as well as handcrafted features proposed in previous\nwork. The evaluation of the relations between the hyperparameters of DNN and\nDRC parameters are also provided. The best model is able to produce a universal\nfeature embedding that is capable of predicting multiple DRC parameters\nsimultaneously, which is a significant improvement from our previous research.\nThe feature embedding shows better performance than handcrafted audio features\nwhen predicting DRC parameters for both mono-instrument audio loops and\npolyphonic music pieces.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:28:54 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Sheng", "Di", ""], ["Fazekas", "Gy\u00f6rgy", ""]]}, {"id": "1905.01023", "submitter": "Imad Alhousseini", "authors": "Imad Alhousseini, Wissam Chemissany, Fatima Kleit, Aly Nasrallah", "title": "Physicist's Journeys Through the AI World - A Topical Review. There is\n  no royal road to unsupervised learning", "comments": "26 pages, 10 figures, 2 appendices, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn physics.comp-ph quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI), defined in its most simple form, is a\ntechnological tool that makes machines intelligent. Since learning is at the\ncore of intelligence, machine learning poses itself as a core sub-field of AI.\nThen there comes a subclass of machine learning, known as deep learning, to\naddress the limitations of their predecessors. AI has generally acquired its\nprominence over the past few years due to its considerable progress in various\nfields. AI has vastly invaded the realm of research. This has led physicists to\nattentively direct their research towards implementing AI tools. Their central\naim has been to gain better understanding and enrich their intuition. This\nreview article is meant to supplement the previously presented efforts to\nbridge the gap between AI and physics, and take a serious step forward to\nfilter out the \"Babelian\" clashes brought about from such gabs. This\nnecessitates first to have fundamental knowledge about common AI tools. To this\nend, the review's primary focus shall be on deep learning models called\nartificial neural networks. They are deep learning models which train\nthemselves through different learning processes. It discusses also the concept\nof Markov decision processes. Finally, shortcut to the main goal, the review\nthoroughly examines how these neural networks are capable to construct a\nphysical theory describing some observations without applying any previous\nphysical knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 11:21:45 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Alhousseini", "Imad", ""], ["Chemissany", "Wissam", ""], ["Kleit", "Fatima", ""], ["Nasrallah", "Aly", ""]]}, {"id": "1905.01034", "submitter": "Yi Sun", "authors": "Daniel Kang and Yi Sun and Tom Brown and Dan Hendrycks and Jacob\n  Steinhardt", "title": "Transfer of Adversarial Robustness Between Perturbation Types", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the transfer of adversarial robustness of deep neural networks\nbetween different perturbation types. While most work on adversarial examples\nhas focused on $L_\\infty$ and $L_2$-bounded perturbations, these do not capture\nall types of perturbations available to an adversary. The present work\nevaluates 32 attacks of 5 different types against models adversarially trained\non a 100-class subset of ImageNet. Our empirical results suggest that\nevaluating on a wide range of perturbation sizes is necessary to understand\nwhether adversarial robustness transfers between perturbation types. We further\ndemonstrate that robustness against one perturbation type may not always imply\nand may sometimes hurt robustness against other perturbation types. In light of\nthese results, we recommend evaluation of adversarial defenses take place on a\ndiverse range of perturbation types and sizes.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 04:51:07 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kang", "Daniel", ""], ["Sun", "Yi", ""], ["Brown", "Tom", ""], ["Hendrycks", "Dan", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1905.01039", "submitter": "Emre Yilmaz", "authors": "Emre Yilmaz, Mohammad Al-Rubaie and J. Morris Chang", "title": "Locally Differentially Private Naive Bayes Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, classification models need to be trained in order to\npredict class labels. When the training data contains personal information\nabout individuals, collecting training data becomes difficult due to privacy\nconcerns. Local differential privacy is a definition to measure the individual\nprivacy when there is no trusted data curator. Individuals interact with an\nuntrusted data aggregator who obtains statistical information about the\npopulation without learning personal data. In order to train a Naive Bayes\nclassifier in an untrusted setting, we propose to use methods satisfying local\ndifferential privacy. Individuals send their perturbed inputs that keep the\nrelationship between the feature values and class labels. The data aggregator\nestimates all probabilities needed by the Naive Bayes classifier. Then, new\ninstances can be classified based on the estimated probabilities. We propose\nsolutions for both discrete and continuous data. In order to eliminate high\namount of noise and decrease communication cost in multi-dimensional data, we\npropose utilizing dimensionality reduction techniques which can be applied by\nindividuals before perturbing their inputs. Our experimental results show that\nthe accuracy of the Naive Bayes classifier is maintained even when the\nindividual privacy is guaranteed under local differential privacy, and that\nusing dimensionality reduction enhances the accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 06:14:18 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yilmaz", "Emre", ""], ["Al-Rubaie", "Mohammad", ""], ["Chang", "J. Morris", ""]]}, {"id": "1905.01044", "submitter": "\\c{C}a\\u{g}lar Aytekin", "authors": "Caglar Aytekin, Francesco Cricri and Emre Aksu", "title": "Compressibility Loss for Neural Network Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply a compressibility loss that enables learning highly\ncompressible neural network weights. The loss was previously proposed as a\nmeasure of negated sparsity of a signal, yet in this paper we show that\nminimizing this loss also enforces the non-zero parts of the signal to have\nvery low entropy, thus making the entire signal more compressible. For an\noptimization problem where the goal is to minimize the compressibility loss\n(the objective), we prove that at any critical point of the objective, the\nweight vector is a ternary signal and the corresponding value of the objective\nis the squared root of the number of non-zero elements in the signal, thus\ndirectly related to sparsity. In the experiments, we train neural networks with\nthe compressibility loss and we show that the proposed method achieves weight\nsparsity and compression ratios comparable with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 06:46:37 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Aytekin", "Caglar", ""], ["Cricri", "Francesco", ""], ["Aksu", "Emre", ""]]}, {"id": "1905.01067", "submitter": "Rosanne Liu", "authors": "Hattie Zhou, Janice Lan, Rosanne Liu, Jason Yosinski", "title": "Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask", "comments": "NeurIPS 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent \"Lottery Ticket Hypothesis\" paper by Frankle & Carbin showed that\na simple approach to creating sparse networks (keeping the large weights)\nresults in models that are trainable from scratch, but only when starting from\nthe same initial weights. The performance of these networks often exceeds the\nperformance of the non-sparse base model, but for reasons that were not well\nunderstood. In this paper we study the three critical components of the Lottery\nTicket (LT) algorithm, showing that each may be varied significantly without\nimpacting the overall results. Ablating these factors leads to new insights for\nwhy LT networks perform as well as they do. We show why setting weights to zero\nis important, how signs are all you need to make the reinitialized network\ntrain, and why masking behaves like training. Finally, we discover the\nexistence of Supermasks, masks that can be applied to an untrained, randomly\ninitialized network to produce a model with performance far better than chance\n(86% on MNIST, 41% on CIFAR-10).\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 08:21:07 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 01:12:35 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 22:14:24 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 05:40:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Zhou", "Hattie", ""], ["Lan", "Janice", ""], ["Liu", "Rosanne", ""], ["Yosinski", "Jason", ""]]}, {"id": "1905.01072", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Wendelin Boehmer, Shimon Whiteson", "title": "Deep Residual Reinforcement Learning", "comments": "AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit residual algorithms in both model-free and model-based\nreinforcement learning settings. We propose the bidirectional target network\ntechnique to stabilize residual algorithms, yielding a residual version of DDPG\nthat significantly outperforms vanilla DDPG in the DeepMind Control Suite\nbenchmark. Moreover, we find the residual algorithm an effective approach to\nthe distribution mismatch problem in model-based planning. Compared with the\nexisting TD($k$) method, our residual-based method makes weaker assumptions\nabout the model and yields a greater performance boost.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 08:38:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 17:42:24 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 21:38:54 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Shangtong", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1905.01078", "submitter": "Jonathan Peck", "authors": "Jonathan Peck, Claire Nie, Raaghavi Sivaguru, Charles Grumer, Femi\n  Olumofin, Bin Yu, Anderson Nascimento and Martine De Cock", "title": "CharBot: A Simple and Effective Method for Evading DGA Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generation algorithms (DGAs) are commonly leveraged by malware to\ncreate lists of domain names which can be used for command and control (C&C)\npurposes. Approaches based on machine learning have recently been developed to\nautomatically detect generated domain names in real-time. In this work, we\npresent a novel DGA called CharBot which is capable of producing large numbers\nof unregistered domain names that are not detected by state-of-the-art\nclassifiers for real-time detection of DGAs, including the recently published\nmethods FANCI (a random forest based on human-engineered features) and LSTM.MI\n(a deep learning approach). CharBot is very simple, effective and requires no\nknowledge of the targeted DGA classifiers. We show that retraining the\nclassifiers on CharBot samples is not a viable defense strategy. We believe\nthese findings show that DGA classifiers are inherently vulnerable to\nadversarial attacks if they rely only on the domain name string to make a\ndecision. Designing a robust DGA classifier may, therefore, necessitate the use\nof additional information besides the domain name alone. To the best of our\nknowledge, CharBot is the simplest and most efficient black-box adversarial\nattack against DGA classifiers proposed to date.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 09:02:41 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 13:02:33 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Peck", "Jonathan", ""], ["Nie", "Claire", ""], ["Sivaguru", "Raaghavi", ""], ["Grumer", "Charles", ""], ["Olumofin", "Femi", ""], ["Yu", "Bin", ""], ["Nascimento", "Anderson", ""], ["De Cock", "Martine", ""]]}, {"id": "1905.01102", "submitter": "Spyros Gidaris", "authors": "Spyros Gidaris, Nikos Komodakis", "title": "Generating Classification Weights with GNN Denoising Autoencoders for\n  Few-Shot Learning", "comments": "Oral presentation at CVPR 2019. The code and models of our paper will\n  be published on: https://github.com/gidariss/wDAE_GNN_FewShot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an initial recognition model already trained on a set of base classes,\nthe goal of this work is to develop a meta-model for few-shot learning. The\nmeta-model, given as input some novel classes with few training examples per\nclass, must properly adapt the existing recognition model into a new model that\ncan correctly classify in a unified way both the novel and the base classes. To\naccomplish this goal it must learn to output the appropriate classification\nweight vectors for those two types of classes. To build our meta-model we make\nuse of two main innovations: we propose the use of a Denoising Autoencoder\nnetwork (DAE) that (during training) takes as input a set of classification\nweights corrupted with Gaussian noise and learns to reconstruct the\ntarget-discriminative classification weights. In this case, the injected noise\non the classification weights serves the role of regularizing the weight\ngenerating meta-model. Furthermore, in order to capture the co-dependencies\nbetween different classes in a given task instance of our meta-model, we\npropose to implement the DAE model as a Graph Neural Network (GNN). In order to\nverify the efficacy of our approach, we extensively evaluate it on ImageNet\nbased few-shot benchmarks and we report strong results that surpass prior\napproaches. The code and models of our paper will be published on:\nhttps://github.com/gidariss/wDAE_GNN_FewShot\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 10:11:54 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Gidaris", "Spyros", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1905.01118", "submitter": "Samanyou Garg", "authors": "Samanyou Garg", "title": "Group Emotion Recognition Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic facial emotion recognition is a challenging task that has gained\nsignificant scientific interest over the past few years, but the problem of\nemotion recognition for a group of people has been less extensively studied.\nHowever, it is slowly gaining popularity due to the massive amount of data\navailable on social networking sites containing images of groups of people\nparticipating in various social events. Group emotion recognition is a\nchallenging problem due to obstructions like head and body pose variations,\nocclusions, variable lighting conditions, variance of actors, varied indoor and\noutdoor settings and image quality. The objective of this task is to classify a\ngroup's perceived emotion as Positive, Neutral or Negative. In this report, we\ndescribe our solution which is a hybrid machine learning system that\nincorporates deep neural networks and Bayesian classifiers. Deep Convolutional\nNeural Networks (CNNs) work from bottom to top, analysing facial expressions\nexpressed by individual faces extracted from the image. The Bayesian network\nworks from top to bottom, inferring the global emotion for the image, by\nintegrating the visual features of the contents of the image obtained through a\nscene descriptor. In the final pipeline, the group emotion category predicted\nby an ensemble of CNNs in the bottom-up module is passed as input to the\nBayesian Network in the top-down module and an overall prediction for the image\nis obtained. Experimental results show that the stated system achieves 65.27%\naccuracy on the validation set which is in line with state-of-the-art results.\nAs an outcome of this project, a Progressive Web Application and an\naccompanying Android app with a simple and intuitive user interface are\npresented, allowing users to test out the system with their own pictures.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 11:21:25 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Garg", "Samanyou", ""]]}, {"id": "1905.01127", "submitter": "Jochen G\\\"ortler", "authors": "Jochen G\\\"ortler, Thilo Spinner, Dirk Streeb, Daniel Weiskopf, Oliver\n  Deussen", "title": "Uncertainty-Aware Principal Component Analysis", "comments": null, "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, 2020", "doi": "10.1109/TVCG.2019.2934812", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique to perform dimensionality reduction on data that is\nsubject to uncertainty. Our method is a generalization of traditional principal\ncomponent analysis (PCA) to multivariate probability distributions. In\ncomparison to non-linear methods, linear dimensionality reduction techniques\nhave the advantage that the characteristics of such probability distributions\nremain intact after projection. We derive a representation of the PCA sample\ncovariance matrix that respects potential uncertainty in each of the inputs,\nbuilding the mathematical foundation of our new method: uncertainty-aware PCA.\nIn addition to the accuracy and performance gained by our approach over\nsampling-based strategies, our formulation allows us to perform sensitivity\nanalysis with regard to the uncertainty in the data. For this, we propose\nfactor traces as a novel visualization that enables to better understand the\ninfluence of uncertainty on the chosen principal components. We provide\nmultiple examples of our technique using real-world datasets. As a special\ncase, we show how to propagate multivariate normal distributions through PCA in\nclosed form. Furthermore, we discuss extensions and limitations of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 11:46:53 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 16:32:10 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 21:35:33 GMT"}, {"version": "v4", "created": "Thu, 1 Aug 2019 15:07:35 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["G\u00f6rtler", "Jochen", ""], ["Spinner", "Thilo", ""], ["Streeb", "Dirk", ""], ["Weiskopf", "Daniel", ""], ["Deussen", "Oliver", ""]]}, {"id": "1905.01145", "submitter": "Shuai Yang", "authors": "Shuai Yang, Wenqi Zhu, Yuesheng Zhu", "title": "Three-Stage Subspace Clustering Framework with Graph-Based\n  Transformation and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering (SC) refers to the problem of clustering high-dimensional\ndata into a union of low-dimensional subspaces. Based on spectral clustering,\nstate-of-the-art approaches solve SC problem within a two-stage framework. In\nthe first stage, data representation techniques are applied to draw an affinity\nmatrix from the original data. In the second stage, spectral clustering is\ndirectly applied to the affinity matrix so that data can be grouped into\ndifferent subspaces. However, the affinity matrix obtained in the first stage\nusually fails to reveal the authentic relationship between data points, which\nleads to inaccurate clustering results. In this paper, we propose a universal\nThree-Stage Subspace Clustering framework (3S-SC). Graph-Based Transformation\nand Optimization (GBTO) is added between data representation and spectral\nclustering. The affinity matrix is obtained in the first stage, then it goes\nthrough the second stage, where the proposed GBTO is applied to generate a\nreconstructed affinity matrix with more authentic similarity between data\npoints. Spectral clustering is applied after GBTO, which is the third stage. We\nverify our 3S-SC framework with GBTO through theoretical analysis. Experiments\non both synthetic data and the real-world data sets of handwritten digits and\nhuman faces demonstrate the universality of the proposed 3S-SC framework in\nimproving the connectivity and accuracy of SC methods based on $\\ell_0$,\n$\\ell_1$, $\\ell_2$ or nuclear norm regularization.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 07:38:41 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yang", "Shuai", ""], ["Zhu", "Wenqi", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "1905.01152", "submitter": "Murali Karthick Baskar", "authors": "Murali Karthick Baskar, Shinji Watanabe, Ramon Astudillo, Takaaki\n  Hori, Luk\\'a\\v{s} Burget, Jan \\v{C}ernock\\'y", "title": "Semi-supervised Sequence-to-sequence ASR using Unpaired Speech and Text", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.IR cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-sequence automatic speech recognition (ASR) models require large\nquantities of data to attain high performance. For this reason, there has been\na recent surge in interest for unsupervised and semi-supervised training in\nsuch models. This work builds upon recent results showing notable improvements\nin semi-supervised training using cycle-consistency and related techniques.\nSuch techniques derive training procedures and losses able to leverage unpaired\nspeech and/or text data by combining ASR with Text-to-Speech (TTS) models. In\nparticular, this work proposes a new semi-supervised loss combining an\nend-to-end differentiable ASR$\\rightarrow$TTS loss with TTS$\\rightarrow$ASR\nloss. The method is able to leverage both unpaired speech and text data to\noutperform recently proposed related techniques in terms of \\%WER. We provide\nextensive results analyzing the impact of data quantity and speech and text\nmodalities and show consistent gains across WSJ and Librispeech corpora. Our\ncode is provided in ESPnet to reproduce the experiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:13:41 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 08:54:20 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Baskar", "Murali Karthick", ""], ["Watanabe", "Shinji", ""], ["Astudillo", "Ramon", ""], ["Hori", "Takaaki", ""], ["Burget", "Luk\u00e1\u0161", ""], ["\u010cernock\u00fd", "Jan", ""]]}, {"id": "1905.01173", "submitter": "Andrija Stajduhar", "authors": "Andrija \\v{S}tajduhar, Tomislav Lipi\\'c, Goran Sedmak, Sven\n  Lon\\v{c}ari\\'c, Milo\\v{s} Juda\\v{s}", "title": "Computational analysis of laminar structure of the human cortex based on\n  local neuron features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a novel method for analysis and segmentation of\nlaminar structure of the cortex based on tissue characteristics whose change\nacross the gray matter underlies distinctive between cortical layers. We\ndevelop and analyze features of individual neurons to investigate changes in\ncytoarchitectonic differentiation and present a novel high-performance,\nautomated framework for neuron-level histological image analysis. Local tissue\nand cell descriptors such as density, neuron size and other measures are used\nfor development of more complex neuron features used in machine learning model\ntrained on data manually labeled by three human experts. Final neuron layer\nclassifications were obtained by training a separate model for each expert and\ncombining their probability outputs. Importances of developed neuron features\non both global model level and individual prediction level are presented and\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 13:15:54 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 15:19:04 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["\u0160tajduhar", "Andrija", ""], ["Lipi\u0107", "Tomislav", ""], ["Sedmak", "Goran", ""], ["Lon\u010dari\u0107", "Sven", ""], ["Juda\u0161", "Milo\u0161", ""]]}, {"id": "1905.01205", "submitter": "Dongkun Zhang", "authors": "Dongkun Zhang, Ling Guo, George Em Karniadakis", "title": "Learning in Modal Space: Solving Time-Dependent Stochastic PDEs Using\n  Physics-Informed Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the open problems in scientific computing is the long-time integration\nof nonlinear stochastic partial differential equations (SPDEs). We address this\nproblem by taking advantage of recent advances in scientific machine learning\nand the dynamically orthogonal (DO) and bi-orthogonal (BO) methods for\nrepresenting stochastic processes. Specifically, we propose two new\nPhysics-Informed Neural Networks (PINNs) for solving time-dependent SPDEs,\nnamely the NN-DO/BO methods, which incorporate the DO/BO constraints into the\nloss function with an implicit form instead of generating explicit expressions\nfor the temporal derivatives of the DO/BO modes. Hence, the proposed methods\novercome some of the drawbacks of the original DO/BO methods: we do not need\nthe assumption that the covariance matrix of the random coefficients is\ninvertible as in the original DO method, and we can remove the assumption of no\neigenvalue crossing as in the original BO method. Moreover, the NN-DO/BO\nmethods can be used to solve time-dependent stochastic inverse problems with\nthe same formulation and computational complexity as for forward problems. We\ndemonstrate the capability of the proposed methods via several numerical\nexamples: (1) A linear stochastic advection equation with deterministic initial\ncondition where the original DO/BO method would fail; (2) Long-time integration\nof the stochastic Burgers' equation with many eigenvalue crossings during the\nwhole time evolution where the original BO method fails. (3) Nonlinear reaction\ndiffusion equation: we consider both the forward and the inverse problem,\nincluding noisy initial data, to investigate the flexibility of the NN-DO/BO\nmethods in handling inverse and mixed type problems. Taken together, these\nsimulation results demonstrate that the NN-DO/BO methods can be employed to\neffectively quantify uncertainty propagation in a wide range of physical\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:39:14 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 11:49:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Dongkun", ""], ["Guo", "Ling", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1905.01209", "submitter": "Manuel Pariente", "authors": "Manuel Pariente (MULTISPEECH), Antoine Deleforge (MULTISPEECH),\n  Emmanuel Vincent (MULTISPEECH)", "title": "A Statistically Principled and Computationally Efficient Approach to\n  Speech Enhancement using Variational Autoencoders", "comments": "Submitted to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have explored the use of deep generative models of speech\nspectra based of variational autoencoders (VAEs), combined with unsupervised\nnoise models, to perform speech enhancement. These studies developed iterative\nalgorithms involving either Gibbs sampling or gradient descent at each step,\nmaking them computationally expensive. This paper proposes a variational\ninference method to iteratively estimate the power spectrogram of the clean\nspeech. Our main contribution is the analytical derivation of the variational\nsteps in which the en-coder of the pre-learned VAE can be used to estimate the\nvaria-tional approximation of the true posterior distribution, using the very\nsame assumption made to train VAEs. Experiments show that the proposed method\nproduces results on par with the afore-mentioned iterative methods using\nsampling, while decreasing the computational cost by a factor 36 to reach a\ngiven performance .\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:46:47 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 08:30:13 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Pariente", "Manuel", "", "MULTISPEECH"], ["Deleforge", "Antoine", "", "MULTISPEECH"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "1905.01213", "submitter": "Waleed Yousef", "authors": "Ahmed A. Elsayed and Waleed A. Yousef", "title": "Matlab vs. OpenCV: A Comparative Study of Different Machine Learning\n  Algorithms", "comments": "This manuscript was composed in 2011 as part of a research pursued\n  that time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific Computing relies on executing computer algorithms coded in some\nprogramming languages. Given a particular available hardware, algorithms speed\nis a crucial factor. There are many scientific computing environments used to\ncode such algorithms. Matlab is one of the most tremendously successful and\nwidespread scientific computing environments that is rich of toolboxes,\nlibraries, and data visualization tools. OpenCV is a (C++)-based library\nwritten primarily for Computer Vision and its related areas. This paper\npresents a comparative study using 20 different real datasets to compare the\nspeed of Matlab and OpenCV for some Machine Learning algorithms. Although\nMatlab is more convenient in developing and data presentation, OpenCV is much\nfaster in execution, where the speed ratio reaches more than 80 in some cases.\nThe best of two worlds can be achieved by exploring using Matlab or similar\nenvironments to select the most successful algorithm; then, implementing the\nselected algorithm using OpenCV or similar environments to gain a speed factor.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:58:58 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 00:15:30 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 14:41:09 GMT"}, {"version": "v4", "created": "Wed, 14 Aug 2019 12:20:37 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Elsayed", "Ahmed A.", ""], ["Yousef", "Waleed A.", ""]]}, {"id": "1905.01219", "submitter": "Vibhatha Abeykoon", "authors": "Vibhatha Abeykoon, Geoffrey Fox, Minje Kim", "title": "Performance Optimization on Model Synchronization in Parallel Stochastic\n  Gradient Descent Based SVM", "comments": "Paper Accepted in HPML 2019 Held in conjunction with IEEE/ACM CCGRID\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the bottlenecks in implementing stochastic gradient descent\n(SGD)-based distributed support vector machines (SVM) algorithm is important in\ntraining larger data sets. The communication time to do the model\nsynchronization across the parallel processes is the main bottleneck that\ncauses inefficiency in the training process. The model synchronization is\ndirectly affected by the mini-batch size of data processed before the global\nsynchronization. In producing an efficient distributed model, the communication\ntime in training model synchronization has to be as minimum as possible while\nretaining a high testing accuracy. The effect from model synchronization\nfrequency over the convergence of the algorithm and accuracy of the generated\nmodel must be well understood to design an efficient distributed model. In this\nresearch, we identify the bottlenecks in model synchronization in parallel\nstochastic gradient descent (PSGD)-based SVM algorithm with respect to the\ntraining model synchronization frequency (MSF). Our research shows that by\noptimizing the MSF in the data sets that we used, a reduction of 98\\% in\ncommunication time can be gained (16x - 24x speed up) with respect to\nhigh-frequency model synchronization. The training model optimization discussed\nin this paper guarantees a higher accuracy than the sequential algorithm along\nwith faster convergence.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:16:02 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Abeykoon", "Vibhatha", ""], ["Fox", "Geoffrey", ""], ["Kim", "Minje", ""]]}, {"id": "1905.01235", "submitter": "Priya Goyal", "authors": "Priya Goyal, Dhruv Mahajan, Abhinav Gupta, Ishan Misra", "title": "Scaling and Benchmarking Self-Supervised Visual Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning aims to learn representations from the data itself\nwithout explicit manual supervision. Existing efforts ignore a crucial aspect\nof self-supervised learning - the ability to scale to large amount of data\nbecause self-supervision requires no manual labels. In this work, we revisit\nthis principle and scale two popular self-supervised approaches to 100 million\nimages. We show that by scaling on various axes (including data size and\nproblem 'hardness'), one can largely match or even exceed the performance of\nsupervised pre-training on a variety of tasks such as object detection, surface\nnormal estimation (3D) and visual navigation using reinforcement learning.\nScaling these methods also provides many interesting insights into the\nlimitations of current self-supervised techniques and evaluations. We conclude\nthat current self-supervised methods are not 'hard' enough to take full\nadvantage of large scale data and do not seem to learn effective high level\nsemantic representations. We also introduce an extensive benchmark across 9\ndifferent datasets and tasks. We believe that such a benchmark along with\ncomparable evaluation settings is necessary to make meaningful progress. Code\nis at: https://github.com/facebookresearch/fair_self_supervision_benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:50:51 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 13:08:29 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Goyal", "Priya", ""], ["Mahajan", "Dhruv", ""], ["Gupta", "Abhinav", ""], ["Misra", "Ishan", ""]]}, {"id": "1905.01240", "submitter": "Alexandre Galashov", "authors": "Alexandre Galashov, Siddhant M. Jayakumar, Leonard Hasenclever, Dhruva\n  Tirumala, Jonathan Schwarz, Guillaume Desjardins, Wojciech M. Czarnecki, Yee\n  Whye Teh, Razvan Pascanu, Nicolas Heess", "title": "Information asymmetry in KL-regularized RL", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world tasks exhibit rich structure that is repeated across\ndifferent parts of the state space or in time. In this work we study the\npossibility of leveraging such repeated structure to speed up and regularize\nlearning. We start from the KL regularized expected reward objective which\nintroduces an additional component, a default policy. Instead of relying on a\nfixed default policy, we learn it from data. But crucially, we restrict the\namount of information the default policy receives, forcing it to learn reusable\nbehaviors that help the policy learn faster. We formalize this strategy and\ndiscuss connections to information bottleneck approaches and to the variational\nEM algorithm. We present empirical results in both discrete and continuous\naction domains and demonstrate that, for certain tasks, learning a default\npolicy alongside the policy can significantly speed up and improve learning.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:59:25 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Galashov", "Alexandre", ""], ["Jayakumar", "Siddhant M.", ""], ["Hasenclever", "Leonard", ""], ["Tirumala", "Dhruva", ""], ["Schwarz", "Jonathan", ""], ["Desjardins", "Guillaume", ""], ["Czarnecki", "Wojciech M.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""], ["Heess", "Nicolas", ""]]}, {"id": "1905.01252", "submitter": "Marko J\\\"arvenp\\\"a\\\"a", "authors": "Marko J\\\"arvenp\\\"a\\\"a, Michael Gutmann, Aki Vehtari, Pekka Marttinen", "title": "Parallel Gaussian process surrogate Bayesian inference with noisy\n  likelihood evaluations", "comments": "Minor changes to the text. 37 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian inference when only a limited number of noisy\nlog-likelihood evaluations can be obtained. This occurs for example when\ncomplex simulator-based statistical models are fitted to data, and synthetic\nlikelihood (SL) method is used to form the noisy log-likelihood estimates using\ncomputationally costly forward simulations. We frame the inference task as a\nsequential Bayesian experimental design problem, where the log-likelihood\nfunction is modelled with a hierarchical Gaussian process (GP) surrogate model,\nwhich is used to efficiently select additional log-likelihood evaluation\nlocations. Motivated by recent progress in the related problem of batch\nBayesian optimisation, we develop various batch-sequential design strategies\nwhich allow to run some of the potentially costly simulations in parallel. We\nanalyse the properties of the resulting method theoretically and empirically.\nExperiments with several toy problems and simulation models suggest that our\nmethod is robust, highly parallelisable, and sample-efficient.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:18:50 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:31:22 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 15:19:26 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 13:35:20 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["J\u00e4rvenp\u00e4\u00e4", "Marko", ""], ["Gutmann", "Michael", ""], ["Vehtari", "Aki", ""], ["Marttinen", "Pekka", ""]]}, {"id": "1905.01258", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar R\\\"atsch,\n  Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "Disentangling Factors of Variation Using Few Labels", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations - ICLR\n  2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations is considered a cornerstone problem in\nrepresentation learning. Recently, Locatello et al. (2019) demonstrated that\nunsupervised disentanglement learning without inductive biases is theoretically\nimpossible and that existing inductive biases and unsupervised methods do not\nallow to consistently learn disentangled representations. However, in many\npractical settings, one might have access to a limited amount of supervision,\nfor example through manual labeling of (some) factors of variation in a few\ntraining examples. In this paper, we investigate the impact of such supervision\non state-of-the-art disentanglement methods and perform a large scale study,\ntraining over 52000 models under well-defined and reproducible experimental\nconditions. We observe that a small number of labeled examples (0.01--0.5\\% of\nthe data set), with potentially imprecise and incomplete labels, is sufficient\nto perform model selection on state-of-the-art unsupervised models. Further, we\ninvestigate the benefit of incorporating supervision into the training process.\nOverall, we empirically validate that with little and imprecise supervision it\nis possible to reliably learn disentangled representations.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:23:49 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 13:24:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Locatello", "Francesco", ""], ["Tschannen", "Michael", ""], ["Bauer", "Stefan", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "1905.01281", "submitter": "Amin Vahedian Khezerlou", "authors": "Amin Vahedian, Xun Zhou, Ling Tong, W. Nick Street and Yanhua Li", "title": "Predicting Urban Dispersal Events: A Two-Stage Framework through Deep\n  Survival Analysis on Mobility Data", "comments": "To appear in AAAI-19 proceedings. The reason for the replacement was\n  the misspelled author name in the meta-data field. Author name was corrected\n  from \"Ynahua Li\" to \"Yanhua Li\". The author list in the paper was correct and\n  remained unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban dispersal events are processes where an unusually large number of\npeople leave the same area in a short period. Early prediction of dispersal\nevents is important in mitigating congestion and safety risks and making better\ndispatching decisions for taxi and ride-sharing fleets. Existing work mostly\nfocuses on predicting taxi demand in the near future by learning patterns from\nhistorical data. However, they fail in case of abnormality because dispersal\nevents with abnormally high demand are non-repetitive and violate common\nassumptions such as smoothness in demand change over time. Instead, in this\npaper we argue that dispersal events follow a complex pattern of trips and\nother related features in the past, which can be used to predict such events.\nTherefore, we formulate the dispersal event prediction problem as a survival\nanalysis problem. We propose a two-stage framework (DILSA), where a deep\nlearning model combined with survival analysis is developed to predict the\nprobability of a dispersal event and its demand volume. We conduct extensive\ncase studies and experiments on the NYC Yellow taxi dataset from 2014-2016.\nResults show that DILSA can predict events in the next 5 hours with F1-score of\n0.7 and with average time error of 18 minutes. It is orders of magnitude better\nthan the state-ofthe-art deep learning approaches for taxi demand prediction.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:25:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 17:16:03 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Vahedian", "Amin", ""], ["Zhou", "Xun", ""], ["Tong", "Ling", ""], ["Street", "W. Nick", ""], ["Li", "Yanhua", ""]]}, {"id": "1905.01282", "submitter": "Frederic Koehler", "authors": "Jonathan Kelner, Frederic Koehler, Raghu Meka, Ankur Moitra", "title": "Learning Some Popular Gaussian Graphical Models without Condition Number\n  Bounds", "comments": "V2: Updated version with some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Graphical Models (GGMs) have wide-ranging applications in machine\nlearning and the natural and social sciences. In most of the settings in which\nthey are applied, the number of observed samples is much smaller than the\ndimension and they are assumed to be sparse. While there are a variety of\nalgorithms (e.g. Graphical Lasso, CLIME) that provably recover the graph\nstructure with a logarithmic number of samples, they assume various conditions\nthat require the precision matrix to be in some sense well-conditioned.\n  Here we give the first polynomial-time algorithms for learning attractive\nGGMs and walk-summable GGMs with a logarithmic number of samples without any\nsuch assumptions. In particular, our algorithms can tolerate strong\ndependencies among the variables. Our result for structure recovery in\nwalk-summable GGMs is derived from a more general result for efficient sparse\nlinear regression in walk-summable models without any norm dependencies. We\ncomplement our results with experiments showing that many existing algorithms\nfail even in some simple settings where there are long dependency chains,\nwhereas ours do not.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:26:18 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:11:45 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 00:41:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kelner", "Jonathan", ""], ["Koehler", "Frederic", ""], ["Meka", "Raghu", ""], ["Moitra", "Ankur", ""]]}, {"id": "1905.01289", "submitter": "Jean-Marc Andreoli", "authors": "Jean-Marc Andreoli", "title": "Convolution, attention and structure embedding", "comments": "Published in NeurIPS 2019 workshop on Graph Representation Learning,\n  Dec 13, 2019, Vancouver, BC, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are composed of layers of parametrised linear operations\nintertwined with non linear activations. In basic models, such as the\nmulti-layer perceptron, a linear layer operates on a simple input vector\nembedding of the instance being processed, and produces an output vector\nembedding by straight multiplication by a matrix parameter. In more complex\nmodels, the input and output are structured and their embeddings are higher\norder tensors. The parameter of each linear operation must then be controlled\nso as not to explode with the complexity of the structures involved. This is\nessentially the role of convolution models, which exist in many flavours\ndependent on the type of structure they deal with (grids, networks, time series\netc.). We present here a unified framework which aims at capturing the essence\nof these diverse models, allowing a systematic analysis of their properties and\ntheir mutual enrichment. We also show that attention models naturally fit in\nthe same framework: attention is convolution in which the structure itself is\nadaptive, and learnt, instead of being given a priori.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:45:08 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 16:01:42 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 10:07:19 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 12:01:36 GMT"}, {"version": "v5", "created": "Thu, 5 Mar 2020 12:33:36 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Andreoli", "Jean-Marc", ""]]}, {"id": "1905.01296", "submitter": "Nicholas Rhinehart", "authors": "Nicholas Rhinehart, Rowan McAllister, Kris Kitani, Sergey Levine", "title": "PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings", "comments": "To appear at the IEEE International Conference on Computer Vision\n  (ICCV 2019). Website: https://sites.google.com/view/precog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous vehicles (AVs) to behave appropriately on roads populated by\nhuman-driven vehicles, they must be able to reason about the uncertain\nintentions and decisions of other drivers from rich perceptual information.\nTowards these capabilities, we present a probabilistic forecasting model of\nfuture interactions between a variable number of agents. We perform both\nstandard forecasting and the novel task of conditional forecasting, which\nreasons about how all agents will likely respond to the goal of a controlled\nagent (here, the AV). We train models on real and simulated data to forecast\nvehicle trajectories given past positions and LIDAR. Our evaluation shows that\nour model is substantially more accurate in multi-agent driving scenarios\ncompared to existing state-of-the-art. Beyond its general ability to perform\nconditional forecasting queries, we show that our model's predictions of all\nagents improve when conditioned on knowledge of the AV's goal, further\nillustrating its capability to model agent interactions.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:54:09 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 19:51:38 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:45:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rhinehart", "Nicholas", ""], ["McAllister", "Rowan", ""], ["Kitani", "Kris", ""], ["Levine", "Sergey", ""]]}, {"id": "1905.01303", "submitter": "Marc Brittain", "authors": "Marc Brittain, Peng Wei", "title": "Autonomous Air Traffic Controller: A Deep Multi-Agent Reinforcement\n  Learning Approach", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is a real-time safety-critical decision making process in\nhighly dynamic and stochastic environments. In today's aviation practice, a\nhuman air traffic controller monitors and directs many aircraft flying through\nits designated airspace sector. With the fast growing air traffic complexity in\ntraditional (commercial airliners) and low-altitude (drones and eVTOL aircraft)\nairspace, an autonomous air traffic control system is needed to accommodate\nhigh density air traffic and ensure safe separation between aircraft. We\npropose a deep multi-agent reinforcement learning framework that is able to\nidentify and resolve conflicts between aircraft in a high-density, stochastic,\nand dynamic en-route sector with multiple intersections and merging points. The\nproposed framework utilizes an actor-critic model, A2C that incorporates the\nloss function from Proximal Policy Optimization (PPO) to help stabilize the\nlearning process. In addition we use a centralized learning, decentralized\nexecution scheme where one neural network is learned and shared by all agents\nin the environment. We show that our framework is both scalable and efficient\nfor large number of incoming aircraft to achieve extremely high traffic\nthroughput with safety guarantee. We evaluate our model via extensive\nsimulations in the BlueSky environment. Results show that our framework is able\nto resolve 99.97% and 100% of all conflicts both at intersections and merging\npoints, respectively, in extreme high-density air traffic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:03:27 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Brittain", "Marc", ""], ["Wei", "Peng", ""]]}, {"id": "1905.01304", "submitter": "Tao Yao", "authors": "Tao Yao, Xiangwei Kong, Lianshan Yan, Wenjing Tang and Qi Tian", "title": "Efficient Discrete Supervised Hashing for Large-scale Cross-modal\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised cross-modal hashing has gained increasing research interest on\nlarge-scale retrieval task owning to its satisfactory performance and\nefficiency. However, it still has some challenging issues to be further\nstudied: 1) most of them fail to well preserve the semantic correlations in\nhash codes because of the large heterogenous gap; 2) most of them relax the\ndiscrete constraint on hash codes, leading to large quantization error and\nconsequent low performance; 3) most of them suffer from relatively high memory\ncost and computational complexity during training procedure, which makes them\nunscalable. In this paper, to address above issues, we propose a supervised\ncross-modal hashing method based on matrix factorization dubbed Efficient\nDiscrete Supervised Hashing (EDSH). Specifically, collective matrix\nfactorization on heterogenous features and semantic embedding with class labels\nare seamlessly integrated to learn hash codes. Therefore, the feature based\nsimilarities and semantic correlations can be both preserved in hash codes,\nwhich makes the learned hash codes more discriminative. Then an efficient\ndiscrete optimal algorithm is proposed to handle the scalable issue. Instead of\nlearning hash codes bit-by-bit, hash codes matrix can be obtained directly\nwhich is more efficient. Extensive experimental results on three public\nreal-world datasets demonstrate that EDSH produces a superior performance in\nboth accuracy and scalability over some existing cross-modal hashing methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 02:34:09 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yao", "Tao", ""], ["Kong", "Xiangwei", ""], ["Yan", "Lianshan", ""], ["Tang", "Wenjing", ""], ["Tian", "Qi", ""]]}, {"id": "1905.01320", "submitter": "Neil Rabinowitz", "authors": "Neil C. Rabinowitz", "title": "Meta-learners' learning dynamics are unlike learners'", "comments": "26 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a tool that allows us to build sample-efficient learning\nsystems. Here we show that, once meta-trained, LSTM Meta-Learners aren't just\nfaster learners than their sample-inefficient deep learning (DL) and\nreinforcement learning (RL) brethren, but that they actually pursue\nfundamentally different learning trajectories. We study their learning dynamics\non three sets of structured tasks for which the corresponding learning dynamics\nof DL and RL systems have been previously described: linear regression (Saxe et\nal., 2013), nonlinear regression (Rahaman et al., 2018; Xu et al., 2018), and\ncontextual bandits (Schaul et al., 2019). In each case, while\nsample-inefficient DL and RL Learners uncover the task structure in a staggered\nmanner, meta-trained LSTM Meta-Learners uncover almost all task structure\nconcurrently, congruent with the patterns expected from Bayes-optimal inference\nalgorithms. This has implications for research areas wherever the learning\nbehaviour itself is of interest, such as safety, curriculum design, and\nhuman-in-the-loop machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:00:26 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rabinowitz", "Neil C.", ""]]}, {"id": "1905.01330", "submitter": "Stefan Leichenauer", "authors": "Chase Roberts, Ashley Milsted, Martin Ganahl, Adam Zalcman, Bruce\n  Fontaine, Yijian Zou, Jack Hidary, Guifre Vidal, Stefan Leichenauer", "title": "TensorNetwork: A Library for Physics and Machine Learning", "comments": "The TensorNetwork library can be found at\n  https://github.com/google/tensornetwork", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.str-el cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorNetwork is an open source library for implementing tensor network\nalgorithms. Tensor networks are sparse data structures originally designed for\nsimulating quantum many-body physics, but are currently also applied in a\nnumber of other research areas, including machine learning. We demonstrate the\nuse of the API with applications both physics and machine learning, with\ndetails appearing in companion papers.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:14:25 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Roberts", "Chase", ""], ["Milsted", "Ashley", ""], ["Ganahl", "Martin", ""], ["Zalcman", "Adam", ""], ["Fontaine", "Bruce", ""], ["Zou", "Yijian", ""], ["Hidary", "Jack", ""], ["Vidal", "Guifre", ""], ["Leichenauer", "Stefan", ""]]}, {"id": "1905.01331", "submitter": "Stefan Leichenauer", "authors": "Ashley Milsted, Martin Ganahl, Stefan Leichenauer, Jack Hidary, Guifre\n  Vidal", "title": "TensorNetwork on TensorFlow: A Spin Chain Application Using Tree Tensor\n  Networks", "comments": "All code can be found at https://github.com/google/tensornetwork", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.str-el cs.LG hep-th physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorNetwork is an open source library for implementing tensor network\nalgorithms in TensorFlow. We describe a tree tensor network (TTN) algorithm for\napproximating the ground state of either a periodic quantum spin chain (1D) or\na lattice model on a thin torus (2D), and implement the algorithm using\nTensorNetwork. We use a standard energy minimization procedure over a TTN\nansatz with bond dimension $\\chi$, with a computational cost that scales as\n$O(\\chi^4)$. Using bond dimension $\\chi \\in [32,256]$ we compare the use of\nCPUs with GPUs and observe significant computational speed-ups, up to a factor\nof $100$, using a GPU and the TensorNetwork library.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:17:38 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Milsted", "Ashley", ""], ["Ganahl", "Martin", ""], ["Leichenauer", "Stefan", ""], ["Hidary", "Jack", ""], ["Vidal", "Guifre", ""]]}, {"id": "1905.01334", "submitter": "Thomas Liao", "authors": "Thomas Liao, Grant Wang, Brian Yang, Rene Lee, Kristofer Pister,\n  Sergey Levine, and Roberto Calandra", "title": "Data-efficient Learning of Morphology and Controller for a Microrobot", "comments": "Accepted at ICRA-2019. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot design is often a slow and difficult process requiring the iterative\nconstruction and testing of prototypes, with the goal of sequentially\noptimizing the design. For most robots, this process is further complicated by\nthe need, when validating the capabilities of the hardware to solve the desired\ntask, to already have an appropriate controller, which is in turn designed and\ntuned for the specific hardware. In this paper, we propose a novel approach,\nHPC-BBO, to efficiently and automatically design hardware configurations, and\nevaluate them by also automatically tuning the corresponding controller.\nHPC-BBO is based on a hierarchical Bayesian optimization process which\niteratively optimizes morphology configurations (based on the performance of\nthe previous designs during the controller learning process) and subsequently\nlearns the corresponding controllers (exploiting the knowledge collected from\noptimizing for previous morphologies). Moreover, HPC-BBO can select a \"batch\"\nof multiple morphology designs at once, thus parallelizing hardware validation\nand reducing the number of time-consuming production cycles. We validate\nHPC-BBO on the design of the morphology and controller for a simulated 6-legged\nmicrorobot. Experimental results show that HPC-BBO outperforms multiple\ncompetitive baselines, and yields a $360\\%$ reduction in production cycles over\nstandard Bayesian optimization, thus reducing the hypothetical manufacturing\ntime of our microrobot from 21 to 4 months.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:28:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liao", "Thomas", ""], ["Wang", "Grant", ""], ["Yang", "Brian", ""], ["Lee", "Rene", ""], ["Pister", "Kristofer", ""], ["Levine", "Sergey", ""], ["Calandra", "Roberto", ""]]}, {"id": "1905.01347", "submitter": "Chris Dulhanty", "authors": "Chris Dulhanty, Alexander Wong", "title": "Auditing ImageNet: Towards a Model-driven Framework for Annotating\n  Demographic Attributes of Large-Scale Image Datasets", "comments": "To appear in the Workshop on Fairness Accountability Transparency and\n  Ethics in Computer Vision (FATE CV) at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ImageNet dataset ushered in a flood of academic and industry interest in\ndeep learning for computer vision applications. Despite its significant impact,\nthere has not been a comprehensive investigation into the demographic\nattributes of images contained within the dataset. Such a study could lead to\nnew insights on inherent biases within ImageNet, particularly important given\nit is frequently used to pretrain models for a wide variety of computer vision\ntasks. In this work, we introduce a model-driven framework for the automatic\nannotation of apparent age and gender attributes in large-scale image datasets.\nUsing this framework, we conduct the first demographic audit of the 2012\nImageNet Large Scale Visual Recognition Challenge (ILSVRC) subset of ImageNet\nand the \"person\" hierarchical category of ImageNet. We find that 41.62% of\nfaces in ILSVRC appear as female, 1.71% appear as individuals above the age of\n60, and males aged 15 to 29 account for the largest subgroup with 27.11%. We\nnote that the presented model-driven framework is not fair for all\nintersectional groups, so annotation are subject to bias. We present this work\nas the starting point for future development of unbiased annotation models and\nfor the study of downstream effects of imbalances in the demographics of\nImageNet. Code and annotations are available at:\nhttp://bit.ly/ImageNetDemoAudit\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 19:33:02 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 18:32:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Dulhanty", "Chris", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.01357", "submitter": "Ercument Ilhan", "authors": "Erc\\\"ument \\.Ilhan, Jeremy Gow, Diego Perez-Liebana", "title": "Teaching on a Budget in Multi-Agent Deep Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) algorithms can solve complex sequential\ndecision tasks successfully. However, they have a major drawback of having poor\nsample efficiency which can often be tackled by knowledge reuse. In Multi-Agent\nReinforcement Learning (MARL) this drawback becomes worse, but at the same\ntime, a new set of opportunities to leverage knowledge are also presented\nthrough agent interactions. One promising approach among these is peer-to-peer\naction advising through a teacher-student framework. Despite being introduced\nfor single-agent RL originally, recent studies show that it can also be applied\nto multi-agent scenarios with promising empirical results. However, studies in\nthis line of research are currently very limited. In this paper, we propose\nheuristics-based action advising techniques in cooperative decentralised MARL,\nusing a nonlinear function approximation based task-level policy. By adopting\nRandom Network Distillation technique, we devise a measurement for agents to\nassess their knowledge in any given state and be able to initiate the\nteacher-student dynamics with no prior role assumptions. Experimental results\nin a gridworld environment show that such an approach may indeed be useful and\nneeds to be further investigated.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 04:22:09 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 23:08:07 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["\u0130lhan", "Erc\u00fcment", ""], ["Gow", "Jeremy", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1905.01360", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "Skynet: A Top Deep RL Agent in the Inaugural Pommerman Team Competition", "comments": "4th Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pommerman Team Environment is a recently proposed benchmark which\ninvolves a multi-agent domain with challenges such as partial observability,\ndecentralized execution (without communication), and very sparse and delayed\nrewards. The inaugural Pommerman Team Competition held at NeurIPS 2018 hosted\n25 participants who submitted a team of 2 agents. Our submission\nnn_team_skynet955_skynet955 won 2nd place of the \"learning agents'' category.\nOur team is composed of 2 neural networks trained with state of the art deep\nreinforcement learning algorithms and makes use of concepts like reward\nshaping, curriculum learning, and an automatic reasoning module for action\npruning. Here, we describe these elements and additionally we present a\ncollection of open-sourced agents that can be used for training and testing in\nthe Pommerman environment. Code available at:\nhttps://github.com/BorealisAI/pommerman-baseline\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 18:30:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gao", "Chao", ""], ["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1905.01369", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Yike Guo", "title": "Static Activation Function Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent seminal work at the intersection of deep neural networks practice and\nrandom matrix theory has linked the convergence speed and robustness of these\nnetworks with the combination of random weight initialization and nonlinear\nactivation function in use. Building on those principles, we introduce a\nprocess to transform an existing activation function into another one with\nbetter properties. We term such transform \\emph{static activation\nnormalization}. More specifically we focus on this normalization applied to the\nReLU unit, and show empirically that it significantly promotes convergence\nrobustness, maximum training depth, and anytime performance. We verify these\nclaims by examining empirical eigenvalue distributions of networks trained with\nthose activations. Our static activation normalization provides a first step\ntowards giving benefits similar in spirit to schemes like batch normalization,\nbut without computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 21:43:35 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Guo", "Yike", ""]]}, {"id": "1905.01375", "submitter": "Ian Covert", "authors": "Ian Covert, Balu Krishnan, Imad Najm, Jiening Zhan, Matthew Shore,\n  John Hixson, Ming Jack Po", "title": "Temporal Graph Convolutional Networks for Automatic Seizure Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seizure detection from EEGs is a challenging and time consuming clinical\nproblem that would benefit from the development of automated algorithms. EEGs\ncan be viewed as structural time series, because they are multivariate time\nseries where the placement of leads on a patient's scalp provides prior\ninformation about the structure of interactions. Commonly used deep learning\nmodels for time series don't offer a way to leverage structural information,\nbut this would be desirable in a model for structural time series. To address\nthis challenge, we propose the temporal graph convolutional network (TGCN), a\nmodel that leverages structural information and has relatively few parameters.\nTGCNs apply feature extraction operations that are localized and shared over\nboth time and space, thereby providing a useful inductive bias in tasks where\none expects similar features to be discriminative across the different\nsequences. In our experiments we focus on metrics that are most important to\nseizure detection, and demonstrate that TGCN matches the performance of related\nmodels that have been shown to be state of the art in other tasks.\nAdditionally, we investigate interpretability advantages of TGCN by exploring\napproaches for helping clinicians determine when precisely seizures occur, and\nthe parts of the brain that are most involved.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 22:39:53 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Covert", "Ian", ""], ["Krishnan", "Balu", ""], ["Najm", "Imad", ""], ["Zhan", "Jiening", ""], ["Shore", "Matthew", ""], ["Hixson", "John", ""], ["Po", "Ming Jack", ""]]}, {"id": "1905.01386", "submitter": "Manojkumar Rangasamy Kannadasan", "authors": "Manojkumar Rangasamy Kannadasan, Grigor Aslanyan", "title": "Personalized Query Auto-Completion Through a Lightweight Representation\n  of the User Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Auto-Completion (QAC) is a widely used feature in many domains,\nincluding web and eCommerce search, suggesting full queries based on a prefix\ntyped by the user. QAC has been extensively studied in the literature in the\nrecent years, and it has been consistently shown that adding personalization\nfeatures can significantly improve the performance of QAC. In this work we\npropose a novel method for personalized QAC that uses lightweight embeddings\nlearnt through fastText. We construct an embedding for the user context\nqueries, which are the last few queries issued by the user. We also use the\nsame model to get the embedding for the candidate queries to be ranked. We\nintroduce ranking features that compute the distance between the candidate\nqueries and the context queries in the embedding space. These features are then\ncombined with other commonly used QAC ranking features to learn a ranking\nmodel. We apply our method to a large eCommerce search engine (eBay) and show\nthat the ranker with our proposed feature significantly outperforms the\nbaselines on all of the offline metrics measured, which includes Mean\nReciprocal Rank (MRR), Success Rate (SR), Mean Average Precision (MAP), and\nNormalized Discounted Cumulative Gain (NDCG). Our baselines include the Most\nPopular Completion (MPC) model as well as a ranking model without our proposed\nfeatures. The ranking model with the proposed features results in a $20-30\\%$\nimprovement over the MPC model on all metrics. We obtain up to a $5\\%$\nimprovement over the baseline ranking model for all the sessions, which goes up\nto about $10\\%$ when we restrict to sessions that contain the user context.\nMoreover, our proposed features also significantly outperform text based\npersonalization features studied in the literature before, and adding text\nbased features on top of our proposed embedding based features results only in\nminor improvements.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 23:28:18 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kannadasan", "Manojkumar Rangasamy", ""], ["Aslanyan", "Grigor", ""]]}, {"id": "1905.01389", "submitter": "Wei Cai", "authors": "Wei Cai, Xiaoguang Li, Lizuo Liu", "title": "PhaseDNN - A Parallel Phase Shift Deep Neural Network for Adaptive\n  Wideband Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a phase shift deep neural network (PhaseDNN) which\nprovides a wideband convergence in approximating a high dimensional function\nduring its training of the network. The PhaseDNN utilizes the fact that many\nDNN achieves convergence in the low frequency range first, thus, a series of\nmoderately-sized of DNNs are constructed and trained in parallel for ranges of\nhigher frequencies. With the help of phase shifts in the frequency domain,\nimplemented through a simple phase factor multiplication on the training data,\neach DNN in the series will be trained to approximate the target function's\nhigher frequency content over a specific range. Due to the phase shift, each\nDNN achieves the speed of convergence as in the low frequency range. As a\nresult, the proposed PhaseDNN system is able to convert wideband frequency\nlearning to low frequency learning, thus allowing a uniform learning to\nwideband high dimensional functions with frequency adaptive training. Numerical\nresults have demonstrated the capability of PhaseDNN in learning information of\na target function from low to high frequency uniformly.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 23:38:55 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 21:19:50 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Cai", "Wei", ""], ["Li", "Xiaoguang", ""], ["Liu", "Lizuo", ""]]}, {"id": "1905.01391", "submitter": "Jonah Casebeer", "authors": "Jonah Casebeer, Michael Colomb, Paris Smaragdis", "title": "Deep Tensor Factorization for Spatially-Aware Scene Decomposition", "comments": "5 pages, 5 figures, accepted to WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a completely unsupervised method to understand audio scenes\nobserved with random microphone arrangements by decomposing the scene into its\nconstituent sources and their relative presence in each microphone. To this\nend, we formulate a neural network architecture that can be interpreted as a\nnonnegative tensor factorization of a multi-channel audio recording. By\nclustering on the learned network parameters corresponding to channel content,\nwe can learn sources' individual spectral dictionaries and their activation\npatterns over time. Our method allows us to leverage deep learning advances\nlike end-to-end training, while also allowing stochastic minibatch training so\nthat we can feasibly decompose realistic audio scenes that are intractable to\ndecompose using standard methods. This neural network architecture is easily\nextensible to other kinds of tensor factorizations.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 23:58:56 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 23:39:19 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Casebeer", "Jonah", ""], ["Colomb", "Michael", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1905.01392", "submitter": "Martin Wistuba", "authors": "Martin Wistuba and Ambrish Rawat and Tejaswini Pedapati", "title": "A Survey on Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest in both the automation of machine learning and deep\nlearning has inevitably led to the development of a wide variety of automated\nmethods for neural architecture search. The choice of the network architecture\nhas proven to be critical, and many advances in deep learning spring from its\nimmediate improvements. However, deep learning techniques are computationally\nintensive and their application requires a high level of domain knowledge.\nTherefore, even partial automation of this process helps to make deep learning\nmore accessible to both researchers and practitioners. With this survey, we\nprovide a formalism which unifies and categorizes the landscape of existing\nmethods along with a detailed analysis that compares and contrasts the\ndifferent approaches. We achieve this via a comprehensive discussion of the\ncommonly adopted architecture search spaces and architecture optimization\nalgorithms based on principles of reinforcement learning and evolutionary\nalgorithms along with approaches that incorporate surrogate and one-shot\nmodels. Additionally, we address the new research directions which include\nconstrained and multi-objective architecture search as well as automated data\naugmentation, optimizer and activation function search.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 00:08:49 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 09:32:21 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Wistuba", "Martin", ""], ["Rawat", "Ambrish", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1905.01395", "submitter": "Steffen Rendle", "authors": "Steffen Rendle, Li Zhang, Yehuda Koren", "title": "On the Difficulty of Evaluating Baselines: A Study on Recommender\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical evaluations with comparisons to baselines play a central role when\njudging research in recommender systems. In this paper, we show that running\nbaselines properly is difficult. We demonstrate this issue on two extensively\nstudied datasets. First, we show that results for baselines that have been used\nin numerous publications over the past five years for the Movielens 10M\nbenchmark are suboptimal. With a careful setup of a vanilla matrix\nfactorization baseline, we are not only able to improve upon the reported\nresults for this baseline but even outperform the reported results of any newly\nproposed method. Secondly, we recap the tremendous effort that was required by\nthe community to obtain high quality results for simple methods on the Netflix\nPrize. Our results indicate that empirical findings in research papers are\nquestionable unless they were obtained on standardized benchmarks where\nbaselines have been tuned extensively by the research community.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 00:27:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rendle", "Steffen", ""], ["Zhang", "Li", ""], ["Koren", "Yehuda", ""]]}, {"id": "1905.01413", "submitter": "Mingyuan Zhou", "authors": "Mingzhang Yin, Yuguang Yue, Mingyuan Zhou", "title": "ARSM: Augment-REINFORCE-Swap-Merge Estimator for Gradient\n  Backpropagation Through Categorical Variables", "comments": "Published in ICML 2019. We have updated Section 4.2 and the Appendix\n  to reflect the improvements brought by fixing some bugs hidden in our\n  original code. Please find the Errata in the authors' websites and check the\n  updated code in Github", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the challenge of backpropagating the gradient through categorical\nvariables, we propose the augment-REINFORCE-swap-merge (ARSM) gradient\nestimator that is unbiased and has low variance. ARSM first uses variable\naugmentation, REINFORCE, and Rao-Blackwellization to re-express the gradient as\nan expectation under the Dirichlet distribution, then uses variable swapping to\nconstruct differently expressed but equivalent expectations, and finally shares\ncommon random numbers between these expectations to achieve significant\nvariance reduction. Experimental results show ARSM closely resembles the\nperformance of the true gradient for optimization in univariate settings;\noutperforms existing estimators by a large margin when applied to categorical\nvariational auto-encoders; and provides a \"try-and-see self-critic\" variance\nreduction method for discrete-action policy gradient, which removes the need of\nestimating baselines by generating a random number of pseudo actions and\nestimating their action-value functions.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 02:26:09 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 16:43:00 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yin", "Mingzhang", ""], ["Yue", "Yuguang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.01416", "submitter": "Ahmed Taha Elthakeb", "authors": "Ahmed T. Elthakeb, Prannoy Pilligundla, Hadi Esmaeilzadeh", "title": "SinReQ: Generalized Sinusoidal Regularization for Low-Bitwidth Deep\n  Quantized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep quantization of neural networks (below eight bits) offers significant\npromise in reducing their compute and storage cost. Albeit alluring, without\nspecial techniques for training and optimization, deep quantization results in\nsignificant accuracy loss. To further mitigate this loss, we propose a novel\nsinusoidal regularization, called SinReQ1, for deep quantized training. SinReQ\nadds a periodic term to the original objective function of the underlying\ntraining algorithm. SinReQ exploits the periodicity, differentiability, and the\ndesired convexity profile in sinusoidal functions to automatically propel\nweights towards values that are inherently closer to quantization levels.\nSince, this technique does not require invasive changes to the training\nprocedure, SinReQ can harmoniously enhance quantized training algorithms.\nSinReQ offers generality and flexibility as it is not limited to a certain\nbitwidth or a uniform assignment of bitwidths across layers. We carry out\nexperimentation using the AlexNet, CIFAR-10, ResNet-18, ResNet-20, SVHN, and\nVGG-11 DNNs with three to five bits for quantization and show the versatility\nof SinReQ in enhancing multiple quantized training algorithms, DoReFa [32] and\nWRPN [24]. Averaging across all the bit configurations shows that SinReQ closes\nthe accuracy gap between these two techniques and the full-precision runs by\n32.4% and 27.5%, respectively. That is improving the absolute accuracy of\nDoReFa and WRPN by 2.8% and 2.1%, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:13:46 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 16:00:02 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 18:31:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Elthakeb", "Ahmed T.", ""], ["Pilligundla", "Prannoy", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1905.01422", "submitter": "Yushu Chen", "authors": "Yushu Chen, Hao Jing, Wenlai Zhao, Zhiqiang Liu, Ouyi Li, Liang Qiao,\n  Wei Xue, Guangwen Yang", "title": "An Adaptive Remote Stochastic Gradient Method for Training Neural\n  Networks", "comments": "The generalization is improved by modifying the preconditioner. For\n  training ResNet-50 on ImageNet, ARSG outperforms ADAM in convergence speed\n  and meanwhile it surpasses SGD in generalization. We also present a\n  convergence bound in non-convex settings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the remote stochastic gradient (RSG) method, which computes the\ngradients at configurable remote observation points, in order to improve the\nconvergence rate and suppress gradient noise at the same time for different\ncurvatures. RSG is further combined with adaptive methods to construct ARSG for\nacceleration. The method is efficient in computation and memory, and is\nstraightforward to implement. We analyze the convergence properties by modeling\nthe training process as a dynamic system, which provides a guideline to select\nthe configurable observation factor without grid search. ARSG yields\n$O(1/\\sqrt{T})$ convergence rate in non-convex settings, that can be further\nimproved to $O(\\log(T)/T)$ in strongly convex settings. Numerical experiments\ndemonstrate that ARSG achieves both faster convergence and better\ngeneralization, compared with popular adaptive methods, such as ADAM, NADAM,\nAMSGRAD, and RANGER for the tested problems. In particular, for training\nResNet-50 on ImageNet, ARSG outperforms ADAM in convergence speed and meanwhile\nit surpasses SGD in generalization.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:39:30 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 16:33:27 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 06:02:12 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 18:19:31 GMT"}, {"version": "v5", "created": "Sun, 29 Sep 2019 12:55:07 GMT"}, {"version": "v6", "created": "Thu, 5 Dec 2019 05:49:22 GMT"}, {"version": "v7", "created": "Mon, 8 Jun 2020 10:26:54 GMT"}, {"version": "v8", "created": "Sun, 6 Sep 2020 04:23:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Yushu", ""], ["Jing", "Hao", ""], ["Zhao", "Wenlai", ""], ["Liu", "Zhiqiang", ""], ["Li", "Ouyi", ""], ["Qiao", "Liang", ""], ["Xue", "Wei", ""], ["Yang", "Guangwen", ""]]}, {"id": "1905.01425", "submitter": "Zhihan Guo", "authors": "Zhihan Guo and Theodoros Rekatsinas", "title": "Learning Functional Dependencies with Sparse Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of discovering functional dependencies (FD) from a noisy\ndataset. We focus on FDs that correspond to statistical dependencies in a\ndataset and draw connections between FD discovery and structure learning in\nprobabilistic graphical models. We show that discovering FDs from a noisy\ndataset is equivalent to learning the structure of a graphical model over\nbinary random variables, where each random variable corresponds to a functional\nof the dataset attributes. We build upon this observation to introduce AutoFD a\nconceptually simple framework in which learning functional dependencies\ncorresponds to solving a sparse regression problem. We show that our methods\ncan recover true functional dependencies across a diverse array of real-world\nand synthetic datasets, even in the presence of noisy or missing data. We find\nthat AutoFD scales to large data instances with millions of tuples and hundreds\nof attributes while it yields an average F1 improvement of 2 times against\nstate-of-the-art FD discovery methods.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:59:05 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Guo", "Zhihan", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "1905.01426", "submitter": "Amandeep Bhatia", "authors": "Amandeep Singh Bhatia, Mandeep Kaur Saggi, Ajay Kumar, Sushma Jain", "title": "Matrix Product State Based Quantum Classifier", "comments": "9", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, interest in expressing the success of neural networks to the\nquantum computing has increased significantly. Tensor network theory has become\nincreasingly popular and widely used to simulate strongly entangled correlated\nsystems. Matrix product state (MPS) is the well-designed class of tensor\nnetwork states, which plays an important role in processing of quantum\ninformation. In this paper, we have shown that matrix product state as\none-dimensional array of tensors can be used to classify classical and quantum\ndata. We have performed binary classification of classical machine learning\ndataset Iris encoded in a quantum state. Further, we have investigated the\nperformance by considering different parameters on the ibmqx4 quantum computer\nand proved that MPS circuits can be used to attain better accuracy. Further,\nthe learning ability of MPS quantum classifier is tested to classify\nevapotranspiration ($ET_{o}$) for Patiala meteorological station located in\nNorthern Punjab (India), using three years of historical dataset (Agri).\nFurthermore, we have used different performance metrics of classification to\nmeasure its capability. Finally, the results are plotted and degree of\ncorrespondence among values of each sample is shown.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 04:08:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Bhatia", "Amandeep Singh", ""], ["Saggi", "Mandeep Kaur", ""], ["Kumar", "Ajay", ""], ["Jain", "Sushma", ""]]}, {"id": "1905.01430", "submitter": "Zhengping Luo", "authors": "Zhengping Luo, Shangqing Zhao, Zhuo Lu, Jie Xu, and Yalin E. Sagduyu", "title": "When Attackers Meet AI: Learning-empowered Attacks in Cooperative\n  Spectrum Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defense strategies have been well studied to combat Byzantine attacks that\naim to disrupt cooperative spectrum sensing by sending falsified versions of\nspectrum sensing data to a fusion center. However, existing studies usually\nassume network or attackers as passive entities, e.g., assuming the prior\nknowledge of attacks is known or fixed. In practice, attackers can actively\nadopt arbitrary behaviors and avoid pre-assumed patterns or assumptions used by\ndefense strategies. In this paper, we revisit this security vulnerability as an\nadversarial machine learning problem and propose a novel learning-empowered\nattack framework named Learning-Evaluation-Beating (LEB) to mislead the fusion\ncenter. Based on the black-box nature of the fusion center in cooperative\nspectrum sensing, our new perspective is to make the adversarial use of machine\nlearning to construct a surrogate model of the fusion center's decision model.\nWe propose a generic algorithm to create malicious sensing data using this\nsurrogate model. Our real-world experiments show that the LEB attack is\neffective to beat a wide range of existing defense strategies with an up to 82%\nof success ratio. Given the gap between the proposed LEB attack and existing\ndefenses, we introduce a non-invasive method named as influence-limiting\ndefense, which can coexist with existing defenses to defend against LEB attack\nor other similar attacks. We show that this defense is highly effective and\nreduces the overall disruption ratio of LEB attack by up to 80%.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 04:58:00 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 21:36:06 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Luo", "Zhengping", ""], ["Zhao", "Shangqing", ""], ["Lu", "Zhuo", ""], ["Xu", "Jie", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1905.01435", "submitter": "Yuan Zhou", "authors": "Yingkai Li, Yining Wang, Xi Chen, Yuan Zhou", "title": "Tight Regret Bounds for Infinite-armed Linear Contextual Bandits", "comments": "10 pages, accepted for presentation at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear contextual bandit is an important class of sequential decision making\nproblems with a wide range of applications to recommender systems, online\nadvertising, healthcare, and many other machine learning related tasks. While\nthere is a lot of prior research, tight regret bounds of linear contextual\nbandit with infinite action sets remain open. In this paper, we address this\nopen problem by considering the linear contextual bandit with (changing)\ninfinite action sets. We prove a regret upper bound on the order of\n$O(\\sqrt{d^2T\\log T})\\times \\text{poly}(\\log\\log T)$ where $d$ is the domain\ndimension and $T$ is the time horizon. Our upper bound matches the previous\nlower bound of $\\Omega(\\sqrt{d^2 T\\log T})$ in [Li et al., 2019] up to iterated\nlogarithmic terms.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 05:51:30 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 18:29:23 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 23:55:53 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Yingkai", ""], ["Wang", "Yining", ""], ["Chen", "Xi", ""], ["Zhou", "Yuan", ""]]}, {"id": "1905.01436", "submitter": "Jongmin Kim", "authors": "Jongmin Kim, Taesup Kim, Sungwoong Kim, Chang D. Yoo", "title": "Edge-labeling Graph Neural Network for Few-shot Learning", "comments": "accepted to CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel edge-labeling graph neural network (EGNN),\nwhich adapts a deep neural network on the edge-labeling graph, for few-shot\nlearning. The previous graph neural network (GNN) approaches in few-shot\nlearning have been based on the node-labeling framework, which implicitly\nmodels the intra-cluster similarity and the inter-cluster dissimilarity. In\ncontrast, the proposed EGNN learns to predict the edge-labels rather than the\nnode-labels on the graph that enables the evolution of an explicit clustering\nby iteratively updating the edge-labels with direct exploitation of both\nintra-cluster similarity and the inter-cluster dissimilarity. It is also well\nsuited for performing on various numbers of classes without retraining, and can\nbe easily extended to perform a transductive inference. The parameters of the\nEGNN are learned by episodic training with an edge-labeling loss to obtain a\nwell-generalizable model for unseen low-data problem. On both of the supervised\nand semi-supervised few-shot image classification tasks with two benchmark\ndatasets, the proposed EGNN significantly improves the performances over the\nexisting GNNs.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 05:58:17 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kim", "Jongmin", ""], ["Kim", "Taesup", ""], ["Kim", "Sungwoong", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1905.01446", "submitter": "Yuheng Jia", "authors": "Yuheng Jia, Hui Liu, Junhui Hou, Sam Kwong", "title": "Clustering-aware Graph Construction: A Joint Learning Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based clustering methods have demonstrated the effectiveness in various\napplications. Generally, existing graph-based clustering methods first\nconstruct a graph to represent the input data and then partition it to generate\nthe clustering result. However, such a stepwise manner may make the constructed\ngraph not fit the requirements for the subsequent decomposition, leading to\ncompromised clustering accuracy. To this end, we propose a joint learning\nframework, which is able to learn the graph and the clustering result\nsimultaneously, such that the resulting graph is tailored to the clustering\ntask. The proposed model is formulated as a well-defined nonnegative and\noff-diagonal constrained optimization problem, which is further efficiently\nsolved with convergence theoretically guaranteed. The advantage of the proposed\nmodel is demonstrated by comparing with 19 state-of-the-art clustering methods\non 10 datasets with 4 clustering metrics.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 06:54:33 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:29:32 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 03:16:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Jia", "Yuheng", ""], ["Liu", "Hui", ""], ["Hou", "Junhui", ""], ["Kwong", "Sam", ""]]}, {"id": "1905.01489", "submitter": "Senthil Yogamani", "authors": "Senthil Yogamani, Ciaran Hughes, Jonathan Horgan, Ganesh Sistu,\n  Padraig Varley, Derek O'Dea, Michal Uricar, Stefan Milz, Martin Simon, Karl\n  Amende, Christian Witt, Hazem Rashed, Sumanth Chennupati, Sanjaya Nayak,\n  Saquib Mansoor, Xavier Perroton, Patrick Perez", "title": "WoodScape: A multi-task, multi-camera fisheye dataset for autonomous\n  driving", "comments": "Accepted for Oral Presentation at IEEE International Conference on\n  Computer Vision (ICCV) 2019. Please refer to our website\n  https://woodscape.valeo.com and https://github.com/valeoai/woodscape for\n  release status and updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisheye cameras are commonly employed for obtaining a large field of view in\nsurveillance, augmented reality and in particular automotive applications. In\nspite of their prevalence, there are few public datasets for detailed\nevaluation of computer vision algorithms on fisheye images. We release the\nfirst extensive fisheye automotive dataset, WoodScape, named after Robert Wood\nwho invented the fisheye camera in 1906. WoodScape comprises of four surround\nview cameras and nine tasks including segmentation, depth estimation, 3D\nbounding box detection and soiling detection. Semantic annotation of 40 classes\nat the instance level is provided for over 10,000 images and annotation for\nother tasks are provided for over 100,000 images. With WoodScape, we would like\nto encourage the community to adapt computer vision models for fisheye camera\ninstead of using naive rectification.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 13:14:12 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 20:40:58 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 22:16:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yogamani", "Senthil", ""], ["Hughes", "Ciaran", ""], ["Horgan", "Jonathan", ""], ["Sistu", "Ganesh", ""], ["Varley", "Padraig", ""], ["O'Dea", "Derek", ""], ["Uricar", "Michal", ""], ["Milz", "Stefan", ""], ["Simon", "Martin", ""], ["Amende", "Karl", ""], ["Witt", "Christian", ""], ["Rashed", "Hazem", ""], ["Chennupati", "Sumanth", ""], ["Nayak", "Sanjaya", ""], ["Mansoor", "Saquib", ""], ["Perroton", "Xavier", ""], ["Perez", "Patrick", ""]]}, {"id": "1905.01492", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, Pavel Krizek, Ganesh Sistu and Senthil Yogamani", "title": "SoilingNet: Soiling Detection on Automotive Surround-View Cameras", "comments": "Accepted for Oral Presentation at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cameras are an essential part of sensor suite in autonomous driving.\nSurround-view cameras are directly exposed to external environment and are\nvulnerable to get soiled. Cameras have a much higher degradation in performance\ndue to soiling compared to other sensors. Thus it is critical to accurately\ndetect soiling on the cameras, particularly for higher levels of autonomous\ndriving. We created a new dataset having multiple types of soiling namely\nopaque and transparent. It will be released publicly as part of our WoodScape\ndataset \\cite{yogamani2019woodscape} to encourage further research. We\ndemonstrate high accuracy using a Convolutional Neural Network (CNN) based\narchitecture. We also show that it can be combined with the existing object\ndetection task in a multi-task learning framework. Finally, we make use of\nGenerative Adversarial Networks (GANs) to generate more images for data\naugmentation and show that it works successfully similar to the style transfer.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 13:39:48 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 16:34:40 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Uricar", "Michal", ""], ["Krizek", "Pavel", ""], ["Sistu", "Ganesh", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1905.01520", "submitter": "Abhishek Ghose", "authors": "Abhishek Ghose, Balaraman Ravindran", "title": "Interpretability with Accurate Small Models", "comments": "The presentation of the method was changed. Results are averaged over\n  multiple runs for reliability. Core ideas, experiments and ideas are same as\n  the previous version", "journal-ref": "Frontiers in Artificial Intelligence, 3 (2020), 3", "doi": "10.3389/frai.2020.00003", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models often need to be constrained to a certain size for them to be\nconsidered interpretable. For example, a decision tree of depth 5 is much\neasier to understand than one of depth 50. Limiting model size, however, often\nreduces accuracy. We suggest a practical technique that minimizes this\ntrade-off between interpretability and classification accuracy. This enables an\narbitrary learning algorithm to produce highly accurate small-sized models. Our\ntechnique identifies the training data distribution to learn from that leads to\nthe highest accuracy for a model of a given size.\n  We represent the training distribution as a combination of sampling schemes.\nEach scheme is defined by a parameterized probability mass function applied to\nthe segmentation produced by a decision tree. An Infinite Mixture Model with\nBeta components is used to represent a combination of such schemes. The mixture\nmodel parameters are learned using Bayesian Optimization. Under simplistic\nassumptions, we would need to optimize for $O(d)$ variables for a distribution\nover a $d$-dimensional input space, which is cumbersome for most real-world\ndata. However, we show that our technique significantly reduces this number to\na \\emph{fixed set of eight variables} at the cost of relatively cheap\npreprocessing. The proposed technique is flexible: it is \\emph{model-agnostic},\ni.e., it may be applied to the learning algorithm for any model family, and it\nadmits a general notion of model size. We demonstrate its effectiveness using\nmultiple real-world datasets to construct decision trees, linear probability\nmodels and gradient boosted models with different sizes. We observe significant\nimprovements in the F1-score in most instances, exceeding an improvement of\n$100\\%$ in some cases.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 16:43:07 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 23:51:21 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Ghose", "Abhishek", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1905.01537", "submitter": "Madhavun Candadai", "authors": "Zach Dwiel, Madhavun Candadai, Mariano Phielipp, Arjun K. Bansal", "title": "Hierarchical Policy Learning is Sensitive to Goal Space Design", "comments": "Accepted to be presented at Task-Agnostic Reinforcement Learning\n  (TARL) workshop at ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchy in reinforcement learning agents allows for control at multiple\ntime scales yielding improved sample efficiency, the ability to deal with long\ntime horizons and transferability of sub-policies to tasks outside the training\ndistribution. It is often implemented as a master policy providing goals to a\nsub-policy. Ideally, we would like the goal-spaces to be learned, however,\nproperties of optimal goal spaces still remain unknown and consequently there\nis no method yet to learn optimal goal spaces. Motivated by this, we\nsystematically analyze how various modifications to the ground-truth goal-space\naffect learning in hierarchical models with the aim of identifying important\nproperties of optimal goal spaces. Our results show that, while rotation of\nground-truth goal spaces and noise had no effect, having additional unnecessary\nfactors significantly impaired learning in hierarchical models.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 18:22:32 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:47:43 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Dwiel", "Zach", ""], ["Candadai", "Madhavun", ""], ["Phielipp", "Mariano", ""], ["Bansal", "Arjun K.", ""]]}, {"id": "1905.01546", "submitter": "Pan Li", "authors": "Pan Li, Alexander Tuzhilin", "title": "Latent Unexpected and Useful Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing unexpected recommendations is an important task for recommender\nsystems. To do this, we need to start from the expectations of users and\ndeviate from these expectations when recommending items. Previously proposed\napproaches model user expectations in the feature space, making them limited to\nthe items that the user has visited or expected by the deduction of associated\nrules, without including the items that the user could also expect from the\nlatent, complex and heterogeneous interactions between users, items and\nentities. In this paper, we define unexpectedness in the latent space rather\nthan in the feature space and develop a novel Latent Convex Hull (LCH) method\nto provide unexpected recommendations. Extensive experiments on two real-world\ndatasets demonstrate the effectiveness of the proposed model that significantly\noutperforms alternative state-of-the-art unexpected recommendation methods in\nterms of unexpectedness measures while achieving the same level of accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 19:45:04 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1905.01553", "submitter": "Elham Shaabani", "authors": "Elham Shaabani, Ashkan Sadeghi-Mobarakeh, Hamidreza Alvari and Paulo\n  Shakarian", "title": "An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter", "comments": "9 pages, 8 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01556", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information \"viral\". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 20:19:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Shaabani", "Elham", ""], ["Sadeghi-Mobarakeh", "Ashkan", ""], ["Alvari", "Hamidreza", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1905.01556", "submitter": "Elham Shaabani", "authors": "Elham Shaabani, Ruocheng Guo, and Paulo Shakarian", "title": "Detecting Pathogenic Social Media Accounts without Content or Network\n  Structure", "comments": "8 pages, 5 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01553", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of harmful mis-information in social media is a pressing problem.\nWe refer accounts that have the capability of spreading such information to\nviral proportions as \"Pathogenic Social Media\" accounts. These accounts include\nterrorist supporters accounts, water armies, and fake news writers. We\nintroduce an unsupervised causality-based framework that also leverages label\npropagation. This approach identifies these users without using network\nstructure, cascade path information, content and user's information. We show\nour approach obtains higher precision (0.75) in identifying Pathogenic Social\nMedia accounts in comparison with random (precision of 0.11) and existing bot\ndetection (precision of 0.16) methods.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 20:51:06 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Shaabani", "Elham", ""], ["Guo", "Ruocheng", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1905.01562", "submitter": "Manuel Lagunas", "authors": "Manuel Lagunas, Sandra Malpica, Ana Serrano, Elena Garces, Diego\n  Gutierrez, Belen Masia", "title": "A Similarity Measure for Material Appearance", "comments": "12 pages, 17 figures", "journal-ref": "ACM Transactions on Graphics (SIGGRAPH 2019)", "doi": "10.1145/3306346.3323036", "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model to measure the similarity in appearance between different\nmaterials, which correlates with human similarity judgments. We first create a\ndatabase of 9,000 rendered images depicting objects with varying materials,\nshape and illumination. We then gather data on perceived similarity from\ncrowdsourced experiments; our analysis of over 114,840 answers suggests that\nindeed a shared perception of appearance similarity exists. We feed this data\nto a deep learning architecture with a novel loss function, which learns a\nfeature space for materials that correlates with such perceived appearance\nsimilarity. Our evaluation shows that our model outperforms existing metrics.\nLast, we demonstrate several applications enabled by our metric, including\nappearance-based search for material suggestions, database visualization,\nclustering and summarization, and gamut mapping.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 22:48:27 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lagunas", "Manuel", ""], ["Malpica", "Sandra", ""], ["Serrano", "Ana", ""], ["Garces", "Elena", ""], ["Gutierrez", "Diego", ""], ["Masia", "Belen", ""]]}, {"id": "1905.01576", "submitter": "Lin Yang", "authors": "Lin F. Yang, Chengzhuo Ni, Mengdi Wang", "title": "Learning to Control in Metric Space with Optimal Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online reinforcement learning for finite-horizon deterministic\ncontrol systems with {\\it arbitrary} state and action spaces. Suppose that the\ntransition dynamics and reward function is unknown, but the state and action\nspace is endowed with a metric that characterizes the proximity between\ndifferent states and actions. We provide a surprisingly simple upper-confidence\nreinforcement learning algorithm that uses a function approximation oracle to\nestimate optimistic Q functions from experiences. We show that the regret of\nthe algorithm after $K$ episodes is $O(HL(KH)^{\\frac{d-1}{d}}) $ where $L$ is a\nsmoothness parameter, and $d$ is the doubling dimension of the state-action\nspace with respect to the given metric. We also establish a near-matching\nregret lower bound. The proposed method can be adapted to work for more\nstructured transition systems, including the finite-state case and the case\nwhere value functions are linear combinations of features, where the method\nalso achieve the optimal regret.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 01:42:44 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yang", "Lin F.", ""], ["Ni", "Chengzhuo", ""], ["Wang", "Mengdi", ""]]}, {"id": "1905.01591", "submitter": "Hoang Nguyen Thai", "authors": "Hoang NT, Choong Jun Jin, Tsuyoshi Murata", "title": "Learning Graph Neural Networks with Noisy Labels", "comments": "5 pages, 4 figures, 3 tables; Appeared as a poster presentation at\n  Limited Labeled Data (LLD) Workshop, ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness to symmetric label noise of GNNs training procedures.\nBy combining the nonlinear neural message-passing models (e.g. Graph\nIsomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present\na noise-tolerant approach for the graph classification task. Our experiments\nshow that test accuracy can be improved under the artificial symmetric noisy\nsetting.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 03:27:50 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["NT", "Hoang", ""], ["Jin", "Choong Jun", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "1905.01595", "submitter": "Yibing Zhan", "authors": "Yibing Zhan, Jun Yu, Ting Yu and Dacheng Tao", "title": "On Exploring Undetermined Relationships for Visual Relationship\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual relationship detection, human-notated relationships can be regarded\nas determinate relationships. However, there are still large amount of\nunlabeled data, such as object pairs with less significant relationships or\neven with no relationships. We refer to these unlabeled but potentially useful\ndata as undetermined relationships. Although a vast body of literature exists,\nfew methods exploit these undetermined relationships for visual relationship\ndetection.\n  In this paper, we explore the beneficial effect of undetermined relationships\non visual relationship detection. We propose a novel multi-modal feature based\nundetermined relationship learning network (MF-URLN) and achieve great\nimprovements in relationship detection. In detail, our MF-URLN automatically\ngenerates undetermined relationships by comparing object pairs with\nhuman-notated data according to a designed criterion. Then, the MF-URLN\nextracts and fuses features of object pairs from three complementary modals:\nvisual, spatial, and linguistic modals. Further, the MF-URLN proposes two\ncorrelated subnetworks: one subnetwork decides the determinate confidence, and\nthe other predicts the relationships. We evaluate the MF-URLN on two datasets:\nthe Visual Relationship Detection (VRD) and the Visual Genome (VG) datasets.\nThe experimental results compared with state-of-the-art methods verify the\nsignificant improvements made by the undetermined relationships, e.g., the\ntop-50 relation detection recall improves from 19.5% to 23.9% on the VRD\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 03:57:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zhan", "Yibing", ""], ["Yu", "Jun", ""], ["Yu", "Ting", ""], ["Tao", "Dacheng", ""]]}, {"id": "1905.01596", "submitter": "Donghui Yan", "authors": "Donghui Yan, Yingjie Wang, Jin Wang, Guodong Wu, Honggang Wang", "title": "Fast communication-efficient spectral clustering over distributed data", "comments": "27 pages, 7 figures", "journal-ref": "IEEE Transactions on Big Data, 2019", "doi": "10.1109/TBDATA.2019.2907985", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decades have seen a surge of interests in distributed computing\nthanks to advances in clustered computing and big data technology. Existing\ndistributed algorithms typically assume {\\it all the data are already in one\nplace}, and divide the data and conquer on multiple machines. However, it is\nincreasingly often that the data are located at a number of distributed sites,\nand one wishes to compute over all the data with low communication overhead.\nFor spectral clustering, we propose a novel framework that enables its\ncomputation over such distributed data, with \"minimal\" communications while a\nmajor speedup in computation. The loss in accuracy is negligible compared to\nthe non-distributed setting. Our approach allows local parallel computing at\nwhere the data are located, thus turns the distributed nature of the data into\na blessing; the speedup is most substantial when the data are evenly\ndistributed across sites. Experiments on synthetic and large UC Irvine datasets\nshow almost no loss in accuracy with our approach while about 2x speedup under\nvarious settings with two distributed sites. As the transmitted data need not\nbe in their original form, our framework readily addresses the privacy concern\nfor data sharing in distributed computing.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 04:02:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yan", "Donghui", ""], ["Wang", "Yingjie", ""], ["Wang", "Jin", ""], ["Wu", "Guodong", ""], ["Wang", "Honggang", ""]]}, {"id": "1905.01620", "submitter": "Gaoyang Li", "authors": "Gaoyang Li, Jinyu Yang, Chunguo Wu, and Qin Ma", "title": "Maximal Margin Distribution Support Vector Regression with coupled\n  Constraints-based Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector regression (SVR) is one of the most popular machine learning\nalgorithms aiming to generate the optimal regression curve through maximizing\nthe minimal margin of selected training samples, i.e., support vectors. Recent\nresearchers reveal that maximizing the margin distribution of whole training\ndataset rather than the minimal margin of a few support vectors, is prone to\nachieve better generalization performance. However, the margin distribution\nsupport vector regression machines suffer difficulties resulted from solving a\nnon-convex quadratic optimization, compared to the margin distribution strategy\nfor support vector classification, This paper firstly proposes a maximal margin\ndistribution model for SVR(MMD-SVR), then implementing coupled constrain factor\nto convert the non-convex quadratic optimization to a convex problem with\nlinear constrains, which enhance the training feasibility and efficiency for\nSVR to derived from maximizing the margin distribution. The theoretical and\nempirical analysis illustrates the superiority of MMD-SVR. In addition,\nnumerical experiments show that MMD-SVR could significantly improve the\naccuracy of prediction and generate more smooth regression curve with better\ngeneralization compared with the classic SVR.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 06:54:32 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Li", "Gaoyang", ""], ["Yang", "Jinyu", ""], ["Wu", "Chunguo", ""], ["Ma", "Qin", ""]]}, {"id": "1905.01627", "submitter": "Burak Uzkent", "authors": "Evan Sheehan, Chenlin Meng, Matthew Tan, Burak Uzkent, Neal Jean,\n  David Lobell, Marshall Burke, Stefano Ermon", "title": "Predicting Economic Development using Geolocated Wikipedia Articles", "comments": "Accepted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress on the UN Sustainable Development Goals (SDGs) is hampered by a\npersistent lack of data regarding key social, environmental, and economic\nindicators, particularly in developing countries. For example, data on poverty\n--- the first of seventeen SDGs --- is both spatially sparse and infrequently\ncollected in Sub-Saharan Africa due to the high cost of surveys. Here we\npropose a novel method for estimating socioeconomic indicators using\nopen-source, geolocated textual information from Wikipedia articles. We\ndemonstrate that modern NLP techniques can be used to predict community-level\nasset wealth and education outcomes using nearby geolocated Wikipedia articles.\nWhen paired with nightlights satellite imagery, our method outperforms all\npreviously published benchmarks for this prediction task, indicating the\npotential of Wikipedia to inform both research in the social sciences and\nfuture policy decisions.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 07:38:10 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 08:09:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Sheehan", "Evan", ""], ["Meng", "Chenlin", ""], ["Tan", "Matthew", ""], ["Uzkent", "Burak", ""], ["Jean", "Neal", ""], ["Lobell", "David", ""], ["Burke", "Marshall", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.01631", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Masayoshi Tomizuka", "title": "Conditional Generative Neural System for Probabilistic Trajectory\n  Prediction", "comments": "Camera ready for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective understanding of the environment and accurate trajectory prediction\nof surrounding dynamic obstacles are critical for intelligent systems such as\nautonomous vehicles and wheeled mobile robotics navigating in complex scenarios\nto achieve safe and high-quality decision making, motion planning and control.\nDue to the uncertain nature of the future, it is desired to make inference from\na probability perspective instead of deterministic prediction. In this paper,\nwe propose a conditional generative neural system (CGNS) for probabilistic\ntrajectory prediction to approximate the data distribution, with which\nrealistic, feasible and diverse future trajectory hypotheses can be sampled.\nThe system combines the strengths of conditional latent space learning and\nvariational divergence minimization, and leverages both static context and\ninteraction information with soft attention mechanisms. We also propose a\nregularization method for incorporating soft constraints into deep neural\nnetworks with differentiable barrier functions, which can regulate and push the\ngenerated samples into the feasible regions. The proposed system is evaluated\non several public benchmark datasets for pedestrian trajectory prediction and a\nroundabout naturalistic driving dataset collected by ourselves. The\nexperimental results demonstrate that our model achieves better performance\nthan various baseline approaches in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 08:19:50 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 08:26:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.01640", "submitter": "Ismail Balaban", "authors": "\\.Ismail Balaban, Fatih Acun, Onur Yi\\u{g}it Arpal{\\i}, Furkan Murat,\n  Numan Ertu\\u{g}rul Babaro\\u{g}lu, Emre Akci, Mehmet \\c{C}ulcu, M\\\"umtaz\n  \\\"Ozkan, Selim Temizer", "title": "Development of a Forecasting and Warning System on the Ecological\n  Life-Cycle of Sunn Pest", "comments": "Paper published on 'International Conference & Exhibition on Digital\n  Transformation & Smart Systems', Ankara (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.PE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We provide a machine learning solution that replaces the traditional methods\nfor deciding the pesticide application time of Sunn Pest. We correlate climate\ndata with phases of Sunn Pest in its life-cycle and decide whether the fields\nshould be sprayed. Our solution includes two groups of prediction models. The\nfirst group contains decision trees that predict migration time of Sunn Pest\nfrom winter quarters to wheat fields. The second group contains random forest\nmodels that predict the nymphal stage percentages of Sunn Pest which is a\ncriterion for pesticide application. We trained our models on four years of\nclimate data which was collected from Kir\\c{s}ehir and Aksaray. The experiments\nshow that our promised solution make correct predictions with high accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 09:47:01 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Balaban", "\u0130smail", ""], ["Acun", "Fatih", ""], ["Arpal\u0131", "Onur Yi\u011fit", ""], ["Murat", "Furkan", ""], ["Babaro\u011flu", "Numan Ertu\u011frul", ""], ["Akci", "Emre", ""], ["\u00c7ulcu", "Mehmet", ""], ["\u00d6zkan", "M\u00fcmtaz", ""], ["Temizer", "Selim", ""]]}, {"id": "1905.01652", "submitter": "Sim\\'on Algorta", "authors": "Sim\\'on Algorta and \\\"Ozg\\\"ur \\c{S}im\\c{s}ek", "title": "The Game of Tetris in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Tetris is an important benchmark for research in artificial\nintelligence and machine learning. This paper provides a historical account of\nthe algorithmic developments in Tetris and discusses open challenges.\nHandcrafted controllers, genetic algorithms, and reinforcement learning have\nall contributed to good solutions. However, existing solutions fall far short\nof what can be achieved by expert players playing without time pressure.\nFurther study of the game has the potential to contribute to important areas of\nresearch, including feature discovery, autonomous learning of action\nhierarchies, and sample-efficient reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:10:46 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 06:12:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Algorta", "Sim\u00f3n", ""], ["\u015eim\u015fek", "\u00d6zg\u00fcr", ""]]}, {"id": "1905.01656", "submitter": "Umair Mohammad", "authors": "Umair Mohammad and Sameh Sorour", "title": "Adaptive Task Allocation for Asynchronous Federated and Parallelized\n  Mobile Edge Learning", "comments": "7 pages, 3 figures, submitted to IEEE TVT as a correspondence paper\n  (conference paper), 3 Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a scheme to efficiently execute distributed learning\ntasks in an asynchronous manner while minimizing the gradient staleness on\nwireless edge nodes with heterogeneous computing and communication capacities.\nThe approach considered in this paper ensures that all devices work for a\ncertain duration that covers the time for data/model distribution, learning\niterations, model collection and global aggregation. The resulting problem is\nan integer non-convex program with quadratic equality constraints as well as\nlinear equality and inequality constraints. Because the problem is NP-hard, we\nrelax the integer constraints in order to solve it efficiently with available\nsolvers. Analytical bounds are derived using the KKT conditions and Lagrangian\nanalysis in conjunction with the suggest-and-improve approach. Results show\nthat our approach reduces the gradient staleness and can offer better accuracy\nthan the synchronous scheme and the asynchronous scheme with equal task\nallocation.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:22:14 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:42:24 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 01:37:24 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mohammad", "Umair", ""], ["Sorour", "Sameh", ""]]}, {"id": "1905.01669", "submitter": "Yukuo Cen", "authors": "Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou and Jie\n  Tang", "title": "Representation Learning for Attributed Multiplex Heterogeneous Network", "comments": "Accepted to KDD 2019. Website: https://sites.google.com/view/gatne", "journal-ref": null, "doi": "10.1145/3292500.3330964", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding (or graph embedding) has been widely used in many\nreal-world applications. However, existing methods mainly focus on networks\nwith single-typed nodes/edges and cannot scale well to handle large networks.\nMany real-world networks consist of billions of nodes and edges of multiple\ntypes, and each node is associated with different attributes. In this paper, we\nformalize the problem of embedding learning for the Attributed Multiplex\nHeterogeneous Network and propose a unified framework to address this problem.\nThe framework supports both transductive and inductive learning. We also give\nthe theoretical analysis of the proposed framework, showing its connection with\nprevious works and proving its better expressiveness. We conduct systematical\nevaluations for the proposed framework on four different genres of challenging\ndatasets: Amazon, YouTube, Twitter, and Alibaba. Experimental results\ndemonstrate that with the learned embeddings from the proposed framework, we\ncan achieve statistically significant improvements (e.g., 5.99-28.23% lift by\nF1 scores; p<<0.01, t-test) over previous state-of-the-art methods for link\nprediction. The framework has also been successfully deployed on the\nrecommendation system of a worldwide leading e-commerce company, Alibaba Group.\nResults of the offline A/B tests on product recommendation further confirm the\neffectiveness and efficiency of the framework in practice.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 12:18:58 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 07:13:45 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cen", "Yukuo", ""], ["Zou", "Xu", ""], ["Zhang", "Jianwei", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Tang", "Jie", ""]]}, {"id": "1905.01681", "submitter": "Jianlong Chang", "authors": "Jianlong Chang, Yiwen Guo, Lingfeng Wang, Gaofeng Meng, Shiming Xiang,\n  Chunhong Pan", "title": "Deep Discriminative Clustering Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional clustering methods often perform clustering with low-level\nindiscriminative representations and ignore relationships between patterns,\nresulting in slight achievements in the era of deep learning. To handle this\nproblem, we develop Deep Discriminative Clustering (DDC) that models the\nclustering task by investigating relationships between patterns with a deep\nneural network. Technically, a global constraint is introduced to adaptively\nestimate the relationships, and a local constraint is developed to endow the\nnetwork with the capability of learning high-level discriminative\nrepresentations. By iteratively training the network and estimating the\nrelationships in a mini-batch manner, DDC theoretically converges and the\ntrained network enables to generate a group of discriminative representations\nthat can be treated as clustering centers for straightway clustering. Extensive\nexperiments strongly demonstrate that DDC outperforms current methods on eight\nimage, text and audio datasets concurrently.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 13:22:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Chang", "Jianlong", ""], ["Guo", "Yiwen", ""], ["Wang", "Lingfeng", ""], ["Meng", "Gaofeng", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1905.01686", "submitter": "Michael Shekasta", "authors": "Michael Shekasta, Gilad Katz, Asnat Greenstein-Messica, Lior Rokach,\n  Bracha Shapira", "title": "New Item Consumption Prediction Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems have become ubiquitous in today's online world and are\nan integral part of practically every e-commerce platform. While traditional\nrecommender systems use customer history, this approach is not feasible in\n'cold start' scenarios. Such scenarios include the need to produce\nrecommendations for new or unregistered users and the introduction of new\nitems. In this study, we present the Purchase Intent Session-bAsed (PISA)\nalgorithm, a content-based algorithm for predicting the purchase intent for\ncold start session-based scenarios. Our approach employs deep learning\ntechniques both for modeling the content and purchase intent prediction. Our\nexperiments show that PISA outperforms a well-known deep learning baseline when\nnew items are introduced. In addition, while content-based approaches often\nfail to perform well in highly imbalanced datasets, our approach successfully\nhandles such cases. Finally, our experiments show that combining PISA with the\nbaseline in non-cold start scenarios further improves performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 14:01:16 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 11:48:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Shekasta", "Michael", ""], ["Katz", "Gilad", ""], ["Greenstein-Messica", "Asnat", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1905.01697", "submitter": "Omolbanin Yazdanbakhsh", "authors": "Omolbanin Yazdanbakhsh and Scott Dick", "title": "Multivariate Time Series Classification using Dilated Convolutional\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series classification is a high value and well-known\nproblem in machine learning community. Feature extraction is a main step in\nclassification tasks. Traditional approaches employ hand-crafted features for\nclassification while convolutional neural networks (CNN) are able to extract\nfeatures automatically. In this paper, we use dilated convolutional neural\nnetwork for multivariate time series classification. To deploy dilated CNN, a\nmultivariate time series is transformed into an image-like style and stacks of\ndilated and strided convolutions are applied to extract in and between features\nof variates in time series simultaneously. We evaluate our model on two human\nactivity recognition time series, finding that the automatic features extracted\nfor the time series can be as effective as hand-crafted features.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 14:59:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yazdanbakhsh", "Omolbanin", ""], ["Dick", "Scott", ""]]}, {"id": "1905.01707", "submitter": "Philippe Casgrain", "authors": "Philippe Casgrain", "title": "A Latent Variational Framework for Stochastic Optimization", "comments": "8 pages main content, 8 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper provides a unifying theoretical framework for stochastic\noptimization algorithms by means of a latent stochastic variational problem.\nUsing techniques from stochastic control, the solution to the variational\nproblem is shown to be equivalent to that of a Forward Backward Stochastic\nDifferential Equation (FBSDE). By solving these equations, we recover a variety\nof existing adaptive stochastic gradient descent methods. This framework\nestablishes a direct connection between stochastic optimization algorithms and\na secondary Bayesian inference problem on gradients, where a prior measure on\nnoisy gradient observations determines the resulting algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 15:59:51 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 12:22:56 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 02:33:12 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 03:18:02 GMT"}, {"version": "v5", "created": "Sun, 27 Oct 2019 15:36:55 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Casgrain", "Philippe", ""]]}, {"id": "1905.01713", "submitter": "Hao Wu", "authors": "Hao Wu and Raj Rao Nadakuditi", "title": "Free Component Analysis: Theory, Algorithms & Applications", "comments": "68 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for unmixing mixtures of freely independent random\nvariables in a manner analogous to the independent component analysis (ICA)\nbased method for unmixing independent random variables from their additive\nmixtures. Random matrices play the role of free random variables in this\ncontext so the method we develop, which we call Free component analysis (FCA),\nunmixes matrices from additive mixtures of matrices. Thus, while the mixing\nmodel is standard, the novelty and difference in unmixing performance comes\nfrom the introduction of a new statistical criteria, derived from free\nprobability theory, that quantify freeness analogous to how kurtosis and\nentropy quantify independence. We describe the theory, the various algorithms,\nand compare FCA to vanilla ICA which does not account for spatial or temporal\nstructure. We highlight why the statistical criteria make FCA also vanilla\ndespite its matricial underpinnings and show that FCA performs comparably to,\nand often better than, (vanilla) ICA in every application, such as image and\nspeech unmixing, where ICA has been known to succeed. Our computational\nexperiments suggest that not-so-random matrices, such as images and\nspectrograms of waveforms are (closer to being) freer \"in the wild\" than we\nmight have theoretically expected.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:20:21 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 02:27:41 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wu", "Hao", ""], ["Nadakuditi", "Raj Rao", ""]]}, {"id": "1905.01718", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Curious Meta-Controller: Adaptive Alternation between Model-Based and\n  Model-Free Control in Deep Reinforcement Learning", "comments": "Accepted at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in deep reinforcement learning for continuous control has been\ndominated by model-free approaches which, unlike model-based approaches, do not\nsuffer from representational limitations in making assumptions about the world\ndynamics and model errors inevitable in complex domains. However, they require\na lot of experiences compared to model-based approaches that are typically more\nsample-efficient. We propose to combine the benefits of the two approaches by\npresenting an integrated approach called Curious Meta-Controller. Our approach\nalternates adaptively between model-based and model-free control using a\ncuriosity feedback based on the learning progress of a neural model of the\ndynamics in a learned latent space. We demonstrate that our approach can\nsignificantly improve the sample efficiency and achieve near-optimal\nperformance on learning robotic reaching and grasping tasks from raw-pixel\ninput in both dense and sparse reward settings.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 17:18:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1905.01722", "submitter": "Takashi Isobe", "authors": "Takashi Isobe, Jian Han, Fang Zhu, Yali Li, Shengjin Wang", "title": "Intra-clip Aggregation for Video Person Re-identification", "comments": "Due to the privacy issue of person re-ID, we require to withdraw the\n  previous version of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video-based person re-identification has drawn massive attention in recent\nyears due to its extensive applications in video surveillance. While deep\nlearning-based methods have led to significant progress, these methods are\nlimited by ineffectively using complementary information, which is blamed on\nnecessary data augmentation in the training process. Data augmentation has been\nwidely used to mitigate the over-fitting trap and improve the ability of\nnetwork representation. However, the previous methods adopt image-based data\naugmentation scheme to individually process the input frames, which corrupts\nthe complementary information between consecutive frames and causes performance\ndegradation. Extensive experiments on three benchmark datasets demonstrate that\nour framework outperforms the most recent state-of-the-art methods. We also\nperform cross-dataset validation to prove the generality of our method.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 17:37:33 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 05:08:46 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 02:52:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Isobe", "Takashi", ""], ["Han", "Jian", ""], ["Zhu", "Fang", ""], ["Li", "Yali", ""], ["Wang", "Shengjin", ""]]}, {"id": "1905.01726", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Arjun Nitin Bhagoji, Liwei Song, Chawin Sitawarin,\n  Daniel Cullina, Mung Chiang, Prateek Mittal", "title": "Better the Devil you Know: An Analysis of Evasion Attacks using\n  Out-of-Distribution Adversarial Examples", "comments": "18 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of recent work has investigated the phenomenon of evasion\nattacks using adversarial examples for deep learning systems, where the\naddition of norm-bounded perturbations to the test inputs leads to incorrect\noutput classification. Previous work has investigated this phenomenon in\nclosed-world systems where training and test inputs follow a pre-specified\ndistribution. However, real-world implementations of deep learning\napplications, such as autonomous driving and content classification are likely\nto operate in the open-world environment. In this paper, we demonstrate the\nsuccess of open-world evasion attacks, where adversarial examples are generated\nfrom out-of-distribution inputs (OOD adversarial examples). In our study, we\nuse 11 state-of-the-art neural network models trained on 3 image datasets of\nvarying complexity. We first demonstrate that state-of-the-art detectors for\nout-of-distribution data are not robust against OOD adversarial examples. We\nthen consider 5 known defenses for adversarial examples, including\nstate-of-the-art robust training methods, and show that against these defenses,\nOOD adversarial examples can achieve up to 4$\\times$ higher target success\nrates compared to adversarial examples generated from in-distribution data. We\nalso take a quantitative look at how open-world evasion attacks may affect\nreal-world systems. Finally, we present the first steps towards a robust\nopen-world machine learning system.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 18:06:41 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Sehwag", "Vikash", ""], ["Bhagoji", "Arjun Nitin", ""], ["Song", "Liwei", ""], ["Sitawarin", "Chawin", ""], ["Cullina", "Daniel", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""]]}, {"id": "1905.01745", "submitter": "Oren Mangoubi", "authors": "Oren Mangoubi and Nisheeth K. Vishnoi", "title": "Faster polytope rounding, sampling, and volume computation via a\n  sublinear \"Ball Walk\"", "comments": "Accepted to IEEE Symposium on Foundations of Computer Science (FOCS)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of \"isotropically rounding\" a polytope\n$K\\subset\\mathbb{R}^n$, that is, computing a linear transformation which makes\nthe uniform distribution on the polytope have roughly identity covariance\nmatrix. We assume $K$ is defined by $m$ linear inequalities, with guarantee\nthat $rB\\subset K\\subset RB$, where $B$ is the unit ball. We introduce a new\nvariant of the ball walk Markov chain and show that, roughly, the expected\nnumber of arithmetic operations per-step of this Markov chain is $O(m)$ that is\nsublinear in the input size $mn$--the per-step time of all prior Markov chains.\nSubsequently, we give a rounding algorithm that succeeds with probability\n$1-\\varepsilon$ in\n$\\tilde{O}(mn^{4.5}\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r}))$\narithmetic operations. This gives a factor of $\\sqrt{n}$ improvement on the\nprevious bound of\n$\\tilde{O}(mn^5\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r}))$ for\nrounding, which uses the hit-and-run algorithm. Since the rounding\npreprocessing step is in many cases the bottleneck in improving sampling or\nvolume computation, our results imply these tasks can also be achieved in\nroughly\n$\\tilde{O}(mn^{4.5}\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r})+mn^4\\delta^{-2})$\noperations for computing the volume of $K$ up to a factor $1+\\delta$ and\n$\\tilde{O}(mn^{4.5}\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r})))$ for\nuniformly sampling on $K$ with TV error $\\varepsilon$. This improves on the\nprevious bounds of\n$\\tilde{O}(mn^5\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r})+mn^4\\delta^{-2})$\nfor volume computation when roughly $m\\geq n^{2.5}$, and\n$\\tilde{O}(mn^5\\mbox{polylog}(\\frac{1}{\\varepsilon},\\frac{R}{r}))$ for sampling\nwhen roughly $m\\geq n^{1.5}$. We achieve this improvement by a novel method of\ncomputing polytope membership, where one avoids checking inequalities estimated\nto have a very low probability of being violated.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 20:52:25 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 02:09:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mangoubi", "Oren", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1905.01756", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Pratik Chaudhari, Alexander J. Smola", "title": "P3O: Policy-on Policy-off Policy Optimization", "comments": "UAI 2019 conference paper. Code: https://github.com/rasoolfa/P3O", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-policy reinforcement learning (RL) algorithms have high sample complexity\nwhile off-policy algorithms are difficult to tune. Merging the two holds the\npromise to develop efficient algorithms that generalize across diverse\nenvironments. It is however challenging in practice to find suitable\nhyper-parameters that govern this trade off. This paper develops a simple\nalgorithm named P3O that interleaves off-policy updates with on-policy updates.\nP3O uses the effective sample size between the behavior policy and the target\npolicy to control how far they can be from each other and does not introduce\nany additional hyper-parameters. Extensive experiments on the Atari-2600 and\nMuJoCo benchmark suites show that this simple technique is effective in\nreducing the sample complexity of state-of-the-art algorithms. Code to\nreproduce experiments in this paper is at https://github.com/rasoolfa/P3O.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 21:51:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 20:10:04 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Fakoor", "Rasool", ""], ["Chaudhari", "Pratik", ""], ["Smola", "Alexander J.", ""]]}, {"id": "1905.01772", "submitter": "Amol Kapoor", "authors": "Amol Kapoor, Hunter Larco, Raimondas Kiveris", "title": "Nostalgin: Extracting 3D City Models from Historical Image Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What did it feel like to walk through a city from the past? In this work, we\ndescribe Nostalgin (Nostalgia Engine), a method that can faithfully reconstruct\ncities from historical images. Unlike existing work in city reconstruction, we\nfocus on the task of reconstructing 3D cities from historical images. Working\nwith historical image data is substantially more difficult, as there are\nsignificantly fewer buildings available and the details of the camera\nparameters which captured the images are unknown. Nostalgin can generate a city\nmodel even if there is only a single image per facade, regardless of viewpoint\nor occlusions. To achieve this, our novel architecture combines image\nsegmentation, rectification, and inpainting. We motivate our design decisions\nwith experimental analysis of individual components of our pipeline, and show\nthat we can improve on baselines in both speed and visual realism. We\ndemonstrate the efficacy of our pipeline by recreating two 1940s Manhattan city\nblocks. We aim to deploy Nostalgin as an open source platform where users can\ngenerate immersive historical experiences from their own photos.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 00:18:15 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kapoor", "Amol", ""], ["Larco", "Hunter", ""], ["Kiveris", "Raimondas", ""]]}, {"id": "1905.01776", "submitter": "Vince Lyzinski", "authors": "Joshua Agterberg, Youngser Park, Jonathan Larson, Christopher White,\n  Carey E. Priebe, and Vince Lyzinski", "title": "Vertex Nomination, Consistent Estimation, and Adversarial Modification", "comments": "34 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a pair of graphs $G_1$ and $G_2$ and a vertex set of interest in $G_1$,\nthe vertex nomination (VN) problem seeks to find the corresponding vertices of\ninterest in $G_2$ (if they exist) and produce a rank list of the vertices in\n$G_2$, with the corresponding vertices of interest in $G_2$ concentrating,\nideally, at the top of the rank list. In this paper, we define and derive the\nanalogue of Bayes optimality for VN with multiple vertices of interest, and we\ndefine the notion of maximal consistency classes in vertex nomination. This\ntheory forms the foundation for a novel VN adversarial contamination model, and\nwe demonstrate with real and simulated data that there are VN schemes that\nperform effectively in the uncontaminated setting, and adversarial network\ncontamination adversely impacts the performance of our VN scheme. We further\ndefine a network regularization method for mitigating the impact of the\nadversarial contamination, and we demonstrate the effectiveness of\nregularization in both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 00:55:29 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 03:00:39 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 16:41:46 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Agterberg", "Joshua", ""], ["Park", "Youngser", ""], ["Larson", "Jonathan", ""], ["White", "Christopher", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "1905.01780", "submitter": "Bo Liu", "authors": "Bo Liu", "title": "Anonymized BERT: An Augmentation Approach to the Gendered Pronoun\n  Resolution Challenge", "comments": "6 pages; accepted by 1st ACL Workshop on Gender Bias for NLP at ACL\n  2019; code is at https://github.com/boliu61/gendered-pronoun-resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our 7th place solution to the Gendered Pronoun Resolution\nchallenge, which uses BERT without fine-tuning and a novel augmentation\nstrategy designed for contextual embedding token-level tasks. Our method\nanonymizes the referent by replacing candidate names with a set of common\nplaceholder names. Besides the usual benefits of effectively increasing\ntraining data size, this approach diversifies idiosyncratic information\nembedded in names. Using same set of common first names can also help the model\nrecognize names better, shorten token length, and remove gender and regional\nbiases associated with names. The system scored 0.1947 log loss in stage 2,\nwhere the augmentation contributed to an improvements of 0.04. Post-competition\nanalysis shows that, when using different embedding layers, the system scores\n0.1799 which would be third place.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 01:16:33 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:46:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Bo", ""]]}, {"id": "1905.01786", "submitter": "Jianlong Chang", "authors": "Jianlong Chang, Xinbang Zhang, Yiwen Guo, Gaofeng Meng, Shiming Xiang,\n  Chunhong Pan", "title": "Differentiable Architecture Search with Ensemble Gumbel-Softmax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For network architecture search (NAS), it is crucial but challenging to\nsimultaneously guarantee both effectiveness and efficiency. Towards achieving\nthis goal, we develop a differentiable NAS solution, where the search space\nincludes arbitrary feed-forward network consisting of the predefined number of\nconnections. Benefiting from a proposed ensemble Gumbel-Softmax estimator, our\nmethod optimizes both the architecture of a deep network and its parameters in\nthe same round of backward propagation, yielding an end-to-end mechanism of\nsearching network architectures. Extensive experiments on a variety of popular\ndatasets strongly evidence that our method is capable of discovering\nhigh-performance architectures, while guaranteeing the requisite efficiency\nduring searching.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 01:47:17 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Chang", "Jianlong", ""], ["Zhang", "Xinbang", ""], ["Guo", "Yiwen", ""], ["Meng", "Gaofeng", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1905.01788", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Takuto Sakuma, Taiju Ishiyama, Hiroki Toda, Kazuya\n  Nishi, Masayuki Karasuyama, Yuta Okubo, Masayuki Sunaga, Yasuo Tabei, Ichiro\n  Takeuchi", "title": "Statistically Discriminative Sub-trajectory Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of discriminative sub-trajectory mining. Given two\ngroups of trajectories, the goal of this problem is to extract moving patterns\nin the form of sub-trajectories which are more similar to sub-trajectories of\none group and less similar to those of the other. We propose a new method\ncalled Statistically Discriminative Sub-trajectory Mining (SDSM) for this\nproblem. An advantage of the SDSM method is that the statistical significance\nof the extracted sub-trajectories are properly controlled in the sense that the\nprobability of finding a false positive sub-trajectory is smaller than a\nspecified significance threshold alpha (e.g., 0.05), which is indispensable\nwhen the method is used in scientific or social studies under noisy\nenvironment. Finding such statistically discriminative sub-trajectories from\nmassive trajectory dataset is both computationally and statistically\nchallenging. In the SDSM method, we resolve the difficulties by introducing a\ntree representation among sub-trajectories and running an efficient\npermutation-based statistical inference method on the tree. To the best of our\nknowledge, SDSM is the first method that can efficiently extract statistically\ndiscriminative sub-trajectories from massive trajectory dataset. We illustrate\nthe effectiveness and scalability of the SDSM method by applying it to a\nreal-world dataset with 1,000,000 trajectories which contains 16,723,602,505\nsub-trajectories.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 02:05:07 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Sakuma", "Takuto", ""], ["Ishiyama", "Taiju", ""], ["Toda", "Hiroki", ""], ["Nishi", "Kazuya", ""], ["Karasuyama", "Masayuki", ""], ["Okubo", "Yuta", ""], ["Sunaga", "Masayuki", ""], ["Tabei", "Yasuo", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1905.01858", "submitter": "Jiliang Zhang", "authors": "Jiliang Zhang, Wuqiao Chen, Yuqi Niu", "title": "DeepCheck: A Non-intrusive Control-flow Integrity Checking based on Deep\n  Learning", "comments": "Submitted to S&P 2020, 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code reuse attack (CRA) is a powerful attack that reuses existing codes to\nhijack the program control flow. Control flow integrity (CFI) is one of the\nmost popular mechanisms to prevent against CRAs. However, current CFI\ntechniques are difficult to be deployed in real applications due to suffering\nseveral issues such as modifying binaries or compiler, extending instruction\nset architectures (ISA) and incurring unacceptable runtime overhead. To address\nthese issues, we propose the first deep learning-based CFI technique, named\nDeepCheck, where the control flow graph (CFG) is split into chains for deep\nneural network (DNN) training. Then the integrity features of CFG can be\nlearned by DNN to detect abnormal control flows. DeepCheck does not interrupt\nthe application and hence incurs zero runtime overhead. Experimental results on\nAdobe Flash Player, Nginx, Proftpd and Firefox show that the average detection\naccuracy of DeepCheck is as high as 98.9%. In addition, 64 ROP exploits created\nby ROPGadget and Ropper are used to further test the effectiveness, which shows\nthat the detection success rate reaches 100%.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 07:45:40 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zhang", "Jiliang", ""], ["Chen", "Wuqiao", ""], ["Niu", "Yuqi", ""]]}, {"id": "1905.01898", "submitter": "Szu-Wei Fu", "authors": "Szu-Wei Fu, Chien-Feng Liao, Yu Tsao", "title": "Learning with Learned Loss Function: Speech Enhancement with Quality-Net\n  to Improve Perceptual Evaluation of Speech Quality", "comments": "Accepted by IEEE Signal Processing Letters (SPL)", "journal-ref": null, "doi": "10.1109/LSP.2019.2953810", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing a human-perception-related objective function to train a speech\nenhancement model has become a popular topic recently. The main reason is that\nthe conventional mean squared error (MSE) loss cannot represent auditory\nperception well. One of the typical hu-man-perception-related metrics, which is\nthe perceptual evaluation of speech quality (PESQ), has been proven to provide\na high correlation to the quality scores rated by humans. Owing to its complex\nand non-differentiable properties, however, the PESQ function may not be used\nto optimize speech enhancement models directly. In this study, we propose\noptimizing the enhancement model with an approximated PESQ function, which is\ndifferentiable and learned from the training data. The experimental results\nshow that the learned surrogate function can guide the enhancement model to\nfurther boost the PESQ score (in-crease of 0.18 points compared to the results\ntrained with MSE loss) and maintain the speech intelligibility.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 09:46:37 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 05:49:36 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 06:20:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Fu", "Szu-Wei", ""], ["Liao", "Chien-Feng", ""], ["Tsao", "Yu", ""]]}, {"id": "1905.01907", "submitter": "Simone Scardapane", "authors": "Indro Spinelli, Simone Scardapane, Aurelio Uncini", "title": "Missing Data Imputation with Adversarially-trained Graph Convolutional\n  Networks", "comments": "Published in Neural Networks (2020)", "journal-ref": "Neural Networks, 129, pp. 249-260, 2020", "doi": "10.1016/j.neunet.2020.06.005", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data imputation (MDI) is a fundamental problem in many scientific\ndisciplines. Popular methods for MDI use global statistics computed from the\nentire data set (e.g., the feature-wise medians), or build predictive models\noperating independently on every instance. In this paper we propose a more\ngeneral framework for MDI, leveraging recent work in the field of graph neural\nnetworks (GNNs). We formulate the MDI task in terms of a graph denoising\nautoencoder, where each edge of the graph encodes the similarity between two\npatterns. A GNN encoder learns to build intermediate representations for each\nexample by interleaving classical projection layers and locally combining\ninformation between neighbors, while another decoding GNN learns to reconstruct\nthe full imputed data set from this intermediate embedding. In order to\nspeed-up training and improve the performance, we use a combination of multiple\nlosses, including an adversarial loss implemented with the Wasserstein metric\nand a gradient penalty. We also explore a few extensions to the basic\narchitecture involving the use of residual connections between layers, and of\nglobal statistics computed from the data set to improve the accuracy. On a\nlarge experimental evaluation, we show that our method robustly outperforms\nstate-of-the-art approaches for MDI, especially for large percentages of\nmissing values.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 10:04:02 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 08:40:58 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Spinelli", "Indro", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1905.01924", "submitter": "Lukas Hahn", "authors": "Lukas Hahn, Lutz Roese-Koerner, Klaus Friedrichs, Anton Kummert", "title": "Fast and Reliable Architecture Selection for Convolutional Neural\n  Networks", "comments": "As published in the proceedings of the 27th European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  (ESANN), pages 179-184, Bruges 2019. 6 pages, 2 figures, 1 table", "journal-ref": "Proceedings of the 27th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN), pages\n  179-184, Bruges 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a Convolutional Neural Network (CNN) depends on its\nhyperparameters, like the number of layers, kernel sizes, or the learning rate\nfor example. Especially in smaller networks and applications with limited\ncomputational resources, optimisation is key. We present a fast and efficient\napproach for CNN architecture selection. Taking into account time consumption,\nprecision and robustness, we develop a heuristic to quickly and reliably assess\na network's performance. In combination with Bayesian optimisation (BO), to\neffectively cover the vast parameter space, our contribution offers a plain and\npowerful architecture search for this machine learning technique.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 10:58:23 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Hahn", "Lukas", ""], ["Roese-Koerner", "Lutz", ""], ["Friedrichs", "Klaus", ""], ["Kummert", "Anton", ""]]}, {"id": "1905.01926", "submitter": "Huang Xie", "authors": "Huang Xie, Tuomas Virtanen", "title": "Zero-Shot Audio Classification Based on Class Label Embeddings", "comments": "2019 IEEE Workshop on Applications of Signal Processing to Audio and\n  Acoustics (WASPAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a zero-shot learning approach for audio classification\nbased on the textual information about class labels without any audio samples\nfrom target classes. We propose an audio classification system built on the\nbilinear model, which takes audio feature embeddings and semantic class label\nembeddings as input, and measures the compatibility between an audio feature\nembedding and a class label embedding. We use VGGish to extract audio feature\nembeddings from audio recordings. We treat textual labels as semantic side\ninformation of audio classes, and use Word2Vec to generate class label\nembeddings. Results on the ESC-50 dataset show that the proposed system can\nperform zero-shot audio classification with small training dataset. It can\nachieve accuracy (26 % on average) better than random guess (10 %) on each\naudio category. Particularly, it reaches up to 39.7 % for the category of\nnatural audio classes.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 11:08:08 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 13:12:55 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Xie", "Huang", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1905.01947", "submitter": "Fayyaz Minhas", "authors": "Amina Asif and Fayyaz ul Amir Afsar Minhas", "title": "An embarrassingly simple approach to neural multiple instance\n  classification", "comments": "7 pages", "journal-ref": "Pattern Recognition Letters, vol. 128, pp. 474-479, Dec. 1, 2019", "doi": "10.1016/j.patrec.2019.10.022", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Instance Learning (MIL) is a weak supervision learning paradigm that\nallows modeling of machine learning problems in which labels are available only\nfor groups of examples called bags. A positive bag may contain one or more\npositive examples but it is not known which examples in the bag are positive.\nAll examples in a negative bag belong to the negative class. Such problems\narise frequently in fields of computer vision, medical image processing and\nbioinformatics. Many neural network based solutions have been proposed in the\nliterature for MIL, however, almost all of them rely on introducing specialized\nblocks and connectivity in the architectures. In this paper, we present a novel\nand effective approach to Multiple Instance Learning in neural networks.\nInstead of making changes to the architectures, we propose a simple bag-level\nranking loss function that allows Multiple Instance Classification in any\nneural architecture. We have demonstrated the effectiveness of our proposed\nmethod for popular MIL benchmark datasets. In addition, we have tested the\nperformance of our method in convolutional neural networks used to model an MIL\nproblem derived from the well-known MNIST dataset. Results have shown that\ndespite being simpler, our proposed scheme is comparable or better than\nexisting methods in the literature in practical scenarios. Python code files\nfor all the experiments can be found at https://github.com/amina01/ESMIL.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:10:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Asif", "Amina", ""], ["Minhas", "Fayyaz ul Amir Afsar", ""]]}, {"id": "1905.01957", "submitter": "Titouan Parcollet", "authors": "Titouan Parcollet, Mohamed Morchid, Xavier Bost, Georges Linar\\`es", "title": "M2H-GAN: A GAN-based Mapping from Machine to Human Transcripts for\n  Speech Understanding", "comments": "Submitted at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is at the core of recent spoken language understanding (SLU)\nrelated tasks. More precisely, deep neural networks (DNNs) drastically\nincreased the performances of SLU systems, and numerous architectures have been\nproposed. In the real-life context of theme identification of telephone\nconversations, it is common to hold both a human, manual (TRS) and an\nautomatically transcribed (ASR) versions of the conversations. Nonetheless, and\ndue to production constraints, only the ASR transcripts are considered to build\nautomatic classifiers. TRS transcripts are only used to measure the\nperformances of ASR systems. Moreover, the recent performances in term of\nclassification accuracy, obtained by DNN related systems are close to the\nperformances reached by humans, and it becomes difficult to further increase\nthe performances by only considering the ASR transcripts. This paper proposes\nto distillates the TRS knowledge available during the training phase within the\nASR representation, by using a new generative adversarial network called\nM2H-GAN to generate a TRS-like version of an ASR document, to improve the theme\nidentification performances.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 20:04:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Parcollet", "Titouan", ""], ["Morchid", "Mohamed", ""], ["Bost", "Xavier", ""], ["Linar\u00e8s", "Georges", ""]]}, {"id": "1905.01958", "submitter": "Alexandre Tomberg", "authors": "Rohollah Soltani and Alexandre Tomberg", "title": "Text2Node: a Cross-Domain System for Mapping Arbitrary Phrases to a\n  Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record (EHR) systems are used extensively throughout the\nhealthcare domain. However, data interchangeability between EHR systems is\nlimited due to the use of different coding standards across systems. Existing\nmethods of mapping coding standards based on manual human experts mapping,\ndictionary mapping, symbolic NLP and classification are unscalable and cannot\naccommodate large scale EHR datasets.\n  In this work, we present Text2Node, a cross-domain mapping system capable of\nmapping medical phrases to concepts in a large taxonomy (such as SNOMED CT).\nThe system is designed to generalize from a limited set of training samples and\nmap phrases to elements of the taxonomy that are not covered by training data.\nAs a result, our system is scalable, robust to wording variants between coding\nsystems and can output highly relevant concepts when no exact concept exists in\nthe target taxonomy. Text2Node operates in three main stages: first, the\nlexicon is mapped to word embeddings; second, the taxonomy is vectorized using\nnode embeddings; and finally, the mapping function is trained to connect the\ntwo embedding spaces. We compared multiple algorithms and architectures for\neach stage of the training, including GloVe and FastText word embeddings, CNN\nand Bi-LSTM mapping functions, and node2vec for node embeddings. We confirmed\nthe robustness and generalisation properties of Text2Node by mapping ICD-9-CM\nDiagnosis phrases to SNOMED CT and by zero-shot training at comparable\naccuracy.\n  This system is a novel methodological contribution to the task of normalizing\nand linking phrases to a taxonomy, advancing data interchangeability in\nhealthcare. When applied, the system can use electronic health records to\ngenerate an embedding that incorporates taxonomical medical knowledge to\nimprove clinical predictive models.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:31:23 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soltani", "Rohollah", ""], ["Tomberg", "Alexandre", ""]]}, {"id": "1905.01959", "submitter": "Yan Liang", "authors": "Yan Liang, Xin Liu, Jianwen Zhang, Yangqiu Song", "title": "Relation Discovery with Out-of-Relation Knowledge Base as Supervision", "comments": "Aceepted by NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised relation discovery aims to discover new relations from a given\ntext corpus without annotated data. However, it does not consider existing\nhuman annotated knowledge bases even when they are relevant to the relations to\nbe discovered. In this paper, we study the problem of how to use\nout-of-relation knowledge bases to supervise the discovery of unseen relations,\nwhere out-of-relation means that relations to discover from the text corpus and\nthose in knowledge bases are not overlapped. We construct a set of constraints\nbetween entity pairs based on the knowledge base embedding and then incorporate\nconstraints into the relation discovery by a variational auto-encoder based\nalgorithm. Experiments show that our new approach can improve the\nstate-of-the-art relation discovery performance by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 02:30:59 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liang", "Yan", ""], ["Liu", "Xin", ""], ["Zhang", "Jianwen", ""], ["Song", "Yangqiu", ""]]}, {"id": "1905.01962", "submitter": "Pedro Sandoval Segura", "authors": "Mehdi Drissi, Pedro Sandoval, Vivaswat Ojha, Julie Medero", "title": "Harvey Mudd College at SemEval-2019 Task 4: The Clint Buchanan\n  Hyperpartisan News Detector", "comments": "Submitted to The 13th International Workshop on Semantic Evaluation\n  (SemEval 2019). 5 pages including references", "journal-ref": null, "doi": "10.18653/v1/S19-2165", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the recently developed Bidirectional Encoder Representations\nfrom Transformers (BERT) model for the hyperpartisan news detection task. Using\na subset of hand-labeled articles from SemEval as a validation set, we test the\nperformance of different parameters for BERT models. We find that accuracy from\ntwo different BERT models using different proportions of the articles is\nconsistently high, with our best-performing model on the validation set\nachieving 85% accuracy and the best-performing model on the test set achieving\n77%. We further determined that our model exhibits strong consistency, labeling\nindependent slices of the same article identically. Finally, we find that\nrandomizing the order of word pieces dramatically reduces validation accuracy\n(to approximately 60%), but that shuffling groups of four or more word pieces\nmaintains an accuracy of about 80%, indicating the model mainly gains value\nfrom local context.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:43:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Drissi", "Mehdi", ""], ["Sandoval", "Pedro", ""], ["Ojha", "Vivaswat", ""], ["Medero", "Julie", ""]]}, {"id": "1905.01963", "submitter": "Junxin Liu", "authors": "Junxin Liu, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Word Segmentation with Lexicon and Unlabeled Data via\n  Posterior Regularization", "comments": "7 pages, 11 figures, accepted by the 2019 World Wide Web Conference\n  (WWW '19)", "journal-ref": null, "doi": "10.1145/3308558.3313437", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for CWS usually rely on a large number of labeled sentences\nto train word segmentation models, which are expensive and time-consuming to\nannotate. Luckily, the unlabeled data is usually easy to collect and many\nhigh-quality Chinese lexicons are off-the-shelf, both of which can provide\nuseful information for CWS. In this paper, we propose a neural approach for\nChinese word segmentation which can exploit both lexicon and unlabeled data.\nOur approach is based on a variant of posterior regularization algorithm, and\nthe unlabeled data and lexicon are incorporated into model training as indirect\nsupervision by regularizing the prediction space of CWS models. Extensive\nexperiments on multiple benchmark datasets in both in-domain and cross-domain\nscenarios validate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:21:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Junxin", ""], ["Wu", "Fangzhao", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1905.01964", "submitter": "Junxin Liu", "authors": "Fangzhao Wu, Junxin Liu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Named Entity Recognition via CNN-LSTM-CRF and Joint\n  Training with Word Segmentation", "comments": "7 pages, 3 figures, accepted by the 2019 World Wide Web Conference\n  (WWW'19)", "journal-ref": null, "doi": "10.1145/3308558.3313743", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese named entity recognition (CNER) is an important task in Chinese\nnatural language processing field. However, CNER is very challenging since\nChinese entity names are highly context-dependent. In addition, Chinese texts\nlack delimiters to separate words, making it difficult to identify the boundary\nof entities. Besides, the training data for CNER in many domains is usually\ninsufficient, and annotating enough training data for CNER is very expensive\nand time-consuming. In this paper, we propose a neural approach for CNER.\nFirst, we introduce a CNN-LSTM-CRF neural architecture to capture both local\nand long-distance contexts for CNER. Second, we propose a unified framework to\njointly train CNER and word segmentation models in order to enhance the ability\nof CNER model in identifying entity boundaries. Third, we introduce an\nautomatic method to generate pseudo labeled samples from existing labeled data\nwhich can enrich the training data. Experiments on two benchmark datasets show\nthat our approach can effectively improve the performance of Chinese named\nentity recognition, especially when training data is insufficient.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:09:56 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wu", "Fangzhao", ""], ["Liu", "Junxin", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1905.01965", "submitter": "Ali Fadel", "authors": "Ali Fadel, Ibraheem Tuffaha, Bara' Al-Jawarneh and Mahmoud Al-Ayyoub", "title": "Arabic Text Diacritization Using Deep Neural Networks", "comments": "7 pages, 4 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritization of Arabic text is both an interesting and a challenging\nproblem at the same time with various applications ranging from speech\nsynthesis to helping students learning the Arabic language. Like many other\ntasks or problems in Arabic language processing, the weak efforts invested into\nthis problem and the lack of available (open-source) resources hinder the\nprogress towards solving this problem. This work provides a critical review for\nthe currently existing systems, measures and resources for Arabic text\ndiacritization. Moreover, it introduces a much-needed free-for-all cleaned\ndataset that can be easily used to benchmark any work on Arabic diacritization.\nExtracted from the Tashkeela Corpus, the dataset consists of 55K lines\ncontaining about 2.3M words. After constructing the dataset, existing tools and\nsystems are tested on it. The results of the experiments show that the neural\nShakkala system significantly outperforms traditional rule-based approaches and\nother closed-source tools with a Diacritic Error Rate (DER) of 2.88% compared\nwith 13.78%, which the best DER for the non-neural approach (obtained by the\nMishkal tool).\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:29:06 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Fadel", "Ali", ""], ["Tuffaha", "Ibraheem", ""], ["Al-Jawarneh", "Bara'", ""], ["Al-Ayyoub", "Mahmoud", ""]]}, {"id": "1905.01971", "submitter": "Yong Liu", "authors": "Yong Liu, Pavel Dmitriev, Yifei Huang, Andrew Brooks, Li Dong", "title": "An Evaluation of Transfer Learning for Classifying Sales Engagement\n  Emails at Large Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper conducts an empirical investigation to evaluate transfer learning\nfor classifying sales engagement emails arising from digital sales engagement\nplatforms. Given the complexity of content and context of sales engagement,\nlack of standardized large corpora and benchmarks, limited labeled examples and\nheterogenous context of intent, this real-world use case poses both a challenge\nand an opportunity for adopting a transfer learning approach. We propose an\nevaluation framework to assess a high performance transfer learning (HPTL)\napproach in three key areas in addition to commonly used accuracy metrics: 1)\neffective embeddings and pretrained language model usage, 2) minimum labeled\nsamples requirement and 3) transfer learning implementation strategies. We use\nin-house sales engagement email samples as the experiment dataset, which\nincludes over 3000 emails labeled as positive, objection, unsubscribe, or\nnot-sure. We discuss our findings on evaluating BERT, ELMo, Flair and GloVe\nembeddings with both feature-based and fine-tuning approaches and their\nscalability on a GPU cluster with increasingly larger labeled samples. Our\nresults show that fine-tuning of the BERT model outperforms with as few as 300\nlabeled samples, but underperforms with fewer than 300 labeled samples,\nrelative to all the feature-based approaches using different embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 18:11:54 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Yong", ""], ["Dmitriev", "Pavel", ""], ["Huang", "Yifei", ""], ["Brooks", "Andrew", ""], ["Dong", "Li", ""]]}, {"id": "1905.01972", "submitter": "Kostantinos Papadamou Mr", "authors": "Harris Partaourides, Kostantinos Papadamou, Nicolas Kourtellis, Ilias\n  Leontiadis, and Sotirios Chatzis", "title": "A Self-Attentive Emotion Recognition Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning approaches have achieved groundbreaking performance in\nmodeling and classifying sequential data. Specifically, attention networks\nconstitute the state-of-the-art paradigm for capturing long temporal dynamics.\nThis paper examines the efficacy of this paradigm in the challenging task of\nemotion recognition in dyadic conversations. In contrast to existing\napproaches, our work introduces a novel attention mechanism capable of\ninferring the immensity of the effect of each past utterance on the current\nspeaker emotional state. The proposed attention mechanism performs this\ninference procedure without the need of a decoder network; this is achieved by\nmeans of innovative self-attention arguments. Our self-attention networks\ncapture the correlation patterns among consecutive encoder network states, thus\nallowing to robustly and effectively model temporal dynamics over arbitrary\nlong temporal horizons. Thus, we enable capturing strong affective patterns\nover the course of long discussions. We exhibit the effectiveness of our\napproach considering the challenging IEMOCAP benchmark. As we show, our devised\nmethodology outperforms state-of-the-art alternatives and commonly used\napproaches, giving rise to promising new research directions in the context of\nOnline Social Network (OSN) analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:46:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Partaourides", "Harris", ""], ["Papadamou", "Kostantinos", ""], ["Kourtellis", "Nicolas", ""], ["Leontiadis", "Ilias", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1905.01973", "submitter": "Simona Maggio", "authors": "B\\'eranger Dumont, Simona Maggio, Ghiles Sidi Said, Quoc-Tien Au", "title": "Who wrote this book? A challenge for e-commerce", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern e-commerce catalogs contain millions of references, associated with\ntextual and visual information that is of paramount importance for the products\nto be found via search or browsing. Of particular significance is the book\ncategory, where the author name(s) field poses a significant challenge. Indeed,\nbooks written by a given author (such as F. Scott Fitzgerald) might be listed\nwith different authors' names in a catalog due to abbreviations and spelling\nvariants and mistakes, among others. To solve this problem at scale, we design\na composite system involving open data sources for books as well as machine\nlearning components leveraging deep learning-based techniques for natural\nlanguage processing. In particular, we use Siamese neural networks for an\napproximate match with known author names, and direct correction of the\nprovided author's name using sequence-to-sequence learning with neural\nnetworks. We evaluate this approach on product data from the e-commerce website\nRakuten France, and find that the top proposal of the system is the normalized\nauthor name with 72% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 10:13:07 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Dumont", "B\u00e9ranger", ""], ["Maggio", "Simona", ""], ["Said", "Ghiles Sidi", ""], ["Au", "Quoc-Tien", ""]]}, {"id": "1905.01982", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh, Andreas Otto", "title": "On Transfer Learning For Chatter Detection in Turning Using Wavelet\n  Packet Transform and Empirical Mode Decomposition", "comments": "Informative wavelet packet numbers were edited with respect to\n  frequency ordering in section 3. Three more supervised learning algorithms\n  were added to compare performance of both method (see section 5 and 6). For\n  transfer learning, results of the application where classifiers are trained\n  with two different stickout size data and tested on remaining cases were\n  added into section 6.3", "journal-ref": null, "doi": "10.1016/j.cirpj.2019.11.003", "report-no": null, "categories": "eess.SP cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of sensor data at machine tools makes automatic\nchatter detection algorithms a trending topic in metal cutting. Two prominent\nand advanced methods for feature extraction via signal decomposition are\nWavelet Packet Transform (WPT) and Ensemble Empirical Mode Decomposition\n(EEMD). We apply these two methods to time series acquired from an acceleration\nsensor at the tool holder of a lathe. Different turning experiments with\nvarying dynamic behavior of the machine tool structure were performed. We\ncompare the performance of these two methods with Support Vector Machine (SVM),\nLogistic Regression, Random Forest Classification and Gradient Boosting\ncombined with Recursive Feature Elimination (RFE). We also show that the common\nWPT-based approach of choosing wavelet packets with the highest energy ratios\nas representative features for chatter does not always result in packets that\nenclose the chatter frequency, thus reducing the classification accuracy.\nFurther, we test the transfer learning capability of each of these methods by\ntraining the classifier on one of the cutting configurations and then testing\nit on the other cases. It is found that when training and testing on data from\nthe same cutting configuration both methods yield high accuracies reaching in\none of the cases as high as 94% and 95%, respectively, for WPT and EEMD.\nHowever, our experimental results show that EEMD can outperform WPT in transfer\nlearning applications with accuracy of up to 95%.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:11:23 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 20:38:21 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""], ["Otto", "Andreas", ""]]}, {"id": "1905.01989", "submitter": "Sahin Geyik", "authors": "Sahin Cem Geyik, Stuart Ambler, Krishnaram Kenthapadi", "title": "Fairness-Aware Ranking in Search & Recommendation Systems with\n  Application to LinkedIn Talent Search", "comments": "This paper has been accepted for publication at ACM KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330691", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for quantifying and mitigating algorithmic bias in\nmechanisms designed for ranking individuals, typically used as part of\nweb-scale search and recommendation systems. We first propose complementary\nmeasures to quantify bias with respect to protected attributes such as gender\nand age. We then present algorithms for computing fairness-aware re-ranking of\nresults. For a given search or recommendation task, our algorithms seek to\nachieve a desired distribution of top ranked results with respect to one or\nmore protected attributes. We show that such a framework can be tailored to\nachieve fairness criteria such as equality of opportunity and demographic\nparity depending on the choice of the desired distribution. We evaluate the\nproposed algorithms via extensive simulations over different parameter choices,\nand study the effect of fairness-aware ranking on both bias and utility\nmeasures. We finally present the online A/B testing results from applying our\nframework towards representative ranking in LinkedIn Talent Search, and discuss\nthe lessons learned in practice. Our approach resulted in tremendous\nimprovement in the fairness metrics (nearly three fold increase in the number\nof search queries with representative results) without affecting the business\nmetrics, which paved the way for deployment to 100% of LinkedIn Recruiter users\nworldwide. Ours is the first large-scale deployed framework for ensuring\nfairness in the hiring domain, with the potential positive impact for more than\n630M LinkedIn members.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 21:06:49 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 22:48:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 19:22:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Geyik", "Sahin Cem", ""], ["Ambler", "Stuart", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "1905.01990", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Jang-Young Kim, Won-Yong Shin, Sang-Wook Kim", "title": "Clustering-Based Collaborative Filtering Using an Incentivized/Penalized\n  User Model", "comments": "12 pages, 4 figures, 6 tables, To appear in the IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving or recommending appropriate content based on the quality of experience\nis the most important and challenging issue in recommender systems. As\ncollaborative filtering (CF) is one of the most prominent and popular\ntechniques used for recommender systems, we propose a new clustering-based CF\n(CBCF) method using an incentivized/penalized user (IPU) model only with\nratings given by users, which is thus easy to implement. We aim to design such\na simple clustering-based approach with no further prior information while\nimproving the recommendation accuracy. To be precise, the purpose of CBCF with\nthe IPU model is to improve recommendation performance such as precision,\nrecall, and $F_1$ score by carefully exploiting different preferences among\nusers. Specifically, we formulate a constrained optimization problem, in which\nwe aim to maximize the recall (or equivalently $F_1$ score) for a given\nprecision. To this end, users are divided into several clusters based on the\nactual rating data and Pearson correlation coefficient. Afterwards, we give\neach item an incentive/penalty according to the preference tendency by users\nwithin the same cluster. Our experimental results show a significant\nperformance improvement over the baseline CF scheme without clustering in terms\nof recall or $F_1$ score for a given precision.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:47:36 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Tran", "Cong", ""], ["Kim", "Jang-Young", ""], ["Shin", "Won-Yong", ""], ["Kim", "Sang-Wook", ""]]}, {"id": "1905.01991", "submitter": "Sudipto Mukherjee", "authors": "Sudipto Mukherjee and Ke Jiang", "title": "A Content-Based Approach to Email Triage Action Prediction: Exploration\n  and Evaluation", "comments": "User representations, Personalization, Email response prediction,\n  Similarity features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email has remained a principal form of communication among people, both in\nenterprise and social settings. With a deluge of emails crowding our mailboxes\ndaily, there is a dire need of smart email systems that can recover important\nemails and make personalized recommendations. In this work, we study the\nproblem of predicting user triage actions to incoming emails where we take the\nreply prediction as a working example. Different from existing methods, we\nformulate the triage action prediction as a recommendation problem and focus on\nthe content-based approach, where the users are represented using the content\nof current and past emails. We also introduce additional similarity features to\nfurther explore the affinities between users and emails. Experiments on the\npublicly available Avocado email collection demonstrate the advantages of our\nproposed recommendation framework and our method is able to achieve better\nperformance compared to the state-of-the-art deep recommendation methods. More\nimportantly, we provide valuable insight into the effectiveness of different\ntextual and user representations and show that traditional bag-of-words\napproaches, with the help from the similarity features, compete favorably with\nthe more advanced neural embedding methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 01:52:57 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Mukherjee", "Sudipto", ""], ["Jiang", "Ke", ""]]}, {"id": "1905.01992", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Anish Khazane, Alan Salimov, Erik T. Mueller", "title": "An Adversarial Learning Framework For A Persona-Based Multi-Turn\n  Dialogue Model", "comments": "NAACL NeuralGen Workshop 2019. arXiv admin note: substantial text\n  overlap with arXiv:1905.01998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq)\nneural network conversation model to a multi-turn dialogue scenario by\nmodifying the state-of-the-art hredGAN architecture to simultaneously capture\nutterance attributes such as speaker identity, dialogue topic, speaker\nsentiments and so on. The proposed system, phredGAN has a persona-based HRED\ngenerator (PHRED) and a conditional discriminator. We also explore two\napproaches to accomplish the conditional discriminator: (1) phredGAN_a, a\nsystem that passes the attribute representation as an additional input into a\ntraditional adversarial discriminator, and (2) phredGAN_d, a dual discriminator\nsystem which in addition to the adversarial discriminator, collaboratively\npredicts the attribute(s) that generated the input utterance. To demonstrate\nthe superior performance of phredGAN over the persona Seq2Seq model, we\nexperiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC)\nand TV series transcripts from the Big Bang Theory and Friends. Performance\ncomparison is made with respect to a variety of quantitative measures as well\nas crowd-sourced human evaluation. We also explore the trade-offs from using\neither variant of phredGAN on datasets with many but weak attribute modalities\n(such as with Big Bang Theory and Friends) and ones with few but strong\nattribute modalities (customer-agent interactions in Ubuntu dataset).\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:21:13 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:43:11 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Khazane", "Anish", ""], ["Salimov", "Alan", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1905.01996", "submitter": "Maulik Parmar", "authors": "Maulik Parmar, V.Susheela Devi", "title": "Neural Machine Translation with Recurrent Highway Networks", "comments": "International Conference on Mining Intelligence and Knowledge\n  Exploration", "journal-ref": "In: Groza A., Prasath R. (eds) Mining Intelligence and Knowledge\n  Exploration. MIKE 2018. Lecture Notes in Computer Science, vol 11308.\n  Springer, Cham", "doi": "10.1007/978-3-030-05918-7_27", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks have lately gained a lot of popularity in language\nmodelling tasks, especially in neural machine translation(NMT). Very recent NMT\nmodels are based on Encoder-Decoder, where a deep LSTM based encoder is used to\nproject the source sentence to a fixed dimensional vector and then another deep\nLSTM decodes the target sentence from the vector. However there has been very\nlittle work on exploring architectures that have more than one layer in\nspace(i.e. in each time step). This paper examines the effectiveness of the\nsimple Recurrent Highway Networks(RHN) in NMT tasks. The model uses Recurrent\nHighway Neural Network in encoder and decoder, with attention .We also explore\nthe reconstructor model to improve adequacy. We demonstrate the effectiveness\nof all three approaches on the IWSLT English-Vietnamese dataset. We see that\nRHN performs on par with LSTM based models and even better in some cases.We see\nthat deep RHN models are easy to train compared to deep LSTM based models\nbecause of highway connections. The paper also investigates the effects of\nincreasing recurrent depth in each time step.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 08:27:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Parmar", "Maulik", ""], ["Devi", "V. Susheela", ""]]}, {"id": "1905.01997", "submitter": "Hui Fang", "authors": "Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo", "title": "Deep Learning for Sequential Recommendation: Algorithms, Influential\n  Factors, and Evaluations", "comments": "41 pages, 19 figures, 6 tables, 155 references, TOIS accepted", "journal-ref": "ACM Transactions on Information Systems, 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of sequential recommendation, deep learning (DL)-based methods\nhave received a lot of attention in the past few years and surpassed\ntraditional models such as Markov chain-based and factorization-based ones.\nHowever, there is little systematic study on DL-based methods, especially\nregarding to how to design an effective DL model for sequential recommendation.\nIn this view, this survey focuses on DL-based sequential recommender systems by\ntaking the aforementioned issues into consideration. Specifically,we illustrate\nthe concept of sequential recommendation, propose a categorization of existing\nalgorithms in terms of three types of behavioral sequence, summarize the key\nfactors affecting the performance of DL-based models, and conduct corresponding\nevaluations to demonstrate the effects of these factors. We conclude this\nsurvey by systematically outlining future directions and challenges in this\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 03:13:50 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 07:34:44 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 07:11:22 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Fang", "Hui", ""], ["Zhang", "Danning", ""], ["Shu", "Yiheng", ""], ["Guo", "Guibing", ""]]}, {"id": "1905.01998", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi O. Olabiyi, Anish Khazane, Erik T. Mueller", "title": "A Persona-based Multi-turn Conversation Model in an Adversarial Learning\n  Framework", "comments": "2018 17th IEEE International Conference on Machine Learning and\n  Applications (ICMLA). arXiv admin note: substantial text overlap with\n  arXiv:1905.01992", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq)\nneural network conversation model to multi-turn dialogue by modifying the\nstate-of-the-art hredGAN architecture. To achieve this, we introduce an\nadditional input modality into the encoder and decoder of hredGAN to capture\nother attributes such as speaker identity, location, sub-topics, and other\nexternal attributes that might be available from the corpus of human-to-human\ninteractions. The resulting persona hredGAN ($phredGAN$) shows better\nperformance than both the existing persona-based Seq2Seq and hredGAN models\nwhen those external attributes are available in a multi-turn dialogue corpus.\nThis superiority is demonstrated on TV drama series with character consistency\n(such as Big Bang Theory and Friends) and customer service interaction datasets\nsuch as Ubuntu dialogue corpus in terms of perplexity, BLEU, ROUGE, and\nDistinct n-gram scores.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:09:34 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Olabiyi", "Oluwatobi O.", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1905.02005", "submitter": "Alexander Zap", "authors": "Alexander Zap, Tobias Joppen, Johannes F\\\"urnkranz", "title": "Deep Ordinal Reinforcement Learning", "comments": "replaced figures for better visibility, added github repository, more\n  details about source of experimental results, updated target value\n  calculation for standard and ordinal Deep Q-Network", "journal-ref": "Proc. ECML/PKDD (3) 2019: 3-18", "doi": "10.1007/978-3-030-46133-1_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning usually makes use of numerical rewards, which have\nnice properties but also come with drawbacks and difficulties. Using rewards on\nan ordinal scale (ordinal rewards) is an alternative to numerical rewards that\nhas received more attention in recent years. In this paper, a general approach\nto adapting reinforcement learning problems to the use of ordinal rewards is\npresented and motivated. We show how to convert common reinforcement learning\nalgorithms to an ordinal variation by the example of Q-learning and introduce\nOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinal\nrewards. Additionally, we run evaluations on problems provided by the OpenAI\nGym framework, showing that our ordinal variants exhibit a performance that is\ncomparable to the numerical variations for a number of problems. We also give\nfirst evidence that our ordinal variant is able to produce better results for\nproblems with less engineered and simpler-to-design reward signals.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:54:22 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 09:28:24 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zap", "Alexander", ""], ["Joppen", "Tobias", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1905.02019", "submitter": "Heguang Liu", "authors": "Heguang Liu", "title": "Conditioning LSTM Decoder and Bi-directional Attention Based Question\n  Answering System", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying neural-networks on Question Answering has gained increasing\npopularity in recent years. In this paper, I implemented a model with\nBi-directional attention flow layer, connected with a Multi-layer LSTM encoder,\nconnected with one start-index decoder and one conditioning end-index decoder.\nI introduce a new end-index decoder layer, conditioning on start-index output.\nThe Experiment shows this has increased model performance by 15.16%. For\nprediction, I proposed a new smart-span equation, rewarding both short answer\nlength and high probability in start-index and end-index, which further\nimproved the prediction accuracy. The best single model achieves an F1 score of\n73.97% and EM score of 64.95% on test set.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 01:07:20 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Heguang", ""]]}, {"id": "1905.02036", "submitter": "Sebastiano Vascon Mr", "authors": "Sebastiano Vascon, Sinem Aslan, Alessandro Torcinovich, Twan van\n  Laarhoven, Elena Marchiori and Marcello Pelillo", "title": "Unsupervised Domain Adaptation using Graph Transduction Games", "comments": "Oral IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) amounts to assigning class labels to the\nunlabeled instances of a dataset from a target domain, using labeled instances\nof a dataset from a related source domain. In this paper, we propose to cast\nthis problem in a game-theoretic setting as a non-cooperative game and\nintroduce a fully automatized iterative algorithm for UDA based on graph\ntransduction games (GTG). The main advantages of this approach are its\nprincipled foundation, guaranteed termination of the iterative algorithms to a\nNash equilibrium (which corresponds to a consistent labeling condition) and\nsoft labels quantifying the uncertainty of the label assignment process. We\nalso investigate the beneficial effect of using pseudo-labels from linear\nclassifiers to initialize the iterative process. The performance of the\nresulting methods is assessed on publicly available object recognition\nbenchmark datasets involving both shallow and deep features. Results of\nexperiments demonstrate the suitability of the proposed game-theoretic approach\nfor solving UDA tasks.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 13:34:04 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Vascon", "Sebastiano", ""], ["Aslan", "Sinem", ""], ["Torcinovich", "Alessandro", ""], ["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""], ["Pelillo", "Marcello", ""]]}, {"id": "1905.02072", "submitter": "Kenneth Harris", "authors": "Kenneth D. Harris", "title": "Characterizing the invariances of learning algorithms using category\n  theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many learning algorithms have invariances: when their training data is\ntransformed in certain ways, the function they learn transforms in a\npredictable manner. Here we formalize this notion using concepts from the\nmathematical field of category theory. The invariances that a supervised\nlearning algorithm possesses are formalized by categories of predictor and\ntarget spaces, whose morphisms represent the algorithm's invariances, and an\nindex category whose morphisms represent permutations of the training examples.\nAn invariant learning algorithm is a natural transformation between two\nfunctors from the product of these categories to the category of sets,\nrepresenting training datasets and learned functions respectively. We\nillustrate the framework by characterizing and contrasting the invariances of\nlinear regression and ridge regression.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 14:48:33 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Harris", "Kenneth D.", ""]]}, {"id": "1905.02099", "submitter": "Siddharth Swaroop", "authors": "Siddharth Swaroop, Cuong V. Nguyen, Thang D. Bui, Richard E. Turner", "title": "Improving and Understanding Variational Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the continual learning setting, tasks are encountered sequentially. The\ngoal is to learn whilst i) avoiding catastrophic forgetting, ii) efficiently\nusing model capacity, and iii) employing forward and backward transfer\nlearning. In this paper, we explore how the Variational Continual Learning\n(VCL) framework achieves these desiderata on two benchmarks in continual\nlearning: split MNIST and permuted MNIST. We first report significantly\nimproved results on what was already a competitive approach. The improvements\nare achieved by establishing a new best practice approach to mean-field\nvariational Bayesian neural networks. We then look at the solutions in detail.\nThis allows us to obtain an understanding of why VCL performs as it does, and\nwe compare the solution to what an `ideal' continual learning solution might\nbe.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 15:23:37 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Swaroop", "Siddharth", ""], ["Nguyen", "Cuong V.", ""], ["Bui", "Thang D.", ""], ["Turner", "Richard E.", ""]]}, {"id": "1905.02121", "submitter": "Finn Kuusisto", "authors": "Finn Kuusisto, Vitor Santos Costa, Zhonggang Hou, James Thomson, David\n  Page, Ron Stewart", "title": "Machine Learning to Predict Developmental Neurotoxicity with\n  High-throughput Data from 2D Bio-engineered Tissues", "comments": null, "journal-ref": null, "doi": "10.1109/ICMLA.2019.00055", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for fast and accurate methods for testing\ndevelopmental neurotoxicity across several chemical exposure sources. Current\napproaches, such as in vivo animal studies, and assays of animal and human\nprimary cell cultures, suffer from challenges related to time, cost, and\napplicability to human physiology. We previously demonstrated success employing\nmachine learning to predict developmental neurotoxicity using gene expression\ndata collected from human 3D tissue models exposed to various compounds. The 3D\nmodel is biologically similar to developing neural structures, but its\ncomplexity necessitates extensive expertise and effort to employ. By instead\nfocusing solely on constructing an assay of developmental neurotoxicity, we\npropose that a simpler 2D tissue model may prove sufficient. We thus compare\nthe accuracy of predictive models trained on data from a 2D tissue model with\nthose trained on data from a 3D tissue model, and find the 2D model to be\nsubstantially more accurate. Furthermore, we find the 2D model to be more\nrobust under stringent gene set selection, whereas the 3D model suffers\nsubstantial accuracy degradation. While both approaches have advantages and\ndisadvantages, we propose that our described 2D approach could be a valuable\ntool for decision makers when prioritizing neurotoxicity screening.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:13:59 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Kuusisto", "Finn", ""], ["Costa", "Vitor Santos", ""], ["Hou", "Zhonggang", ""], ["Thomson", "James", ""], ["Page", "David", ""], ["Stewart", "Ron", ""]]}, {"id": "1905.02138", "submitter": "Alessandro Epasto", "authors": "Alessandro Epasto and Bryan Perozzi", "title": "Is a Single Embedding Enough? Learning Node Representations that Capture\n  Multiple Social Contexts", "comments": null, "journal-ref": "In Proceedings of \"The Web Conference\" 2019, WWW, 2019", "doi": "10.1145/3308558.3313660", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent interest in graph embedding methods has focused on learning a single\nrepresentation for each node in the graph. But can nodes really be best\ndescribed by a single vector representation? In this work, we propose a method\nfor learning multiple representations of the nodes in a graph (e.g., the users\nof a social network). Based on a principled decomposition of the ego-network,\neach representation encodes the role of the node in a different local community\nin which the nodes participate. These representations allow for improved\nreconstruction of the nuanced relationships that occur in the graph -- a\nphenomenon that we illustrate through state-of-the-art results on link\nprediction tasks on a variety of graphs, reducing the error by up to $90\\%$. In\naddition, we show that these embeddings allow for effective visual analysis of\nthe learned community structure.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:46:38 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Epasto", "Alessandro", ""], ["Perozzi", "Bryan", ""]]}, {"id": "1905.02149", "submitter": "Sebastian Wild", "authors": "David Durfee, Yu Gao, Anup B. Rao, Sebastian Wild", "title": "Efficient Second-Order Shape-Constrained Function Fitting", "comments": "accepted for WADS 2019; (v2 fixes various typos)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm to compute a one-dimensional shape-constrained function\nthat best fits given data in weighted-$L_{\\infty}$ norm. We give a single\nalgorithm that works for a variety of commonly studied shape constraints\nincluding monotonicity, Lipschitz-continuity and convexity, and more generally,\nany shape constraint expressible by bounds on first- and/or second-order\ndifferences. Our algorithm computes an approximation with additive error\n$\\varepsilon$ in $O\\left(n \\log \\frac{U}{\\varepsilon} \\right)$ time, where $U$\ncaptures the range of input values. We also give a simple greedy algorithm that\nruns in $O(n)$ time for the special case of unweighted $L_{\\infty}$ convex\nregression. These are the first (near-)linear-time algorithms for\nsecond-order-constrained function fitting. To achieve these results, we use a\nnovel geometric interpretation of the underlying dynamic programming problem.\nWe further show that a generalization of the corresponding problems to directed\nacyclic graphs (DAGs) is as difficult as linear programming.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:08:52 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 20:17:51 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Durfee", "David", ""], ["Gao", "Yu", ""], ["Rao", "Anup B.", ""], ["Wild", "Sebastian", ""]]}, {"id": "1905.02161", "submitter": "Angus Galloway", "authors": "Angus Galloway and Anna Golubeva and Thomas Tanay and Medhat Moussa\n  and Graham W. Taylor", "title": "Batch Normalization is a Cause of Adversarial Vulnerability", "comments": "To appear in the ICML 2019 Workshop on Identifying and Understanding\n  Deep Learning Phenomena", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization (batch norm) is often used in an attempt to stabilize and\naccelerate training in deep neural networks. In many cases it indeed decreases\nthe number of parameter updates required to achieve low training error.\nHowever, it also reduces robustness to small adversarial input perturbations\nand noise by double-digit percentages, as we show on five standard datasets.\nFurthermore, substituting weight decay for batch norm is sufficient to nullify\nthe relationship between adversarial vulnerability and the input dimension. Our\nwork is consistent with a mean-field analysis that found that batch norm causes\nexploding gradients.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:21:08 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 22:08:08 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Galloway", "Angus", ""], ["Golubeva", "Anna", ""], ["Tanay", "Thomas", ""], ["Moussa", "Medhat", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1905.02168", "submitter": "Alexander Elkholy", "authors": "Alexander Elkholy, Fangkai Yang, Steven Gustafson", "title": "Interpretable Automated Machine Learning in Maana(TM) Knowledge Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is becoming an essential part of developing solutions for\nmany industrial applications, but the lack of interpretability hinders wide\nindustry adoption to rapidly build, test, deploy and validate machine learning\nmodels, in the sense that the insight of developing machine learning solutions\nare not structurally encoded, justified and transferred. In this paper we\ndescribe Maana Meta-learning Service, an interpretable and interactive\nautomated machine learning service residing in Maana Knowledge Platform that\nperforms machine-guided, user assisted pipeline search and hyper-parameter\ntuning and generates structured knowledge about decisions for pipeline\nprofiling and selection. The service is shipped with Maana Knowledge Platform\nand is validated using benchmark dataset. Furthermore, its capability of\nderiving knowledge from pipeline search facilitates various inference tasks and\ntransferring to similar data science projects.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:37:15 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Elkholy", "Alexander", ""], ["Yang", "Fangkai", ""], ["Gustafson", "Steven", ""]]}, {"id": "1905.02175", "submitter": "Dimitris Tsipras", "authors": "Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom,\n  Brandon Tran, Aleksander Madry", "title": "Adversarial Examples Are Not Bugs, They Are Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have attracted significant attention in machine\nlearning, but the reasons for their existence and pervasiveness remain unclear.\nWe demonstrate that adversarial examples can be directly attributed to the\npresence of non-robust features: features derived from patterns in the data\ndistribution that are highly predictive, yet brittle and incomprehensible to\nhumans. After capturing these features within a theoretical framework, we\nestablish their widespread existence in standard datasets. Finally, we present\na simple setting where we can rigorously tie the phenomena we observe in\npractice to a misalignment between the (human-specified) notion of robustness\nand the inherent geometry of the data.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:45:05 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:01:14 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 00:25:20 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 14:36:10 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Engstrom", "Logan", ""], ["Tran", "Brandon", ""], ["Madry", "Aleksander", ""]]}, {"id": "1905.02185", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Tatsuya Harada", "title": "Label-Noise Robust Multi-Domain Image-to-Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain image-to-image translation is a problem where the goal is to\nlearn mappings among multiple domains. This problem is challenging in terms of\nscalability because it requires the learning of numerous mappings, the number\nof which increases proportional to the number of domains. However, generative\nadversarial networks (GANs) have emerged recently as a powerful framework for\nthis problem. In particular, label-conditional extensions (e.g., StarGAN) have\nbecome a promising solution owing to their ability to address this problem\nusing only a single unified model. Nonetheless, a limitation is that they rely\non the availability of large-scale clean-labeled data, which are often\nlaborious or impractical to collect in a real-world scenario. To overcome this\nlimitation, we propose a novel model called the label-noise robust\nimage-to-image translation model (RMIT) that can learn a clean label\nconditional generator even when noisy labeled data are only available. In\nparticular, we propose a novel loss called the virtual cycle consistency loss\nthat is able to regularize cyclic reconstruction independently of noisy labeled\ndata, as well as we introduce advanced techniques to boost the performance in\npractice. Our experimental results demonstrate that RMIT is useful for\nobtaining label-noise robustness in various settings including synthetic and\nreal-world noise.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:57:43 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1905.02197", "submitter": "Mohammadreza Khajeh Hosseini", "authors": "Mohammadreza Khajeh-Hosseini and Alireza Talebpour", "title": "Back to the Future: Predicting Traffic Shockwave Formation and\n  Propagation Using a Convolutional Encoder-Decoder Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a deep learning methodology to predict the propagation of\ntraffic shockwaves. The input to the deep neural network is time-space diagram\nof the study segment, and the output of the network is the predicted (future)\npropagation of the shockwave on the study segment in the form of time-space\ndiagram. The main feature of the proposed methodology is the ability to extract\nthe features embedded in the time-space diagram to predict the propagation of\ntraffic shockwaves.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 18:33:55 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Khajeh-Hosseini", "Mohammadreza", ""], ["Talebpour", "Alireza", ""]]}, {"id": "1905.02199", "submitter": "Guergana Petrova", "authors": "I. Daubechies, R. DeVore, S. Foucart, B. Hanin, and G. Petrova", "title": "Nonlinear Approximation and (Deep) ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is concerned with the approximation and expressive powers of\ndeep neural networks. This is an active research area currently producing many\ninteresting papers. The results most commonly found in the literature prove\nthat neural networks approximate functions with classical smoothness to the\nsame accuracy as classical linear methods of approximation, e.g. approximation\nby polynomials or by piecewise polynomials on prescribed partitions. However,\napproximation by neural networks depending on n parameters is a form of\nnonlinear approximation and as such should be compared with other nonlinear\nmethods such as variable knot splines or n-term approximation from\ndictionaries. The performance of neural networks in targeted applications such\nas machine learning indicate that they actually possess even greater\napproximation power than these traditional methods of nonlinear approximation.\nThe main results of this article prove that this is indeed the case. This is\ndone by exhibiting large classes of functions which can be efficiently captured\nby neural networks where classical nonlinear methods fall short of the task.\nThe present article purposefully limits itself to studying the approximation of\nunivariate functions by ReLU networks. Many generalizations to functions of\nseveral variables and other activation functions can be envisioned. However,\neven in this simplest of settings considered here, a theory that completely\nquantifies the approximation power of neural networks is still lacking.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 12:54:35 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Daubechies", "I.", ""], ["DeVore", "R.", ""], ["Foucart", "S.", ""], ["Hanin", "B.", ""], ["Petrova", "G.", ""]]}, {"id": "1905.02200", "submitter": "Song Gao", "authors": "Yuhao Kang, Song Gao, Robert E. Roth", "title": "Transferring Multiscale Map Styles Using Generative Adversarial Networks", "comments": "12 pages, 17 figure", "journal-ref": "International Journal of Cartography, 2019", "doi": "10.1080/23729333.2019.1615729", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The advancement of the Artificial Intelligence (AI) technologies makes it\npossible to learn stylistic design criteria from existing maps or other visual\nart and transfer these styles to make new digital maps. In this paper, we\npropose a novel framework using AI for map style transfer applicable across\nmultiple map scales. Specifically, we identify and transfer the stylistic\nelements from a target group of visual examples, including Google Maps,\nOpenStreetMap, and artistic paintings, to unstylized GIS vector data through\ntwo generative adversarial network (GAN) models. We then train a binary\nclassifier based on a deep convolutional neural network to evaluate whether the\ntransfer styled map images preserve the original map design characteristics.\nOur experiment results show that GANs have a great potential for multiscale map\nstyle transferring, but many challenges remain requiring future research.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 04:52:42 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 05:47:15 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kang", "Yuhao", ""], ["Gao", "Song", ""], ["Roth", "Robert E.", ""]]}, {"id": "1905.02219", "submitter": "Nikos Karampatziakis", "authors": "Nikos Karampatziakis, Sebastian Kochman, Jade Huang, Paul Mineiro,\n  Kathy Osborne, Weizhu Chen", "title": "Lessons from Contextual Bandit Learning in a Customer Support Bot", "comments": "Reinforcement Learning for Real Life Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe practical lessons we have learned from successfully\nusing contextual bandits (CBs) to improve key business metrics of the Microsoft\nVirtual Agent for customer support. While our current use cases focus on single\nstep einforcement learning (RL) and mostly in the domain of natural language\nprocessing and information retrieval we believe many of our findings are\ngenerally applicable. Through this article, we highlight certain issues that RL\npractitioners may encounter in similar types of applications as well as offer\npractical solutions to these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 18:00:46 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 17:59:16 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Karampatziakis", "Nikos", ""], ["Kochman", "Sebastian", ""], ["Huang", "Jade", ""], ["Mineiro", "Paul", ""], ["Osborne", "Kathy", ""], ["Chen", "Weizhu", ""]]}, {"id": "1905.02234", "submitter": "Shreyansh Gandhi", "authors": "Shreyansh Gandhi, Samrat Kokkula, Abon Chaudhuri, Alessandro Magnani,\n  Theban Stanley, Behzad Ahmadi, Venkatesh Kandaswamy, Omer Ovenc, Shie Mannor", "title": "Image Matters: Scalable Detection of Offensive and Non-Compliant Content\n  / Logo in Product Images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, product content, especially product images have a significant\ninfluence on a customer's journey from product discovery to evaluation and\nfinally, purchase decision. Since many e-commerce retailers sell items from\nother third-party marketplace sellers besides their own, the content published\nby both internal and external content creators needs to be monitored and\nenriched, wherever possible. Despite guidelines and warnings, product listings\nthat contain offensive and non-compliant images continue to enter catalogs.\nOffensive and non-compliant content can include a wide range of objects, logos,\nand banners conveying violent, sexually explicit, racist, or promotional\nmessages. Such images can severely damage the customer experience, lead to\nlegal issues, and erode the company brand. In this paper, we present a computer\nvision driven offensive and non-compliant image detection system for extremely\nlarge image datasets. This paper delves into the unique challenges of applying\ndeep learning to real-world product image data from retail world. We\ndemonstrate how we resolve a number of technical challenges such as lack of\ntraining data, severe class imbalance, fine-grained class definitions etc.\nusing a number of practical yet unique technical strategies. Our system\ncombines state-of-the-art image classification and object detection techniques\nwith budgeted crowdsourcing to develop a solution customized for a massive,\ndiverse, and constantly evolving product catalog.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 18:35:28 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 07:38:26 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Gandhi", "Shreyansh", ""], ["Kokkula", "Samrat", ""], ["Chaudhuri", "Abon", ""], ["Magnani", "Alessandro", ""], ["Stanley", "Theban", ""], ["Ahmadi", "Behzad", ""], ["Kandaswamy", "Venkatesh", ""], ["Ovenc", "Omer", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.02248", "submitter": "Xiaoliang Chen", "authors": "Xiaoliang Chen, Baojia Li, Roberto Proietti, Hongbo Lu, Zuqing Zhu, S.\n  J. Ben Yoo", "title": "DeepRMSA: A Deep Reinforcement Learning Framework for Routing,\n  Modulation and Spectrum Assignment in Elastic Optical Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JLT.2019.2923615", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes DeepRMSA, a deep reinforcement learning framework for\nrouting, modulation and spectrum assignment (RMSA) in elastic optical networks\n(EONs). DeepRMSA learns the correct online RMSA policies by parameterizing the\npolicies with deep neural networks (DNNs) that can sense complex EON states.\nThe DNNs are trained with experiences of dynamic lightpath provisioning. We\nfirst modify the asynchronous advantage actor-critic algorithm and present an\nepisode-based training mechanism for DeepRMSA, namely, DeepRMSA-EP. DeepRMSA-EP\ndivides the dynamic provisioning process into multiple episodes (each\ncontaining the servicing of a fixed number of lightpath requests) and performs\ntraining by the end of each episode. The optimization target of DeepRMSA-EP at\neach step of servicing a request is to maximize the cumulative reward within\nthe rest of the episode. Thus, we obviate the need for estimating the rewards\nrelated to unknown future states. To overcome the instability issue in the\ntraining of DeepRMSA-EP due to the oscillations of cumulative rewards, we\nfurther propose a window-based flexible training mechanism, i.e., DeepRMSA-FLX.\nDeepRMSA-FLX attempts to smooth out the oscillations by defining the\noptimization scope at each step as a sliding window, and ensuring that the\ncumulative rewards always include rewards from a fixed number of requests.\nEvaluations with the two sample topologies show that DeepRMSA-FLX can\neffectively stabilize the training while achieving blocking probability\nreductions of more than 20.3% and 14.3%, when compared with the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:51:24 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 18:58:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chen", "Xiaoliang", ""], ["Li", "Baojia", ""], ["Proietti", "Roberto", ""], ["Lu", "Hongbo", ""], ["Zhu", "Zuqing", ""], ["Yoo", "S. J. Ben", ""]]}, {"id": "1905.02249", "submitter": "David Berthelot", "authors": "David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot,\n  Avital Oliver, Colin Raffel", "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning has proven to be a powerful paradigm for leveraging\nunlabeled data to mitigate the reliance on large labeled datasets. In this\nwork, we unify the current dominant approaches for semi-supervised learning to\nproduce a new algorithm, MixMatch, that works by guessing low-entropy labels\nfor data-augmented unlabeled examples and mixing labeled and unlabeled data\nusing MixUp. We show that MixMatch obtains state-of-the-art results by a large\nmargin across many datasets and labeled data amounts. For example, on CIFAR-10\nwith 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by\na factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a\ndramatically better accuracy-privacy trade-off for differential privacy.\nFinally, we perform an ablation study to tease apart which components of\nMixMatch are most important for its success.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:56:03 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:47:34 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Berthelot", "David", ""], ["Carlini", "Nicholas", ""], ["Goodfellow", "Ian", ""], ["Papernot", "Nicolas", ""], ["Oliver", "Avital", ""], ["Raffel", "Colin", ""]]}, {"id": "1905.02257", "submitter": "Shu Wang", "authors": "Shu Wang, Jonathan G. Yabes and Chung-Chou H. Chang", "title": "Hybrid Density- and Partition-based Clustering Algorithm for Data with\n  Mixed-type Variables", "comments": null, "journal-ref": "Journal of Data Science 19(2021)15-36", "doi": "10.6339/21-JDS996", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an essential technique for discovering patterns in data. The\nsteady increase in amount and complexity of data over the years led to\nimprovements and development of new clustering algorithms. However, algorithms\nthat can cluster data with mixed variable types (continuous and categorical)\nremain limited, despite the abundance of data with mixed types particularly in\nthe medical field. Among existing methods for mixed data, some posit\nunverifiable distributional assumptions or that the contributions of different\nvariable types are not well balanced.\n  We propose a two-step hybrid density- and partition-based algorithm (HyDaP)\nthat can detect clusters after variables selection. The first step involves\nboth density-based and partition-based algorithms to identify the data\nstructure formed by continuous variables and recognize the important variables\nfor clustering; the second step involves partition-based algorithm together\nwith a novel dissimilarity measure we designed for mixed data to obtain\nclustering results. Simulations across various scenarios and data structures\nwere conducted to examine the performance of the HyDaP algorithm compared to\ncommonly used methods. We also applied the HyDaP algorithm on electronic health\nrecords to identify sepsis phenotypes.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 20:34:35 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Wang", "Shu", ""], ["Yabes", "Jonathan G.", ""], ["Chang", "Chung-Chou H.", ""]]}, {"id": "1905.02259", "submitter": "Scott McCloskey", "authors": "Michael Albright and Scott McCloskey", "title": "Source Generator Attribution via Inversion", "comments": "Updated with new experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in Generative Adversarial Networks (GANs) leading to\ndramatically-improved synthetic images and video, there is an increased need\nfor algorithms which extend traditional forensics to this new category of\nimagery. While GANs have been shown to be helpful in a number of computer\nvision applications, there are other problematic uses such as `deep fakes'\nwhich necessitate such forensics. Source camera attribution algorithms using\nvarious cues have addressed this need for imagery captured by a camera, but\nthere are fewer options for synthetic imagery. We address the problem of\nattributing a synthetic image to a specific generator in a white box setting,\nby inverting the process of generation. This enables us to simultaneously\ndetermine whether the generator produced the image and recover an input which\nproduces a close match to the synthetic image.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 20:47:28 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 19:01:37 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Albright", "Michael", ""], ["McCloskey", "Scott", ""]]}, {"id": "1905.02263", "submitter": "Yang-Hui He", "authors": "Yang-Hui He and Minhyong Kim", "title": "Learning Algebraic Structures: Preliminary Investigations", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th math.GR math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ techniques of machine-learning, exemplified by support vector\nmachines and neural classifiers, to initiate the study of whether AI can\n\"learn\" algebraic structures. Using finite groups and finite rings as a\nconcrete playground, we find that questions such as identification of simple\ngroups by \"looking\" at the Cayley table or correctly matching addition and\nmultiplication tables for finite rings can, at least for structures of small\nsize, be performed by the AI, even after having been trained only on small\nnumber of cases. These results are in tandem with recent investigations on\nwhether AI can solve certain classes of problems in algebraic geometry.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 19:09:00 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["He", "Yang-Hui", ""], ["Kim", "Minhyong", ""]]}, {"id": "1905.02266", "submitter": "Guido Previde Massara", "authors": "Guido Previde Massara and Tomaso Aste", "title": "Learning Clique Forests", "comments": "47 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a topological learning algorithm for the estimation of the\nconditional dependency structure of large sets of random variables from sparse\nand noisy data. The algorithm, named Maximally Filtered Clique Forest (MFCF),\nproduces a clique forest and an associated Markov Random Field (MRF) by\ngeneralising Prim's minimum spanning tree algorithm. To the best of our\nknowledge, the MFCF presents three elements of novelty with respect to existing\nstructure learning approaches. The first is the repeated application of a local\ntopological move, the clique expansion, that preserves the decomposability of\nthe underlying graph. Through this move the decomposability and calculation of\nscores is performed incrementally at the variable (rather than edge) level, and\nthis provides better computational performance and an intuitive application of\nmultivariate statistical tests. The second is the capability to accommodate a\nvariety of score functions and, while this paper is focused on multivariate\nnormal distributions, it can be directly generalised to different types of\nstatistics. Finally, the third is the variable range of allowed clique sizes\nwhich is an adjustable topological constraint that acts as a topological\npenalizer providing a way to tackle sparsity at $l_0$ semi-norm level; this\nallows a clean decoupling of structure learning and parameter estimation. The\nMFCF produces a representation of the clique forest, together with a perfect\nordering of the cliques and a perfect elimination ordering for the vertices. As\nan example we propose an application to covariance selection models and we show\nthat the MCFC outperforms the Graphical Lasso for a number of classes of\nmatrices.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 21:15:46 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 16:19:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Massara", "Guido Previde", ""], ["Aste", "Tomaso", ""]]}, {"id": "1905.02269", "submitter": "Achille Nazaret", "authors": "Romain Lopez, Achille Nazaret, Maxime Langevin, Jules Samaran, Jeffrey\n  Regier, Michael I. Jordan, Nir Yosef", "title": "A joint model of unpaired data from scRNA-seq and spatial\n  transcriptomics for imputing missing gene expression measurements", "comments": "submitted to the 2019 ICML Workshop on Computational Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial studies of transcriptome provide biologists with gene expression maps\nof heterogeneous and complex tissues. However, most experimental protocols for\nspatial transcriptomics suffer from the need to select beforehand a small\nfraction of genes to be quantified over the entire transcriptome. Standard\nsingle-cell RNA sequencing (scRNA-seq) is more prevalent, easier to implement\nand can in principle capture any gene but cannot recover the spatial location\nof the cells. In this manuscript, we focus on the problem of imputation of\nmissing genes in spatial transcriptomic data based on (unpaired) standard\nscRNA-seq data from the same biological tissue. Building upon domain adaptation\nwork, we propose gimVI, a deep generative model for the integration of spatial\ntranscriptomic data and scRNA-seq data that can be used to impute missing\ngenes. After describing our generative model and an inference procedure for it,\nwe compare gimVI to alternative methods from computational biology or domain\nadaptation on real datasets and outperform Seurat Anchors, Liger and CORAL to\nimpute held-out genes.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 21:24:17 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Lopez", "Romain", ""], ["Nazaret", "Achille", ""], ["Langevin", "Maxime", ""], ["Samaran", "Jules", ""], ["Regier", "Jeffrey", ""], ["Jordan", "Michael I.", ""], ["Yosef", "Nir", ""]]}, {"id": "1905.02291", "submitter": "Mark-Oliver Stehr", "authors": "Mark-Oliver Stehr, Peter Avar, Andrew R. Korte, Lida Parvin, Ziad J.\n  Sahab, Deborah I. Bunin, Merrill Knapp, Denise Nishita, Andrew Poggio,\n  Carolyn L. Talcott, Brian M. Davis, Christine A. Morton, Christopher J.\n  Sevinsky, Maria I. Zavodszky, Akos Vertes", "title": "Learning Causality: Synthesis of Large-Scale Causal Networks from\n  High-Dimensional Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an abundance of complex dynamic systems that are critical to our\ndaily lives and our society but that are hardly understood, and even with\ntoday's possibilities to sense and collect large amounts of experimental data,\nthey are so complex and continuously evolving that it is unlikely that their\ndynamics will ever be understood in full detail. Nevertheless, through\ncomputational tools we can try to make the best possible use of the current\ntechnologies and available data. We believe that the most useful models will\nhave to take into account the imbalance between system complexity and available\ndata in the context of limited knowledge or multiple hypotheses. The complex\nsystem of biological cells is a prime example of such a system that is studied\nin systems biology and has motivated the methods presented in this paper. They\nwere developed as part of the DARPA Rapid Threat Assessment (RTA) program,\nwhich is concerned with understanding of the mechanism of action (MoA) of\ntoxins or drugs affecting human cells. Using a combination of Gaussian\nprocesses and abstract network modeling, we present three fundamentally\ndifferent machine-learning-based approaches to learn causal relations and\nsynthesize causal networks from high-dimensional time series data. While other\ntypes of data are available and have been analyzed and integrated in our RTA\nwork, we focus on transcriptomics (that is gene expression) data obtained from\nhigh-throughput microarray experiments in this paper to illustrate capabilities\nand limitations of our algorithms. Our algorithms make different but overall\nrelatively few biological assumptions, so that they are applicable to other\ntypes of biological data and potentially even to other complex systems that\nexhibit high dimensionality but are not of biological nature.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 23:18:03 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Stehr", "Mark-Oliver", ""], ["Avar", "Peter", ""], ["Korte", "Andrew R.", ""], ["Parvin", "Lida", ""], ["Sahab", "Ziad J.", ""], ["Bunin", "Deborah I.", ""], ["Knapp", "Merrill", ""], ["Nishita", "Denise", ""], ["Poggio", "Andrew", ""], ["Talcott", "Carolyn L.", ""], ["Davis", "Brian M.", ""], ["Morton", "Christine A.", ""], ["Sevinsky", "Christopher J.", ""], ["Zavodszky", "Maria I.", ""], ["Vertes", "Akos", ""]]}, {"id": "1905.02295", "submitter": "Paul Bertin", "authors": "Paul Bertin, Mohammad Hashir, Martin Weiss, Vincent Frappier, Theodore\n  J. Perkins, Genevi\\`eve Boucher and Joseph Paul Cohen", "title": "Analysis of Gene Interaction Graphs as Prior Knowledge for Machine\n  Learning Models", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene interaction graphs aim to capture various relationships between genes\nand can represent decades of biology research. When trying to make predictions\nfrom genomic data, those graphs could be used to overcome the curse of\ndimensionality by making machine learning models sparser and more consistent\nwith biological common knowledge. In this work, we focus on assessing how well\nthose graphs capture dependencies seen in gene expression data to evaluate the\nadequacy of the prior knowledge provided by those graphs. We propose a\ncondition graphs should satisfy to provide good prior knowledge and test it\nusing `Single Gene Inference' tasks. We also compare with randomly generated\ngraphs, aiming to measure the true benefit of using biologically relevant\ngraphs in this context, and validate our findings with five clinical tasks. We\nfind some graphs capture relevant dependencies for most genes while being very\nsparse. Our analysis with random graphs finds that dependencies can be captured\nalmost as well at random which suggests that, in terms of gene expression\nlevels, the relevant information about the state of the cell is spread across\nmany genes.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 23:57:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 22:21:39 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Bertin", "Paul", ""], ["Hashir", "Mohammad", ""], ["Weiss", "Martin", ""], ["Frappier", "Vincent", ""], ["Perkins", "Theodore J.", ""], ["Boucher", "Genevi\u00e8ve", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1905.02296", "submitter": "Leonardo Teixeira", "authors": "Leonardo Teixeira, Brian Jalaian and Bruno Ribeiro", "title": "Are Graph Neural Networks Miscalibrated?", "comments": "Presented at the ICML 2019 Workshop on Learning and Reasoning with\n  Graph-Structured Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have proven to be successful in many\nclassification tasks, outperforming previous state-of-the-art methods in terms\nof accuracy. However, accuracy alone is not enough for high-stakes decision\nmaking. Decision makers want to know the likelihood that a specific GNN\nprediction is correct. For this purpose, obtaining calibrated models is\nessential. In this work, we perform an empirical evaluation of the calibration\nof state-of-the-art GNNs on multiple datasets. Our experiments show that GNNs\ncan be calibrated in some datasets but also badly miscalibrated in others, and\nthat state-of-the-art calibration methods are helpful but do not fix the\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 00:05:31 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:10:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Teixeira", "Leonardo", ""], ["Jalaian", "Brian", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1905.02304", "submitter": "Justin Chen", "authors": "Justin Chen, Edward Gan, Kexin Rong, Sahaana Suri, Peter Bailis", "title": "CrossTrainer: Practical Domain Adaptation with Loss Reweighting", "comments": null, "journal-ref": null, "doi": "10.1145/3329486.3329491", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation provides a powerful set of model training techniques given\ndomain-specific training data and supplemental data with unknown relevance. The\ntechniques are useful when users need to develop models with data from varying\nsources, of varying quality, or from different time ranges. We build\nCrossTrainer, a system for practical domain adaptation. CrossTrainer utilizes\nloss reweighting, which provides consistently high model accuracy across a\nvariety of datasets in our empirical analysis. However, loss reweighting is\nsensitive to the choice of a weight hyperparameter that is expensive to tune.\nWe develop optimizations leveraging unique properties of loss reweighting that\nallow CrossTrainer to output accurate models while improving training time\ncompared to naive hyperparameter search.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 00:48:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Chen", "Justin", ""], ["Gan", "Edward", ""], ["Rong", "Kexin", ""], ["Suri", "Sahaana", ""], ["Bailis", "Peter", ""]]}, {"id": "1905.02313", "submitter": "Zongchen Chen", "authors": "Zongchen Chen, Santosh S. Vempala", "title": "Optimal Convergence Rate of Hamiltonian Monte Carlo for Strongly\n  Logconcave Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Hamiltonian Monte Carlo (HMC) for sampling from a strongly\nlogconcave density proportional to $e^{-f}$ where $f:\\mathbb{R}^d \\to\n\\mathbb{R}$ is $\\mu$-strongly convex and $L$-smooth (the condition number is\n$\\kappa = L/\\mu$). We show that the relaxation time (inverse of the spectral\ngap) of ideal HMC is $O(\\kappa)$, improving on the previous best bound of\n$O(\\kappa^{1.5})$; we complement this with an example where the relaxation time\nis $\\Omega(\\kappa)$. When implemented using a nearly optimal ODE solver, HMC\nreturns an $\\varepsilon$-approximate point in $2$-Wasserstein distance using\n$\\widetilde{O}((\\kappa d)^{0.5} \\varepsilon^{-1})$ gradient evaluations per\nstep and $\\widetilde{O}((\\kappa d)^{1.5}\\varepsilon^{-1})$ total time.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 01:20:59 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Chen", "Zongchen", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "1905.02325", "submitter": "Priyank Jaini", "authors": "Priyank Jaini and Kira A. Selby and Yaoliang Yu", "title": "Sum-of-Squares Polynomial Flow", "comments": "13 pages, ICML'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangular map is a recent construct in probability theory that allows one to\ntransform any source probability density function to any target density\nfunction. Based on triangular maps, we propose a general framework for\nhigh-dimensional density estimation, by specifying one-dimensional\ntransformations (equivalently conditional densities) and appropriate\nconditioner networks. This framework (a) reveals the commonalities and\ndifferences of existing autoregressive and flow based methods, (b) allows a\nunified understanding of the limitations and representation power of these\nrecent approaches and, (c) motivates us to uncover a new Sum-of-Squares (SOS)\nflow that is interpretable, universal, and easy to train. We perform several\nsynthetic experiments on various density geometries to demonstrate the benefits\n(and short-comings) of such transformations. SOS flows achieve competitive\nresults in simulations and several real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 02:16:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 20:06:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Jaini", "Priyank", ""], ["Selby", "Kira A.", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1905.02331", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Hsiang-Fu Yu, Kai Zhong, Yiming Yang, Inderjit\n  Dhillon", "title": "Taming Pretrained Transformers for Extreme Multi-label Text\n  Classification", "comments": "KDD 2020 Applied Data Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the extreme multi-label text classification (XMC) problem: given\nan input text, return the most relevant labels from a large label collection.\nFor example, the input text could be a product description on Amazon.com and\nthe labels could be product categories. XMC is an important yet challenging\nproblem in the NLP community. Recently, deep pretrained transformer models have\nachieved state-of-the-art performance on many NLP tasks including sentence\nclassification, albeit with small label sets. However, naively applying deep\ntransformer models to the XMC problem leads to sub-optimal performance due to\nthe large output space and the label sparsity issue. In this paper, we propose\nX-Transformer, the first scalable approach to fine-tuning deep transformer\nmodels for the XMC problem. The proposed method achieves new state-of-the-art\nresults on four XMC benchmark datasets. In particular, on a Wiki dataset with\naround 0.5 million labels, the prec@1 of X-Transformer is 77.28%, a substantial\nimprovement over state-of-the-art XMC approaches Parabel (linear) and\nAttentionXML (neural), which achieve 68.70% and 76.95% precision@1,\nrespectively. We further apply X-Transformer to a product2query dataset from\nAmazon and gained 10.7% relative improvement on prec@1 over Parabel.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 02:32:06 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 18:54:52 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 01:13:05 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 19:28:18 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Yu", "Hsiang-Fu", ""], ["Zhong", "Kai", ""], ["Yang", "Yiming", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "1905.02341", "submitter": "Lei Pang", "authors": "Yang Jiang and Cong Zhao and Zeyang Dou and Lei Pang", "title": "Neural Architecture Refinement: A Practical Way for Avoiding Overfitting\n  in NAS", "comments": "9 pages, 1 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is proposed to automate the architecture\ndesign process and attracts overwhelming interest from both academia and\nindustry. However, it is confronted with overfitting issue due to the\nhigh-dimensional search space composed by operator selection and skip\nconnection of each layer. This paper explores the architecture overfitting\nissue in depth based on the reinforcement learning-based NAS framework. We show\nthat the policy gradient method has deep correlations with the cross entropy\nminimization. Based on this correlation, we further demonstrate that, though\nthe reward of NAS is sparse, the policy gradient method implicitly assign the\nreward to all operations and skip connections based on the sampling frequency.\nHowever, due to the inaccurate reward estimation, curse of dimensionality\nproblem and the hierachical structure of neural networks, reward charateristics\nfor operators and skip connections have intrinsic differences, the assigned\nrewards for the skip connections are extremely noisy and inaccurate. To\nalleviate this problem, we propose a neural architecture refinement approach\nthat working with an initial state-of-the-art network structure and only\nrefining its operators. Extensive experiments have demonstrated that the\nproposed method can achieve fascinated results, including classification, face\nrecognition etc.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 03:41:12 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 06:13:43 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 02:04:20 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Jiang", "Yang", ""], ["Zhao", "Cong", ""], ["Dou", "Zeyang", ""], ["Pang", "Lei", ""]]}, {"id": "1905.02342", "submitter": "Nhan Duy Truong", "authors": "Nhan Duy Truong, Jing Yan Haw, Syed Muhamad Assad, Ping Koy Lam, Omid\n  Kavehei", "title": "Machine Learning Cryptanalysis of a Quantum Random Number Generator", "comments": "Accepted for publication in IEEE Transactions on Information\n  Forensics and Security. Related code is at\n  https://github.com/Nano-Neuro-Research-Lab/Machine-Learning-Cryptanalysis-of-a-Quantum-Random-Number-Generator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random number generators (RNGs) that are crucial for cryptographic\napplications have been the subject of adversarial attacks. These attacks\nexploit environmental information to predict generated random numbers that are\nsupposed to be truly random and unpredictable. Though quantum random number\ngenerators (QRNGs) are based on the intrinsic indeterministic nature of quantum\nproperties, the presence of classical noise in the measurement process\ncompromises the integrity of a QRNG. In this paper, we develop a predictive\nmachine learning (ML) analysis to investigate the impact of deterministic\nclassical noise in different stages of an optical continuous variable QRNG. Our\nML model successfully detects inherent correlations when the deterministic\nnoise sources are prominent. After appropriate filtering and randomness\nextraction processes are introduced, our QRNG system, in turn, demonstrates its\nrobustness against ML. We further demonstrate the robustness of our ML approach\nby applying it to uniformly distributed random numbers from the QRNG and a\ncongruential RNG. Hence, our result shows that ML has potentials in\nbenchmarking the quality of RNG devices.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 03:42:04 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 02:59:02 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Truong", "Nhan Duy", ""], ["Haw", "Jing Yan", ""], ["Assad", "Syed Muhamad", ""], ["Lam", "Ping Koy", ""], ["Kavehei", "Omid", ""]]}, {"id": "1905.02361", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Lina Yao, Feng Yuan", "title": "Adversarial Variational Embedding for Robust Semi-supervised Learning", "comments": "9 pages, Accepted by Research Track in KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330966", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is sought for leveraging the unlabelled data when\nlabelled data is difficult or expensive to acquire. Deep generative models\n(e.g., Variational Autoencoder (VAE)) and semisupervised Generative Adversarial\nNetworks (GANs) have recently shown promising performance in semi-supervised\nclassification for the excellent discriminative representing ability. However,\nthe latent code learned by the traditional VAE is not exclusive (repeatable)\nfor a specific input sample, which prevents it from excellent classification\nperformance. In particular, the learned latent representation depends on a\nnon-exclusive component which is stochastically sampled from the prior\ndistribution. Moreover, the semi-supervised GAN models generate data from\npre-defined distribution (e.g., Gaussian noises) which is independent of the\ninput data distribution and may obstruct the convergence and is difficult to\ncontrol the distribution of the generated data. To address the aforementioned\nissues, we propose a novel Adversarial Variational Embedding (AVAE) framework\nfor robust and effective semi-supervised learning to leverage both the\nadvantage of GAN as a high quality generative model and VAE as a posterior\ndistribution learner. The proposed approach first produces an exclusive latent\ncode by the model which we call VAE++, and meanwhile, provides a meaningful\nprior distribution for the generator of GAN. The proposed approach is evaluated\nover four different real-world applications and we show that our method\noutperforms the state-of-the-art models, which confirms that the combination of\nVAE++ and GAN can provide significant improvements in semisupervised\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 05:47:01 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 02:47:48 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Zhang", "Xiang", ""], ["Yao", "Lina", ""], ["Yuan", "Feng", ""]]}, {"id": "1905.02363", "submitter": "Youngchul Sung", "authors": "Seungyul Han, Youngchul Sung", "title": "Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient\n  Reinforcement Learning", "comments": "Accepted to the 36th International Conference on Machine Learning\n  (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In importance sampling (IS)-based reinforcement learning algorithms such as\nProximal Policy Optimization (PPO), IS weights are typically clipped to avoid\nlarge variance in learning. However, policy update from clipped statistics\ninduces large bias in tasks with high action dimensions, and bias from clipping\nmakes it difficult to reuse old samples with large IS weights. In this paper,\nwe consider PPO, a representative on-policy algorithm, and propose its\nimprovement by dimension-wise IS weight clipping which separately clips the IS\nweight of each action dimension to avoid large bias and adaptively controls the\nIS weight to bound policy update from the current policy. This new technique\nenables efficient learning for high action-dimensional tasks and reusing of old\nsamples like in off-policy learning to increase the sample efficiency.\nNumerical results show that the proposed new algorithm outperforms PPO and\nother RL algorithms in various Open AI Gym tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 05:53:11 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:09:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "1905.02367", "submitter": "Samson Zhou", "authors": "Dmitrii Avdiukhin, Slobodan Mitrovi\\'c, Grigory Yaroslavtsev, Samson\n  Zhou", "title": "Adversarially Robust Submodular Maximization under Knapsack Constraints", "comments": "To appear in KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first adversarially robust algorithm for monotone submodular\nmaximization under single and multiple knapsack constraints with scalable\nimplementations in distributed and streaming settings. For a single knapsack\nconstraint, our algorithm outputs a robust summary of almost optimal (up to\npolylogarithmic factors) size, from which a constant-factor approximation to\nthe optimal solution can be constructed. For multiple knapsack constraints, our\napproximation is within a constant-factor of the best known non-robust\nsolution.\n  We evaluate the performance of our algorithms by comparison to natural\nrobustifications of existing non-robust algorithms under two objectives: 1)\ndominating set for large social network graphs from Facebook and Twitter\ncollected by the Stanford Network Analysis Project (SNAP), 2) movie\nrecommendations on a dataset from MovieLens. Experimental results show that our\nalgorithms give the best objective for a majority of the inputs and show strong\nperformance even compared to offline algorithms that are given the set of\nremovals in advance.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:16:53 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Avdiukhin", "Dmitrii", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Yaroslavtsev", "Grigory", ""], ["Zhou", "Samson", ""]]}, {"id": "1905.02370", "submitter": "Takashi Wada", "authors": "Takashi Wada and Hideitsu Hino", "title": "Bayesian Optimization for Multi-objective Optimization and Multi-point\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is an effective method to efficiently optimize unknown\nobjective functions with high evaluation costs. Traditional Bayesian\noptimization algorithms select one point per iteration for single objective\nfunction, whereas in recent years, Bayesian optimization for multi-objective\noptimization or multi-point search per iteration have been proposed. However,\nBayesian optimization that can deal with them at the same time in non-heuristic\nway is not known at present. We propose a Bayesian optimization algorithm that\ncan deal with multi-objective optimization and multi-point search at the same\ntime. First, we define an acquisition function that considers both\nmulti-objective and multi-point search problems. It is difficult to\nanalytically maximize the acquisition function as the computational cost is\nprohibitive even when approximate calculations such as sampling approximation\nare performed; therefore, we propose an accurate and computationally efficient\nmethod for estimating gradient of the acquisition function, and develop an\nalgorithm for Bayesian optimization with multi-objective and multi-point\nsearch. It is shown via numerical experiments that the performance of the\nproposed method is comparable or superior to those of heuristic methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:27:27 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Wada", "Takashi", ""], ["Hino", "Hideitsu", ""]]}, {"id": "1905.02374", "submitter": "Julien Mairal", "authors": "Andrei Kulunchakov (Thoth), Julien Mairal (Thoth)", "title": "Estimate Sequences for Variance-Reduced Stochastic Composite\n  Optimization", "comments": "short version of preprint arXiv:1901.08788", "journal-ref": "International Conference on Machine Learning (ICML), Jun 2019,\n  Long Beach, United States", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unified view of gradient-based algorithms for\nstochastic convex composite optimization by extending the concept of estimate\nsequence introduced by Nesterov. This point of view covers the stochastic\ngradient descent method, variants of the approaches SAGA, SVRG, and has several\nadvantages: (i) we provide a generic proof of convergence for the\naforementioned methods; (ii) we show that this SVRG variant is adaptive to\nstrong convexity; (iii) we naturally obtain new algorithms with the same\nguarantees; (iv) we derive generic strategies to make these algorithms robust\nto stochastic noise, which is useful when data is corrupted by small random\nperturbations. Finally, we show that this viewpoint is useful to obtain new\naccelerated algorithms in the sense of Nesterov.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:41:24 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Kulunchakov", "Andrei", "", "Thoth"], ["Mairal", "Julien", "", "Thoth"]]}, {"id": "1905.02383", "submitter": "Jinshuo Dong", "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su", "title": "Gaussian Differential Privacy", "comments": "v2 revises introduction, adds discussion and fixes some\n  inconsistencies. v3 fixes typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has seen remarkable success as a rigorous and practical\nformalization of data privacy in the past decade. This privacy definition and\nits divergence based relaxations, however, have several acknowledged\nweaknesses, either in handling composition of private algorithms or in\nanalyzing important primitives like privacy amplification by subsampling.\nInspired by the hypothesis testing formulation of privacy, this paper proposes\na new relaxation, which we term `$f$-differential privacy' ($f$-DP). This\nnotion of privacy has a number of appealing properties and, in particular,\navoids difficulties associated with divergence based relaxations. First, $f$-DP\npreserves the hypothesis testing interpretation. In addition, $f$-DP allows for\nlossless reasoning about composition in an algebraic fashion. Moreover, we\nprovide a powerful technique to import existing results proven for original DP\nto $f$-DP and, as an application, obtain a simple subsampling theorem for\n$f$-DP.\n  In addition to the above findings, we introduce a canonical single-parameter\nfamily of privacy notions within the $f$-DP class that is referred to as\n`Gaussian differential privacy' (GDP), defined based on testing two shifted\nGaussians. GDP is focal among the $f$-DP class because of a central limit\ntheorem we prove. More precisely, the privacy guarantees of \\emph{any}\nhypothesis testing based definition of privacy (including original DP)\nconverges to GDP in the limit under composition. The CLT also yields a\ncomputationally inexpensive tool for analyzing the exact composition of private\nalgorithms.\n  Taken together, this collection of attractive properties render $f$-DP a\nmathematically coherent, analytically tractable, and versatile framework for\nprivate data analysis. Finally, we demonstrate the use of the tools we develop\nby giving an improved privacy analysis of noisy stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:57:19 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 17:48:32 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 23:51:04 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Dong", "Jinshuo", ""], ["Roth", "Aaron", ""], ["Su", "Weijie J.", ""]]}, {"id": "1905.02417", "submitter": "Sukarna Barua", "authors": "Sukarna Barua and Sarah Monazam Erfani and James Bailey", "title": "FCC-GAN: A Fully Connected and Convolutional Net Architecture for GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a powerful class of generative\nmodels. Despite their successes, the most appropriate choice of a GAN network\narchitecture is still not well understood. GAN models for image synthesis have\nadopted a deep convolutional network architecture, which eliminates or\nminimizes the use of fully connected and pooling layers in favor of convolution\nlayers in the generator and discriminator of GANs. In this paper, we\ndemonstrate that a convolution network architecture utilizing deep fully\nconnected layers and pooling layers can be more effective than the traditional\nconvolution-only architecture, and we propose FCC-GAN, a fully connected and\nconvolutional GAN architecture. Models based on our FCC-GAN architecture learn\nboth faster than the conventional architecture and also generate higher quality\nof samples. We demonstrate the effectiveness and stability of our approach\nacross four popular image datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:58:16 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 06:06:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Barua", "Sukarna", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""]]}, {"id": "1905.02438", "submitter": "George Constantinides", "authors": "George A. Constantinides", "title": "Rethinking Arithmetic for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2019.0051", "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider efficiency in the implementation of deep neural networks.\nHardware accelerators are gaining interest as machine learning becomes one of\nthe drivers of high-performance computing. In these accelerators, the directed\ngraph describing a neural network can be implemented as a directed graph\ndescribing a Boolean circuit. We make this observation precise, leading\nnaturally to an understanding of practical neural networks as discrete\nfunctions, and show that so-called binarised neural networks are functionally\ncomplete. In general, our results suggest that it is valuable to consider\nBoolean circuits as neural networks, leading to the question of which circuit\ntopologies are promising. We argue that continuity is central to generalisation\nin learning, explore the interaction between data coding, network topology, and\nnode functionality for continuity, and pose some open questions for future\nresearch. As a first step to bridging the gap between continuous and Boolean\nviews of neural network accelerators, we present some recent results from our\nwork on LUTNet, a novel Field-Programmable Gate Array inference approach.\nFinally, we conclude with additional possible fruitful avenues for research\nbridging the continuous and discrete views of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 09:36:48 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 14:00:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Constantinides", "George A.", ""]]}, {"id": "1905.02448", "submitter": "Yehia Elkhatib PhD", "authors": "Faiza Samreen, Gordon S Blair, Yehia Elkhatib", "title": "Transferable Knowledge for Low-cost Decision Making in Cloud\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of cloud computing are increasingly overwhelmed with the wide range of\nproviders and services offered by each provider. As such, many users select\ncloud services based on description alone. An emerging alternative is to use a\ndecision support system (DSS), which typically relies on gaining insights from\nobservational data in order to assist a customer in making decisions regarding\noptimal deployment or redeployment of cloud applications. The primary activity\nof such systems is the generation of a prediction model (e.g. using machine\nlearning), which requires a significantly large amount of training data.\nHowever, considering the varying architectures of applications, cloud\nproviders, and cloud offerings, this activity is not sustainable as it incurs\nadditional time and cost to collect training data and subsequently train the\nmodels. We overcome this through developing a Transfer Learning (TL) approach\nwhere the knowledge (in the form of the prediction model and associated data\nset) gained from running an application on a particular cloud infrastructure is\ntransferred in order to substantially reduce the overhead of building new\nmodels for the performance of new applications and/or cloud infrastructures. In\nthis paper, we present our approach and evaluate it through extensive\nexperimentation involving three real world applications over two major public\ncloud providers, namely Amazon and Google. Our evaluation shows that our novel\ntwo-mode TL scheme increases overall efficiency with a factor of 60\\% reduction\nin the time and cost of generating a new prediction model. We test this under a\nnumber of cross-application and cross-cloud scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:08:19 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Samreen", "Faiza", ""], ["Blair", "Gordon S", ""], ["Elkhatib", "Yehia", ""]]}, {"id": "1905.02450", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation", "comments": "Accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training and fine-tuning, e.g., BERT, have achieved great success in\nlanguage understanding by transferring knowledge from rich-resource\npre-training task to the low/zero-resource downstream tasks. Inspired by the\nsuccess of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for\nthe encoder-decoder based language generation tasks. MASS adopts the\nencoder-decoder framework to reconstruct a sentence fragment given the\nremaining part of the sentence: its encoder takes a sentence with randomly\nmasked fragment (several consecutive tokens) as input, and its decoder tries to\npredict this masked fragment. In this way, MASS can jointly train the encoder\nand decoder to develop the capability of representation extraction and language\nmodeling. By further fine-tuning on a variety of zero/low-resource language\ngeneration tasks, including neural machine translation, text summarization and\nconversational response generation (3 tasks and totally 8 datasets), MASS\nachieves significant improvements over the baselines without pre-training or\nwith other pre-training methods. Specially, we achieve the state-of-the-art\naccuracy (37.5 in terms of BLEU score) on the unsupervised English-French\ntranslation, even beating the early attention-based supervised model.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:13:04 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 06:46:26 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 11:43:27 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 03:43:41 GMT"}, {"version": "v5", "created": "Fri, 21 Jun 2019 04:36:52 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Lu", "Jianfeng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.02463", "submitter": "Isaac Dunn", "authors": "Isaac Dunn, Hadrien Pouget, Tom Melham, Daniel Kroening", "title": "Adaptive Generation of Unrestricted Adversarial Inputs", "comments": "Updated to include new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarially-constructed perturbations of\ntheir inputs. Most research so far has considered perturbations of a fixed\nmagnitude under some $l_p$ norm. Although studying these attacks is valuable,\nthere has been increasing interest in the construction of (and robustness to)\nunrestricted attacks, which are not constrained to a small and rather\nartificial subset of all possible adversarial inputs. We introduce a novel\nalgorithm for generating such unrestricted adversarial inputs which, unlike\nprior work, is adaptive: it is able to tune its attacks to the classifier being\ntargeted. It also offers a 400-2,000x speedup over the existing state of the\nart. We demonstrate our approach by generating unrestricted adversarial inputs\nthat fool classifiers robust to perturbation-based attacks. We also show that,\nby virtue of being adaptive and unrestricted, our attack is able to defeat\nadversarial training against it.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:54:43 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:43:55 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Dunn", "Isaac", ""], ["Pouget", "Hadrien", ""], ["Melham", "Tom", ""], ["Kroening", "Daniel", ""]]}, {"id": "1905.02486", "submitter": "Anush Sankaran", "authors": "Srikanth Tamilselvam, Naveen Panwar, Shreya Khare, Rahul Aralikatte,\n  Anush Sankaran, Senthil Mani", "title": "A Visual Programming Paradigm for Abstract Deep Learning Model\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is one of the fastest growing technologies in computer science\nwith a plethora of applications. But this unprecedented growth has so far been\nlimited to the consumption of deep learning experts. The primary challenge\nbeing a steep learning curve for learning the programming libraries and the\nlack of intuitive systems enabling non-experts to consume deep learning.\nTowards this goal, we study the effectiveness of a no-code paradigm for\ndesigning deep learning models. Particularly, a visual drag-and-drop interface\nis found more efficient when compared with the traditional programming and\nalternative visual programming paradigms. We conduct user studies of different\nexpertise levels to measure the entry level barrier and the developer load\nacross different programming paradigms. We obtain a System Usability Scale\n(SUS) of 90 and a NASA Task Load index (TLX) score of 21 for the proposed\nvisual programming compared to 68 and 52, respectively, for the traditional\nprogramming methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 11:54:20 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 17:24:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tamilselvam", "Srikanth", ""], ["Panwar", "Naveen", ""], ["Khare", "Shreya", ""], ["Aralikatte", "Rahul", ""], ["Sankaran", "Anush", ""], ["Mani", "Senthil", ""]]}, {"id": "1905.02494", "submitter": "Felix Axel Gimeno Gil", "authors": "Aditya Paliwal, Felix Gimeno, Vinod Nair, Yujia Li, Miles Lubin,\n  Pushmeet Kohli, Oriol Vinyals", "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "comments": "Accepted to ICLR 2020 https://openreview.net/forum?id=rkxDoJBYPB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep reinforcement learning approach to minimizing the execution\ncost of neural network computation graphs in an optimizing compiler. Unlike\nearlier learning-based works that require training the optimizer on the same\ngraph to be optimized, we propose a learning approach that trains an optimizer\noffline and then generalizes to previously unseen graphs without further\ntraining. This allows our approach to produce high-quality execution decisions\non real-world TensorFlow graphs in seconds instead of hours. We consider two\noptimization tasks for computation graphs: minimizing running time and peak\nmemory usage. In comparison to an extensive set of baselines, our approach\nachieves significant improvements over classical and other learning-based\nmethods on these two tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:15:06 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:07:27 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 17:52:11 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 11:57:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Paliwal", "Aditya", ""], ["Gimeno", "Felix", ""], ["Nair", "Vinod", ""], ["Li", "Yujia", ""], ["Lubin", "Miles", ""], ["Kohli", "Pushmeet", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1905.02495", "submitter": "Christos Liaskos K.", "authors": "Christos Liaskos, Ageliki Tsioliaridou, Shuai Nie, Andreas\n  Pitsillides, Sotiris Ioannidis, Ian Akyildiz", "title": "An Interpretable Neural Network for Configuring Programmable Wireless\n  Environments", "comments": "In proceedings of IEEE SPAWC 2019 - Special Session on Signal\n  Processing Advances for Emerging Transceiver Hardware. This work was funded\n  by the European Union via the Horizon 2020: Future Emerging Topics call\n  (FETOPEN), grant EU736876, project VISORSURF (http://www.visorsurf.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined metasurfaces (SDMs) comprise a dense topology of basic\nelements called meta-atoms, exerting the highest degree of control over surface\ncurrents among intelligent panel technologies. As such, they can transform\nimpinging electromagnetic (EM) waves in complex ways, modifying their\ndirection, power, frequency spectrum, polarity and phase. A well-defined\nsoftware interface allows for applying such functionalities to waves and\ninter-networking SDMs, while abstracting the underlying physics. A network of\nSDMs deployed over objects within an area, such as a floorplan walls, creates\nprogrammable wireless environments (PWEs) with fully customizable propagation\nof waves within them. This work studies the use of machine learning for\nconfiguring such environments to the benefit of users within. The methodology\nconsists of modeling wireless propagation as a custom, interpretable,\nback-propagating neural network, with SDM elements as nodes and their\ncross-interactions as links. Following a training period the network learns the\npropagation basics of SDMs and configures them to facilitate the communication\nof users within their vicinity.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:19:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Liaskos", "Christos", ""], ["Tsioliaridou", "Ageliki", ""], ["Nie", "Shuai", ""], ["Pitsillides", "Andreas", ""], ["Ioannidis", "Sotiris", ""], ["Akyildiz", "Ian", ""]]}, {"id": "1905.02506", "submitter": "Burak Uzkent", "authors": "Burak Uzkent, Evan Sheehan, Chenlin Meng, Zhongyi Tang, Marshall\n  Burke, David Lobell, Stefano Ermon", "title": "Learning to Interpret Satellite Images in Global Scale Using Wikipedia", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in computer vision, finegrained interpretation of\nsatellite images remains challenging because of a lack of labeled training\ndata. To overcome this limitation, we construct a novel dataset called\nWikiSatNet by pairing georeferenced Wikipedia articles with satellite imagery\nof their corresponding locations. We then propose two strategies to learn\nrepresentations of satellite images by predicting properties of the\ncorresponding articles from the images. Leveraging this new multi-modal\ndataset, we can drastically reduce the quantity of human-annotated labels and\ntime required for downstream tasks. On the recently released fMoW dataset, our\npre-training strategies can boost the performance of a model pre-trained on\nImageNet by up to 4:5% in F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:47:39 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 08:02:01 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2019 21:56:27 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Uzkent", "Burak", ""], ["Sheehan", "Evan", ""], ["Meng", "Chenlin", ""], ["Tang", "Zhongyi", ""], ["Burke", "Marshall", ""], ["Lobell", "David", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.02515", "submitter": "Kai Puolamaki", "authors": "Kai Puolam\\\"aki, Emilia Oikarinen, Andreas Henelius", "title": "Guided Visual Exploration of Relations in Data Sets", "comments": "32 pages, 13 figures. This article extends arXiv:1804.03194 and\n  arXiv:1805.07725", "journal-ref": "Journal of Machine Learning Research 22(96):1-32, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient explorative data analysis systems must take into account both what\na user knows and wants to know. This paper proposes a principled framework for\ninteractive visual exploration of relations in data, through views most\ninformative given the user's current knowledge and objectives. The user can\ninput pre-existing knowledge of relations in the data and also formulate\nspecific exploration interests, which are then taken into account in the\nexploration. The idea is to steer the exploration process towards the interests\nof the user, instead of showing uninteresting or already known relations. The\nuser's knowledge is modelled by a distribution over data sets parametrised by\nsubsets of rows and columns of data, called tile constraints. We provide a\ncomputationally efficient implementation of this concept based on constrained\nrandomisation. Furthermore, we describe a novel dimensionality reduction method\nfor finding the views most informative to the user, which at the limit of no\nbackground knowledge and with generic objectives reduces to PCA. We show that\nthe method is suitable for interactive use and is robust to noise, outperforms\nstandard projection pursuit visualisation methods, and gives understandable and\nuseful results in analysis of real-world data. We provide an open-source\nimplementation of the framework.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:57:59 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 05:54:21 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 08:49:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Puolam\u00e4ki", "Kai", ""], ["Oikarinen", "Emilia", ""], ["Henelius", "Andreas", ""]]}, {"id": "1905.02530", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim", "title": "Deep Learning to Predict Student Outcomes", "comments": "Accepted as oral presentation to ICLR 2019, AI for Social Good\n  Workshop. arXiv admin note: substantial text overlap with arXiv:1809.06686,\n  arXiv:1804.07405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly fast development cycle for online course contents, along\nwith the diverse student demographics in each online classroom, make real-time\nstudent outcomes prediction an interesting topic for both industrial research\nand practical needs. In this paper, we tackle the problem of real-time student\nperformance prediction in an on-going course using a domain adaptation\nframework. This framework is a system trained on labeled student outcome data\nfrom previous coursework but is meant to be deployed on another course. In\nparticular, we introduce a GritNet architecture, and develop an unsupervised\ndomain adaptation method to transfer a GritNet trained on a past course to a\nnew course without any student outcome label. Our results for real Udacity\nstudent graduation predictions show that the GritNet not only generalizes well\nfrom one course to another across different Nanodegree programs, but also\nenhances real-time predictions explicitly in the first few weeks when accurate\npredictions are most challenging.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 07:37:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Kim", "Byung-Hak", ""]]}, {"id": "1905.02534", "submitter": "Florian Stelzer", "authors": "Florian Stelzer, Andr\\'e R\\\"ohm, Kathy L\\\"udge, Serhiy Yanchuk", "title": "Performance boost of time-delay reservoir computing by non-resonant\n  clock cycle", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.01.010", "report-no": null, "categories": "nlin.AO cs.LG cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time-delay-based reservoir computing setup has seen tremendous success in\nboth experiment and simulation. It allows for the construction of large\nneuromorphic computing systems with only few components. However, until now the\ninterplay of the different timescales has not been investigated thoroughly. In\nthis manuscript, we investigate the effects of a mismatch between the\ntime-delay and the clock cycle for a general model. Typically, these two time\nscales are considered to be equal. Here we show that the case of equal or\nresonant time-delay and clock cycle could be actively detrimental and leads to\nan increase of the approximation error of the reservoir. In particular, we can\nshow that non-resonant ratios of these time scales have maximal memory\ncapacities. We achieve this by translating the periodically driven\ndelay-dynamical system into an equivalent network. Networks that originate from\na system with resonant delay-times and clock cycles fail to utilize all of\ntheir degrees of freedom, which causes the degradation of their performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:18:14 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 14:06:21 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Stelzer", "Florian", ""], ["R\u00f6hm", "Andr\u00e9", ""], ["L\u00fcdge", "Kathy", ""], ["Yanchuk", "Serhiy", ""]]}, {"id": "1905.02535", "submitter": "Masaaki Okabe", "authors": "Masaaki Okabe, Jun Tsuchida, Hiroshi Yadohisa", "title": "F-measure Maximizing Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is a widely used method in several fields. When applying\nlogistic regression to imbalanced data, for which majority classes dominate\nover minority classes, all class labels are estimated as `majority class.' In\nthis article, we use an F-measure optimization method to improve the\nperformance of logistic regression applied to imbalanced data. While many\nF-measure optimization methods adopt a ratio of the estimators to approximate\nthe F-measure, the ratio of the estimators tends to have more bias than when\nthe ratio is directly approximated. Therefore, we employ an approximate\nF-measure for estimating the relative density ratio. In addition, we define a\nrelative F-measure and approximate the relative F-measure. We show an algorithm\nfor a logistic regression weighted approximated relative to the F-measure. The\nexperimental results using real world data demonstrated that our proposed\nmethod is an efficient algorithm to improve the performance of logistic\nregression applied to imbalanced data.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:18:22 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Okabe", "Masaaki", ""], ["Tsuchida", "Jun", ""], ["Yadohisa", "Hiroshi", ""]]}, {"id": "1905.02541", "submitter": "Jing Zhang", "authors": "Jing Zhang, Hengtao He, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li", "title": "Deep Learning Based on Orthogonal Approximate Message Passing for\n  CP-Free OFDM", "comments": "5 pages, 4 figures, updated manuscript, International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP 2019). arXiv admin note:\n  substantial text overlap with arXiv:1903.04766", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682639", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel estimation and signal detection are very challenging for an\northogonal frequency division multiplexing (OFDM) system without cyclic prefix\n(CP). In this article, deep learning based on orthogonal approximate message\npassing (DL-OAMP) is used to address these problems. The DL-OAMP receiver\nincludes a channel estimation neural network (CE-Net) and a signal detection\nneural network based on OAMP, called OAMP-Net. The CE-Net is initialized by the\nleast square channel estimation algorithm and refined by minimum mean-squared\nerror (MMSE) neural network. The OAMP-Net is established by unfolding the\niterative OAMP algorithm and adding some trainable parameters to improve the\ndetection performance. The DL-OAMP receiver is with low complexity and can\nestimate time-varying channels with only a single training. Simulation results\ndemonstrate that the bit-error rate (BER) of the proposed scheme is lower than\nthose of competitive algorithms for high-order modulation.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:26:06 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Zhang", "Jing", ""], ["He", "Hengtao", ""], ["Wen", "Chao-Kai", ""], ["Jin", "Shi", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1905.02544", "submitter": "Yaroub Elloumi", "authors": "Yaroub Elloumi (LIGM), Mohamed Akil (LIGM), Henda Boudegga", "title": "Ocular Diseases Diagnosis in Fundus Images using a Deep Learning:\n  Approaches, tools and Performance evaluation", "comments": null, "journal-ref": "SPIE Real-Time Image Processing and Deep Learning, Apr 2019,\n  Baltimore, Maryland, United States", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ocular pathology detection from fundus images presents an important challenge\non health care. In fact, each pathology has different severity stages that may\nbe deduced by verifying the existence of specific lesions. Each lesion is\ncharacterized by morphological features. Moreover, several lesions of different\npathologies have similar features. We note that patient may be affected\nsimultaneously by several pathologies. Consequently, the ocular pathology\ndetection presents a multi-class classification with a complex resolution\nprinciple. Several detection methods of ocular pathologies from fundus images\nhave been proposed. The methods based on deep learning are distinguished by\nhigher performance detection, due to their capability to configure the network\nwith respect to the detection objective. This work proposes a survey of ocular\npathology detection methods based on deep learning. First, we study the\nexisting methods either for lesion segmentation or pathology classification.\nAfterwards, we extract the principle steps of processing and we analyze the\nproposed neural network structures. Subsequently, we identify the hardware and\nsoftware environment required to employ the deep learning architecture.\nThereafter, we investigate about the experimentation principles involved to\nevaluate the methods and the databases used either for training and testing\nphases. The detection performance ratios and execution times are also reported\nand discussed.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:21:01 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Elloumi", "Yaroub", "", "LIGM"], ["Akil", "Mohamed", "", "LIGM"], ["Boudegga", "Henda", ""]]}, {"id": "1905.02576", "submitter": "Omer Ben-Porat", "authors": "Omer Ben-Porat, Moshe Tennenholtz", "title": "Regression Equilibrium", "comments": "This paper was published in the twentieth ACM conference on Economics\n  and Computation (ACM EC 19). arXiv admin note: substantial text overlap with\n  arXiv:1806.01703", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction is a well-studied machine learning task, and prediction algorithms\nare core ingredients in online products and services. Despite their centrality\nin the competition between online companies who offer prediction-based\nproducts, the \\textit{strategic} use of prediction algorithms remains\nunexplored. The goal of this paper is to examine strategic use of prediction\nalgorithms. We introduce a novel game-theoretic setting that is based on the\nPAC learning framework, where each player (aka a prediction algorithm aimed at\ncompetition) seeks to maximize the sum of points for which it produces an\naccurate prediction and the others do not. We show that algorithms aiming at\ngeneralization may wittingly mispredict some points to perform better than\nothers on expectation. We analyze the empirical game, i.e., the game induced on\na given sample, prove that it always possesses a pure Nash equilibrium, and\nshow that every better-response learning process converges. Moreover, our\nlearning-theoretic analysis suggests that players can, with high probability,\nlearn an approximate pure Nash equilibrium for the whole population using a\nsmall number of samples.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 13:00:42 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ben-Porat", "Omer", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "1905.02599", "submitter": "Hiske Overweg", "authors": "Hiske Overweg, Anna-Lena Popkes, Ari Ercole, Yingzhen Li, Jos\\'e\n  Miguel Hern\\'andez-Lobato, Yordan Zaykov, Cheng Zhang", "title": "Interpretable Outcome Prediction with Sparse Bayesian Neural Networks in\n  Intensive Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical decision making is challenging because of pathological complexity,\nas well as large amounts of heterogeneous data generated as part of routine\nclinical care. In recent years, machine learning tools have been developed to\naid this process. Intensive care unit (ICU) admissions represent the most data\ndense and time-critical patient care episodes. In this context, prediction\nmodels may help clinicians determine which patients are most at risk and\nprioritize care. However, flexible tools such as artificial neural networks\n(ANNs) suffer from a lack of interpretability limiting their acceptability to\nclinicians. In this work, we propose a novel interpretable Bayesian neural\nnetwork architecture which offers both the flexibility of ANNs and\ninterpretability in terms of feature selection. In particular, we employ a\nsparsity inducing prior distribution in a tied manner to learn which features\nare important for outcome prediction. We evaluate our approach on the task of\nmortality prediction using two real-world ICU cohorts. In collaboration with\nclinicians we found that, in addition to the predicted outcome results, our\napproach can provide novel insights into the importance of different clinical\nmeasurements. This suggests that our model can support medical experts in their\ndecision making process.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:16:04 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:59:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Overweg", "Hiske", ""], ["Popkes", "Anna-Lena", ""], ["Ercole", "Ari", ""], ["Li", "Yingzhen", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Zaykov", "Yordan", ""], ["Zhang", "Cheng", ""]]}, {"id": "1905.02607", "submitter": "Wen Dong", "authors": "Wen Dong and Tong Guan and Bruno Lepri and Chunming Qiao", "title": "PocketCare: Tracking the Flu with Mobile Phones using Partial\n  Observations of Proximity and Symptoms", "comments": null, "journal-ref": null, "doi": "10.1145/3328912", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones provide a powerful sensing platform that researchers may adopt\nto understand proximity interactions among people and the diffusion, through\nthese interactions, of diseases, behaviors, and opinions. However, it remains a\nchallenge to track the proximity-based interactions of a whole community and\nthen model the social diffusion of diseases and behaviors starting from the\nobservations of a small fraction of the volunteer population. In this paper, we\npropose a novel approach that tries to connect together these sparse\nobservations using a model of how individuals interact with each other and how\nsocial interactions happen in terms of a sequence of proximity interactions. We\napply our approach to track the spreading of flu in the spatial-proximity\nnetwork of a 3000-people university campus by mobilizing 300 volunteers from\nthis population to monitor nearby mobile phones through Bluetooth scanning and\nto daily report flu symptoms about and around them. Our aim is to predict the\nlikelihood for an individual to get flu based on how often her/his daily\nroutine intersects with those of the volunteers. Thus, we use the daily\nroutines of the volunteers to build a model of the volunteers as well as of the\nnon-volunteers. Our results show that we can predict flu infection two weeks\nahead of time with an average precision from 0.24 to 0.35 depending on the\namount of information. This precision is six to nine times higher than with a\nrandom guess model. At the population level, we can predict infectious\npopulation in a two-week window with an r-squared value of 0.95 (a random-guess\nmodel obtains an r-squared value of 0.2). These results point to an innovative\napproach for tracking individuals who have interacted with people showing\nsymptoms, allowing us to warn those in danger of infection and to inform health\nresearchers about the progression of contact-induced diseases.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:27:05 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Dong", "Wen", ""], ["Guan", "Tong", ""], ["Lepri", "Bruno", ""], ["Qiao", "Chunming", ""]]}, {"id": "1905.02610", "submitter": "Chunxu Zhang", "authors": "Chunxu Zhang and Jiaxu Cui and Bo Yang", "title": "Learning Optimal Data Augmentation Policies via Bayesian Optimization\n  for Image Classification Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has achieved remarkable achievements in many\nfields, including computer vision, natural language processing, speech\nrecognition and others. Adequate training data is the key to ensure the\neffectiveness of the deep models. However, obtaining valid data requires a lot\nof time and labor resources. Data augmentation (DA) is an effective alternative\napproach, which can generate new labeled data based on existing data using\nlabel-preserving transformations. Although we can benefit a lot from DA,\ndesigning appropriate DA policies requires a lot of expert experience and time\nconsumption, and the evaluation of searching the optimal policies is costly. So\nwe raise a new question in this paper: how to achieve automated data\naugmentation at as low cost as possible? We propose a method named BO-Aug for\nautomating the process by finding the optimal DA policies using the Bayesian\noptimization approach. Our method can find the optimal policies at a relatively\nlow search cost, and the searched policies based on a specific dataset are\ntransferable across different neural network architectures or even different\ndatasets. We validate the BO-Aug on three widely used image classification\ndatasets, including CIFAR-10, CIFAR-100 and SVHN. Experimental results show\nthat the proposed method can achieve state-of-the-art or near advanced\nclassification accuracy. Code to reproduce our experiments is available at\nhttps://github.com/zhangxiaozao/BO-Aug.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 15:49:02 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 04:50:16 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhang", "Chunxu", ""], ["Cui", "Jiaxu", ""], ["Yang", "Bo", ""]]}, {"id": "1905.02616", "submitter": "Sakshi Mishra", "authors": "Sakshi Mishra, Praveen Palanisamy", "title": "An Integrated Multi-Time-Scale Modeling for Solar Irradiance Forecasting\n  Using Deep Learning", "comments": "19 pages, 12 figures, 3 tables, under review for journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For short-term solar irradiance forecasting, the traditional point\nforecasting methods are rendered less useful due to the non-stationary\ncharacteristic of solar power. The amount of operating reserves required to\nmaintain reliable operation of the electric grid rises due to the variability\nof solar energy. The higher the uncertainty in the generation, the greater the\noperating-reserve requirements, which translates to an increased cost of\noperation. In this research work, we propose a unified architecture for\nmulti-time-scale predictions for intra-day solar irradiance forecasting using\nrecurrent neural networks (RNN) and long-short-term memory networks (LSTMs).\nThis paper also lays out a framework for extending this modeling approach to\nintra-hour forecasting horizons thus, making it a multi-time-horizon\nforecasting approach, capable of predicting intra-hour as well as intra-day\nsolar irradiance. We develop an end-to-end pipeline to effectuate the proposed\narchitecture. The performance of the prediction model is tested and validated\nby the methodical implementation. The robustness of the approach is\ndemonstrated with case studies conducted for geographically scattered sites\nacross the United States. The predictions demonstrate that our proposed unified\narchitecture-based approach is effective for multi-time-scale solar forecasts\nand achieves a lower root-mean-square prediction error when benchmarked against\nthe best-performing methods documented in the literature that use separate\nmodels for each time-scale during the day. Our proposed method results in a\n71.5% reduction in the mean RMSE averaged across all the test sites compared to\nthe ML-based best-performing method reported in the literature. Additionally,\nthe proposed method enables multi-time-horizon forecasts with real-time inputs,\nwhich have a significant potential for practical industry applications in the\nevolving grid.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:40:32 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 23:00:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mishra", "Sakshi", ""], ["Palanisamy", "Praveen", ""]]}, {"id": "1905.02636", "submitter": "Sam Blakeman", "authors": "Sam Blakeman and Denis Mareschal", "title": "A Complementary Learning Systems Approach to Temporal Difference\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementary Learning Systems (CLS) theory suggests that the brain uses a\n'neocortical' and a 'hippocampal' learning system to achieve complex behavior.\nThese two systems are complementary in that the 'neocortical' system relies on\nslow learning of distributed representations while the 'hippocampal' system\nrelies on fast learning of pattern-separated representations. Both of these\nsystems project to the striatum, which is a key neural structure in the brain's\nimplementation of Reinforcement Learning (RL). Current deep RL approaches share\nsimilarities with a 'neocortical' system because they slowly learn distributed\nrepresentations through backpropagation in Deep Neural Networks (DNNs). An\nongoing criticism of such approaches is that they are data inefficient and lack\nflexibility. CLS theory suggests that the addition of a 'hippocampal' system\ncould address these criticisms. In the present study we propose a novel\nalgorithm known as Complementary Temporal Difference Learning (CTDL), which\ncombines a DNN with a Self-Organising Map (SOM) to obtain the benefits of both\na 'neocortical' and a 'hippocampal' system. Key features of CTDL include the\nuse of Temporal Difference (TD) error to update a SOM and the combination of a\nSOM and DNN to calculate action values. We evaluate CTDL on grid worlds and the\nCart-Pole environment, and show several benefits over the classic Deep\nQ-Network (DQN) approach. These results demonstrate (1) the utility of\ncomplementary learning systems for the evaluation of actions, (2) that the TD\nerror signal is a useful form of communication between the two systems and (3)\nthe biological plausibility of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:17:20 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Blakeman", "Sam", ""], ["Mareschal", "Denis", ""]]}, {"id": "1905.02649", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Rong Xiao, Jianfeng Wang, Thomas Huang, Lei Zhang", "title": "High Frequency Residual Learning for Multi-Scale Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel high frequency residual learning framework, which leads to\na highly efficient multi-scale network (MSNet) architecture for mobile and\nembedded vision problems. The architecture utilizes two networks: a low\nresolution network to efficiently approximate low frequency components and a\nhigh resolution network to learn high frequency residuals by reusing the\nupsampled low resolution features. With a classifier calibration module, MSNet\ncan dynamically allocate computation resources during inference to achieve a\nbetter speed and accuracy trade-off. We evaluate our methods on the challenging\nImageNet-1k dataset and observe consistent improvements over different base\nnetworks. On ResNet-18 and MobileNet with alpha=1.0, MSNet gains 1.5% accuracy\nover both architectures without increasing computations. On the more efficient\nMobileNet with alpha=0.25, our method gains 3.8% accuracy with the same amount\nof computations.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:47:27 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Cheng", "Bowen", ""], ["Xiao", "Rong", ""], ["Wang", "Jianfeng", ""], ["Huang", "Thomas", ""], ["Zhang", "Lei", ""]]}, {"id": "1905.02662", "submitter": "Mikhail Burtsev", "authors": "Artyom Y. Sorokin and Mikhail S. Burtsev", "title": "Continual and Multi-task Reinforcement Learning With Shared Episodic\n  Memory", "comments": "Presented at the Task-Agnostic Reinforcement Learning Workshop at\n  ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic memory plays an important role in the behavior of animals and\nhumans. It allows the accumulation of information about current state of the\nenvironment in a task-agnostic way. This episodic representation can be later\naccessed by down-stream tasks in order to make their execution more efficient.\nIn this work, we introduce the neural architecture with shared episodic memory\n(SEM) for learning and the sequential execution of multiple tasks. We\nexplicitly split the encoding of episodic memory and task-specific memory into\nseparate recurrent sub-networks. An agent augmented with SEM was able to\neffectively reuse episodic knowledge collected during other tasks to improve\nits policy on a current task in the Taxi problem. Repeated use of episodic\nrepresentation in continual learning experiments facilitated acquisition of\nnovel skills in the same environment.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:08:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Sorokin", "Artyom Y.", ""], ["Burtsev", "Mikhail S.", ""]]}, {"id": "1905.02675", "submitter": "Todor Davchev", "authors": "Todor Davchev, Timos Korres, Stathi Fotiadis, Nick Antonopoulos,\n  Subramanian Ramamoorthy", "title": "An Empirical Evaluation of Adversarial Robustness under Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we evaluate adversarial robustness in the context of transfer\nlearning from a source trained on CIFAR 100 to a target network trained on\nCIFAR 10. Specifically, we study the effects of using robust optimisation in\nthe source and target networks. This allows us to identify transfer learning\nstrategies under which adversarial defences are successfully retained, in\naddition to revealing potential vulnerabilities. We study the extent to which\nfeatures learnt by a fast gradient sign method (FGSM) and its iterative\nalternative (PGD) can preserve their defence properties against black and\nwhite-box attacks under three different transfer learning strategies. We find\nthat using PGD examples during training on the source task leads to more\ngeneral robust features that are easier to transfer. Furthermore, under\nsuccessful transfer, it achieves 5.2% more accuracy against white-box PGD\nattacks than suitable baselines. Overall, our empirical evaluations give\ninsights on how well adversarial robustness under transfer learning can\ngeneralise.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:26:26 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 00:34:28 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 09:37:44 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 22:25:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Davchev", "Todor", ""], ["Korres", "Timos", ""], ["Fotiadis", "Stathi", ""], ["Antonopoulos", "Nick", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1905.02680", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Katherine Driggs-Campbell, Krister Wolff, Leo Laine,\n  Mykel J. Kochenderfer", "title": "Combining Planning and Deep Reinforcement Learning in Tactical Decision\n  Making for Autonomous Driving", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Vehicles, 2019", "doi": "10.1109/TIV.2019.2955905", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactical decision making for autonomous driving is challenging due to the\ndiversity of environments, the uncertainty in the sensor information, and the\ncomplex interaction with other road users. This paper introduces a general\nframework for tactical decision making, which combines the concepts of planning\nand learning, in the form of Monte Carlo tree search and deep reinforcement\nlearning. The method is based on the AlphaGo Zero algorithm, which is extended\nto a domain with a continuous state space where self-play cannot be used. The\nframework is applied to two different highway driving cases in a simulated\nenvironment and it is shown to perform better than a commonly used baseline\nmethod. The strength of combining planning and learning is also illustrated by\na comparison to using the Monte Carlo tree search or the neural network policy\nseparately.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:50:14 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Driggs-Campbell", "Katherine", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1905.02681", "submitter": "Armel Jacques Nzekon Nzeko'o", "authors": "Armel Jacques Nzekon Nzeko'o, Maurice Tchuente, Matthieu Latapy", "title": "A general graph-based framework for top-N recommendation using content,\n  temporal and trust information", "comments": "27 pages", "journal-ref": "Journal of Interdisciplinary Methodologies and Issues in Sciences,\n  2019", "doi": "10.18713/JIMIS-300519-5-2", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending appropriate items to users is crucial in many e-commerce\nplatforms that contain implicit data as users' browsing, purchasing and\nstreaming history. One common approach consists in selecting the N most\nrelevant items to each user, for a given N, which is called top-N\nrecommendation. To do so, recommender systems rely on various kinds of\ninformation, like item and user features, past interest of users for items,\nbrowsing history and trust between users. However, they often use only one or\ntwo such pieces of information, which limits their performance. In this paper,\nwe design and implement GraFC2T2, a general graph-based framework to easily\ncombine and compare various kinds of side information for top-N recommendation.\nIt encodes content-based features, temporal and trust information into a\ncomplex graph, and uses personalized PageRank on this graph to perform\nrecommendation. We conduct experiments on Epinions and Ciao datasets, and\ncompare obtained performances using F1-score, Hit ratio and MAP evaluation\nmetrics, to systems based on matrix factorization and deep learning. This shows\nthat our framework is convenient for such explorations, and that combining\ndifferent kinds of information indeed improves recommendation in general.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:52:44 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Nzeko'o", "Armel Jacques Nzekon", ""], ["Tchuente", "Maurice", ""], ["Latapy", "Matthieu", ""]]}, {"id": "1905.02685", "submitter": "Vu Nguyen", "authors": "Vu Nguyen and Michael A. Osborne", "title": "Knowing The What But Not The Where in Bayesian Optimization", "comments": "16 pages", "journal-ref": "International Conference on Machine Learning (ICML) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has demonstrated impressive success in finding the\noptimum input x* and output f* = f(x*) = max f(x) of a black-box function f. In\nsome applications, however, the optimum output f* is known in advance and the\ngoal is to find the corresponding optimum input x*. In this paper, we consider\na new setting in BO in which the knowledge of the optimum output f* is\navailable. Our goal is to exploit the knowledge about f* to search for the\ninput x* efficiently. To achieve this goal, we first transform the Gaussian\nprocess surrogate using the information about the optimum output. Then, we\npropose two acquisition functions, called confidence bound minimization and\nexpected regret minimization. We show that our approaches work intuitively and\ngive quantitatively better performance against standard BO methods. We\ndemonstrate real applications in tuning a deep reinforcement learning algorithm\non the CartPole problem and XGBoost on Skin Segmentation dataset in which the\noptimum values are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:42:01 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 21:33:09 GMT"}, {"version": "v3", "created": "Sat, 11 May 2019 09:22:13 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 15:24:01 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 21:47:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Nguyen", "Vu", ""], ["Osborne", "Michael A.", ""]]}, {"id": "1905.02691", "submitter": "Patrick M. Pilarski", "authors": "Patrick M. Pilarski, Andrew Butcher, Michael Johanson, Matthew M.\n  Botvinick, Andrew Bolt, Adam S. R. Parker", "title": "Learned human-agent decision-making, communication and joint action in a\n  virtual reality environment", "comments": "5 pages, 3 figures. Accepted to The 4th Multidisciplinary Conference\n  on Reinforcement Learning and Decision Making, July 7-10, 2019, McGill\n  University, Montreal, Quebec, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans make decisions and act alongside other humans to pursue both\nshort-term and long-term goals. As a result of ongoing progress in areas such\nas computing science and automation, humans now also interact with non-human\nagents of varying complexity as part of their day-to-day activities;\nsubstantial work is being done to integrate increasingly intelligent machine\nagents into human work and play. With increases in the cognitive, sensory, and\nmotor capacity of these agents, intelligent machinery for human assistance can\nnow reasonably be considered to engage in joint action with humans---i.e., two\nor more agents adapting their behaviour and their understanding of each other\nso as to progress in shared objectives or goals. The mechanisms, conditions,\nand opportunities for skillful joint action in human-machine partnerships is of\ngreat interest to multiple communities. Despite this, human-machine joint\naction is as yet under-explored, especially in cases where a human and an\nintelligent machine interact in a persistent way during the course of\nreal-time, daily-life experience. In this work, we contribute a virtual reality\nenvironment wherein a human and an agent can adapt their predictions, their\nactions, and their communication so as to pursue a simple foraging task. In a\ncase study with a single participant, we provide an example of human-agent\ncoordination and decision-making involving prediction learning on the part of\nthe human and the machine agent, and control learning on the part of the\nmachine agent wherein audio communication signals are used to cue its human\npartner in service of acquiring shared reward. These comparisons suggest the\nutility of studying human-machine coordination in a virtual reality\nenvironment, and identify further research that will expand our understanding\nof persistent human-machine joint action.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:53:48 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Pilarski", "Patrick M.", ""], ["Butcher", "Andrew", ""], ["Johanson", "Michael", ""], ["Botvinick", "Matthew M.", ""], ["Bolt", "Andrew", ""], ["Parker", "Adam S. R.", ""]]}, {"id": "1905.02693", "submitter": "Vitor Guizilini", "authors": "Vitor Guizilini, Rares Ambrus, Sudeep Pillai, Allan Raventos, Adrien\n  Gaidon", "title": "3D Packing for Self-Supervised Monocular Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cameras are ubiquitous, robotic platforms typically rely on active\nsensors like LiDAR for direct 3D perception. In this work, we propose a novel\nself-supervised monocular depth estimation method combining geometry with a new\ndeep network, PackNet, learned only from unlabeled monocular videos. Our\narchitecture leverages novel symmetrical packing and unpacking blocks to\njointly learn to compress and decompress detail-preserving representations\nusing 3D convolutions. Although self-supervised, our method outperforms other\nself, semi, and fully supervised methods on the KITTI benchmark. The 3D\ninductive bias in PackNet enables it to scale with input resolution and number\nof parameters without overfitting, generalizing better on out-of-domain data\nsuch as the NuScenes dataset. Furthermore, it does not require large-scale\nsupervised pretraining on ImageNet and can run in real-time. Finally, we\nrelease DDAD (Dense Depth for Automated Driving), a new urban driving dataset\nwith more challenging and accurate depth evaluation, thanks to longer-range and\ndenser ground-truth depth generated from high-density LiDARs mounted on a fleet\nof self-driving cars operating world-wide.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:09:52 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:34:18 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 03:21:21 GMT"}, {"version": "v4", "created": "Sat, 28 Mar 2020 18:49:27 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Guizilini", "Vitor", ""], ["Ambrus", "Rares", ""], ["Pillai", "Sudeep", ""], ["Raventos", "Allan", ""], ["Gaidon", "Adrien", ""]]}, {"id": "1905.02698", "submitter": "John Mern", "authors": "John Mern and Dorsa Sadigh and Mykel Kochenderfer", "title": "Object Exchangeability in Reinforcement Learning: Extended Abstract", "comments": "In Proceedings of the 18th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2019), Montreal,Canada, May 13 to 17,\n  2019,IFAAMAS, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep reinforcement learning has advanced significantly over the past\nseveral years, sample efficiency remains a major challenge. Careful choice of\ninput representations can help improve efficiency depending on the structure\npresent in the problem. In this work, we present an attention-based method to\nproject inputs into an efficient representation space that is invariant under\nchanges to input ordering. We show that our proposed representation results in\na search space that is a factor of m! smaller for inputs of m objects. Our\nexperiments demonstrate improvements in sample efficiency for policy gradient\nmethods on a variety of tasks. We show that our representation allows us to\nsolve problems that are otherwise intractable when using naive approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:20:41 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Mern", "John", ""], ["Sadigh", "Dorsa", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1905.02704", "submitter": "Saima Sharmin", "authors": "Saima Sharmin, Priyadarshini Panda, Syed Shakib Sarwar, Chankyu Lee,\n  Wachirawit Ponghiran and Kaushik Roy", "title": "A Comprehensive Analysis on Adversarial Robustness of Spiking Neural\n  Networks", "comments": "Accepted in IJCNN2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of machine learning models, their functionality is being\nthreatened by adversarial attacks. In the face of this struggle for making\nartificial neural networks robust, finding a model, resilient to these attacks,\nis very important. In this work, we present, for the first time, a\ncomprehensive analysis of the behavior of more bio-plausible networks, namely\nSpiking Neural Network (SNN) under state-of-the-art adversarial tests. We\nperform a comparative study of the accuracy degradation between conventional\nVGG-9 Artificial Neural Network (ANN) and equivalent spiking network with\nCIFAR-10 dataset in both whitebox and blackbox setting for different types of\nsingle-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We\ndemonstrate that SNNs tend to show more resiliency compared to ANN under\nblack-box attack scenario. Additionally, we find that SNN robustness is largely\ndependent on the corresponding training mechanism. We observe that SNNs trained\nby spike-based backpropagation are more adversarially robust than the ones\nobtained by ANN-to-SNN conversion rules in several whitebox and blackbox\nscenarios. Finally, we also propose a simple, yet, effective framework for\ncrafting adversarial attacks from SNNs. Our results suggest that attacks\ncrafted from SNNs following our proposed method are much stronger than those\ncrafted from ANNs.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:41:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Sharmin", "Saima", ""], ["Panda", "Priyadarshini", ""], ["Sarwar", "Syed Shakib", ""], ["Lee", "Chankyu", ""], ["Ponghiran", "Wachirawit", ""], ["Roy", "Kaushik", ""]]}, {"id": "1905.02706", "submitter": "Tejas Khot", "authors": "Tejas Khot, Shubham Agrawal, Shubham Tulsiani, Christoph Mertz, Simon\n  Lucey, Martial Hebert", "title": "Learning Unsupervised Multi-View Stereopsis via Robust Photometric\n  Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning based approach for multi-view stereopsis (MVS). While\ncurrent deep MVS methods achieve impressive results, they crucially rely on\nground-truth 3D training data, and acquisition of such precise 3D geometry for\nsupervision is a major hurdle. Our framework instead leverages photometric\nconsistency between multiple views as supervisory signal for learning depth\nprediction in a wide baseline MVS setup. However, naively applying photo\nconsistency constraints is undesirable due to occlusion and lighting changes\nacross views. To overcome this, we propose a robust loss formulation that: a)\nenforces first order consistency and b) for each point, selectively enforces\nconsistency with some views, thus implicitly handling occlusions. We\ndemonstrate our ability to learn MVS without 3D supervision using a real\ndataset, and show that each component of our proposed robust loss results in a\nsignificant improvement. We qualitatively observe that our reconstructions are\noften more complete than the acquired ground truth, further showing the merits\nof this approach. Lastly, our learned model generalizes to novel settings, and\nour approach allows adaptation of existing CNNs to datasets without\nground-truth 3D by unsupervised finetuning. Project webpage:\nhttps://tejaskhot.github.io/unsup_mvs\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:45:22 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 17:30:47 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Khot", "Tejas", ""], ["Agrawal", "Shubham", ""], ["Tulsiani", "Shubham", ""], ["Mertz", "Christoph", ""], ["Lucey", "Simon", ""], ["Hebert", "Martial", ""]]}, {"id": "1905.02780", "submitter": "Yuchen Cui", "authors": "Yuchen Cui, David Isele, Scott Niekum and Kikuo Fujimura", "title": "Uncertainty-Aware Data Aggregation for Deep Imitation Learning", "comments": "Accepted to International Conference on Robotics and Automation 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating statistical uncertainties allows autonomous agents to communicate\ntheir confidence during task execution and is important for applications in\nsafety-critical domains such as autonomous driving. In this work, we present\nthe uncertainty-aware imitation learning (UAIL) algorithm for improving\nend-to-end control systems via data aggregation. UAIL applies Monte Carlo\nDropout to estimate uncertainty in the control output of end-to-end systems,\nusing states where it is uncertain to selectively acquire new training data. In\ncontrast to prior data aggregation algorithms that force human experts to visit\nsub-optimal states at random, UAIL can anticipate its own mistakes and switch\ncontrol to the expert in order to prevent visiting a series of sub-optimal\nstates. Our experimental results from simulated driving tasks demonstrate that\nour proposed uncertainty estimation method can be leveraged to reliably predict\ninfractions. Our analysis shows that UAIL outperforms existing data aggregation\nalgorithms on a series of benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 19:29:58 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Cui", "Yuchen", ""], ["Isele", "David", ""], ["Niekum", "Scott", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1905.02789", "submitter": "Yingzhou Li", "authors": "Yingzhou Li, Jianfeng Lu, Anqi Mao", "title": "Variational training of neural network approximations of solution maps\n  for physical models", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109338", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel solve-training framework is proposed to train neural network in\nrepresenting low dimensional solution maps of physical models. Solve-training\nframework uses the neural network as the ansatz of the solution map and train\nthe network variationally via loss functions from the underlying physical\nmodels. Solve-training framework avoids expensive data preparation in the\ntraditional supervised training procedure, which prepares labels for input\ndata, and still achieves effective representation of the solution map adapted\nto the input data distribution. The efficiency of solve-training framework is\ndemonstrated through obtaining solutions maps for linear and nonlinear elliptic\nequations, and maps from potentials to ground states of linear and nonlinear\nSchr\\\"odinger equations.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 19:51:06 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:33:35 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 01:51:56 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Li", "Yingzhou", ""], ["Lu", "Jianfeng", ""], ["Mao", "Anqi", ""]]}, {"id": "1905.02796", "submitter": "Yufei Han", "authors": "Yufei Han, Yuzhe Ma, Christopher Gates, Kevin Roundy and Yun Shen", "title": "Collaborative and Privacy-Preserving Machine Teaching via Consensus\n  Optimization", "comments": null, "journal-ref": "IJCNN 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we define a collaborative and privacy-preserving machine\nteaching paradigm with multiple distributed teachers. We focus on consensus\nsuper teaching. It aims at organizing distributed teachers to jointly select a\ncompact while informative training subset from data hosted by the teachers to\nmake a learner learn better. The challenges arise from three perspectives.\nFirst, the state-of-the-art pool-based super teaching method applies\nmixed-integer non-linear programming (MINLP) which does not scale well to very\nlarge data sets. Second, it is desirable to restrict data access of the\nteachers to only their own data during the collaboration stage to mitigate\nprivacy leaks. Finally, the teaching collaboration should be\ncommunication-efficient since large communication overheads can cause\nsynchronization delays between teachers.\n  To address these challenges, we formulate collaborative teaching as a\nconsensus and privacy-preserving optimization process to minimize teaching\nrisk. We theoretically demonstrate the necessity of collaboration between\nteachers for improving the learner's learning. Furthermore, we show that the\nproposed method enjoys a similar property as the Oracle property of adaptive\nLasso. The empirical study illustrates that our teaching method can deliver\nsignificantly more accurate teaching results with high speed, while the\nnon-collaborative MINLP-based super teaching becomes prohibitively expensive to\ncompute.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 20:15:31 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Han", "Yufei", ""], ["Ma", "Yuzhe", ""], ["Gates", "Christopher", ""], ["Roundy", "Kevin", ""], ["Shen", "Yun", ""]]}, {"id": "1905.02797", "submitter": "Maria Peifer", "authors": "Maria Peifer, Luiz. F. O. Chamon, Santiago Paternain, and Alejandro\n  Ribeiro", "title": "Sparse multiresolution representations with adaptive kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducing kernel Hilbert spaces (RKHSs) are key elements of many\nnon-parametric tools successfully used in signal processing, statistics, and\nmachine learning. In this work, we aim to address three issues of the classical\nRKHS based techniques. First, they require the RKHS to be known a priori, which\nis unrealistic in many applications. Furthermore, the choice of RKHS affects\nthe shape and smoothness of the solution, thus impacting its performance.\nSecond, RKHSs are ill-equipped to deal with heterogeneous degrees of\nsmoothness, i.e., with functions that are smooth in some parts of their domain\nbut vary rapidly in others. Finally, the computational complexity of evaluating\nthe solution of these methods grows with the number of data points, rendering\nthese techniques infeasible for many applications. Though kernel learning,\nlocal kernel adaptation, and sparsity have been used to address these issues,\nmany of these approaches are computationally intensive or forgo optimality\nguarantees. We tackle these problems by leveraging a novel integral\nrepresentation of functions in RKHSs that allows for arbitrary centers and\ndifferent kernels at each center. To address the complexity issues, we then\nwrite the function estimation problem as a sparse functional program that\nexplicitly minimizes the support of the representation leading to low\ncomplexity solutions. Despite their non-convexity and infinite dimensionality,\nwe show these problems can be solved exactly and efficiently by leveraging\nduality, and we illustrate this new approach in simulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 20:17:17 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Peifer", "Maria", ""], ["Chamon", "Luiz. F. O.", ""], ["Paternain", "Santiago", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1905.02825", "submitter": "Emma Tosch", "authors": "Emma Tosch, Kaleigh Clary, John Foley, David Jensen", "title": "Toybox: A Suite of Environments for Experimental Evaluation of Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of deep reinforcement learning (RL) is inherently challenging. In\nparticular, learned policies are largely opaque, and hypotheses about the\nbehavior of deep RL agents are difficult to test in black-box environments.\nConsiderable effort has gone into addressing opacity, but almost no effort has\nbeen devoted to producing high quality environments for experimental evaluation\nof agent behavior. We present TOYBOX, a new high-performance, open-source*\nsubset of Atari environments re-designed for the experimental evaluation of\ndeep RL. We show that TOYBOX enables a wide range of experiments and analyses\nthat are impossible in other environments.\n  *https://kdl-umass.github.io/Toybox/\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 22:21:50 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Tosch", "Emma", ""], ["Clary", "Kaleigh", ""], ["Foley", "John", ""], ["Jensen", "David", ""]]}, {"id": "1905.02841", "submitter": "Huaqing Xiong", "authors": "Bowen Weng, Huaqing Xiong and Wei Zhang", "title": "Accelerated Target Updates for Q-learning", "comments": "We need further adjustment of some parts of the papaer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies accelerations in Q-learning algorithms. We propose an\naccelerated target update scheme by incorporating the historical iterates of Q\nfunctions. The idea is conceptually inspired by the momentum-based accelerated\nmethods in the optimization theory. Conditions under which the proposed\naccelerated algorithms converge are established. The algorithms are validated\nusing commonly adopted testing problems in reinforcement learning, including\nthe FrozenLake grid world game, two discrete-time LQR problems from the\nDeepmind Control Suite, and the Atari 2600 games. Simulation results show that\nthe proposed accelerated algorithms can improve the convergence performance\ncompared with the vanilla Q-learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:14:23 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 12:40:11 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Weng", "Bowen", ""], ["Xiong", "Huaqing", ""], ["Zhang", "Wei", ""]]}, {"id": "1905.02843", "submitter": "Venkateshwaran Balasubramanian", "authors": "Erkan Baser, Venkateshwaran Balasubramanian, Prarthana Bhattacharyya,\n  Krzysztof Czarnecki", "title": "FANTrack: 3D Multi-Object Tracking with Feature Association Network", "comments": "8 pages, 10 figures, IEEE Intelligent Vehicles Symposium (IV 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach to online multi-object tracking (MOT) that\nuses a convolutional neural network (CNN) for data association in a\ntracking-by-detection framework. The problem of multi-target tracking aims to\nassign noisy detections to a-priori unknown and time-varying number of tracked\nobjects across a sequence of frames. A majority of the existing solutions focus\non either tediously designing cost functions or formulating the task of data\nassociation as a complex optimization problem that can be solved effectively.\nInstead, we exploit the power of deep learning to formulate the data\nassociation problem as inference in a CNN. To this end, we propose to learn a\nsimilarity function that combines cues from both image and spatial features of\nobjects. Our solution learns to perform global assignments in 3D purely from\ndata, handles noisy detections and a varying number of targets, and is easy to\ntrain. We evaluate our approach on the challenging KITTI dataset and show\ncompetitive results. Our code is available at\nhttps://git.uwaterloo.ca/wise-lab/fantrack.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:26:03 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Baser", "Erkan", ""], ["Balasubramanian", "Venkateshwaran", ""], ["Bhattacharyya", "Prarthana", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1905.02845", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Maria N. Samad, Sayema Asif Mashhadi, Tania Kapoor,\n  Wahab Ali, Fakhri Karray, Mark Crowley", "title": "Feature Selection and Feature Extraction in Pattern Analysis: A\n  Literature Review", "comments": "14 pages, 1 figure, 2 tables, survey (literature review) paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern analysis often requires a pre-processing stage for extracting or\nselecting features in order to help the classification, prediction, or\nclustering stage discriminate or represent the data in a better way. The reason\nfor this requirement is that the raw data are complex and difficult to process\nwithout extracting or selecting appropriate features beforehand. This paper\nreviews theory and motivation of different common methods of feature selection\nand extraction and introduces some of their applications. Some numerical\nimplementations are also shown for these methods. Finally, the methods in\nfeature selection and extraction are compared.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:41:34 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Samad", "Maria N.", ""], ["Mashhadi", "Sayema Asif", ""], ["Kapoor", "Tania", ""], ["Ali", "Wahab", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1905.02850", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Graham W. Taylor, Mohamed R. Amer", "title": "Understanding Attention and Generalization in Graph Neural Networks", "comments": "NeurIPS 2019, camera-ready and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to better understand attention over nodes in graph neural networks\n(GNNs) and identify factors influencing its effectiveness. We particularly\nfocus on the ability of attention GNNs to generalize to larger, more complex or\nnoisy graphs. Motivated by insights from the work on Graph Isomorphism\nNetworks, we design simple graph reasoning tasks that allow us to study\nattention in a controlled environment. We find that under typical conditions\nthe effect of attention is negligible or even harmful, but under certain\nconditions it provides an exceptional gain in performance of more than 60% in\nsome of our classification tasks. Satisfying these conditions in practice is\nchallenging and often requires optimal initialization or supervised training of\nattention. We propose an alternative recipe and train attention in a\nweakly-supervised fashion that approaches the performance of supervised models,\nand, compared to unsupervised models, improves results on several synthetic as\nwell as real datasets. Source code and datasets are available at\nhttps://github.com/bknyaz/graph_attention_pool.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 00:30:25 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 11:40:58 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 14:51:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Knyazev", "Boris", ""], ["Taylor", "Graham W.", ""], ["Amer", "Mohamed R.", ""]]}, {"id": "1905.02876", "submitter": "Giorgos Bouritsas", "authors": "Giorgos Bouritsas, Sergiy Bokhnyak, Stylianos Ploumpis, Michael\n  Bronstein, Stefanos Zafeiriou", "title": "Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape\n  Representation Learning and Generation", "comments": "to appear at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for 3D geometric data arise in many important applications\nin 3D computer vision and graphics. In this paper, we focus on 3D deformable\nshapes that share a common topological structure, such as human faces and\nbodies. Morphable Models and their variants, despite their linear formulation,\nhave been widely used for shape representation, while most of the recently\nproposed nonlinear approaches resort to intermediate representations, such as\n3D voxel grids or 2D views. In this work, we introduce a novel graph\nconvolutional operator, acting directly on the 3D mesh, that explicitly models\nthe inductive bias of the fixed underlying graph. This is achieved by enforcing\nconsistent local orderings of the vertices of the graph, through the spiral\noperator, thus breaking the permutation invariance property that is adopted by\nall the prior work on Graph Neural Networks. Our operator comes by construction\nwith desirable properties (anisotropic, topology-aware, lightweight,\neasy-to-optimise), and by using it as a building block for traditional deep\ngenerative architectures, we demonstrate state-of-the-art results on a variety\nof 3D shape datasets compared to the linear Morphable Model and other graph\nconvolutional operators.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:37:27 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:14:27 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2019 00:14:45 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Bouritsas", "Giorgos", ""], ["Bokhnyak", "Sergiy", ""], ["Ploumpis", "Stylianos", ""], ["Bronstein", "Michael", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1905.02898", "submitter": "Lior Deutsch", "authors": "Lior Deutsch, Erik Nijkamp, Yu Yang", "title": "A Generative Model for Sampling High-Performance and Diverse Weights for\n  Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.01952", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on mode connectivity in the loss landscape of deep neural\nnetworks has demonstrated that the locus of (sub-)optimal weight vectors lies\non continuous paths. In this work, we train a neural network that serves as a\nhypernetwork, mapping a latent vector into high-performance (low-loss) weight\nvectors, generalizing recent findings of mode connectivity to higher\ndimensional manifolds. We formulate the training objective as a compromise\nbetween accuracy and diversity, where the diversity takes into account trivial\nsymmetry transformations of the target network. We demonstrate how to reduce\nthe number of parameters in the hypernetwork by parameter sharing. Once\nlearned, the hypernetwork allows for a computationally efficient, ancestral\nsampling of neural network weights, which we recruit to form large ensembles.\nThe improvement in classification accuracy obtained by this ensembling\nindicates that the generated manifold extends in dimensions other than\ndirections implied by trivial symmetries. For computational efficiency, we\ndistill an ensemble into a single classifier while retaining generalization.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 04:28:46 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Deutsch", "Lior", ""], ["Nijkamp", "Erik", ""], ["Yang", "Yu", ""]]}, {"id": "1905.02941", "submitter": "Yufei Han", "authors": "Yufei Han and Xiangliang Zhang", "title": "Robust Federated Training via Collaborative Machine Teaching using\n  Trusted Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning performs distributed model training using local data\nhosted by agents. It shares only model parameter updates for iterative\naggregation at the server. Although it is privacy-preserving by design,\nfederated learning is vulnerable to noise corruption of local agents, as\ndemonstrated in the previous study on adversarial data poisoning threat against\nfederated learning systems. Even a single noise-corrupted agent can bias the\nmodel training. In our work, we propose a collaborative and privacy-preserving\nmachine teaching paradigm with multiple distributed teachers, to improve\nrobustness of the federated training process against local data corruption. We\nassume that each local agent (teacher) have the resources to verify a small\nportions of trusted instances, which may not by itself be adequate for\nlearning. In the proposed collaborative machine teaching method, these trusted\ninstances guide the distributed agents to jointly select a compact while\ninformative training subset from data hosted by their own. Simultaneously, the\nagents learn to add changes of limited magnitudes into the selected data\ninstances, in order to improve the testing performances of the federally\ntrained model despite of the training data corruption. Experiments on toy and\nreal data demonstrate that our approach can identify training set bugs\neffectively and suggest appropriate changes to the labels. Our algorithm is a\nstep toward trustworthy machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 07:27:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Han", "Yufei", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.02954", "submitter": "Matin Hashemi", "authors": "Alireza Amirshahi, Matin Hashemi", "title": "Ultra Low-Power and Real-time ECG Classification Based on STDP and\n  R-STDP Neural Networks for Wearable Devices", "comments": "Published in IEEE Transactions on Biomedical Circuits and Systems\n  (TBioCAS), 2019", "journal-ref": null, "doi": "10.1109/TBCAS.2019.2948920", "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel ECG classification algorithm for real-time\ncardiac monitoring on ultra low-power wearable devices. The proposed solution\nis based on spiking neural networks which are the third generation of neural\nnetworks. In specific, we employ spike-timing dependent plasticity (STDP), and\nreward-modulated STDP (R-STDP), in which the model weights are trained\naccording to the timings of spike signals, and reward or punishment signals.\nExperiments show that the proposed solution is suitable for real-time\noperation, achieves comparable accuracy with respect to previous methods, and\nmore importantly, its energy consumption is significantly smaller than previous\nneural network based solutions.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:26:36 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 14:33:39 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 09:26:36 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 11:06:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Amirshahi", "Alireza", ""], ["Hashemi", "Matin", ""]]}, {"id": "1905.02957", "submitter": "Guanghui Wang", "authors": "Guanghui Wang, Shiyin Lu, Weiwei Tu, Lijun Zhang", "title": "SAdam: A Variant of Adam for Strongly Convex Functions", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adam algorithm has become extremely popular for large-scale machine\nlearning. Under convexity condition, it has been proved to enjoy a\ndata-dependant $O(\\sqrt{T})$ regret bound where $T$ is the time horizon.\nHowever, whether strong convexity can be utilized to further improve the\nperformance remains an open problem. In this paper, we give an affirmative\nanswer by developing a variant of Adam (referred to as SAdam) which achieves a\ndata-dependant $O(\\log T)$ regret bound for strongly convex functions. The\nessential idea is to maintain a faster decaying yet under controlled step size\nfor exploiting strong convexity. In addition, under a special configuration of\nhyperparameters, our SAdam reduces to SC-RMSprop, a recently proposed variant\nof RMSprop for strongly convex functions, for which we provide the first\ndata-dependent logarithmic regret bound. Empirical results on optimizing\nstrongly convex functions and training deep networks demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:38:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Wang", "Guanghui", ""], ["Lu", "Shiyin", ""], ["Tu", "Weiwei", ""], ["Zhang", "Lijun", ""]]}, {"id": "1905.02961", "submitter": "Gavneet Singh Chadha", "authors": "Gavneet Singh Chadha, Jan Niclas Reimann and Andreas Schwung", "title": "Generalized Dilation Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanilla convolutional neural networks are known to provide superior\nperformance not only in image recognition tasks but also in natural language\nprocessing and time series analysis. One of the strengths of convolutional\nlayers is the ability to learn features about spatial relations in the input\ndomain using various parameterized convolutional kernels. However, in time\nseries analysis learning such spatial relations is not necessarily required nor\neffective. In such cases, kernels which model temporal dependencies or kernels\nwith broader spatial resolutions are recommended for more efficient training as\nproposed by dilation kernels. However, the dilation has to be fixed a priori\nwhich limits the flexibility of the kernels. We propose generalized dilation\nnetworks which generalize the initial dilations in two aspects. First we derive\nan end-to-end learnable architecture for dilation layers where also the\ndilation rate can be learned. Second we break up the strict dilation structure,\nin that we develop kernels operating independently in the input space.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:46:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Chadha", "Gavneet Singh", ""], ["Reimann", "Jan Niclas", ""], ["Schwung", "Andreas", ""]]}, {"id": "1905.03026", "submitter": "Ivo Matteo Baltruschat", "authors": "Ivo Matteo Baltruschat and Patryk Szwargulski and Florian Griese and\n  Mirco Grosser and Ren\\'e Werner and Tobias Knopp", "title": "3d-SMRnet: Achieving a new quality of MPI system matrix recovery by deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic particle imaging (MPI) data is commonly reconstructed using a system\nmatrix acquired in a time-consuming calibration measurement. The calibration\napproach has the important advantage over model-based reconstruction that it\ntakes the complex particle physics as well as system imperfections into\naccount. This benefit comes for the cost that the system matrix needs to be\nre-calibrated whenever the scan parameters, particle types or even the particle\nenvironment (e.g. viscosity or temperature) changes. One route for reducing the\ncalibration time is the sampling of the system matrix at a subset of the\nspatial positions of the intended field-of-view and employing system matrix\nrecovery. Recent approaches used compressed sensing (CS) and achieved\nsubsampling factors up to 28 that still allowed reconstructing MPI images of\nsufficient quality. In this work, we propose a novel framework with a 3d-System\nMatrix Recovery Network and demonstrate it to recover a 3d system matrix with a\nsubsampling factor of 64 in less than one minute and to outperform CS in terms\nof system matrix quality, reconstructed image quality, and processing time. The\nadvantage of our method is demonstrated by reconstructing open access MPI\ndatasets. The model is further shown to be capable of inferring system matrices\nfor different particle types.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:21:39 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Baltruschat", "Ivo Matteo", ""], ["Szwargulski", "Patryk", ""], ["Griese", "Florian", ""], ["Grosser", "Mirco", ""], ["Werner", "Ren\u00e9", ""], ["Knopp", "Tobias", ""]]}, {"id": "1905.03028", "submitter": "Kan Ren", "authors": "Kan Ren, Jiarui Qin, Lei Zheng, Zhengyu Yang, Weinan Zhang and Yong Yu", "title": "Deep Landscape Forecasting for Real-time Bidding Advertising", "comments": "KDD 2019. The reproducible code and dataset link is\n  https://github.com/rk2900/DLF", "journal-ref": null, "doi": "10.1145/3292500.3330870", "report-no": null, "categories": "cs.IR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of real-time auction in online advertising has drawn huge\nattention of modeling the market competition, i.e., bid landscape forecasting.\nThe problem is formulated as to forecast the probability distribution of market\nprice for each ad auction. With the consideration of the censorship issue which\nis caused by the second-price auction mechanism, many researchers have devoted\ntheir efforts on bid landscape forecasting by incorporating survival analysis\nfrom medical research field. However, most existing solutions mainly focus on\neither counting-based statistics of the segmented sample clusters, or learning\na parameterized model based on some heuristic assumptions of distribution\nforms. Moreover, they neither consider the sequential patterns of the feature\nover the price space. In order to capture more sophisticated yet flexible\npatterns at fine-grained level of the data, we propose a Deep Landscape\nForecasting (DLF) model which combines deep learning for probability\ndistribution forecasting and survival analysis for censorship handling.\nSpecifically, we utilize a recurrent neural network to flexibly model the\nconditional winning probability w.r.t. each bid price. Then we conduct the bid\nlandscape forecasting through probability chain rule with strict mathematical\nderivations. And, in an end-to-end manner, we optimize the model by minimizing\ntwo negative likelihood losses with comprehensive motivations. Without any\nspecific assumption for the distribution form of bid landscape, our model shows\ngreat advantages over previous works on fitting various sophisticated market\nprice distributions. In the experiments over two large-scale real-world\ndatasets, our model significantly outperforms the state-of-the-art solutions\nunder various metrics.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:22:02 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 16:27:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ren", "Kan", ""], ["Qin", "Jiarui", ""], ["Zheng", "Lei", ""], ["Yang", "Zhengyu", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1905.03030", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Jane X. Wang, Mark Rowland, Tim Genewein, Zeb\n  Kurth-Nelson, Razvan Pascanu, Nicolas Heess, Joel Veness, Alex Pritzel, Pablo\n  Sprechmann, Siddhant M. Jayakumar, Tom McGrath, Kevin Miller, Mohammad Azar,\n  Ian Osband, Neil Rabinowitz, Andr\\'as Gy\\\"orgy, Silvia Chiappa, Simon\n  Osindero, Yee Whye Teh, Hado van Hasselt, Nando de Freitas, Matthew\n  Botvinick, Shane Legg", "title": "Meta-learning of Sequential Strategies", "comments": "DeepMind Technical Report (15 pages, 6 figures). Version V1.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we review memory-based meta-learning as a tool for building\nsample-efficient strategies that learn from past experience to adapt to any\ntask within a target class. Our goal is to equip the reader with the conceptual\nfoundations of this tool for building new, scalable agents that operate on\nbroad domains. To do so, we present basic algorithmic templates for building\nnear-optimal predictors and reinforcement learners which behave as if they had\na probabilistic model that allowed them to efficiently exploit task structure.\nFurthermore, we recast memory-based meta-learning within a Bayesian framework,\nshowing that the meta-learned strategies are near-optimal because they amortize\nBayes-filtered data, where the adaptation is implemented in the memory dynamics\nas a state-machine of sufficient statistics. Essentially, memory-based\nmeta-learning translates the hard problem of probabilistic sequential inference\ninto a regression problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:27:20 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 18:09:19 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Wang", "Jane X.", ""], ["Rowland", "Mark", ""], ["Genewein", "Tim", ""], ["Kurth-Nelson", "Zeb", ""], ["Pascanu", "Razvan", ""], ["Heess", "Nicolas", ""], ["Veness", "Joel", ""], ["Pritzel", "Alex", ""], ["Sprechmann", "Pablo", ""], ["Jayakumar", "Siddhant M.", ""], ["McGrath", "Tom", ""], ["Miller", "Kevin", ""], ["Azar", "Mohammad", ""], ["Osband", "Ian", ""], ["Rabinowitz", "Neil", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Chiappa", "Silvia", ""], ["Osindero", "Simon", ""], ["Teh", "Yee Whye", ""], ["van Hasselt", "Hado", ""], ["de Freitas", "Nando", ""], ["Botvinick", "Matthew", ""], ["Legg", "Shane", ""]]}, {"id": "1905.03035", "submitter": "Yufeng Yu", "authors": "Yufeng Yu, Yuelong Zhu, Dingsheng Wan, Qun Zhao, Kai Shu, Huan Liu", "title": "Applications of Social Media in Hydroinformatics: A Survey", "comments": "37pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floods of research and practical applications employ social media data for a\nwide range of public applications, including environmental monitoring, water\nresource managing, disaster and emergency response.Hydroinformatics can benefit\nfrom the social media technologies with newly emerged data, techniques and\nanalytical tools to handle large datasets, from which creative ideas and new\nvalues could be mined.This paper first proposes a 4W (What, Why, When, hoW)\nmodel and a methodological structure to better understand and represent the\napplication of social media to hydroinformatics, then provides an overview of\nacademic research of applying social media to hydroinformatics such as water\nenvironment, water resources, flood, drought and water Scarcity management. At\nlast,some advanced topics and suggestions of water related social media\napplications from data collection, data quality management, fake news\ndetection, privacy issues, algorithms and platforms was present to\nhydroinformatics managers and researchers based on previous discussion.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:48:19 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Yu", "Yufeng", ""], ["Zhu", "Yuelong", ""], ["Wan", "Dingsheng", ""], ["Zhao", "Qun", ""], ["Shu", "Kai", ""], ["Liu", "Huan", ""]]}, {"id": "1905.03036", "submitter": "Hendrik Burwinkel", "authors": "Hendrik Burwinkel, Anees Kazi, Gerome Vivar, Shadi Albarqouni,\n  Guillaume Zahnd, Nassir Navab, Seyed-Ahmad Ahmadi", "title": "Adaptive Image-Feature Learning for Disease Classification Using\n  Inductive Graph Networks", "comments": "9 pages, 2 figures. Medical Image Computing and Computer Assisted\n  Intervention - MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32226-7_71", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Geometric Deep Learning (GDL) has been introduced as a novel and\nversatile framework for computer-aided disease classification. GDL uses patient\nmeta-information such as age and gender to model patient cohort relations in a\ngraph structure. Concepts from graph signal processing are leveraged to learn\nthe optimal mapping of multi-modal features, e.g. from images to disease\nclasses. Related studies so far have considered image features that are\nextracted in a pre-processing step. We hypothesize that such an approach\nprevents the network from optimizing feature representations towards achieving\nthe best performance in the graph network. We propose a new network\narchitecture that exploits an inductive end-to-end learning approach for\ndisease classification, where filters from both the CNN and the graph are\ntrained jointly. We validate this architecture against state-of-the-art\ninductive graph networks and demonstrate significantly improved classification\nscores on a modified MNIST toy dataset, as well as comparable classification\nresults with higher stability on a chest X-ray image dataset. Additionally, we\nexplain how the structural information of the graph affects both the image\nfilters and the feature learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:39:43 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 15:21:04 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Burwinkel", "Hendrik", ""], ["Kazi", "Anees", ""], ["Vivar", "Gerome", ""], ["Albarqouni", "Shadi", ""], ["Zahnd", "Guillaume", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "1905.03041", "submitter": "Junshan Wang", "authors": "Junshan Wang, Zhicong Lu, Guojie Song, Yue Fan, Lun Du, Wei Lin", "title": "Tag2Vec: Learning Tag Representations in Tag Networks", "comments": "6 pages", "journal-ref": null, "doi": "10.1145/3308558.3308558.3313622", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is a method to learn low-dimensional representation vectors\nfor nodes in complex networks. In real networks, nodes may have multiple tags\nbut existing methods ignore the abundant semantic and hierarchical information\nof tags. This information is useful to many network applications and usually\nvery stable. In this paper, we propose a tag representation learning model,\nTag2Vec, which mixes nodes and tags into a hybrid network. Firstly, for tag\nnetworks, we define semantic distance as the proximity between tags and design\na novel strategy, parameterized random walk, to generate context with semantic\nand hierarchical information of tags adaptively. Then, we propose hyperbolic\nSkip-gram model to express the complex hierarchical structure better with lower\noutput dimensions. We evaluate our model on the NBER U.S. patent dataset and\nWordNet dataset. The results show that our model can learn tag representations\nwith rich semantic information and it outperforms other baselines.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 12:29:24 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 06:21:35 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wang", "Junshan", ""], ["Lu", "Zhicong", ""], ["Song", "Guojie", ""], ["Fan", "Yue", ""], ["Du", "Lun", ""], ["Lin", "Wei", ""]]}, {"id": "1905.03042", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Xiao Luo, Duc Minh Nguyen, Nikos Deligiannis", "title": "Rumour Detection via News Propagation Dynamics and User Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rumours have existed for a long time and have been known for serious\nconsequences. The rapid growth of social media platforms has multiplied the\nnegative impact of rumours; it thus becomes important to early detect them.\nMany methods have been introduced to detect rumours using the content or the\nsocial context of news. However, most existing methods ignore or do not explore\neffectively the propagation pattern of news in social media, including the\nsequence of interactions of social media users with news across time. In this\nwork, we propose a novel method for rumour detection based on deep learning.\nOur method leverages the propagation process of the news by learning the users'\nrepresentation and the temporal interrelation of users' responses. Experiments\nconducted on Twitter and Weibo datasets demonstrate the state-of-the-art\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:13:03 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Do", "Tien Huu", ""], ["Luo", "Xiao", ""], ["Nguyen", "Duc Minh", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1905.03046", "submitter": "Peter Meltzer", "authors": "Peter Meltzer, Marcelo Daniel Gutierrez Mallea and Peter J. Bentley", "title": "PiNet: A Permutation Invariant Graph Neural Network for Graph\n  Classification", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end deep learning learning model for graph\nclassification and representation learning that is invariant to permutation of\nthe nodes of the input graphs. We address the challenge of learning a fixed\nsize graph representation for graphs of varying dimensions through a\ndifferentiable node attention pooling mechanism. In addition to a theoretical\nproof of its invariance to permutation, we provide empirical evidence\ndemonstrating the statistically significant gain in accuracy when faced with an\nisomorphic graph classification task given only a small number of training\nexamples. We analyse the effect of four different matrices to facilitate the\nlocal message passing mechanism by which graph convolutions are performed vs. a\nmatrix parametrised by a learned parameter pair able to transition smoothly\nbetween the former. Finally, we show that our model achieves competitive\nclassification performance with existing techniques on a set of molecule\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:51:52 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Meltzer", "Peter", ""], ["Mallea", "Marcelo Daniel Gutierrez", ""], ["Bentley", "Peter J.", ""]]}, {"id": "1905.03052", "submitter": "Zhi-Hua Zhou", "authors": "Shen-Huan Lv and Liang Yang and Zhi-Hua Zhou", "title": "Forest Representation Learning Guided by Margin Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reformulate the forest representation learning approach as\nan additive model which boosts the augmented feature instead of the prediction.\nWe substantially improve the upper bound of generalization gap from\n$\\mathcal{O}(\\sqrt\\frac{\\ln m}{m})$ to $\\mathcal{O}(\\frac{\\ln m}{m})$, while\n$\\lambda$ - the margin ratio between the margin standard deviation and the\nmargin mean is small enough. This tighter upper bound inspires us to optimize\nthe margin distribution ratio $\\lambda$. Therefore, we design the margin\ndistribution reweighting approach (mdDF) to achieve small ratio $\\lambda$ by\nboosting the augmented feature. Experiments and visualizations confirm the\neffectiveness of the approach in terms of performance and representation\nlearning ability. This study offers a novel understanding of the cascaded deep\nforest from the margin-theory perspective and further uses the mdDF approach to\nguide the layer-by-layer forest representation learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 07:28:11 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Lv", "Shen-Huan", ""], ["Yang", "Liang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1905.03053", "submitter": "Gerome Vivar", "authors": "Gerome Vivar, Hendrik Burwinkel, Anees Kazi, Andreas Zwergal, Nassir\n  Navab, Seyed-Ahmad Ahmadi", "title": "Multi-modal Graph Fusion for Inductive Disease Classification in\n  Incomplete Datasets", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical diagnostic decision making and population-based studies often rely\non multi-modal data which is noisy and incomplete. Recently, several works\nproposed geometric deep learning approaches to solve disease classification, by\nmodeling patients as nodes in a graph, along with graph signal processing of\nmulti-modal features. Many of these approaches are limited by assuming\nmodality- and feature-completeness, and by transductive inference, which\nrequires re-training of the entire model for each new test sample. In this\nwork, we propose a novel inductive graph-based approach that can generalize to\nout-of-sample patients, despite missing features from entire modalities per\npatient. We propose multi-modal graph fusion which is trained end-to-end\ntowards node-level classification. We demonstrate the fundamental working\nprinciple of this method on a simplified MNIST toy dataset. In experiments on\nmedical data, our method outperforms single static graph approach in\nmulti-modal disease classification.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 13:10:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Vivar", "Gerome", ""], ["Burwinkel", "Hendrik", ""], ["Kazi", "Anees", ""], ["Zwergal", "Andreas", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "1905.03066", "submitter": "Manuel Herzog", "authors": "Manuel Herzog, Klaus Dietmayer", "title": "Training a Fast Object Detector for LiDAR Range Images Using Labeled\n  Data from Sensors with Higher Resolution", "comments": null, "journal-ref": "2019 IEEE Intelligent Transportation Systems Conference (ITSC),\n  Auckland, New Zealand, 2019, pp. 2707-2713", "doi": "10.1109/ITSC.2019.8917011", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a strategy for training neural networks for object\ndetection in range images obtained from one type of LiDAR sensor using labeled\ndata from a different type of LiDAR sensor. Additionally, an efficient model\nfor object detection in range images for use in self-driving cars is presented.\nCurrently, the highest performing algorithms for object detection from LiDAR\nmeasurements are based on neural networks. Training these networks using\nsupervised learning requires large annotated datasets. Therefore, most research\nusing neural networks for object detection from LiDAR point clouds is conducted\non a very small number of publicly available datasets. Consequently, only a\nsmall number of sensor types are used. We use an existing annotated dataset to\ntrain a neural network that can be used with a LiDAR sensor that has a lower\nresolution than the one used for recording the annotated dataset. This is done\nby simulating data from the lower resolution LiDAR sensor based on the higher\nresolution dataset. Furthermore, improvements to models that use LiDAR range\nimages for object detection are presented. The results are validated using both\nsimulated sensor data and data from an actual lower resolution sensor mounted\nto a research vehicle. It is shown that the model can detect objects from\n360{\\deg} range images in real time.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 13:43:03 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 08:14:08 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 14:03:40 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Herzog", "Manuel", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1905.03086", "submitter": "Shadrokh Samavi", "authors": "Shadrokh Samavi, Pejman Khadivi", "title": "Fault-Tolerant Routing in Hypercube Networks by Avoiding Faulty Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next to the high performance, the essential feature of the multiprocessor\nsystems is their fault-tolerant capability. In this regard, fault-tolerant\ninterconnection networks and especially fault-tolerant routing methods are\ncrucial parts of these systems. Hypercube is a popular interconnection network\nthat is used in many multiprocessors. There are several suggested practices for\nfault tolerant routing in these systems. In this paper, a neural routing method\nis introduced which is named as Fault Avoidance Routing (FAR). This method\nkeeps the message as far from the faulty nodes as possible. The proposed method\nemploys the Hopfield neural network. In comparison with other neural routing\nmethods, FAR requires a small number of neurons. The simulation results show\nthat FAR has excellent performance in larger interconnection networks and\nnetworks with a high density of faulty nodes.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 07:30:54 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Samavi", "Shadrokh", ""], ["Khadivi", "Pejman", ""]]}, {"id": "1905.03092", "submitter": "Chaitanya K. Joshi", "authors": "Kuhu Joshi, Chaitanya K. Joshi", "title": "Working women and caste in India: A study of social disadvantage using\n  feature attribution", "comments": "Presented at the ICLR AI for Social Good Workshop 2019; Updated with\n  Addendum (Jan 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Women belonging to the socially disadvantaged caste-groups in India have\nhistorically been engaged in labour-intensive, blue-collar work. We study\nwhether there has been any change in the ability to predict a woman's\nwork-status and work-type based on her caste by interpreting machine learning\nmodels using feature attribution. We find that caste is now a less important\ndeterminant of work for the younger generation of women compared to the older\ngeneration. Moreover, younger women from disadvantaged castes are now more\nlikely to be working in white-collar jobs.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 07:15:33 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 12:54:19 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Joshi", "Kuhu", ""], ["Joshi", "Chaitanya K.", ""]]}, {"id": "1905.03100", "submitter": "Per Rutquist", "authors": "Per Rutquist", "title": "Unsupervised Learning through Temporal Smoothing and Entropy\n  Maximization", "comments": "This paper has been submitted to the 58th IEEE Conference on Decision\n  and Control (CDC2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for machine learning from unlabeled data in the\nform of a time-series. The mapping that is learned is shown to extract slowly\nevolving information that would be useful for control applications, while\nefficiently filtering out unwanted, higher-frequency noise.\n  The method consists of training a feedforward artificial neural network with\nbackpropagation using two opposing objectives.\n  The first of these is to minimize the squared changes in activations between\ntime steps of each unit in the network. This \"temporal smoothing\" has the\neffect of correlating inputs that occur close in time with outputs that are\nclose in the L2-norm.\n  The second objective is to maximize the log determinant of the covariance\nmatrix of activations in each layer of the network. This objective ensures that\ninformation from each layer is passed through to the next. This second\nobjective acts as a balance to the first, which on its own would result in a\nnetwork with all input weights equal to zero.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:37:38 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Rutquist", "Per", ""]]}, {"id": "1905.03125", "submitter": "Nadav Merlis", "authors": "Nadav Merlis, Shie Mannor", "title": "Batch-Size Independent Regret Bounds for the Combinatorial Multi-Armed\n  Bandit Problem", "comments": "Accepted to COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the combinatorial multi-armed bandit (CMAB) problem, where the\nreward function is nonlinear. In this setting, the agent chooses a batch of\narms on each round and receives feedback from each arm of the batch. The reward\nthat the agent aims to maximize is a function of the selected arms and their\nexpectations. In many applications, the reward function is highly nonlinear,\nand the performance of existing algorithms relies on a global Lipschitz\nconstant to encapsulate the function's nonlinearity. This may lead to loose\nregret bounds, since by itself, a large gradient does not necessarily cause a\nlarge regret, but only in regions where the uncertainty in the reward's\nparameters is high. To overcome this problem, we introduce a new smoothness\ncriterion, which we term \\emph{Gini-weighted smoothness}, that takes into\naccount both the nonlinearity of the reward and concentration properties of the\narms. We show that a linear dependence of the regret in the batch size in\nexisting algorithms can be replaced by this smoothness parameter. This, in\nturn, leads to much tighter regret bounds when the smoothness parameter is\nbatch-size independent. For example, in the probabilistic maximum coverage\n(PMC) problem, that has many applications, including influence maximization,\ndiverse recommendations and more, we achieve dramatic improvements in the upper\nbounds. We also prove matching lower bounds for the PMC problem and show that\nour algorithm is tight, up to a logarithmic factor in the problem's parameters.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:58:24 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 13:32:38 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 12:03:53 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 07:22:57 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.03135", "submitter": "Patrick Rebeschini", "authors": "Dominic Richards and Patrick Rebeschini", "title": "Optimal Statistical Rates for Decentralised Non-Parametric Regression\n  with Linear Speed-Up", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the learning performance of Distributed Gradient Descent in the\ncontext of multi-agent decentralised non-parametric regression with the square\nloss function when i.i.d. samples are assigned to agents. We show that if\nagents hold sufficiently many samples with respect to the network size, then\nDistributed Gradient Descent achieves optimal statistical rates with a number\nof iterations that scales, up to a threshold, with the inverse of the spectral\ngap of the gossip matrix divided by the number of samples owned by each agent\nraised to a problem-dependent power. The presence of the threshold comes from\nstatistics. It encodes the existence of a \"big data\" regime where the number of\nrequired iterations does not depend on the network topology. In this regime,\nDistributed Gradient Descent achieves optimal statistical rates with the same\norder of iterations as gradient descent run with all the samples in the\nnetwork. Provided the communication delay is sufficiently small, the\ndistributed protocol yields a linear speed-up in runtime compared to the\nsingle-machine protocol. This is in contrast to decentralised optimisation\nalgorithms that do not exploit statistics and only yield a linear speed-up in\ngraphs where the spectral gap is bounded away from zero. Our results exploit\nthe statistical concentration of quantities held by agents and shed new light\non the interplay between statistics and communication in decentralised methods.\nBounds are given in the standard non-parametric setting with source/capacity\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:08:28 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:29:35 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Richards", "Dominic", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1905.03151", "submitter": "Giles Hooker", "authors": "Giles Hooker and Lucas Mentch", "title": "Please Stop Permuting Features: An Explanation and Alternatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advocates against permute-and-predict (PaP) methods for\ninterpreting black box functions. Methods such as the variable importance\nmeasures proposed for random forests, partial dependence plots, and individual\nconditional expectation plots remain popular because of their ability to\nprovide model-agnostic measures that depend only on the pre-trained model\noutput. However, numerous studies have found that these tools can produce\ndiagnostics that are highly misleading, particularly when there is strong\ndependence among features. Rather than simply add to this growing literature by\nfurther demonstrating such issues, here we seek to provide an explanation for\nthe observed behavior. In particular, we argue that breaking dependencies\nbetween features in hold-out data places undue emphasis on sparse regions of\nthe feature space by forcing the original model to extrapolate to regions where\nthere is little to no data. We explore these effects through various settings\nwhere a ground-truth is understood and find support for previous claims in the\nliterature that PaP metrics tend to over-emphasize correlated features both in\nvariable importance and partial dependence plots, even though applying\npermutation methods to the ground-truth models do not. As an alternative, we\nrecommend more direct approaches that have proven successful in other settings:\nexplicitly removing features, conditional permutations, or model distillation\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 22:37:47 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Hooker", "Giles", ""], ["Mentch", "Lucas", ""]]}, {"id": "1905.03168", "submitter": "arXiv Admin", "authors": "Gael Kamdem De Teyou and Junior Ziazet", "title": "Convolutional Neural Network for Intrusion Detection System In Cyber\n  Physical Systems", "comments": "This submission has been withdrawn by arXiv administrators due to\n  inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extensive use of Information and Communication Technology in critical\ninfrastructures such as Industrial Control Systems make them vulnerable to\ncyber-attacks. One particular class of cyber-attacks is advanced persistent\nthreats where highly skilled attackers can steal user authentication\ninformation's and move in the network from host to host until a valuable target\nis reached. The detection of the attacker should occur as soon as possible in\norder to take appropriate response, otherwise the attacker will have enough\ntime to reach sensitive assets. When facing intelligent threats, intelligent\nsolutions have to be designed. Therefore, in this paper, we take advantage of\nrecent progress in deep learning to build a convolutional neural networks that\ncan detect intrusions in cyber physical system. The Intrusion Detection System\nis applied on the NSL-KDD dataset and the performances of the proposed approach\nare presented and compared with the state of art. Results show the\neffectiveness of the techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:53:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:32:43 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["De Teyou", "Gael Kamdem", ""], ["Ziazet", "Junior", ""]]}, {"id": "1905.03175", "submitter": "Jinming Lu", "authors": "Siyuan Lu, Jinming Lu, Jun Lin and Zhongfeng Wang", "title": "A Hardware-Oriented and Memory-Efficient Method for CTC Decoding", "comments": "13 pages, 11 figures", "journal-ref": "IEEE Access, vol. 7, pp. 120681-120694, 2019", "doi": "10.1109/ACCESS.2019.2937680", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Connectionist Temporal Classification (CTC) has achieved great success in\nsequence to sequence analysis tasks such as automatic speech recognition (ASR)\nand scene text recognition (STR). These applications can use the CTC objective\nfunction to train the recurrent neural networks (RNNs), and decode the outputs\nof RNNs during inference. While hardware architectures for RNNs have been\nstudied, hardware-based CTCdecoders are desired for high-speed CTC-based\ninference systems. This paper, for the first time, provides a low-complexity\nand memory-efficient approach to build a CTC-decoder based on the beam search\ndecoding. Firstly, we improve the beam search decoding algorithm to save the\nstorage space. Secondly, we compress a dictionary (reduced from 26.02MB to\n1.12MB) and use it as the language model. Meanwhile searching this dictionary\nis trivial. Finally, a fixed-point CTC-decoder for an English ASR and an STR\ntask using the proposed method is implemented with C++ language. It is shown\nthat the proposed method has little precision loss compared with its\nfloating-point counterpart. Our experiments demonstrate the compression ratio\nof the storage required by the proposed beam search decoding algorithm are\n29.49 (ASR) and 17.95 (STR).\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:59:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lu", "Siyuan", ""], ["Lu", "Jinming", ""], ["Lin", "Jun", ""], ["Wang", "Zhongfeng", ""]]}, {"id": "1905.03177", "submitter": "Zachary Charles", "authors": "Shashank Rajput, Zhili Feng, Zachary Charles, Po-Ling Loh, Dimitris\n  Papailiopoulos", "title": "Does Data Augmentation Lead to Positive Margin?", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation (DA) is commonly used during model training, as it\nsignificantly improves test error and model robustness. DA artificially expands\nthe training set by applying random noise, rotations, crops, or even\nadversarial perturbations to the input data. Although DA is widely used, its\ncapacity to provably improve robustness is not fully understood. In this work,\nwe analyze the robustness that DA begets by quantifying the margin that DA\nenforces on empirical risk minimizers. We first focus on linear separators, and\nthen a class of nonlinear models whose labeling is constant within small convex\nhulls of data points. We present lower bounds on the number of augmented data\npoints required for non-zero margin, and show that commonly used DA techniques\nmay only introduce significant margin after adding exponentially many points to\nthe data set.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:03:06 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Rajput", "Shashank", ""], ["Feng", "Zhili", ""], ["Charles", "Zachary", ""], ["Loh", "Po-Ling", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1905.03209", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali, Felix Zhou, Christian Daul, Barbara Braden, Adam Bailey,\n  Stefano Realdon, James East, Georges Wagni\\`eres, Victor Loschenov, Enrico\n  Grisan, Walter Blondel, Jens Rittscher", "title": "Endoscopy artifact detection (EAD 2019) challenge dataset", "comments": "12 pages, EAD2019 dataset description", "journal-ref": null, "doi": "10.17632/C7FJBXCGJ9.1", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Endoscopic artifacts are a core challenge in facilitating the diagnosis and\ntreatment of diseases in hollow organs. Precise detection of specific artifacts\nlike pixel saturations, motion blur, specular reflections, bubbles and debris\nis essential for high-quality frame restoration and is crucial for realizing\nreliable computer-assisted tools for improved patient care. At present most\nvideos in endoscopy are currently not analyzed due to the abundant presence of\nmulti-class artifacts in video frames. Through the endoscopic artifact\ndetection (EAD 2019) challenge, we address this key bottleneck problem by\nsolving the accurate identification and localization of endoscopic frame\nartifacts to enable further key quantitative analysis of unusable video frames\nsuch as mosaicking and 3D reconstruction which is crucial for delivering\nimproved patient care. This paper summarizes the challenge tasks and describes\nthe dataset and evaluation criteria established in the EAD 2019 challenge.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:53:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Ali", "Sharib", ""], ["Zhou", "Felix", ""], ["Daul", "Christian", ""], ["Braden", "Barbara", ""], ["Bailey", "Adam", ""], ["Realdon", "Stefano", ""], ["East", "James", ""], ["Wagni\u00e8res", "Georges", ""], ["Loschenov", "Victor", ""], ["Grisan", "Enrico", ""], ["Blondel", "Walter", ""], ["Rittscher", "Jens", ""]]}, {"id": "1905.03218", "submitter": "Xi Zhang", "authors": "Xi Sheryl Zhang, Fengyi Tang, Hiroko Dodge, Jiayu Zhou, Fei Wang", "title": "MetaPred: Meta-Learning for Clinical Risk Prediction with Limited\n  Patient Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, increasingly augmentation of health data, such as patient\nElectronic Health Records (EHR), are becoming readily available. This provides\nan unprecedented opportunity for knowledge discovery and data mining algorithms\nto dig insights from them, which can, later on, be helpful to the improvement\nof the quality of care delivery. Predictive modeling of clinical risk,\nincluding in-hospital mortality, hospital readmission, chronic disease onset,\ncondition exacerbation, etc., from patient EHR, is one of the health data\nanalytic problems that attract most of the interests. The reason is not only\nbecause the problem is important in clinical settings, but also there are\nchallenges working with EHR such as sparsity, irregularity, temporality, etc.\nDifferent from applications in other domains such as computer vision and\nnatural language processing, the labeled data samples in medicine (patients)\nare relatively limited, which creates lots of troubles for effective predictive\nmodel learning, especially for complicated models such as deep learning. In\nthis paper, we propose MetaPred, a meta-learning for clinical risk prediction\nfrom longitudinal patient EHRs. In particular, in order to predict the target\nrisk where there are limited data samples, we train a meta-learner from a set\nof related risk prediction tasks which learns how a good predictor is learned.\nThe meta-learned can then be directly used in target risk prediction, and the\nlimited available samples can be used for further fine-tuning the model\nperformance. The effectiveness of MetaPred is tested on a real patient EHR\nrepository from Oregon Health & Science University. We are able to demonstrate\nthat with CNN and RNN as base predictors, MetaPred can achieve much better\nperformance for predicting target risk with low resources comparing with the\npredictor trained on the limited samples available for this risk.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:07:51 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Zhang", "Xi Sheryl", ""], ["Tang", "Fengyi", ""], ["Dodge", "Hiroko", ""], ["Zhou", "Jiayu", ""], ["Wang", "Fei", ""]]}, {"id": "1905.03231", "submitter": "Matteo Papini", "authors": "Matteo Papini, Matteo Pirotta, Marcello Restelli", "title": "Smoothing Policies and Safe Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient algorithms are among the best candidates for the much\nanticipated application of reinforcement learning to real-world control tasks,\nsuch as the ones arising in robotics. However, the trial-and-error nature of\nthese methods introduces safety issues whenever the learning phase itself must\nbe performed on a physical system. In this paper, we address a specific safety\nformulation, where danger is encoded in the reward signal and the learning\nagent is constrained to never worsen its performance. By studying actor-only\npolicy gradient from a stochastic optimization perspective, we establish\nimprovement guarantees for a wide class of parametric policies, generalizing\nexisting results on Gaussian policies. This, together with novel upper bounds\non the variance of policy gradient estimators, allows to identify those\nmeta-parameter schedules that guarantee monotonic improvement with high\nprobability. The two key meta-parameters are the step size of the parameter\nupdates and the batch size of the gradient estimators. By a joint, adaptive\nselection of these meta-parameters, we obtain a safe policy gradient algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:40:46 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Papini", "Matteo", ""], ["Pirotta", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1905.03239", "submitter": "Huadong Liao", "authors": "Huadong Liao, Jiawei He, Kunxian Shu", "title": "Generative Model with Dynamic Linear Flow", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models are a family of exact log-likelihood models with\ntractable sampling and latent-variable inference, hence conceptually attractive\nfor modeling complex distributions. However, flow-based models are limited by\ndensity estimation performance issues as compared to state-of-the-art\nautoregressive models. Autoregressive models, which also belong to the family\nof likelihood-based methods, however suffer from limited parallelizability. In\nthis paper, we propose Dynamic Linear Flow (DLF), a new family of invertible\ntransformations with partially autoregressive structure. Our method benefits\nfrom the efficient computation of flow-based methods and high density\nestimation performance of autoregressive methods. We demonstrate that the\nproposed DLF yields state-of-theart performance on ImageNet 32x32 and 64x64 out\nof all flow-based methods, and is competitive with the best autoregressive\nmodel. Additionally, our model converges 10 times faster than Glow (Kingma and\nDhariwal, 2018). The code is available at https://github.com/naturomics/DLF.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:51:11 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Liao", "Huadong", ""], ["He", "Jiawei", ""], ["Shu", "Kunxian", ""]]}, {"id": "1905.03282", "submitter": "Behrooz Razeghi", "authors": "Shideh Rezaeifar, Behrooz Razeghi, Olga Taran, Taras Holotyak, Slava\n  Voloshynovskiy", "title": "Reconstruction of Privacy-Sensitive Data from Protected Templates", "comments": "accepted at ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of data reconstruction from\nprivacy-protected templates, based on recent concept of sparse ternary coding\nwith ambiguization (STCA). The STCA is a generalization of randomization\ntechniques which includes random projections, lossy quantization, and addition\nof ambiguization noise to satisfy the privacy-utility trade-off requirements.\nThe theoretical privacy-preserving properties of STCA have been validated on\nsynthetic data. However, the applicability of STCA to real data and potential\nthreats linked to reconstruction based on recent deep reconstruction algorithms\nare still open problems. Our results demonstrate that STCA still achieves the\nclaimed theoretical performance when facing deep reconstruction attacks for the\nsynthetic i.i.d. data, while for real images special measures are required to\nguarantee proper protection of the templates.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 18:17:01 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Rezaeifar", "Shideh", ""], ["Razeghi", "Behrooz", ""], ["Taran", "Olga", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1905.03290", "submitter": "Artem Sobolev", "authors": "Artem Sobolev and Dmitry Vetrov", "title": "Importance Weighted Hierarchical Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Inference is a powerful tool in the Bayesian modeling toolkit,\nhowever, its effectiveness is determined by the expressivity of the utilized\nvariational distributions in terms of their ability to match the true posterior\ndistribution. In turn, the expressivity of the variational family is largely\nlimited by the requirement of having a tractable density function. To overcome\nthis roadblock, we introduce a new family of variational upper bounds on a\nmarginal log density in the case of hierarchical models (also known as latent\nvariable models). We then give an upper bound on the Kullback-Leibler\ndivergence and derive a family of increasingly tighter variational lower bounds\non the otherwise intractable standard evidence lower bound for hierarchical\nvariational distributions, enabling the use of more expressive approximate\nposteriors. We show that previously known methods, such as Hierarchical\nVariational Models, Semi-Implicit Variational Inference and Doubly\nSemi-Implicit Variational Inference can be seen as special cases of the\nproposed approach, and empirically demonstrate superior performance of the\nproposed method in a set of experiments.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 18:38:51 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Sobolev", "Artem", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1905.03297", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Dennis Wei, Bhanukiran Vinzamuri, Monica Shekhar, Sara\n  E. Berger, Subhro Das, Kush R. Varshney", "title": "Interpretable Subgroup Discovery in Treatment Effect Estimation with\n  Application to Opioid Prescribing Guidelines", "comments": null, "journal-ref": "First ACM Conference on Health, Inference and Learning (CHIL) 2020", "doi": "10.1145/3368555.3384456", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dearth of prescribing guidelines for physicians is one key driver of the\ncurrent opioid epidemic in the United States. In this work, we analyze medical\nand pharmaceutical claims data to draw insights on characteristics of patients\nwho are more prone to adverse outcomes after an initial synthetic opioid\nprescription. Toward this end, we propose a generative model that allows\ndiscovery from observational data of subgroups that demonstrate an enhanced or\ndiminished causal effect due to treatment. Our approach models these\nsub-populations as a mixture distribution, using sparsity to enhance\ninterpretability, while jointly learning nonlinear predictors of the potential\noutcomes to better adjust for confounding. The approach leads to\nhuman-interpretable insights on discovered subgroups, improving the practical\nutility for decision support\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 19:00:09 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 20:27:46 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 19:48:54 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Nagpal", "Chirag", ""], ["Wei", "Dennis", ""], ["Vinzamuri", "Bhanukiran", ""], ["Shekhar", "Monica", ""], ["Berger", "Sara E.", ""], ["Das", "Subhro", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1905.03302", "submitter": "Priyadarshini Kumari", "authors": "Priyadarshini Kumari, Siddhartha Chaudhuri, and Subhasis Chaudhuri", "title": "PerceptNet: Learning Perceptual Similarity of Haptic Textures in\n  Presence of Unorderable Triplets", "comments": "Published in IEEE World Haptics Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to design haptic icons or build a haptic vocabulary, we require a\nset of easily distinguishable haptic signals to avoid perceptual ambiguity,\nwhich in turn requires a way to accurately estimate the perceptual\n(dis)similarity of such signals. In this work, we present a novel method to\nlearn such a perceptual metric based on data from human studies. Our method is\nbased on a deep neural network that projects signals to an embedding space\nwhere the natural Euclidean distance accurately models the degree of\ndissimilarity between two signals. The network is trained only on non-numerical\ncomparisons of triplets of signals, using a novel triplet loss that considers\nboth types of triplets that are easy to order (inequality constraints), as well\nas those that are unorderable/ambiguous (equality constraints). Unlike prior\nMDS-based non-parametric approaches, our method can be trained on a partial set\nof comparisons and can embed new haptic signals without retraining the model\nfrom scratch. Extensive experimental evaluations show that our method is\nsignificantly more effective at modeling perceptual dissimilarity than\nalternatives.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 19:06:39 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 07:23:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kumari", "Priyadarshini", ""], ["Chaudhuri", "Siddhartha", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "1905.03319", "submitter": "Xiao Lin", "authors": "Xiao Lin, Indranil Sur, Samuel A. Nastase, Ajay Divakaran, Uri Hasson\n  and Mohamed R. Amer", "title": "Data-Efficient Mutual Information Neural Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring Mutual Information (MI) between high-dimensional, continuous,\nrandom variables from observed samples has wide theoretical and practical\napplications. Recent work, MINE (Belghazi et al. 2018), focused on estimating\ntight variational lower bounds of MI using neural networks, but assumed\nunlimited supply of samples to prevent overfitting. In real world applications,\ndata is not always available at a surplus. In this work, we focus on improving\ndata efficiency and propose a Data-Efficient MINE Estimator (DEMINE), by\ndeveloping a relaxed predictive MI lower bound that can be estimated at higher\ndata efficiency by orders of magnitudes. The predictive MI lower bound also\nenables us to develop a new meta-learning approach using task augmentation,\nMeta-DEMINE, to improve generalization of the network and further boost\nestimation accuracy empirically. With improved data-efficiency, our estimators\nenables statistical testing of dependency at practical dataset sizes. We\ndemonstrate the effectiveness of our estimators on synthetic benchmarks and a\nreal world fMRI data, with application of inter-subject correlation analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:22:13 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 22:26:54 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lin", "Xiao", ""], ["Sur", "Indranil", ""], ["Nastase", "Samuel A.", ""], ["Divakaran", "Ajay", ""], ["Hasson", "Uri", ""], ["Amer", "Mohamed R.", ""]]}, {"id": "1905.03329", "submitter": "Charlie Frogner", "authors": "Charlie Frogner, Farzaneh Mirzazadeh, Justin Solomon", "title": "Learning Embeddings into Entropic Wasserstein Spaces", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean embeddings of data are fundamentally limited in their ability to\ncapture latent semantic structures, which need not conform to Euclidean spatial\nassumptions. Here we consider an alternative, which embeds data as discrete\nprobability distributions in a Wasserstein space, endowed with an optimal\ntransport metric. Wasserstein spaces are much larger and more flexible than\nEuclidean spaces, in that they can successfully embed a wider variety of metric\nstructures. We exploit this flexibility by learning an embedding that captures\nsemantic information in the Wasserstein distance between embedded\ndistributions. We examine empirically the representational capacity of our\nlearned Wasserstein embeddings, showing that they can embed a wide variety of\nmetric structures with smaller distortion than an equivalent Euclidean\nembedding. We also investigate an application to word embedding, demonstrating\na unique advantage of Wasserstein embeddings: We can visualize the\nhigh-dimensional embedding directly, since it is a probability distribution on\na low-dimensional space. This obviates the need for dimensionality reduction\ntechniques like t-SNE for visualization.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:48:28 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Frogner", "Charlie", ""], ["Mirzazadeh", "Farzaneh", ""], ["Solomon", "Justin", ""]]}, {"id": "1905.03330", "submitter": "Scott Wisdom", "authors": "Ilya Kavalerov, Scott Wisdom, Hakan Erdogan, Brian Patton, Kevin\n  Wilson, Jonathan Le Roux, John R. Hershey", "title": "Universal Sound Separation", "comments": "5 pages, accepted to WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning approaches have achieved impressive performance on\nspeech enhancement and separation tasks. However, these approaches have not\nbeen investigated for separating mixtures of arbitrary sounds of different\ntypes, a task we refer to as universal sound separation, and it is unknown how\nperformance on speech tasks carries over to non-speech tasks. To study this\nquestion, we develop a dataset of mixtures containing arbitrary sounds, and use\nit to investigate the space of mask-based separation architectures, varying\nboth the overall network architecture and the framewise analysis-synthesis\nbasis for signal transformations. These network architectures include\nconvolutional long short-term memory networks and time-dilated convolution\nstacks inspired by the recent success of time-domain enhancement networks like\nConvTasNet. For the latter architecture, we also propose novel modifications\nthat further improve separation performance. In terms of the framewise\nanalysis-synthesis basis, we explore both a short-time Fourier transform (STFT)\nand a learnable basis, as used in ConvTasNet. For both of these bases, we also\nexamine the effect of window size. In particular, for STFTs, we find that\nlonger windows (25-50 ms) work best for speech/non-speech separation, while\nshorter windows (2.5 ms) work best for arbitrary sounds. For learnable bases,\nshorter windows (2.5 ms) work best on all tasks. Surprisingly, for universal\nsound separation, STFTs outperform learnable bases. Our best methods produce an\nimprovement in scale-invariant signal-to-distortion ratio of over 13 dB for\nspeech/non-speech separation and close to 10 dB for universal sound separation.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:48:49 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 20:44:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kavalerov", "Ilya", ""], ["Wisdom", "Scott", ""], ["Erdogan", "Hakan", ""], ["Patton", "Brian", ""], ["Wilson", "Kevin", ""], ["Roux", "Jonathan Le", ""], ["Hershey", "John R.", ""]]}, {"id": "1905.03333", "submitter": "Yunhan Jia", "authors": "Yunhan Jia, Yantao Lu, Senem Velipasalar, Zhenyu Zhong, Tao Wei", "title": "Enhancing Cross-task Transferability of Adversarial Examples with\n  Dispersion Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are known to be vulnerable to carefully crafted adversarial\nexamples, and these malicious samples often transfer, i.e., they maintain their\neffectiveness even against other models. With great efforts delved into the\ntransferability of adversarial examples, surprisingly, less attention has been\npaid to its impact on real-world deep learning deployment. In this paper, we\ninvestigate the transferability of adversarial examples across a wide range of\nreal-world computer vision tasks, including image classification, explicit\ncontent detection, optical character recognition (OCR), and object detection.\nIt represents the cybercriminal's situation where an ensemble of different\ndetection mechanisms need to be evaded all at once. We propose practical attack\nthat overcomes existing attacks' limitation of requiring task-specific loss\nfunctions by targeting on the `dispersion' of internal feature map. We report\nevaluation on four different computer vision tasks provided by Google Cloud\nVision APIs to show how our approach outperforms existing attacks by degrading\nperformance of multiple CV tasks by a large margin with only modest\nperturbations.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:56:47 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Jia", "Yunhan", ""], ["Lu", "Yantao", ""], ["Velipasalar", "Senem", ""], ["Zhong", "Zhenyu", ""], ["Wei", "Tao", ""]]}, {"id": "1905.03350", "submitter": "Ali Hebbal", "authors": "Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi and\n  Nouredine Melab", "title": "Bayesian Optimization using Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization using Gaussian Processes is a popular approach to deal\nwith the optimization of expensive black-box functions. However, because of the\na priori on the stationarity of the covariance matrix of classic Gaussian\nProcesses, this method may not be adapted for non-stationary functions involved\nin the optimization problem. To overcome this issue, a new Bayesian\nOptimization approach is proposed. It is based on Deep Gaussian Processes as\nsurrogate models instead of classic Gaussian Processes. This modeling technique\nincreases the power of representation to capture the non-stationarity by simply\nconsidering a functional composition of stationary Gaussian Processes,\nproviding a multiple layer structure. This paper proposes a new algorithm for\nGlobal Optimization by coupling Deep Gaussian Processes and Bayesian\nOptimization. The specificities of this optimization method are discussed and\nhighlighted with academic test cases. The performance of the proposed algorithm\nis assessed on analytical test cases and an aerospace design optimization\nproblem and compared to the state-of-the-art stationary and non-stationary\nBayesian Optimization approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 11:07:53 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hebbal", "Ali", ""], ["Brevault", "Loic", ""], ["Balesdent", "Mathieu", ""], ["Talbi", "El-Ghazali", ""], ["Melab", "Nouredine", ""]]}, {"id": "1905.03353", "submitter": "Ioannis Panageas", "authors": "Constantinos Daskalakis, Nishanth Dikkala, Ioannis Panageas", "title": "Regression from Dependent Observations", "comments": "33 pages, in proceedings of STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard linear and logistic regression models assume that the response\nvariables are independent, but share the same linear relationship to their\ncorresponding vectors of covariates. The assumption that the response variables\nare independent is, however, too strong. In many applications, these responses\nare collected on nodes of a network, or some spatial or temporal domain, and\nare dependent. Examples abound in financial and meteorological applications,\nand dependencies naturally arise in social networks through peer effects.\nRegression with dependent responses has thus received a lot of attention in the\nStatistics and Economics literature, but there are no strong consistency\nresults unless multiple independent samples of the vectors of dependent\nresponses can be collected from these models. We present computationally and\nstatistically efficient methods for linear and logistic regression models when\nthe response variables are dependent on a network. Given one sample from a\nnetworked linear or logistic regression model and under mild assumptions, we\nprove strong consistency results for recovering the vector of coefficients and\nthe strength of the dependencies, recovering the rates of standard regression\nunder independent observations. We use projected gradient descent on the\nnegative log-likelihood, or negative log-pseudolikelihood, and establish their\nstrong convexity and consistency using concentration of measure for dependent\nrandom variables.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 21:11:50 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 10:26:36 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Panageas", "Ioannis", ""]]}, {"id": "1905.03356", "submitter": "Yicheng Chen", "authors": "Yicheng Chen, Angela Jakary, Sivakami Avadiappan, Christopher P. Hess,\n  Janine M. Lupo", "title": "QSMGAN: Improved Quantitative Susceptibility Mapping using 3D Generative\n  Adversarial Networks with Increased Receptive Field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative susceptibility mapping (QSM) is a powerful MRI technique that\nhas shown great potential in quantifying tissue susceptibility in numerous\nneurological disorders. However, the intrinsic ill-posed dipole inversion\nproblem greatly affects the accuracy of the susceptibility map. We propose\nQSMGAN: a 3D deep convolutional neural network approach based on a 3D U-Net\narchitecture with increased receptive field of the input phase compared to the\noutput and further refined the network using the WGAN with gradient penalty\ntraining strategy. Our method generates accurate QSM maps from single\norientation phase maps efficiently and performs significantly better than\ntraditional non-learning-based dipole inversion algorithms. The generalization\ncapability was verified by applying the algorithm to an unseen pathology--brain\ntumor patients with radiation-induced cerebral microbleeds.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 21:19:02 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:27:22 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chen", "Yicheng", ""], ["Jakary", "Angela", ""], ["Avadiappan", "Sivakami", ""], ["Hess", "Christopher P.", ""], ["Lupo", "Janine M.", ""]]}, {"id": "1905.03375", "submitter": "Harald Steck", "authors": "Harald Steck", "title": "Embarrassingly Shallow Autoencoders for Sparse Data", "comments": "In the proceedings of the Web Conference (WWW) 2019 (7 pages)", "journal-ref": null, "doi": "10.1145/3308558.3313710", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining simple elements from the literature, we define a linear model that\nis geared toward sparse data, in particular implicit feedback data for\nrecommender systems. We show that its training objective has a closed-form\nsolution, and discuss the resulting conceptual insights. Surprisingly, this\nsimple model achieves better ranking accuracy than various state-of-the-art\ncollaborative-filtering approaches, including deep non-linear models, on most\nof the publicly available data-sets used in our experiments.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 22:16:59 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Steck", "Harald", ""]]}, {"id": "1905.03381", "submitter": "Jiong Zhang", "authors": "Jiong Zhang, Hsiang-fu Yu, Inderjit S. Dhillon", "title": "AutoAssist: A Framework to Accelerate Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have yielded superior performance in many applications;\nhowever, the gradient computation in a deep model with millions of instances\nlead to a lengthy training process even with modern GPU/TPU hardware\nacceleration. In this paper, we propose AutoAssist, a simple framework to\naccelerate training of a deep neural network. Typically, as the training\nprocedure evolves, the amount of improvement in the current model by a\nstochastic gradient update on each instance varies dynamically. In AutoAssist,\nwe utilize this fact and design a simple instance shrinking operation, which is\nused to filter out instances with relatively low marginal improvement to the\ncurrent model; thus the computationally intensive gradient computations are\nperformed on informative instances as much as possible. We prove that the\nproposed technique outperforms vanilla SGD with existing importance sampling\napproaches for linear SVM problems, and establish an O(1/k) convergence for\nstrongly convex problems. In order to apply the proposed techniques to\naccelerate training of deep models, we propose to jointly train a very\nlightweight Assistant network in addition to the original deep network referred\nto as Boss. The Assistant network is designed to gauge the importance of a\ngiven instance with respect to the current Boss such that a shrinking operation\ncan be applied in the batch generator. With careful design, we train the Boss\nand Assistant in a nonblocking and asynchronous fashion such that overhead is\nminimal. We demonstrate that AutoAssist reduces the number of epochs by 40% for\ntraining a ResNet to reach the same test accuracy on an image classification\ndata set and saves 30% training time needed for a transformer model to yield\nthe same BLEU scores on a translation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 22:36:37 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhang", "Jiong", ""], ["Yu", "Hsiang-fu", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1905.03389", "submitter": "Vladimir Golkov", "authors": "Jan Schuchardt, Vladimir Golkov, Daniel Cremers", "title": "Learning to Evolve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution and learning are two of the fundamental mechanisms by which life\nadapts in order to survive and to transcend limitations. These biological\nphenomena inspired successful computational methods such as evolutionary\nalgorithms and deep learning. Evolution relies on random mutations and on\nrandom genetic recombination. Here we show that learning to evolve, i.e.\nlearning to mutate and recombine better than at random, improves the result of\nevolution in terms of fitness increase per generation and even in terms of\nattainable fitness. We use deep reinforcement learning to learn to dynamically\nadjust the strategy of evolutionary algorithms to varying circumstances. Our\nmethods outperform classical evolutionary algorithms on combinatorial and\ncontinuous optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 23:35:02 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Schuchardt", "Jan", ""], ["Golkov", "Vladimir", ""], ["Cremers", "Daniel", ""]]}, {"id": "1905.03406", "submitter": "Francisco Sahli Costabal", "authors": "Francisco Sahli Costabal, Paris Perdikaris, Ellen Kuhl and Daniel E.\n  Hurtado", "title": "Multi-fidelity classification using Gaussian processes: accelerating the\n  prediction of large-scale computational models", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.112602", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques typically rely on large datasets to create\naccurate classifiers. However, there are situations when data is scarce and\nexpensive to acquire. This is the case of studies that rely on state-of-the-art\ncomputational models which typically take days to run, thus hindering the\npotential of machine learning tools. In this work, we present a novel\nclassifier that takes advantage of lower fidelity models and inexpensive\napproximations to predict the binary output of expensive computer simulations.\nWe postulate an autoregressive model between the different levels of fidelity\nwith Gaussian process priors. We adopt a fully Bayesian treatment for the\nhyper-parameters and use Markov Chain Mont Carlo samplers. We take advantage of\nthe probabilistic nature of the classifier to implement active learning\nstrategies. We also introduce a sparse approximation to enhance the ability of\nthemulti-fidelity classifier to handle large datasets. We test these\nmulti-fidelity classifiers against their single-fidelity counterpart with\nsynthetic data, showing a median computational cost reduction of 23% for a\ntarget accuracy of 90%. In an application to cardiac electrophysiology, the\nmulti-fidelity classifier achieves an F1 score, the harmonic mean of precision\nand recall, of 99.6% compared to 74.1% of a single-fidelity classifier when\nboth are trained with 50 samples. In general, our results show that the\nmulti-fidelity classifiers outperform their single-fidelity counterpart in\nterms of accuracy in all cases. We envision that this new tool will enable\nresearchers to study classification problems that would otherwise be\nprohibitively expensive. Source code is available at\nhttps://github.com/fsahli/MFclass.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 01:52:47 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Costabal", "Francisco Sahli", ""], ["Perdikaris", "Paris", ""], ["Kuhl", "Ellen", ""], ["Hurtado", "Daniel E.", ""]]}, {"id": "1905.03410", "submitter": "Jonathan Scarlett", "authors": "Zihan Li, Matthias Fresacher, Jonathan Scarlett", "title": "Learning Erd\\H{o}s-R\\'enyi Random Graphs via Edge Detecting Queries", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LG math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of learning an unknown graph via\nqueries on groups of nodes, with the result indicating whether or not at least\none edge is present among those nodes. While learning arbitrary graphs with $n$\nnodes and $k$ edges is known to be hard in the sense of requiring $\\Omega(\n\\min\\{ k^2 \\log n, n^2\\})$ tests (even when a small probability of error is\nallowed), we show that learning an Erd\\H{o}s-R\\'enyi random graph with an\naverage of $\\bar{k}$ edges is much easier; namely, one can attain\nasymptotically vanishing error probability with only $O(\\bar{k}\\log n)$ tests.\nWe establish such bounds for a variety of algorithms inspired by the group\ntesting problem, with explicit constant factors indicating a near-optimal\nnumber of tests, and in some cases asymptotic optimality including constant\nfactors. In addition, we present an alternative design that permits a\nnear-optimal sublinear decoding time of $O(\\bar{k} \\log^2 \\bar{k} + \\bar{k}\n\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 02:10:17 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 01:13:51 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 11:02:45 GMT"}, {"version": "v4", "created": "Fri, 3 Jan 2020 22:47:29 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Li", "Zihan", ""], ["Fresacher", "Matthias", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "1905.03418", "submitter": "arXiv Admin", "authors": "Gael Kamdem De Teyou", "title": "Deep Learning Acceleration Techniques for Real Time Mobile Vision\n  Applications", "comments": "This submission has been withdrawn by arXiv administrators due to\n  inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has become a crucial technology for Artificial\nIntelligence (AI). It is a powerful technique to automatically extract\nhigh-level features from complex data which can be exploited for applications\nsuch as computer vision, natural language processing, cybersecurity,\ncommunications, and so on. For the particular case of computer vision, several\nalgorithms like object detection in real time videos have been proposed and\nthey work well on Desktop GPUs and distributed computing platforms. However\nthese algorithms are still heavy for mobile and embedded visual applications.\nThe rapid spreading of smart portable devices and the emerging 5G network are\nintroducing new smart multimedia applications in mobile environments. As a\nconsequence, the possibility of implementing deep neural networks to mobile\nenvironments has attracted a lot of researchers. This paper presents emerging\ndeep learning acceleration techniques that can enable the delivery of real time\nvisual recognition into the hands of end users, anytime and anywhere.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 02:39:37 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:31:48 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["De Teyou", "Gael Kamdem", ""]]}, {"id": "1905.03420", "submitter": "Muhammad Bilal", "authors": "Muhammad Bilal and Mohib Ullah", "title": "A deep learning approach for analyzing the composition of chemometric\n  data", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel deep learning based chemometric data analysis technique. We\ntrained L2 regularized sparse autoencoder end-to-end for reducing the size of\nthe feature vector to handle the classic problem of the curse of dimensionality\nin chemometric data analysis. We introduce a novel technique of automatic\nselection of nodes inside the hidden layer of an autoencoder through Pareto\noptimization. Moreover, Gaussian process regressor is applied on the reduced\nsize feature vector for the regression. We evaluated our technique on orange\njuice and wine dataset and results are compared against 3 state-of-the-art\nmethods. Quantitative results are shown on Normalized Mean Square Error (NMSE)\nand the results show considerable improvement in the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:20:47 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Bilal", "Muhammad", ""], ["Ullah", "Mohib", ""]]}, {"id": "1905.03421", "submitter": "Kazuya Kakizaki", "authors": "Kazuya Kakizaki, Kosuke Yoshida", "title": "Adversarial Image Translation: Unrestricted Adversarial Examples in Face\n  Recognition Systems", "comments": "Kazuya Kakizaki and Kosuke Yoshida share equal contributions.\n  Accepted at AAAI Workshop on Artificial Intelligence Safety (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to recent advances in deep neural networks (DNNs), face recognition\nsystems have become highly accurate in classifying a large number of face\nimages. However, recent studies have found that DNNs could be vulnerable to\nadversarial examples, raising concerns about the robustness of such systems.\nAdversarial examples that are not restricted to small perturbations could be\nmore serious since conventional certified defenses might be ineffective against\nthem. To shed light on the vulnerability to such adversarial examples, we\npropose a flexible and efficient method for generating unrestricted adversarial\nexamples using image translation techniques. Our method enables us to translate\na source image into any desired facial appearance with large perturbations to\ndeceive target face recognition systems. Our experimental results indicate that\nour method achieved about $90$ and $80\\%$ attack success rates under white- and\nblack-box settings, respectively, and that the translated images are\nperceptually realistic and maintain the identifiability of the individual while\nthe perturbations are large enough to bypass certified defenses.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 02:58:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:05:43 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 06:36:40 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kakizaki", "Kazuya", ""], ["Yoshida", "Kosuke", ""]]}, {"id": "1905.03433", "submitter": "Baoyuan Wu", "authors": "Baoyuan Wu, Li Shen, Tong Zhang, Bernard Ghanem", "title": "MAP Inference via L2-Sphere Linear Program Reformulation", "comments": "Accepted to International Journal of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum a posteriori (MAP) inference is an important task for graphical\nmodels. Due to complex dependencies among variables in realistic model, finding\nan exact solution for MAP inference is often intractable. Thus, many\napproximation methods have been developed, among which the linear programming\n(LP) relaxation based methods show promising performance. However, one major\ndrawback of LP relaxation is that it is possible to give fractional solutions.\nInstead of presenting a tighter relaxation, in this work we propose a\ncontinuous but equivalent reformulation of the original MAP inference problem,\ncalled LS-LP. We add the L2-sphere constraint onto the original LP relaxation,\nleading to an intersected space with the local marginal polytope that is\nequivalent to the space of all valid integer label configurations. Thus, LS-LP\nis equivalent to the original MAP inference problem. We propose a perturbed\nalternating direction method of multipliers (ADMM) algorithm to optimize the\nLS-LP problem, by adding a sufficiently small perturbation epsilon onto the\nobjective function and constraints. We prove that the perturbed ADMM algorithm\nglobally converges to the epsilon-Karush-Kuhn-Tucker (epsilon-KKT) point of the\nLS-LP problem. The convergence rate will also be analyzed. Experiments on\nseveral benchmark datasets from Probabilistic Inference Challenge (PIC 2011)\nand OpenGM 2 show competitive performance of our proposed method against\nstate-of-the-art MAP inference methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 03:47:15 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 08:52:11 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 03:09:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Baoyuan", ""], ["Shen", "Li", ""], ["Zhang", "Tong", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1905.03438", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Yingyi Chen and Johan A.K. Suykens", "title": "Two-stage Best-scored Random Forest for Large-scale Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method designed for large-scale regression problems,\nnamely the two-stage best-scored random forest (TBRF). \"Best-scored\" means to\nselect one regression tree with the best empirical performance out of a certain\nnumber of purely random regression tree candidates, and \"two-stage\" means to\ndivide the original random tree splitting procedure into two: In stage one, the\nfeature space is partitioned into non-overlapping cells; in stage two, child\ntrees grow separately on these cells. The strengths of this algorithm can be\nsummarized as follows: First of all, the pure randomness in TBRF leads to the\nalmost optimal learning rates, and also makes ensemble learning possible, which\nresolves the boundary discontinuities long plaguing the existing algorithms.\nSecondly, the two-stage procedure paves the way for parallel computing, leading\nto computational efficiency. Last but not least, TBRF can serve as an inclusive\nframework where different mainstream regression strategies such as linear\npredictor and least squares support vector machines (LS-SVMs) can also be\nincorporated as value assignment approaches on leaves of the child trees,\ndepending on the characteristics of the underlying data sets. Numerical\nassessments on comparisons with other state-of-the-art methods on several\nlarge-scale real data sets validate the promising prediction accuracy and high\ncomputational efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 04:20:48 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hang", "Hanyuan", ""], ["Chen", "Yingyi", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1905.03440", "submitter": "Yong Zeng", "authors": "Yong Zeng and Xiaoli Xu", "title": "Path Design for Cellular-Connected UAV with Reinforcement Learning", "comments": "submitted for conference publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the path design problem for cellular-connected unmanned\naerial vehicle (UAV), which aims to minimize its mission completion time while\nmaintaining good connectivity with the cellular network. We first argue that\nthe conventional path design approach via formulating and solving optimization\nproblems faces several practical challenges, and then propose a new\nreinforcement learning-based UAV path design algorithm by applying\n\\emph{temporal-difference} method to directly learn the \\emph{state-value\nfunction} of the corresponding Markov Decision Process. The proposed algorithm\nis further extended by using linear function approximation with tile coding to\ndeal with large state space. The proposed algorithms only require the raw\nmeasured or simulation-generated signal strength as the input and are suitable\nfor both online and offline implementations. Numerical results show that the\nproposed path designs can successfully avoid the coverage holes of cellular\nnetworks even in the complex urban environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 04:48:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zeng", "Yong", ""], ["Xu", "Xiaoli", ""]]}, {"id": "1905.03454", "submitter": "Di Zhao", "authors": "Di Zhao, Jiqiang Liu, Jialin Wang, Wenjia Niu, Endong Tong, Tong Chen,\n  Gang Li", "title": "Bidirectional RNN-based Few-shot Training for Detecting Multi-stage\n  Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Feint Attack\", as a new type of APT attack, has become the focus of\nattention. It adopts a multi-stage attacks mode which can be concluded as a\ncombination of virtual attacks and real attacks. Under the cover of virtual\nattacks, real attacks can achieve the real purpose of the attacker, as a\nresult, it often caused huge losses inadvertently. However, to our knowledge,\nall previous works use common methods such as Causal-Correlation or Cased-based\nto detect outdated multi-stage attacks. Few attentions have been paid to detect\nthe \"Feint Attack\", because the difficulty of detection lies in the\ndiversification of the concept of \"Feint Attack\" and the lack of professional\ndatasets, many detection methods ignore the semantic relationship in the\nattack. Aiming at the existing challenge, this paper explores a new method to\nsolve the problem. In the attack scenario, the fuzzy clustering method based on\nattribute similarity is used to mine multi-stage attack chains. Then we use a\nfew-shot deep learning algorithm (SMOTE&CNN-SVM) and bidirectional Recurrent\nNeural Network model (Bi-RNN) to obtain the \"Feint Attack\" chains. \"Feint\nAttack\" is simulated by the real attack inserted in the normal causal attack\nchain, and the addition of the real attack destroys the causal relationship of\nthe original attack chain. So we used Bi-RNN coding to obtain the hidden\nfeature of \"Feint Attack\" chain. In the end, our method achieved the goal to\ndetect the \"Feint Attack\" accurately by using the LLDoS1.0 and LLDoS2.0 of\nDARPA2000 and CICIDS2017 of Canadian Institute for Cybersecurity.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 06:38:12 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhao", "Di", ""], ["Liu", "Jiqiang", ""], ["Wang", "Jialin", ""], ["Niu", "Wenjia", ""], ["Tong", "Endong", ""], ["Chen", "Tong", ""], ["Li", "Gang", ""]]}, {"id": "1905.03493", "submitter": "Sakshi Agarwal", "authors": "Sakshi Agarwal and Lav R. Varshney", "title": "Limits of Deepfake Detection: A Robust Estimation Viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake detection is formulated as a hypothesis testing problem to classify\nan image as genuine or GAN-generated. A robust statistics view of GANs is\nconsidered to bound the error probability for various GAN implementations in\nterms of their performance. The bounds are further simplified using a Euclidean\napproximation for the low error regime. Lastly, relationships between error\nprobability and epidemic thresholds for spreading processes in networks are\nestablished.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:01:08 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Agarwal", "Sakshi", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1905.03501", "submitter": "Yunfei Li", "authors": "Xiaoqin Zhang, Yunfei Li, Huimin Ma, Xiong Luo", "title": "Pretrain Soft Q-Learning with Imperfect Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining reinforcement learning methods with demonstrations has been an\nimportant concept in the study of reinforcement learning since a large amount\nof computing power is spent on online simulations with existing reinforcement\nlearning algorithms. Pretraining reinforcement learning remains a significant\nchallenge in exploiting expert demonstrations whilst keeping exploration\npotentials, especially for value based methods. In this paper, we propose a\npretraining method for soft Q-learning. Our work is inspired by pretraining\nmethods for actor-critic algorithms since soft Q-learning is a value based\nalgorithm that is equivalent to policy gradient. The proposed method is based\non $\\gamma$-discounted biased policy evaluation with entropy regularization,\nwhich is also the updating target of soft Q-learning. Our method is evaluated\non various tasks from Atari 2600. Experiments show that our method effectively\nlearns from imperfect demonstrations, and outperforms other state-of-the-art\nmethods that learn from expert demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:23:53 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhang", "Xiaoqin", ""], ["Li", "Yunfei", ""], ["Ma", "Huimin", ""], ["Luo", "Xiong", ""]]}, {"id": "1905.03517", "submitter": "Chris Einar San Agustin", "authors": "Chris Einar San Agustin", "title": "Mitigating Deep Learning Vulnerabilities from Adversarial Examples\n  Attack in the Cybersecurity Domain", "comments": "10 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning models are known to solve classification and regression\nproblems by employing a number of epoch and training samples on a large dataset\nwith optimal accuracy. However, that doesn't mean they are attack-proof or\nunexposed to vulnerabilities. Newly deployed systems particularly on a public\nenvironment (i.e public networks) are vulnerable to attacks from various\nentities. Moreover, published research on deep learning systems (Goodfellow et\nal., 2014) have determined a significant number of attacks points and a wide\narray of attack surface that has evidence of exploitation from adversarial\nexamples. Successful exploit on these systems could lead to critical real world\nrepercussions. For instance, (1) an adversarial attack on a self-driving car\nrunning a deep reinforcement learning system yields a direct misclassification\non humans causing untoward accidents.(2) a self-driving vehicle misreading a\nred light signal may cause the car to crash to another car (3)\nmisclassification of a pedestrian lane as an intersection lane that could lead\nto car crashes. This is just the tip of the iceberg, computer vision deployment\nare not entirely focused on self-driving cars but on many other areas as well -\nthat would have definitive impact on the real-world. These vulnerabilities must\nbe mitigated at an early stage of development. It is imperative to develop and\nimplement baseline security standards at a global level prior to real-world\ndeployment.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:24:39 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Agustin", "Chris Einar San", ""]]}, {"id": "1905.03546", "submitter": "Shujaat Khan Engr", "authors": "Shujaat Khan, Imran Naseem, Roberto Togneri, and Mohammed Bennamoun", "title": "A Novel Adaptive Kernel for the RBF Neural Networks", "comments": null, "journal-ref": "Circuits, Systems, and Signal Processing, vol. 36, no. 4, pp.\n  1639-1653, 2017", "doi": "10.1007/s00034-016-0375-7", "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel adaptive kernel for the radial basis\nfunction (RBF) neural networks. The proposed kernel adaptively fuses the\nEuclidean and cosine distance measures to exploit the reciprocating properties\nof the two. The proposed framework dynamically adapts the weights of the\nparticipating kernels using the gradient descent method thereby alleviating the\nneed for predetermined weights. The proposed method is shown to outperform the\nmanual fusion of the kernels on three major problems of estimation namely\nnonlinear system identification, pattern classification and function\napproximation.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 11:38:57 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Khan", "Shujaat", ""], ["Naseem", "Imran", ""], ["Togneri", "Roberto", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1905.03617", "submitter": "Sungjae Cho", "authors": "Sungjae Cho, Jaeseo Lim, Chris Hickey, Jung Ae Park, Byoung-Tak Zhang", "title": "Simulating Problem Difficulty in Arithmetic Cognition Through Dynamic\n  Connectionist Models", "comments": "7 pages; 15 figures; 5 tables; Published in the proceedings of the\n  17th International Conference on Cognitive Modelling (ICCM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study aims to investigate similarities between how humans and\nconnectionist models experience difficulty in arithmetic problems. Problem\ndifficulty was operationalized by the number of carries involved in solving a\ngiven problem. Problem difficulty was measured in humans by response time, and\nin models by computational steps. The present study found that both humans and\nconnectionist models experience difficulty similarly when solving binary\naddition and subtraction. Specifically, both agents found difficulty to be\nstrictly increasing with respect to the number of carries. Another notable\nsimilarity is that problem difficulty increases more steeply in subtraction\nthan in addition, for both humans and connectionist models. Further\ninvestigation on two model hyperparameters --- confidence threshold and hidden\ndimension --- shows higher confidence thresholds cause the model to take more\ncomputational steps to arrive at the correct answer. Likewise, larger hidden\ndimensions cause the model to take more computational steps to correctly answer\narithmetic problems; however, this effect by hidden dimensions is negligible.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:33:59 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 19:07:40 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 04:55:49 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Cho", "Sungjae", ""], ["Lim", "Jaeseo", ""], ["Hickey", "Chris", ""], ["Park", "Jung Ae", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1905.03629", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Yue Wu, Wael AbdAlmageed, Premkumar Natarajan", "title": "Unified Adversarial Invariance", "comments": "In submission to T-PAMI. Some results updated. arXiv admin note:\n  substantial text overlap with arXiv:1809.10083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified invariance framework for supervised neural networks that\ncan induce independence to nuisance factors of data without using any nuisance\nannotations, but can additionally use labeled information about biasing factors\nto force their removal from the latent embedding for making fair predictions.\nInvariance to nuisance is achieved by learning a split representation of data\nthrough competitive training between the prediction task and a reconstruction\ntask coupled with disentanglement, whereas that to biasing factors is brought\nabout by penalizing the network if the latent embedding contains any\ninformation about them. We describe an adversarial instantiation of this\nframework and provide analysis of its working. Our model outperforms previous\nworks at inducing invariance to nuisance factors without using any labeled\ninformation about such variables, and achieves state-of-the-art performance at\nlearning independence to biasing factors in fairness settings.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 22:08:38 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 02:14:24 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Wu", "Yue", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1905.03652", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen, Yiming Ying", "title": "Stochastic Iterative Hard Thresholding for Graph-structured Sparsity\n  Optimization", "comments": "published in ICML-2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization algorithms update models with cheap per-iteration\ncosts sequentially, which makes them amenable for large-scale data analysis.\nSuch algorithms have been widely studied for structured sparse models where the\nsparsity information is very specific, e.g., convex sparsity-inducing norms or\n$\\ell^0$-norm. However, these norms cannot be directly applied to the problem\nof complex (non-convex) graph-structured sparsity models, which have important\napplication in disease outbreak and social networks, etc. In this paper, we\npropose a stochastic gradient-based method for solving graph-structured\nsparsity constraint problems, not restricted to the least square loss. We prove\nthat our algorithm enjoys a linear convergence up to a constant error, which is\ncompetitive with the counterparts in the batch learning setting. We conduct\nextensive experiments to show the efficiency and effectiveness of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:24:43 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""], ["Ying", "Yiming", ""]]}, {"id": "1905.03658", "submitter": "Jason Ramapuram", "authors": "Jason Ramapuram and Russ Webb", "title": "Improving Discrete Latent Representations With Differentiable\n  Approximation Bridges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural network training relies on piece-wise (sub-)differentiable\nfunctions in order to use backpropagation to update model parameters. In this\nwork, we introduce a novel method to allow simple non-differentiable functions\nat intermediary layers of deep neural networks. We do so by training with a\ndifferentiable approximation bridge (DAB) neural network which approximates the\nnon-differentiable forward function and provides gradient updates during\nbackpropagation. We present strong empirical results (performing over 600\nexperiments) in four different domains: unsupervised (image) representation\nlearning, variational (image) density estimation, image classification, and\nsequence sorting to demonstrate that our proposed method improves state of the\nart performance. We demonstrate that training with DAB aided discrete\nnon-differentiable functions improves image reconstruction quality and\nposterior linear separability by 10% against the Gumbel-Softmax relaxed\nestimator [37, 26] as well as providing a 9% improvement in the test\nvariational lower bound in comparison to the state of the art RELAX [16]\ndiscrete estimator. We also observe an accuracy improvement of 77% in neural\nsequence sorting and a 25% improvement against the straight-through estimator\n[5] in an image classification setting. The DAB network is not used for\ninference and expands the class of functions that are usable in neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:31:59 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 13:46:02 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 01:41:50 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ramapuram", "Jason", ""], ["Webb", "Russ", ""]]}, {"id": "1905.03670", "submitter": "Xiaohua Zhai", "authors": "Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov, Lucas Beyer", "title": "S4L: Self-Supervised Semi-Supervised Learning", "comments": "All four authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work tackles the problem of semi-supervised learning of image\nclassifiers. Our main insight is that the field of semi-supervised learning can\nbenefit from the quickly advancing field of self-supervised visual\nrepresentation learning. Unifying these two approaches, we propose the\nframework of self-supervised semi-supervised learning and use it to derive two\nnovel semi-supervised image classification methods. We demonstrate the\neffectiveness of these methods in comparison to both carefully tuned baselines,\nand existing semi-supervised learning methods. We then show that our approach\nand existing semi-supervised methods can be jointly trained, yielding a new\nstate-of-the-art result on semi-supervised ILSVRC-2012 with 10% of labels.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:55:56 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 13:31:21 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Zhai", "Xiaohua", ""], ["Oliver", "Avital", ""], ["Kolesnikov", "Alexander", ""], ["Beyer", "Lucas", ""]]}, {"id": "1905.03674", "submitter": "Brandon Fain", "authors": "Xingyu Chen, Brandon Fain, Liang Lyu, Kamesh Munagala", "title": "Proportionally Fair Clustering", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the fair machine learning literature by considering the problem of\nproportional centroid clustering in a metric context. For clustering $n$ points\nwith $k$ centers, we define fairness as proportionality to mean that any $n/k$\npoints are entitled to form their own cluster if there is another center that\nis closer in distance for all $n/k$ points. We seek clustering solutions to\nwhich there are no such justified complaints from any subsets of agents,\nwithout assuming any a priori notion of protected subsets. We present and\nanalyze algorithms to efficiently compute, optimize, and audit proportional\nsolutions. We conclude with an empirical examination of the tradeoff between\nproportional solutions and the $k$-means objective.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:58:43 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 18:19:34 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 19:51:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Xingyu", ""], ["Fain", "Brandon", ""], ["Lyu", "Liang", ""], ["Munagala", "Kamesh", ""]]}, {"id": "1905.03677", "submitter": "Donggeun Yoo", "authors": "Donggeun Yoo, In So Kweon", "title": "Learning Loss for Active Learning", "comments": "Accepted to CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks improves with more annotated data.\nThe problem is that the budget for annotation is limited. One solution to this\nis active learning, where a model asks human to annotate data that it perceived\nas uncertain. A variety of recent methods have been proposed to apply active\nlearning to deep networks but most of them are either designed specific for\ntheir target tasks or computationally inefficient for large networks. In this\npaper, we propose a novel active learning method that is simple but\ntask-agnostic, and works efficiently with the deep networks. We attach a small\nparametric module, named \"loss prediction module,\" to a target network, and\nlearn it to predict target losses of unlabeled inputs. Then, this module can\nsuggest data that the target model is likely to produce a wrong prediction.\nThis method is task-agnostic as networks are learned from a single loss\nregardless of target tasks. We rigorously validate our method through image\nclassification, object detection, and human pose estimation, with the recent\nnetwork architectures. The results demonstrate that our method consistently\noutperforms the previous methods over the tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:03:48 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Yoo", "Donggeun", ""], ["Kweon", "In So", ""]]}, {"id": "1905.03679", "submitter": "Shen Wang", "authors": "Shen Wang, Zhengzhang Chen, Jingchao Ni, Xiao Yu, Zhichun Li, Haifeng\n  Chen, Philip S. Yu", "title": "Adversarial Defense Framework for Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN), as a powerful representation learning model on\ngraph data, attracts much attention across various disciplines. However, recent\nstudies show that GNN is vulnerable to adversarial attacks. How to make GNN\nmore robust? What are the key vulnerabilities in GNN? How to address the\nvulnerabilities and defense GNN against the adversarial attacks? In this paper,\nwe propose DefNet, an effective adversarial defense framework for GNNs. In\nparticular, we first investigate the latent vulnerabilities in every layer of\nGNNs and propose corresponding strategies including dual-stage aggregation and\nbottleneck perceptron. Then, to cope with the scarcity of training data, we\npropose an adversarial contrastive learning method to train the GNN in a\nconditional GAN manner by leveraging the high-level graph representation.\nExtensive experiments on three public datasets demonstrate the effectiveness of\nDefNet in improving the robustness of popular GNN variants, such as Graph\nConvolutional Network and GraphSAGE, under various types of adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:10:30 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 20:26:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Shen", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Yu", "Xiao", ""], ["Li", "Zhichun", ""], ["Chen", "Haifeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1905.03680", "submitter": "Shu Wang", "authors": "Shu Wang, Jonathan G. Yabes and Chung-Chou H. Chang", "title": "A Bayesian Finite Mixture Model with Variable Selection for Data with\n  Mixed-type Variables", "comments": "34 pages, 12 table and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture model is an important branch of clustering methods and can be\napplied on data sets with mixed types of variables. However, challenges exist\nin its applications. First, it typically relies on the EM algorithm which could\nbe sensitive to the choice of initial values. Second, biomarkers subject to\nlimits of detection (LOD) are common to encounter in clinical data, which\nbrings censored variables into finite mixture model. Additionally, researchers\nare recently getting more interest in variable importance due to the increasing\nnumber of variables that become available for clustering.\n  To address these challenges, we propose a Bayesian finite mixture model to\nsimultaneously conduct variable selection, account for biomarker LOD and obtain\nclustering results. We took a Bayesian approach to obtain parameter estimates\nand the cluster membership to bypass the limitation of the EM algorithm. To\naccount for LOD, we added one more step in Gibbs sampling to iteratively fill\nin biomarker values below or above LODs. In addition, we put a spike-and-slab\ntype of prior on each variable to obtain variable importance. Simulations\nacross various scenarios were conducted to examine the performance of this\nmethod. Real data application on electronic health records was also conducted.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:13:13 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wang", "Shu", ""], ["Yabes", "Jonathan G.", ""], ["Chang", "Chung-Chou H.", ""]]}, {"id": "1905.03684", "submitter": "Colin Wei", "authors": "Colin Wei, Tengyu Ma", "title": "Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Rademacher complexity bounds for neural networks rely only on norm\ncontrol of the weight matrices and depend exponentially on depth via a product\nof the matrix norms. Lower bounds show that this exponential dependence on\ndepth is unavoidable when no additional properties of the training data are\nconsidered. We suspect that this conundrum comes from the fact that these\nbounds depend on the training data only through the margin. In practice, many\ndata-dependent techniques such as Batchnorm improve the generalization\nperformance. For feedforward neural nets as well as RNNs, we obtain tighter\nRademacher complexity bounds by considering additional data-dependent\nproperties of the network: the norms of the hidden layers of the network, and\nthe norms of the Jacobians of each layer with respect to all previous layers.\nOur bounds scale polynomially in depth when these empirical quantities are\nsmall, as is usually the case in practice. To obtain these bounds, we develop\ngeneral tools for augmenting a sequence of functions to make their composition\nLipschitz and then covering the augmented functions. Inspired by our theory, we\ndirectly regularize the network's Jacobians during training and empirically\ndemonstrate that this improves test performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:18:41 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 18:22:35 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 09:08:38 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Wei", "Colin", ""], ["Ma", "Tengyu", ""]]}, {"id": "1905.03685", "submitter": "Qianru Zhou", "authors": "Qianru Zhou, Dimitrios Pezaros", "title": "Evaluation of Machine Learning Classifiers for Zero-Day Intrusion\n  Detection -- An Analysis on CIC-AWS-2018 dataset", "comments": "error found in the manuscript, major revision is required before\n  publish again", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting Zero-Day intrusions has been the goal of Cybersecurity, especially\nintrusion detection for a long time. Machine learning is believed to be the\npromising methodology to solve that problem, numerous models have been proposed\nbut a practical solution is still yet to come, mainly due to the limitation\ncaused by the out-of-date open datasets available. In this paper, we take a\ndeep inspection of the flow-based statistical data generated by CICFlowMeter,\nwith six most popular machine learning classification models for Zero-Day\nattacks detection. The training dataset CIC-AWS-2018 Dataset contains fourteen\ntypes of intrusions, while the testing datasets contains eight different types\nof attacks. The six classification models are evaluated and cross validated on\nCIC-AWS-2018 Dataset for their accuracy in terms of false-positive rate,\ntrue-positive rate, and time overhead. Testing dataset, including eight novel\n(or Zero-Day) real-life attacks and benign traffic flows collected in real\nresearch production network are used to test the performance of the chosen\ndecision tree classifier. Promising results are received with the accuracy as\nhigh as 100% and reasonable time overhead. We argue that with the statistical\ndata collected from CICFlowMeter, simple machine learning models such as the\ndecision tree classification could be able to take charge in detecting Zero-Day\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:20:18 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 02:02:59 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zhou", "Qianru", ""], ["Pezaros", "Dimitrios", ""]]}, {"id": "1905.03695", "submitter": "Kwang Woo Nam", "authors": "Wei Ding, KwangSoo Yang and Kwang Woo Nam", "title": "Measuring similarity between geo-tagged videos using largest common view", "comments": "2 pages", "journal-ref": "IET electronics letters, vol.55, no. 8, pp.450-452, 2019", "doi": "10.1049/el.2018.7499", "report-no": null, "categories": "cs.CV cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel problem for discovering the similar trajectories\nbased on the field of view (FoV) of the video data. The problem is important\nfor many societal applications such as grouping moving objects, classifying\ngeo-images, and identifying the interesting trajectory patterns. Prior work\nconsider only either spatial locations or spatial relationship between two\nline-segments. However, these approaches show a limitation to find the similar\nmoving objects with common views. In this paper, we propose new algorithm that\ncan group both spatial locations and points of view to identify similar\ntrajectories. We also propose novel methods that reduce the computational cost\nfor the proposed work. Experimental results using real-world datasets\ndemonstrates that the proposed approach outperforms prior work and reduces the\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 14:46:06 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ding", "Wei", ""], ["Yang", "KwangSoo", ""], ["Nam", "Kwang Woo", ""]]}, {"id": "1905.03697", "submitter": "J{\\o}rgen Falck Erichsen M.Sc.", "authors": "Jorgen F. Erichsen, Sampsa Kohtala, Martin Steinert, Torgeir Welo", "title": "On Applying Machine Learning/Object Detection Models for Analysing\n  Digitally Captured Physical Prototypes from Engineering Design Projects", "comments": "13 pages, 4 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While computer vision has received increasing attention in computer science\nover the last decade, there are few efforts in applying this to leverage\nengineering design research. Existing datasets and technologies allow\nresearchers to capture and access more observations and video files, hence\nanalysis is becoming a limiting factor. Therefore, this paper is investigating\nthe application of machine learning, namely object detection methods to aid in\nthe analysis of physical porotypes. With access to a large dataset of digitally\ncaptured physical prototypes from early-stage development projects (5950 images\nfrom 850 prototypes), the authors investigate applications that can be used for\nanalysing this dataset. The authors retrained two pre-trained object detection\nmodels from two known frameworks, the TensorFlow Object Detection API and\nDarknet, using custom image sets of images of physical prototypes. As a result,\na proof-of-concept of four trained models are presented; two models for\ndetecting samples of wood-based sheet materials and two models for detecting\nsamples containing microcontrollers. All models are evaluated using standard\nmetrics for object detection model performance and the applicability of using\nobject detection models in engineering design research is discussed. Results\nindicate that the models can successfully classify the type of material and\ntype of pre-made component, respectively. However, more work is needed to fully\nintegrate object detection models in the engineering design analysis workflow.\nThe authors also extrapolate that the use of object detection for analysing\nimages of physical prototypes will substantially reduce the effort required for\nanalysing large datasets in engineering design research.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 07:33:53 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Erichsen", "Jorgen F.", ""], ["Kohtala", "Sampsa", ""], ["Steinert", "Martin", ""], ["Welo", "Torgeir", ""]]}, {"id": "1905.03698", "submitter": "Yongshun Gong", "authors": "Yongshun Gong, Jinfeng Yi, Dongdong Chen, Jian Zhang, Jiayu Zhou,\n  Zhihua Zhou", "title": "Inferring the Importance of Product Appearance: A Step Towards the\n  Screenless Revolution", "comments": "We want to withdraw this paper. there are some insufficient\n  explanations and bad figure presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, almost all the online orders were placed through screened devices\nsuch as mobile phones, tablets, and computers. With the rapid development of\nthe Internet of Things (IoT) and smart appliances, more and more screenless\nsmart devices, e.g., smart speaker and smart refrigerator, appear in our daily\nlives. They open up new means of interaction and may provide an excellent\nopportunity to reach new customers and increase sales. However, not all the\nitems are suitable for screenless shopping, since some items' appearance play\nan important role in consumer decision making. Typical examples include\nclothes, dolls, bags, and shoes. In this paper, we aim to infer the\nsignificance of every item's appearance in consumer decision making and\nidentify the group of items that are suitable for screenless shopping.\nSpecifically, we formulate the problem as a classification task that predicts\nif an item's appearance has a significant impact on people's purchase behavior.\nTo solve this problem, we extract features from three different views, namely\nitems' intrinsic properties, items' images, and users' comments, and collect a\nset of necessary labels via crowdsourcing. We then propose an iterative\nsemi-supervised learning framework with three carefully designed loss\nfunctions. We conduct extensive experiments on a real-world transaction dataset\ncollected from the online retail giant JD.com. Experimental results verify the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 00:21:43 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 09:43:24 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Gong", "Yongshun", ""], ["Yi", "Jinfeng", ""], ["Chen", "Dongdong", ""], ["Zhang", "Jian", ""], ["Zhou", "Jiayu", ""], ["Zhou", "Zhihua", ""]]}, {"id": "1905.03699", "submitter": "Emad Ul Haq Qazi", "authors": "Helala AlShehri, Muhammad Hussain, Hatim AboAlSamh, Qazi Emad-ul-Haq,\n  and Aqil M. Azmi", "title": "Alignment-Free Cross-Sensor Fingerprint Matching based on the\n  Co-Occurrence of Ridge Orientations and Gabor-HoG Descriptor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing automatic fingerprint verification methods are designed to work\nunder the assumption that the same sensor is installed for enrollment and\nauthentication (regular matching). There is a remarkable decrease in efficiency\nwhen one type of contact-based sensor is employed for enrolment and another\ntype of contact-based sensor is used for authentication (cross-matching or\nfingerprint sensor interoperability problem,). The ridge orientation patterns\nin a fingerprint are invariant to sensor type. Based on this observation, we\npropose a robust fingerprint descriptor called the co-occurrence of ridge\norientations (Co-Ror), which encodes the spatial distribution of ridge\norientations. Employing this descriptor, we introduce an efficient automatic\nfingerprint verification method for cross-matching problem. Further, to enhance\nthe robustness of the method, we incorporate scale based ridge orientation\ninformation through Gabor-HoG descriptor. The two descriptors are fused with\ncanonical correlation analysis (CCA), and the matching score between two\nfingerprints is calculated using city-block distance. The proposed method is\nalignment-free and can handle the matching process without the need for a\nregistration step. The intensive experiments on two benchmark databases\n(FingerPass and MOLF) show the effectiveness of the method and reveal its\nsignificant enhancement over the state-of-the-art methods such as VeriFinger (a\ncommercial SDK), minutia cylinder-code (MCC), MCC with scale, and the\nthin-plate spline (TPS) model. The proposed research will help security\nagencies, service providers and law-enforcement departments to overcome the\ninteroperability problem of contact sensors of different technology and\ninteraction types.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:26:04 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["AlShehri", "Helala", ""], ["Hussain", "Muhammad", ""], ["AboAlSamh", "Hatim", ""], ["Emad-ul-Haq", "Qazi", ""], ["Azmi", "Aqil M.", ""]]}, {"id": "1905.03702", "submitter": "Sachin Talathi", "authors": "Stephan J. Garbin, Yiru Shen, Immo Schuetz, Robert Cavin, Gregory\n  Hughes, and Sachin S. Talathi", "title": "OpenEDS: Open Eye Dataset", "comments": "11 pages; 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large scale data set, OpenEDS: Open Eye Dataset, of eye-images\ncaptured using a virtual-reality (VR) head mounted display mounted with two\nsynchronized eyefacing cameras at a frame rate of 200 Hz under controlled\nillumination. This dataset is compiled from video capture of the eye-region\ncollected from 152 individual participants and is divided into four subsets:\n(i) 12,759 images with pixel-level annotations for key eye-regions: iris, pupil\nand sclera (ii) 252,690 unlabelled eye-images, (iii) 91,200 frames from\nrandomly selected video sequence of 1.5 seconds in duration and (iv) 143 pairs\nof left and right point cloud data compiled from corneal topography of eye\nregions collected from a subset, 143 out of 152, participants in the study. A\nbaseline experiment has been evaluated on OpenEDS for the task of semantic\nsegmentation of pupil, iris, sclera and background, with the mean\nintersectionover-union (mIoU) of 98.3 %. We anticipate that OpenEDS will create\nopportunities to researchers in the eye tracking community and the broader\nmachine learning and computer vision community to advance the state of\neye-tracking for VR applications. The dataset is available for download upon\nrequest at https://research.fb.com/programs/openeds-challenge\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:47:53 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 16:18:02 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Garbin", "Stephan J.", ""], ["Shen", "Yiru", ""], ["Schuetz", "Immo", ""], ["Cavin", "Robert", ""], ["Hughes", "Gregory", ""], ["Talathi", "Sachin S.", ""]]}, {"id": "1905.03707", "submitter": "Reza Malekian Ph.D.", "authors": "Schalk Wilhelm Pienaar, Reza Malekian", "title": "Human Activity Recognition Using Visual Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Human Activity Recognition (HAR) and data fusion with other sensors\ncan help us at tracking the behavior and activity of underground miners with\nlittle obstruction. Existing models, such as Single Shot Detector (SSD),\ntrained on the Common Objects in Context (COCO) dataset is used in this paper\nto detect the current state of a miner, such as an injured miner vs a\nnon-injured miner. Tensorflow is used for the abstraction layer of implementing\nmachine learning algorithms, and although it uses Python to deal with nodes and\ntensors, the actual algorithms run on C++ libraries, providing a good balance\nbetween performance and speed of development. The paper further discusses\nevaluation methods for determining the accuracy of the machine-learning and an\napproach to increase the accuracy of the detected activity/state of people in a\nmining environment, by means of data fusion.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 07:17:51 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Pienaar", "Schalk Wilhelm", ""], ["Malekian", "Reza", ""]]}, {"id": "1905.03708", "submitter": "Javad Ghofrani", "authors": "Javad Ghofrani, Robert Kirschne, Daniel Rossburg, Dirk Reichelt, Tom\n  Dimter", "title": "Machine Vision in the Context of Robotics: A Systematic Literature\n  Review", "comments": "10 pages 5 figures, systematic literature study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine vision is critical to robotics due to a wide range of applications\nwhich rely on input from visual sensors such as autonomous mobile robots and\nsmart production systems. To create the smart homes and systems of tomorrow, an\noverview about current challenges in the research field would be of use to\nidentify further possible directions, created in a systematic and reproducible\nmanner. In this work a systematic literature review was conducted covering\nresearch from the last 10 years. We screened 172 papers from four databases and\nselected 52 relevant papers. While robustness and computation time were\nimproved greatly, occlusion and lighting variance are still the biggest\nproblems faced. From the number of recent publications, we conclude that the\nobserved field is of relevance and interest to the research community. Further\nchallenges arise in many areas of the field.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 09:00:07 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ghofrani", "Javad", ""], ["Kirschne", "Robert", ""], ["Rossburg", "Daniel", ""], ["Reichelt", "Dirk", ""], ["Dimter", "Tom", ""]]}, {"id": "1905.03710", "submitter": "Xiaorui Zhu", "authors": "Lijun Yan, Jun-Bao Li, Xiaorui Zhu, Jeng-Shyang Pan and Linlin Tang", "title": "Bilinear discriminant feature line analysis for image feature extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel bilinear discriminant feature line analysis (BDFLA) is proposed for\nimage feature extraction. The nearest feature line (NFL) is a powerful\nclassifier. Some NFL-based subspace algorithms were introduced recently. In\nmost of the classical NFL-based subspace learning approaches, the input samples\nare vectors. For image classification tasks, the image samples should be\ntransformed to vectors first. This process induces a high computational\ncomplexity and may also lead to loss of the geometric feature of samples. The\nproposed BDFLA is a matrix-based algorithm. It aims to minimise the\nwithin-class scatter and maximise the between-class scatter based on a\ntwo-dimensional (2D) NFL. Experimental results on two-image databases confirm\nthe effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 04:54:43 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Yan", "Lijun", ""], ["Li", "Jun-Bao", ""], ["Zhu", "Xiaorui", ""], ["Pan", "Jeng-Shyang", ""], ["Tang", "Linlin", ""]]}, {"id": "1905.03711", "submitter": "Angelos Katharopoulos", "authors": "Angelos Katharopoulos and Fran\\c{c}ois Fleuret", "title": "Processing Megapixel Images with Deep Attention-Sampling Models", "comments": "Presented in ICML 2019. Code is available at\n  https://github.com/idiap/attention-sampling", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:3282-3291, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep architectures cannot operate on very large signals such as\nmegapixel images due to computational and memory constraints. To tackle this\nlimitation, we propose a fully differentiable end-to-end trainable model that\nsamples and processes only a fraction of the full resolution input image. The\nlocations to process are sampled from an attention distribution computed from a\nlow resolution view of the input. We refer to our method as attention sampling\nand it can process images of several megapixels with a standard single GPU\nsetup. We show that sampling from the attention distribution results in an\nunbiased estimator of the full model with minimal variance, and we derive an\nunbiased estimator of the gradient that we use to train our model end-to-end\nwith a normal SGD procedure. This new method is evaluated on three\nclassification tasks, where we show that it allows to reduce computation and\nmemory footprint by an order of magnitude for the same accuracy as classical\narchitectures. We also show the consistency of the sampling that indeed focuses\non informative parts of the input images.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:27:46 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 15:20:50 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Katharopoulos", "Angelos", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "1905.03715", "submitter": "Kin Ng", "authors": "Kin Ng", "title": "Tuned Inception V3 for Recognizing States of Cooking Ingredients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooking is a task that must be performed in a daily basis, and thus it is an\nactivity that many people take for granted. For humans preparing a meal comes\nnaturally, but for robots even preparing a simple sandwich results in an\nextremely difficult task. In robotics, designing kitchen robots is complicated\nsince cooking relies on a variety of physical interactions that are dependent\non different conditions such as changes in the environment, proper execution of\nsequential instructions, along with motions, and detection of the different\nstates in which cooking-ingredients can be in for their correct grasping and\nmanipulation. In this paper, we focus on the challenge of state recognition and\npropose a fine tuned convolutional neural network that makes use of transfer\nlearning by reusing the Inception V3 pre-trained model. The model is trained\nand validated on a cooking dataset consisting of eleven states (e.g. peeled,\ndiced, whole, etc.). The work presented on this paper could provide insight\ninto finding a potential solution to the problem.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:38:52 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ng", "Kin", ""]]}, {"id": "1905.03718", "submitter": "Yanhao Wang", "authors": "Yanhao Wang, Yuchen Li, Kian-Lee Tan", "title": "Coresets for Minimum Enclosing Balls over Sliding Windows", "comments": "28 pages, 10 figures, to appear in The 25th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330826", "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \\emph{Coresets} are important tools to generate concise summaries of massive\ndatasets for approximate analysis. A coreset is a small subset of points\nextracted from the original point set such that certain geometric properties\nare preserved with provable guarantees. This paper investigates the problem of\nmaintaining a coreset to preserve the minimum enclosing ball (MEB) for a\nsliding window of points that are continuously updated in a data stream.\nAlthough the problem has been extensively studied in batch and append-only\nstreaming settings, no efficient sliding-window solution is available yet. In\nthis work, we first introduce an algorithm, called AOMEB, to build a coreset\nfor MEB in an append-only stream. AOMEB improves the practical performance of\nthe state-of-the-art algorithm while having the same approximation ratio.\nFurthermore, using AOMEB as a building block, we propose two novel algorithms,\nnamely SWMEB and SWMEB+, to maintain coresets for MEB over the sliding window\nwith constant approximation ratios. The proposed algorithms also support\ncoresets for MEB in a reproducing kernel Hilbert space (RKHS). Finally,\nextensive experiments on real-world and synthetic datasets demonstrate that\nSWMEB and SWMEB+ achieve speedups of up to four orders of magnitude over the\nstate-of-the-art batch algorithm while providing coresets for MEB with rather\nsmall errors compared to the optimal ones.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:55:03 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 05:11:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wang", "Yanhao", ""], ["Li", "Yuchen", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1905.03729", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Hongwei Wen", "title": "Best-scored Random Forest Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a brand new nonparametric density estimation strategy\nnamed the best-scored random forest density estimation whose effectiveness is\nsupported by both solid theoretical analysis and significant experimental\nperformance. The terminology best-scored stands for selecting one density tree\nwith the best estimation performance out of a certain number of purely random\ndensity tree candidates and we then name the selected one the best-scored\nrandom density tree. In this manner, the ensemble of these selected trees that\nis the best-scored random density forest can achieve even better estimation\nresults than simply integrating trees without selection. From the theoretical\nperspective, by decomposing the error term into two, we are able to carry out\nthe following analysis: First of all, we establish the consistency of the\nbest-scored random density trees under $L_1$-norm. Secondly, we provide the\nconvergence rates of them under $L_1$-norm concerning with three different tail\nassumptions, respectively. Thirdly, the convergence rates under\n$L_{\\infty}$-norm is presented. Last but not least, we also achieve the above\nconvergence rates analysis for the best-scored random density forest. When\nconducting comparative experiments with other state-of-the-art density\nestimation approaches on both synthetic and real data sets, it turns out that\nour algorithm has not only significant advantages in terms of estimation\naccuracy over other methods, but also stronger resistance to the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:11:55 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hang", "Hanyuan", ""], ["Wen", "Hongwei", ""]]}, {"id": "1905.03743", "submitter": "Gaurav Mittal", "authors": "Gaurav Mittal, Shubham Agrawal, Anuva Agarwal, Sushant Mehta, Tanya\n  Marwah", "title": "Interactive Image Generation Using Scene Graphs", "comments": "Published at ICLR 2019 Deep Generative Models for Highly Structured\n  Data Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed some exciting developments in the domain of\ngenerating images from scene-based text descriptions. These approaches have\nprimarily focused on generating images from a static text description and are\nlimited to generating images in a single pass. They are unable to generate an\nimage interactively based on an incrementally additive text description\n(something that is more intuitive and similar to the way we describe an image).\nWe propose a method to generate an image incrementally based on a sequence of\ngraphs of scene descriptions (scene-graphs). We propose a recurrent network\narchitecture that preserves the image content generated in previous steps and\nmodifies the cumulative image as per the newly provided scene information. Our\nmodel utilizes Graph Convolutional Networks (GCN) to cater to variable-sized\nscene graphs along with Generative Adversarial image translation networks to\ngenerate realistic multi-object images without needing any intermediate\nsupervision during training. We experiment with Coco-Stuff dataset which has\nmulti-object images along with annotations describing the visual scene and show\nthat our model significantly outperforms other approaches on the same dataset\nin generating visually consistent images for incrementally growing scene\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:39:31 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mittal", "Gaurav", ""], ["Agrawal", "Shubham", ""], ["Agarwal", "Anuva", ""], ["Mehta", "Sushant", ""], ["Marwah", "Tanya", ""]]}, {"id": "1905.03752", "submitter": "Chenghao Liu", "authors": "Chenghao Liu, Tao Lu, Xin Wang, Zhiyong Cheng, Jianling Sun, Steven\n  C.H. Hoi", "title": "Compositional Coding for Collaborative Filtering", "comments": "SIGIR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency is crucial to the online recommender systems. Representing users\nand items as binary vectors for Collaborative Filtering (CF) can achieve fast\nuser-item affinity computation in the Hamming space, in recent years, we have\nwitnessed an emerging research effort in exploiting binary hashing techniques\nfor CF methods. However, CF with binary codes naturally suffers from low\naccuracy due to limited representation capability in each bit, which impedes it\nfrom modeling complex structure of the data.\n  In this work, we attempt to improve the efficiency without hurting the model\nperformance by utilizing both the accuracy of real-valued vectors and the\nefficiency of binary codes to represent users/items. In particular, we propose\nthe Compositional Coding for Collaborative Filtering (CCCF) framework, which\nnot only gains better recommendation efficiency than the state-of-the-art\nbinarized CF approaches but also achieves even higher accuracy than the\nreal-valued CF method. Specifically, CCCF innovatively represents each\nuser/item with a set of binary vectors, which are associated with a sparse\nreal-value weight vector. Each value of the weight vector encodes the\nimportance of the corresponding binary vector to the user/item. The continuous\nweight vectors greatly enhances the representation capability of binary codes,\nand its sparsity guarantees the processing speed. Furthermore, an integer\nweight approximation scheme is proposed to further accelerate the speed. Based\non the CCCF framework, we design an efficient discrete optimization algorithm\nto learn its parameters. Extensive experiments on three real-world datasets\nshow that our method outperforms the state-of-the-art binarized CF methods\n(even achieves better performance than the real-valued CF method) by a large\nmargin in terms of both recommendation accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:57:27 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Liu", "Chenghao", ""], ["Lu", "Tao", ""], ["Wang", "Xin", ""], ["Cheng", "Zhiyong", ""], ["Sun", "Jianling", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1905.03776", "submitter": "Daniel Park", "authors": "Daniel S. Park, Jascha Sohl-Dickstein, Quoc V. Le, Samuel L. Smith", "title": "The Effect of Network Width on Stochastic Gradient Descent and\n  Generalization: an Empirical Study", "comments": "17 pages, 3 tables, 17 figures; accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how the final parameters found by stochastic gradient descent\nare influenced by over-parameterization. We generate families of models by\nincreasing the number of channels in a base network, and then perform a large\nhyper-parameter search to study how the test error depends on learning rate,\nbatch size, and network width. We find that the optimal SGD hyper-parameters\nare determined by a \"normalized noise scale,\" which is a function of the batch\nsize, learning rate, and initialization conditions. In the absence of batch\nnormalization, the optimal normalized noise scale is directly proportional to\nwidth. Wider networks, with their higher optimal noise scale, also achieve\nhigher test accuracy. These observations hold for MLPs, ConvNets, and ResNets,\nand for two different parameterization schemes (\"Standard\" and \"NTK\"). We\nobserve a similar trend with batch normalization for ResNets. Surprisingly,\nsince the largest stable learning rate is bounded, the largest batch size\nconsistent with the optimal normalized noise scale decreases as the width\nincreases.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 17:58:13 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Park", "Daniel S.", ""], ["Sohl-Dickstein", "Jascha", ""], ["Le", "Quoc V.", ""], ["Smith", "Samuel L.", ""]]}, {"id": "1905.03806", "submitter": "Rajat Sen", "authors": "Rajat Sen, Hsiang-Fu Yu, Inderjit Dhillon", "title": "Think Globally, Act Locally: A Deep Neural Network Approach to\n  High-Dimensional Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting high-dimensional time series plays a crucial role in many\napplications such as demand forecasting and financial predictions. Modern\ndatasets can have millions of correlated time-series that evolve together, i.e\nthey are extremely high dimensional (one dimension for each individual\ntime-series). There is a need for exploiting global patterns and coupling them\nwith local calibration for better prediction. However, most recent deep\nlearning approaches in the literature are one-dimensional, i.e, even though\nthey are trained on the whole dataset, during prediction, the future forecast\nfor a single dimension mainly depends on past values from the same dimension.\nIn this paper, we seek to correct this deficiency and propose DeepGLO, a deep\nforecasting model which thinks globally and acts locally. In particular,\nDeepGLO is a hybrid model that combines a global matrix factorization model\nregularized by a temporal convolution network, along with another temporal\nnetwork that can capture local properties of each time-series and associated\ncovariates. Our model can be trained effectively on high-dimensional but\ndiverse time series, where different time series can have vastly different\nscales, without a priori normalization or rescaling. Empirical results\ndemonstrate that DeepGLO can outperform state-of-the-art approaches; for\nexample, we see more than 25% improvement in WAPE over other methods on a\npublic dataset that contains more than 100K-dimensional time series.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:24:34 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 02:44:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sen", "Rajat", ""], ["Yu", "Hsiang-Fu", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "1905.03809", "submitter": "Kim Phuc Tran", "authors": "H.D. Nguyen, K.P. Tran, X. Zeng, L. Koehl, and G. Tartare", "title": "Wearable Sensor Data Based Human Activity Recognition using Machine\n  Learning: A new approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed the rapid development of human activity\nrecognition (HAR) based on wearable sensor data. One can find many practical\napplications in this area, especially in the field of health care. Many machine\nlearning algorithms such as Decision Trees, Support Vector Machine, Naive\nBayes, K-Nearest Neighbor, and Multilayer Perceptron are successfully used in\nHAR. Although these methods are fast and easy for implementation, they still\nhave some limitations due to poor performance in a number of situations. In\nthis paper, we propose a novel method based on the ensemble learning to boost\nthe performance of these machine learning methods for HAR.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:28:10 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Nguyen", "H. D.", ""], ["Tran", "K. P.", ""], ["Zeng", "X.", ""], ["Koehl", "L.", ""], ["Tartare", "G.", ""]]}, {"id": "1905.03812", "submitter": "Andrew Stephan", "authors": "Andrew W. Stephan and Steven J. Koester", "title": "Convolutional Neural Networks Utilizing Multifunctional Spin-Hall MTJ\n  Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new network architecture for standard spin-Hall magnetic tunnel\njunction-based spintronic neurons that allows them to compute multiple critical\nconvolutional neural network functionalities simultaneously and in parallel,\nsaving space and time. An approximation to the Rectified Linear Unit transfer\nfunction and the local pooling function are computed simultaneously with the\nconvolution operation itself. A proof-of-concept simulation is performed on the\nMNIST dataset, achieving up to 98% accuracy at a cost of less than 1 nJ for all\nconvolution, activation and pooling operations combined. The simulations are\nremarkably robust to thermal noise, performing well even with very small\nmagnetic layers.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:37:00 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Stephan", "Andrew W.", ""], ["Koester", "Steven J.", ""]]}, {"id": "1905.03813", "submitter": "Hongyu Li", "authors": "Jose Cambronero, Hongyu Li, Seohyun Kim, Koushik Sen and Satish\n  Chandra", "title": "When Deep Learning Met Code Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There have been multiple recent proposals on using deep neural networks for\ncode search using natural language. Common across these proposals is the idea\nof $\\mathit{embedding}$ code and natural language queries, into real vectors\nand then using vector distance to approximate semantic correlation between code\nand the query. Multiple approaches exist for learning these embeddings,\nincluding $\\mathit{unsupervised}$ techniques, which rely only on a corpus of\ncode examples, and $\\mathit{supervised}$ techniques, which use an\n$\\mathit{aligned}$ corpus of paired code and natural language descriptions. The\ngoal of this supervision is to produce embeddings that are more similar for a\nquery and the corresponding desired code snippet. Clearly, there are choices in\nwhether to use supervised techniques at all, and if one does, what sort of\nnetwork and training to use for supervision. This paper is the first to\nevaluate these choices systematically. To this end, we assembled\nimplementations of state-of-the-art techniques to run on a common platform,\ntraining and evaluation corpora. To explore the design space in network\ncomplexity, we also introduced a new design point that is a $\\mathit{minimal}$\nsupervision extension to an existing unsupervised technique. Our evaluation\nshows that: 1. adding supervision to an existing unsupervised technique can\nimprove performance, though not necessarily by much; 2. simple networks for\nsupervision can be more effective that more sophisticated sequence-based\nnetworks for code search; 3. while it is common to use docstrings to carry out\nsupervision, there is a sizeable gap between the effectiveness of docstrings\nand a more query-appropriate supervision corpus.\n  The evaluation dataset is now available at arXiv:1908.09804\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:47:38 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 21:36:47 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 14:01:11 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 06:11:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Cambronero", "Jose", ""], ["Li", "Hongyu", ""], ["Kim", "Seohyun", ""], ["Sen", "Koushik", ""], ["Chandra", "Satish", ""]]}, {"id": "1905.03814", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Kevin Jamieson", "title": "Non-Asymptotic Gap-Dependent Regret Bounds for Tabular MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes that optimistic algorithms attain gap-dependent and\nnon-asymptotic logarithmic regret for episodic MDPs. In contrast to prior work,\nour bounds do not suffer a dependence on diameter-like quantities or\nergodicity, and smoothly interpolate between the gap dependent\nlogarithmic-regret, and the $\\widetilde{\\mathcal{O}}(\\sqrt{HSAT})$-minimax\nrate. The key technique in our analysis is a novel \"clipped\" regret\ndecomposition which applies to a broad family of recent optimistic algorithms\nfor episodic MDPs.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:00:31 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 21:53:40 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Simchowitz", "Max", ""], ["Jamieson", "Kevin", ""]]}, {"id": "1905.03817", "submitter": "Hao Yu", "authors": "Hao Yu and Rong Jin and Sen Yang", "title": "On the Linear Speedup Analysis of Communication Efficient Momentum SGD\n  for Distributed Non-Convex Optimization", "comments": "A short version of this paper is accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments on large-scale distributed machine learning applications,\ne.g., deep neural networks, benefit enormously from the advances in distributed\nnon-convex optimization techniques, e.g., distributed Stochastic Gradient\nDescent (SGD). A series of recent works study the linear speedup property of\ndistributed SGD variants with reduced communication. The linear speedup\nproperty enable us to scale out the computing capability by adding more\ncomputing nodes into our system. The reduced communication complexity is\ndesirable since communication overhead is often the performance bottleneck in\ndistributed systems. Recently, momentum methods are more and more widely\nadopted in training machine learning models and can often converge faster and\ngeneralize better. For example, many practitioners use distributed SGD with\nmomentum to train deep neural networks with big data. However, it remains\nunclear whether any distributed momentum SGD possesses the same linear speedup\nproperty as distributed SGD and has reduced communication complexity. This\npaper fills the gap by considering a distributed communication efficient\nmomentum SGD method and proving its linear speedup property.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:06:47 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Yu", "Hao", ""], ["Jin", "Rong", ""], ["Yang", "Sen", ""]]}, {"id": "1905.03818", "submitter": "David Hubbard", "authors": "David Hubbard, Benoit Rostykus, Yves Raimond, Tony Jebara", "title": "Beta Survival Models", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article analyzes the problem of estimating the time until an event\noccurs, also known as survival modeling. We observe through substantial\nexperiments on large real-world datasets and use-cases that populations are\nlargely heterogeneous. Sub-populations have different mean and variance in\ntheir survival rates requiring flexible models that capture heterogeneity. We\nleverage a classical extension of the logistic function into the survival\nsetting to characterize unobserved heterogeneity using the beta distribution.\nThis yields insights into the geometry of the problem as well as efficient\nestimation methods for linear, tree and neural network models that adjust the\nbeta distribution based on observed covariates. We also show that the\nadditional information captured by the beta distribution leads to interesting\nranking implications as we determine who is most-at-risk. We show theoretically\nthat the ranking is variable as we forecast forward in time and prove that\npairwise comparisons of survival remain transitive. Empirical results using\nlarge-scale datasets across two use-cases (online conversions and retention\nmodeling), demonstrate the competitiveness of the method. The simplicity of the\nmethod and its ability to capture skew in the data makes it a viable\nalternative to standard techniques particularly when we are interested in the\ntime to event and when the underlying probabilities are heterogeneous.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:10:49 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Hubbard", "David", ""], ["Rostykus", "Benoit", ""], ["Raimond", "Yves", ""], ["Jebara", "Tony", ""]]}, {"id": "1905.03826", "submitter": "Aonan Zhang", "authors": "Aonan Zhang, John Paisley", "title": "Random Function Priors for Correlation Modeling", "comments": "Accepted by ICML 2019. 13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The likelihood model of high dimensional data $X_n$ can often be expressed as\n$p(X_n|Z_n,\\theta)$, where $\\theta\\mathrel{\\mathop:}=(\\theta_k)_{k\\in[K]}$ is a\ncollection of hidden features shared across objects, indexed by $n$, and $Z_n$\nis a non-negative factor loading vector with $K$ entries where $Z_{nk}$\nindicates the strength of $\\theta_k$ used to express $X_n$. In this paper, we\nintroduce random function priors for $Z_n$ for modeling correlations among its\n$K$ dimensions $Z_{n1}$ through $Z_{nK}$, which we call \\textit{population\nrandom measure embedding} (PRME). Our model can be viewed as a generalized\npaintbox model~\\cite{Broderick13} using random functions, and can be learned\nefficiently with neural networks via amortized variational inference. We derive\nour Bayesian nonparametric method by applying a representation theorem on\nseparately exchangeable discrete random measures.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:32:48 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 01:21:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhang", "Aonan", ""], ["Paisley", "John", ""]]}, {"id": "1905.03828", "submitter": "Paarth Neekhara", "authors": "Paarth Neekhara, Shehzeen Hussain, Prakhar Pandey, Shlomo Dubnov,\n  Julian McAuley, Farinaz Koushanfar", "title": "Universal Adversarial Perturbations for Speech Recognition Systems", "comments": "Published as a conference paper at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we demonstrate the existence of universal adversarial audio\nperturbations that cause mis-transcription of audio signals by automatic speech\nrecognition (ASR) systems. We propose an algorithm to find a single\nquasi-imperceptible perturbation, which when added to any arbitrary speech\nsignal, will most likely fool the victim speech recognition model. Our\nexperiments demonstrate the application of our proposed technique by crafting\naudio-agnostic universal perturbations for the state-of-the-art ASR system --\nMozilla DeepSpeech. Additionally, we show that such perturbations generalize to\na significant extent across models that are not available during training, by\nperforming a transferability test on a WaveNet based ASR system.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:35:30 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 05:15:43 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Neekhara", "Paarth", ""], ["Hussain", "Shehzeen", ""], ["Pandey", "Prakhar", ""], ["Dubnov", "Shlomo", ""], ["McAuley", "Julian", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1905.03837", "submitter": "Evelyn Duesterwald", "authors": "Evelyn Duesterwald and Anupama Murthi and Ganesh Venkataraman and\n  Mathieu Sinn and Deepak Vijaykeerthy", "title": "Exploring the Hyperparameter Landscape of Adversarial Robustness", "comments": null, "journal-ref": "Safe Machine Learning Workshop at ICLR (International Conference\n  on Learning Representations), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training shows promise as an approach for training models that\nare robust towards adversarial perturbation. In this paper, we explore some of\nthe practical challenges of adversarial training. We present a sensitivity\nanalysis that illustrates that the effectiveness of adversarial training hinges\non the settings of a few salient hyperparameters. We show that the robustness\nsurface that emerges across these salient parameters can be surprisingly\ncomplex and that therefore no effective one-size-fits-all parameter settings\nexist. We then demonstrate that we can use the same salient hyperparameters as\ntuning knob to navigate the tension that can arise between robustness and\naccuracy. Based on these findings, we present a practical approach that\nleverages hyperparameter optimization techniques for tuning adversarial\ntraining to maximize robustness while keeping the loss in accuracy within a\ndefined budget.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:06:02 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Duesterwald", "Evelyn", ""], ["Murthi", "Anupama", ""], ["Venkataraman", "Ganesh", ""], ["Sinn", "Mathieu", ""], ["Vijaykeerthy", "Deepak", ""]]}, {"id": "1905.03852", "submitter": "Jieru Zhao", "authors": "Jieru Zhao, Tingyuan Liang, Sharad Sinha and Wei Zhang", "title": "Machine Learning Based Routing Congestion Prediction in FPGA High-Level\n  Synthesis", "comments": "Preprint: to appear in Proceedings of Design, Automation and Test in\n  Europe (DATE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level synthesis (HLS) shortens the development time of hardware designs\nand enables faster design space exploration at a higher abstraction level.\nOptimization of complex applications in HLS is challenging due to the effects\nof implementation issues such as routing congestion. Routing congestion\nestimation is absent or inaccurate in existing HLS design methods and tools.\nEarly and accurate congestion estimation is of great benefit to guide the\noptimization in HLS and improve the efficiency of implementation. However,\nroutability, a serious concern in FPGA designs, has been difficult to evaluate\nin HLS without analyzing post-implementation details after Place and Route. To\nthis end, we propose a novel method to predict routing congestion in HLS using\nmachine learning and map the expected congested regions in the design to the\nrelevant high-level source code. This is greatly beneficial in early\nidentification of routability oriented bottlenecks in the high-level source\ncode without running time-consuming register-transfer level (RTL)\nimplementation flow. Experiments demonstrate that our approach accurately\nestimates vertical and horizontal routing congestion with errors of 6.71% and\n10.05% respectively. By presenting Face Detection application as a case study,\nwe show that by discovering the bottlenecks in high-level source code, routing\ncongestion can be easily and quickly resolved compared to the efforts involved\nin RTL implementation and design feedback.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 06:33:22 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Zhao", "Jieru", ""], ["Liang", "Tingyuan", ""], ["Sinha", "Sharad", ""], ["Zhang", "Wei", ""]]}, {"id": "1905.03853", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi and Rachid Guerraoui and Arsany Guirguis and L\\^e\n  Nguy\\^en Hoang and S\\'ebastien Rouault", "title": "Genuinely Distributed Byzantine Machine Learning", "comments": "This is a merge of arXiv:1905.03853 and arXiv:1911.07537;\n  arXiv:1911.07537 will be retracted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning (ML) solutions are nowadays distributed, according to the\nso-called server/worker architecture. One server holds the model parameters\nwhile several workers train the model. Clearly, such architecture is prone to\nvarious types of component failures, which can be all encompassed within the\nspectrum of a Byzantine behavior. Several approaches have been proposed\nrecently to tolerate Byzantine workers. Yet all require trusting a central\nparameter server. We initiate in this paper the study of the ``general''\nByzantine-resilient distributed machine learning problem where no individual\ncomponent is trusted.\n  We show that this problem can be solved in an asynchronous system, despite\nthe presence of $\\frac{1}{3}$ Byzantine parameter servers and $\\frac{1}{3}$\nByzantine workers (which is optimal). We present a new algorithm, ByzSGD, which\nsolves the general Byzantine-resilient distributed machine learning problem by\nrelying on three major schemes. The first, Scatter/Gather, is a communication\nscheme whose goal is to bound the maximum drift among models on correct\nservers. The second, Distributed Median Contraction (DMC), leverages the\ngeometric properties of the median in high dimensional spaces to bring\nparameters within the correct servers back close to each other, ensuring\nlearning convergence. The third, Minimum-Diameter Averaging (MDA), is a\nstatistically-robust gradient aggregation rule whose goal is to tolerate\nByzantine workers. MDA requires loose bound on the variance of non-Byzantine\ngradient estimates, compared to existing alternatives (e.g., Krum).\nInterestingly, ByzSGD ensures Byzantine resilience without adding communication\nrounds (on a normal path), compared to vanilla non-Byzantine alternatives.\nByzSGD requires, however, a larger number of messages which, we show, can be\nreduced if we assume synchrony.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:14:30 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 08:57:00 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""], ["Hoang", "L\u00ea Nguy\u00ean", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1905.03854", "submitter": "Bashima Islam", "authors": "Bashima Islam and Shahriar Nirjon", "title": "Zygarde: Time-Sensitive On-Device Deep Inference and Adaptation on\n  Intermittently-Powered Systems", "comments": "Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies, September 2020, Vol 4, No 3", "journal-ref": "Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies. September 2020 Article No.: 82", "doi": "10.1145/3411808", "report-no": null, "categories": "cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Zygarde -- which is an energy -- and accuracy-aware soft real-time\ntask scheduling framework for batteryless systems that flexibly execute deep\nlearning tasks1 that are suitable for running on microcontrollers. The sporadic\nnature of harvested energy, resource constraints of the embedded platform, and\nthe computational demand of deep neural networks (DNNs) pose a unique and\nchallenging real-time scheduling problem for which no solutions have been\nproposed in the literature. We empirically study the problem and model the\nenergy harvesting pattern as well as the trade-off between the accuracy and\nexecution of a DNN. We develop an imprecise computing-based scheduling\nalgorithm that improves the timeliness of DNN tasks on intermittently powered\nsystems. We evaluate Zygarde using four standard datasets as well as by\ndeploying it in six real-life applications involving audio and camera sensor\nsystems. Results show that Zygarde decreases the execution time by up to 26%\nand schedules 9%-34% more tasks with up to 21% higher inference accuracy,\ncompared to traditional schedulers such as the earliest deadline first (EDF).\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 01:06:48 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:55:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Islam", "Bashima", ""], ["Nirjon", "Shahriar", ""]]}, {"id": "1905.03864", "submitter": "Orhan Ocal", "authors": "Orhan Ocal, Oguz H. Elibol, Gokce Keskin, Cory Stephenson, Anil\n  Thomas, Kannan Ramchandran", "title": "Adversarially Trained Autoencoders for Parallel-Data-Free Voice\n  Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for converting the voices between a set of speakers. Our\nmethod is based on training multiple autoencoder paths, where there is a single\nspeaker-independent encoder and multiple speaker-dependent decoders. The\nautoencoders are trained with an addition of an adversarial loss which is\nprovided by an auxiliary classifier in order to guide the output of the encoder\nto be speaker independent. The training of the model is unsupervised in the\nsense that it does not require collecting the same utterances from the speakers\nnor does it require time aligning over phonemes. Due to the use of a single\nencoder, our method can generalize to converting the voice of out-of-training\nspeakers to speakers in the training dataset. We present subjective tests\ncorroborating the performance of our method.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 21:34:13 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ocal", "Orhan", ""], ["Elibol", "Oguz H.", ""], ["Keskin", "Gokce", ""], ["Stephenson", "Cory", ""], ["Thomas", "Anil", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1905.03871", "submitter": "Galen Andrew", "authors": "Galen Andrew, Om Thakkar, H. Brendan McMahan, Swaroop Ramaswamy", "title": "Differentially Private Learning with Adaptive Clipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of hyperparameter tuning in training neural networks\nwith user-level differential privacy (DP). Existing approaches for DP training\n(e.g., DP Federated Averaging) involve bounding the contribution of each user's\nmodel update by *clipping* them to a fixed norm. However there is no good *a\npriori* setting of the clipping norm across tasks and learning settings: the\nupdate norm distribution depends on the model architecture and loss, the amount\nof data on each device, the client learning rate, and possibly various other\nparameters. In this work, we propose a method wherein instead of using a fixed\nclipping norm, one clips to a value at a specified quantile of the distribution\nof update norms, where the value at the quantile is itself estimated online,\nwith differential privacy. Experiments demonstrate that adaptive clipping to\nthe median update norm works well across a range of federated learning\nproblems, eliminating the need to tune any clipping hyperparameter.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 21:50:15 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 01:20:45 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 23:37:41 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Andrew", "Galen", ""], ["Thakkar", "Om", ""], ["McMahan", "H. Brendan", ""], ["Ramaswamy", "Swaroop", ""]]}, {"id": "1905.03889", "submitter": "Simon Friedrich Gerhard Ehlers", "authors": "Simon F. G. Ehlers", "title": "Traffic Queue Length and Pressure Estimation for Road Networks with\n  Geometric Deep Learning Algorithms", "comments": "Project thesis as part of a masters program at University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to urbanization and the increase of individual mobility, in most\nmetropolitan areas around the world congestion and inefficient traffic\nmanagement occur. Highly necessary intelligent traffic control systems, which\nare able to reduce congestion, rely on measurements of traffic situations in\nurban road networks and freeways. Unfortunately, the instrumentation for\naccurate traffic measurement is expensive and not widely implemented. This\nthesis addresses this problem, where relatively inexpensive and easy to install\nloop-detectors are used by a geometric deep learning algorithm, which uses\nloop-detector data in a spatial context of a road network, to estimate queue\nlength in front of signalized intersections, which can be then used for\nfollowing traffic control tasks. Therefore, in the first part of this work a\nconventional estimation method for queue length (which does not use machine\nlearning techniques) based on second-by-second loop-detector data is\nimplemented, which uses detected shockwaves in queues to estimate the length\nand point of time for the maximum queue. The method is later used as reference\nbut also as additional input information for the geometric deep learning\napproach. In the second part the geometric deep learning algorithm is\ndeveloped, which uses spatial correlations in the road network but also\ntemporal correlations in detector data time sequences by new attention\nmechanisms, to overcome the limitations of conventional methods like excess\ntraffic demand, lane changing and stop-and-go traffic. Therefore, it is\nnecessary to abstract the topology of the road network in a graph. Both\napproaches are compared regarding their performance, reliability as well as\nlimitations and validated by usage of the traffic simulation software SUMO\n(Simulation of Urban MObility). Finally, the results are discussed in the\nconclusions and further investigations are suggested.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 23:34:36 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ehlers", "Simon F. G.", ""]]}, {"id": "1905.03911", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Oh-Hyun Kwon, Kwan-Liu Ma", "title": "Supporting Analysis of Dimensionality Reduction Results with Contrastive\n  Learning", "comments": "This is the author's version of the article that has been published\n  in IEEE Transactions on Visualization and Computer Graphics. The final\n  version of this record is available at: 10.1109/TVCG.2019.2934251", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934251", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction (DR) is frequently used for analyzing and\nvisualizing high-dimensional data as it provides a good first glance of the\ndata. However, to interpret the DR result for gaining useful insights from the\ndata, it would take additional analysis effort such as identifying clusters and\nunderstanding their characteristics. While there are many automatic methods\n(e.g., density-based clustering methods) to identify clusters, effective\nmethods for understanding a cluster's characteristics are still lacking. A\ncluster can be mostly characterized by its distribution of feature values.\nReviewing the original feature values is not a straightforward task when the\nnumber of features is large. To address this challenge, we present a visual\nanalytics method that effectively highlights the essential features of a\ncluster in a DR result. To extract the essential features, we introduce an\nenhanced usage of contrastive principal component analysis (cPCA). Our method,\ncalled ccPCA (contrasting clusters in PCA), can calculate each feature's\nrelative contribution to the contrast between one cluster and other clusters.\nWith ccPCA, we have created an interactive system including a scalable\nvisualization of clusters' feature contributions. We demonstrate the\neffectiveness of our method and system with case studies using several publicly\navailable datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 02:07:58 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 04:55:59 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 00:01:18 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Kwon", "Oh-Hyun", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "1905.03920", "submitter": "Hong Peng", "authors": "Hong Peng, Yu Hu, Jiazhou Chen, Haiyan Wang, Yang Li, and Hongmin Cai", "title": "Integrating Tensor Similarity to Enhance Clustering Performance", "comments": "10 pages, 7 figures, 2 tables, 4 pages supplementary information\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of most the clustering methods hinges on the used pairwise\naffinity, which is usually denoted by a similarity matrix. However, the\npairwise similarity is notoriously known for its vulnerability of noise\ncontamination or the imbalance in samples or features, and thus hinders\naccurate clustering. To tackle this issue, we propose to use information among\nsamples to boost the clustering performance. We proved that a simplified\nsimilarity for pairs, denoted by a fourth order tensor, equals to the Kronecker\nproduct of pairwise similarity matrices under decomposable assumption, or\nprovide complementary information for which the pairwise similarity missed\nunder indecomposable assumption. Then a high order similarity matrix is\nobtained from the tensor similarity via eigenvalue decomposition. The high\norder similarity capturing spatial information serves as a robust complement\nfor the pairwise similarity. It is further integrated with the popular pairwise\nsimilarity, named by IPS2, to boost the clustering performance. Extensive\nexperiments demonstrated that the proposed IPS2 significantly outperformed\nprevious similarity-based methods on real-world datasets and it was capable of\nhandling the clustering task over under-sampled and noisy datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 03:15:27 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 04:01:58 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Peng", "Hong", ""], ["Hu", "Yu", ""], ["Chen", "Jiazhou", ""], ["Wang", "Haiyan", ""], ["Li", "Yang", ""], ["Cai", "Hongmin", ""]]}, {"id": "1905.03927", "submitter": "Chandramouli Kamanchi", "authors": "Chandramouli Kamanchi, Raghuram Bharadwaj Diddigi, Shalabh Bhatnagar", "title": "Second Order Value Iteration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a fixed point iteration technique utilized to obtain the\noptimal value function and policy in a discounted reward Markov Decision\nProcess (MDP). Here, a contraction operator is constructed and applied\nrepeatedly to arrive at the optimal solution. Value iteration is a first order\nmethod and therefore it may take a large number of iterations to converge to\nthe optimal solution. In this work, we propose a novel second order value\niteration procedure based on the Newton-Raphson method. We first construct a\nmodified contraction operator and then apply Newton-Raphson method to arrive at\nour algorithm. We prove the global convergence of our algorithm to the optimal\nsolution and show the second order convergence. Through experiments, we\ndemonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:02:50 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Kamanchi", "Chandramouli", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1905.03929", "submitter": "Yuxiu Hua", "authors": "Yuxiu Hua, Rongpeng Li, Zhifeng Zhao, Xianfu Chen, Honggang Zhang", "title": "GAN-powered Deep Distributional Reinforcement Learning for Resource\n  Management in Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is a key technology in 5G communications system. Its purpose\nis to dynamically and efficiently allocate resources for diversified services\nwith distinct requirements over a common underlying physical infrastructure.\nTherein, demand-aware resource allocation is of significant importance to\nnetwork slicing. In this paper, we consider a scenario that contains several\nslices in a radio access network with base stations that share the same\nphysical resources (e.g., bandwidth or slots). We leverage deep reinforcement\nlearning (DRL) to solve this problem by considering the varying service demands\nas the environment state and the allocated resources as the environment action.\nIn order to reduce the effects of the annoying randomness and noise embedded in\nthe received service level agreement (SLA) satisfaction ratio (SSR) and\nspectrum efficiency (SE), we primarily propose generative adversarial\nnetwork-powered deep distributional Q network (GAN-DDQN) to learn the\naction-value distribution driven by minimizing the discrepancy between the\nestimated action-value distribution and the target action-value distribution.\nWe put forward a reward-clipping mechanism to stabilize GAN-DDQN training\nagainst the effects of widely-spanning utility values. Moreover, we further\ndevelop Dueling GAN-DDQN, which uses a specially designed dueling generator, to\nlearn the action-value distribution by estimating the state-value distribution\nand the action advantage function. Finally, we verify the performance of the\nproposed GAN-DDQN and Dueling GAN-DDQN algorithms through extensive\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:10:43 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:58:34 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 14:51:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hua", "Yuxiu", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Chen", "Xianfu", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.03938", "submitter": "Bijun Tang", "authors": "Bijun Tang, Yuhao Lu, Jiadong Zhou, Han Wang, Prafful Golani, Manzhang\n  Xu, Quan Xu, Cuntai Guan, and Zheng Liu", "title": "Machine learning-guided synthesis of advanced inorganic materials", "comments": null, "journal-ref": null, "doi": "10.1016/j.mattod.2020.06.010", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis of advanced inorganic materials with minimum number of trials is of\nparamount importance towards the acceleration of inorganic materials\ndevelopment. The enormous complexity involved in existing multi-variable\nsynthesis methods leads to high uncertainty, numerous trials and exorbitant\ncost. Recently, machine learning (ML) has demonstrated tremendous potential for\nmaterial research. Here, we report the application of ML to optimize and\naccelerate material synthesis process in two representative multi-variable\nsystems. A classification ML model on chemical vapor deposition-grown MoS2 is\nestablished, capable of optimizing the synthesis conditions to achieve higher\nsuccess rate. While a regression model is constructed on the\nhydrothermal-synthesized carbon quantum dots, to enhance the process-related\nproperties such as the photoluminescence quantum yield. Progressive adaptive\nmodel is further developed, aiming to involve ML at the beginning stage of new\nmaterial synthesis. Optimization of the experimental outcome with minimized\nnumber of trials can be achieved with the effective feedback loops. This work\nserves as proof of concept revealing the feasibility and remarkable capability\nof ML to facilitate the synthesis of inorganic materials, and opens up a new\nwindow for accelerating material development.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 04:53:29 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Tang", "Bijun", ""], ["Lu", "Yuhao", ""], ["Zhou", "Jiadong", ""], ["Wang", "Han", ""], ["Golani", "Prafful", ""], ["Xu", "Manzhang", ""], ["Xu", "Quan", ""], ["Guan", "Cuntai", ""], ["Liu", "Zheng", ""]]}, {"id": "1905.03946", "submitter": "Nikolay Dubina", "authors": "Nikolay Dubina, Dasom Kang, Alex Suh", "title": "Credit Scoring for Micro-Loans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit Scores are ubiquitous and instrumental for loan providers and\nregulators. In this paper we showcase how micro-loan credit system can be\ndeveloped in real setting. We show what challenges arise and discuss solutions.\nParticularly, we are concerned about model interpretability and data quality.\nIn the final section, we introduce semi-supervised algorithm that aids model\ndevelopment and evaluate its performance\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 05:26:03 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Dubina", "Nikolay", ""], ["Kang", "Dasom", ""], ["Suh", "Alex", ""]]}, {"id": "1905.03960", "submitter": "Anand Jayarajan", "authors": "Anand Jayarajan, Jinliang Wei, Garth Gibson, Alexandra Fedorova,\n  Gennady Pekhimenko", "title": "Priority-based Parameter Propagation for Distributed DNN Training", "comments": "In proceedings of the 2nd SysML Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallel training is widely used for scaling distributed deep neural\nnetwork (DNN) training. However, the performance benefits are often limited by\nthe communication-heavy parameter synchronization step. In this paper, we take\nadvantage of the domain specific knowledge of DNN training and overlap\nparameter synchronization with computation in order to improve the training\nperformance. We make two key observations: (1) the optimal data representation\ngranularity for the communication may differ from that used by the underlying\nDNN model implementation and (2) different parameters can afford different\nsynchronization delays. Based on these observations, we propose a new\nsynchronization mechanism called Priority-based Parameter Propagation (P3). P3\nsynchronizes parameters at a finer granularity and schedules data transmission\nin such a way that the training process incurs minimal communication delay. We\nshow that P3 can improve the training throughput of ResNet-50, Sockeye and\nVGG-19 by as much as 25%, 38% and 66% respectively on clusters with realistic\nnetwork bandwidth\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 06:22:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Jayarajan", "Anand", ""], ["Wei", "Jinliang", ""], ["Gibson", "Garth", ""], ["Fedorova", "Alexandra", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1905.03970", "submitter": "Sindhu Padakandla", "authors": "Sindhu Padakandla, Prabuchandran K. J, and Shalabh Bhatnagar", "title": "Reinforcement Learning in Non-Stationary Environments", "comments": null, "journal-ref": "Applied Intelligence 2020", "doi": "10.1007/s10489-020-01758-5", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) methods learn optimal decisions in the presence\nof a stationary environment. However, the stationary assumption on the\nenvironment is very restrictive. In many real world problems like traffic\nsignal control, robotic applications, one often encounters situations with\nnon-stationary environments and in these scenarios, RL methods yield\nsub-optimal decisions. In this paper, we thus consider the problem of\ndeveloping RL methods that obtain optimal decisions in a non-stationary\nenvironment. The goal of this problem is to maximize the long-term discounted\nreward achieved when the underlying model of the environment changes over time.\nTo achieve this, we first adapt a change point algorithm to detect change in\nthe statistics of the environment and then develop an RL algorithm that\nmaximizes the long-run reward accrued. We illustrate that our change point\nmethod detects change in the model of the environment effectively and thus\nfacilitates the RL algorithm in maximizing the long-run reward. We further\nvalidate the effectiveness of the proposed solution on non-stationary random\nMarkov decision processes, a sensor energy management problem and a traffic\nsignal control problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:05:27 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 12:54:18 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 07:21:45 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 09:48:13 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Padakandla", "Sindhu", ""], ["J", "Prabuchandran K.", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1905.03980", "submitter": "Ju Xu", "authors": "Ju Xu, Jin Ma, Zhanxing Zhu", "title": "Bayesian Optimized Continual Learning with Attention Mechanism", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Though neural networks have achieved much progress in various applications,\nit is still highly challenging for them to learn from a continuous stream of\ntasks without forgetting. Continual learning, a new learning paradigm, aims to\nsolve this issue. In this work, we propose a new model for continual learning,\ncalled Bayesian Optimized Continual Learning with Attention Mechanism (BOCL)\nthat dynamically expands the network capacity upon the arrival of new tasks by\nBayesian optimization and selectively utilizes previous knowledge (e.g. feature\nmaps of previous tasks) via attention mechanism. Our experiments on variants of\nMNIST and CIFAR-100 demonstrate that our methods outperform the\nstate-of-the-art in preventing catastrophic forgetting and fitting new tasks\nbetter.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:30:53 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Xu", "Ju", ""], ["Ma", "Jin", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1905.03985", "submitter": "Elaheh Barati", "authors": "Elaheh Barati, Xuewen Chen, Zichun Zhong", "title": "Attention-based Deep Reinforcement Learning for Multi-view Environments", "comments": "The 18th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning algorithms, it is a common practice to account for\nonly a single view of the environment to make the desired decisions; however,\nutilizing multiple views of the environment can help to promote the learning of\ncomplicated policies. Since the views may frequently suffer from partial\nobservability, their provided observation can have different levels of\nimportance. In this paper, we present a novel attention-based deep\nreinforcement learning method in a multi-view environment in which each view\ncan provide various representative information about the environment.\nSpecifically, our method learns a policy to dynamically attend to views of the\nenvironment based on their importance in the decision-making process. We\nevaluate the performance of our method on TORCS racing car simulator and three\nother complex 3D environments with obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:39:39 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Barati", "Elaheh", ""], ["Chen", "Xuewen", ""], ["Zhong", "Zichun", ""]]}, {"id": "1905.03994", "submitter": "Han Zhichao", "authors": "Jia Li, Zhichao Han, Hong Cheng, Jiao Su, Pengyun Wang, Jianfeng\n  Zhang, Lujia Pan", "title": "Predicting Path Failure In Time-Evolving Graphs", "comments": "Accepted by KDD2019 Research track (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we use a time-evolving graph which consists of a sequence of\ngraph snapshots over time to model many real-world networks. We study the path\nclassification problem in a time-evolving graph, which has many applications in\nreal-world scenarios, for example, predicting path failure in a\ntelecommunication network and predicting path congestion in a traffic network\nin the near future. In order to capture the temporal dependency and graph\nstructure dynamics, we design a novel deep neural network named Long Short-Term\nMemory R-GCN (LRGCN). LRGCN considers temporal dependency between time-adjacent\ngraph snapshots as a special relation with memory, and uses relational GCN to\njointly process both intra-time and inter-time relations. We also propose a new\npath representation method named self-attentive path embedding (SAPE), to embed\npaths of arbitrary length into fixed-length vectors. Through experiments on a\nreal-world telecommunication network and a traffic network in California, we\ndemonstrate the superiority of LRGCN to other competing methods in path failure\nprediction, and prove the effectiveness of SAPE on path representation.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 08:03:12 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 12:06:23 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Li", "Jia", ""], ["Han", "Zhichao", ""], ["Cheng", "Hong", ""], ["Su", "Jiao", ""], ["Wang", "Pengyun", ""], ["Zhang", "Jianfeng", ""], ["Pan", "Lujia", ""]]}, {"id": "1905.04000", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Jia-Kai Chou, Shilpika, Panpan Xu, Liu Ren,\n  Kwan-Liu Ma", "title": "An Incremental Dimensionality Reduction Method for Visualizing Streaming\n  Multidimensional Data", "comments": "This is the author's version of the article that has been published\n  in IEEE Transactions on Visualization and Computer Graphics. The final\n  version of this record is available at: 10.1109/TVCG.2019.2934433", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934433", "report-no": null, "categories": "cs.GR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction (DR) methods are commonly used for analyzing and\nvisualizing multidimensional data. However, when data is a live streaming feed,\nconventional DR methods cannot be directly used because of their computational\ncomplexity and inability to preserve the projected data positions at previous\ntime points. In addition, the problem becomes even more challenging when the\ndynamic data records have a varying number of dimensions as often found in\nreal-world applications. This paper presents an incremental DR solution. We\nenhance an existing incremental PCA method in several ways to ensure its\nusability for visualizing streaming multidimensional data. First, we use\ngeometric transformation and animation methods to help preserve a viewer's\nmental map when visualizing the incremental results. Second, to handle data\ndimension variants, we use an optimization method to estimate the projected\ndata positions, and also convey the resulting uncertainty in the visualization.\nWe demonstrate the effectiveness of our design with two case studies using\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 08:15:42 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 05:38:20 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 04:16:00 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Chou", "Jia-Kai", ""], ["Shilpika", "", ""], ["Xu", "Panpan", ""], ["Ren", "Liu", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "1905.04014", "submitter": "Loic Landrieu", "authors": "Loic Landrieu and Mohamed Boussaha", "title": "Supervized Segmentation with Graph-Structured Deep Metric Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.02113", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully-supervized method for learning to segment data structured\nby an adjacency graph. We introduce the graph-structured contrastive loss, a\nloss function structured by a ground truth segmentation. It promotes learning\nvertex embeddings which are homogeneous within desired segments, and have high\ncontrast at their interface. Thus, computing a piecewise-constant approximation\nof such embeddings produces a graph-partition close to the objective\nsegmentation. This loss is fully backpropagable, which allows us to learn\nvertex embeddings with deep learning algorithms. We evaluate our methods on a\n3D point cloud oversegmentation task, defining a new state-of-the-art by a\nlarge margin. These results are based on the published work of Landrieu and\nBoussaha 2019.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 08:55:49 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 15:03:33 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Landrieu", "Loic", ""], ["Boussaha", "Mohamed", ""]]}, {"id": "1905.04035", "submitter": "Valeriu Codreanu", "authors": "Derya Cavdar, Valeriu Codreanu, Can Karakus, John A. Lockman III,\n  Damian Podareanu, Vikram Saletore, Alexander Sergeev, Don D. Smith II, Victor\n  Suthichai, Quy Ta, Srinivas Varadharajan, Lucas A. Wilson, Rengan Xu, Pei\n  Yang", "title": "Densifying Assumed-sparse Tensors: Improving Memory Efficiency and MPI\n  Collective Performance during Tensor Accumulation for Parallelized Training\n  of Neural Machine Translation Models", "comments": "18 pages, 10 figures, accepted at the 2019 International\n  Supercomputing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation - using neural networks to translate human\nlanguage - is an area of active research exploring new neuron types and network\ntopologies with the goal of dramatically improving machine translation\nperformance. Current state-of-the-art approaches, such as the multi-head\nattention-based transformer, require very large translation corpuses and many\nepochs to produce models of reasonable quality. Recent attempts to parallelize\nthe official TensorFlow \"Transformer\" model across multiple nodes have hit\nroadblocks due to excessive memory use and resulting out of memory errors when\nperforming MPI collectives. This paper describes modifications made to the\nHorovod MPI-based distributed training framework to reduce memory usage for\ntransformer models by converting assumed-sparse tensors to dense tensors, and\nsubsequently replacing sparse gradient gather with dense gradient reduction.\nThe result is a dramatic increase in scale-out capability, with CPU-only\nscaling tests achieving 91% weak scaling efficiency up to 1200 MPI processes\n(300 nodes), and up to 65% strong scaling efficiency up to 400 MPI processes\n(200 nodes) using the Stampede2 supercomputer.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:44:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Cavdar", "Derya", ""], ["Codreanu", "Valeriu", ""], ["Karakus", "Can", ""], ["Lockman", "John A.", "III"], ["Podareanu", "Damian", ""], ["Saletore", "Vikram", ""], ["Sergeev", "Alexander", ""], ["Smith", "Don D.", "II"], ["Suthichai", "Victor", ""], ["Ta", "Quy", ""], ["Varadharajan", "Srinivas", ""], ["Wilson", "Lucas A.", ""], ["Xu", "Rengan", ""], ["Yang", "Pei", ""]]}, {"id": "1905.04042", "submitter": "Lu Liu", "authors": "Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Lina Yao, Chengqi Zhang", "title": "Prototype Propagation Networks (PPN) for Weakly-supervised Few-shot\n  Learning on Category Graph", "comments": "Accepted to IJCAI 2019, Code is publicly available at:\n  https://github.com/liulu112601/PPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of machine learning applications expect to achieve rapid learning\nfrom a limited number of labeled data. However, the success of most current\nmodels is the result of heavy training on big data. Meta-learning addresses\nthis problem by extracting common knowledge across different tasks that can be\nquickly adapted to new tasks. However, they do not fully explore\nweakly-supervised information, which is usually free or cheap to collect. In\nthis paper, we show that weakly-labeled data can significantly improve the\nperformance of meta-learning on few-shot classification. We propose prototype\npropagation network (PPN) trained on few-shot tasks together with data\nannotated by coarse-label. Given a category graph of the targeted fine-classes\nand some weakly-labeled coarse-classes, PPN learns an attention mechanism which\npropagates the prototype of one class to another on the graph, so that the\nK-nearest neighbor (KNN) classifier defined on the propagated prototypes\nresults in high accuracy across different few-shot tasks. The training tasks\nare generated by subgraph sampling, and the training objective is obtained by\naccumulating the level-wise classification loss on the subgraph. The resulting\ngraph of prototypes can be continually re-used and updated for new tasks and\nclasses. We also introduce two practical test/inference settings which differ\naccording to whether the test task can leverage any weakly-supervised\ninformation as in training. On two benchmarks, PPN significantly outperforms\nmost recent few-shot learning methods in different settings, even when they are\nalso allowed to train on weakly-labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:57:23 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 12:40:13 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Yao", "Lina", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1905.04062", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Michalis K. Titsias", "title": "A Contrastive Divergence for Combining Variational Inference and MCMC", "comments": "International Conference on Machine Learning (ICML 2019). 12 pages, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to combine Markov chain Monte Carlo (MCMC) and\nvariational inference (VI), leveraging the advantages of both inference\napproaches. Specifically, we improve the variational distribution by running a\nfew MCMC steps. To make inference tractable, we introduce the variational\ncontrastive divergence (VCD), a new divergence that replaces the standard\nKullback-Leibler (KL) divergence used in VI. The VCD captures a notion of\ndiscrepancy between the initial variational distribution and its improved\nversion (obtained after running the MCMC steps), and it converges\nasymptotically to the symmetrized KL divergence between the variational\ndistribution and the posterior of interest. The VCD objective can be optimized\nefficiently with respect to the variational parameters via stochastic\noptimization. We show experimentally that optimizing the VCD leads to better\npredictive performance on two latent variable models: logistic matrix\nfactorization and variational autoencoders (VAEs).\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:45:23 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:02:03 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Titsias", "Michalis K.", ""]]}, {"id": "1905.04071", "submitter": "Jan Deriu", "authors": "Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie\n  Rosset, Eneko Agirre, Mark Cieliebak", "title": "Survey on Evaluation Methods for Dialogue Systems", "comments": null, "journal-ref": "Artificial Intelligence Review, June 2020", "doi": "10.1007/s10462-020-09866-x", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we survey the methods and concepts developed for the evaluation\nof dialogue systems. Evaluation is a crucial part during the development\nprocess. Often, dialogue systems are evaluated by means of human evaluations\nand questionnaires. However, this tends to be very cost and time intensive.\nThus, much work has been put into finding methods, which allow to reduce the\ninvolvement of human labour. In this survey, we present the main concepts and\nmethods. For this, we differentiate between the various classes of dialogue\nsystems (task-oriented dialogue systems, conversational dialogue systems, and\nquestion-answering dialogue systems). We cover each class by introducing the\nmain technologies developed for the dialogue systems and then by presenting the\nevaluation methods regarding this class.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:14:12 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:07:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Deriu", "Jan", ""], ["Rodrigo", "Alvaro", ""], ["Otegi", "Arantxa", ""], ["Echegoyen", "Guillermo", ""], ["Rosset", "Sophie", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1905.04079", "submitter": "Yat Hong Lam", "authors": "Yat Hong Lam, Alireza Zare, Caglar Aytekin, Francesco Cricri, Jani\n  Lainema, Emre Aksu, Miska Hannuksela", "title": "Compressing Weight-updates for Image Artifacts Removal Neural Networks", "comments": "Submission for CHALLENGE ON LEARNED IMAGE COMPRESSION (CLIC) 2019\n  (updated on 14 June 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for fine-tuning a decoder-side\nneural network in the context of image compression, such that the\nweight-updates are better compressible. At encoder side, we fine-tune a\npre-trained artifact removal network on target data by using a compression\nobjective applied on the weight-update. In particular, the compression\nobjective encourages weight-updates which are sparse and closer to quantized\nvalues. This way, the final weight-update can be compressed more efficiently by\npruning and quantization, and can be included into the encoded bitstream\ntogether with the image bitstream of a traditional codec. We show that this\napproach achieves reconstruction quality which is on-par or slightly superior\nto a traditional codec, at comparable bitrates. To our knowledge, this is the\nfirst attempt to combine image compression and neural network's weight update\ncompression.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:36:36 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 12:30:34 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Lam", "Yat Hong", ""], ["Zare", "Alireza", ""], ["Aytekin", "Caglar", ""], ["Cricri", "Francesco", ""], ["Lainema", "Jani", ""], ["Aksu", "Emre", ""], ["Hannuksela", "Miska", ""]]}, {"id": "1905.04094", "submitter": "Jin Chen", "authors": "Jin Chen, Xinxiao Wu, Lixin Duan and Shenghua Gao", "title": "Domain Adversarial Reinforcement Learning for Partial Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial domain adaptation aims to transfer knowledge from a label-rich source\ndomain to a label-scarce target domain which relaxes the fully shared label\nspace assumption across different domains. In this more general and practical\nscenario, a major challenge is how to select source instances in the shared\nclasses across different domains for positive transfer. To address this issue,\nwe propose a Domain Adversarial Reinforcement Learning (DARL) framework to\nautomatically select source instances in the shared classes for circumventing\nnegative transfer as well as to simultaneously learn transferable features\nbetween domains by reducing the domain shift. Specifically, in this framework,\nwe employ deep Q-learning to learn policies for an agent to make selection\ndecisions by approximating the action-value function. Moreover, domain\nadversarial learning is introduced to learn domain-invariant features for the\nselected source instances by the agent and the target instances, and also to\ndetermine rewards for the agent based on how relevant the selected source\ninstances are to the target domain. Experiments on several benchmark datasets\ndemonstrate that the superior performance of our DARL method over existing\nstate of the arts for partial domain adaptation.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:02:32 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Chen", "Jin", ""], ["Wu", "Xinxiao", ""], ["Duan", "Lixin", ""], ["Gao", "Shenghua", ""]]}, {"id": "1905.04101", "submitter": "Bernd Illing", "authors": "Bernd Illing, Wulfram Gerstner, Johanni Brea", "title": "Biologically plausible deep learning -- but how far can we go with\n  shallow networks?", "comments": "14 pages, 4 figures", "journal-ref": "Neural Networks, Volume 118, October 2019, Pages 90-101", "doi": "10.1016/j.neunet.2019.06.001", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with the error backpropagation algorithm is\nconsidered implausible from a biological perspective. Numerous recent\npublications suggest elaborate models for biologically plausible variants of\ndeep learning, typically defining success as reaching around 98% test accuracy\non the MNIST data set. Here, we investigate how far we can go on digit (MNIST)\nand object (CIFAR10) classification with biologically plausible, local learning\nrules in a network with one hidden layer and a single readout layer. The hidden\nlayer weights are either fixed (random or random Gabor filters) or trained with\nunsupervised methods (PCA, ICA or Sparse Coding) that can be implemented by\nlocal learning rules. The readout layer is trained with a supervised, local\nlearning rule. We first implement these models with rate neurons. This\ncomparison reveals, first, that unsupervised learning does not lead to better\nperformance than fixed random projections or Gabor filters for large hidden\nlayers. Second, networks with localized receptive fields perform significantly\nbetter than networks with all-to-all connectivity and can reach backpropagation\nperformance on MNIST. We then implement two of the networks - fixed, localized,\nrandom & random Gabor filters in the hidden layer - with spiking leaky\nintegrate-and-fire neurons and spike timing dependent plasticity to train the\nreadout layer. These spiking models achieve > 98.2% test accuracy on MNIST,\nwhich is close to the performance of rate networks with one hidden layer\ntrained with backpropagation. The performance of our shallow network models is\ncomparable to most current biologically plausible models of deep learning.\nFurthermore, our results with a shallow spiking network provide an important\nreference and suggest the use of datasets other than MNIST for testing the\nperformance of future models of biologically plausible deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:16:28 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 15:54:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Illing", "Bernd", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1905.04105", "submitter": "Jong Chul Ye", "authors": "Dongwook Lee, Won-Jin Moon, Jong Chul Ye", "title": "Which Contrast Does Matter? Towards a Deep Understanding of MR Contrast\n  using Collaborative GAN", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the recent success of generative adversarial network (GAN) for\nimage synthesis, there are many exciting GAN approaches that successfully\nsynthesize MR image contrast from other images with different contrasts. These\napproaches are potentially important for image imputation problems, where\ncomplete set of data is often difficult to obtain and image synthesis is one of\nthe key solutions for handling the missing data problem. Unfortunately, the\nlack of the scalability of the existing GAN-based image translation approaches\nposes a fundamental challenge to understand the nature of the MR contrast\nimputation problem: which contrast does matter? Here, we present a systematic\napproach using Collaborative Generative Adversarial Networks (CollaGAN), which\nenable the learning of the joint image manifold of multiple MR contrasts to\ninvestigate which contrasts are essential. Our experimental results showed that\nthe exogenous contrast from contrast agents is not replaceable, but other\nendogenous contrast such as T1, T2, etc can be synthesized from other contrast.\nThese findings may give important guidance to the acquisition protocol design\nfor MR in real clinical environment.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:18:19 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Lee", "Dongwook", ""], ["Moon", "Won-Jin", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1905.04121", "submitter": "Nikolas Kantas", "authors": "Nikolas Kantas, Panos Parpas, Grigorios A. Pavliotis", "title": "The sharp, the flat and the shallow: Can weakly interacting agents learn\n  to escape bad minima?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem in machine learning is whether flat minima generalize better\nand how to compute such minima efficiently. This is a very challenging problem.\nAs a first step towards understanding this question we formalize it as an\noptimization problem with weakly interacting agents. We review appropriate\nbackground material from the theory of stochastic processes and provide\ninsights that are relevant to practitioners. We propose an algorithmic\nframework for an extended stochastic gradient Langevin dynamics and illustrate\nits potential. The paper is written as a tutorial, and presents an alternative\nuse of multi-agent learning. Our primary focus is on the design of algorithms\nfor machine learning applications; however the underlying mathematical\nframework is suitable for the understanding of large scale systems of agent\nbased models that are popular in the social sciences, economics and finance.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:37:51 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Kantas", "Nikolas", ""], ["Parpas", "Panos", ""], ["Pavliotis", "Grigorios A.", ""]]}, {"id": "1905.04124", "submitter": "Kirill Simonov", "authors": "Fedor V. Fomin, Petr A. Golovach, Fahad Panolan, Kirill Simonov", "title": "Refined Complexity of PCA with Outliers", "comments": "To be presented at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is one of the most fundamental procedures\nin exploratory data analysis and is the basic step in applications ranging from\nquantitative finance and bioinformatics to image analysis and neuroscience.\nHowever, it is well-documented that the applicability of PCA in many real\nscenarios could be constrained by an \"immune deficiency\" to outliers such as\ncorrupted observations. We consider the following algorithmic question about\nthe PCA with outliers. For a set of $n$ points in $\\mathbb{R}^{d}$, how to\nlearn a subset of points, say 1% of the total number of points, such that the\nremaining part of the points is best fit into some unknown $r$-dimensional\nsubspace? We provide a rigorous algorithmic analysis of the problem. We show\nthat the problem is solvable in time $n^{O(d^2)}$. In particular, for constant\ndimension the problem is solvable in polynomial time. We complement the\nalgorithmic result by the lower bound, showing that unless Exponential Time\nHypothesis fails, in time $f(d)n^{o(d)}$, for any function $f$ of $d$, it is\nimpossible not only to solve the problem exactly but even to approximate it\nwithin a constant factor.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:40:31 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Panolan", "Fahad", ""], ["Simonov", "Kirill", ""]]}, {"id": "1905.04127", "submitter": "Andrei Roibu", "authors": "Andrei Claudiu Roibu", "title": "Design of Artificial Intelligence Agents for Games using Deep\n  Reinforcement Learning", "comments": "Dissertation submitted to the University of Sheffield in partial\n  fulfilment of the requirements for the degree of Master of Engineering. 98\n  pages, 21 Tables, 58 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order perform a large variety of tasks and to achieve human-level\nperformance in complex real-world environments, Artificial Intelligence (AI)\nAgents must be able to learn from their past experiences and gain both\nknowledge and an accurate representation of their environment from raw sensory\ninputs. Traditionally, AI agents have suffered from difficulties in using only\nsensory inputs to obtain a good representation of their environment and then\nmapping this representation to an efficient control policy. Deep reinforcement\nlearning algorithms have provided a solution to this issue. In this study, the\nperformance of different conventional and novel deep reinforcement learning\nalgorithms was analysed. The proposed method utilises two types of algorithms,\none trained with a variant of Q-learning (DQN) and another trained with SARSA\nlearning (DSN) to assess the feasibility of using direct feedback alignment, a\nnovel biologically plausible method for back-propagating the error. These novel\nagents, alongside two similar agents trained with the conventional\nbackpropagation algorithm, were tested by using the OpenAI Gym toolkit on\nseveral classic control theory problems and Atari 2600 video games. The results\nof this investigation open the way into new, biologically-inspired deep\nreinforcement learning algorithms, and their implementation on neuromorphic\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:43:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Roibu", "Andrei Claudiu", ""]]}, {"id": "1905.04149", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Lina Yao, Xianzhi Wang, Jessica Monaghan, David Mcalpine,\n  Yu Zhang", "title": "A Survey on Deep Learning-based Non-Invasive Brain Signals:Recent\n  Advances and New Frontiers", "comments": "Accepted by Journal of Neural Engineering. Summarized more than 200+\n  brain signal-related papers, systematically covering 8 Brain-Computer\n  Interface (BCI) categories and 10+ deep learning models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Computer Interface (BCI) bridges the human's neural world and the outer\nphysical world by decoding individuals' brain signals into commands\nrecognizable by computer devices. Deep learning has lifted the performance of\nbrain-computer interface systems significantly in recent years. In this\narticle, we systematically investigate brain signal types for BCI and related\ndeep learning concepts for brain signal analysis. We then present a\ncomprehensive survey of deep learning techniques used for BCI, by summarizing\nover 230 contributions most published in the past five years. Finally, we\ndiscuss the applied areas, opening challenges, and future directions for deep\nlearning-based BCI.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:04:00 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:26:12 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 13:32:22 GMT"}, {"version": "v4", "created": "Sat, 26 Oct 2019 06:29:35 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 23:44:10 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhang", "Xiang", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Monaghan", "Jessica", ""], ["Mcalpine", "David", ""], ["Zhang", "Yu", ""]]}, {"id": "1905.04152", "submitter": "Hamid Shiri", "authors": "Hamid Shiri, Jihong Park, Mehdi Bennis", "title": "Massive Autonomous UAV Path Planning: A Neural Network Based Mean-Field\n  Game Theoretic Approach", "comments": "6 pages, 5 figures, submitted to IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the autonomous control of massive unmanned aerial\nvehicles (UAVs) for mission-critical applications (e.g., dispatching many UAVs\nfrom a source to a destination for firefighting). Achieving their fast travel\nand low motion energy without inter-UAV collision under wind perturbation is a\ndaunting control task, which incurs huge communication energy for exchanging\nUAV states in real time. We tackle this problem by exploiting a mean-field game\n(MFG) theoretic control method that requires the UAV state exchanges only once\nat the initial source. Afterwards, each UAV can control its acceleration by\nlocally solving two partial differential equations (PDEs), known as the\nHamilton-Jacobi-Bellman (HJB) and Fokker-Planck-Kolmogorov (FPK) equations.\nThis approach, however, brings about huge computation energy for solving the\nPDEs, particularly under multi-dimensional UAV states. We address this issue by\nutilizing a machine learning (ML) method where two separate ML models\napproximate the solutions of the HJB and FPK equations. These ML models are\ntrained and exploited using an online gradient descent method with low\ncomputational complexity. Numerical evaluations validate that the proposed ML\naided MFG theoretic algorithm, referred to as MFG learning control, is\neffective in collision avoidance with low communication energy and acceptable\ncomputation energy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:07:00 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Shiri", "Hamid", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1905.04159", "submitter": "Dimitrios Stamoulis", "authors": "Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos,\n  Bodhi Priyantha, Jie Liu, Diana Marculescu", "title": "Single-Path NAS: Device-Aware Efficient ConvNet Design", "comments": "ODML-CDNNR 2019 (ICML'19 workshop) oral presentation (extended\n  abstract, required non-archival version). Full paper: arXiv:1904.02877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we automatically design a Convolutional Network (ConvNet) with the\nhighest image classification accuracy under the latency constraint of a mobile\ndevice? Neural Architecture Search (NAS) for ConvNet design is a challenging\nproblem due to the combinatorially large design space and search time (at least\n200 GPU-hours). To alleviate this complexity, we propose Single-Path NAS, a\nnovel differentiable NAS method for designing device-efficient ConvNets in less\nthan 4 hours. 1. Novel NAS formulation: our method introduces a single-path,\nover-parameterized ConvNet to encode all architectural decisions with shared\nconvolutional kernel parameters. 2. NAS efficiency: Our method decreases the\nNAS search cost down to 8 epochs (30 TPU-hours), i.e., up to 5,000x faster\ncompared to prior work. 3. On-device image classification: Single-Path NAS\nachieves 74.96% top-1 accuracy on ImageNet with 79ms inference latency on a\nPixel 1 phone, which is state-of-the-art accuracy compared to NAS methods with\nsimilar latency (<80ms).\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:23:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Stamoulis", "Dimitrios", ""], ["Ding", "Ruizhou", ""], ["Wang", "Di", ""], ["Lymberopoulos", "Dimitrios", ""], ["Priyantha", "Bodhi", ""], ["Liu", "Jie", ""], ["Marculescu", "Diana", ""]]}, {"id": "1905.04166", "submitter": "Daniele Palossi", "authors": "Daniele Palossi, Francesco Conti, Luca Benini", "title": "An Open Source and Open Hardware Deep Learning-powered Visual Navigation\n  Engine for Autonomous Nano-UAVs", "comments": "Accepted for publication in Proceeding of International Conference on\n  Distributed Computing in Sensor Systems (DCOSS 2019). arXiv admin note: text\n  overlap with arXiv:1805.01831", "journal-ref": null, "doi": "10.1109/DCOSS.2019.00111", "report-no": null, "categories": "cs.RO cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter\nand sub-10 Watts of total power budget, have so far been considered incapable\nof running sophisticated visual-based autonomous navigation software without\nexternal aid from base-stations, ad-hoc local positioning infrastructure, and\npowerful external computation servers. In this work, we present what is, to the\nbest of our knowledge, the first 27g nano-UAV system able to run aboard an\nend-to-end, closed-loop visual pipeline for autonomous navigation based on a\nstate-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie\n2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination\nof an ultra-low power computing device (the GAP8 system-on-chip) with a novel\nmethodology for the deployment of deep convolutional neural networks (CNNs). We\nenable onboard real-time execution of a state-of-the-art deep CNN at up to\n18Hz. Field experiments demonstrate that the system's high responsiveness\nprevents collisions with unexpected dynamic obstacles up to a flight speed of\n1.5m/s. In addition, we also demonstrate the capability of our visual\nnavigation engine of fully autonomous indoor navigation on a 113m previously\nunseen path. To share our key findings with the embedded and robotics\ncommunities and foster further developments in autonomous nano-UAVs, we\npublicly release all our code, datasets, and trained networks.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:34:18 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Palossi", "Daniele", ""], ["Conti", "Francesco", ""], ["Benini", "Luca", ""]]}, {"id": "1905.04172", "submitter": "Christian Etmann", "authors": "Christian Etmann, Sebastian Lunz, Peter Maass, Carola-Bibiane\n  Sch\\\"onlieb", "title": "On the Connection Between Adversarial Robustness and Saliency Map\n  Interpretability", "comments": "12 pages, accepted for publication at the 36th International\n  Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on the adversarial vulnerability of neural networks have shown\nthat models trained to be more robust to adversarial attacks exhibit more\ninterpretable saliency maps than their non-robust counterparts. We aim to\nquantify this behavior by considering the alignment between input image and\nsaliency map. We hypothesize that as the distance to the decision boundary\ngrows,so does the alignment. This connection is strictly true in the case of\nlinear models. We confirm these theoretical findings with experiments based on\nmodels trained with a local Lipschitz regularization and identify where the\nnon-linear nature of neural networks weakens the relation.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:45:21 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Etmann", "Christian", ""], ["Lunz", "Sebastian", ""], ["Maass", "Peter", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1905.04175", "submitter": "Fabien Lotte", "authors": "Giuseppe Amato (CNR PISA), Malte Behrmann, Fr\\'ed\\'eric Bimbot\n  (PANAMA), Baptiste Caramiaux (LRI, EX-SITU), Fabrizio Falchi (CNR PISA),\n  Ander Garcia, Joost Geurts (Inria), Jaume Gibert, Guillaume Gravier\n  (LinkMedia), Hadmut Holken, Hartmut Koenitz (HKU), Sylvain Lefebvre (MFX),\n  Antoine Liutkus (LORIA, ZENITH), Fabien Lotte (Potioc, LaBRI), Andrew Perkis\n  (NTNU), Rafael Redondo, Enrico Turrin (FEP), Thierry Vieville (Mnemosyne),\n  Emmanuel Vincent (MULTISPEECH)", "title": "AI in the media and creative industries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the Big Data revolution and increasing computing capacities,\nArtificial Intelligence (AI) has made an impressive revival over the past few\nyears and is now omnipresent in both research and industry. The creative\nsectors have always been early adopters of AI technologies and this continues\nto be the case. As a matter of fact, recent technological developments keep\npushing the boundaries of intelligent systems in creative applications: the\ncritically acclaimed movie \"Sunspring\", released in 2016, was entirely written\nby AI technology, and the first-ever Music Album, called \"Hello World\",\nproduced using AI has been released this year. Simultaneously, the exploratory\nnature of the creative process is raising important technical challenges for AI\nsuch as the ability for AI-powered techniques to be accurate under limited data\nresources, as opposed to the conventional \"Big Data\" approach, or the ability\nto process, analyse and match data from multiple modalities (text, sound,\nimages, etc.) at the same time. The purpose of this white paper is to\nunderstand future technological advances in AI and their growing impact on\ncreative industries. This paper addresses the following questions: Where does\nAI operate in creative Industries? What is its operative role? How will AI\ntransform creative industries in the next ten years? This white paper aims to\nprovide a realistic perspective of the scope of AI actions in creative\nindustries, proposes a vision of how this technology could contribute to\nresearch and development works in such context, and identifies research and\ndevelopment challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:56:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Amato", "Giuseppe", "", "CNR PISA"], ["Behrmann", "Malte", "", "PANAMA"], ["Bimbot", "Fr\u00e9d\u00e9ric", "", "PANAMA"], ["Caramiaux", "Baptiste", "", "LRI, EX-SITU"], ["Falchi", "Fabrizio", "", "CNR PISA"], ["Garcia", "Ander", "", "Inria"], ["Geurts", "Joost", "", "Inria"], ["Gibert", "Jaume", "", "LinkMedia"], ["Gravier", "Guillaume", "", "LinkMedia"], ["Holken", "Hadmut", "", "HKU"], ["Koenitz", "Hartmut", "", "HKU"], ["Lefebvre", "Sylvain", "", "MFX"], ["Liutkus", "Antoine", "", "LORIA, ZENITH"], ["Lotte", "Fabien", "", "Potioc, LaBRI"], ["Perkis", "Andrew", "", "NTNU"], ["Redondo", "Rafael", "", "FEP"], ["Turrin", "Enrico", "", "FEP"], ["Vieville", "Thierry", "", "Mnemosyne"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "1905.04181", "submitter": "Abdulmajid Murad", "authors": "Abdulmajid Murad, Frank Alexander Kraemer, Kerstin Bach, Gavin Taylor", "title": "Autonomous Management of Energy-Harvesting IoT Nodes Using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": "IEEE 13th International Conference on Self-Adaptive and\n  Self-Organizing Systems (SASO) 2019 Jun 16 (pp. 43-51)", "doi": "10.1109/SASO.2019.00015", "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is capable of managing wireless,\nenergy-harvesting IoT nodes by solving the problem of autonomous management in\nnon-stationary, resource-constrained settings. We show that the\nstate-of-the-art policy-gradient approaches to RL are appropriate for the IoT\ndomain and that they outperform previous approaches. Due to the ability to\nmodel continuous observation and action spaces, as well as improved function\napproximation capability, the new approaches are able to solve harder problems,\npermitting reward functions that are better aligned with the actual application\ngoals. We show such a reward function and use policy-gradient approaches to\nlearn capable policies, leading to behavior more appropriate for IoT nodes with\nless manual design effort, increasing the level of autonomy in IoT.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:09:13 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Murad", "Abdulmajid", ""], ["Kraemer", "Frank Alexander", ""], ["Bach", "Kerstin", ""], ["Taylor", "Gavin", ""]]}, {"id": "1905.04191", "submitter": "Guoxian Yu", "authors": "Xing Wang, Jun Wang, Carlotta Domeniconi, Guoxian Yu, Guoqiang Xiao,\n  Maozu Guo", "title": "Multiple Independent Subspace Clusterings", "comments": "AAAI2019", "journal-ref": "AAAI2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple clustering aims at discovering diverse ways of organizing data into\nclusters. Despite the progress made, it's still a challenge for users to\nanalyze and understand the distinctive structure of each output clustering. To\nease this process, we consider diverse clusterings embedded in different\nsubspaces, and analyze the embedding subspaces to shed light into the structure\nof each clustering. To this end, we provide a two-stage approach called MISC\n(Multiple Independent Subspace Clusterings). In the first stage, MISC uses\nindependent subspace analysis to seek multiple and statistical independent\n(i.e. non-redundant) subspaces, and determines the number of subspaces via the\nminimum description length principle. In the second stage, to account for the\nintrinsic geometric structure of samples embedded in each subspace, MISC\nperforms graph regularized semi-nonnegative matrix factorization to explore\nclusters. It additionally integrates the kernel trick into matrix factorization\nto handle non-linearly separable clusters. Experimental results on synthetic\ndatasets show that MISC can find different interesting clusterings from the\nsought independent subspaces, and it also outperforms other related and\ncompetitive approaches on real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:24:44 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Wang", "Xing", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Yu", "Guoxian", ""], ["Xiao", "Guoqiang", ""], ["Guo", "Maozu", ""]]}, {"id": "1905.04192", "submitter": "Abraham Woubie Zewoudie Dr.", "authors": "Abraham Woubie, Anssi Kanervisto, Janne Karttunen, and Ville Hautamaki", "title": "Do Autonomous Agents Benefit from Hearing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mapping states to actions in deep reinforcement learning is mainly based on\nvisual information. The commonly used approach for dealing with visual\ninformation is to extract pixels from images and use them as state\nrepresentation for reinforcement learning agent. But, any vision only agent is\nhandicapped by not being able to sense audible cues. Using hearing, animals are\nable to sense targets that are outside of their visual range. In this work, we\npropose the use of audio as complementary information to visual only in state\nrepresentation. We assess the impact of such multi-modal setup in\nreach-the-goal tasks in ViZDoom environment. Results show that the agent\nimproves its behavior when visual information is accompanied with audio\nfeatures.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:25:49 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Woubie", "Abraham", ""], ["Kanervisto", "Anssi", ""], ["Karttunen", "Janne", ""], ["Hautamaki", "Ville", ""]]}, {"id": "1905.04194", "submitter": "John T\\\"ornblom", "authors": "John T\\\"ornblom and Simin Nadjm-Tehrani", "title": "Formal Verification of Input-Output Mappings of Tree Ensembles", "comments": null, "journal-ref": null, "doi": "10.1016/j.scico.2020.102450", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent advances in machine learning and artificial intelligence are now being\nconsidered in safety-critical autonomous systems where software defects may\ncause severe harm to humans and the environment. Design organizations in these\ndomains are currently unable to provide convincing arguments that their systems\nare safe to operate when machine learning algorithms are used to implement\ntheir software.\n  In this paper, we present an efficient method to extract equivalence classes\nfrom decision trees and tree ensembles, and to formally verify that their\ninput-output mappings comply with requirements. The idea is that, given that\nsafety requirements can be traced to desirable properties on system\ninput-output patterns, we can use positive verification outcomes in safety\narguments. This paper presents the implementation of the method in the tool\nVoTE (Verifier of Tree Ensembles), and evaluates its scalability on two case\nstudies presented in current literature.\n  We demonstrate that our method is practical for tree ensembles trained on\nlow-dimensional data with up to 25 decision trees and tree depths of up to 20.\nOur work also studies the limitations of the method with high-dimensional data\nand preliminarily investigates the trade-off between large number of trees and\ntime taken for verification.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:30:59 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 09:56:03 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["T\u00f6rnblom", "John", ""], ["Nadjm-Tehrani", "Simin", ""]]}, {"id": "1905.04199", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Xuan Zhang, and Morten\n  Goodwin", "title": "A Scheme for Continuous Input to the Tsetlin Machine with Applications\n  to Forecasting Disease Outbreaks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply a new promising tool for pattern classification,\nnamely, the Tsetlin Machine (TM), to the field of disease forecasting. The TM\nis interpretable because it is based on manipulating expressions in\npropositional logic, leveraging a large team of Tsetlin Automata (TA). Apart\nfrom being interpretable, this approach is attractive due to its low\ncomputational cost and its capacity to handle noise. To attack the problem of\nforecasting, we introduce a preprocessing method that extends the TM so that it\ncan handle continuous input. Briefly stated, we convert continuous input into a\nbinary representation based on thresholding. The resulting extended TM is\nevaluated and analyzed using an artificial dataset. The TM is further applied\nto forecast dengue outbreaks of all the seventeen regions in the Philippines\nusing the spatio-temporal properties of the data. Experimental results show\nthat dengue outbreak forecasts made by the TM are more accurate than those\nobtained by a Support Vector Machine (SVM), Decision Trees (DTs), and several\nmulti-layered Artificial Neural Networks (ANNs), both in terms of forecasting\nprecision and F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:42:10 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:08:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Zhang", "Xuan", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.04205", "submitter": "Sven Tomforde", "authors": "Stefan Rudolph, Sven Tomforde, J\\\"org H\\\"ahner", "title": "On the Detection of Mutual Influences and Their Consideration in\n  Reinforcement Learning Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adaptation has been proposed as a mechanism to counter complexity in\ncontrol problems of technical systems. A major driver behind self-adaptation is\nthe idea to transfer traditional design-time decisions to runtime and into the\nresponsibility of systems themselves. In order to deal with unforeseen events\nand conditions, systems need creativity -- typically realized by means of\nmachine learning capabilities. Such learning mechanisms are based on different\nsources of knowledge. Feedback from the environment used for reinforcement\npurposes is probably the most prominent one within the self-adapting and\nself-organizing (SASO) systems community. However, the impact of other\n(sub-)systems on the success of the individual system's learning performance\nhas mostly been neglected in this context. In this article, we propose a novel\nmethodology to identify effects of actions performed by other systems in a\nshared environment on the utility achievement of an autonomous system. Consider\nsmart cameras (SC) as illustrating example: For goals such as 3D reconstruction\nof objects, the most promising configuration of one SC in terms of\npan/tilt/zoom parameters depends largely on the configuration of other SCs in\nthe vicinity. Since such mutual influences cannot be pre-defined for dynamic\nsystems, they have to be learned at runtime. Furthermore, they have to be taken\ninto consideration when self-improving the own configuration decisions based on\na feedback loop concept, e.g., known from the SASO domain or the Autonomic and\nOrganic Computing initiatives. We define a methodology to detect such\ninfluences at runtime, present an approach to consider this information in a\nreinforcement learning technique, and analyze the behavior in artificial as\nwell as real-world SASO system settings.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:04:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Rudolph", "Stefan", ""], ["Tomforde", "Sven", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "1905.04206", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Lei Jiao, and Morten\n  Goodwin", "title": "The Regression Tsetlin Machine: A Tsetlin Machine for Continuous Output\n  Problems", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Tsetlin Machine (TM) has provided competitive pattern\nclassification accuracy in several benchmarks, composing patterns with\neasy-to-interpret conjunctive clauses in propositional logic. In this paper, we\ngo beyond pattern classification by introducing a new type of TMs, namely, the\nRegression Tsetlin Machine (RTM). In all brevity, we modify the inner inference\nmechanism of the TM so that input patterns are transformed into a single\ncontinuous output, rather than to distinct categories. We achieve this by: (1)\nusing the conjunctive clauses of the TM to capture arbitrarily complex\npatterns; (2) mapping these patterns to a continuous output through a novel\nvoting and normalization mechanism; and (3) employing a feedback scheme that\nupdates the TM clauses to minimize the regression error. The feedback scheme\nuses a new activation probability function that stabilizes the updating of\nclauses, while the overall system converges towards an accurate input-output\nmapping. The performance of the RTM is evaluated using six different artificial\ndatasets with and without noise, in comparison with the Classic Tsetlin Machine\n(CTM) and the Multiclass Tsetlin Machine (MTM). Our empirical results indicate\nthat the RTM obtains the best training and testing results for both noisy and\nnoise-free datasets, with a smaller number of clauses. This, in turn,\ntranslates to higher regression accuracy, using significantly less\ncomputational resources.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:05:30 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 19:02:39 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.04211", "submitter": "Yang Yang", "authors": "Yang Yang, Marius Pesavento, Zhi-Quan Luo, Bj\\\"orn Ottersten", "title": "Inexact Block Coordinate Descent Algorithms for Nonsmooth Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2959240", "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an inexact block coordinate descent algorithm for\nlarge-scale nonsmooth nonconvex optimization problems. At each iteration, a\nparticular block variable is selected and updated by inexactly solving the\noriginal optimization problem with respect to that block variable. More\nprecisely, a local approximation of the original optimization problem is\nsolved. The proposed algorithm has several attractive features, namely, i) high\nflexibility, as the approximation function only needs to be strictly convex and\nit does not have to be a global upper bound of the original function; ii) fast\nconvergence, as the approximation function can be designed to exploit the\nproblem structure at hand and the stepsize is calculated by the line search;\niii) low complexity, as the approximation subproblems are much easier to solve\nand the line search scheme is carried out over a properly constructed\ndifferentiable function; iv) guaranteed convergence of a subsequence to a\nstationary point, even when the objective function does not have a Lipschitz\ncontinuous gradient. Interestingly, when the approximation subproblem is solved\nby a descent algorithm, convergence of a subsequence to a stationary point is\nstill guaranteed even if the approximation subproblem is solved inexactly by\nterminating the descent algorithm after a finite number of iterations. These\nfeatures make the proposed algorithm suitable for large-scale problems where\nthe dimension exceeds the memory and/or the processing capability of the\nexisting hardware. These features are also illustrated by several applications\nin signal processing and machine learning, for instance, network anomaly\ndetection and phase retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:16:24 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 21:06:15 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 13:30:15 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 11:47:05 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 08:35:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Yang", "Yang", ""], ["Pesavento", "Marius", ""], ["Luo", "Zhi-Quan", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "1905.04218", "submitter": "Aran Sena", "authors": "Aran Sena, Matthew J Howard", "title": "Quantifying Teaching Behaviour in Robot Learning from Demonstration", "comments": "Preprint for International Journal of Robotics Research (IJRR)\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration allows for rapid deployment of robot manipulators\nto a great many tasks, by relying on a person showing the robot what to do\nrather than programming it. While this approach provides many opportunities,\nmeasuring, evaluating and improving the person's teaching ability has remained\nlargely unexplored in robot manipulation research. To this end, a model for\nlearning from demonstration is presented here which incorporates the teacher's\nunderstanding of, and influence on, the learner. The proposed model is used to\nclarify the teacher's objectives during learning from demonstration, providing\nnew views on how teaching failures and efficiency can be defined. The benefit\nof this approach is shown in two experiments (N=30 and N=36, respectively),\nwhich highlight the difficulty teachers have in providing effective\ndemonstrations, and show how ~169-180% improvement in teaching efficiency can\nbe achieved through evaluation and feedback shaped by the proposed framework,\nrelative to unguided teaching.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:30:25 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sena", "Aran", ""], ["Howard", "Matthew J", ""]]}, {"id": "1905.04223", "submitter": "Colin Paterson", "authors": "Rob Ashmore, Radu Calinescu and Colin Paterson", "title": "Assuring the Machine Learning Lifecycle: Desiderata, Methods, and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has evolved into an enabling technology for a wide range of\nhighly successful applications. The potential for this success to continue and\naccelerate has placed machine learning (ML) at the top of research, economic\nand political agendas. Such unprecedented interest is fuelled by a vision of ML\napplicability extending to healthcare, transportation, defence and other\ndomains of great societal importance. Achieving this vision requires the use of\nML in safety-critical applications that demand levels of assurance beyond those\nneeded for current ML applications. Our paper provides a comprehensive survey\nof the state-of-the-art in the assurance of ML, i.e. in the generation of\nevidence that ML is sufficiently safe for its intended use. The survey covers\nthe methods capable of providing such evidence at different stages of the\nmachine learning lifecycle, i.e. of the complex, iterative process that starts\nwith the collection of the data used to train an ML component for a system, and\nends with the deployment of that component within the system. The paper begins\nwith a systematic presentation of the ML lifecycle and its stages. We then\ndefine assurance desiderata for each stage, review existing methods that\ncontribute to achieving these desiderata, and identify open challenges that\nrequire further research.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:44:38 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ashmore", "Rob", ""], ["Calinescu", "Radu", ""], ["Paterson", "Colin", ""]]}, {"id": "1905.04225", "submitter": "Okan K\\\"op\\\"ukl\\\"u", "authors": "Okan K\\\"op\\\"ukl\\\"u, Yao Rong, Gerhard Rigoll", "title": "Talking With Your Hands: Scaling Hand Gestures and Recognition With CNNs", "comments": "Accepted to ICCV 2019 workshop - Observing and Understanding Hands in\n  Action (HANDS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of hand gestures provides a natural alternative to cumbersome\ninterface devices for Human-Computer Interaction (HCI) systems. As the\ntechnology advances and communication between humans and machines becomes more\ncomplex, HCI systems should also be scaled accordingly in order to accommodate\nthe introduced complexities. In this paper, we propose a methodology to scale\nhand gestures by forming them with predefined gesture-phonemes, and a\nconvolutional neural network (CNN) based framework to recognize hand gestures\nby learning only their constituents of gesture-phonemes. The total number of\npossible hand gestures can be increased exponentially by increasing the number\nof used gesture-phonemes. For this objective, we introduce a new benchmark\ndataset named Scaled Hand Gestures Dataset (SHGD) with only gesture-phonemes in\nits training set and 3-tuples gestures in the test set. In our experimental\nanalysis, we achieve to recognize hand gestures containing one and three\ngesture-phonemes with an accuracy of 98.47% (in 15 classes) and 94.69% (in 810\nclasses), respectively. Our dataset, code and pretrained models are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:49:16 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 08:28:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["K\u00f6p\u00fckl\u00fc", "Okan", ""], ["Rong", "Yao", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "1905.04226", "submitter": "Kazuki Irie", "authors": "Kazuki Irie, Albert Zeyer, Ralf Schl\\\"uter, Hermann Ney", "title": "Language Modeling with Deep Transformers", "comments": "To appear in the proceedings of INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-2225", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore deep autoregressive Transformer models in language modeling for\nspeech recognition. We focus on two aspects. First, we revisit Transformer\nmodel configurations specifically for language modeling. We show that well\nconfigured Transformer models outperform our baseline models based on the\nshallow stack of LSTM recurrent neural network layers. We carry out experiments\non the open-source LibriSpeech 960hr task, for both 200K vocabulary word-level\nand 10K byte-pair encoding subword-level language modeling. We apply our\nword-level models to conventional hybrid speech recognition by lattice\nrescoring, and the subword-level models to attention based encoder-decoder\nmodels by shallow fusion. Second, we show that deep Transformer language models\ndo not require positional encoding. The positional encoding is an essential\naugmentation for the self-attention mechanism which is invariant to sequence\nordering. However, in autoregressive setup, as is the case for language\nmodeling, the amount of information increases along the position dimension,\nwhich is a positional signal by its own. The analysis of attention weights\nshows that deep autoregressive self-attention models can automatically make use\nof such positional information. We find that removing the positional encoding\neven slightly improves the performance of these models.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:50:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 15:45:32 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Irie", "Kazuki", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.04230", "submitter": "Oguz Elibol", "authors": "Oguz H. Elibol, Gokce Keskin, Anil Thomas", "title": "Semi-supervised and Population Based Training for Voice Commands\n  Recognition", "comments": null, "journal-ref": "ICASSP 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a rapid design methodology that combines automated hyper-parameter\ntuning with semi-supervised training to build highly accurate and robust models\nfor voice commands classification. Proposed approach allows quick evaluation of\nnetwork architectures to fit performance and power constraints of available\nhardware, while ensuring good hyper-parameter choices for each network in\nreal-world scenarios. Leveraging the vast amount of unlabeled data with a\nstudent/teacher based semi-supervised method, classification accuracy is\nimproved from 84% to 94% in the validation set. For model optimization, we\nexplore the hyper-parameter space through population based training and obtain\nan optimized model in the same time frame as it takes to train a single model.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:58:38 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Elibol", "Oguz H.", ""], ["Keskin", "Gokce", ""], ["Thomas", "Anil", ""]]}, {"id": "1905.04232", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Automatic Programming of Cellular Automata and Artificial Neural\n  Networks Guided by Philosophy", "comments": "12 pages, 1 figure", "journal-ref": "Rolf Dornberger, editor, New Trends in Business Information\n  Systems and Technology: Digital Innovation and Digital Business\n  Transformation, pages 131-146. Springer, Cham, 2020", "doi": "10.1007/978-3-030-48332-6", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many computer models such as cellular automata and artificial neural networks\nhave been developed and successfully applied. However, in some cases, these\nmodels might be restrictive on the possible solutions or their solutions might\nbe difficult to interpret. To overcome this problem, we outline a new approach,\nthe so-called allagmatic method, that automatically programs and executes\nmodels with as little limitations as possible while maintaining human\ninterpretability. Earlier we described a metamodel and its building blocks\naccording to the philosophical concepts of structure (spatial dimension) and\noperation (temporal dimension). They are entity, milieu, and update function\nthat together abstractly describe cellular automata, artificial neural\nnetworks, and possibly any kind of computer model. By automatically combining\nthese building blocks in an evolutionary computation, interpretability might be\nincreased by the relationship to the metamodel, and models might be translated\ninto more interpretable models via the metamodel. We propose generic and\nobject-oriented programming to implement the entities and their milieus as\ndynamic and generic arrays and the update function as a method. We show two\nexperiments where a simple cellular automaton and an artificial neural network\nare automatically programmed, compiled, and executed. A target state is\nsuccessfully evolved and learned in the cellular automaton and artificial\nneural network, respectively. We conclude that the allagmatic method can create\nand execute cellular automaton and artificial neural network models in an\nautomated manner with the guidance of philosophy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:00:09 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:03:51 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 10:06:41 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:47:05 GMT"}, {"version": "v5", "created": "Sun, 3 May 2020 21:05:20 GMT"}, {"version": "v6", "created": "Mon, 31 Aug 2020 21:45:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "1905.04241", "submitter": "Tong Wang", "authors": "Tong Wang and Qihang Lin", "title": "Hybrid Predictive Model: When an Interpretable Model Collaborates with a\n  Black-box Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable machine learning has become a strong competitor for traditional\nblack-box models. However, the possible loss of the predictive performance for\ngaining interpretability is often inevitable, putting practitioners in a\ndilemma of choosing between high accuracy (black-box models) and\ninterpretability (interpretable models). In this work, we propose a novel\nframework for building a Hybrid Predictive Model (HPM) that integrates an\ninterpretable model with any black-box model to combine their strengths. The\ninterpretable model substitutes the black-box model on a subset of data where\nthe black-box is overkill or nearly overkill, gaining transparency at no or low\ncost of the predictive accuracy. We design a principled objective function that\nconsiders predictive accuracy, model interpretability, and model transparency\n(defined as the percentage of data processed by the interpretable substitute.)\nUnder this framework, we propose two hybrid models, one substituting with\nassociation rules and the other with linear models, and we design customized\ntraining algorithms for both models. We test the hybrid models on structured\ndata and text data where interpretable models collaborate with various\nstate-of-the-art black-box models. Results show that hybrid models obtain an\nefficient trade-off between transparency and predictive performance,\ncharacterized by our proposed efficient frontiers.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:21:00 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wang", "Tong", ""], ["Lin", "Qihang", ""]]}, {"id": "1905.04243", "submitter": "Zhengwei Wang", "authors": "Zhengwei Wang, Qi She, Alan F. Smeaton, Tomas E. Ward, Graham Healy", "title": "Synthetic-Neuroscore: Using A Neuro-AI Interface for Evaluating\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are increasingly attracting attention\nin the computer vision, natural language processing, speech synthesis and\nsimilar domains. Arguably the most striking results have been in the area of\nimage synthesis. However, evaluating the performance of GANs is still an open\nand challenging problem. Existing evaluation metrics primarily measure the\ndissimilarity between real and generated images using automated statistical\nmethods. They often require large sample sizes for evaluation and do not\ndirectly reflect human perception of image quality. In this work, we describe\nan evaluation metric we call Neuroscore, for evaluating the performance of\nGANs, that more directly reflects psychoperceptual image quality through the\nutilization of brain signals. Our results show that Neuroscore has superior\nperformance to the current evaluation metrics in that: (1) It is more\nconsistent with human judgment; (2) The evaluation process needs much smaller\nnumbers of samples; and (3) It is able to rank the quality of images on a per\nGAN basis. A convolutional neural network (CNN) based neuro-AI interface is\nproposed to predict Neuroscore from GAN-generated images directly without the\nneed for neural responses. Importantly, we show that including neural responses\nduring the training phase of the network can significantly improve the\nprediction capability of the proposed model. Materials related to this work are\nprovided at https://github.com/villawang/Neuro-AI-Interface.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:25:07 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 00:55:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Zhengwei", ""], ["She", "Qi", ""], ["Smeaton", "Alan F.", ""], ["Ward", "Tomas E.", ""], ["Healy", "Graham", ""]]}, {"id": "1905.04270", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, Yanzhi Wang, Xiang\n  Chen", "title": "Interpreting and Evaluating Neural Network Robustness", "comments": "Accepted in IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, adversarial deception becomes one of the most considerable threats\nto deep neural networks. However, compared to extensive research in new designs\nof various adversarial attacks and defenses, the neural networks' intrinsic\nrobustness property is still lack of thorough investigation. This work aims to\nqualitatively interpret the adversarial attack and defense mechanism through\nloss visualization, and establish a quantitative metric to evaluate the neural\nnetwork model's intrinsic robustness. The proposed robustness metric identifies\nthe upper bound of a model's prediction divergence in the given domain and thus\nindicates whether the model can maintain a stable prediction. With extensive\nexperiments, our metric demonstrates several advantages over conventional\nadversarial testing accuracy based robustness estimation: (1) it provides a\nuniformed evaluation to models with different structures and parameter scales;\n(2) it over-performs conventional accuracy based robustness estimation and\nprovides a more reliable evaluation that is invariant to different test\nsettings; (3) it can be fast generated without considerable testing cost.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:21:15 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Yu", "Fuxun", ""], ["Qin", "Zhuwei", ""], ["Liu", "Chenchen", ""], ["Zhao", "Liang", ""], ["Wang", "Yanzhi", ""], ["Chen", "Xiang", ""]]}, {"id": "1905.04271", "submitter": "Huitao Shen", "authors": "Huitao Shen", "title": "Mutual Information Scaling and Expressive Power of Sequence Models", "comments": "12 + 15 pages. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence models assign probabilities to variable-length sequences such as\nnatural language texts. The ability of sequence models to capture temporal\ndependence can be characterized by the temporal scaling of correlation and\nmutual information. In this paper, we study the mutual information of recurrent\nneural networks (RNNs) including long short-term memories and self-attention\nnetworks such as Transformers. Through a combination of theoretical study of\nlinear RNNs and empirical study of nonlinear RNNs, we find their mutual\ninformation decays exponentially in temporal distance. On the other hand,\nTransformers can capture long-range mutual information more efficiently, making\nthem preferable in modeling sequences with slow power-law mutual information,\nsuch as natural languages and stock prices. We discuss the connection of these\nresults with statistical mechanics. We also point out the non-uniformity\nproblem in many natural language datasets. We hope this work provides a new\nperspective in understanding the expressive power of sequence models and shed\nnew light on improving the architecture of them.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:21:21 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Shen", "Huitao", ""]]}, {"id": "1905.04278", "submitter": "Zongheng Yang", "authors": "Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi\n  Chen, Pieter Abbeel, Joseph M. Hellerstein, Sanjay Krishnan, Ion Stoica", "title": "Deep Unsupervised Cardinality Estimation", "comments": "VLDB 2020. Updates since version 1: new title and new/revised content", "journal-ref": "Proceedings of the VLDB Endowment (PLVDB), Vol. 13, No. 3, pp.\n  279-292 (2019)", "doi": "10.14778/3368289.3368294", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality estimation has long been grounded in statistical tools for\ndensity estimation. To capture the rich multivariate distributions of\nrelational tables, we propose the use of a new type of high-capacity\nstatistical model: deep autoregressive models. However, direct application of\nthese models leads to a limited estimator that is prohibitively expensive to\nevaluate for range or wildcard predicates. To produce a truly usable estimator,\nwe develop a Monte Carlo integration scheme on top of autoregressive models\nthat can efficiently handle range queries with dozens of dimensions or more.\n  Like classical synopses, our estimator summarizes the data without\nsupervision. Unlike previous solutions, we approximate the joint data\ndistribution without any independence assumptions. Evaluated on real-world\ndatasets and compared against real systems and dominant families of techniques,\nour estimator achieves single-digit multiplicative error at tail, an up to\n90$\\times$ accuracy improvement over the second best method, and is space- and\nruntime-efficient.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:36:00 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 18:36:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yang", "Zongheng", ""], ["Liang", "Eric", ""], ["Kamsetty", "Amog", ""], ["Wu", "Chenggang", ""], ["Duan", "Yan", ""], ["Chen", "Xi", ""], ["Abbeel", "Pieter", ""], ["Hellerstein", "Joseph M.", ""], ["Krishnan", "Sanjay", ""], ["Stoica", "Ion", ""]]}, {"id": "1905.04305", "submitter": "Lukas Kades", "authors": "Lukas Kades, Jan M. Pawlowski, Alexander Rothkopf, Manuel Scherzer,\n  Julian M. Urban, Sebastian J. Wetzel, Nicolas Wink, Felix P. G. Ziegler", "title": "Spectral Reconstruction with Deep Neural Networks", "comments": "20 pages, 16 figures", "journal-ref": "Phys. Rev. D 102, 096001 (2020)", "doi": "10.1103/PhysRevD.102.096001", "report-no": null, "categories": "physics.comp-ph cs.LG hep-lat hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore artificial neural networks as a tool for the reconstruction of\nspectral functions from imaginary time Green's functions, a classic\nill-conditioned inverse problem. Our ansatz is based on a supervised learning\nframework in which prior knowledge is encoded in the training data and the\ninverse transformation manifold is explicitly parametrised through a neural\nnetwork. We systematically investigate this novel reconstruction approach,\nproviding a detailed analysis of its performance on physically motivated mock\ndata, and compare it to established methods of Bayesian inference. The\nreconstruction accuracy is found to be at least comparable, and potentially\nsuperior in particular at larger noise levels. We argue that the use of\nlabelled training data in a supervised setting and the freedom in defining an\noptimisation objective are inherent advantages of the present approach and may\nlead to significant improvements over state-of-the-art methods in the future.\nPotential directions for further research are discussed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:51:45 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 12:34:20 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kades", "Lukas", ""], ["Pawlowski", "Jan M.", ""], ["Rothkopf", "Alexander", ""], ["Scherzer", "Manuel", ""], ["Urban", "Julian M.", ""], ["Wetzel", "Sebastian J.", ""], ["Wink", "Nicolas", ""], ["Ziegler", "Felix P. G.", ""]]}, {"id": "1905.04307", "submitter": "Daniel Salles Civitarese", "authors": "Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brazil, Bianca\n  Zadrozny", "title": "Semantic Segmentation of Seismic Images", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all work to understand Earth's subsurface on a large scale relies on\nthe interpretation of seismic surveys by experts who segment the survey\n(usually a cube) into layers; a process that is very time demanding. In this\npaper, we present a new deep neural network architecture specially designed to\nsemantically segment seismic images with a minimal amount of training data. To\nachieve this, we make use of a transposed residual unit that replaces the\ntraditional dilated convolution for the decode block. Also, instead of using a\npredefined shape for up-scaling, our network learns all the steps to upscale\nthe features from the encoder. We train our neural network using the Penobscot\n3D dataset; a real seismic dataset acquired offshore Nova Scotia, Canada. We\ncompare our approach with two well-known deep neural network topologies: Fully\nConvolutional Network and U-Net. In our experiments, we show that our approach\ncan achieve more than 99 percent of the mean intersection over union (mIOU)\nmetric, outperforming the existing topologies. Moreover, our qualitative\nresults show that the obtained model can produce masks very close to human\ninterpretation with very little discontinuity.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:42:35 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Civitarese", "Daniel", ""], ["Szwarcman", "Daniela", ""], ["Brazil", "Emilio Vital", ""], ["Zadrozny", "Bianca", ""]]}, {"id": "1905.04326", "submitter": "Everett Fall", "authors": "Everett Fall, Kai-wei Chang, Liang-Gee Chen", "title": "Dynamically Expanded CNN Array for Video Coding", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video coding is a critical step in all popular methods of streaming video.\nMarked progress has been made in video quality, compression, and computational\nefficiency. Recently, there has been an interest in finding ways to apply\ntechniques form the fast-progressing field of machine learning to further\nimprove video coding.\n  We present a method that uses convolutional neural networks to help refine\nthe output of various standard coding methods. The novelty of our approach is\nto train multiple different sets of network parameters, with each set\ncorresponding to a specific, short segment of video. The array of network\nparameter sets expands dynamically to match a video of any length. We show that\nour method can improve the quality and compression efficiency of standard video\ncodecs.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:16:10 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Fall", "Everett", ""], ["Chang", "Kai-wei", ""], ["Chen", "Liang-Gee", ""]]}, {"id": "1905.04337", "submitter": "Randy Jia", "authors": "Shipra Agrawal, Randy Jia", "title": "Learning in structured MDPs with convex cost functions: Improved regret\n  bounds for inventory management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic inventory control problem under censored demands,\nlost sales, and positive lead times. This is a fundamental problem in inventory\nmanagement, with significant literature establishing near-optimality of a\nsimple class of policies called ``base-stock policies'' for the underlying\nMarkov Decision Process (MDP), as well as convexity of long run average-cost\nunder those policies. We consider the relatively less studied problem of\ndesigning a learning algorithm for this problem when the underlying demand\ndistribution is unknown. The goal is to bound regret of the algorithm when\ncompared to the best base-stock policy. We utilize the convexity properties and\na newly derived bound on bias of base-stock policies to establish a connection\nto stochastic convex bandit optimization.\n  Our main contribution is a learning algorithm with a regret bound of\n$\\tilde{O}(L\\sqrt{T}+D)$ for the inventory control problem. Here $L$ is the\nfixed and known lead time, and $D$ is an unknown parameter of the demand\ndistribution described roughly as the number of time steps needed to generate\nenough demand for depleting one unit of inventory. Notably, even though the\nstate space of the underlying MDP is continuous and $L$-dimensional, our regret\nbounds depend linearly on $L$. Our results significantly improve the previously\nbest known regret bounds for this problem where the dependence on $L$ was\nexponential and many further assumptions on demand distribution were required.\nThe techniques presented here may be of independent interest for other settings\nthat involve large structured MDPs but with convex cost functions.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:38:38 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Agrawal", "Shipra", ""], ["Jia", "Randy", ""]]}, {"id": "1905.04346", "submitter": "Hao Yu", "authors": "Hao Yu and Rong Jin", "title": "On the Computation and Communication Complexity of Parallel SGD with\n  Dynamic Batch Sizes for Stochastic Non-Convex Optimization", "comments": "A short version is accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For SGD based distributed stochastic optimization, computation complexity,\nmeasured by the convergence rate in terms of the number of stochastic gradient\ncalls, and communication complexity, measured by the number of inter-node\ncommunication rounds, are two most important performance metrics. The classical\ndata-parallel implementation of SGD over $N$ workers can achieve linear speedup\nof its convergence rate but incurs an inter-node communication round at each\nbatch. We study the benefit of using dynamically increasing batch sizes in\nparallel SGD for stochastic non-convex optimization by charactering the\nattained convergence rate and the required number of communication rounds. We\nshow that for stochastic non-convex optimization under the P-L condition, the\nclassical data-parallel SGD with exponentially increasing batch sizes can\nachieve the fastest known $O(1/(NT))$ convergence with linear speedup using\nonly $\\log(T)$ communication rounds. For general stochastic non-convex\noptimization, we propose a Catalyst-like algorithm to achieve the fastest known\n$O(1/\\sqrt{NT})$ convergence with only $O(\\sqrt{NT}\\log(\\frac{T}{N}))$\ncommunication rounds.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:08:26 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yu", "Hao", ""], ["Jin", "Rong", ""]]}, {"id": "1905.04348", "submitter": "Shauna Revay", "authors": "Shauna Revay, Matthew Teschke", "title": "Multiclass Language Identification using Deep Learning on Spectral\n  Images of Audio Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step in any voice recognition software is to determine what\nlanguage a speaker is using, and ideally this process would be automated. The\ntechnique described in this paper, language identification for audio\nspectrograms (LIFAS), uses spectrograms generated from audio signals as inputs\nto a convolutional neural network (CNN) to be used for language identification.\nLIFAS requires minimal pre-processing on the audio signals as the spectrograms\nare generated during each batch as they are input to the network during\ntraining.\n  LIFAS utilizes deep learning tools that are shown to be successful on image\nprocessing tasks and applies it to audio signal classification. LIFAS performs\nbinary language classification with an accuracy of 97\\%, and multi-class\nclassification with six languages at an accuracy of 89\\% on 3.75 second audio\nclips.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:15:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Revay", "Shauna", ""], ["Teschke", "Matthew", ""]]}, {"id": "1905.04351", "submitter": "Craig Michoski", "authors": "Craig Michoski, Milos Milosavljevic, Todd Oliver, David Hatch", "title": "Solving Irregular and Data-enriched Differential Equations using Deep\n  Neural Networks", "comments": "21 pages, 14 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has introduced a simple numerical method for solving partial\ndifferential equations (PDEs) with deep neural networks (DNNs). This paper\nreviews and extends the method while applying it to analyze one of the most\nfundamental features in numerical PDEs and nonlinear analysis: irregular\nsolutions. First, the Sod shock tube solution to compressible Euler equations\nis discussed, analyzed, and then compared to conventional finite element and\nfinite volume methods. These methods are extended to consider performance\nimprovements and simultaneous parameter space exploration. Next, a shock\nsolution to compressible magnetohydrodynamics (MHD) is solved for, and used in\na scenario where experimental data is utilized to enhance a PDE system that is\n\\emph{a priori} insufficient to validate against the observed/experimental\ndata. This is accomplished by enriching the model PDE system with source terms\nand using supervised training on synthetic experimental data. The resulting DNN\nframework for PDEs seems to demonstrate almost fantastical ease of system\nprototyping, natural integration of large data sets (be they synthetic or\nexperimental), all while simultaneously enabling single-pass exploration of the\nentire parameter space.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:25:53 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Michoski", "Craig", ""], ["Milosavljevic", "Milos", ""], ["Oliver", "Todd", ""], ["Hatch", "David", ""]]}, {"id": "1905.04363", "submitter": "Andrew Massimino", "authors": "Gregory H. Canal, Andrew K. Massimino, Mark A. Davenport, and\n  Christopher J. Rozell", "title": "Active embedding search via noisy paired comparisons", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we wish to estimate a user's preference vector $w$ from paired\ncomparisons of the form \"does user $w$ prefer item $p$ or item $q$?,\" where\nboth the user and items are embedded in a low-dimensional Euclidean space with\ndistances that reflect user and item similarities. Such observations arise in\nnumerous settings, including psychometrics and psychology experiments, search\ntasks, advertising, and recommender systems. In such tasks, queries can be\nextremely costly and subject to varying levels of response noise; thus, we aim\nto actively choose pairs that are most informative given the results of\nprevious comparisons. We provide new theoretical insights into the benefits and\nchallenges of greedy information maximization in this setting, and develop two\nnovel strategies that maximize lower bounds on information gain and are simpler\nto analyze and compute respectively. We use simulated responses from a\nreal-world dataset to validate our strategies through their similar performance\nto greedy information maximization, and their superior preference estimation\nover state-of-the-art selection methods as well as random queries.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:55:50 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:25:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Canal", "Gregory H.", ""], ["Massimino", "Andrew K.", ""], ["Davenport", "Mark A.", ""], ["Rozell", "Christopher J.", ""]]}, {"id": "1905.04368", "submitter": "Chee Seng Chan", "authors": "Lixin Fan and KamWoh Ng and Chee Seng Chan", "title": "Digital Passport: A Novel Technological Strategy for Intellectual\n  Property Protection of Convolutional Neural Networks", "comments": "This paper proposes a new timely IPR solution that embed digital\n  passports into CNN models to prevent the unauthorized network usage (i.e.\n  infringement) by paralyzing the networks while maintaining its functionality\n  for verified users", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to prevent deep neural networks from being infringed by unauthorized\nparties, we propose a generic solution which embeds a designated digital\npassport into a network, and subsequently, either paralyzes the network\nfunctionalities for unauthorized usages or maintain its functionalities in the\npresence of a verified passport. Such a desired network behavior is\nsuccessfully demonstrated in a number of implementation schemes, which provide\nreliable, preventive and timely protections against tens of thousands of\nfake-passport deceptions. Extensive experiments also show that the deep neural\nnetwork performance under unauthorized usages deteriorate significantly (e.g.\nwith 33% to 82% reductions of CIFAR10 classification accuracies), while\nnetworks endorsed with valid passports remain intact.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 20:13:38 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Fan", "Lixin", ""], ["Ng", "KamWoh", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1905.04374", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi and Rachid Guerraoui and S\\'ebastien Rouault", "title": "Fast and Robust Distributed Learning in High Dimension", "comments": "preliminary theoretical draft, complements the SysML 2019 practical\n  paper of which the code is provided at\n  https://github.com/LPD-EPFL/AggregaThor. arXiv admin note: text overlap with\n  arXiv:1703.02757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Could a gradient aggregation rule (GAR) for distributed machine learning be\nboth robust and fast? This paper answers by the affirmative through\nmulti-Bulyan. Given $n$ workers, $f$ of which are arbitrary malicious\n(Byzantine) and $m=n-f$ are not, we prove that multi-Bulyan can ensure a strong\nform of Byzantine resilience, as well as an ${\\frac{m}{n}}$ slowdown, compared\nto averaging, the fastest (but non Byzantine resilient) rule for distributed\nmachine learning. When $m \\approx n$ (almost all workers are correct),\nmulti-Bulyan reaches the speed of averaging. We also prove that multi-Bulyan's\ncost in local computation is $O(d)$ (like averaging), an important feature for\nML where $d$ commonly reaches $10^9$, while robust alternatives have at least\nquadratic cost in $d$.\n  Our theoretical findings are complemented with an experimental evaluation\nwhich, in addition to supporting the linear $O(d)$ complexity argument, conveys\nthe fact that multi-Bulyan's parallelisability further adds to its efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:41:25 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:44:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1905.04384", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali and Jens Rittscher", "title": "Efficient video indexing for monitoring disease activity and progression\n  in the upper gastrointestinal tract", "comments": "Accepted at IEEE International Symposium on Biomedical Imaging\n  (ISBI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Endoscopy is a routine imaging technique used for both diagnosis and\nminimally invasive surgical treatment. While the endoscopy video contains a\nwealth of information, tools to capture this information for the purpose of\nclinical reporting are rather poor. In date, endoscopists do not have any\naccess to tools that enable them to browse the video data in an efficient and\nuser friendly manner. Fast and reliable video retrieval methods could for\nexample, allow them to review data from previous exams and therefore improve\ntheir ability to monitor disease progression. Deep learning provides new\navenues of compressing and indexing video in an extremely efficient manner. In\nthis study, we propose to use an autoencoder for efficient video compression\nand fast retrieval of video images. To boost the accuracy of video image\nretrieval and to address data variability like multi-modality and view-point\nchanges, we propose the integration of a Siamese network. We demonstrate that\nour approach is competitive in retrieving images from 3 large scale videos of 3\ndifferent patients obtained against the query samples of their previous\ndiagnosis. Quantitative validation shows that the combined approach yield an\noverall improvement of 5% and 8% over classical and variational autoencoders,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 21:31:11 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ali", "Sharib", ""], ["Rittscher", "Jens", ""]]}, {"id": "1905.04385", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali, Nasullah Khalid Alham, Clare Verrill, Jens Rittscher", "title": "Ink removal from histopathology whole slide images by combining\n  classification, detection and image generation models", "comments": "Accepted paper at IEEE International Symposium on Biomedical Imaging\n  (ISBI) 2019, Venice, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Histopathology slides are routinely marked by pathologists using permanent\nink markers that should not be removed as they form part of the medical record.\nOften tumour regions are marked up for the purpose of highlighting features or\nother downstream processing such an gene sequencing. Once digitised there is no\nestablished method for removing this information from the whole slide images\nlimiting its usability in research and study. Removal of marker ink from these\nhigh-resolution whole slide images is non-trivial and complex problem as they\ncontaminate different regions and in an inconsistent manner. We propose an\nefficient pipeline using convolution neural networks that results in ink-free\nimages without compromising information and image resolution. Our pipeline\nincludes a sequential classical convolution neural network for accurate\nclassification of contaminated image tiles, a fast region detector and a domain\nadaptive cycle consistent adversarial generative model for restoration of\nforeground pixels. Both quantitative and qualitative results on four different\nwhole slide images show that our approach yields visually coherent ink-free\nwhole slide images.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 21:33:12 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ali", "Sharib", ""], ["Alham", "Nasullah Khalid", ""], ["Verrill", "Clare", ""], ["Rittscher", "Jens", ""]]}, {"id": "1905.04388", "submitter": "Craig Bester", "authors": "Craig J. Bester, Steven D. James, George D. Konidaris", "title": "Multi-Pass Q-Networks for Deep Reinforcement Learning with Parameterised\n  Action Spaces", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterised actions in reinforcement learning are composed of discrete\nactions with continuous action-parameters. This provides a framework for\nsolving complex domains that require combining high-level actions with flexible\ncontrol. The recent P-DQN algorithm extends deep Q-networks to learn over such\naction spaces. However, it treats all action-parameters as a single joint input\nto the Q-network, invalidating its theoretical foundations. We analyse the\nissues with this approach and propose a novel method, multi-pass deep\nQ-networks, or MP-DQN, to address them. We empirically demonstrate that MP-DQN\nsignificantly outperforms P-DQN and other previous algorithms in terms of data\nefficiency and converged policy performance on the Platform, Robot Soccer Goal,\nand Half Field Offense domains.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 21:57:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bester", "Craig J.", ""], ["James", "Steven D.", ""], ["Konidaris", "George D.", ""]]}, {"id": "1905.04392", "submitter": "Mohsen Joneidi", "authors": "Mohsen Joneidi, Ismail Alkhouri, Nazanin Rahnavard", "title": "Large-Scale Spectrum Occupancy Learning via Tensor Decomposition and\n  LSTM Networks", "comments": "Submitted to the 2019 IEEE Global Communications Conference\n  (GLOBECOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new paradigm for large-scale spectrum occupancy learning based on long\nshort-term memory (LSTM) recurrent neural networks is proposed. Studies have\nshown that spectrum usage is a highly correlated time series. Moreover, there\nis a correlation for occupancy of spectrum between different frequency\nchannels. Therefore, revealing all these correlations using learning and\nprediction of one-dimensional time series is not a trivial task. In this paper,\nwe introduce a new framework for representing the spectrum measurements in a\ntensor format. Next, a time-series prediction method based on CANDECOMP/PARFAC\n(CP) tensor decomposition and LSTM recurrent neural networks is proposed. The\nproposed method is computationally efficient and is able to capture different\ntypes of correlation within the measured spectrum. Moreover, it is robust\nagainst noise and missing entries of sensed spectrum. The superiority of the\nproposed method is evaluated over a large-scale synthetic dataset in terms of\nprediction accuracy and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 22:22:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Joneidi", "Mohsen", ""], ["Alkhouri", "Ismail", ""], ["Rahnavard", "Nazanin", ""]]}, {"id": "1905.04394", "submitter": "Muhammad Aminul Islam", "authors": "Muhammad Aminul Islam, Derek T. Anderson, Anthony J. Pinar, Timothy C.\n  Havens, Grant Scott, James M. Keller", "title": "Enabling Explainable Fusion in Deep Learning with Fuzzy Integral Neural\n  Networks", "comments": "IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2019.2917124", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information fusion is an essential part of numerous engineering systems and\nbiological functions, e.g., human cognition. Fusion occurs at many levels,\nranging from the low-level combination of signals to the high-level aggregation\nof heterogeneous decision-making processes. While the last decade has witnessed\nan explosion of research in deep learning, fusion in neural networks has not\nobserved the same revolution. Specifically, most neural fusion approaches are\nad hoc, are not understood, are distributed versus localized, and/or\nexplainability is low (if present at all). Herein, we prove that the fuzzy\nChoquet integral (ChI), a powerful nonlinear aggregation function, can be\nrepresented as a multi-layer network, referred to hereafter as ChIMP. We also\nput forth an improved ChIMP (iChIMP) that leads to a stochastic gradient\ndescent-based optimization in light of the exponential number of ChI inequality\nconstraints. An additional benefit of ChIMP/iChIMP is that it enables\neXplainable AI (XAI). Synthetic validation experiments are provided and iChIMP\nis applied to the fusion of a set of heterogeneous architecture deep models in\nremote sensing. We show an improvement in model accuracy and our previously\nestablished XAI indices shed light on the quality of our data, model, and its\ndecisions.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 22:31:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Islam", "Muhammad Aminul", ""], ["Anderson", "Derek T.", ""], ["Pinar", "Anthony J.", ""], ["Havens", "Timothy C.", ""], ["Scott", "Grant", ""], ["Keller", "James M.", ""]]}, {"id": "1905.04398", "submitter": "Avinash Ravichandran", "authors": "Avinash Ravichandran, Rahul Bhotika, Stefano Soatto", "title": "Few-Shot Learning with Embedded Class Models and Shot-Free Meta Training", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning embeddings for few-shot learning that is\nsuitable for use with any number of ways and any number of shots (shot-free).\nRather than fixing the class prototypes to be the Euclidean average of sample\nembeddings, we allow them to live in a higher-dimensional space (embedded class\nmodels) and learn the prototypes along with the model parameters. The class\nrepresentation function is defined implicitly, which allows us to deal with a\nvariable number of shots per each class with a simple constant-size\narchitecture. The class embedding encompasses metric learning, that facilitates\nadding new classes without crowding the class representation space. Despite\nbeing general and not tuned to the benchmark, our approach achieves\nstate-of-the-art performance on the standard few-shot benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 23:21:31 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 18:15:58 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.04403", "submitter": "Maximilian Weininger", "authors": "Pranav Ashok, Jan K\\v{r}et\\'insk\\'y and Maximilian Weininger", "title": "PAC Statistical Model Checking for Markov Decision Processes and\n  Stochastic Games", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-25540-4_29", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical model checking (SMC) is a technique for analysis of probabilistic\nsystems that may be (partially) unknown. We present an SMC algorithm for\n(unbounded) reachability yielding probably approximately correct (PAC)\nguarantees on the results. We consider both the setting (i) with no knowledge\nof the transition function (with the only quantity required a bound on the\nminimum transition probability) and (ii) with knowledge of the topology of the\nunderlying graph. On the one hand, it is the first algorithm for stochastic\ngames. On the other hand, it is the first practical algorithm even for Markov\ndecision processes. Compared to previous approaches where PAC guarantees\nrequire running times longer than the age of universe even for systems with a\nhandful of states, our algorithm often yields reasonably precise results within\nminutes, not requiring the knowledge of mixing time or the topology of the\nwhole model.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 23:36:05 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 11:15:44 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 15:00:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ashok", "Pranav", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weininger", "Maximilian", ""]]}, {"id": "1905.04411", "submitter": "Angelina Wang", "authors": "Angelina Wang, Thanard Kurutach, Kara Liu, Pieter Abbeel, Aviv Tamar", "title": "Learning Robotic Manipulation through Visual Planning and Acting", "comments": "RSS 2019. Website at https://sites.google.com/berkeley.edu/vpa/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for robotic manipulation requires reasoning about the changes a\nrobot can affect on objects. When such interactions can be modelled\nanalytically, as in domains with rigid objects, efficient planning algorithms\nexist. However, in both domestic and industrial domains, the objects of\ninterest can be soft, or deformable, and hard to model analytically. For such\ncases, we posit that a data-driven modelling approach is more suitable. In\nrecent years, progress in deep generative models has produced methods that\nlearn to `imagine' plausible images from data. Building on the recent Causal\nInfoGAN generative model, in this work we learn to imagine goal-directed object\nmanipulation directly from raw image data of self-supervised interaction of the\nrobot with the object. After learning, given a goal observation of the system,\nour model can generate an imagined plan -- a sequence of images that transition\nthe object into the desired goal. To execute the plan, we use it as a reference\ntrajectory to track with a visual servoing controller, which we also learn from\nthe data as an inverse dynamics model. In a simulated manipulation task, we\nshow that separating the problem into visual planning and visual tracking\ncontrol is more sample efficient and more interpretable than alternative\ndata-driven approaches. We further demonstrate our approach on learning to\nimagine and execute in 3 environments, the final of which is deformable rope\nmanipulation on a PR2 robot.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:30:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Angelina", ""], ["Kurutach", "Thanard", ""], ["Liu", "Kara", ""], ["Abbeel", "Pieter", ""], ["Tamar", "Aviv", ""]]}, {"id": "1905.04413", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao,\n  Wenjie Li, Zhongyuan Wang", "title": "Knowledge-aware Graph Neural Networks with Label Smoothness\n  Regularization for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs capture structured information and relations between a set\nof entities or items. As such knowledge graphs represent an attractive source\nof information that could help improve recommender systems. However, existing\napproaches in this domain rely on manual feature engineering and do not allow\nfor an end-to-end training. Here we propose Knowledge-aware Graph Neural\nNetworks with Label Smoothness regularization (KGNN-LS) to provide better\nrecommendations. Conceptually, our approach computes user-specific item\nembeddings by first applying a trainable function that identifies important\nknowledge graph relationships for a given user. This way we transform the\nknowledge graph into a user-specific weighted graph and then apply a graph\nneural network to compute personalized item embeddings. To provide better\ninductive bias, we rely on label smoothness assumption, which posits that\nadjacent items in the knowledge graph are likely to have similar user relevance\nlabels/scores. Label smoothness provides regularization over the edge weights\nand we prove that it is equivalent to a label propagation scheme on a graph. We\nalso develop an efficient implementation that shows strong scalability with\nrespect to the knowledge graph size. Experiments on four datasets show that our\nmethod outperforms state of the art baselines. KGNN-LS also achieves strong\nperformance in cold-start scenarios where user-item interactions are sparse.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:43:54 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 05:27:40 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 00:25:25 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Zhang", "Mengdi", ""], ["Leskovec", "Jure", ""], ["Zhao", "Miao", ""], ["Li", "Wenjie", ""], ["Wang", "Zhongyuan", ""]]}, {"id": "1905.04418", "submitter": "Michael Bianco", "authors": "Michael J. Bianco, Peter Gerstoft, James Traer, Emma Ozanich, Marie A.\n  Roch, Sharon Gannot, Charles-Alban Deledalle", "title": "Machine learning in acoustics: theory and applications", "comments": "Published with free access in Journal of the Acoustical Society of\n  America, 27 Nov. 2019", "journal-ref": "Journal of the Acoustical Society of America, 146(5)\n  pp.3590--3628, 2019", "doi": "10.1121/1.5133944", "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic data provide scientific and engineering insights in fields ranging\nfrom biology and communications to ocean and Earth science. We survey the\nrecent advances and transformative potential of machine learning (ML),\nincluding deep learning, in the field of acoustics. ML is a broad family of\ntechniques, which are often based in statistics, for automatically detecting\nand utilizing patterns in data. Relative to conventional acoustics and signal\nprocessing, ML is data-driven. Given sufficient training data, ML can discover\ncomplex relationships between features and desired labels or actions, or\nbetween features themselves. With large volumes of training data, ML can\ndiscover models describing complex acoustic phenomena such as human speech and\nreverberation. ML in acoustics is rapidly developing with compelling results\nand significant future promise. We first introduce ML, then highlight ML\ndevelopments in four acoustics research areas: source localization in speech\nprocessing, source localization in ocean acoustics, bioacoustics, and\nenvironmental sounds in everyday scenes.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 01:14:55 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 07:01:07 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 23:16:16 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 08:01:49 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bianco", "Michael J.", ""], ["Gerstoft", "Peter", ""], ["Traer", "James", ""], ["Ozanich", "Emma", ""], ["Roch", "Marie A.", ""], ["Gannot", "Sharon", ""], ["Deledalle", "Charles-Alban", ""]]}, {"id": "1905.04423", "submitter": "Lizhong Chen", "authors": "Ting-Ru Lin, Drew Penney, Massoud Pedram, Lizhong Chen", "title": "Optimizing Routerless Network-on-Chip Designs: An Innovative\n  Learning-Based Framework", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applied to architecture design presents a promising\nopportunity with broad applications. Recent deep reinforcement learning (DRL)\ntechniques, in particular, enable efficient exploration in vast design spaces\nwhere conventional design strategies may be inadequate. This paper proposes a\nnovel deep reinforcement framework, taking routerless networks-on-chip (NoC) as\nan evaluation case study. The new framework successfully resolves problems with\nprior design approaches being either unreliable due to random searches or\ninflexible due to severe design space restrictions. The framework learns\n(near-)optimal loop placement for routerless NoCs with various design\nconstraints. A deep neural network is developed using parallel threads that\nefficiently explore the immense routerless NoC design space with a Monte Carlo\nsearch tree. Experimental results show that, compared with conventional mesh,\nthe proposed deep reinforcement learning (DRL) routerless design achieves a\n3.25x increase in throughput, 1.6x reduction in packet latency, and 5x\nreduction in power. Compared with the state-of-the-art routerless NoC, DRL\nachieves a 1.47x increase in throughput, 1.18x reduction in packet latency, and\n1.14x reduction in average hop count albeit with slightly more power overhead.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:15:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lin", "Ting-Ru", ""], ["Penney", "Drew", ""], ["Pedram", "Massoud", ""], ["Chen", "Lizhong", ""]]}, {"id": "1905.04424", "submitter": "Songsong Wu", "authors": "Songsong Wu, Yan Yan, Hao Tang, Jianjun Qian, Jian Zhang, Xiao-Yuan\n  Jing", "title": "Structured Discriminative Tensor Dictionary Learning for Unsupervised\n  Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) addresses the problem of performance\ndegradation due to domain shift between training and testing sets, which is\ncommon in computer vision applications. Most existing UDA approaches are based\non vector-form data although the typical format of data or features in visual\napplications is multi-dimensional tensor. Besides, current methods, including\nthe deep network approaches, assume that abundant labeled source samples are\nprovided for training. However, the number of labeled source samples are always\nlimited due to expensive annotation cost in practice, making sub-optimal\nperformance been observed. In this paper, we propose to seek discriminative\nrepresentation for multi-dimensional data by learning a structured dictionary\nin tensor space. The dictionary separates domain-specific information and\nclass-specific information to guarantee the representation robust to domains.\nIn addition, a pseudo-label estimation scheme is developed to combine with\ndiscriminant analysis in the algorithm iteration for avoiding the external\nclassifier design. We perform extensive results on different datasets with\nlimited source samples. Experimental results demonstrates that the proposed\nmethod outperforms the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:28:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wu", "Songsong", ""], ["Yan", "Yan", ""], ["Tang", "Hao", ""], ["Qian", "Jianjun", ""], ["Zhang", "Jian", ""], ["Jing", "Xiao-Yuan", ""]]}, {"id": "1905.04430", "submitter": "Mohammad Mahdi Kazemi Moghaddam", "authors": "Mohammad Mahdi Kazemi Moghaddam, Ehsan Abbasnejad and Javen Shi", "title": "Follow the Attention: Combining Partial Pose and Object Motion for\n  Fine-Grained Action Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retailers have long been searching for ways to effectively understand their\ncustomers' behaviour in order to provide a smooth and pleasant shopping\nexperience that attracts more customers everyday and maximises their revenue,\nconsequently. Humans can flawlessly understand others' behaviour by combining\ndifferent visual cues from activity to gestures and facial expressions.\nEmpowering the computer vision systems to do so, however, is still an open\nproblem due to its intrinsic challenges as well as extrinsic enforced\ndifficulties like lack of publicly available data and unique environment\nconditions (wild). In this work, We emphasise on detecting the first and by far\nthe most crucial cue in behaviour analysis; that is human activity detection in\ncomputer vision. To do so, we introduce a framework for integrating human pose\nand object motion to both temporally detect and classify the activities in a\nfine-grained manner (very short and similar activities). We incorporate partial\nhuman pose and interaction with the objects in a multi-stream neural network\narchitecture to guide the spatiotemporal attention mechanism for more efficient\nactivity recognition. To this end, in the absence of pose supervision, we\npropose to use the Generative Adversarial Network (GAN) to generate exact joint\nlocations from noisy probability heat maps. Additionally, based on the\nintuition that complex actions demand more than one source of information to be\nidentified even by humans, we integrate the second stream of object motion to\nour network as a prior knowledge that we quantitatively show improves the\nrecognition results. We empirically show the capability of our approach by\nachieving state-of-the-art results on MERL shopping dataset. We further\ninvestigate the effectiveness of this approach on a new shopping dataset that\nwe have collected to address existing shortcomings.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 02:54:01 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 04:44:58 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Moghaddam", "Mohammad Mahdi Kazemi", ""], ["Abbasnejad", "Ehsan", ""], ["Shi", "Javen", ""]]}, {"id": "1905.04442", "submitter": "Wei Cui", "authors": "Zihan Wang, Yaoguang Li, and Wei Cui", "title": "ECG Identification under Exercise and Rest Situations via Various\n  Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the advancement of information security, human recognition as its core\ntechnology, has absorbed an increasing amount of attention in the past few\nyears. A myriad of biometric features including fingerprint, face, iris, have\nbeen applied to security systems, which are occasionally considered vulnerable\nto forgery and spoofing attacks. Due to the difficulty of being fabricated,\nelectrocardiogram (ECG) has attracted much attention. Though many works have\nshown the excellent human identification provided by ECG, most current ECG\nhuman identification (ECGID) researches only focus on rest situation. In this\nmanuscript, we overcome the oversimplification of previous researches and\nevaluate the performance under both exercise and rest situations, especially\nthe influence of exercise on ECGID. By applying various existing learning\nmethods to our ECG dataset, we find that current methods which can well support\nthe identification of individuals under rests, do not suffice to present\nsatisfying ECGID performance under exercise situations, therefore exposing the\ndeficiency of existing ECG identification methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 04:07:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Zihan", ""], ["Li", "Yaoguang", ""], ["Cui", "Wei", ""]]}, {"id": "1905.04446", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Vinay Kumar Verma, Piyush Rai, Vinay P. Namboodiri", "title": "Play and Prune: Adaptive Filter Pruning for Deep Model Compression", "comments": "International Joint Conference on Artificial Intelligence\n  (IJCAI-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While convolutional neural networks (CNN) have achieved impressive\nperformance on various classification/recognition tasks, they typically consist\nof a massive number of parameters. This results in significant memory\nrequirement as well as computational overheads. Consequently, there is a\ngrowing need for filter-level pruning approaches for compressing CNN based\nmodels that not only reduce the total number of parameters but reduce the\noverall computation as well. We present a new min-max framework for\nfilter-level pruning of CNNs. Our framework, called Play and Prune (PP),\njointly prunes and fine-tunes CNN model parameters, with an adaptive pruning\nrate, while maintaining the model's predictive performance. Our framework\nconsists of two modules: (1) An adaptive filter pruning (AFP) module, which\nminimizes the number of filters in the model; and (2) A pruning rate controller\n(PRC) module, which maximizes the accuracy during pruning. Moreover, unlike\nmost previous approaches, our approach allows directly specifying the desired\nerror tolerance instead of pruning level. Our compressed models can be deployed\nat run-time, without requiring any special libraries or hardware. Our approach\nreduces the number of parameters of VGG-16 by an impressive factor of 17.5X,\nand number of FLOPS by 6.43X, with no loss of accuracy, significantly\noutperforming other state-of-the-art filter pruning methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 04:37:10 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Singh", "Pravendra", ""], ["Verma", "Vinay Kumar", ""], ["Rai", "Piyush", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1905.04447", "submitter": "Zhao Song", "authors": "Yin Tat Lee, Zhao Song, Qiuyi Zhang", "title": "Solving Empirical Risk Minimization in the Current Matrix Multiplication\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many convex problems in machine learning and computer science share the same\nform: \\begin{align*} \\min_{x} \\sum_{i} f_i( A_i x + b_i), \\end{align*} where\n$f_i$ are convex functions on $\\mathbb{R}^{n_i}$ with constant $n_i$, $A_i \\in\n\\mathbb{R}^{n_i \\times d}$, $b_i \\in \\mathbb{R}^{n_i}$ and $\\sum_i n_i = n$.\nThis problem generalizes linear programming and includes many problems in\nempirical risk minimization. In this paper, we give an algorithm that runs in\ntime \\begin{align*} O^* ( ( n^{\\omega} + n^{2.5 - \\alpha/2} + n^{2+ 1/6} ) \\log\n(n / \\delta) ) \\end{align*} where $\\omega$ is the exponent of matrix\nmultiplication, $\\alpha$ is the dual exponent of matrix multiplication, and\n$\\delta$ is the relative accuracy. Note that the runtime has only a log\ndependence on the condition numbers or other data dependent parameters and\nthese are captured in $\\delta$. For the current bound $\\omega \\sim 2.38$\n[Vassilevska Williams'12, Le Gall'14] and $\\alpha \\sim 0.31$ [Le Gall,\nUrrutia'18], our runtime $O^* ( n^{\\omega} \\log (n / \\delta))$ matches the\ncurrent best for solving a dense least squares regression problem, a special\ncase of the problem we consider. Very recently, [Alman'18] proved that all the\ncurrent known techniques can not give a better $\\omega$ below $2.168$ which is\nlarger than our $2+1/6$. Our result generalizes the very recent result of\nsolving linear programs in the current matrix multiplication time [Cohen, Lee,\nSong'19] to a more broad class of problems. Our algorithm proposes two concepts\nwhich are different from [Cohen, Lee, Song'19] :\n  $\\bullet$ We give a robust deterministic central path method, whereas the\nprevious one is a stochastic central path which updates weights by a random\nsparse vector.\n  $\\bullet$ We propose an efficient data-structure to maintain the central path\nof interior point methods even when the weights update vector is dense.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 04:42:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lee", "Yin Tat", ""], ["Song", "Zhao", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "1905.04450", "submitter": "Guoxian Yu", "authors": "Xuanwu Liu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Yazhou Ren,\n  Maozu Guo", "title": "Ranking-based Deep Cross-modal Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal hashing has been receiving increasing interests for its low\nstorage cost and fast query speed in multi-modal data retrievals. However, most\nexisting hashing methods are based on hand-crafted or raw level features of\nobjects, which may not be optimally compatible with the coding process.\nBesides, these hashing methods are mainly designed to handle simple pairwise\nsimilarity. The complex multilevel ranking semantic structure of instances\nassociated with multiple labels has not been well explored yet. In this paper,\nwe propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH\nfirstly uses the feature and label information of data to derive a\nsemi-supervised semantic ranking list. Next, to expand the semantic\nrepresentation power of hand-crafted features, RDCMH integrates the semantic\nranking information into deep cross-modal hashing and jointly optimizes the\ncompatible parameters of deep feature representations and of hashing functions.\nExperiments on real multi-modal datasets show that RDCMH outperforms other\ncompetitive baselines and achieves the state-of-the-art performance in\ncross-modal retrieval applications.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 05:13:06 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Liu", "Xuanwu", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Wang", "Jun", ""], ["Ren", "Yazhou", ""], ["Guo", "Maozu", ""]]}, {"id": "1905.04453", "submitter": "Sudeep Pillai", "authors": "Sudeep Pillai and John Leonard", "title": "Self-Supervised Visual Place Recognition Learning in Mobile Robots", "comments": "Presented at Learning for Localization and Mapping Workshop at IROS\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place recognition is a critical component in robot navigation that enables it\nto re-establish previously visited locations, and simultaneously use this\ninformation to correct the drift incurred in its dead-reckoned estimate. In\nthis work, we develop a self-supervised approach to place recognition in\nrobots. The task of visual loop-closure identification is cast as a metric\nlearning problem, where the labels for positive and negative examples of\nloop-closures can be bootstrapped using a GPS-aided navigation solution that\nthe robot already uses. By leveraging the synchronization between sensors, we\nshow that we are able to learn an appropriate distance metric for arbitrary\nreal-valued image descriptors (including state-of-the-art CNN models), that is\nspecifically geared for visual place recognition in mobile robots. Furthermore,\nwe show that the newly learned embedding can be particularly powerful in\ndisambiguating visual scenes for the task of vision-based loop-closure\nidentification in mobile robots.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 05:49:36 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Pillai", "Sudeep", ""], ["Leonard", "John", ""]]}, {"id": "1905.04454", "submitter": "Mingbao Lin", "authors": "Mingbao Lin, Rongrong Ji, Hong Liu, Xiaoshuai Sun, Shen Chen, Qi Tian", "title": "Hadamard Matrix Guided Online Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online image hashing has attracted increasing research attention recently,\nwhich receives large-scale data in a streaming manner to update the hash\nfunctions on-the-fly. Its key challenge lies in the difficulty of balancing the\nlearning timeliness and model accuracy. To this end, most works follow a\nsupervised setting, i.e., using class labels to boost the hashing performance,\nwhich defects in two aspects: First, strong constraints, e.g., orthogonal or\nsimilarity preserving, are used, which however are typically relaxed and lead\nto large accuracy drop. Second, large amounts of training batches are required\nto learn the up-to-date hash functions, which largely increase the learning\ncomplexity. To handle the above challenges, a novel supervised online hashing\nscheme termed Hadamard Matrix Guided Online Hashing (HMOH) is proposed in this\npaper. Our key innovation lies in introducing Hadamard matrix, which is an\northogonal binary matrix built via Sylvester method. In particular, to release\nthe need of strong constraints, we regard each column of Hadamard matrix as the\ntarget code for each class label, which by nature satisfies several desired\nproperties of hashing codes. To accelerate the online training, LSH is first\nadopted to align the lengths of target code and to-be-learned binary code. We\nthen treat the learning of hash functions as a set of binary classification\nproblems to fit the assigned target code. Finally, extensive experiments\ndemonstrate the superior accuracy and efficiency of the proposed method over\nvarious state-of-the-art methods. Codes are available at\nhttps://github.com/lmbxmu/mycode.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 05:53:31 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 09:44:17 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 14:31:52 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Lin", "Mingbao", ""], ["Ji", "Rongrong", ""], ["Liu", "Hong", ""], ["Sun", "Xiaoshuai", ""], ["Chen", "Shen", ""], ["Tian", "Qi", ""]]}, {"id": "1905.04457", "submitter": "Yushu Feng", "authors": "Yushu Feng, Huan Wang, Daniel T. Yi, Roland Hu", "title": "Triplet Distillation for Deep Face Recognition", "comments": "5 pages, 2 tables, accpeted by ICML 2019 ODML-CDNNR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved a great success in face\nrecognition, which unfortunately comes at the cost of massive computation and\nstorage consumption. Many compact face recognition networks are thus proposed\nto resolve this problem. Triplet loss is effective to further improve the\nperformance of those compact models. However, it normally employs a fixed\nmargin to all the samples, which neglects the informative similarity structures\nbetween different identities. In this paper, we propose an enhanced version of\ntriplet loss, named triplet distillation, which exploits the capability of a\nteacher model to transfer the similarity information to a small model by\nadaptively varying the margin between positive and negative pairs. Experiments\non LFW, AgeDB, and CPLFW datasets show the merits of our method compared to the\noriginal triplet loss.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:23:51 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 14:13:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Feng", "Yushu", ""], ["Wang", "Huan", ""], ["Yi", "Daniel T.", ""], ["Hu", "Roland", ""]]}, {"id": "1905.04467", "submitter": "Alfred Sch\\\"ottl", "authors": "Fabian Truetsch, Alfred Sch\\\"ottl", "title": "Monocular Depth Estimation with Directional Consistency by Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As processing power has become more available, more human-like artificial\nintelligences are created to solve image processing tasks that we are\ninherently good at. As such we propose a model that estimates depth from a\nmonocular image. Our approach utilizes a combination of structure from motion\nand stereo disparity. We estimate a pose between the source image and a\ndifferent viewpoint and a dense depth map and use a simple transformation to\nreconstruct the image seen from said viewpoint. We can then use the real image\nat that viewpoint to act as supervision to train out model. The metric chosen\nfor image comparison employs standard L1 and structural similarity and a\nconsistency constraint between depth maps as well as smoothness constraint. We\nshow that similar to human perception utilizing the correlation within the\nprovided data by two different approaches increases the accuracy and\noutperforms the individual components.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 07:13:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Truetsch", "Fabian", ""], ["Sch\u00f6ttl", "Alfred", ""]]}, {"id": "1905.04497", "submitter": "Fernando Gama", "authors": "Fernando Gama, Joan Bruna, Alejandro Ribeiro", "title": "Stability Properties of Graph Neural Networks", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3026980", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged as a powerful tool for nonlinear\nprocessing of graph signals, exhibiting success in recommender systems, power\noutage prediction, and motion planning, among others. GNNs consists of a\ncascade of layers, each of which applies a graph convolution, followed by a\npointwise nonlinearity. In this work, we study the impact that changes in the\nunderlying topology have on the output of the GNN. First, we show that GNNs are\npermutation equivariant, which implies that they effectively exploit internal\nsymmetries of the underlying topology. Then, we prove that graph convolutions\nwith integral Lipschitz filters, in combination with the frequency mixing\neffect of the corresponding nonlinearities, yields an architecture that is both\nstable to small changes in the underlying topology and discriminative of\ninformation located at high frequencies. These are two properties that cannot\nsimultaneously hold when using only linear graph filters, which are either\ndiscriminative or stable, thus explaining the superior performance of GNNs.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 10:38:47 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 23:41:46 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 18:29:34 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 17:05:18 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 16:59:01 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Gama", "Fernando", ""], ["Bruna", "Joan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1905.04502", "submitter": "Creighton Heaukulani", "authors": "Onno Kampman, Creighton Heaukulani", "title": "Variational inference for neural network matrix factorization and its\n  application to stochastic blockmodeling", "comments": "In proceedings of the 2019 ICML Workshop on Learning and Reasoning\n  with Graph-Structured Representations, Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the probabilistic analogue to neural network matrix factorization\n(Dziugaite & Roy, 2015), which we construct with Bayesian neural networks and\nfit with variational inference. We find that a linear model fit with\nvariational inference can attain equivalent predictive performance to the\nregular neural network variants on the Movielens data sets. We discuss the\nimplications of this result, which include some suggestions on the pros and\ncons of using the neural network construction, as well as the variational\napproach to inference. Such a probabilistic approach is required, however, when\nconsidering the important class of stochastic block models. We describe a\nvariational inference algorithm for a neural network matrix factorization model\nwith nonparametric block structure and evaluate its performance on the NIPS\nco-authorship data set.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:24:51 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 17:22:32 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2019 08:11:46 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Kampman", "Onno", ""], ["Heaukulani", "Creighton", ""]]}, {"id": "1905.04505", "submitter": "Suhansanu Kumar", "authors": "Suhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin\n  Chen-Chuan Chang", "title": "Mining Hidden Populations through Attributed Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers often query online social platforms through their application\nprogramming interfaces (API) to find target populations such as people with\nmental illness~\\cite{De-Choudhury2017} and jazz\nmusicians~\\cite{heckathorn2001finding}. Entities of such target population\nsatisfy a property that is typically identified using an oracle (human or a\npre-trained classifier). When the property of the target entities is not\ndirectly queryable via the API, we refer to the property as `hidden' and the\npopulation as a hidden population. Finding individuals who belong to these\npopulations on social networks is hard because they are non-queryable, and the\nsampler has to explore from a combinatorial query space within a finite budget\nlimit. By exploiting the correlation between queryable attributes and the\npopulation of interest and by hierarchically ordering the query space, we\npropose a Decision tree-based Thompson sampler (\\texttt{DT-TMP}) that\nefficiently discovers the right combination of attributes to query. Our\nproposed sampler outperforms the state-of-the-art samplers in online\nexperiments, for example by 54\\% on Twitter. When the number of matching\nentities to a query is known in offline experiments, \\texttt{DT-TMP} performs\nexceedingly well by a factor of 0.9-1.5$\\times$ over the baseline samplers. In\nthe future, we wish to explore the option of finding hidden populations by\nformulating more complex queries.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:36:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kumar", "Suhansanu", ""], ["Gao", "Heting", ""], ["Wang", "Changyu", ""], ["Sundaram", "Hari", ""], ["Chang", "Kevin Chen-Chuan", ""]]}, {"id": "1905.04509", "submitter": "Jongheon Jeong", "authors": "Jongheon Jeong and Jinwoo Shin", "title": "Training CNNs with Selective Allocation of Channels", "comments": "15 pages; Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep convolutional neural networks (CNNs) have enabled a\nsimple paradigm of architecture design: larger models typically achieve better\naccuracy. Due to this, in modern CNN architectures, it becomes more important\nto design models that generalize well under certain resource constraints, e.g.\nthe number of parameters. In this paper, we propose a simple way to improve the\ncapacity of any CNN model having large-scale features, without adding more\nparameters. In particular, we modify a standard convolutional layer to have a\nnew functionality of channel-selectivity, so that the layer is trained to\nselect important channels to re-distribute their parameters. Our experimental\nresults under various CNN architectures and datasets demonstrate that the\nproposed new convolutional layer allows new optima that generalize better via\nefficient resource utilization, compared to the baseline.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 12:00:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Jeong", "Jongheon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1905.04519", "submitter": "Guan Wang", "authors": "Guan Wang", "title": "Interpret Federated Learning with Shapley Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is introduced to protect privacy by distributing training\ndata into multiple parties. Each party trains its own model and a meta-model is\nconstructed from the sub models. In this way the details of the data are not\ndisclosed in between each party. In this paper we investigate the model\ninterpretation methods for Federated Learning, specifically on the measurement\nof feature importance of vertical Federated Learning where feature space of the\ndata is divided into two parties, namely host and guest. For host party to\ninterpret a single prediction of vertical Federated Learning model, the\ninterpretation results, namely the feature importance, are very likely to\nreveal the protected data from guest party. We propose a method to balance the\nmodel interpretability and data privacy in vertical Federated Learning by using\nShapley values to reveal detailed feature importance for host features and a\nunified importance value for federated guest features. Our experiments indicate\nrobust and informative results for interpreting Federated Learning models.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 12:59:36 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Guan", ""]]}, {"id": "1905.04522", "submitter": "Arijit Nandi", "authors": "Arijit Nandi, Nanda Dulal Jana", "title": "Accuracy Improvement of Neural Network Training using Particle Swarm\n  Optimization and its Stability Analysis for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised classification is the most active and emerging research trends in\ntoday's scenario. In this view, Artificial Neural Network (ANN) techniques have\nbeen widely employed and growing interest to the researchers day by day. ANN\ntraining aims to find the proper setting of parameters such as weights\n($\\textbf{W}$) and biases ($b$) to properly classify the given data samples.\nThe training process is formulated in an error minimization problem which\nconsists of many local optima in the search landscape. In this paper, an\nenhanced Particle Swarm Optimization is proposed to minimize the error function\nfor classifying real-life data sets. A stability analysis is performed to\nestablish the efficiency of the proposed method for improving classification\naccuracy. The performance measurement such as confusion matrix, $F$-measure and\nconvergence graph indicates the significant improvement in the classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 13:08:50 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 04:51:50 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Nandi", "Arijit", ""], ["Jana", "Nanda Dulal", ""]]}, {"id": "1905.04532", "submitter": "James Bailey", "authors": "James P. Bailey, Georgios Piliouras", "title": "Fast and Furious Learning in Zero-Sum Games: Vanishing Regret with\n  Non-Vanishing Step Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show for the first time, to our knowledge, that it is possible to\nreconcile in online learning in zero-sum games two seemingly contradictory\nobjectives: vanishing time-average regret and non-vanishing step sizes. This\nphenomenon, that we coin ``fast and furious\" learning in games, sets a new\nbenchmark about what is possible both in max-min optimization as well as in\nmulti-agent systems. Our analysis does not depend on introducing a carefully\ntailored dynamic. Instead we focus on the most well studied online dynamic,\ngradient descent. Similarly, we focus on the simplest textbook class of games,\ntwo-agent two-strategy zero-sum games, such as Matching Pennies. Even for this\nsimplest of benchmarks the best known bound for total regret, prior to our\nwork, was the trivial one of $O(T)$, which is immediately applicable even to a\nnon-learning agent. Based on a tight understanding of the geometry of the\nnon-equilibrating trajectories in the dual space we prove a regret bound of\n$\\Theta(\\sqrt{T})$ matching the well known optimal bound for adaptive step\nsizes in the online setting. This guarantee holds for all fixed step-sizes\nwithout having to know the time horizon in advance and adapt the fixed\nstep-size accordingly. As a corollary, we establish that even with fixed\nlearning rates the time-average of mixed strategies, utilities converge to\ntheir exact Nash equilibrium values.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 14:34:24 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bailey", "James P.", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1905.04534", "submitter": "Fan Bao", "authors": "Fan Bao, Hang Su, Jun Zhu", "title": "Boosting Generative Models by Leveraging Cascaded Meta-Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are effective methods of modeling data. However, it is\nnot easy for a single generative model to faithfully capture the distributions\nof complex data such as images. In this paper, we propose an approach for\nboosting generative models, which cascades meta-models together to produce a\nstronger model. Any hidden variable meta-model (e.g., RBM and VAE) which\nsupports likelihood evaluation can be leveraged. We derive a decomposable\nvariational lower bound of the boosted model, which allows each meta-model to\nbe trained separately and greedily. Besides, our framework can be extended to\nsemi-supervised boosting, where the boosted model learns a joint distribution\nof data and labels. Finally, we combine our boosting framework with the\nmultiplicative boosting framework, which further improves the learning power of\ngenerative models.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 14:46:00 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bao", "Fan", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1905.04538", "submitter": "Wayne Wu", "authors": "Wayne Wu, Kaidi Cao, Cheng Li, Chen Qian, Chen Change Loy", "title": "Disentangling Content and Style via Unsupervised Geometry Distillation", "comments": "Accepted to ICLR 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to disentangle an object into two orthogonal spaces of\ncontent and style since each can influence the visual observation differently\nand unpredictably. It is rare for one to have access to a large number of data\nto help separate the influences. In this paper, we present a novel framework to\nlearn this disentangled representation in a completely unsupervised manner. We\naddress this problem in a two-branch Autoencoder framework. For the structural\ncontent branch, we project the latent factor into a soft structured point\ntensor and constrain it with losses derived from prior knowledge. This\nconstraint encourages the branch to distill geometry information. Another\nbranch learns the complementary style information. The two branches form an\neffective framework that can disentangle object's content-style representation\nwithout any human annotation. We evaluate our approach on four image datasets,\non which we demonstrate the superior disentanglement and visual analogy quality\nboth in synthesized and real-world data. We are able to generate\nphoto-realistic images with 256*256 resolution that are clearly disentangled in\ncontent and style.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 15:12:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wu", "Wayne", ""], ["Cao", "Kaidi", ""], ["Li", "Cheng", ""], ["Qian", "Chen", ""], ["Loy", "Chen Change", ""]]}, {"id": "1905.04545", "submitter": "Adriano Baldeschi", "authors": "Adriano Baldeschi, Raffaella Margutti, Adam Miller", "title": "Deep Learning: a new definition of artificial neuron with double weight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a subset of a broader family of machine learning methods\nbased on learning data representations. These models are inspired by human\nbiological nervous systems, even if there are various differences pertaining to\nthe structural and functional properties of biological brains. The elementary\nconstituents of deep learning models are neurons, which can be considered as\nfunctions that receive inputs and produce an output that is a weighted sum of\nthe inputs fed through an activation function. Several models of neurons were\nproposed in the course of the years that are all based on learnable parameters\ncalled weights. In this paper we present a new type of artificial neuron, the\ndouble-weight neuron,characterized by additional learnable weights that lead to\na more complex and accurate system. We tested a feed-forward and convolutional\nneural network consisting of double-weight neurons on the MNIST dataset, and we\ntested a convolution network on the CIFAR-10 dataset. For MNIST we find a\n$\\approx 4\\%$ and $\\approx 1\\%$ improved classification accuracy, respectively,\nwhen compared to a standard feed-forward and convolutional neural network built\nwith the same sets of hyperparameters. For CIFAR-10 we find a $\\approx 12\\%$\nimproved classification accuracy. We thus conclude that this novel artificial\nneuron can be considered as a valuable alternative to common ones.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 16:00:08 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 18:20:39 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Baldeschi", "Adriano", ""], ["Margutti", "Raffaella", ""], ["Miller", "Adam", ""]]}, {"id": "1905.04554", "submitter": "Achintya Sarkar", "authors": "Achintya kr. Sarkar, Zheng-Hua Tan, Hao Tang, Suwon Shon and James\n  Glass", "title": "Time-Contrastive Learning Based Deep Bottleneck Features for\n  Text-Dependent Speaker Verification", "comments": "Copyright (c) 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  2019", "doi": "10.1109/TASLP.2019.2915322", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a number of studies about extraction of bottleneck (BN) features\nfrom deep neural networks (DNNs)trained to discriminate speakers, pass-phrases\nand triphone states for improving the performance of text-dependent speaker\nverification (TD-SV). However, a moderate success has been achieved. A recent\nstudy [1] presented a time contrastive learning (TCL) concept to explore the\nnon-stationarity of brain signals for classification of brain states. Speech\nsignals have similar non-stationarity property, and TCL further has the\nadvantage of having no need for labeled data. We therefore present a TCL based\nBN feature extraction method. The method uniformly partitions each speech\nutterance in a training dataset into a predefined number of multi-frame\nsegments. Each segment in an utterance corresponds to one class, and class\nlabels are shared across utterances. DNNs are then trained to discriminate all\nspeech frames among the classes to exploit the temporal structure of speech. In\naddition, we propose a segment-based unsupervised clustering algorithm to\nre-assign class labels to the segments. TD-SV experiments were conducted on the\nRedDots challenge database. The TCL-DNNs were trained using speech data of\nfixed pass-phrases that were excluded from the TD-SV evaluation set, so the\nlearned features can be considered phrase-independent. We compare the\nperformance of the proposed TCL bottleneck (BN) feature with those of\nshort-time cepstral features and BN features extracted from DNNs discriminating\nspeakers, pass-phrases, speaker+pass-phrase, as well as monophones whose labels\nand boundaries are generated by three different automatic speech recognition\n(ASR) systems. Experimental results show that the proposed TCL-BN outperforms\ncepstral features and speaker+pass-phrase discriminant BN features, and its\nperformance is on par with those of ASR derived BN features. Moreover,....\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:20:19 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Sarkar", "Achintya kr.", ""], ["Tan", "Zheng-Hua", ""], ["Tang", "Hao", ""], ["Shon", "Suwon", ""], ["Glass", "James", ""]]}, {"id": "1905.04559", "submitter": "Arash Gholami Davoodi", "authors": "Arash Gholami Davoodi, Sean Chang, Hyun Gon Yoo, Anubhav Baweja, Mihir\n  Mongia and Hosein Mohimani", "title": "ForestDSH: A Universal Hash Design for Discrete Probability\n  Distributions", "comments": "45 pages,11 figures", "journal-ref": "DAMI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of classification of $M$ high\ndimensional queries $y^1,\\cdots,y^M\\in B^S$ to $N$ high dimensional classes\n$x^1,\\cdots,x^N\\in A^S$ where $A$ and $B$ are discrete alphabets and the\nprobabilistic model that relates data to the classes $P(x,y)$ is known. This\nproblem has applications in various fields including the database search\nproblem in mass spectrometry. The problem is analogous to the nearest neighbor\nsearch problem, where the goal is to find the data point in a database that is\nthe most similar to a query point. The state of the art method for solving an\napproximate version of the nearest neighbor search problem in high dimensions\nis locality sensitive hashing (LSH). LSH is based on designing hash functions\nthat map near points to the same buckets with a probability higher than random\n(far) points. To solve our high dimensional classification problem, we\nintroduce distribution sensitive hashes that map jointly generated pairs\n$(x,y)\\sim P$ to the same bucket with probability higher than random pairs\n$x\\sim P^A$ and $y\\sim P^B$, where $P^A$ and $P^B$ are the marginal probability\ndistributions of $P$. We design distribution sensitive hashes using a forest of\ndecision trees and we show that the complexity of search grows with\n$O(N^{\\lambda^*(P)})$ where $\\lambda^*(P)$ is expressed in an analytical form.\nWe further show that the proposed hashes perform faster than state of the art\napproximate nearest neighbor search methods for a range of probability\ndistributions, in both theory and simulations. Finally, we apply our method to\nthe spectral library search problem in mass spectrometry, and show that it is\nan order of magnitude faster than the state of the art methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:38:29 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:30:38 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Davoodi", "Arash Gholami", ""], ["Chang", "Sean", ""], ["Yoo", "Hyun Gon", ""], ["Baweja", "Anubhav", ""], ["Mongia", "Mihir", ""], ["Mohimani", "Hosein", ""]]}, {"id": "1905.04561", "submitter": "Angxiu Ni", "authors": "Angxiu Ni and Chaitanya Talnikar", "title": "Linear Range in Gradient Descent", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines linear range as the range of parameter perturbations which\nlead to approximately linear perturbations in the states of a network. We\ncompute linear range from the difference between actual perturbations in states\nand the tangent solution. Linear range is a new criterion for estimating the\neffectivenss of gradients and thus having many possible applications. In\nparticular, we propose that the optimal learning rate at the initial stages of\ntraining is such that parameter changes on all minibatches are within linear\nrange. We demonstrate our algorithm on two shallow neural networks and a\nResNet.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:50:11 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 04:51:39 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ni", "Angxiu", ""], ["Talnikar", "Chaitanya", ""]]}, {"id": "1905.04564", "submitter": "Amar Saini", "authors": "Amar Saini", "title": "PrivateJobMatch: A Privacy-Oriented Deferred Multi-Match Recommender\n  System for Stable Employment", "comments": "45 pages, 28 figures, RecSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination failure reduces match quality among employers and candidates in\nthe job market, resulting in a large number of unfilled positions and/or\nunstable, short-term employment. Centralized job search engines provide a\nplatform that connects directly employers with job-seekers. However, they\nrequire users to disclose a significant amount of personal data, i.e., build a\nuser profile, in order to provide meaningful recommendations. In this paper, we\npresent PrivateJobMatch -- a privacy-oriented deferred multi-match recommender\nsystem -- which generates stable pairings while requiring users to provide only\na partial ranking of their preferences. PrivateJobMatch explores a series of\nadaptations of the game-theoretic Gale-Shapley deferred-acceptance algorithm\nwhich combine the flexibility of decentralized markets with the intelligence of\ncentralized matching. We identify the shortcomings of the original algorithm\nwhen applied to a job market and propose novel solutions that rely on machine\nlearning techniques. Experimental results on real and synthetic data confirm\nthe benefits of the proposed algorithms across several quality measures. Over\nthe past year, we have implemented a PrivateJobMatch prototype and deployed it\nin an active job market economy. Using the gathered real-user preference data,\nwe find that the match-recommendations are superior to a typical decentralized\njob market---while requiring only a partial ranking of the user preferences.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:58:40 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Saini", "Amar", ""]]}, {"id": "1905.04579", "submitter": "Ting Chen", "authors": "Ting Chen, Song Bian, Yizhou Sun", "title": "Are Powerful Graph Neural Nets Necessary? A Dissection on Graph\n  Classification", "comments": "A shorter version titled \"Graph Feature Networks\" was accepted to\n  ICLR'19 RLGM workshop. code available at https://github.com/chentingpc/gfn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Nets (GNNs) have received increasing attentions, partially due\nto their superior performance in many node and graph classification tasks.\nHowever, there is a lack of understanding on what they are learning and how\nsophisticated the learned graph functions are. In this work, we propose a\ndissection of GNNs on graph classification into two parts: 1) the graph\nfiltering, where graph-based neighbor aggregations are performed, and 2) the\nset function, where a set of hidden node features are composed for prediction.\nTo study the importance of both parts, we propose to linearize them separately.\nWe first linearize the graph filtering function, resulting Graph Feature\nNetwork (GFN), which is a simple lightweight neural net defined on a\n\\textit{set} of graph augmented features. Further linearization of GFN's set\nfunction results in Graph Linear Network (GLN), which is a linear function.\nEmpirically we perform evaluations on common graph classification benchmarks.\nTo our surprise, we find that, despite the simplification, GFN could match or\nexceed the best accuracies produced by recently proposed GNNs (with a fraction\nof computation cost), while GLN underperforms significantly. Our results\ndemonstrate the importance of non-linear set function, and suggest that linear\ngraph filtering with non-linear set function is an efficient and powerful\nscheme for modeling existing graph classification benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 19:47:19 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 04:45:21 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 22:32:19 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Ting", ""], ["Bian", "Song", ""], ["Sun", "Yizhou", ""]]}, {"id": "1905.04590", "submitter": "Yang Zhang", "authors": "Yang Zhang", "title": "Language in Our Time: An Empirical Analysis of Hashtags", "comments": "WWW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashtags in online social networks have gained tremendous popularity during\nthe past five years. The resulting large quantity of data has provided a new\nlens into modern society. Previously, researchers mainly rely on data collected\nfrom Twitter to study either a certain type of hashtags or a certain property\nof hashtags. In this paper, we perform the first large-scale empirical analysis\nof hashtags shared on Instagram, the major platform for hashtag-sharing. We\nstudy hashtags from three different dimensions including the temporal-spatial\ndimension, the semantic dimension, and the social dimension. Extensive\nexperiments performed on three large-scale datasets with more than 7 million\nhashtags in total provide a series of interesting observations. First, we show\nthat the temporal patterns of hashtags can be categorized into four different\nclusters, and people tend to share fewer hashtags at certain places and more\nhashtags at others. Second, we observe that a non-negligible proportion of\nhashtags exhibit large semantic displacement. We demonstrate hashtags that are\nmore uniformly shared among users, as quantified by the proposed hashtag\nentropy, are less prone to semantic displacement. In the end, we propose a\nbipartite graph embedding model to summarize users' hashtag profiles, and rely\non these profiles to perform friendship prediction. Evaluation results show\nthat our approach achieves an effective prediction with AUC (area under the ROC\ncurve) above 0.8 which demonstrates the strong social signals possessed in\nhashtags.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 20:47:30 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhang", "Yang", ""]]}, {"id": "1905.04610", "submitter": "Scott Lundberg", "authors": "Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M.\n  Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, Su-In Lee", "title": "Explainable AI for Trees: From Local Explanations to Global\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based machine learning models such as random forests, decision trees,\nand gradient boosted trees are the most popular non-linear predictive models\nused in practice today, yet comparatively little attention has been paid to\nexplaining their predictions. Here we significantly improve the\ninterpretability of tree-based models through three main contributions: 1) The\nfirst polynomial time algorithm to compute optimal explanations based on game\ntheory. 2) A new type of explanation that directly measures local feature\ninteraction effects. 3) A new set of tools for understanding global model\nstructure based on combining many local explanations of each prediction. We\napply these tools to three medical machine learning problems and show how\ncombining many high-quality local explanations allows us to represent global\nstructure while retaining local faithfulness to the original model. These tools\nenable us to i) identify high magnitude but low frequency non-linear mortality\nrisk factors in the general US population, ii) highlight distinct population\nsub-groups with shared risk characteristics, iii) identify non-linear\ninteraction effects among risk factors for chronic kidney disease, and iv)\nmonitor a machine learning model deployed in a hospital by identifying which\nfeatures are degrading the model's performance over time. Given the popularity\nof tree-based machine learning models, these improvements to their\ninterpretability have implications across a broad set of domains.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 23:36:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lundberg", "Scott M.", ""], ["Erion", "Gabriel", ""], ["Chen", "Hugh", ""], ["DeGrave", "Alex", ""], ["Prutkin", "Jordan M.", ""], ["Nair", "Bala", ""], ["Katz", "Ronit", ""], ["Himmelfarb", "Jonathan", ""], ["Bansal", "Nisha", ""], ["Lee", "Su-In", ""]]}, {"id": "1905.04616", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Kevin Hu and Neil Gaikwad and Michiel Bakker and Madelon Hulsebos and\n  Emanuel Zgraggen and C\\'esar Hidalgo and Tim Kraska and Guoliang Li and\n  Arvind Satyanarayan and \\c{C}a\\u{g}atay Demiralp", "title": "VizNet: Towards A Large-Scale Visualization Learning and Benchmarking\n  Repository", "comments": "CHI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers currently rely on ad hoc datasets to train automated\nvisualization tools and evaluate the effectiveness of visualization designs.\nThese exemplars often lack the characteristics of real-world datasets, and\ntheir one-off nature makes it difficult to compare different techniques. In\nthis paper, we present VizNet: a large-scale corpus of over 31 million datasets\ncompiled from open data repositories and online visualization galleries. On\naverage, these datasets comprise 17 records over 3 dimensions and across the\ncorpus, we find 51% of the dimensions record categorical data, 44%\nquantitative, and only 5% temporal. VizNet provides the necessary common\nbaseline for comparing visualization design techniques, and developing\nbenchmark models and algorithms for automating visual analysis. To demonstrate\nVizNet's utility as a platform for conducting online crowdsourced experiments\nat scale, we replicate a prior study assessing the influence of user task and\ndata distribution on visual encoding effectiveness, and extend it by\nconsidering an additional task: outlier detection. To contend with running such\nstudies at scale, we demonstrate how a metric of perceptual effectiveness can\nbe learned from experimental results, and show its predictive power across test\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 00:47:28 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hu", "Kevin", ""], ["Gaikwad", "Neil", ""], ["Bakker", "Michiel", ""], ["Hulsebos", "Madelon", ""], ["Zgraggen", "Emanuel", ""], ["Hidalgo", "C\u00e9sar", ""], ["Kraska", "Tim", ""], ["Li", "Guoliang", ""], ["Satyanarayan", "Arvind", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1905.04621", "submitter": "Zilong Zhong", "authors": "Zilong Zhong, Jonathan Li, David A. Clausi, Alexander Wong", "title": "Generative Adversarial Networks and Conditional Random Fields for\n  Hyperspectral Image Classification", "comments": "Accepted by IEEE T-CYB", "journal-ref": null, "doi": "10.1109/TCYB.2019.2915094", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the hyperspectral image (HSI) classification task\nwith a generative adversarial network and conditional random field (GAN-CRF)\n-based framework, which integrates a semi-supervised deep learning and a\nprobabilistic graphical model, and make three contributions. First, we design\nfour types of convolutional and transposed convolutional layers that consider\nthe characteristics of HSIs to help with extracting discriminative features\nfrom limited numbers of labeled HSI samples. Second, we construct\nsemi-supervised GANs to alleviate the shortage of training samples by adding\nlabels to them and implicitly reconstructing real HSI data distribution through\nadversarial training. Third, we build dense conditional random fields (CRFs) on\ntop of the random variables that are initialized to the softmax predictions of\nthe trained GANs and are conditioned on HSIs to refine classification maps.\nThis semi-supervised framework leverages the merits of discriminative and\ngenerative models through a game-theoretical approach. Moreover, even though we\nused very small numbers of labeled training HSI samples from the two most\nchallenging and extensively studied datasets, the experimental results\ndemonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved\ntop-ranking accuracy for semi-supervised HSI classification.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 01:13:35 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhong", "Zilong", ""], ["Li", "Jonathan", ""], ["Clausi", "David A.", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.04629", "submitter": "Quanming Yao", "authors": "Quanming Yao and Hangsi Yang and En-Liang Hu and James Kwok", "title": "Efficient Low-Rank Semidefinite Programming with Robust Loss Functions", "comments": "Preprint version. Final version is accepted to \"IEEE Transactions on\n  Pattern Analysis and Machine Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, it is important for machine learning algorithms\nto be robust against data outliers or corruptions. In this paper, we focus on\nimproving the robustness of a large class of learning algorithms that are\nformulated as low-rank semi-definite programming (SDP) problems. Traditional\nformulations use square loss, which is notorious for being sensitive to\noutliers. We propose to replace this with more robust noise models, including\nthe $\\ell_1$-loss and other nonconvex losses. However, the resultant\noptimization problem becomes difficult as the objective is no longer convex or\nsmooth. To alleviate this problem, we design an efficient algorithm based on\nmajorization-minimization. The crux is on constructing a good optimization\nsurrogate, and we show that this surrogate can be efficiently obtained by the\nalternating direction method of multipliers (ADMM). By properly monitoring\nADMM's convergence, the proposed algorithm is empirically efficient and also\ntheoretically guaranteed to converge to a critical point. Extensive experiments\nare performed on four machine learning applications using both synthetic and\nreal-world data sets. Results show that the proposed algorithm is not only fast\nbut also has better performance than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 02:30:09 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 03:19:25 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Yao", "Quanming", ""], ["Yang", "Hangsi", ""], ["Hu", "En-Liang", ""], ["Kwok", "James", ""]]}, {"id": "1905.04634", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, Arsalan Sharifnassab, S. Jamaloddin Golestani", "title": "One-Shot Federated Learning: Theoretical Limits and Algorithms to\n  Achieve Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed statistical optimization in one-shot setting, where\nthere are $m$ machines each observing $n$ i.i.d. samples. Based on its observed\nsamples, each machine sends a $B$-bit-long message to a server. The server then\ncollects messages from all machines, and estimates a parameter that minimizes\nan expected convex loss function. We investigate the impact of communication\nconstraint, $B$, on the expected error and derive a tight lower bound on the\nerror achievable by any algorithm. We then propose an estimator, which we call\nMulti-Resolution Estimator (MRE), whose expected error (when $B\\ge\\log mn$)\nmeets the aforementioned lower bound up to poly-logarithmic factors, and is\nthereby order optimal. We also address the problem of learning under tiny\ncommunication budget, and present lower and upper error bounds when $B$ is a\nconstant. The expected error of MRE, unlike existing algorithms, tends to zero\nas the number of machines ($m$) goes to infinity, even when the number of\nsamples per machine ($n$) remains upper bounded by a constant. This property of\nthe MRE algorithm makes it applicable in new machine learning paradigms where\n$m$ is much larger than $n$.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 02:52:08 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 05:07:38 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 08:14:52 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 11:20:03 GMT"}, {"version": "v5", "created": "Mon, 30 Dec 2019 10:20:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Sharifnassab", "Arsalan", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1905.04651", "submitter": "Muzammil Abdul Rehman", "authors": "Muzammil Abdul Rehman (1), Sharon Goldberg (2), David Choffnes (1)\n  ((1) Northeastern University, (2) Boston University)", "title": "Passport: Enabling Accurate Country-Level Router Geolocation using\n  Inaccurate Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When does Internet traffic cross international borders? This question has\nmajor geopolitical, legal and social implications and is surprisingly difficult\nto answer. A critical stumbling block is a dearth of tools that accurately map\nrouters traversed by Internet traffic to the countries in which they are\nlocated. This paper presents Passport: a new approach for efficient, accurate\ncountry-level router geolocation and a system that implements it. Passport\nprovides location predictions with limited active measurements, using machine\nlearning to combine information from IP geolocation databases, router\nhostnames, whois records, and ping measurements. We show that Passport\nsubstantially outperforms existing techniques, and identify cases where paths\ntraverse countries with implications for security, privacy, and performance.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 06:04:03 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 18:05:02 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 07:03:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Rehman", "Muzammil Abdul", "", "Northeastern University"], ["Goldberg", "Sharon", "", "Boston University"], ["Choffnes", "David", "", "Northeastern University"]]}, {"id": "1905.04654", "submitter": "Shi Dong", "authors": "Shi Dong, Tengyu Ma, Benjamin Van Roy", "title": "On the Performance of Thompson Sampling on Logistic Bandits", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the logistic bandit, in which rewards are binary with success\nprobability $\\exp(\\beta a^\\top \\theta) / (1 + \\exp(\\beta a^\\top \\theta))$ and\nactions $a$ and coefficients $\\theta$ are within the $d$-dimensional unit ball.\nWhile prior regret bounds for algorithms that address the logistic bandit\nexhibit exponential dependence on the slope parameter $\\beta$, we establish a\nregret bound for Thompson sampling that is independent of $\\beta$.\nSpecifically, we establish that, when the set of feasible actions is identical\nto the set of possible coefficient vectors, the Bayesian regret of Thompson\nsampling is $\\tilde{O}(d\\sqrt{T})$. We also establish a $\\tilde{O}(\\sqrt{d\\eta\nT}/\\lambda)$ bound that applies more broadly, where $\\lambda$ is the worst-case\noptimal log-odds and $\\eta$ is the \"fragility dimension,\" a new statistic we\ndefine to capture the degree to which an optimal action for one model fails to\nsatisfice for others. We demonstrate that the fragility dimension plays an\nessential role by showing that, for any $\\epsilon > 0$, no algorithm can\nachieve $\\mathrm{poly}(d, 1/\\lambda)\\cdot T^{1-\\epsilon}$ regret.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 06:10:22 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Dong", "Shi", ""], ["Ma", "Tengyu", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1905.04663", "submitter": "Daniel Worrall", "authors": "Nichita Diaconu, Daniel E Worrall", "title": "Learning to Convolve: A Generalized Weight-Tying Approach", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work (Cohen & Welling, 2016) has shown that generalizations of\nconvolutions, based on group theory, provide powerful inductive biases for\nlearning. In these generalizations, filters are not only translated but can\nalso be rotated, flipped, etc. However, coming up with exact models of how to\nrotate a 3 x 3 filter on a square pixel-grid is difficult. In this paper, we\nlearn how to transform filters for use in the group convolution, focussing on\nroto-translation. For this, we learn a filter basis and all rotated versions of\nthat filter basis. Filters are then encoded by a set of rotation invariant\ncoefficients. To rotate a filter, we switch the basis. We demonstrate we can\nproduce feature maps with low sensitivity to input rotations, while achieving\nhigh performance on MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 07:55:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Diaconu", "Nichita", ""], ["Worrall", "Daniel E", ""]]}, {"id": "1905.04667", "submitter": "Nadezhda Gribkova Dr.", "authors": "Nadezhda Gribkova and Ri\\v{c}ardas Zitikis", "title": "Functional Correlations in the Pursuit of Performance Assessment of\n  Classifiers", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical classification and machine learning, as well as in social and\nother sciences, a number of measures of association have been proposed for\nassessing and comparing individual classifiers, raters, as well as their\ngroups. In this paper, we introduce, justify, and explore several new measures\nof association, which we call CO-, ANTI- and COANTI-correlation coefficients,\nthat we demonstrate to be powerful tools for classifying confusion matrices. We\nillustrate the performance of these new coefficients using a number of\nexamples, from which we also conclude that the coefficients are new objects in\nthe sense that they differ from those already in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 08:43:06 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 17:18:24 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 08:18:20 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Gribkova", "Nadezhda", ""], ["Zitikis", "Ri\u010dardas", ""]]}, {"id": "1905.04682", "submitter": "Ben Day", "authors": "Enxhell Luzhnica, Ben Day and Pietro Li\\`o", "title": "On Graph Classification Networks, Datasets and Baselines", "comments": "Submitted to the ICML 2019 Workshop on Learning and Reasoning with\n  Graph-Structured Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification receives a great deal of attention from the\nnon-Euclidean machine learning community. Recent advances in graph coarsening\nhave enabled the training of deeper networks and produced new state-of-the-art\nresults in many benchmark tasks. We examine how these architectures train and\nfind that performance is highly-sensitive to initialisation and depends\nstrongly on jumping-knowledge structures. We then show that, despite the great\ncomplexity of these models, competitive performance is achieved by the simplest\nof models -- structure-blind MLP, single-layer GCN and fixed-weight GCN -- and\npropose these be included as baselines in future.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 10:16:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Luzhnica", "Enxhell", ""], ["Day", "Ben", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1905.04708", "submitter": "Koby Bibas", "authors": "Koby Bibas, Yaniv Fogel and Meir Feder", "title": "A New Look at an Old Problem: A Universal Learning Approach to Linear\n  Regression", "comments": null, "journal-ref": null, "doi": "10.1109/ISIT.2019.8849398", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression is a classical paradigm in statistics. A new look at it is\nprovided via the lens of universal learning. In applying universal learning to\nlinear regression the hypotheses class represents the label $y\\in {\\cal R}$ as\na linear combination of the feature vector $x^T\\theta$ where $x\\in {\\cal R}^M$,\nwithin a Gaussian error. The Predictive Normalized Maximum Likelihood (pNML)\nsolution for universal learning of individual data can be expressed\nanalytically in this case, as well as its associated learnability measure.\nInterestingly, the situation where the number of parameters $M$ may even be\nlarger than the number of training samples $N$ can be examined. As expected, in\nthis case learnability cannot be attained in every situation; nevertheless, if\nthe test vector resides mostly in a subspace spanned by the eigenvectors\nassociated with the large eigenvalues of the empirical correlation matrix of\nthe training data, linear regression can generalize despite the fact that it\nuses an ``over-parametrized'' model. We demonstrate the results with a\nsimulation of fitting a polynomial to data with a possibly large polynomial\ndegree.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 12:23:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Bibas", "Koby", ""], ["Fogel", "Yaniv", ""], ["Feder", "Meir", ""]]}, {"id": "1905.04714", "submitter": "Ali Mert Ertugrul", "authors": "Ali Mert Ertugrul, Yu-Ru Lin, Tugba Taskaya-Temizel", "title": "CASTNet: Community-Attentive Spatio-Temporal Networks for Opioid\n  Overdose Forecasting", "comments": "Accepted as conference paper at ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioid overdose is a growing public health crisis in the United States. This\ncrisis, recognized as \"opioid epidemic,\" has widespread societal consequences\nincluding the degradation of health, and the increase in crime rates and family\nproblems. To improve the overdose surveillance and to identify the areas in\nneed of prevention effort, in this work, we focus on forecasting opioid\noverdose using real-time crime dynamics. Previous work identified various types\nof links between opioid use and criminal activities, such as financial motives\nand common causes. Motivated by these observations, we propose a novel\nspatio-temporal predictive model for opioid overdose forecasting by leveraging\nthe spatio-temporal patterns of crime incidents. Our proposed model\nincorporates multi-head attentional networks to learn different representation\nsubspaces of features. Such deep learning architecture, called\n\"community-attentive\" networks, allows the prediction of a given location to be\noptimized by a mixture of groups (i.e., communities) of regions. In addition,\nour proposed model allows for interpreting what features, from what\ncommunities, have more contributions to predicting local incidents as well as\nhow these communities are captured through forecasting. Our results on two\nreal-world overdose datasets indicate that our model achieves superior\nforecasting performance and provides meaningful interpretations in terms of\nspatio-temporal relationships between the dynamics of crime and that of opioid\noverdose.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 12:57:05 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:57:39 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 09:38:18 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 17:12:42 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ertugrul", "Ali Mert", ""], ["Lin", "Yu-Ru", ""], ["Taskaya-Temizel", "Tugba", ""]]}, {"id": "1905.04716", "submitter": "Guanjie Zheng", "authors": "Guanjie Zheng, Xinshi Zang, Nan Xu, Hua Wei, Zhengyao Yu, Vikash\n  Gayah, Kai Xu, Zhenhui Li", "title": "Diagnosing Reinforcement Learning for Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of traffic data and advance of deep\nreinforcement learning techniques, there is an emerging trend of employing\nreinforcement learning (RL) for traffic signal control. A key question for\napplying RL to traffic signal control is how to define the reward and state.\nThe ultimate objective in traffic signal control is to minimize the travel\ntime, which is difficult to reach directly. Hence, existing studies often\ndefine reward as an ad-hoc weighted linear combination of several traffic\nmeasures. However, there is no guarantee that the travel time will be optimized\nwith the reward. In addition, recent RL approaches use more complicated state\n(e.g., image) in order to describe the full traffic situation. However, none of\nthe existing studies has discussed whether such a complex state representation\nis necessary. This extra complexity may lead to significantly slower learning\nprocess but may not necessarily bring significant performance gain.\n  In this paper, we propose to re-examine the RL approaches through the lens of\nclassic transportation theory. We ask the following questions: (1) How should\nwe design the reward so that one can guarantee to minimize the travel time? (2)\nHow to design a state representation which is concise yet sufficient to obtain\nthe optimal solution? Our proposed method LIT is theoretically supported by the\nclassic traffic signal control methods in transportation field. LIT has a very\nsimple state and reward design, thus can serve as a building block for future\nRL approaches to traffic signal control. Extensive experiments on both\nsynthetic and real datasets show that our method significantly outperforms the\nstate-of-the-art traffic signal control methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:03:23 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zheng", "Guanjie", ""], ["Zang", "Xinshi", ""], ["Xu", "Nan", ""], ["Wei", "Hua", ""], ["Yu", "Zhengyao", ""], ["Gayah", "Vikash", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.04720", "submitter": "Rajbir-Singh Nirwan", "authors": "Rajbir S. Nirwan, Nils Bertschinger", "title": "Rotation Invariant Householder Parameterization for Bayesian PCA", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider probabilistic PCA and related factor models from a Bayesian\nperspective. These models are in general not identifiable as the likelihood has\na rotational symmetry. This gives rise to complicated posterior distributions\nwith continuous subspaces of equal density and thus hinders efficiency of\ninference as well as interpretation of obtained parameters. In particular,\nposterior averages over factor loadings become meaningless and only model\npredictions are unambiguous. Here, we propose a parameterization based on\nHouseholder transformations, which remove the rotational symmetry of the\nposterior. Furthermore, by relying on results from random matrix theory, we\nestablish the parameter distribution which leaves the model unchanged compared\nto the original rotationally symmetric formulation. In particular, we avoid the\nneed to compute the Jacobian determinant of the parameter transformation. This\nallows us to efficiently implement probabilistic PCA in a rotation invariant\nfashion in any state of the art toolbox. Here, we implemented our model in the\nprobabilistic programming language Stan and illustrate it on several examples.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:19:17 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Nirwan", "Rajbir S.", ""], ["Bertschinger", "Nils", ""]]}, {"id": "1905.04722", "submitter": "Guanjie Zheng", "authors": "Guanjie Zheng, Yuanhao Xiong, Xinshi Zang, Jie Feng, Hua Wei, Huichu\n  Zhang, Yong Li, Kai Xu, Zhenhui Li", "title": "Learning Phase Competition for Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly available city data and advanced learning techniques have\nempowered people to improve the efficiency of our city functions. Among them,\nimproving the urban transportation efficiency is one of the most prominent\ntopics. Recent studies have proposed to use reinforcement learning (RL) for\ntraffic signal control. Different from traditional transportation approaches\nwhich rely heavily on prior knowledge, RL can learn directly from the feedback.\nOn the other side, without a careful model design, existing RL methods\ntypically take a long time to converge and the learned models may not be able\nto adapt to new scenarios. For example, a model that is trained well for\nmorning traffic may not work for the afternoon traffic because the traffic flow\ncould be reversed, resulting in a very different state representation. In this\npaper, we propose a novel design called FRAP, which is based on the intuitive\nprinciple of phase competition in traffic signal control: when two traffic\nsignals conflict, priority should be given to one with larger traffic movement\n(i.e., higher demand). Through the phase competition modeling, our model\nachieves invariance to symmetrical cases such as flipping and rotation in\ntraffic flow. By conducting comprehensive experiments, we demonstrate that our\nmodel finds better solutions than existing RL methods in the complicated\nall-phase selection problem, converges much faster during training, and\nachieves superior generalizability for different road structures and traffic\nconditions.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:31:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zheng", "Guanjie", ""], ["Xiong", "Yuanhao", ""], ["Zang", "Xinshi", ""], ["Feng", "Jie", ""], ["Wei", "Hua", ""], ["Zhang", "Huichu", ""], ["Li", "Yong", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.04729", "submitter": "Ziqiang Zheng", "authors": "Ziqiang Zheng, Zhibin Yu, Haiyong Zheng, Yang Yang, Heng Tao Shen", "title": "One-Shot Image-to-Image Translation via Part-Global Learning with a\n  Multi-adversarial Framework", "comments": "9 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that humans can learn and recognize objects effectively from\nseveral limited image samples. However, learning from just a few images is\nstill a tremendous challenge for existing main-stream deep neural networks.\nInspired by analogical reasoning in the human mind, a feasible strategy is to\ntranslate the abundant images of a rich source domain to enrich the relevant\nyet different target domain with insufficient image data. To achieve this goal,\nwe propose a novel, effective multi-adversarial framework (MA) based on\npart-global learning, which accomplishes one-shot cross-domain image-to-image\ntranslation. In specific, we first devise a part-global adversarial training\nscheme to provide an efficient way for feature extraction and prevent\ndiscriminators being over-fitted. Then, a multi-adversarial mechanism is\nemployed to enhance the image-to-image translation ability to unearth the\nhigh-level semantic representation. Moreover, a balanced adversarial loss\nfunction is presented, which aims to balance the training data and stabilize\nthe training process. Extensive experiments demonstrate that the proposed\napproach can obtain impressive results on various datasets between two\nextremely imbalanced image domains and outperform state-of-the-art methods on\none-shot image-to-image translation.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 14:29:57 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zheng", "Ziqiang", ""], ["Yu", "Zhibin", ""], ["Zheng", "Haiyong", ""], ["Yang", "Yang", ""], ["Shen", "Heng Tao", ""]]}, {"id": "1905.04730", "submitter": "Thomas M\\\"ollenhoff", "authors": "Thomas M\\\"ollenhoff, Daniel Cremers", "title": "Flat Metric Minimization with Applications in Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take the novel perspective to view data not as a probability distribution\nbut rather as a current. Primarily studied in the field of geometric measure\ntheory, $k$-currents are continuous linear functionals acting on compactly\nsupported smooth differential forms and can be understood as a generalized\nnotion of oriented $k$-dimensional manifold. By moving from distributions\n(which are $0$-currents) to $k$-currents, we can explicitly orient the data by\nattaching a $k$-dimensional tangent plane to each sample point. Based on the\nflat metric which is a fundamental distance between currents, we derive\nFlatGAN, a formulation in the spirit of generative adversarial networks but\ngeneralized to $k$-currents. In our theoretical contribution we prove that the\nflat metric between a parametrized current and a reference current is Lipschitz\ncontinuous in the parameters. In experiments, we show that the proposed shift\nto $k>0$ leads to interpretable and disentangled latent representations which\nbehave equivariantly to the specified oriented tangent planes.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 14:37:07 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["M\u00f6llenhoff", "Thomas", ""], ["Cremers", "Daniel", ""]]}, {"id": "1905.04748", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Guiguang Ding, Yuchen Guo, Jungong Han, Chenggang Yan", "title": "Approximated Oracle Filter Pruning for Destructive CNN Width\n  Optimization", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not easy to design and run Convolutional Neural Networks (CNNs) due to:\n1) finding the optimal number of filters (i.e., the width) at each layer is\ntricky, given an architecture; and 2) the computational intensity of CNNs\nimpedes the deployment on computationally limited devices. Oracle Pruning is\ndesigned to remove the unimportant filters from a well-trained CNN, which\nestimates the filters' importance by ablating them in turn and evaluating the\nmodel, thus delivers high accuracy but suffers from intolerable time\ncomplexity, and requires a given resulting width but cannot automatically find\nit. To address these problems, we propose Approximated Oracle Filter Pruning\n(AOFP), which keeps searching for the least important filters in a binary\nsearch manner, makes pruning attempts by masking out filters randomly,\naccumulates the resulting errors, and finetunes the model via a multi-path\nframework. As AOFP enables simultaneous pruning on multiple layers, we can\nprune an existing very deep CNN with acceptable time cost, negligible accuracy\ndrop, and no heuristic knowledge, or re-design a model which exerts higher\naccuracy and faster inference.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 17:14:19 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ding", "Xiaohan", ""], ["Ding", "Guiguang", ""], ["Guo", "Yuchen", ""], ["Han", "Jungong", ""], ["Yan", "Chenggang", ""]]}, {"id": "1905.04749", "submitter": "Md. Tawkat Islam Khondaker", "authors": "Junaed Younus Khan, Md. Tawkat Islam Khondaker, Sadia Afroz, Gias\n  Uddin, Anindya Iqbal", "title": "A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection", "comments": "22 pages, 5 figures, to be published in Machine Learning with\n  Applications journal", "journal-ref": "Machine Learning with Applications: 4(2021).100032", "doi": "10.1016/j.mlwa.2021.100032", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 17:15:11 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 05:30:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Khan", "Junaed Younus", ""], ["Khondaker", "Md. Tawkat Islam", ""], ["Afroz", "Sadia", ""], ["Uddin", "Gias", ""], ["Iqbal", "Anindya", ""]]}, {"id": "1905.04753", "submitter": "Mengtian Li", "authors": "Mengtian Li, Ersin Yumer and Deva Ramanan", "title": "Budgeted Training: Rethinking Deep Neural Network Training Under\n  Resource Constraints", "comments": "ICLR 2020. Project page with code is at\n  http://www.cs.cmu.edu/~mengtial/proj/budgetnn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most practical settings and theoretical analyses, one assumes that a model\ncan be trained until convergence. However, the growing complexity of machine\nlearning datasets and models may violate such assumptions. Indeed, current\napproaches for hyper-parameter tuning and neural architecture search tend to be\nlimited by practical resource constraints. Therefore, we introduce a formal\nsetting for studying training under the non-asymptotic, resource-constrained\nregime, i.e., budgeted training. We analyze the following problem: \"given a\ndataset, algorithm, and fixed resource budget, what is the best achievable\nperformance?\" We focus on the number of optimization iterations as the\nrepresentative resource. Under such a setting, we show that it is critical to\nadjust the learning rate schedule according to the given budget. Among\nbudget-aware learning schedules, we find simple linear decay to be both robust\nand high-performing. We support our claim through extensive experiments with\nstate-of-the-art models on ImageNet (image classification), Kinetics (video\nclassification), MS COCO (object detection and instance segmentation), and\nCityscapes (semantic segmentation). We also analyze our results and find that\nthe key to a good schedule is budgeted convergence, a phenomenon whereby the\ngradient vanishes at the end of each allowed budget. We also revisit existing\napproaches for fast convergence and show that budget-aware learning schedules\nreadily outperform such approaches under (the practical but under-explored)\nbudgeted training setting.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 17:49:49 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 20:49:09 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 21:06:30 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 00:45:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Li", "Mengtian", ""], ["Yumer", "Ersin", ""], ["Ramanan", "Deva", ""]]}, {"id": "1905.04787", "submitter": "Felix Lucka", "authors": "Henri Der Sarkissian, Felix Lucka, Maureen van Eijnatten, Giulia\n  Colacicco, Sophia Bethany Coban, Kees Joost Batenburg", "title": "A Cone-Beam X-Ray CT Data Collection designed for Machine Learning", "comments": "The reconstruction codes and links to the data are available at\n  https://github.com/cicwi/WalnutReconstructionCodes", "journal-ref": null, "doi": "10.1038/s41597-019-0235-y", "report-no": null, "categories": "eess.IV cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike previous works, this open data collection consists of X-ray cone-beam\n(CB) computed tomography (CT) datasets specifically designed for machine\nlearning applications and high cone-angle artefact reduction. Forty-two walnuts\nwere scanned with a laboratory X-ray set-up to provide not only data from a\nsingle object but from a class of objects with natural variability. For each\nwalnut, CB projections on three different source orbits were acquired to\nprovide CB data with different cone angles as well as being able to compute\nartefact-free, high-quality ground truth images from the combined data that can\nbe used for supervised learning. We provide the complete image reconstruction\npipeline: raw projection data, a description of the scanning geometry,\npre-processing and reconstruction scripts using open software, and the\nreconstructed volumes. Due to this, the dataset can not only be used for high\ncone-angle artefact reduction but also for algorithm development and evaluation\nfor other tasks, such as image reconstruction from limited or sparse-angle\n(low-dose) scanning, super resolution, or segmentation.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 20:27:38 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 12:43:59 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Der Sarkissian", "Henri", ""], ["Lucka", "Felix", ""], ["van Eijnatten", "Maureen", ""], ["Colacicco", "Giulia", ""], ["Coban", "Sophia Bethany", ""], ["Batenburg", "Kees Joost", ""]]}, {"id": "1905.04788", "submitter": "Mohammad Yousefvand", "authors": "Mohammad Yousefvand, Kenza Hamidouche, Narayan B. Mandayam", "title": "Learning-based Resource Optimization in Ultra Reliable Low Latency\n  HetNets", "comments": "Submitted to IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problems of user offloading and resource optimization are\njointly addressed to support ultra-reliable and low latency communications\n(URLLC) in HetNets. In particular, a multi-tier network with a single macro\nbase station (MBS) and multiple overlaid small cell base stations (SBSs) is\nconsidered that includes users with different latency and reliability\nconstraints. Modeling the latency and reliability constraints of users with\nprobabilistic guarantees, the joint problem of user offloading and resource\nallocation (JUR) in a URLLC setting is formulated as an optimization problem to\nminimize the cost of serving users for the MBS. In the considered scheme, SBSs\nbid to serve URLLC users under their coverage at a given price, and the MBS\ndecides whether to serve each user locally or to offload it to one of the\noverlaid SBSs. Since the JUR optimization is NP-hard, we propose a low\ncomplexity learning-based heuristic method (LHM) which includes a support\nvector machine-based user association model and a convex resource optimization\n(CRO) algorithm. To further reduce the delay, we propose an alternating\ndirection method of multipliers (ADMM)-based solution to the CRO problem.\nSimulation results show that using LHM, the MBS significantly decreases the\nspectrum access delay for users (by $\\sim$ 93\\%) as compared to JUR, while also\nreducing its bandwidth and power costs in serving users (by $\\sim$ 33\\%) as\ncompared to directly serving users without offloading.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 20:33:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Yousefvand", "Mohammad", ""], ["Hamidouche", "Kenza", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "1905.04803", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Jwala Dhamala, Prashnna Kumar Gyawali, John L Sapp,\n  B. Milan Horacek, Linwei Wang", "title": "Generative Modeling and Inverse Imaging of Cardiac Transmembrane\n  Potential", "comments": null, "journal-ref": "In International Conference on Medical Image Computing and\n  Computer-Assisted Intervention, pp. 508-516. Springer, Cham, 2018", "doi": "10.1007/978-3-030-00934-2_57", "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noninvasive reconstruction of cardiac transmembrane potential (TMP) from\nsurface electrocardiograms (ECG) involves an ill-posed inverse problem.\nModel-constrained regularization is powerful for incorporating rich\nphysiological knowledge about spatiotemporal TMP dynamics. These models are\ncontrolled by high-dimensional physical parameters which, if fixed, can\nintroduce model errors and reduce the accuracy of TMP reconstruction.\nSimultaneous adaptation of these parameters during TMP reconstruction, however,\nis difficult due to their high dimensionality. We introduce a novel\nmodel-constrained inference framework that replaces conventional physiological\nmodels with a deep generative model trained to generate TMP sequences from\nlow-dimensional generative factors. Using a variational auto-encoder (VAE) with\nlong short-term memory (LSTM) networks, we train the VAE decoder to learn the\nconditional likelihood of TMP, while the encoder learns the prior distribution\nof generative factors. These two components allow us to develop an efficient\nalgorithm to simultaneously infer the generative factors and TMP signals from\nECG data. Synthetic and real-data experiments demonstrate that the presented\nmethod significantly improve the accuracy of TMP reconstruction compared with\nmethods constrained by conventional physiological models or without\nphysiological constraints.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 22:40:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Dhamala", "Jwala", ""], ["Gyawali", "Prashnna Kumar", ""], ["Sapp", "John L", ""], ["Horacek", "B. Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1905.04815", "submitter": "Vishwanath Saragadam Raja Venkata", "authors": "Vishwanath Saragadam and Aswin C. Sankaranarayanan", "title": "Programmable Spectrometry -- Per-pixel Classification of Materials using\n  Learned Spectral Filters", "comments": null, "journal-ref": null, "doi": "10.1109/ICCP48838.2020.9105281", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many materials have distinct spectral profiles. This facilitates estimation\nof the material composition of a scene at each pixel by first acquiring its\nhyperspectral image, and subsequently filtering it using a bank of spectral\nprofiles. This process is inherently wasteful since only a set of linear\nprojections of the acquired measurements contribute to the classification task.\nWe propose a novel programmable camera that is capable of producing images of a\nscene with an arbitrary spectral filter. We use this camera to optically\nimplement the spectral filtering of the scene's hyperspectral image with the\nbank of spectral profiles needed to perform per-pixel material classification.\nThis provides gains both in terms of acquisition speed --- since only the\nrelevant measurements are acquired --- and in signal-to-noise ratio --- since\nwe invariably avoid narrowband filters that are light inefficient. Given\ntraining data, we use a range of classical and modern techniques including SVMs\nand neural networks to identify the bank of spectral profiles that facilitate\nmaterial classification. We verify the method in simulations on standard\ndatasets as well as real data using a lab prototype of the camera.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 00:20:31 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Saragadam", "Vishwanath", ""], ["Sankaranarayanan", "Aswin C.", ""]]}, {"id": "1905.04817", "submitter": "Yibo Yang", "authors": "Georgios Kissas, Yibo Yang, Eileen Hwuang, Walter R. Witschey, John A.\n  Detre, Paris Perdikaris", "title": "Machine learning in cardiovascular flows modeling: Predicting arterial\n  blood pressure from non-invasive 4D flow MRI data using physics-informed\n  neural networks", "comments": "30 pages, 13 figures", "journal-ref": "Published on Computer Methods in Applied Mechanics and Engineering\n  2019", "doi": "10.1016/j.cma.2019.112623", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computational science offer a principled pipeline for predictive\nmodeling of cardiovascular flows and aspire to provide a valuable tool for\nmonitoring, diagnostics and surgical planning. Such models can be nowadays\ndeployed on large patient-specific topologies of systemic arterial networks and\nreturn detailed predictions on flow patterns, wall shear stresses, and pulse\nwave propagation. However, their success heavily relies on tedious\npre-processing and calibration procedures that typically induce a significant\ncomputational cost, thus hampering their clinical applicability. In this work\nwe put forth a machine learning framework that enables the seamless synthesis\nof non-invasive in-vivo measurement techniques and computational flow dynamics\nmodels derived from first physical principles. We illustrate this new paradigm\nby showing how one-dimensional models of pulsatile flow can be used to\nconstrain the output of deep neural networks such that their predictions\nsatisfy the conservation of mass and momentum principles. Once trained on noisy\nand scattered clinical data of flow and wall displacement, these networks can\nreturn physically consistent predictions for velocity, pressure and wall\ndisplacement pulse wave propagation, all without the need to employ\nconventional simulators. A simple post-processing of these outputs can also\nprovide a cheap and effective way for estimating Windkessel model parameters\nthat are required for the calibration of traditional computational models. The\neffectiveness of the proposed techniques is demonstrated through a series of\nprototype benchmarks, as well as a realistic clinical case involving in-vivo\nmeasurements near the aorta/carotid bifurcation of a healthy human subject.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 01:07:06 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 18:45:41 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kissas", "Georgios", ""], ["Yang", "Yibo", ""], ["Hwuang", "Eileen", ""], ["Witschey", "Walter R.", ""], ["Detre", "John A.", ""], ["Perdikaris", "Paris", ""]]}, {"id": "1905.04819", "submitter": "Yilun Du", "authors": "Yilun Du, Karthik Narasimhan", "title": "Task-Agnostic Dynamics Priors for Deep Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  While model-based deep reinforcement learning (RL) holds great promise for\nsample efficiency and generalization, learning an accurate dynamics model is\noften challenging and requires substantial interaction with the environment. A\nwide variety of domains have dynamics that share common foundations like the\nlaws of classical mechanics, which are rarely exploited by existing algorithms.\nIn fact, humans continuously acquire and use such dynamics priors to easily\nadapt to operating in new environments. In this work, we propose an approach to\nlearn task-agnostic dynamics priors from videos and incorporate them into an RL\nagent. Our method involves pre-training a frame predictor on task-agnostic\nphysics videos to initialize dynamics models (and fine-tune them) for unseen\ntarget environments. Our frame prediction architecture, SpatialNet, is designed\nspecifically to capture localized physical phenomena and interactions. Our\napproach allows for both faster policy learning and convergence to better\npolicies, outperforming competitive approaches on several different\nenvironments. We also demonstrate that incorporating this prior allows for more\neffective transfer between environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 01:16:16 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 01:04:30 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 13:18:50 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 13:11:19 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Du", "Yilun", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "1905.04833", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Ariel D. Procaccia, Kevin S. Chan, Sridhar\n  Venkatesan, Noam Ben-Asher, Nandi O. Leslie, Charles Kamhoua, Fei Fang", "title": "Learning and Planning in the Feature Deception Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's high-stakes adversarial interactions feature attackers who constantly\nbreach the ever-improving security measures. Deception mitigates the defender's\nloss by misleading the attacker to make suboptimal decisions. In order to\nformally reason about deception, we introduce the feature deception problem\n(FDP), a domain-independent model and present a learning and planning framework\nfor finding the optimal deception strategy, taking into account the adversary's\npreferences which are initially unknown to the defender. We make the following\ncontributions. (1) We show that we can uniformly learn the adversary's\npreferences using data from a modest number of deception strategies. (2) We\npropose an approximation algorithm for finding the optimal deception strategy\ngiven the learned preferences and show that the problem is NP-hard. (3) We\nperform extensive experiments to validate our methods and results. In addition,\nwe provide a case study of the credit bureau network to illustrate how FDP\nimplements deception on a real-world problem.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 02:54:40 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Procaccia", "Ariel D.", ""], ["Chan", "Kevin S.", ""], ["Venkatesan", "Sridhar", ""], ["Ben-Asher", "Noam", ""], ["Leslie", "Nandi O.", ""], ["Kamhoua", "Charles", ""], ["Fang", "Fei", ""]]}, {"id": "1905.04835", "submitter": "Hossein K. Mousavi", "authors": "Hossein K. Mousavi, Mohammadreza Nazari, Martin Tak\\'a\\v{c}, Nader\n  Motee", "title": "Multi-Agent Image Classification via Reinforcement Learning", "comments": "Preprint of the paper to be published in IROS'19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a classification problem using multiple mobile agents capable\nof collecting (partial) pose-dependent observations of an unknown environment.\nThe objective is to classify an image over a finite time horizon. We propose a\nnetwork architecture on how agents should form a local belief, take local\nactions, and extract relevant features from their raw partial observations.\nAgents are allowed to exchange information with their neighboring agents to\nupdate their own beliefs. It is shown how reinforcement learning techniques can\nbe utilized to achieve decentralized implementation of the classification\nproblem by running a decentralized consensus protocol. Our experimental results\non the MNIST handwritten digit dataset demonstrates the effectiveness of our\nproposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:24:19 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 17:16:22 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Mousavi", "Hossein K.", ""], ["Nazari", "Mohammadreza", ""], ["Tak\u00e1\u010d", "Martin", ""], ["Motee", "Nader", ""]]}, {"id": "1905.04847", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong", "title": "Synchronous Bidirectional Neural Machine Translation", "comments": "Published by TACL 2019, 15 pages, 9 figures, 9 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing approaches to neural machine translation (NMT) generate the target\nlanguage sequence token by token from left to right. However, this kind of\nunidirectional decoding framework cannot make full use of the target-side\nfuture contexts which can be produced in a right-to-left decoding direction,\nand thus suffers from the issue of unbalanced outputs. In this paper, we\nintroduce a synchronous bidirectional neural machine translation (SB-NMT) that\npredicts its outputs using left-to-right and right-to-left decoding\nsimultaneously and interactively, in order to leverage both of the history and\nfuture information at the same time. Specifically, we first propose a new\nalgorithm that enables synchronous bidirectional decoding in a single model.\nThen, we present an interactive decoding model in which left-to-right\n(right-to-left) generation does not only depend on its previously generated\noutputs, but also relies on future contexts predicted by right-to-left\n(left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on\nlarge-scale NIST Chinese-English, WMT14 English-German, and WMT18\nRussian-English translation tasks. Experimental results demonstrate that our\nmodel achieves significant improvements over the strong Transformer model by\n3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art\nperformance on Chinese-English and English-German translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:34:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1905.04849", "submitter": "Cai Shaofeng", "authors": "Shaofeng Cai, Yao Shu, Wei Wang, Beng Chin Ooi", "title": "Dynamic Routing Networks", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of deep neural networks in real-world applications is mostly\nrestricted by their high inference costs. Extensive efforts have been made to\nimprove the accuracy with expert-designed or algorithm-searched architectures.\nHowever, the incremental improvement is typically achieved with increasingly\nmore expensive models that only a small portion of input instances really need.\nInference with a static architecture that processes all input instances via the\nsame transformation would thus incur unnecessary computational costs.\nTherefore, customizing the model capacity in an instance-aware manner is much\nneeded for higher inference efficiency. In this paper, we propose Dynamic\nRouting Networks (DRNets), which support efficient instance-aware inference by\nrouting the input instance to only necessary transformation branches selected\nfrom a candidate set of branches for each connection between transformation\nnodes. The branch selection is dynamically determined via the corresponding\nbranch importance weights, which are first generated from lightweight\nhypernetworks (RouterNets) and then recalibrated with Gumbel-Softmax before the\nselection. Extensive experiments show that DRNets can reduce a substantial\namount of parameter size and FLOPs during inference with prediction performance\ncomparable to state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:45:42 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 16:45:18 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 04:47:36 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 16:26:29 GMT"}, {"version": "v5", "created": "Sun, 8 Nov 2020 13:11:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cai", "Shaofeng", ""], ["Shu", "Yao", ""], ["Wang", "Wei", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "1905.04859", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii, Naoya Takeishi, Motokazu Hojo, Yuki Inaba and Yoshinobu\n  Kawahara", "title": "Physically-interpretable classification of biological network dynamics\n  for complex collective motions", "comments": "42 pages with 7 figures and 3 tables. The latest version is published\n  in Scientific Reports, 2020", "journal-ref": "Scientific Reports, 10, 3005, 2020", "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SI math.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding biological network dynamics is a fundamental issue in various\nscientific and engineering fields. Network theory is capable of revealing the\nrelationship between elements and their propagation; however, for complex\ncollective motions, the network properties often transiently and complexly\nchange. A fundamental question addressed here pertains to the classification of\ncollective motion network based on physically-interpretable dynamical\nproperties. Here we apply a data-driven spectral analysis called graph dynamic\nmode decomposition, which obtains the dynamical properties for collective\nmotion classification. Using a ballgame as an example, we classified the\nstrategic collective motions in different global behaviours and discovered\nthat, in addition to the physical properties, the contextual node information\nwas critical for classification. Furthermore, we discovered the label-specific\nstronger spectra in the relationship among the nearest agents, providing\nphysical and semantic interpretations. Our approach contributes to the\nunderstanding of principles of biological complex network dynamics from the\nperspective of nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 04:54:59 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 23:04:14 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Fujii", "Keisuke", ""], ["Takeishi", "Naoya", ""], ["Hojo", "Motokazu", ""], ["Inaba", "Yuki", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1905.04866", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Kris Sankaran, Eeshan Dhekane, Alexandre Lacoste,\n  Aaron Courville", "title": "Hierarchical Importance Weighted Autoencoders", "comments": "Accepted by ICML 2019. 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance weighted variational inference (Burda et al., 2015) uses multiple\ni.i.d. samples to have a tighter variational lower bound. We believe a joint\nproposal has the potential of reducing the number of redundant samples, and\nintroduce a hierarchical structure to induce correlation. The hope is that the\nproposals would coordinate to make up for the error made by one another to\nreduce the variance of the importance estimator. Theoretically, we analyze the\ncondition under which convergence of the estimator variance can be connected to\nconvergence of the lower bound. Empirically, we confirm that maximization of\nthe lower bound does implicitly minimize variance. Further analysis shows that\nthis is a result of negative correlation induced by the proposed hierarchical\nmeta sampling scheme, and performance of inference also improves when the\nnumber of samples increases.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 05:27:05 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Sankaran", "Kris", ""], ["Dhekane", "Eeshan", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1905.04872", "submitter": "Ryan Wen Liu", "authors": "Yan Li, Ryan Wen Liu, Zhao Liu, Jingxian Liu", "title": "Similarity Grouping-Guided Neural Network Modeling for Maritime Time\n  Series Prediction", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reliable and accurate prediction of time series plays a crucial role in\nmaritime industry, such as economic investment, transportation planning, port\nplanning and design, etc. The dynamic growth of maritime time series has the\npredominantly complex, nonlinear and non-stationary properties. To guarantee\nhigh-quality prediction performance, we propose to first adopt the empirical\nmode decomposition (EMD) and ensemble EMD (EEMD) methods to decompose the\noriginal time series into high- and low-frequency components. The low-frequency\ncomponents can be easily predicted directly through traditional neural network\n(NN) methods. It is more difficult to predict high-frequency components due to\ntheir properties of weak mathematical regularity. To take advantage of the\ninherent self-similarities within high-frequency components, these components\nwill be divided into several continuous small (overlapping) segments. The\ngrouped segments with high similarities are then selected to form more proper\ntraining datasets for traditional NN methods. This regrouping strategy can\nassist in enhancing the prediction accuracy of high-frequency components. The\nfinal prediction result is obtained by integrating the predicted high- and\nlow-frequency components. Our proposed three-step prediction frameworks benefit\nfrom the time series decomposition and similar segments grouping. Experiments\non both port cargo throughput and vessel traffic flow have illustrated its\nsuperior performance in terms of prediction accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 06:13:27 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Yan", ""], ["Liu", "Ryan Wen", ""], ["Liu", "Zhao", ""], ["Liu", "Jingxian", ""]]}, {"id": "1905.04873", "submitter": "K S Sesh Kumar", "authors": "K S Sesh Kumar, Marc Peter Deisenroth", "title": "Differentially Private Empirical Risk Minimization with\n  Sparsity-Inducing Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is concerned about the prediction quality while\nmeasuring the privacy impact on individuals whose information is contained in\nthe data. We consider differentially private risk minimization problems with\nregularizers that induce structured sparsity. These regularizers are known to\nbe convex but they are often non-differentiable. We analyze the standard\ndifferentially private algorithms, such as output perturbation, Frank-Wolfe and\nobjective perturbation. Output perturbation is a differentially private\nalgorithm that is known to perform well for minimizing risks that are strongly\nconvex. Previous works have derived excess risk bounds that are independent of\nthe dimensionality. In this paper, we assume a particular class of convex but\nnon-smooth regularizers that induce structured sparsity and loss functions for\ngeneralized linear models. We also consider differentially private Frank-Wolfe\nalgorithms to optimize the dual of the risk minimization problem. We derive\nexcess risk bounds for both these algorithms. Both the bounds depend on the\nGaussian width of the unit ball of the dual norm. We also show that objective\nperturbation of the risk minimization problems is equivalent to the output\nperturbation of a dual optimization problem. This is the first work that\nanalyzes the dual optimization problems of risk minimization problems in the\ncontext of differential privacy.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 06:16:00 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kumar", "K S Sesh", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1905.04874", "submitter": "Szu-Wei Fu", "authors": "Szu-Wei Fu, Chien-Feng Liao, Yu Tsao, Shou-De Lin", "title": "MetricGAN: Generative Adversarial Networks based Black-box Metric Scores\n  Optimization for Speech Enhancement", "comments": "Accepted by Thirty-sixth International Conference on Machine Learning\n  (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial loss in a conditional generative adversarial network (GAN) is not\ndesigned to directly optimize evaluation metrics of a target task, and thus,\nmay not always guide the generator in a GAN to generate data with improved\nmetric scores. To overcome this issue, we propose a novel MetricGAN approach\nwith an aim to optimize the generator with respect to one or multiple\nevaluation metrics. Moreover, based on MetricGAN, the metric scores of the\ngenerated data can also be arbitrarily specified by users. We tested the\nproposed MetricGAN on a speech enhancement task, which is particularly suitable\nto verify the proposed approach because there are multiple metrics measuring\ndifferent aspects of speech signals. Moreover, these metrics are generally\ncomplex and could not be fully optimized by Lp or conventional adversarial\nlosses.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 06:21:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Fu", "Szu-Wei", ""], ["Liao", "Chien-Feng", ""], ["Tsao", "Yu", ""], ["Lin", "Shou-De", ""]]}, {"id": "1905.04899", "submitter": "Sangdoo Yun", "authors": "Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe,\n  Youngjoon Yoo", "title": "CutMix: Regularization Strategy to Train Strong Classifiers with\n  Localizable Features", "comments": "Accepted at ICCV 2019 (oral talk). 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regional dropout strategies have been proposed to enhance the performance of\nconvolutional neural network classifiers. They have proved to be effective for\nguiding the model to attend on less discriminative parts of objects (e.g. leg\nas opposed to head of a person), thereby letting the network generalize better\nand have better object localization capabilities. On the other hand, current\nmethods for regional dropout remove informative pixels on training images by\noverlaying a patch of either black pixels or random noise. Such removal is not\ndesirable because it leads to information loss and inefficiency during\ntraining. We therefore propose the CutMix augmentation strategy: patches are\ncut and pasted among training images where the ground truth labels are also\nmixed proportionally to the area of the patches. By making efficient use of\ntraining pixels and retaining the regularization effect of regional dropout,\nCutMix consistently outperforms the state-of-the-art augmentation strategies on\nCIFAR and ImageNet classification tasks, as well as on the ImageNet\nweakly-supervised localization task. Moreover, unlike previous augmentation\nmethods, our CutMix-trained ImageNet classifier, when used as a pretrained\nmodel, results in consistent performance gains in Pascal detection and MS-COCO\nimage captioning benchmarks. We also show that CutMix improves the model\nrobustness against input corruptions and its out-of-distribution detection\nperformances. Source code and pretrained models are available at\nhttps://github.com/clovaai/CutMix-PyTorch .\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 08:10:22 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 07:15:29 GMT"}], "update_date": "2019-08-11", "authors_parsed": [["Yun", "Sangdoo", ""], ["Han", "Dongyoon", ""], ["Oh", "Seong Joon", ""], ["Chun", "Sanghyuk", ""], ["Choe", "Junsuk", ""], ["Yoo", "Youngjoon", ""]]}, {"id": "1905.04914", "submitter": "Wei Hu", "authors": "Lingbing Guo and Zequn Sun and Wei Hu", "title": "Learning to Exploit Long-term Relational Dependencies in Knowledge\n  Graphs", "comments": "Accepted by the 36th International Conference on Machine Learning\n  (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of knowledge graph (KG) embedding. A widely-established\nassumption to this problem is that similar entities are likely to have similar\nrelational roles. However, existing related methods derive KG embeddings mainly\nbased on triple-level learning, which lack the capability of capturing\nlong-term relational dependencies of entities. Moreover, triple-level learning\nis insufficient for the propagation of semantic information among entities,\nespecially for the case of cross-KG embedding. In this paper, we propose\nrecurrent skipping networks (RSNs), which employ a skipping mechanism to bridge\nthe gaps between entities. RSNs integrate recurrent neural networks (RNNs) with\nresidual learning to efficiently capture the long-term relational dependencies\nwithin and between KGs. We design an end-to-end framework to support RSNs on\ndifferent tasks. Our experimental results showed that RSNs outperformed\nstate-of-the-art embedding-based methods for entity alignment and achieved\ncompetitive performance for KG completion.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 08:53:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Guo", "Lingbing", ""], ["Sun", "Zequn", ""], ["Hu", "Wei", ""]]}, {"id": "1905.04919", "submitter": "Wei Pan", "authors": "Hongpeng Zhou, Minghao Yang, Jun Wang, Wei Pan", "title": "BayesNAS: A Bayesian Approach for Neural Architecture Search", "comments": "International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One-Shot Neural Architecture Search (NAS) is a promising method to\nsignificantly reduce search time without any separate training. It can be\ntreated as a Network Compression problem on the architecture parameters from an\nover-parameterized network. However, there are two issues associated with most\none-shot NAS methods. First, dependencies between a node and its predecessors\nand successors are often disregarded which result in improper treatment over\nzero operations. Second, architecture parameters pruning based on their\nmagnitude is questionable. In this paper, we employ the classic Bayesian\nlearning approach to alleviate these two issues by modeling architecture\nparameters using hierarchical automatic relevance determination (HARD) priors.\nUnlike other NAS methods, we train the over-parameterized network for only one\nepoch then update the architecture. Impressively, this enabled us to find the\narchitecture on CIFAR-10 within only 0.2 GPU days using a single GPU.\nCompetitive performance can be also achieved by transferring to ImageNet. As a\nbyproduct, our approach can be applied directly to compress convolutional\nneural networks by enforcing structural sparsity which achieves extremely\nsparse networks without accuracy deterioration.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:00:13 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 21:12:09 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhou", "Hongpeng", ""], ["Yang", "Minghao", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "1905.04926", "submitter": "David Balduzzi", "authors": "Alistair Letcher and David Balduzzi and Sebastien Racaniere and James\n  Martens and Jakob Foerster and Karl Tuyls and Thore Graepel", "title": "Differentiable Game Mechanics", "comments": "JMLR 2019, journal version of arXiv:1802.05642", "journal-ref": "Journal of Machine Learning Research (JMLR), v20 (84) 1-40, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is built on the foundational guarantee that gradient descent on\nan objective function converges to local minima. Unfortunately, this guarantee\nfails in settings, such as generative adversarial nets, that exhibit multiple\ninteracting losses. The behavior of gradient-based methods in games is not well\nunderstood -- and is becoming increasingly important as adversarial and\nmulti-objective architectures proliferate. In this paper, we develop new tools\nto understand and control the dynamics in n-player differentiable games.\n  The key result is to decompose the game Jacobian into two components. The\nfirst, symmetric component, is related to potential games, which reduce to\ngradient descent on an implicit function. The second, antisymmetric component,\nrelates to Hamiltonian games, a new class of games that obey a conservation law\nakin to conservation laws in classical mechanical systems. The decomposition\nmotivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding\nstable fixed points in differentiable games. Basic experiments show SGA is\ncompetitive with recently proposed algorithms for finding stable fixed points\nin GANs -- while at the same time being applicable to, and having guarantees\nin, much more general cases.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:21:08 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Letcher", "Alistair", ""], ["Balduzzi", "David", ""], ["Racaniere", "Sebastien", ""], ["Martens", "James", ""], ["Foerster", "Jakob", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1905.04943", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven and Gabriel Peyr\\'e", "title": "Universal Invariant and Equivariant Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) come in many flavors, but should always be either\ninvariant (permutation of the nodes of the input graph does not affect the\noutput) or equivariant (permutation of the input permutes the output). In this\npaper, we consider a specific class of invariant and equivariant networks, for\nwhich we prove new universality theorems. More precisely, we consider networks\nwith a single hidden layer, obtained by summing channels formed by applying an\nequivariant linear operator, a pointwise non-linearity and either an invariant\nor equivariant linear operator. Recently, Maron et al. (2019) showed that by\nallowing higher-order tensorization inside the network, universal invariant\nGNNs can be obtained. As a first contribution, we propose an alternative proof\nof this result, which relies on the Stone-Weierstrass theorem for algebra of\nreal-valued functions. Our main contribution is then an extension of this\nresult to the equivariant case, which appears in many practical applications\nbut has been less studied from a theoretical point of view. The proof relies on\na new generalized Stone-Weierstrass theorem for algebra of equivariant\nfunctions, which is of independent interest. Finally, unlike many previous\nsettings that consider a fixed number of nodes, our results show that a GNN\ndefined by a single set of parameters can approximate uniformly well a function\ndefined on graphs of varying size.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 10:10:48 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 09:37:56 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Keriven", "Nicolas", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1905.04967", "submitter": "Dushyant Mehta", "authors": "Dushyant Mehta, Kwang In Kim, Christian Theobalt", "title": "Implicit Filter Sparsification In Convolutional Neural Networks", "comments": "ODML-CDNNR 2019 (ICML'19 workshop) extended abstract of the CVPR 2019\n  paper \"On Implicit Filter Level Sparsity in Convolutional Neural Networks,\n  Mehta et al.\" (arXiv:1811.12495)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show implicit filter level sparsity manifests in convolutional neural\nnetworks (CNNs) which employ Batch Normalization and ReLU activation, and are\ntrained with adaptive gradient descent techniques and L2 regularization or\nweight decay. Through an extensive empirical study (Mehta et al., 2019) we\nhypothesize the mechanism behind the sparsification process, and find\nsurprising links to certain filter sparsification heuristics proposed in\nliterature. Emergence of, and the subsequent pruning of selective features is\nobserved to be one of the contributing mechanisms, leading to feature sparsity\nat par or better than certain explicit sparsification / pruning approaches. In\nthis workshop article we summarize our findings, and point out corollaries of\nselective-featurepenalization which could also be employed as heuristics for\nfilter pruning\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:10:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mehta", "Dushyant", ""], ["Kim", "Kwang In", ""], ["Theobalt", "Christian", ""]]}, {"id": "1905.04970", "submitter": "Aaron Klein", "authors": "Aaron Klein and Frank Hutter", "title": "Tabular Benchmarks for Joint Architecture and Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high computational demands executing a rigorous comparison between\nhyperparameter optimization (HPO) methods is often cumbersome. The goal of this\npaper is to facilitate a better empirical evaluation of HPO methods by\nproviding benchmarks that are cheap to evaluate, but still represent realistic\nuse cases. We believe these benchmarks provide an easy and efficient way to\nconduct reproducible experiments for neural hyperparameter search. Our\nbenchmarks consist of a large grid of configurations of a feed forward neural\nnetwork on four different regression datasets including architectural\nhyperparameters and hyperparameters concerning the training pipeline. Based on\nthis data, we performed an in-depth analysis to gain a better understanding of\nthe properties of the optimization problem, as well as of the importance of\ndifferent types of hyperparameters. Second, we exhaustively compared various\ndifferent state-of-the-art methods from the hyperparameter optimization\nliterature on these benchmarks in terms of performance and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:17:23 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Klein", "Aaron", ""], ["Hutter", "Frank", ""]]}, {"id": "1905.04981", "submitter": "Maolin Li", "authors": "Maolin Li, Arvid Fahlstr\\\"om Myrman, Tingting Mu, Sophia Ananiadou", "title": "Modelling Instance-Level Annotator Reliability for Natural Language\n  Labelling Tasks", "comments": "9 pages, 1 figures, 10 tables, 2019 Annual Conference of the North\n  American Chapter of the Association for Computational Linguistics (NAACL2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When constructing models that learn from noisy labels produced by multiple\nannotators, it is important to accurately estimate the reliability of\nannotators. Annotators may provide labels of inconsistent quality due to their\nvarying expertise and reliability in a domain. Previous studies have mostly\nfocused on estimating each annotator's overall reliability on the entire\nannotation task. However, in practice, the reliability of an annotator may\ndepend on each specific instance. Only a limited number of studies have\ninvestigated modelling per-instance reliability and these only considered\nbinary labels. In this paper, we propose an unsupervised model which can handle\nboth binary and multi-class labels. It can automatically estimate the\nper-instance reliability of each annotator and the correct label for each\ninstance. We specify our model as a probabilistic model which incorporates\nneural networks to model the dependency between latent variables and instances.\nFor evaluation, the proposed method is applied to both synthetic and real data,\nincluding two labelling tasks: text classification and textual entailment.\nExperimental results demonstrate our novel method can not only accurately\nestimate the reliability of annotators across different instances, but also\nachieve superior performance in predicting the correct labels and detecting the\nleast reliable annotators compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:40:09 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Maolin", ""], ["Myrman", "Arvid Fahlstr\u00f6m", ""], ["Mu", "Tingting", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1905.04982", "submitter": "Alexej Klushyn", "authors": "Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, Patrick van\n  der Smagt", "title": "Learning Hierarchical Priors in VAEs", "comments": "Published at NeurIPS 2019 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn a hierarchical prior in the context of variational\nautoencoders to avoid the over-regularisation resulting from a standard normal\nprior distribution. To incentivise an informative latent representation of the\ndata, we formulate the learning problem as a constrained optimisation problem\nby extending the Taming VAEs framework to two-level hierarchical models. We\nintroduce a graph-based interpolation method, which shows that the topology of\nthe learned latent representation corresponds to the topology of the data\nmanifold---and present several examples, where desired properties of latent\nrepresentation such as smoothness and simple explanatory factors are learned by\nthe prior.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:42:27 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:33:08 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 14:42:37 GMT"}, {"version": "v4", "created": "Sun, 15 Sep 2019 16:36:19 GMT"}, {"version": "v5", "created": "Sat, 5 Oct 2019 16:44:42 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Klushyn", "Alexej", ""], ["Chen", "Nutan", ""], ["Kurle", "Richard", ""], ["Cseke", "Botond", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1905.04992", "submitter": "Julius Berner", "authors": "Julius Berner, Dennis Elbr\\\"achter, Philipp Grohs, Arnulf Jentzen", "title": "Towards a regularity theory for ReLU networks -- chain rule and global\n  error estimates", "comments": "Accepted for presentation at SampTA 2019", "journal-ref": "13th International conference on Sampling Theory and Applications\n  (SampTA), 2019, pp. 1-5", "doi": "10.1109/SampTA45681.2019.9031005", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although for neural networks with locally Lipschitz continuous activation\nfunctions the classical derivative exists almost everywhere, the standard chain\nrule is in general not applicable. We will consider a way of introducing a\nderivative for neural networks that admits a chain rule, which is both rigorous\nand easy to work with. In addition we will present a method of converting\napproximation results on bounded domains to global (pointwise) estimates. This\ncan be used to extend known neural network approximation theory to include the\nstudy of regularity properties. Of particular interest is the application to\nneural networks with ReLU activation function, where it contributes to the\nunderstanding of the success of deep learning methods for high-dimensional\npartial differential equations.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:17:53 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Berner", "Julius", ""], ["Elbr\u00e4chter", "Dennis", ""], ["Grohs", "Philipp", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1905.05004", "submitter": "Wenjie Hu", "authors": "Wenjie Hu, Yang Yang, Liang Wu, Zongtao Liu, Zhanlin Sun and Bingshen\n  Yao", "title": "Capturing Evolution Genes for Time Series Data", "comments": "a preprint version. arXiv admin note: text overlap with\n  arXiv:1703.10155 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling of time series is becoming increasingly critical in a wide\nvariety of applications. Overall, data evolves by following different patterns,\nwhich are generally caused by different user behaviors. Given a time series, we\ndefine the evolution gene to capture the latent user behaviors and to describe\nhow the behaviors lead to the generation of time series. In particular, we\npropose a uniform framework that recognizes different evolution genes of\nsegments by learning a classifier, and adopt an adversarial generator to\nimplement the evolution gene by estimating the segments' distribution.\nExperimental results based on a synthetic dataset and five real-world datasets\nshow that our approach can not only achieve a good prediction results (e.g.,\naveragely +10.56% in terms of F1), but is also able to provide explanations of\nthe results.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:09:34 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hu", "Wenjie", ""], ["Yang", "Yang", ""], ["Wu", "Liang", ""], ["Liu", "Zongtao", ""], ["Sun", "Zhanlin", ""], ["Yao", "Bingshen", ""]]}, {"id": "1905.05006", "submitter": "Wenjie Hu", "authors": "Wenjie Hu, Yang Yang, Ziqiang Cheng, Carl Yang and Xiang Ren", "title": "Time-Series Event Prediction with Evolutionary State Graph", "comments": "A long version of EvoNet (WSDM 2021)", "journal-ref": "Proceedings of the Fourteenth ACM International Conference on Web\n  Search and Data Mining, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The accurate and interpretable prediction of future events in time-series\ndata often requires the capturing of representative patterns (or referred to as\nstates) underpinning the observed data. To this end, most existing studies\nfocus on the representation and recognition of states, but ignore the changing\ntransitional relations among them. In this paper, we present evolutionary state\ngraph, a dynamic graph structure designed to systematically represent the\nevolving relations (edges) among states (nodes) along time. We conduct analysis\non the dynamic graphs constructed from the time-series data and show that\nchanges on the graph structures (e.g., edges connecting certain state nodes)\ncan inform the occurrences of events (i.e., time-series fluctuation). Inspired\nby this, we propose a novel graph neural network model, Evolutionary State\nGraph Network (EvoNet), to encode the evolutionary state graph for accurate and\ninterpretable time-series event prediction. Specifically, Evolutionary State\nGraph Network models both the node-level (state-to-state) and graph-level\n(segment-to-segment) propagation, and captures the node-graph\n(state-to-segment) interactions over time. Experimental results based on five\nreal-world datasets show that our approach not only achieves clear improvements\ncompared with 11 baselines, but also provides more insights towards explaining\nthe results of event predictions.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 07:11:17 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 09:10:33 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 04:41:46 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 08:04:26 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Hu", "Wenjie", ""], ["Yang", "Yang", ""], ["Cheng", "Ziqiang", ""], ["Yang", "Carl", ""], ["Ren", "Xiang", ""]]}, {"id": "1905.05022", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Nishma Laitonjam, Guangyuan Piao, Neil Hurley", "title": "Inferring Hierarchical Mixture Structures: A Bayesian Nonparametric\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of hierarchical non-overlapping clustering\nof a dataset. In such a clustering, each data item is associated with exactly\none leaf node and each internal node is associated with all the data items\nstored in the sub-tree beneath it, so that each level of the hierarchy\ncorresponds to a partition of the dataset. We develop a novel Bayesian\nnonparametric method combining the nested Chinese Restaurant Process (nCRP) and\nthe Hierarchical Dirichlet Process (HDP). Compared with other existing Bayesian\napproaches, our solution tackles data with complex latent mixture features\nwhich has not been previously explored in the literature. We discuss the\ndetails of the model and the inference procedure. Furthermore, experiments on\nthree datasets show that our method achieves solid empirical results in\ncomparison with existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:06:22 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 23:52:30 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:43:17 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 21:00:49 GMT"}, {"version": "v5", "created": "Sun, 28 Feb 2021 20:30:22 GMT"}, {"version": "v6", "created": "Tue, 25 May 2021 09:33:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Huang", "Weipeng", ""], ["Laitonjam", "Nishma", ""], ["Piao", "Guangyuan", ""], ["Hurley", "Neil", ""]]}, {"id": "1905.05037", "submitter": "Alexander Bihlo", "authors": "Alexander Bihlo", "title": "Precipitation nowcasting using a stochastic variational frame predictor\n  with learned prior distribution", "comments": "7 pages, 3 figures, release version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of a stochastic variational frame prediction deep neural\nnetwork with a learned prior distribution trained on two-dimensional rain radar\nreflectivity maps for precipitation nowcasting with lead times of up to 2 1/2\nhours. We present a comparison to a standard convolutional LSTM network and\nassess the evolution of the structural similarity index for both methods. Case\nstudies are presented that illustrate that the novel methodology can yield\nmeaningful forecasts without excessive blur for the time horizons of interest.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:51:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bihlo", "Alexander", ""]]}, {"id": "1905.05040", "submitter": "Pengfei Chen", "authors": "Pengfei Chen, Benben Liao, Guangyong Chen, Shengyu Zhang", "title": "Understanding and Utilizing Deep Neural Networks Trained with Noisy\n  Labels", "comments": "Correspondence to: Guangyong Chen <gycchen@tencent.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labels are ubiquitous in real-world datasets, which poses a challenge\nfor robustly training deep neural networks (DNNs) as DNNs usually have the high\ncapacity to memorize the noisy labels. In this paper, we find that the test\naccuracy can be quantitatively characterized in terms of the noise ratio in\ndatasets. In particular, the test accuracy is a quadratic function of the noise\nratio in the case of symmetric noise, which explains the experimental findings\npreviously published. Based on our analysis, we apply cross-validation to\nrandomly split noisy datasets, which identifies most samples that have correct\nlabels. Then we adopt the Co-teaching strategy which takes full advantage of\nthe identified samples to train DNNs robustly against noisy labels. Compared\nwith extensive state-of-the-art methods, our strategy consistently improves the\ngeneralization performance of DNNs under both synthetic and real-world training\nnoise.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:56:54 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Chen", "Pengfei", ""], ["Liao", "Benben", ""], ["Chen", "Guangyong", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1905.05049", "submitter": "Daniyar Chumbalov", "authors": "Daniyar Chumbalov, Lucas Maystre, Matthias Grossglauser", "title": "Scalable and Efficient Comparison-based Search without Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a target object $t$ using pairwise\ncomparisons, by asking an oracle questions of the form \\emph{\"Which object from\nthe pair $(i,j)$ is more similar to $t$?\"}. Objects live in a space of latent\nfeatures, from which the oracle generates noisy answers. First, we consider the\n{\\em non-blind} setting where these features are accessible. We propose a new\nBayesian comparison-based search algorithm with noisy answers; it has low\ncomputational complexity yet is efficient in the number of queries. We provide\ntheoretical guarantees, deriving the form of the optimal query and proving\nalmost sure convergence to the target $t$. Second, we consider the \\emph{blind}\nsetting, where the object features are hidden from the search algorithm. In\nthis setting, we combine our search method and a new distributional triplet\nembedding algorithm into one scalable learning framework called\n\\textsc{Learn2Search}. We show that the query complexity of our approach on two\nreal-world datasets is on par with the non-blind setting, which is not\nachievable using any of the current state-of-the-art embedding methods.\nFinally, we demonstrate the efficacy of our framework by conducting an\nexperiment with users searching for movie actors.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:12:44 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 22:01:58 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:22:42 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chumbalov", "Daniyar", ""], ["Maystre", "Lucas", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1905.05053", "submitter": "Guoxian Yu", "authors": "Shixing Yao, Guoxian Yu, Jun Wang, Carlotta Domeniconi and Xiangliang\n  Zhang", "title": "Multi-View Multiple Clustering", "comments": "7 pages, 5 figures, uses ijcai19.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple clustering aims at exploring alternative clusterings to organize the\ndata into meaningful groups from different perspectives. Existing multiple\nclustering algorithms are designed for single-view data. We assume that the\nindividuality and commonality of multi-view data can be leveraged to generate\nhigh-quality and diverse clusterings. To this end, we propose a novel\nmulti-view multiple clustering (MVMC) algorithm. MVMC first adapts multi-view\nself-representation learning to explore the individuality encoding matrices and\nthe shared commonality matrix of multi-view data. It additionally reduces the\nredundancy (i.e., enhancing the individuality) among the matrices using the\nHilbert-Schmidt Independence Criterion (HSIC), and collects shared information\nby forcing the shared matrix to be smooth across all views. It then uses matrix\nfactorization on the individual matrices, along with the shared matrix, to\ngenerate diverse clusterings of high-quality. We further extend multiple\nco-clustering on multi-view data and propose a solution called multi-view\nmultiple co-clustering (MVMCC). Our empirical study shows that MVMC (MVMCC) can\nexploit multi-view data to generate multiple high-quality and diverse\nclusterings (co-clusterings), with superior performance to the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:20:44 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yao", "Shixing", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.05061", "submitter": "Guoxian Yu", "authors": "Yuying Xing, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang and\n  Maozu Guo", "title": "Multi-View Multi-Instance Multi-Label Learning based on Collaborative\n  Matrix Factorization", "comments": "8 pages, 8 figures, uses aaai19.sty, accepted to AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view Multi-instance Multi-label Learning(M3L) deals with complex\nobjects encompassing diverse instances, represented with different feature\nviews, and annotated with multiple labels. Existing M3L solutions only\npartially explore the inter or intra relations between objects (or bags),\ninstances, and labels, which can convey important contextual information for\nM3L. As such, they may have a compromised performance. In this paper, we\npropose a collaborative matrix factorization based solution called M3Lcmf.\nM3Lcmf first uses a heterogeneous network composed of nodes of bags, instances,\nand labels, to encode different types of relations via multiple relational data\nmatrices. To preserve the intrinsic structure of the data matrices, M3Lcmf\ncollaboratively factorizes them into low-rank matrices, explores the latent\nrelationships between bags, instances, and labels, and selectively merges the\ndata matrices. An aggregation scheme is further introduced to aggregate the\ninstance-level labels into bag-level and to guide the factorization. An\nempirical study on benchmark datasets show that M3Lcmf outperforms other\nrelated competitive solutions both in the instance-level and bag-level\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:37:25 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 07:05:04 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Xing", "Yuying", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Wang", "Jun", ""], ["Zhang", "Zili", ""], ["Guo", "Maozu", ""]]}, {"id": "1905.05095", "submitter": "Emilio Jorge", "authors": "Arman Rahbar and Emilio Jorge and Devdatt Dubhashi and Morteza Haghir\n  Chehreghani", "title": "Spectral Analysis of Kernel and Neural Embeddings: Optimization and\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the recent results of (Arora et al. 2019). by spectral analysis of\nthe representations corresponding to the kernel and neural embeddings. They\nshowed that in a simple single-layer network, the alignment of the labels to\nthe eigenvectors of the corresponding Gram matrix determines both the\nconvergence of the optimization during training as well as the generalization\nproperties. We generalize their result to the kernel and neural representations\nand show these extensions improve both optimization and generalization of the\nbasic setup studied in (Arora et al. 2019). In particular, we first extend the\nsetup with the Gaussian kernel and the approximations by random Fourier\nfeatures as well as with the embeddings produced by two-layer networks trained\non different tasks. We then study the use of more sophisticated kernels and\nembeddings, those designed optimally for deep neural networks and those\ndeveloped for the classification task of interest given the data and the\ntraining labels, independent of any specific classification model.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:38:38 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:58:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rahbar", "Arman", ""], ["Jorge", "Emilio", ""], ["Dubhashi", "Devdatt", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "1905.05125", "submitter": "Haoyang Liu", "authors": "Haoyang Liu", "title": "Exact high-dimensional asymptotics for Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Support Vector Machine (SVM) is one of the most widely used\nclassification methods. In this paper, we consider the soft-margin SVM used on\ndata points with independent features, where the sample size $n$ and the\nfeature dimension $p$ grows to $\\infty$ in a fixed ratio $p/n\\rightarrow\n\\delta$. We propose a set of equations that exactly characterizes the\nasymptotic behavior of support vector machine. In particular, we give exact\nformulas for (1) the variability of the optimal coefficients, (2) the\nproportion of data points lying on the margin boundary (i.e. number of support\nvectors), (3) the final objective function value, and (4) the expected\nmisclassification error on new data points, which in particular implies the\nexact formula for the optimal tuning parameter given a data generating\nmechanism. We first establish these formulas in the case where the label\n$y\\in\\{+1,-1\\}$ is independent of the feature $x$. Then the results are\ngeneralized to the case where the label $y\\in\\{+1,-1\\}$ is allowed to have a\ngeneral dependence on the feature $x$ through a linear combination $a_0^Tx$.\nThese formulas for the non-smooth hinge loss are analogous to the recent\nresults in \\citep{sur2018modern} for smooth logistic loss. Our approach is\nbased on heuristic leave-one-out calculations.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:25:44 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 21:54:03 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Liu", "Haoyang", ""]]}, {"id": "1905.05134", "submitter": "Sana Tonekaboni", "authors": "Sana Tonekaboni, Shalmali Joshi, Melissa D McCradden, Anna Goldenberg", "title": "What Clinicians Want: Contextualizing Explainable Machine Learning for\n  Clinical End Use", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating machine learning (ML) models effectively to clinical practice\nrequires establishing clinicians' trust. Explainability, or the ability of an\nML model to justify its outcomes and assist clinicians in rationalizing the\nmodel prediction, has been generally understood to be critical to establishing\ntrust. However, the field suffers from the lack of concrete definitions for\nusable explanations in different settings. To identify specific aspects of\nexplainability that may catalyze building trust in ML models, we surveyed\nclinicians from two distinct acute care specialties (Intenstive Care Unit and\nEmergency Department). We use their feedback to characterize when\nexplainability helps to improve clinicians' trust in ML models. We further\nidentify the classes of explanations that clinicians identified as most\nrelevant and crucial for effective translation to clinical practice. Finally,\nwe discern concrete metrics for rigorous evaluation of clinical explainability\nmethods. By integrating perceptions of explainability between clinicians and ML\nresearchers we hope to facilitate the endorsement and broader adoption and\nsustained use of ML systems in healthcare.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:41:37 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 16:07:07 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Tonekaboni", "Sana", ""], ["Joshi", "Shalmali", ""], ["McCradden", "Melissa D", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1905.05137", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Omair Shafiq and Ashraf Matrawy", "title": "Analyzing Adversarial Attacks Against Deep Learning for Intrusion\n  Detection in IoT Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have been widely studied in the field of computer vision\nbut their impact on network security applications remains an area of open\nresearch. As IoT, 5G and AI continue to converge to realize the promise of the\nfourth industrial revolution (Industry 4.0), security incidents and events on\nIoT networks have increased. Deep learning techniques are being applied to\ndetect and mitigate many of such security threats against IoT networks.\nFeedforward Neural Networks (FNN) have been widely used for classifying\nintrusion attacks in IoT networks. In this paper, we consider a variant of the\nFNN known as the Self-normalizing Neural Network (SNN) and compare its\nperformance with the FNN for classifying intrusion attacks in an IoT network.\nOur analysis is performed using the BoT-IoT dataset from the Cyber Range Lab of\nthe center of UNSW Canberra Cyber. In our experimental results, the FNN\noutperforms the SNN for intrusion detection in IoT networks based on multiple\nperformance metrics such as accuracy, precision, and recall as well as\nmulti-classification metrics such as Cohen's Kappa score. However, when tested\nfor adversarial robustness, the SNN demonstrates better resilience against the\nadversarial samples from the IoT dataset, presenting a promising future in the\nquest for safer and more secure deep learning in IoT networks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:43:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Shafiq", "Omair", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1905.05142", "submitter": "Yujing Chen", "authors": "Yujing Chen, Yue Ning, Zheng Chai, Huzefa Rangwala", "title": "Federated Multi-task Hierarchical Attention Model for Sensor Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensors are an integral part of modern Internet of Things (IoT) applications.\nThere is a critical need for the analysis of heterogeneous multivariate\ntemporal data obtained from the individual sensors of these systems. In this\npaper we particularly focus on the problem of the scarce amount of training\ndata available per sensor. We propose a novel federated multi-task hierarchical\nattention model (FATHOM) that jointly trains classification/regression models\nfrom multiple sensors. The attention mechanism of the proposed model seeks to\nextract feature representations from the input and learn a shared\nrepresentation focused on time dimensions across multiple sensors. The\nunderlying temporal and non-linear relationships are modeled using a\ncombination of attention mechanism and long-short term memory (LSTM) networks.\nWe find that our proposed method outperforms a wide range of competitive\nbaselines in both classification and regression settings on activity\nrecognition and environment monitoring datasets. We further provide\nvisualization of feature representations learned by our model at the input\nsensor level and central time level.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:55:43 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Chen", "Yujing", ""], ["Ning", "Yue", ""], ["Chai", "Zheng", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1905.05162", "submitter": "Grady Williams", "authors": "Grady Williams, Brian Goldfain, James M. Rehg, and Evangelos A.\n  Theodorou", "title": "Locally Weighted Regression Pseudo-Rehearsal for Online Learning of\n  Vehicle Dynamics", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online adaptation of a neural network designed to\nrepresent vehicle dynamics. The neural network model is intended to be used by\nan MPC control law to autonomously control the vehicle. This problem is\nchallenging because both the input and target distributions are non-stationary,\nand naive approaches to online adaptation result in catastrophic forgetting,\nwhich can in turn lead to controller failures. We present a novel online\nlearning method, which combines the pseudo-rehearsal method with locally\nweighted projection regression. We demonstrate the effectiveness of the\nresulting Locally Weighted Projection Regression Pseudo-Rehearsal (LW-PR$^2$)\nmethod in simulation and on a large real world dataset collected with a 1/5\nscale autonomous vehicle.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 17:45:02 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Williams", "Grady", ""], ["Goldfain", "Brian", ""], ["Rehg", "James M.", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1905.05163", "submitter": "Xintian Han", "authors": "Xintian Han, Yuxuan Hu, Luca Foschini, Larry Chinitz, Lior Jankelson,\n  Rajesh Ranganath", "title": "Adversarial Examples for Electrocardiograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the electrocardiogram (ECG) has seen a large diffusion in\nboth medical and commercial applications, fueled by the rise of single-lead\nversions. Single-lead ECG can be embedded in medical devices and wearable\nproducts such as the injectable Medtronic Linq monitor, the iRhythm Ziopatch\nwearable monitor, and the Apple Watch Series 4. Recently, deep neural networks\nhave been used to automatically analyze ECG tracings, outperforming even\nphysicians specialized in cardiac electrophysiology in detecting certain rhythm\nirregularities. However, deep learning classifiers have been shown to be\nbrittle to adversarial examples, which are examples created to look\nincontrovertibly belonging to a certain class to a human eye but contain subtle\nfeatures that fool the classifier into misclassifying them into the wrong\nclass. Very recently, adversarial examples have also been created for\nmedical-related tasks. Yet, traditional attack methods to create adversarial\nexamples, such as projected gradient descent (PGD) do not extend directly to\nECG signals, as they generate examples that introduce square wave artifacts\nthat are not physiologically plausible. Here, we developed a method to\nconstruct smoothed adversarial examples for single-lead ECG. First, we\nimplemented a neural network model achieving state-of-the-art performance on\nthe data from the 2017 PhysioNet/Computing-in-Cardiology Challenge for\narrhythmia detection from single lead ECG classification. For this model, we\nutilized a new technique to generate smoothed examples to produce signals that\nare 1) indistinguishable to cardiologists from the original examples and 2)\nincorrectly classified by the neural network. Finally, we show that adversarial\nexamples are not unique and provide a general technique to collate and perturb\nknown adversarial examples to create new ones.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 17:47:25 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 23:04:02 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Han", "Xintian", ""], ["Hu", "Yuxuan", ""], ["Foschini", "Luca", ""], ["Chinitz", "Larry", ""], ["Jankelson", "Lior", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1905.05177", "submitter": "Jun Li", "authors": "Jun Li and Xun Lin and Xiaoguang Rui and Yong Rui and Dacheng Tao", "title": "A Distributed Approach towards Discriminative Distance Metric Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2014.2377211", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning is successful in discovering intrinsic relations in\ndata. However, most algorithms are computationally demanding when the problem\nsize becomes large. In this paper, we propose a discriminative metric learning\nalgorithm, and develop a distributed scheme learning metrics on moderate-sized\nsubsets of data, and aggregating the results into a global solution. The\ntechnique leverages the power of parallel computation. The algorithm of the\naggregated distance metric learning (ADML) scales well with the data size and\ncan be controlled by the partition. We theoretically analyse and provide bounds\nfor the error induced by the distributed treatment. We have conducted\nexperimental evaluation of ADML, both on specially designed tests and on\npractical image annotation tasks. Those tests have shown that ADML achieves the\nstate-of-the-art performance at only a fraction of the cost incurred by most\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:56:33 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Li", "Jun", ""], ["Lin", "Xun", ""], ["Rui", "Xiaoguang", ""], ["Rui", "Yong", ""], ["Tao", "Dacheng", ""]]}, {"id": "1905.05178", "submitter": "Hongyang Gao", "authors": "Hongyang Gao and Shuiwang Ji", "title": "Graph U-Nets", "comments": "10 pages, ICML19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of representation learning for graph data.\nConvolutional neural networks can naturally operate on images, but have\nsignificant challenges in dealing with graph data. Given images are special\ncases of graphs with nodes lie on 2D lattices, graph embedding tasks have a\nnatural correspondence with image pixel-wise prediction tasks such as\nsegmentation. While encoder-decoder architectures like U-Nets have been\nsuccessfully applied on many image pixel-wise prediction tasks, similar methods\nare lacking for graph data. This is due to the fact that pooling and\nup-sampling operations are not natural on graph data. To address these\nchallenges, we propose novel graph pooling (gPool) and unpooling (gUnpool)\noperations in this work. The gPool layer adaptively selects some nodes to form\na smaller graph based on their scalar projection values on a trainable\nprojection vector. We further propose the gUnpool layer as the inverse\noperation of the gPool layer. The gUnpool layer restores the graph into its\noriginal structure using the position information of nodes selected in the\ncorresponding gPool layer. Based on our proposed gPool and gUnpool layers, we\ndevelop an encoder-decoder model on graph, known as the graph U-Nets. Our\nexperimental results on node classification and graph classification tasks\ndemonstrate that our methods achieve consistently better performance than\nprevious models.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 14:10:04 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Gao", "Hongyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1905.05179", "submitter": "Aditya Modi", "authors": "Aditya Modi, Debadeepta Dey, Alekh Agarwal, Adith Swaminathan, Besmira\n  Nushi, Sean Andrist, Eric Horvitz", "title": "Metareasoning in Modular Software Systems: On-the-Fly Configuration\n  using Reinforcement Learning with Rich Contextual Representations", "comments": "12 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assemblies of modular subsystems are being pressed into service to perform\nsensing, reasoning, and decision making in high-stakes, time-critical tasks in\nsuch areas as transportation, healthcare, and industrial automation. We address\nthe opportunity to maximize the utility of an overall computing system by\nemploying reinforcement learning to guide the configuration of the set of\ninteracting modules that comprise the system. The challenge of doing\nsystem-wide optimization is a combinatorial problem. Local attempts to boost\nthe performance of a specific module by modifying its configuration often leads\nto losses in overall utility of the system's performance as the distribution of\ninputs to downstream modules changes drastically. We present metareasoning\ntechniques which consider a rich representation of the input, monitor the state\nof the entire pipeline, and adjust the configuration of modules on-the-fly so\nas to maximize the utility of a system's operation. We show significant\nimprovement in both real-world and synthetic pipelines across a variety of\nreinforcement learning techniques.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 07:24:48 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Modi", "Aditya", ""], ["Dey", "Debadeepta", ""], ["Agarwal", "Alekh", ""], ["Swaminathan", "Adith", ""], ["Nushi", "Besmira", ""], ["Andrist", "Sean", ""], ["Horvitz", "Eric", ""]]}, {"id": "1905.05180", "submitter": "Libo Xing", "authors": "Libo Xing", "title": "Learning and Exploiting Multiple Subgoals for Fast Exploration in\n  Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning (HRL) exploits temporally extended\nactions, or options, to make decisions from a higher-dimensional perspective to\nalleviate the sparse reward problem, one of the most challenging problems in\nreinforcement learning. The majority of existing HRL algorithms require either\nsignificant manual design with respect to the specific environment or enormous\nexploration to automatically learn options from data. To achieve fast\nexploration without using manual design, we devise a multi-goal HRL algorithm,\nconsisting of a high-level policy Manager and a low-level policy Worker. The\nManager provides the Worker multiple subgoals at each time step. Each subgoal\ncorresponds to an option to control the environment. Although the agent may\nshow some confusion at the beginning of training since it is guided by three\ndiverse subgoals, the agent's behavior policy will quickly learn how to respond\nto multiple subgoals from the high-level controller on different occasions. By\nexploiting multiple subgoals, the exploration efficiency is significantly\nimproved. We conduct experiments in Atari's Montezuma's Revenge environment, a\nwell-known sparse reward environment, and in doing so achieve the same\nperformance as state-of-the-art HRL methods with substantially reduced training\ntime cost.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:13:06 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Xing", "Libo", ""]]}, {"id": "1905.05185", "submitter": "Jia Bi", "authors": "Jia Bi and Steve R. Gunn", "title": "A Stochastic Gradient Method with Biased Estimation for Faster Nonconvex\n  Optimization", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A number of optimization approaches have been proposed for optimizing\nnonconvex objectives (e.g. deep learning models), such as batch gradient\ndescent, stochastic gradient descent and stochastic variance reduced gradient\ndescent. Theory shows these optimization methods can converge by using an\nunbiased gradient estimator. However, in practice biased gradient estimation\ncan allow more efficient convergence to the vicinity since an unbiased approach\nis computationally more expensive. To produce fast convergence there are two\ntrade-offs of these optimization strategies which are between stochastic/batch,\nand between biased/unbiased. This paper proposes an integrated approach which\ncan control the nature of the stochastic element in the optimizer and can\nbalance the trade-off of estimator between the biased and unbiased by using a\nhyper-parameter. It is shown theoretically and experimentally that this\nhyper-parameter can be configured to provide an effective balance to improve\nthe convergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:45:04 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bi", "Jia", ""], ["Gunn", "Steve R.", ""]]}, {"id": "1905.05186", "submitter": "Nupur Kumari", "authors": "Mayank Singh, Abhishek Sinha, Nupur Kumari, Harshitha Machiraju,\n  Balaji Krishnamurthy, Vineeth N Balasubramanian", "title": "Harnessing the Vulnerability of Latent Layers in Adversarially Trained\n  Models", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial attacks -- small visually\nimperceptible crafted noise which when added to the input drastically changes\nthe output. The most effective method of defending against these adversarial\nattacks is to use the methodology of adversarial training. We analyze the\nadversarially trained robust models to study their vulnerability against\nadversarial attacks at the level of the latent layers. Our analysis reveals\nthat contrary to the input layer which is robust to adversarial attack, the\nlatent layer of these robust models are highly susceptible to adversarial\nperturbations of small magnitude. Leveraging this information, we introduce a\nnew technique Latent Adversarial Training (LAT) which comprises of fine-tuning\nthe adversarially trained models to ensure the robustness at the feature\nlayers. We also propose Latent Attack (LA), a novel algorithm for construction\nof adversarial examples. LAT results in minor improvement in test accuracy and\nleads to a state-of-the-art adversarial accuracy against the universal\nfirst-order adversarial PGD attack which is shown for the MNIST, CIFAR-10,\nCIFAR-100 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:44:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:38:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Singh", "Mayank", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Machiraju", "Harshitha", ""], ["Krishnamurthy", "Balaji", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1905.05217", "submitter": "Huichu Zhang", "authors": "Huichu Zhang, Siyuan Feng, Chang Liu, Yaoyao Ding, Yichen Zhu, Zihan\n  Zhou, Weinan Zhang, Yong Yu, Haiming Jin, Zhenhui Li", "title": "CityFlow: A Multi-Agent Reinforcement Learning Environment for Large\n  Scale City Traffic Scenario", "comments": "WWW 2019 Demo Paper", "journal-ref": null, "doi": "10.1145/3308558.3314139", "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control is an emerging application scenario for reinforcement\nlearning. Besides being as an important problem that affects people's daily\nlife in commuting, traffic signal control poses its unique challenges for\nreinforcement learning in terms of adapting to dynamic traffic environment and\ncoordinating thousands of agents including vehicles and pedestrians. A key\nfactor in the success of modern reinforcement learning relies on a good\nsimulator to generate a large number of data samples for learning. The most\ncommonly used open-source traffic simulator SUMO is, however, not scalable to\nlarge road network and large traffic flow, which hinders the study of\nreinforcement learning on traffic scenarios. This motivates us to create a new\ntraffic simulator CityFlow with fundamentally optimized data structures and\nefficient algorithms. CityFlow can support flexible definitions for road\nnetwork and traffic flow based on synthetic and real-world data. It also\nprovides user-friendly interface for reinforcement learning. Most importantly,\nCityFlow is more than twenty times faster than SUMO and is capable of\nsupporting city-wide traffic simulation with an interactive render for\nmonitoring. Besides traffic signal control, CityFlow could serve as the base\nfor other transportation studies and can create new possibilities to test\nmachine learning methods in the intelligent transportation domain.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:07:41 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Huichu", ""], ["Feng", "Siyuan", ""], ["Liu", "Chang", ""], ["Ding", "Yaoyao", ""], ["Zhu", "Yichen", ""], ["Zhou", "Zihan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Jin", "Haiming", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.05233", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz and David Gregg", "title": "Winograd Convolution for DNNs: Beyond linear polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Winograd convolution is widely used in deep neural networks (DNNs). Existing\nwork for DNNs considers only the subset Winograd algorithms that are equivalent\nto Toom-Cook convolution. We investigate a wider range of Winograd algorithms\nfor DNNs and show that these additional algorithms can significantly improve\nfloating point (FP) accuracy in many cases. We present results for three FP\nformats: fp32, fp16 and bf16 (a truncated form of fp32) using 2000 inputs from\nthe ImageNet dataset. We found that in fp16 this approach gives us up to 6.5\ntimes better image recognition accuracy in one important case while maintaining\nthe same number of elementwise multiplication operations in the innermost loop.\nIn bf16 the convolution can be computed using 5% fewer innermost loop\nmultiplications than with currently used Winograd algorithms while keeping the\naccuracy of image recognition the same as for direct convolution method.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:34:17 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 09:12:22 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Barabasz", "Barbara", ""], ["Gregg", "David", ""]]}, {"id": "1905.05251", "submitter": "Ke Wang", "authors": "Ke Wang", "title": "Learning Scalable and Precise Representation of Program Semantics", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural program embedding has shown potential in aiding the analysis of\nlarge-scale, complicated software. Newly proposed deep neural architectures\npride themselves on learning program semantics rather than superficial\nsyntactic features. However, by considering the source code only, the vast\nmajority of neural networks do not capture a deep, precise representation of\nprogram semantics. In this paper, we present \\dypro, a novel deep neural\nnetwork that learns from program execution traces. Compared to the prior\ndynamic models, not only is \\dypro capable of generalizing across multiple\nexecutions for learning a program's dynamic semantics in its entirety, but\n\\dypro is also more efficient when dealing with programs yielding long\nexecution traces. For evaluation, we task \\dypro with semantic classification\n(i.e. categorizing programs based on their semantics) and compared it against\ntwo prominent static models: Gated Graph Neural Network and TreeLSTM. We find\nthat \\dypro achieves the highest prediction accuracy among all models. To\nfurther reveal the capacity of all aforementioned deep neural architectures, we\nexamine if the models can learn to detect deeper semantic properties of a\nprogram. In particular given a task of recognizing loop invariants, we show\n\\dypro beats all static models by a wide margin.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:16:22 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 17:16:46 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 23:57:07 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Ke", ""]]}, {"id": "1905.05252", "submitter": "Yunbo Zhang", "authors": "Yunbo Zhang, Wenhao Yu, Greg Turk", "title": "Learning Novel Policies For Tasks", "comments": "8 pages, Accepted ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a reinforcement learning algorithm that can find a\nvariety of policies (novel policies) for a task that is given by a task reward\nfunction. Our method does this by creating a second reward function that\nrecognizes previously seen state sequences and rewards those by novelty, which\nis measured using autoencoders that have been trained on state sequences from\npreviously discovered policies. We present a two-objective update technique for\npolicy gradient algorithms in which each update of the policy is a compromise\nbetween improving the task reward and improving the novelty reward. Using this\nmethod, we end up with a collection of policies that solves a given task as\nwell as carrying out action sequences that are distinct from one another. We\ndemonstrate this method on maze navigation tasks, a reaching task for a\nsimulated robot arm, and a locomotion task for a hopper. We also demonstrate\nthe effectiveness of our approach on deceptive tasks in which policy gradient\nmethods often get stuck.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:17:33 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 15:52:09 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhang", "Yunbo", ""], ["Yu", "Wenhao", ""], ["Turk", "Greg", ""]]}, {"id": "1905.05256", "submitter": "Chen Zhong", "authors": "Chen Zhong, M. Cenk Gursoy, and Senem Velipasalar", "title": "Deep Multi-Agent Reinforcement Learning Based Cooperative Edge Caching\n  in Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing demand on high-quality and low-latency multimedia services has\nled to much interest in edge caching techniques. Motivated by this, we in this\npaper consider edge caching at the base stations with unknown content\npopularity distributions. To solve the dynamic control problem of making\ncaching decisions, we propose a deep actor-critic reinforcement learning based\nmulti-agent framework with the aim to minimize the overall average transmission\ndelay. To evaluate the proposed framework, we compare the learning-based\nperformance with three other caching policies, namely least recently used\n(LRU), least frequently used (LFU), and first-in-first-out (FIFO) policies.\nThrough simulation results, performance improvements of the proposed framework\nover these three caching algorithms have been identified and its superior\nability to adapt to varying environments is demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:25:14 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhong", "Chen", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1905.05264", "submitter": "Claudio Conti", "authors": "Giulia Marcucci and Davide Pierangeli and Pepijn Pinkse and Mehul\n  Malik and Claudio Conti", "title": "Programming multi-level quantum gates in disordered computing reservoirs\n  via machine learning and TensorFlow", "comments": "Added a new section and a new figure about implementation of the\n  gates by a single spatial light modulator. 9 pages and 4 figures", "journal-ref": null, "doi": "10.1364/OE.389432", "report-no": null, "categories": "quant-ph cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel machine learning computational tools open new perspectives for quantum\ninformation systems. Here we adopt the open-source programming library\nTensorFlow to design multi-level quantum gates including a computing reservoir\nrepresented by a random unitary matrix. In optics, the reservoir is a\ndisordered medium or a multi-modal fiber. We show that trainable operators at\nthe input and the readout enable one to realize multi-level gates. We study\nvarious qudit gates, including the scaling properties of the algorithms with\nthe size of the reservoir. Despite an initial low slop learning stage,\nTensorFlow turns out to be an extremely versatile resource for designing gates\nwith complex media, including different models that use spatial light\nmodulators with quantized modulation levels.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:54:54 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 17:38:45 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 16:09:31 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Marcucci", "Giulia", ""], ["Pierangeli", "Davide", ""], ["Pinkse", "Pepijn", ""], ["Malik", "Mehul", ""], ["Conti", "Claudio", ""]]}, {"id": "1905.05284", "submitter": "Ryan Martin", "authors": "Yue Yang and Ryan Martin and Howard Bondell", "title": "Variational approximations using Fisher divergence", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern applications of Bayesian inference involve models that are\nsufficiently complex that the corresponding posterior distributions are\nintractable and must be approximated. The most common approximation is based on\nMarkov chain Monte Carlo, but these can be expensive when the data set is large\nand/or the model is complex, so more efficient variational approximations have\nrecently received considerable attention. The traditional variational methods,\nthat seek to minimize the Kullback--Leibler divergence between the posterior\nand a relatively simple parametric family, provide accurate and efficient\nestimation of the posterior mean, but often does not capture other moments, and\nhave limitations in terms of the models to which they can be applied. Here we\npropose the construction of variational approximations based on minimizing the\nFisher divergence, and develop an efficient computational algorithm that can be\napplied to a wide range of models without conjugacy or potentially unrealistic\nmean-field assumptions. We demonstrate the superior performance of the proposed\nmethod for the benchmark case of logistic regression.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 20:58:34 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yang", "Yue", ""], ["Martin", "Ryan", ""], ["Bondell", "Howard", ""]]}, {"id": "1905.05285", "submitter": "George Chen", "authors": "George H. Chen", "title": "Nearest Neighbor and Kernel Survival Analysis: Nonasymptotic Error\n  Bounds and Strong Consistency Rates", "comments": "International Conference on Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the first nonasymptotic error bounds for Kaplan-Meier-based\nnearest neighbor and kernel survival probability estimators where feature\nvectors reside in metric spaces. Our bounds imply rates of strong consistency\nfor these nonparametric estimators and, up to a log factor, match an existing\nlower bound for conditional CDF estimation. Our proof strategy also yields\nnonasymptotic guarantees for nearest neighbor and kernel variants of the\nNelson-Aalen cumulative hazards estimator. We experimentally compare these\nmethods on four datasets. We find that for the kernel survival estimator, a\ngood choice of kernel is one learned using random survival forests.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 20:59:33 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Chen", "George H.", ""]]}, {"id": "1905.05298", "submitter": "Vinicius Carid\\'a", "authors": "Amir Jalilifard, Vinicius Carid\\'a, Alex Mansano, Rogers Cristo", "title": "Can NetGAN be improved on short random walks?", "comments": "6 pages, 6 figures, 1 table, 10 equations, 22 citations Paper was\n  submited to BRACIS conferece 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are useful structures that can model several important real-world\nproblems. Recently, learning graphs have drawn considerable attention, leading\nto the proposal of new methods for learning these data structures. One of these\nstudies produced NetGAN, a new approach for generating graphs via random walks.\nAlthough NetGAN has shown promising results in terms of accuracy in the tasks\nof generating graphs and link prediction, the choice of vertices from which it\nstarts random walks can lead to inconsistent and highly variable results,\nespecially when the length of walks is short. As an alternative to random\nstarting, this study aims to establish a new method for initializing random\nwalks from a set of dense vertices. We purpose estimating the importance of a\nnode based on the inverse of its influence over the whole vertices of its\nneighborhood through random walks of different sizes. The proposed method\nmanages to achieve significantly better accuracy, less variance and lesser\noutliers.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 21:42:50 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 22:21:53 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Jalilifard", "Amir", ""], ["Carid\u00e1", "Vinicius", ""], ["Mansano", "Alex", ""], ["Cristo", "Rogers", ""]]}, {"id": "1905.05300", "submitter": "Alexander Wong", "authors": "Rene Bidart and Alexander Wong", "title": "Affine Variational Autoencoders: An Efficient Approach for Improving\n  Generalization and Robustness to Distribution Shift", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the Affine Variational Autoencoder (AVAE), a\nvariant of Variational Autoencoder (VAE) designed to improve robustness by\novercoming the inability of VAEs to generalize to distributional shifts in the\nform of affine perturbations. By optimizing an affine transform to maximize\nELBO, the proposed AVAE transforms an input to the training distribution\nwithout the need to increase model complexity to model the full distribution of\naffine transforms. In addition, we introduce a training procedure to create an\nefficient model by learning a subset of the training distribution, and using\nthe AVAE to improve generalization and robustness to distributional shift at\ntest time. Experiments on affine perturbations demonstrate that the proposed\nAVAE significantly improves generalization and robustness to distributional\nshift in the form of affine perturbations without an increase in model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 21:56:27 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bidart", "Rene", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.05301", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Ying Wei, Junzhou Huang, Zhenhui Li", "title": "Hierarchically Structured Meta-learning", "comments": "ICML 2019; Errata: this version fix the results of A1 in Table 10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to learn quickly with few samples, meta-learning utilizes prior\nknowledge learned from previous tasks. However, a critical challenge in\nmeta-learning is task uncertainty and heterogeneity, which can not be handled\nvia globally sharing knowledge among tasks. In this paper, based on\ngradient-based meta-learning, we propose a hierarchically structured\nmeta-learning (HSML) algorithm that explicitly tailors the transferable\nknowledge to different clusters of tasks. Inspired by the way human beings\norganize knowledge, we resort to a hierarchical task clustering structure to\ncluster tasks. As a result, the proposed approach not only addresses the\nchallenge via the knowledge customization to different clusters of tasks, but\nalso preserves knowledge generalization among a cluster of similar tasks. To\ntackle the changing of task relationship, in addition, we extend the\nhierarchical structure to a continual learning environment. The experimental\nresults show that our approach can achieve state-of-the-art performance in both\ntoy-regression and few-shot image classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 21:56:37 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 21:15:22 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yao", "Huaxiu", ""], ["Wei", "Ying", ""], ["Huang", "Junzhou", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.05305", "submitter": "Behzad Tabibian", "authors": "Behzad Tabibian, Vicen\\c{c} G\\'omez, Abir De, Bernhard Sch\\\"olkopf,\n  Manuel Gomez Rodriguez", "title": "Consequential Ranking Algorithms and Long-term Welfare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking models are typically designed to provide rankings that optimize some\nmeasure of immediate utility to the users. As a result, they have been unable\nto anticipate an increasing number of undesirable long-term consequences of\ntheir proposed rankings, from fueling the spread of misinformation and\nincreasing polarization to degrading social discourse. Can we design ranking\nmodels that understand the consequences of their proposed rankings and, more\nimportantly, are able to avoid the undesirable ones? In this paper, we first\nintroduce a joint representation of rankings and user dynamics using Markov\ndecision processes. Then, we show that this representation greatly simplifies\nthe construction of consequential ranking models that trade off the immediate\nutility and the long-term welfare. In particular, we can obtain optimal\nconsequential rankings just by applying weighted sampling on the rankings\nprovided by models that maximize measures of immediate utility. However, in\npractice, such a strategy may be inefficient and impractical, specially in high\ndimensional scenarios. To overcome this, we introduce an efficient\ngradient-based algorithm to learn parameterized consequential ranking models\nthat effectively approximate optimal ones. We showcase our methodology using\nsynthetic and real data gathered from Reddit and show that ranking models\nderived using our methodology provide ranks that may mitigate the spread of\nmisinformation and improve the civility of online discussions.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 22:27:59 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Tabibian", "Behzad", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["De", "Abir", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Rodriguez", "Manuel Gomez", ""]]}, {"id": "1905.05313", "submitter": "Carlo Lucibello", "authors": "Luca Saglietti, Yue M. Lu, Carlo Lucibello", "title": "Generalized Approximate Survey Propagation for High-Dimensional\n  Estimation", "comments": null, "journal-ref": "ICML 2019", "doi": "10.1088/1742-5468/abc62c", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Generalized Linear Estimation (GLE) problems, we seek to estimate a signal\nthat is observed through a linear transform followed by a component-wise,\npossibly nonlinear and noisy, channel. In the Bayesian optimal setting,\nGeneralized Approximate Message Passing (GAMP) is known to achieve optimal\nperformance for GLE. However, its performance can significantly degrade\nwhenever there is a mismatch between the assumed and the true generative model,\na situation frequently encountered in practice. In this paper, we propose a new\nalgorithm, named Generalized Approximate Survey Propagation (GASP), for solving\nGLE in the presence of prior or model mis-specifications. As a prototypical\nexample, we consider the phase retrieval problem, where we show that GASP\noutperforms the corresponding GAMP, reducing the reconstruction threshold and,\nfor certain choices of its parameters, approaching Bayesian optimal\nperformance. Furthermore, we present a set of State Evolution equations that\nexactly characterize the dynamics of GASP in the high-dimensional limit.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 23:07:27 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Saglietti", "Luca", ""], ["Lu", "Yue M.", ""], ["Lucibello", "Carlo", ""]]}, {"id": "1905.05334", "submitter": "Yan Ru Pei", "authors": "Yan Ru Pei, Haik Manukian, Massimiliano Di Ventra", "title": "Generating Weighted MAX-2-SAT Instances of Tunable Difficulty with\n  Frustrated Loops", "comments": "38 pages, 9 figures", "journal-ref": "Journal of Machine Learning Research 21(159), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many optimization problems can be cast into the maximum satisfiability\n(MAX-SAT) form, and many solvers have been developed for tackling such\nproblems. To evaluate a MAX-SAT solver, it is convenient to generate hard\nMAX-SAT instances with known solutions. Here, we propose a method of generating\nweighted MAX-2-SAT instances inspired by the frustrated-loop algorithm used by\nthe quantum annealing community. We extend the algorithm for instances of\ngeneral bipartite couplings, with the associated optimization problem being the\nminimization of the restricted Boltzmann machine (RBM) energy over the nodal\nvalues, which is useful for effectively pre-training the RBM. The hardness of\nthe generated instances can be tuned through a central parameter known as the\nfrustration index. Two versions of the algorithm are presented: the random- and\nstructured-loop algorithms. For the random-loop algorithm, we provide a\nthorough theoretical and empirical analysis on its mathematical properties from\nthe perspective of frustration, and observe empirically a double phase\ntransition behavior in the hardness scaling behavior driven by the frustration\nindex. For the structured-loop algorithm, we show that it offers an improvement\nin hardness over the random-loop algorithm in the regime of high loop density,\nwith the variation of hardness tunable through the concentration of frustrated\nweights.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 01:12:49 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 22:18:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pei", "Yan Ru", ""], ["Manukian", "Haik", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1905.05335", "submitter": "Da Tang", "authors": "Da Tang, Dawen Liang, Tony Jebara, Nicholas Ruozzi", "title": "Correlated Variational Auto-Encoders", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders (VAEs) are capable of learning latent\nrepresentations for high dimensional data. However, due to the i.i.d.\nassumption, VAEs only optimize the singleton variational distributions and fail\nto account for the correlations between data points, which might be crucial for\nlearning latent representations from dataset where a priori we know\ncorrelations exist. We propose Correlated Variational Auto-Encoders (CVAEs)\nthat can take the correlation structure into consideration when learning latent\nrepresentations with VAEs. CVAEs apply a prior based on the correlation\nstructure. To address the intractability introduced by the correlated prior, we\ndevelop an approximation by average of a set of tractable lower bounds over all\nmaximal acyclic subgraphs of the undirected correlation graph. Experimental\nresults on matching and link prediction on public benchmark rating datasets and\nspectral clustering on a synthetic dataset show the effectiveness of the\nproposed method over baseline algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 01:14:23 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:25:18 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 18:32:11 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 20:06:50 GMT"}, {"version": "v5", "created": "Fri, 17 Apr 2020 04:27:41 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tang", "Da", ""], ["Liang", "Dawen", ""], ["Jebara", "Tony", ""], ["Ruozzi", "Nicholas", ""]]}, {"id": "1905.05339", "submitter": "Shaojie Tang", "authors": "Shaojie Tang and Jing Yuan", "title": "Adaptive Robust Optimization with Nearly Submodular Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained submodular maximization has been extensively studied in the\nrecent years. In this paper, we study adaptive robust optimization with nearly\nsubmodular structure (ARONSS). Our objective is to randomly select a subset of\nitems that maximizes the worst-case value of several reward functions\nsimultaneously. Our work differs from existing studies in two ways: (1) we\nstudy the robust optimization problem under the adaptive setting, i.e., one\nneeds to adaptively select items based on the feedback collected from picked\nitems, and (2) our results apply to a broad range of reward functions\ncharacterized by $\\epsilon$-nearly submodular function. We first analyze the\nadaptvity gap of ARONSS and show that the gap between the best adaptive\nsolution and the best non-adaptive solution is bounded. Then we propose a\napproximate solution to this problem when all reward functions are submodular.\nOur algorithm achieves approximation ratio $(1-1/e)$ when considering matroid\nconstraint. At last, we present two heuristics for the general case. All\nproposed solutions are non-adaptive which are easy to implement.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 01:33:04 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 02:53:23 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 03:10:55 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "1905.05345", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg", "title": "Adaptive surrogate models for parametric studies", "comments": "225 pages, Master's thesis, Leibniz University of Hannover, Germany\n  (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational effort for the evaluation of numerical simulations based on\ne.g. the finite-element method is high. Metamodels can be utilized to create a\nlow-cost alternative. However the number of required samples for the creation\nof a sufficient metamodel should be kept low, which can be achieved by using\nadaptive sampling techniques. In this Master thesis adaptive sampling\ntechniques are investigated for their use in creating metamodels with the\nKriging technique, which interpolates values by a Gaussian process governed by\nprior covariances. The Kriging framework with extension to multifidelity\nproblems is presented and utilized to compare adaptive sampling techniques\nfound in the literature for benchmark problems as well as applications for\ncontact mechanics. This thesis offers the first comprehensive comparison of a\nlarge spectrum of adaptive techniques for the Kriging framework. Furthermore a\nmultitude of adaptive techniques is introduced to multifidelity Kriging as well\nas well as to a Kriging model with reduced hyperparameter dimension called\npartial least squares Kriging. In addition, an innovative adaptive scheme for\nbinary classification is presented and tested for identifying chaotic motion of\na Duffing's type oscillator.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 11:08:50 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Fuhg", "Jan N.", ""]]}, {"id": "1905.05347", "submitter": "Penghui Sun", "authors": "Penghui Sun, Jingwei Qu, Xiaoqing Lyu, Haibin Ling and Zhi Tang", "title": "Graph Attribute Aggregation Network with Progressive Margin Folding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) have been attracting increasing\nresearch attention due to its great potential in inference over graph\nstructures. However, insufficient effort has been devoted to the aggregation\nmethods between different convolution graph layers. In this paper, we introduce\na graph attribute aggregation network (GAAN) architecture. Different from the\nconventional pooling operations, a graph-transformation-based aggregation\nstrategy, progressive margin folding, PMF, is proposed for integrating graph\nfeatures. By distinguishing internal and margin elements, we provide an\napproach for implementing the folding iteratively. And a mechanism is also\ndevised for preserving the local structures during progressively folding. In\naddition, a hypergraph-based representation is introduced for transferring the\naggregated information between different layers. Our experiments applied to the\npublic molecule datasets demonstrate that the proposed GAAN outperforms the\nexisting GCNN models with significant effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 02:13:15 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Sun", "Penghui", ""], ["Qu", "Jingwei", ""], ["Lyu", "Xiaoqing", ""], ["Ling", "Haibin", ""], ["Tang", "Zhi", ""]]}, {"id": "1905.05348", "submitter": "Sejun Park", "authors": "Sejun Park, Eunho Yang, Se-Young Yun, Jinwoo Shin", "title": "Spectral Approximate Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graphical model (GM), computing its partition function is the most\nessential inference task, but it is computationally intractable in general. To\naddress the issue, iterative approximation algorithms exploring certain local\nstructure/consistency of GM have been investigated as popular choices in\npractice. However, due to their local/iterative nature, they often output poor\napproximations or even do not converge, e.g., in low-temperature regimes (hard\ninstances of large parameters). To overcome the limitation, we propose a novel\napproach utilizing the global spectral feature of GM. Our contribution is\ntwo-fold: (a) we first propose a fully polynomial-time approximation scheme\n(FPTAS) for approximating the partition function of GM associating with a\nlow-rank coupling matrix; (b) for general high-rank GMs, we design a spectral\nmean-field scheme utilizing (a) as a subroutine, where it approximates a\nhigh-rank GM into a product of rank-1 GMs for an efficient approximation of the\npartition function. The proposed algorithm is more robust in its running time\nand accuracy than prior methods, i.e., neither suffers from the convergence\nissue nor depends on hard local structures, as demonstrated in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 02:13:17 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Park", "Sejun", ""], ["Yang", "Eunho", ""], ["Yun", "Se-Young", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1905.05375", "submitter": "Yu-Ding Lu", "authors": "Yu-Ding Lu, Hsin-Ying Lee, Hung-Yu Tseng, Ming-Hsuan Yang", "title": "Self-supervised Audio Spatialization with Correspondence Classifier", "comments": "ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial audio is an essential medium to audiences for 3D visual and auditory\nexperience. However, the recording devices and techniques are expensive or\ninaccessible to the general public. In this work, we propose a self-supervised\naudio spatialization network that can generate spatial audio given the\ncorresponding video and monaural audio. To enhance spatialization performance,\nwe use an auxiliary classifier to classify ground-truth videos and those with\naudio where the left and right channels are swapped. We collect a large-scale\nvideo dataset with spatial audio to validate the proposed method. Experimental\nresults demonstrate the effectiveness of the proposed model on the audio\nspatialization task.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:20:49 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lu", "Yu-Ding", ""], ["Lee", "Hsin-Ying", ""], ["Tseng", "Hung-Yu", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "1905.05376", "submitter": "Ruosong Wang", "authors": "Kenneth L. Clarkson, Ruosong Wang, David P. Woodruff", "title": "Dimensionality Reduction for Tukey Regression", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first dimensionality reduction methods for the overconstrained\nTukey regression problem. The Tukey loss function $\\|y\\|_M = \\sum_i M(y_i)$ has\n$M(y_i) \\approx |y_i|^p$ for residual errors $y_i$ smaller than a prescribed\nthreshold $\\tau$, but $M(y_i)$ becomes constant for errors $|y_i| > \\tau$. Our\nresults depend on a new structural result, proven constructively, showing that\nfor any $d$-dimensional subspace $L \\subset \\mathbb{R}^n$, there is a fixed\nbounded-size subset of coordinates containing, for every $y \\in L$, all the\nlarge coordinates, with respect to the Tukey loss function, of $y$. Our methods\nreduce a given Tukey regression problem to a smaller weighted version, whose\nsolution is a provably good approximate solution to the original problem. Our\nreductions are fast, simple and easy to implement, and we give empirical\nresults demonstrating their practicality, using existing heuristic solvers for\nthe small versions. We also give exponential-time algorithms giving provably\ngood solutions, and hardness results suggesting that a significant speedup in\nthe worst case is unlikely.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:24:40 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Clarkson", "Kenneth L.", ""], ["Wang", "Ruosong", ""], ["Woodruff", "David P.", ""]]}, {"id": "1905.05380", "submitter": "Richard Cheng", "authors": "Richard Cheng, Abhinav Verma, Gabor Orosz, Swarat Chaudhuri, Yisong\n  Yue, Joel W. Burdick", "title": "Control Regularization for Reduced Variance Reinforcement Learning", "comments": "Appearing in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with high variance is a significant challenge in model-free\nreinforcement learning (RL). Existing methods are unreliable, exhibiting high\nvariance in performance from run to run using different initializations/seeds.\nFocusing on problems arising in continuous control, we propose a functional\nregularization approach to augmenting model-free RL. In particular, we\nregularize the behavior of the deep policy to be similar to a policy prior,\ni.e., we regularize in function space. We show that functional regularization\nyields a bias-variance trade-off, and propose an adaptive tuning strategy to\noptimize this trade-off. When the policy prior has control-theoretic stability\nguarantees, we further show that this regularization approximately preserves\nthose stability guarantees throughout learning. We validate our approach\nempirically on a range of settings, and demonstrate significantly reduced\nvariance, guaranteed dynamic stability, and more efficient learning than deep\nRL alone.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:37:37 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Cheng", "Richard", ""], ["Verma", "Abhinav", ""], ["Orosz", "Gabor", ""], ["Chaudhuri", "Swarat", ""], ["Yue", "Yisong", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1905.05381", "submitter": "Anh Duc Le Dr.", "authors": "Anh Duc Le, Hung Tuan Nguyen and Masaki Nakagawa", "title": "End to End Recognition System for Recognizing Offline Unconstrained\n  Vietnamese Handwriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes in neural machine translation and image caption\ngeneration, we present an attention based encoder decoder model (AED) to\nrecognize Vietnamese Handwritten Text. The model composes of two parts: a\nDenseNet for extracting invariant features, and a Long Short-Term Memory\nnetwork (LSTM) with an attention model incorporated for generating output text\n(LSTM decoder), which are connected from the CNN part to the attention model.\nThe input of the CNN part is a handwritten text image and the target of the\nLSTM decoder is the corresponding text of the input image. Our model is trained\nend-to-end to predict the text from a given input image since all the parts are\ndifferential components. In the experiment section, we evaluate our proposed\nAED model on the VNOnDB-Word and VNOnDB-Line datasets to verify its efficiency.\nThe experiential results show that our model achieves 12.30% of word error rate\nwithout using any language model. This result is competitive with the\nhandwriting recognition system provided by Google in the Vietnamese Online\nHandwritten Text Recognition competition.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:59:46 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Le", "Anh Duc", ""], ["Nguyen", "Hung Tuan", ""], ["Nakagawa", "Masaki", ""]]}, {"id": "1905.05393", "submitter": "Daniel Ho", "authors": "Daniel Ho, Eric Liang, Ion Stoica, Pieter Abbeel, Xi Chen", "title": "Population Based Augmentation: Efficient Learning of Augmentation Policy\n  Schedules", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in leveraging data augmentation for neural network training\nis choosing an effective augmentation policy from a large search space of\ncandidate operations. Properly chosen augmentation policies can lead to\nsignificant generalization improvements; however, state-of-the-art approaches\nsuch as AutoAugment are computationally infeasible to run for the ordinary\nuser. In this paper, we introduce a new data augmentation algorithm, Population\nBased Augmentation (PBA), which generates nonstationary augmentation policy\nschedules instead of a fixed augmentation policy. We show that PBA can match\nthe performance of AutoAugment on CIFAR-10, CIFAR-100, and SVHN, with three\norders of magnitude less overall compute. On CIFAR-10 we achieve a mean test\nerror of 1.46%, which is a slight improvement upon the current\nstate-of-the-art. The code for PBA is open source and is available at\nhttps://github.com/arcelien/pba.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 05:01:43 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ho", "Daniel", ""], ["Liang", "Eric", ""], ["Stoica", "Ion", ""], ["Abbeel", "Pieter", ""], ["Chen", "Xi", ""]]}, {"id": "1905.05394", "submitter": "Mingyuan Zhou", "authors": "Chaojie Wang, Bo Chen, Sucheng Xiao, Mingyuan Zhou", "title": "Convolutional Poisson Gamma Belief Network", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For text analysis, one often resorts to a lossy representation that either\ncompletely ignores word order or embeds each word as a low-dimensional dense\nfeature vector. In this paper, we propose convolutional Poisson factor analysis\n(CPFA) that directly operates on a lossless representation that processes the\nwords in each document as a sequence of high-dimensional one-hot vectors. To\nboost its performance, we further propose the convolutional Poisson gamma\nbelief network (CPGBN) that couples CPFA with the gamma belief network via a\nnovel probabilistic pooling layer. CPFA forms words into phrases and captures\nvery specific phrase-level topics, and CPGBN further builds a hierarchy of\nincreasingly more general phrase-level topics. For efficient inference, we\ndevelop both a Gibbs sampler and a Weibull distribution based convolutional\nvariational auto-encoder. Experimental results demonstrate that CPGBN can\nextract high-quality text latent representations that capture the word order\ninformation, and hence can be leveraged as a building block to enrich a wide\nvariety of existing latent variable models that ignore word order.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 05:08:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wang", "Chaojie", ""], ["Chen", "Bo", ""], ["Xiao", "Sucheng", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.05408", "submitter": "Kyunghwan Son", "authors": "Kyunghwan Son, Daewoo Kim, Wan Ju Kang, David Earl Hostallero, Yung Yi", "title": "QTRAN: Learning to Factorize with Transformation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "18 pages; Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based solutions for multi-agent reinforcement learning\n(MARL) tasks in the centralized training with decentralized execution (CTDE)\nregime popularized recently. However, VDN and QMIX are representative examples\nthat use the idea of factorization of the joint action-value function into\nindividual ones for decentralized execution. VDN and QMIX address only a\nfraction of factorizable MARL tasks due to their structural constraint in\nfactorization such as additivity and monotonicity. In this paper, we propose a\nnew factorization method for MARL, QTRAN, which is free from such structural\nconstraints and takes on a new approach to transforming the original joint\naction-value function into an easily factorizable one, with the same optimal\nactions. QTRAN guarantees more general factorization than VDN or QMIX, thus\ncovering a much wider class of MARL tasks than does previous methods. Our\nexperiments for the tasks of multi-domain Gaussian-squeeze and modified\npredator-prey demonstrate QTRAN's superior performance with especially larger\nmargins in games whose payoffs penalize non-cooperative behavior more\naggressively.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:29:51 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Son", "Kyunghwan", ""], ["Kim", "Daewoo", ""], ["Kang", "Wan Ju", ""], ["Hostallero", "David Earl", ""], ["Yi", "Yung", ""]]}, {"id": "1905.05416", "submitter": "Hao Tang", "authors": "Hao Tang, Wei Wang, Songsong Wu, Xinya Chen, Dan Xu, Nicu Sebe, Yan\n  Yan", "title": "Expression Conditional GAN for Facial Expression-to-Expression\n  Translation", "comments": "5 pages, 5 figures, accepted to ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the facial expression translation task and propose\na novel Expression Conditional GAN (ECGAN) which can learn the mapping from one\nimage domain to another one based on an additional expression attribute. The\nproposed ECGAN is a generic framework and is applicable to different expression\ngeneration tasks where specific facial expression can be easily controlled by\nthe conditional attribute label. Besides, we introduce a novel face mask loss\nto reduce the influence of background changing. Moreover, we propose an entire\nframework for facial expression generation and recognition in the wild, which\nconsists of two modules, i.e., generation and recognition. Finally, we evaluate\nour framework on several public face datasets in which the subjects have\ndifferent races, illumination, occlusion, pose, color, content and background\nconditions. Even though these datasets are very diverse, both the qualitative\nand quantitative results demonstrate that our approach is able to generate\nfacial expressions accurately and robustly.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:52:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Tang", "Hao", ""], ["Wang", "Wei", ""], ["Wu", "Songsong", ""], ["Chen", "Xinya", ""], ["Xu", "Dan", ""], ["Sebe", "Nicu", ""], ["Yan", "Yan", ""]]}, {"id": "1905.05435", "submitter": "Hugh Salimbeni", "authors": "Hugh Salimbeni, Vincent Dutordoir, James Hensman, Marc Peter\n  Deisenroth", "title": "Deep Gaussian Processes with Importance-Weighted Variational Inference", "comments": "Appearing ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian processes (DGPs) can model complex marginal densities as well\nas complex mappings. Non-Gaussian marginals are essential for modelling\nreal-world data, and can be generated from the DGP by incorporating\nuncorrelated variables to the model. Previous work on DGP models has introduced\nnoise additively and used variational inference with a combination of sparse\nGaussian processes and mean-field Gaussians for the approximate posterior.\nAdditive noise attenuates the signal, and the Gaussian form of variational\ndistribution may lead to an inaccurate posterior. We instead incorporate noisy\nvariables as latent covariates, and propose a novel importance-weighted\nobjective, which leverages analytic results and provides a mechanism to trade\noff computation for improved accuracy. Our results demonstrate that the\nimportance-weighted objective works well in practice and consistently\noutperforms classical variational inference, especially for deeper models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 07:56:58 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Salimbeni", "Hugh", ""], ["Dutordoir", "Vincent", ""], ["Hensman", "James", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1905.05441", "submitter": "Julien Rabin", "authors": "Lo\\\"ic Simon, Ryan Webster and Julien Rabin", "title": "Revisiting Precision and Recall Definition for Generative Model\n  Evaluation", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we revisit the definition of Precision-Recall (PR) curves for\ngenerative models proposed by Sajjadi et al. (arXiv:1806.00035). Rather than\nproviding a scalar for generative quality, PR curves distinguish mode-collapse\n(poor recall) and bad quality (poor precision). We first generalize their\nformulation to arbitrary measures, hence removing any restriction to finite\nsupport. We also expose a bridge between PR curves and type I and type II error\nrates of likelihood ratio classifiers on the task of discriminating between\nsamples of the two distributions. Building upon this new perspective, we\npropose a novel algorithm to approximate precision-recall curves, that shares\nsome interesting methodological properties with the hypothesis testing\ntechnique from Lopez-Paz et al (arXiv:1610.06545). We demonstrate the interest\nof the proposed formulation over the original approach on controlled\nmulti-modal datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:15:35 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Simon", "Lo\u00efc", ""], ["Webster", "Ryan", ""], ["Rabin", "Julien", ""]]}, {"id": "1905.05444", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, Jamal Atif, Rida Laraki, David Saltiel", "title": "NGO-GM: Natural Gradient Optimization for Graphical Models", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with estimating model parameters in graphical models. We\nreformulate it as an information geometric optimization problem and introduce a\nnatural gradient descent strategy that incorporates additional meta parameters.\nWe show that our approach is a strong alternative to the celebrated EM approach\nfor learning in graphical models. Actually, our natural gradient based strategy\nleads to learning optimal parameters for the final objective function without\nartificially trying to fit a distribution that may not correspond to the real\none. We support our theoretical findings with the question of trend detection\nin financial markets and show that the learned model performs better than\ntraditional practitioner methods and is less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:21:20 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Benhamou", "Eric", ""], ["Atif", "Jamal", ""], ["Laraki", "Rida", ""], ["Saltiel", "David", ""]]}, {"id": "1905.05451", "submitter": "Christian Wildner", "authors": "Christian Wildner, Heinz Koeppl", "title": "Moment-Based Variational Inference for Markov Jump Processes", "comments": "Accepted by the 36th International Conference on Machine Learning\n  (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose moment-based variational inference as a flexible framework for\napproximate smoothing of latent Markov jump processes. The main ingredient of\nour approach is to partition the set of all transitions of the latent process\ninto classes. This allows to express the Kullback-Leibler divergence between\nthe approximate and the exact posterior process in terms of a set of moment\nfunctions that arise naturally from the chosen partition. To illustrate\npossible choices of the partition, we consider special classes of jump\nprocesses that frequently occur in applications. We then extend the results to\nparameter inference and demonstrate the method on several examples.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:31:17 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wildner", "Christian", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1905.05454", "submitter": "Olga Taran", "authors": "Olga Taran, Shideh Rezaeifar, Taras Holotyak, Slava Voloshynovskiy", "title": "Robustification of deep net classifiers by key based diversified\n  aggregation with pre-filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address a problem of machine learning system vulnerability\nto adversarial attacks. We propose and investigate a Key based Diversified\nAggregation (KDA) mechanism as a defense strategy. The KDA assumes that the\nattacker (i) knows the architecture of classifier and the used defense\nstrategy, (ii) has an access to the training data set but (iii) does not know\nthe secret key. The robustness of the system is achieved by a specially\ndesigned key based randomization. The proposed randomization prevents the\ngradients' back propagation or the creating of a \"bypass\" system. The\nrandomization is performed simultaneously in several channels and a\nmulti-channel aggregation stabilizes the results of randomization by\naggregating soft outputs from each classifier in multi-channel system. The\nperformed experimental evaluation demonstrates a high robustness and\nuniversality of the KDA against the most efficient gradient based attacks like\nthose proposed by N. Carlini and D. Wagner and the non-gradient based sparse\nadversarial perturbations like OnePixel attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:39:09 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Taran", "Olga", ""], ["Rezaeifar", "Shideh", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1905.05461", "submitter": "Charlotte Bunne", "authors": "Charlotte Bunne, David Alvarez-Melis, Andreas Krause, Stefanie Jegelka", "title": "Learning Generative Models across Incomparable Spaces", "comments": "International Conference on Machine Learning (ICML)", "journal-ref": "Proceedings of Machine Learning Research (PMLR), 97 (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks have shown remarkable success in learning a\ndistribution that faithfully recovers a reference distribution in its entirety.\nHowever, in some cases, we may want to only learn some aspects (e.g., cluster\nor manifold structure), while modifying others (e.g., style, orientation or\ndimension). In this work, we propose an approach to learn generative models\nacross such incomparable spaces, and demonstrate how to steer the learned\ndistribution towards target properties. A key component of our model is the\nGromov-Wasserstein distance, a notion of discrepancy that compares\ndistributions relationally rather than absolutely. While this framework\nsubsumes current generative models in identically reproducing distributions,\nits inherent flexibility allows application to tasks in manifold learning,\nrelational learning and cross-domain learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:56:12 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 08:27:28 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Bunne", "Charlotte", ""], ["Alvarez-Melis", "David", ""], ["Krause", "Andreas", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.05468", "submitter": "Weida Li", "authors": "Weida Li, Mingxia Liu, Fang Chen, Daoqiang Zhang", "title": "Graph-Based Decoding Model for Functional Alignment of Unaligned fMRI\n  Data", "comments": "17 pages, 10 figures, Proceedings of the Association for the\n  Advancement of Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating multi-subject functional magnetic resonance imaging (fMRI) data\nis indispensable for generating valid and general inferences from patterns\ndistributed across human brains. The disparities in anatomical structures and\nfunctional topographies of human brains warrant aligning fMRI data across\nsubjects. However, the existing functional alignment methods cannot handle well\nvarious kinds of fMRI datasets today, especially when they are not\ntemporally-aligned, i.e., some of the subjects probably lack the responses to\nsome stimuli, or different subjects might follow different sequences of\nstimuli. In this paper, a cross-subject graph that depicts the\n(dis)similarities between samples across subjects is used as a priori for\ndeveloping a more flexible framework that suits an assortment of fMRI datasets.\nHowever, the high dimension of fMRI data and the use of multiple subjects makes\nthe crude framework time-consuming or unpractical. To address this issue, we\nfurther regularize the framework, so that a novel feasible kernel-based\noptimization, which permits nonlinear feature extraction, could be\ntheoretically developed. Specifically, a low-dimension assumption is imposed on\neach new feature space to avoid overfitting caused by the\nhighspatial-low-temporal resolution of fMRI data. Experimental results on five\ndatasets suggest that the proposed method is not only superior to several\nstate-of-the-art methods on temporally-aligned fMRI data, but also suitable for\ndealing `with temporally-unaligned fMRI data.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:02:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 10:15:13 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 02:19:21 GMT"}, {"version": "v4", "created": "Sat, 15 Jun 2019 16:09:13 GMT"}, {"version": "v5", "created": "Fri, 16 Aug 2019 14:23:01 GMT"}, {"version": "v6", "created": "Mon, 9 Sep 2019 16:56:00 GMT"}, {"version": "v7", "created": "Mon, 18 Nov 2019 14:49:37 GMT"}, {"version": "v8", "created": "Tue, 19 Nov 2019 07:18:36 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Weida", ""], ["Liu", "Mingxia", ""], ["Chen", "Fang", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1905.05469", "submitter": "Ngoc-Trung Tran", "authors": "Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Ngai-Man Cheung", "title": "An Improved Self-supervised GAN via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to improve unconditional Generative Adversarial Networks (GAN) by\ntraining the self-supervised learning with the adversarial process. In\nparticular, we apply self-supervised learning via the geometric transformation\non input images and assign the pseudo-labels to these transformed images. (i)\nIn addition to the GAN task, which distinguishes data (real) versus generated\n(fake) samples, we train the discriminator to predict the correct pseudo-labels\nof real transformed samples (classification task). Importantly, we find out\nthat simultaneously training the discriminator to classify the fake class from\nthe pseudo-classes of real samples for the classification task will improve the\ndiscriminator and subsequently lead better guides to train generator. (ii) The\ngenerator is trained by attempting to confuse the discriminator for not only\nthe GAN task but also the classification task. For the classification task, the\ngenerator tries to confuse the discriminator recognizing the transformation of\nits output as one of the real transformed classes. Especially, we exploit that\nwhen the generator creates samples that result in a similar loss (via\ncross-entropy) as that of the real ones, the training is more stable and the\ngenerator distribution tends to match better the data distribution. When\nintegrating our techniques into a state-of-the-art Auto-Encoder (AE) based-GAN\nmodel, they help to significantly boost the model's performance and also\nestablish new state-of-the-art Fr\\'echet Inception Distance (FID) scores in the\nliterature of unconditional GAN for CIFAR-10 and STL-10 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:05:35 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Tran", "Ngoc-Trung", ""], ["Tran", "Viet-Hung", ""], ["Nguyen", "Ngoc-Bao", ""], ["Cheung", "Ngai-Man", ""]]}, {"id": "1905.05475", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Yingbo Gao, Hermann Ney", "title": "Effective Cross-lingual Transfer of Neural Machine Translation Models\n  without Shared Vocabularies", "comments": "ACL 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning or multilingual model is essential for low-resource neural\nmachine translation (NMT), but the applicability is limited to cognate\nlanguages by sharing their vocabularies. This paper shows effective techniques\nto transfer a pre-trained NMT model to a new, unrelated language without shared\nvocabularies. We relieve the vocabulary mismatch by using cross-lingual word\nembedding, train a more language-agnostic encoder by injecting artificial\nnoises, and generate synthetic data easily from the pre-training data without\nback-translation. Our methods do not require restructuring the vocabulary or\nretraining the model. We improve plain NMT transfer by up to +5.1% BLEU in five\nlow-resource translation tasks, outperforming multilingual joint training by a\nlarge margin. We also provide extensive ablation studies on pre-trained\nembedding, synthetic data, vocabulary size, and parameter freezing for a better\nunderstanding of NMT transfer.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:13:23 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 11:04:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Kim", "Yunsu", ""], ["Gao", "Yingbo", ""], ["Ney", "Hermann", ""]]}, {"id": "1905.05498", "submitter": "Binyamin Manela", "authors": "Binyamin Manela, Armin Biess", "title": "Bias-Reduced Hindsight Experience Replay with Virtual Goal\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindsight Experience Replay (HER) is a multi-goal reinforcement learning\nalgorithm for sparse reward functions. The algorithm treats every failure as a\nsuccess for an alternative (virtual) goal that has been achieved in the\nepisode. Virtual goals are randomly selected, irrespective of which are most\ninstructive for the agent. In this paper, we present two improvements over the\nexisting HER algorithm. First, we prioritize virtual goals from which the agent\nwill learn more valuable information. We call this property the instructiveness\nof the virtual goal and define it by a heuristic measure, which expresses how\nwell the agent will be able to generalize from that virtual goal to actual\ngoals. Secondly, we reduce existing bias in HER by the removal of misleading\nsamples. To test our algorithms, we built two challenging environments with\nsparse reward functions. Our empirical results in both environments show vast\nimprovement in the final success rate and sample efficiency when compared to\nthe original HER algorithm. A video showing experimental results is available\nat https://youtu.be/3cZwfK8Nfps .\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:12:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 10:02:32 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 11:34:24 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 14:45:47 GMT"}, {"version": "v5", "created": "Sun, 7 Mar 2021 11:36:58 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Manela", "Binyamin", ""], ["Biess", "Armin", ""]]}, {"id": "1905.05532", "submitter": "Ganbin Zhou", "authors": "Ganbin Zhou, Ping Luo, Jingwu Chen, Fen Lin, Leyu Lin, Qing He", "title": "Atom Responding Machine for Dialog Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, improving the relevance and diversity of dialogue system has\nattracted wide attention. For a post x, the corresponding response y is usually\ndiverse in the real-world corpus, while the conventional encoder-decoder model\ntends to output the high-frequency (safe but trivial) responses and thus is\ndifficult to handle the large number of responding styles. To address these\nissues, we propose the Atom Responding Machine (ARM), which is based on a\nproposed encoder-composer-decoder network trained by a teacher-student\nframework. To enrich the generated responses, ARM introduces a large number of\nmolecule-mechanisms as various responding styles, which are conducted by taking\ndifferent combinations from a few atom-mechanisms. In other words, even a\nlittle of atom-mechanisms can make a mickle of molecule-mechanisms. The\nexperiments demonstrate diversity and quality of the responses generated by\nARM. We also present generating process to show underlying interpretability for\nthe result.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:44:54 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 10:42:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Zhou", "Ganbin", ""], ["Luo", "Ping", ""], ["Chen", "Jingwu", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "1905.05540", "submitter": "Donya Rahmani", "authors": "Donya Rahmani, Damien Fay and Jacek Brodzki", "title": "A self-organising eigenspace map for time series clustering", "comments": "16 pages-27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel time series clustering method, the\nself-organising eigenspace map (SOEM), based on a generalisation of the\nwell-known self-organising feature map (SOFM). The SOEM operates on the\neigenspaces of the embedded covariance structures of time series which are\nrelated directly to modes in those time series. Approximate joint\ndiagonalisation acts as a pseudo-metric across these spaces allowing us to\ngeneralise the SOFM to a neural network with matrix input. The technique is\nempirically validated against three sets of experiments; univariate and\nmultivariate time series clustering, and application to (clustered)\nmulti-variate time series forecasting. Results indicate that the technique\nperforms a valid topologically ordered clustering of the time series. The\nclustering is superior in comparison to standard benchmarks when the data is\nnon-aligned, gives the best clustering stage for when used in forecasting, and\ncan be used with partial/non-overlapping time series, multivariate clustering\nand produces a topological representation of the time series objects.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:09:04 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Rahmani", "Donya", ""], ["Fay", "Damien", ""], ["Brodzki", "Jacek", ""]]}, {"id": "1905.05547", "submitter": "Kamen Brestnichki", "authors": "Francisco Vargas, Kamen Brestnichki, Alex Papadopoulos-Korfiatis and\n  Nils Hammerla", "title": "Multilingual Factor Analysis", "comments": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we approach the task of learning multilingual word\nrepresentations in an offline manner by fitting a generative latent variable\nmodel to a multilingual dictionary. We model equivalent words in different\nlanguages as different views of the same word generated by a common latent\nvariable representing their latent lexical meaning. We explore the task of\nalignment by querying the fitted model for multilingual embeddings achieving\ncompetitive results across a variety of tasks. The proposed model is robust to\nnoise in the embedding space making it a suitable method for distributed\nrepresentations learned from noisy corpora.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:22:39 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 22:49:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Vargas", "Francisco", ""], ["Brestnichki", "Kamen", ""], ["Papadopoulos-Korfiatis", "Alex", ""], ["Hammerla", "Nils", ""]]}, {"id": "1905.05559", "submitter": "Geir Kjetil Nilsen Mr", "authors": "Geir K. Nilsen, Antonella Z. Munthe-Kaas, Hans J. Skaug, Morten Brun", "title": "Efficient Computation of Hessian Matrices in TensorFlow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hessian matrix has a number of important applications in a variety of\ndifferent fields, such as optimzation, image processing and statistics. In this\npaper we focus on the practical aspects of efficiently computing Hessian\nmatrices in the context of deep learning using the Python scripting language\nand the TensorFlow library. We define a general feed-forward neural network\nmodel and show how to efficiently compute two quantities: the cost function's\nexact Hessian matrix, and the cost function's approximate Hessian matrix, known\nas the Outer Product of Gradients (OPG) matrix. Furthermore, as the number of\nparameters (weights and biases) in deep learning usually is very large, we show\nhow to reduce the quadratic space complexity by an efficient implementation\nbased on approximate eigendecompositions.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:43:44 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 11:38:18 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Nilsen", "Geir K.", ""], ["Munthe-Kaas", "Antonella Z.", ""], ["Skaug", "Hans J.", ""], ["Brun", "Morten", ""]]}, {"id": "1905.05567", "submitter": "Gorker Alp Malazgirt", "authors": "Gorker Alp Malazgirt, Osman S. Unsal, Adrian Cristal Kestelman", "title": "TauRieL: Targeting Traveling Salesman Problem with a deep reinforcement\n  learning inspired architecture", "comments": "10 pages, 5 figures, 1 Algorithm, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose TauRieL and target Traveling Salesman Problem (TSP)\nsince it has broad applicability in theoretical and applied sciences. TauRieL\nutilizes an actor-critic inspired architecture that adopts ordinary feedforward\nnets to obtain a policy update vector $v$. Then, we use $v$ to improve the\nstate transition matrix from which we generate the policy. Also, the state\ntransition matrix allows the solver to initialize from precomputed solutions\nsuch as nearest neighbors. In an online learning setting, TauRieL unifies the\ntraining and the search where it can generate near-optimal results in seconds.\nThe input to the neural nets in the actor-critic architecture are raw 2-D\ninputs, and the design idea behind this decision is to keep neural nets\nrelatively smaller than the architectures with wide embeddings with the\ntradeoff of omitting any distributed representations of the embeddings.\nConsequently, TauRieL generates TSP solutions two orders of magnitude faster\nper TSP instance as compared to state-of-the-art offline techniques with a\nperformance impact of 6.1\\% in the worst case.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:49:32 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Malazgirt", "Gorker Alp", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}, {"id": "1905.05570", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Guanghui Qin, Jason Eisner", "title": "Imputing Missing Events in Continuous-Time Event Streams", "comments": "ICML 2019 camera-ready. The first version of this work appeared on\n  OpenReview in September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events in the world may be caused by other, unobserved events. We consider\nsequences of events in continuous time. Given a probability model of complete\nsequences, we propose particle smoothing---a form of sequential importance\nsampling---to impute the missing events in an incomplete sequence. We develop a\ntrainable family of proposal distributions based on a type of bidirectional\ncontinuous-time LSTM: Bidirectionality lets the proposals condition on future\nobservations, not just on the past as in particle filtering. Our method can\nsample an ensemble of possible complete sequences (particles), from which we\nform a single consensus prediction that has low Bayes risk under our chosen\nloss metric. We experiment in multiple synthetic and real domains, using\ndifferent missingness mechanisms, and modeling the complete sequences in each\ndomain with a neural Hawkes process (Mei & Eisner 2017). On held-out incomplete\nsequences, our method is effective at inferring the ground-truth unobserved\nevents, with particle smoothing consistently improving upon particle filtering.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:55:42 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mei", "Hongyuan", ""], ["Qin", "Guanghui", ""], ["Eisner", "Jason", ""]]}, {"id": "1905.05604", "submitter": "Alexander Wagner", "authors": "Peter Bubenik, Alexander Wagner", "title": "Embeddings of Persistence Diagrams into Hilbert Spaces", "comments": "Improvements in exposition thanks to the anonymous referees. To\n  appear in the Journal of Applied and Computational Topology", "journal-ref": "Journal of Applied and Computational Topology, volume 4, pages\n  339-351 (2020)", "doi": "10.1007/s41468-020-00056-w", "report-no": null, "categories": "cs.LG math.AT math.MG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since persistence diagrams do not admit an inner product structure, a map\ninto a Hilbert space is needed in order to use kernel methods. It is natural to\nask if such maps necessarily distort the metric on persistence diagrams. We\nshow that persistence diagrams with the bottleneck distance do not even admit a\ncoarse embedding into a Hilbert space. As part of our proof, we show that any\nseparable, bounded metric space isometrically embeds into the space of\npersistence diagrams with the bottleneck distance. As corollaries, we obtain\nthe generalized roundness, negative type, and asymptotic dimension of this\nspace.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:12:55 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 17:58:53 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 17:36:26 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Bubenik", "Peter", ""], ["Wagner", "Alexander", ""]]}, {"id": "1905.05614", "submitter": "Xiaoyuan Liang", "authors": "Xiaoyuan Liang, Guiling Wang, Martin Renqiang Min, Yi Qi, Zhu Han", "title": "A Deep Spatio-Temporal Fuzzy Neural Network for Passenger Demand\n  Prediction", "comments": "https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.12", "journal-ref": "Proceedings of the 2019 SIAM International Conference on Data\n  Mining", "doi": "10.1137/1.9781611975673.12", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of its importance, passenger demand prediction is a highly\nchallenging problem, because the demand is simultaneously influenced by the\ncomplex interactions among many spatial and temporal factors and other external\nfactors such as weather. To address this problem, we propose a Spatio-TEmporal\nFuzzy neural Network (STEF-Net) to accurately predict passenger demands\nincorporating the complex interactions of all known important factors. We\ndesign an end-to-end learning framework with different neural networks modeling\ndifferent factors. Specifically, we propose to capture spatio-temporal feature\ninteractions via a convolutional long short-term memory network and model\nexternal factors via a fuzzy neural network that handles data uncertainty\nsignificantly better than deterministic methods. To keep the temporal relations\nwhen fusing two networks and emphasize discriminative spatio-temporal feature\ninteractions, we employ a novel feature fusion method with a convolution\noperation and an attention layer. As far as we know, our work is the first to\nfuse a deep recurrent neural network and a fuzzy neural network to model\ncomplex spatial-temporal feature interactions with additional uncertain input\nfeatures for predictive learning. Experiments on a large-scale real-world\ndataset show that our model achieves more than 10% improvement over the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:57:14 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Liang", "Xiaoyuan", ""], ["Wang", "Guiling", ""], ["Min", "Martin Renqiang", ""], ["Qi", "Yi", ""], ["Han", "Zhu", ""]]}, {"id": "1905.05622", "submitter": "Boyi Jiang", "authors": "Boyi Jiang, Juyong Zhang, Jianfei Cai, Jianmin Zheng", "title": "Disentangled Human Body Embedding Based on Deep Hierarchical Neural\n  Network", "comments": "This manuscript is accepted for publication in the IEEE Transactions\n  on Visualization and Computer Graphics Journal (IEEE TVCG). The Code is\n  available at https://github.com/Juyong/DHNN_BodyRepresentation", "journal-ref": null, "doi": "10.1109/TVCG.2020.2988476", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human bodies exhibit various shapes for different identities or poses, but\nthe body shape has certain similarities in structure and thus can be embedded\nin a low-dimensional space. This paper presents an autoencoder-like network\narchitecture to learn disentangled shape and pose embedding specifically for\nthe 3D human body. This is inspired by recent progress of deformation-based\nlatent representation learning. To improve the reconstruction accuracy, we\npropose a hierarchical reconstruction pipeline for the disentangling process\nand construct a large dataset of human body models with consistent connectivity\nfor the learning of the neural network. Our learned embedding can not only\nachieve superior reconstruction accuracy but also provide great flexibility in\n3D human body generation via interpolation, bilinear interpolation, and latent\nspace sampling. The results from extensive experiments demonstrate the\npowerfulness of our learned 3D human body embedding in various applications.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:06:54 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 10:09:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Jiang", "Boyi", ""], ["Zhang", "Juyong", ""], ["Cai", "Jianfei", ""], ["Zheng", "Jianmin", ""]]}, {"id": "1905.05637", "submitter": "MyungJae Shin", "authors": "MyungJae Shin, Joongheon Kim", "title": "Randomized Adversarial Imitation Learning for Autonomous Driving", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of various advanced driver assistance system (ADAS)\nplatforms, the design of autonomous driving system is becoming more complex and\nsafety-critical. The autonomous driving system simultaneously activates\nmultiple ADAS functions; and thus it is essential to coordinate various ADAS\nfunctions. This paper proposes a randomized adversarial imitation learning\n(RAIL) method that imitates the coordination of autonomous vehicle equipped\nwith advanced sensors. The RAIL policies are trained through derivative-free\noptimization for the decision maker that coordinates the proper ADAS functions,\ne.g., smart cruise control and lane keeping system. Especially, the proposed\nmethod is also able to deal with the LIDAR data and makes decisions in complex\nmulti-lane highways and multi-agent environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:27:00 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Shin", "MyungJae", ""], ["Kim", "Joongheon", ""]]}, {"id": "1905.05643", "submitter": "Cameron Musco", "authors": "Yonina C. Eldar, Jerry Li, Cameron Musco, Christopher Musco", "title": "Sample Efficient Toeplitz Covariance Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of estimating the covariance matrix $T$ of a\ndistribution $\\mathcal{D}$ over $d$-dimensional vectors, under the assumption\nthat $T$ is Toeplitz. This assumption arises in many signal processing\nproblems, where the covariance between any two measurements only depends on the\ntime or distance between those measurements. We are interested in estimation\nstrategies that may choose to view only a subset of entries in each vector\nsample $x \\sim \\mathcal{D}$, which often equates to reducing hardware and\ncommunication requirements in applications ranging from wireless signal\nprocessing to advanced imaging. Our goal is to minimize both 1) the number of\nvector samples drawn from $\\mathcal{D}$ and 2) the number of entries accessed\nin each sample.\n  We provide some of the first non-asymptotic bounds on these sample complexity\nmeasures that exploit $T$'s Toeplitz structure, and by doing so, significantly\nimprove on results for generic covariance matrices. Our bounds follow from a\nnovel analysis of classical and widely used estimation algorithms (along with\nsome new variants), including methods based on selecting entries from each\nvector sample according to a so-called sparse ruler. In many cases, we pair our\nupper bounds with matching or nearly matching lower bounds.\n  In addition to results that hold for any Toeplitz $T$, we further study the\nimportant setting when $T$ is close to low-rank, which is often the case in\npractice. We show that methods based on sparse rulers perform even better in\nthis setting, with sample complexity scaling sublinearly in $d$. Motivated by\nthis finding, we develop a new covariance estimation strategy that further\nimproves on all existing methods in the low-rank case: when $T$ is rank-$k$ or\nnearly rank-$k$, it achieves sample complexity depending polynomially on $k$\nand only logarithmically on $d$.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:34:58 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 20:37:26 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 15:11:34 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 12:43:44 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 05:47:07 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Eldar", "Yonina C.", ""], ["Li", "Jerry", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""]]}, {"id": "1905.05644", "submitter": "Fei Mi", "authors": "Fei Mi, Minlie Huang, Jiyong Zhang, Boi Faltings", "title": "Meta-Learning for Low-resource Natural Language Generation in\n  Task-oriented Dialogue Systems", "comments": "Accepted as a full paper at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is an essential component of task-oriented\ndialogue systems. Despite the recent success of neural approaches for NLG, they\nare typically developed for particular domains with rich annotated training\nexamples. In this paper, we study NLG in a low-resource setting to generate\nsentences in new scenarios with handful training examples. We formulate the\nproblem from a meta-learning perspective, and propose a generalized\noptimization-based approach (Meta-NLG) based on the well-recognized\nmodel-agnostic meta-learning (MAML) algorithm. Meta-NLG defines a set of meta\ntasks, and directly incorporates the objective of adapting to new low-resource\nNLG tasks into the meta-learning optimization process. Extensive experiments\nare conducted on a large multi-domain dataset (MultiWoz) with diverse\nlinguistic variations. We show that Meta-NLG significantly outperforms other\ntraining procedures in various low-resource configurations. We analyze the\nresults, and demonstrate that Meta-NLG adapts extremely fast and well to\nlow-resource situations.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:35:06 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mi", "Fei", ""], ["Huang", "Minlie", ""], ["Zhang", "Jiyong", ""], ["Faltings", "Boi", ""]]}, {"id": "1905.05659", "submitter": "Guoxian Yu", "authors": "Xia Chen, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Zhao Li and\n  Xiangliang Zhang", "title": "ActiveHNE: Active Heterogeneous Network Embedding", "comments": "Accepted to IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous network embedding (HNE) is a challenging task due to the\ndiverse node types and/or diverse relationships between nodes. Existing HNE\nmethods are typically unsupervised. To maximize the profit of utilizing the\nrare and valuable supervised information in HNEs, we develop a novel Active\nHeterogeneous Network Embedding (ActiveHNE) framework, which includes two\ncomponents: Discriminative Heterogeneous Network Embedding (DHNE) and Active\nQuery in Heterogeneous Networks (AQHN). In DHNE, we introduce a novel\nsemi-supervised heterogeneous network embedding method based on graph\nconvolutional neural network. In AQHN, we first introduce three active\nselection strategies based on uncertainty and representativeness, and then\nderive a batch selection method that assembles these strategies using a\nmulti-armed bandit mechanism. ActiveHNE aims at improving the performance of\nHNE by feeding the most valuable supervision obtained by AQHN into DHNE.\nExperiments on public datasets demonstrate the effectiveness of ActiveHNE and\nits advantage on reducing the query cost.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:10:35 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:11:48 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Chen", "Xia", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Li", "Zhao", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.05667", "submitter": "Julio Omar Palacio Ni\\~no", "authors": "Julio-Omar Palacio-Ni\\~no, Fernando Berzal", "title": "Evaluation Metrics for Unsupervised Learning Algorithms", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Determining the quality of the results obtained by clustering techniques is a\nkey issue in unsupervised machine learning. Many authors have discussed the\ndesirable features of good clustering algorithms. However, Jon Kleinberg\nestablished an impossibility theorem for clustering. As a consequence, a wealth\nof studies have proposed techniques to evaluate the quality of clustering\nresults depending on the characteristics of the clustering problem and the\nalgorithmic technique employed to cluster data.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:27:46 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:36:30 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Palacio-Ni\u00f1o", "Julio-Omar", ""], ["Berzal", "Fernando", ""]]}, {"id": "1905.05679", "submitter": "Pravesh K Kothari", "authors": "Sushrut Karmalkar, Adam R. Klivans, Pravesh K. Kothari", "title": "List-Decodable Linear Regression", "comments": "28 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time algorithm for robust regression in the\nlist-decodable setting where an adversary can corrupt a greater than $1/2$\nfraction of examples.\n  For any $\\alpha < 1$, our algorithm takes as input a sample $\\{(x_i,y_i)\\}_{i\n\\leq n}$ of $n$ linear equations where $\\alpha n$ of the equations satisfy $y_i\n= \\langle x_i,\\ell^*\\rangle +\\zeta$ for some small noise $\\zeta$ and\n$(1-\\alpha)n$ of the equations are {\\em arbitrarily} chosen. It outputs a list\n$L$ of size $O(1/\\alpha)$ - a fixed constant - that contains an $\\ell$ that is\nclose to $\\ell^*$.\n  Our algorithm succeeds whenever the inliers are chosen from a\n\\emph{certifiably} anti-concentrated distribution $D$. In particular, this\ngives a $(d/\\alpha)^{O(1/\\alpha^8)}$ time algorithm to find a $O(1/\\alpha)$\nsize list when the inlier distribution is standard Gaussian. For discrete\nproduct distributions that are anti-concentrated only in \\emph{regular}\ndirections, we give an algorithm that achieves similar guarantee under the\npromise that $\\ell^*$ has all coordinates of the same magnitude. To complement\nour result, we prove that the anti-concentration assumption on the inliers is\ninformation-theoretically necessary.\n  Our algorithm is based on a new framework for list-decodable learning that\nstrengthens the `identifiability to algorithms' paradigm based on the\nsum-of-squares method.\n  In an independent and concurrent work, Raghavendra and Yau also used the\nSum-of-Squares method to give a similar result for list-decodable regression.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:43:33 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 22:41:10 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 04:45:23 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Karmalkar", "Sushrut", ""], ["Klivans", "Adam R.", ""], ["Kothari", "Pravesh K.", ""]]}, {"id": "1905.05686", "submitter": "Dongsoo Lee", "authors": "Dongsoo Lee, Se Jung Kwon, Byeongwook Kim, Parichay Kapoor, Gu-Yeon\n  Wei", "title": "Network Pruning for Low-Rank Binary Indexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is an efficient model compression technique to remove redundancy in\nthe connectivity of deep neural networks (DNNs). Computations using sparse\nmatrices obtained by pruning parameters, however, exhibit vastly different\nparallelism depending on the index representation scheme. As a result,\nfine-grained pruning has not gained much attention due to its irregular index\nform leading to large memory footprint and low parallelism for convolutions and\nmatrix multiplications. In this paper, we propose a new network pruning\ntechnique that generates a low-rank binary index matrix to compress index data\nwhile decompressing index data is performed by simple binary matrix\nmultiplication. This proposed compression method finds a particular\nfine-grained pruning mask that can be decomposed into two binary matrices. We\nalso propose a tile-based factorization technique that not only lowers memory\nrequirements but also enhances compression ratio. Various DNN models can be\npruned with much fewer indexes compared to previous sparse matrix formats while\nmaintaining the same pruning rate.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:00:41 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Kapoor", "Parichay", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1905.05699", "submitter": "Adem Tekerek", "authors": "Baris Baburoglu, Adem Tekerek, Mehmet Tekerek", "title": "Development of Deep Learning Based Natural Language Processing Model for\n  Turkish", "comments": "8 pages, in Turkish, 5 figures, ICITS 2019 02-04 May 2019\n  K{\\i}r\\c{s}ehir T\\\"urkiye", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Natural language is one of the most fundamental features that distinguish\npeople from other living things and enable people to communicate each other.\nLanguage is a tool that enables people to express their feelings and thoughts\nand to transfers cultures through generations. Texts and audio are examples of\nnatural language in daily life. In the natural language, many words disappear\nin time, on the other hand new words are derived. Therefore, while the process\nof natural language processing (NLP) is complex even for human, it is difficult\nto process in computer system. The area of linguistics examines how people use\nlanguage. NLP, which requires the collaboration of linguists and computer\nscientists, plays an important role in human computer interaction. Studies in\nNLP have increased with the use of artificial intelligence technologies in the\nfield of linguistics. With the deep learning methods which are one of the\nartificial intelligence study areas, platforms close to natural language are\nbeing developed. Developed platforms for language comprehension, machine\ntranslation and part of speech (POS) tagging benefit from deep learning\nmethods. Recurrent Neural Network (RNN), one of the deep learning\narchitectures, is preferred for processing sequential data such as text or\naudio data. In this study, Turkish POS tagging model has been proposed by using\nBidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed\nPOS tagging model is provided to natural language researchers with a platform\nthat allows them to perform and use their own analysis. In the development\nphase of the platform developed by using BLSTM, the error rate of the POS\ntagger has been reduced by taking feedback with expert opinion.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 21:09:49 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Baburoglu", "Baris", ""], ["Tekerek", "Adem", ""], ["Tekerek", "Mehmet", ""]]}, {"id": "1905.05700", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Omar M. Ibrahime, Taha M. Madbouly, Moustafa A.\n  Mahmoud", "title": "Learning meters of Arabic and English poems with Recurrent Neural\n  Networks: a step forward for language understanding and synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing a piece of writing as a poem or prose is usually easy for the\nmajority of people; however, only specialists can determine which meter a poem\nbelongs to. In this paper, we build Recurrent Neural Network (RNN) models that\ncan classify poems according to their meters from plain text. The input text is\nencoded at the character level and directly fed to the models without feature\nhandcrafting. This is a step forward for machine understanding and synthesis of\nlanguages in general, and Arabic language in particular. Among the 16 poem\nmeters of Arabic and the 4 meters of English the networks were able to\ncorrectly classify poem with an overall accuracy of 96.38\\% and 82.31\\%\nrespectively. The poem datasets used to conduct this research were massive,\nover 1.5 million of verses, and were crawled from different nontechnical\nsources, almost Arabic and English literature sites, and in different\nheterogeneous and unstructured formats. These datasets are now made publicly\navailable in clean, structured, and documented format for other future\nresearch. To the best of the authors' knowledge, this research is the first to\naddress classifying poem meters in a machine learning approach, in general, and\nin RNN featureless based approach, in particular. In addition, the dataset is\nthe first publicly available dataset ready for the purpose of future\ncomputational research.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 21:14:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Ibrahime", "Omar M.", ""], ["Madbouly", "Taha M.", ""], ["Mahmoud", "Moustafa A.", ""]]}, {"id": "1905.05701", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe\n  Riccardi", "title": "Modeling user context for valence prediction from narratives", "comments": "To be published in Interspeech 2019", "journal-ref": "Interspeech 2019", "doi": "10.21437/Interspeech.2019-2489", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated prediction of valence, one key feature of a person's emotional\nstate, from individuals' personal narratives may provide crucial information\nfor mental healthcare (e.g. early diagnosis of mental diseases, supervision of\ndisease course, etc.). In the Interspeech 2018 ComParE Self-Assessed Affect\nchallenge, the task of valence prediction was framed as a three-class\nclassification problem using 8 seconds fragments from individuals' narratives.\nAs such, the task did not allow for exploring contextual information of the\nnarratives. In this work, we investigate the intrinsic information from\nmultiple narratives recounted by the same individual in order to predict their\ncurrent state-of-mind. Furthermore, with generalizability in mind, we decided\nto focus our experiments exclusively on textual information as the public\navailability of audio narratives is limited compared to text. Our hypothesis\nis, that context modeling might provide insights about emotion triggering\nconcepts (e.g. events, people, places) mentioned in the narratives that are\nlinked to an individual's state of mind. We explore multiple machine learning\ntechniques to model narratives. We find that the models are able to capture\ninter-individual differences, leading to more accurate predictions of an\nindividual's emotional state, as compared to single narratives.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:57:14 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 15:03:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Messner", "Eva-Maria", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1905.05702", "submitter": "Ben Peters", "authors": "Ben Peters, Vlad Niculae and Andr\\'e F.T. Martins", "title": "Sparse Sequence-to-Sequence Models", "comments": "ACL 2019 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models are a powerful workhorse of NLP. Most variants\nemploy a softmax transformation in both their attention mechanism and output\nlayer, leading to dense alignments and strictly positive output probabilities.\nThis density is wasteful, making models less interpretable and assigning\nprobability mass to many implausible outputs. In this paper, we propose sparse\nsequence-to-sequence models, rooted in a new family of $\\alpha$-entmax\ntransformations, which includes softmax and sparsemax as particular cases, and\nis sparse for any $\\alpha > 1$. We provide fast algorithms to evaluate these\ntransformations and their gradients, which scale well for large vocabulary\nsizes. Our models are able to produce sparse alignments and to assign nonzero\nprobability to a short list of plausible outputs, sometimes rendering beam\nsearch exact. Experiments on morphological inflection and machine translation\nreveal consistent gains over dense models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:21:34 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 18:20:25 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Peters", "Ben", ""], ["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1905.05704", "submitter": "Felipe Salvatore", "authors": "Felipe Salvatore, Marcelo Finger, Roberto Hirata Jr", "title": "A logical-based corpus for cross-lingual evaluation", "comments": "To appear in the proceedings of the Deep Learning for low-resource\n  NLP (DeepLo) workshop at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At present, different deep learning models are presenting high accuracy on\npopular inference datasets such as SNLI, MNLI, and SciTail. However, there are\ndifferent indicators that those datasets can be exploited by using some simple\nlinguistic patterns. This fact poses difficulties to our understanding of the\nactual capacity of machine learning models to solve the complex task of textual\ninference. We propose a new set of syntactic tasks focused on contradiction\ndetection that require specific capacities over linguistic logical forms such\nas: Boolean coordination, quantifiers, definite description, and counting\noperators. We evaluate two kinds of deep learning models that implicitly\nexploit language structure: recurrent models and the Transformer network BERT.\nWe show that although BERT is clearly more efficient to generalize over most\nlogical forms, there is space for improvement when dealing with counting\noperators. Since the syntactic tasks can be implemented in different languages,\nwe show a successful case of cross-lingual transfer learning between English\nand Portuguese.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:39:55 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:39:36 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:03:10 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2019 17:12:55 GMT"}, {"version": "v5", "created": "Thu, 24 Oct 2019 00:15:50 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Salvatore", "Felipe", ""], ["Finger", "Marcelo", ""], ["Hirata", "Roberto", "Jr"]]}, {"id": "1905.05710", "submitter": "Andreas Doerr", "authors": "Andreas Doerr, Michael Volpp, Marc Toussaint, Sebastian Trimpe,\n  Christian Daniel", "title": "Trajectory-Based Off-Policy Deep Reinforcement Learning", "comments": "Includes appendix. Accepted for ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are powerful reinforcement learning algorithms and\nhave been demonstrated to solve many complex tasks. However, these methods are\nalso data-inefficient, afflicted with high variance gradient estimates, and\nfrequently get stuck in local optima. This work addresses these weaknesses by\ncombining recent improvements in the reuse of off-policy data and exploration\nin parameter space with deterministic behavioral policies. The resulting\nobjective is amenable to standard neural network optimization strategies like\nstochastic gradient descent or stochastic gradient Hamiltonian Monte Carlo.\nIncorporation of previous rollouts via importance sampling greatly improves\ndata-efficiency, whilst stochastic optimization schemes facilitate the escape\nfrom local optima. We evaluate the proposed approach on a series of continuous\ncontrol benchmark tasks. The results show that the proposed algorithm is able\nto successfully and reliably learn solutions using fewer system interactions\nthan standard policy gradient methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:35:00 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Doerr", "Andreas", ""], ["Volpp", "Michael", ""], ["Toussaint", "Marc", ""], ["Trimpe", "Sebastian", ""], ["Daniel", "Christian", ""]]}, {"id": "1905.05715", "submitter": "Matteo Interlandi", "authors": "Zeeshan Ahmed, Saeed Amizadeh, Mikhail Bilenko, Rogan Carr, Wei-Sheng\n  Chin, Yael Dekel, Xavier Dupre, Vadim Eksarevskiy, Eric Erhardt, Costin\n  Eseanu, Senja Filipi, Tom Finley, Abhishek Goswami, Monte Hoover, Scott\n  Inglis, Matteo Interlandi, Shon Katzenberger, Najeeb Kazmi, Gleb Krivosheev,\n  Pete Luferenko, Ivan Matantsev, Sergiy Matusevych, Shahab Moradi, Gani\n  Nazirov, Justin Ormont, Gal Oshri, Artidoro Pagnoni, Jignesh Parmar, Prabhat\n  Roy, Sarthak Shah, Mohammad Zeeshan Siddiqui, Markus Weimer, Shauheen\n  Zahirazami, Yiwen Zhu", "title": "Machine Learning at Microsoft with ML .NET", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330667", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning is transitioning from an art and science into a technology\navailable to every developer. In the near future, every application on every\nplatform will incorporate trained models to encode data-based decisions that\nwould be impossible for developers to author. This presents a significant\nengineering challenge, since currently data science and modeling are largely\ndecoupled from standard software development processes. This separation makes\nincorporating machine learning capabilities inside applications unnecessarily\ncostly and difficult, and furthermore discourage developers from embracing ML\nin first place. In this paper we present ML .NET, a framework developed at\nMicrosoft over the last decade in response to the challenge of making it easy\nto ship machine learning models in large software applications. We present its\narchitecture, and illuminate the application demands that shaped it.\nSpecifically, we introduce DataView, the core data abstraction of ML .NET which\nallows it to capture full predictive pipelines efficiently and consistently\nacross training and inference lifecycles. We close the paper with a\nsurprisingly favorable performance study of ML .NET compared to more recent\nentrants, and a discussion of some lessons learned.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:43:16 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 19:12:02 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ahmed", "Zeeshan", ""], ["Amizadeh", "Saeed", ""], ["Bilenko", "Mikhail", ""], ["Carr", "Rogan", ""], ["Chin", "Wei-Sheng", ""], ["Dekel", "Yael", ""], ["Dupre", "Xavier", ""], ["Eksarevskiy", "Vadim", ""], ["Erhardt", "Eric", ""], ["Eseanu", "Costin", ""], ["Filipi", "Senja", ""], ["Finley", "Tom", ""], ["Goswami", "Abhishek", ""], ["Hoover", "Monte", ""], ["Inglis", "Scott", ""], ["Interlandi", "Matteo", ""], ["Katzenberger", "Shon", ""], ["Kazmi", "Najeeb", ""], ["Krivosheev", "Gleb", ""], ["Luferenko", "Pete", ""], ["Matantsev", "Ivan", ""], ["Matusevych", "Sergiy", ""], ["Moradi", "Shahab", ""], ["Nazirov", "Gani", ""], ["Ormont", "Justin", ""], ["Oshri", "Gal", ""], ["Pagnoni", "Artidoro", ""], ["Parmar", "Jignesh", ""], ["Roy", "Prabhat", ""], ["Shah", "Sarthak", ""], ["Siddiqui", "Mohammad Zeeshan", ""], ["Weimer", "Markus", ""], ["Zahirazami", "Shauheen", ""], ["Zhu", "Yiwen", ""]]}, {"id": "1905.05717", "submitter": "Hua Wei", "authors": "Hua Wei, Nan Xu, Huichu Zhang, Guanjie Zheng, Xinshi Zang, Chacha\n  Chen, Weinan Zhang, Yanmin Zhu, Kai Xu, Zhenhui Li", "title": "CoLight: Learning Network-level Cooperation for Traffic Signal Control", "comments": "10 pages. Proceedings of the 28th ACM International on Conference on\n  Information and Knowledge Management. ACM, 2018", "journal-ref": null, "doi": "10.1145/3357384.3357902", "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation among the traffic signals enables vehicles to move through\nintersections more quickly. Conventional transportation approaches implement\ncooperation by pre-calculating the offsets between two intersections. Such\npre-calculated offsets are not suitable for dynamic traffic environments. To\nenable cooperation of traffic signals, in this paper, we propose a model,\nCoLight, which uses graph attentional networks to facilitate communication.\nSpecifically, for a target intersection in a network, CoLight can not only\nincorporate the temporal and spatial influences of neighboring intersections to\nthe target intersection, but also build up index-free modeling of neighboring\nintersections. To the best of our knowledge, we are the first to use graph\nattentional networks in the setting of reinforcement learning for traffic\nsignal control and to conduct experiments on the large-scale road network with\nhundreds of traffic signals. In experiments, we demonstrate that by learning\nthe communication, the proposed model can achieve superior performance against\nthe state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:26:11 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 09:17:57 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wei", "Hua", ""], ["Xu", "Nan", ""], ["Zhang", "Huichu", ""], ["Zheng", "Guanjie", ""], ["Zang", "Xinshi", ""], ["Chen", "Chacha", ""], ["Zhang", "Weinan", ""], ["Zhu", "Yanmin", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.05731", "submitter": "Rahul Ramesh", "authors": "Rahul Ramesh, Manan Tomar and Balaraman Ravindran", "title": "Successor Options: An Option Discovery Framework for Reinforcement\n  Learning", "comments": "To appear in the proceedings of the International Joint Conference on\n  Artificial Intelligence 2019 (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The options framework in reinforcement learning models the notion of a skill\nor a temporally extended sequence of actions. The discovery of a reusable set\nof skills has typically entailed building options, that navigate to bottleneck\nstates. This work adopts a complementary approach, where we attempt to discover\noptions that navigate to landmark states. These states are prototypical\nrepresentatives of well-connected regions and can hence access the associated\nregion with relative ease. In this work, we propose Successor Options, which\nleverages Successor Representations to build a model of the state space. The\nintra-option policies are learnt using a novel pseudo-reward and the model\nscales to high-dimensional spaces easily. Additionally, we also propose an\nIncremental Successor Options model that iterates between constructing\nSuccessor Representations and building options, which is useful when robust\nSuccessor Representations cannot be built solely from primitive actions. We\ndemonstrate the efficacy of our approach on a collection of grid-worlds, and on\nthe high-dimensional robotic control environment of Fetch.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:24:11 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ramesh", "Rahul", ""], ["Tomar", "Manan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1905.05733", "submitter": "Shehzaad Dhuliawala", "authors": "Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Andrew McCallum", "title": "Multi-step Retriever-Reader Interaction for Scalable Open-domain\n  Question Answering", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for open-domain question answering in\nwhich the retriever and the reader iteratively interact with each other. The\nframework is agnostic to the architecture of the machine reading model, only\nrequiring access to the token-level hidden representations of the reader. The\nretriever uses fast nearest neighbor search to scale to corpora containing\nmillions of paragraphs. A gated recurrent unit updates the query at each step\nconditioned on the state of the reader and the reformulated query is used to\nre-rank the paragraphs by the retriever. We conduct analysis and show that\niterative interaction helps in retrieving informative paragraphs from the\ncorpus. Finally, we show that our multi-step-reasoning framework brings\nconsistent improvement when applied to two widely used reader architectures\nDrQA and BiDAF on various large open-domain datasets --- TriviaQA-unfiltered,\nQuasarT, SearchQA, and SQuAD-Open.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:27:08 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Das", "Rajarshi", ""], ["Dhuliawala", "Shehzaad", ""], ["Zaheer", "Manzil", ""], ["McCallum", "Andrew", ""]]}, {"id": "1905.05738", "submitter": "Nikhil Mehta", "authors": "Nikhil Mehta, Lawrence Carin, Piyush Rai", "title": "Stochastic Blockmodels meet Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic blockmodels (SBM) and their variants, $e.g.$, mixed-membership and\noverlapping stochastic blockmodels, are latent variable based generative models\nfor graphs. They have proven to be successful for various tasks, such as\ndiscovering the community structure and link prediction on graph-structured\ndata. Recently, graph neural networks, $e.g.$, graph convolutional networks,\nhave also emerged as a promising approach to learn powerful representations\n(embeddings) for the nodes in the graph, by exploiting graph properties such as\nlocality and invariance. In this work, we unify these two directions by\ndeveloping a \\emph{sparse} variational autoencoder for graphs, that retains the\ninterpretability of SBMs, while also enjoying the excellent predictive\nperformance of graph neural nets. Moreover, our framework is accompanied by a\nfast recognition model that enables fast inference of the node embeddings\n(which are of independent interest for inference in SBM and its variants).\nAlthough we develop this framework for a particular type of SBM, namely the\n\\emph{overlapping} stochastic blockmodel, the proposed framework can be adapted\nreadily for other types of SBMs. Experimental results on several benchmarks\ndemonstrate encouraging results on link prediction while learning an\ninterpretable latent structure that can be used for community discovery.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:32:12 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Mehta", "Nikhil", ""], ["Carin", "Lawrence", ""], ["Rai", "Piyush", ""]]}, {"id": "1905.05739", "submitter": "Ben Glocker", "authors": "Ian Walker and Ben Glocker", "title": "Graph Convolutional Gaussian Processes", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian nonparametric method to learn\ntranslation-invariant relationships on non-Euclidean domains. The resulting\ngraph convolutional Gaussian processes can be applied to problems in machine\nlearning for which the input observations are functions with domains on general\ngraphs. The structure of these models allows for high dimensional inputs while\nretaining expressibility, as is the case with convolutional neural networks. We\npresent applications of graph convolutional Gaussian processes to images and\ntriangular meshes, demonstrating their versatility and effectiveness, comparing\nfavorably to existing methods, despite being relatively simple models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:32:29 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Walker", "Ian", ""], ["Glocker", "Ben", ""]]}, {"id": "1905.05749", "submitter": "Lukas Mosser", "authors": "Lukas Mosser, Olivier Dubrule, Martin J. Blunt", "title": "DeepFlow: History Matching in the Space of Deep Generative Models", "comments": "25 pages, 15 figures, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.comp-ph physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The calibration of a reservoir model with observed transient data of fluid\npressures and rates is a key task in obtaining a predictive model of the flow\nand transport behaviour of the earth's subsurface. The model calibration task,\ncommonly referred to as \"history matching\", can be formalised as an ill-posed\ninverse problem where we aim to find the underlying spatial distribution of\npetrophysical properties that explain the observed dynamic data. We use a\ngenerative adversarial network pretrained on geostatistical object-based models\nto represent the distribution of rock properties for a synthetic model of a\nhydrocarbon reservoir. The dynamic behaviour of the reservoir fluids is\nmodelled using a transient two-phase incompressible Darcy formulation. We\ninvert for the underlying reservoir properties by first modeling property\ndistributions using the pre-trained generative model then using the adjoint\nequations of the forward problem to perform gradient descent on the latent\nvariables that control the output of the generative model. In addition to the\ndynamic observation data, we include well rock-type constraints by introducing\nan additional objective function. Our contribution shows that for a synthetic\ntest case, we are able to obtain solutions to the inverse problem by optimising\nin the latent variable space of a deep generative model, given a set of\ntransient observations of a non-linear forward problem.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:52:52 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 12:49:02 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Mosser", "Lukas", ""], ["Dubrule", "Olivier", ""], ["Blunt", "Martin J.", ""]]}, {"id": "1905.05761", "submitter": "Shiliang Sun", "authors": "Jingjing Fei, Shiliang Sun", "title": "Online Anomaly Detection with Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online anomaly detection of time-series data is an important and challenging\ntask in machine learning. Gaussian processes (GPs) are powerful and flexible\nmodels for modeling time-series data. However, the high time complexity of GPs\nlimits their applications in online anomaly detection. Attributed to some\ninternal or external changes, concept drift usually occurs in time-series data,\nwhere the characteristics of data and meanings of abnormal behaviors alter over\ntime. Online anomaly detection methods should have the ability to adapt to\nconcept drift. Motivated by the above facts, this paper proposes the method of\nsparse Gaussian processes with Q-function (SGP-Q). The SGP-Q employs sparse\nGaussian processes (SGPs) whose time complexity is lower than that of GPs, thus\nsignificantly speeding up online anomaly detection. By using Q-function\nproperly, the SGP-Q can adapt to concept drift well. Moreover, the SGP-Q makes\nuse of few abnormal data in the training data by its strategy of updating\ntraining data, resulting in more accurate sparse Gaussian process regression\nmodels and better anomaly detection results. We evaluate the SGP-Q on various\nartificial and real-world datasets. Experimental results validate the\neffectiveness of the SGP-Q.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:42:58 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Fei", "Jingjing", ""], ["Sun", "Shiliang", ""]]}, {"id": "1905.05774", "submitter": "Samarth Tripathi", "authors": "Samarth Tripathi, Jiayi Liu, Unmesh Kurup, Mohak Shah, Sauptik Dhar", "title": "Improving Model Training by Periodic Sampling over Weight Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore techniques centered around periodic sampling of\nmodel weights that provide convergence improvements on gradient update methods\n(vanilla \\acs{SGD}, Momentum, Adam) for a variety of vision problems\n(classification, detection, segmentation). Importantly, our algorithms provide\nbetter, faster and more robust convergence and training performance with only a\nslight increase in computation time. Our techniques are independent of the\nneural network model, gradient optimization methods or existing optimal\ntraining policies and converge in a less volatile fashion with performance\nimprovements that are approximately monotonic. We conduct a variety of\nexperiments to quantify these improvements and identify scenarios where these\ntechniques could be more useful.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:00:23 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 21:37:12 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Tripathi", "Samarth", ""], ["Liu", "Jiayi", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""], ["Dhar", "Sauptik", ""]]}, {"id": "1905.05778", "submitter": "Shi Feng", "authors": "Shi Feng, Eric Wallace, Jordan Boyd-Graber", "title": "Misleading Failures of Partial-input Baselines", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work establishes dataset difficulty and removes annotation artifacts\nvia partial-input baselines (e.g., hypothesis-only models for SNLI or\nquestion-only models for VQA). When a partial-input baseline gets high\naccuracy, a dataset is cheatable. However, the converse is not necessarily\ntrue: the failure of a partial-input baseline does not mean a dataset is free\nof artifacts. To illustrate this, we first design artificial datasets which\ncontain trivial patterns in the full input that are undetectable by any\npartial-input model. Next, we identify such artifacts in the SNLI dataset - a\nhypothesis-only model augmented with trivial patterns in the premise can solve\n15% of the examples that are previously considered \"hard\". Our work provides a\ncaveat for the use of partial-input baselines for dataset verification and\ncreation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:01:41 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:39:20 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 17:07:09 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Feng", "Shi", ""], ["Wallace", "Eric", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1905.05786", "submitter": "Joymallya Chakraborty Mr.", "authors": "Joymallya Chakraborty, Tianpei Xia, Fahmid M. Fahid, Tim Menzies", "title": "Software Engineering for Fairness: A Case Study with Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assert that it is the ethical duty of software engineers to strive to\nreduce software discrimination. This paper discusses how that might be done.\nThis is an important topic since machine learning software is increasingly\nbeing used to make decisions that affect people's lives. Potentially, the\napplication of that software will result in fairer decisions because (unlike\nhumans) machine learning software is not biased. However, recent results show\nthat the software within many data mining packages exhibits \"group\ndiscrimination\"; i.e. their decisions are inappropriately affected by\n\"protected attributes\"(e.g., race, gender, age, etc.).\n  There has been much prior work on validating the fairness of machine-learning\nmodels (by recognizing when such software discrimination exists). But after\ndetection, comes mitigation. What steps can ethical software engineers take to\nreduce discrimination in the software they produce?\n  This paper shows that making \\textit{fairness} as a goal during\nhyperparameter optimization can (a) preserve the predictive power of a model\nlearned from a data miner while also (b) generates fairer results. To the best\nof our knowledge, this is the first application of hyperparameter optimization\nas a tool for software engineers to generate fairer software.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:23:39 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 15:06:13 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Chakraborty", "Joymallya", ""], ["Xia", "Tianpei", ""], ["Fahid", "Fahmid M.", ""], ["Menzies", "Tim", ""]]}, {"id": "1905.05787", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Yao Liu, Scott Sussex, Emma Brunskill, Finale\n  Doshi-Velez", "title": "Combining Parametric and Nonparametric Models for Off-Policy Evaluation", "comments": null, "journal-ref": "PMLR 97:2366-2375, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model-based approach to perform batch off-policy evaluation in\nreinforcement learning. Our method takes a mixture-of-experts approach to\ncombine parametric and non-parametric models of the environment such that the\nfinal value estimate has the least expected error. We do so by first estimating\nthe local accuracy of each model and then using a planner to select which model\nto use at every time step as to minimize the return error estimate along entire\ntrajectories. Across a variety of domains, our mixture-based approach\noutperforms the individual models alone as well as state-of-the-art importance\nsampling-based estimators.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:39:26 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 00:37:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gottesman", "Omer", ""], ["Liu", "Yao", ""], ["Sussex", "Scott", ""], ["Brunskill", "Emma", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1905.05809", "submitter": "Dennis Soemers", "authors": "Dennis J. N. J. Soemers, \\'Eric Piette, Matthew Stephenson, Cameron\n  Browne", "title": "Learning Policies from Self-Play with Policy Gradients and MCTS Value\n  Estimates", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, state-of-the-art game-playing agents often involve policies\nthat are trained in self-playing processes where Monte Carlo tree search (MCTS)\nalgorithms and trained policies iteratively improve each other. The strongest\nresults have been obtained when policies are trained to mimic the search\nbehaviour of MCTS by minimising a cross-entropy loss. Because MCTS, by design,\nincludes an element of exploration, policies trained in this manner are also\nlikely to exhibit a similar extent of exploration. In this paper, we are\ninterested in learning policies for a project with future goals including the\nextraction of interpretable strategies, rather than state-of-the-art\ngame-playing performance. For these goals, we argue that such an extent of\nexploration is undesirable, and we propose a novel objective function for\ntraining policies that are not exploratory. We derive a policy gradient\nexpression for maximising this objective function, which can be estimated using\nMCTS value estimates, rather than MCTS visit counts. We empirically evaluate\nvarious properties of resulting policies, in a variety of board games.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 19:33:45 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Browne", "Cameron", ""]]}, {"id": "1905.05824", "submitter": "Michael Oberst", "authors": "Michael Oberst, David Sontag", "title": "Counterfactual Off-Policy Evaluation with Gumbel-Max Structural Causal\n  Models", "comments": "To appear in ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:4881-4890, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an off-policy evaluation procedure for highlighting episodes\nwhere applying a reinforcement learned (RL) policy is likely to have produced a\nsubstantially different outcome than the observed policy. In particular, we\nintroduce a class of structural causal models (SCMs) for generating\ncounterfactual trajectories in finite partially observable Markov Decision\nProcesses (POMDPs). We see this as a useful procedure for off-policy\n\"debugging\" in high-risk settings (e.g., healthcare); by decomposing the\nexpected difference in reward between the RL and observed policy into specific\nepisodes, we can identify episodes where the counterfactual difference in\nreward is most dramatic. This in turn can be used to facilitate review of\nspecific episodes by domain experts. We demonstrate the utility of this\nprocedure with a synthetic environment of sepsis management.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:18:31 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:36:45 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 19:47:48 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Oberst", "Michael", ""], ["Sontag", "David", ""]]}, {"id": "1905.05833", "submitter": "Juan Irving Vasquez-Gomez", "authors": "Miguel Mendoza, J. Irving Vasquez-Gomez, Hind Taud, Luis Enrique\n  Sucar, Carolina Reta", "title": "Supervised Learning of the Next-Best-View for 3D Object Reconstruction", "comments": "Under review in Pattern Recognition Letters", "journal-ref": "Pattern Recognition Letters, Volume 133, 2020, Pages 224-231, ISSN\n  0167-8655", "doi": "10.1016/j.patrec.2020.02.024", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the advances in 3D sensing technology and the spreading of\nlow-cost robotic platforms, 3D object reconstruction has become a common task\nin many areas. Nevertheless, the selection of the optimal sensor pose that\nmaximizes the reconstructed surface is a problem that remains open. It is known\nin the literature as the next-best-view planning problem. In this paper, we\npropose a novel next-best-view planning scheme based on supervised deep\nlearning. The scheme contains an algorithm for automatic generation of datasets\nand an original three-dimensional convolutional neural network (3D-CNN) used to\nlearn the next-best-view. Unlike previous work where the problem is addressed\nas a search, the trained 3D-CNN directly predicts the sensor pose. We present a\ncomparison of the proposed network against a similar net, and we present\nseveral experiments of the reconstruction of unknown objects validating the\neffectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:39:38 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Mendoza", "Miguel", ""], ["Vasquez-Gomez", "J. Irving", ""], ["Taud", "Hind", ""], ["Sucar", "Luis Enrique", ""], ["Reta", "Carolina", ""]]}, {"id": "1905.05839", "submitter": "Ilya Amburg", "authors": "Ilya Amburg, Jon Kleinberg, Austin R. Benson", "title": "Planted Hitting Set Recovery in Hypergraphs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various application areas, networked data is collected by measuring\ninteractions involving some specific set of core nodes. This results in a\nnetwork dataset containing the core nodes along with a potentially much larger\nset of fringe nodes that all have at least one interaction with a core node. In\nmany settings, this type of data arises for structures that are richer than\ngraphs, because they involve the interactions of larger sets; for example, the\ncore nodes might be a set of individuals under surveillance, where we observe\nthe attendees of meetings involving at least one of the core individuals. We\nmodel such scenarios using hypergraphs, and we study the problem of core\nrecovery: if we observe the hypergraph but not the labels of core and fringe\nnodes, can we recover the \"planted\" set of core nodes in the hypergraph?\n  We provide a theoretical framework for analyzing the recovery of such a set\nof core nodes and use our theory to develop a practical and scalable algorithm\nfor core recovery. The crux of our analysis and algorithm is that the core\nnodes are a hitting set of the hypergraph, meaning that every hyperedge has at\nleast one node in the set of core nodes. We demonstrate the efficacy of our\nalgorithm on a number of real-world datasets, outperforming competitive\nbaselines derived from network centrality and core-periphery measures.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 20:57:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Amburg", "Ilya", ""], ["Kleinberg", "Jon", ""], ["Benson", "Austin R.", ""]]}, {"id": "1905.05840", "submitter": "Yan-Li Liu", "authors": "Yan-li Liu and Chu-min Li and Hua Jiang and Kun He", "title": "A Learning based Branch and Bound for Maximum Common Subgraph Problems", "comments": "6 pages, 4 figures, uses ijcai19.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch-and-bound (BnB) algorithms are widely used to solve combinatorial\nproblems, and the performance crucially depends on its branching heuristic.In\nthis work, we consider a typical problem of maximum common subgraph (MCS), and\npropose a branching heuristic inspired from reinforcement learning with a goal\nof reaching a tree leaf as early as possible to greatly reduce the search tree\nsize.Extensive experiments show that our method is beneficial and outperforms\ncurrent best BnB algorithm for the MCS.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 01:37:02 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 01:40:04 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Liu", "Yan-li", ""], ["Li", "Chu-min", ""], ["Jiang", "Hua", ""], ["He", "Kun", ""]]}, {"id": "1905.05843", "submitter": "Siavash Golkar", "authors": "Siavash Golkar and Kyunghyun Cho", "title": "Task-Driven Data Verification via Gradient Descent", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel algorithm for the detection of possible sample\ncorruption such as mislabeled samples in a training dataset given a small clean\nvalidation set. We use a set of inclusion variables which determine whether or\nnot any element of the noisy training set should be included in the training of\na network. We compute these inclusion variables by optimizing the performance\nof the network on the clean validation set via \"gradient descent on gradient\ndescent\" based learning. The inclusion variables as well as the network trained\nin such a way form the basis of our methods, which we call Corruption Detection\nvia Gradient Descent (CDGD). This algorithm can be applied to any supervised\nmachine learning task and is not limited to classification problems. We provide\na quantitative comparison of these methods on synthetic and real world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 21:06:12 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Golkar", "Siavash", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1905.05849", "submitter": "Shaeke Salman", "authors": "Shaeke Salman, Seyedeh Neelufar Payrovnaziri, Xiuwen Liu, Pablo\n  Rengifo-Moreno, Zhe He", "title": "Consensus-based Interpretable Deep Neural Networks with Application to\n  Mortality Prediction", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved remarkable success in various challenging\ntasks. However, the black-box nature of such networks is not acceptable to\ncritical applications, such as healthcare. In particular, the existence of\nadversarial examples and their overgeneralization to irrelevant,\nout-of-distribution inputs with high confidence makes it difficult, if not\nimpossible, to explain decisions by such networks. In this paper, we analyze\nthe underlying mechanism of generalization of deep neural networks and propose\nan ($n$, $k$) consensus algorithm which is insensitive to adversarial examples\nand can reliably reject out-of-distribution samples. Furthermore, the consensus\nalgorithm is able to improve classification accuracy by using multiple trained\ndeep neural networks. To handle the complexity of deep neural networks, we\ncluster linear approximations of individual models and identify highly\ncorrelated clusters among different models to capture feature importance\nrobustly, resulting in improved interpretability. Motivated by the importance\nof building accurate and interpretable prediction models for healthcare, our\nexperimental results on an ICU dataset show the effectiveness of our algorithm\nin enhancing both the prediction accuracy and the interpretability of deep\nneural network models on one-year patient mortality prediction. In particular,\nwhile the proposed method maintains similar interpretability as conventional\nshallow models such as logistic regression, it improves the prediction accuracy\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 21:26:56 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:32:07 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Salman", "Shaeke", ""], ["Payrovnaziri", "Seyedeh Neelufar", ""], ["Liu", "Xiuwen", ""], ["Rengifo-Moreno", "Pablo", ""], ["He", "Zhe", ""]]}, {"id": "1905.05857", "submitter": "Pratik Gajane", "authors": "Pratik Gajane and Ronald Ortner and Peter Auer", "title": "Variational Regret Bounds for Reinforcement Learning", "comments": "Presented at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider undiscounted reinforcement learning in Markov decision processes\n(MDPs) where both the reward functions and the state-transition probabilities\nmay vary (gradually or abruptly) over time. For this problem setting, we\npropose an algorithm and provide performance guarantees for the regret\nevaluated against the optimal non-stationary policy. The upper bound on the\nregret is given in terms of the total variation in the MDP. This is the first\nvariational regret bound for the general reinforcement learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 21:48:52 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 10:57:18 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 12:47:18 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Gajane", "Pratik", ""], ["Ortner", "Ronald", ""], ["Auer", "Peter", ""]]}, {"id": "1905.05865", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Rohan Sangave, Amit Chahar, Parth Shah, Artur\n  Dubrawski, Bhiksha Raj", "title": "Nonlinear Semi-Parametric Models for Survival Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-parametric survival analysis methods like the Cox Proportional Hazards\n(CPH) regression (Cox, 1972) are a popular approach for survival analysis.\nThese methods involve fitting of the log-proportional hazard as a function of\nthe covariates and are convenient as they do not require estimation of the\nbaseline hazard rate. Recent approaches have involved learning non-linear\nrepresentations of the input covariates and demonstrate improved performance.\nIn this paper we argue against such deep parameterizations for survival\nanalysis and experimentally demonstrate that more interpretable semi-parametric\nmodels inspired from mixtures of experts perform equally well or in some cases\nbetter than such overly parameterized deep models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 22:27:09 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Nagpal", "Chirag", ""], ["Sangave", "Rohan", ""], ["Chahar", "Amit", ""], ["Shah", "Parth", ""], ["Dubrawski", "Artur", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1905.05879", "submitter": "Xuesong Yang", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Mark\n  Hasegawa-Johnson", "title": "AUTOVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss", "comments": "To Appear in Thirty-sixth International Conference on Machine\n  Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel many-to-many voice conversion, as well as zero-shot voice\nconversion, remain under-explored areas. Deep style transfer algorithms, such\nas generative adversarial networks (GAN) and conditional variational\nautoencoder (CVAE), are being applied as new solutions in this field. However,\nGAN training is sophisticated and difficult, and there is no strong evidence\nthat its generated speech is of good perceptual quality. On the other hand,\nCVAE training is simple but does not come with the distribution-matching\nproperty of a GAN. In this paper, we propose a new style transfer scheme that\ninvolves only an autoencoder with a carefully designed bottleneck. We formally\nshow that this scheme can achieve distribution-matching style transfer by\ntraining only on a self-reconstruction loss. Based on this scheme, we proposed\nAUTOVC, which achieves state-of-the-art results in many-to-many voice\nconversion with non-parallel data, and which is the first to perform zero-shot\nvoice conversion.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:19:04 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 05:44:48 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Qian", "Kaizhi", ""], ["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Yang", "Xuesong", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1905.05881", "submitter": "Diego Marron", "authors": "Diego Marr\\'on, Eduard Ayguad\\'e, Jos\\'e Ramon Herrero, Albert Bifet", "title": "Resource-aware Elastic Swap Random Forest for Evolving Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning based on data stream mining deals with ubiquitous sources\nof Big Data arriving at high-velocity and in real-time. Adaptive Random Forest\n({\\em ARF}) is a popular ensemble method used for continual learning due to its\nsimplicity in combining adaptive leveraging bagging with fast random Hoeffding\ntrees. While the default ARF size provides competitive accuracy, it is usually\nover-provisioned resulting in the use of additional classifiers that only\ncontribute to increasing CPU and memory consumption with marginal impact in the\noverall accuracy. This paper presents Elastic Swap Random Forest ({\\em ESRF}),\na method for reducing the number of trees in the ARF ensemble while providing\nsimilar accuracy. {\\em ESRF} extends {\\em ARF} with two orthogonal components:\n1) a swap component that splits learners into two sets based on their accuracy\n(only classifiers with the highest accuracy are used to make predictions); and\n2) an elastic component for dynamically increasing or decreasing the number of\nclassifiers in the ensemble. The experimental evaluation of {\\em ESRF} and\ncomparison with the original {\\em ARF} shows how the two new components\ncontribute to reducing the number of classifiers up to one third while\nproviding almost the same accuracy, resulting in speed-ups in terms of\nper-sample execution time close to 3x.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:20:28 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Marr\u00f3n", "Diego", ""], ["Ayguad\u00e9", "Eduard", ""], ["Herrero", "Jos\u00e9 Ramon", ""], ["Bifet", "Albert", ""]]}, {"id": "1905.05882", "submitter": "Patsorn Sangkloy", "authors": "Wittawat Jitkrittum, Patsorn Sangkloy, Muhammad Waleed Gondal, Amit\n  Raj, James Hays, Bernhard Sch\\\"olkopf", "title": "Kernel Mean Matching for Content Addressability of GANs", "comments": "Wittawat Jitkrittum and Patsorn Sangkloy contributed equally to this\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel procedure which adds \"content-addressability\" to any given\nunconditional implicit model e.g., a generative adversarial network (GAN). The\nprocedure allows users to control the generative process by specifying a set\n(arbitrary size) of desired examples based on which similar samples are\ngenerated from the model. The proposed approach, based on kernel mean matching,\nis applicable to any generative models which transform latent vectors to\nsamples, and does not require retraining of the model. Experiments on various\nhigh-dimensional image generation problems (CelebA-HQ, LSUN bedroom, bridge,\ntower) show that our approach is able to generate images which are consistent\nwith the input set, while retaining the image quality of the original model. To\nour knowledge, this is the first work that attempts to construct, at test time,\na content-addressable generative model from a trained marginal model.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:32:53 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Sangkloy", "Patsorn", ""], ["Gondal", "Muhammad Waleed", ""], ["Raj", "Amit", ""], ["Hays", "James", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1905.05894", "submitter": "Vitaliy Chiley", "authors": "Vitaliy Chiley, Ilya Sharapov, Atli Kosson, Urs Koster, Ryan Reece,\n  Sofia Samaniego de la Fuente, Vishal Subbiah, Michael James", "title": "Online Normalization for Training Neural Networks", "comments": "Published at the Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada. Code:\n  https://github.com/Cerebras/online-normalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Normalization is a new technique for normalizing the hidden\nactivations of a neural network. Like Batch Normalization, it normalizes the\nsample dimension. While Online Normalization does not use batches, it is as\naccurate as Batch Normalization. We resolve a theoretical limitation of Batch\nNormalization by introducing an unbiased technique for computing the gradient\nof normalized activations. Online Normalization works with automatic\ndifferentiation by adding statistical normalization as a primitive. This\ntechnique can be used in cases not covered by some other normalizers, such as\nrecurrent networks, fully connected networks, and networks with activation\nmemory requirements prohibitive for batching. We show its applications to image\nclassification, image segmentation, and language modeling. We present formal\nproofs and experimental results on ImageNet, CIFAR, and PTB datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:09:29 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 23:29:33 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 20:34:46 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Chiley", "Vitaliy", ""], ["Sharapov", "Ilya", ""], ["Kosson", "Atli", ""], ["Koster", "Urs", ""], ["Reece", "Ryan", ""], ["de la Fuente", "Sofia Samaniego", ""], ["Subbiah", "Vishal", ""], ["James", "Michael", ""]]}, {"id": "1905.05895", "submitter": "Chen Huang", "authors": "Chen Huang, Shuangfei Zhai, Walter Talbott, Miguel Angel Bautista,\n  Shih-Yu Sun, Carlos Guestrin, Josh Susskind", "title": "Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most machine learning training paradigms a fixed, often handcrafted, loss\nfunction is assumed to be a good proxy for an underlying evaluation metric. In\nthis work we assess this assumption by meta-learning an adaptive loss function\nto directly optimize the evaluation metric. We propose a sample efficient\nreinforcement learning approach for adapting the loss dynamically during\ntraining. We empirically show how this formulation improves performance by\nsimultaneously optimizing the evaluation metric and smoothing the loss\nlandscape. We verify our method in metric learning and classification\nscenarios, showing considerable improvements over the state-of-the-art on a\ndiverse set of tasks. Importantly, our method is applicable to a wide range of\nloss functions and evaluation metrics. Furthermore, the learned policies are\ntransferable across tasks and data, demonstrating the versatility of the\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:12:07 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Huang", "Chen", ""], ["Zhai", "Shuangfei", ""], ["Talbott", "Walter", ""], ["Bautista", "Miguel Angel", ""], ["Sun", "Shih-Yu", ""], ["Guestrin", "Carlos", ""], ["Susskind", "Josh", ""]]}, {"id": "1905.05897", "submitter": "Chen Zhu", "authors": "Chen Zhu, W. Ronny Huang, Ali Shafahi, Hengduo Li, Gavin Taylor,\n  Christoph Studer, Tom Goldstein", "title": "Transferable Clean-Label Poisoning Attacks on Deep Neural Nets", "comments": "Accepted to ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Clean-label poisoning attacks inject innocuous looking (and \"correctly\"\nlabeled) poison images into training data, causing a model to misclassify a\ntargeted image after being trained on this data. We consider transferable\npoisoning attacks that succeed without access to the victim network's outputs,\narchitecture, or (in some cases) training data. To achieve this, we propose a\nnew \"polytope attack\" in which poison images are designed to surround the\ntargeted image in feature space. We also demonstrate that using Dropout during\npoison creation helps to enhance transferability of this attack. We achieve\ntransferable attack success rates of over 50% while poisoning only 1% of the\ntraining set.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:15:01 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 15:05:37 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhu", "Chen", ""], ["Huang", "W. Ronny", ""], ["Shafahi", "Ali", ""], ["Li", "Hengduo", ""], ["Taylor", "Gavin", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "1905.05901", "submitter": "Hankook Lee", "authors": "Yunhun Jang, Hankook Lee, Sung Ju Hwang, Jinwoo Shin", "title": "Learning What and Where to Transfer", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the application of deep learning has expanded to real-world problems with\ninsufficient volume of training data, transfer learning recently has gained\nmuch attention as means of improving the performance in such small-data regime.\nHowever, when existing methods are applied between heterogeneous architectures\nand tasks, it becomes more important to manage their detailed configurations\nand often requires exhaustive tuning on them for the desired performance. To\naddress the issue, we propose a novel transfer learning approach based on\nmeta-learning that can automatically learn what knowledge to transfer from the\nsource network to where in the target network. Given source and target\nnetworks, we propose an efficient training scheme to learn meta-networks that\ndecide (a) which pairs of layers between the source and target networks should\nbe matched for knowledge transfer and (b) which features and how much knowledge\nfrom each feature should be transferred. We validate our meta-transfer approach\nagainst recent transfer learning methods on various datasets and network\narchitectures, on which our automated scheme significantly outperforms the\nprior baselines that find \"what and where to transfer\" in a hand-crafted\nmanner.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:36:49 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Jang", "Yunhun", ""], ["Lee", "Hankook", ""], ["Hwang", "Sung Ju", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1905.05914", "submitter": "Jian Wang", "authors": "Jian Wang, Chen Xu, Yourui Huangfu, Rong Li, Yiqun Ge, Jun Wang", "title": "Deep Reinforcement Learning for Scheduling in Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating artificial intelligence (AI) into wireless networks has drawn\nsignificant interest in both industry and academia. A common solution is to\nreplace partial or even all modules in the conventional systems, which is often\nlack of efficiency and robustness due to their ignoring of expert knowledge. In\nthis paper, we take deep reinforcement learning (DRL) based scheduling as an\nexample to investigate how expert knowledge can help with AI module in cellular\nnetworks. A simulation platform, which has considered link adaption, feedback\nand other practical mechanisms, is developed to facilitate the investigation.\nBesides the traditional way, which is learning directly from the environment,\nfor training DRL agent, we propose two novel methods, i.e., learning from a\ndual AI module and learning from the expert solution. The results show that,\nfor the considering scheduling problem, DRL training procedure can be improved\non both performance and convergence speed by involving the expert knowledge.\nHence, instead of replacing conventional scheduling module in the system,\nadding a newly introduced AI module, which is capable to interact with the\nconventional module and provide more flexibility, is a more feasible solution.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:09:37 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 03:50:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Jian", ""], ["Xu", "Chen", ""], ["Huangfu", "Yourui", ""], ["Li", "Rong", ""], ["Ge", "Yiqun", ""], ["Wang", "Jun", ""]]}, {"id": "1905.05917", "submitter": "Guanghui Wang", "authors": "Guanghui Wang, Shiyin Lu, Lijun Zhang", "title": "Adaptivity and Optimality: A Universal Algorithm for Online Convex\n  Optimization", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study adaptive online convex optimization, and aim to\ndesign a universal algorithm that achieves optimal regret bounds for multiple\ncommon types of loss functions. Existing universal methods are limited in the\nsense that they are optimal for only a subclass of loss functions. To address\nthis limitation, we propose a novel online method, namely Maler, which enjoys\nthe optimal $O(\\sqrt{T})$, $O(d\\log T)$ and $O(\\log T)$ regret bounds for\ngeneral convex, exponentially concave, and strongly convex functions\nrespectively. The essential idea is to run multiple types of learning\nalgorithms with different learning rates in parallel, and utilize a meta\nalgorithm to track the best one on the fly. Empirical results demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:29:21 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Guanghui", ""], ["Lu", "Shiyin", ""], ["Zhang", "Lijun", ""]]}, {"id": "1905.05918", "submitter": "David Laredo Razo", "authors": "David Laredo, Zhaoyin Chen, Oliver Sch\\\"utze, Jian-Qiao Sun", "title": "A Neural Network-Evolutionary Computational Framework for Remaining\n  Useful Life Estimation of Mechanical Systems", "comments": "Published at Neural Networks 116, (2019) 178-187", "journal-ref": "Neural Networks 116, (2019) 178-187", "doi": "10.1016/j.neunet.2019.04.016", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for estimating the remaining useful life\n(RUL) of mechanical systems. The framework consists of a multi-layer perceptron\nand an evolutionary algorithm for optimizing the data-related parameters. The\nframework makes use of a strided time window to estimate the RUL for mechanical\ncomponents. Tuning the data-related parameters can become a very time consuming\ntask. The framework presented here automatically reshapes the data such that\nthe efficiency of the model is increased. Furthermore, the complexity of the\nmodel is kept low, e.g. neural networks with few hidden layers and few neurons\nat each layer. Having simple models has several advantages like short training\ntimes and the capacity of being in environments with limited computational\nresources such as embedded systems. The proposed method is evaluated on the\npublicly available C-MAPSS dataset, its accuracy is compared against other\nstate-of-the art methods for the same dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:31:45 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Laredo", "David", ""], ["Chen", "Zhaoyin", ""], ["Sch\u00fctze", "Oliver", ""], ["Sun", "Jian-Qiao", ""]]}, {"id": "1905.05925", "submitter": "Jiangnan Li", "authors": "Haoran Niu, Jiangnan Li, Yu Zhao", "title": "SmartBullets: A Cloud-Assisted Bullet Screen Filter based on Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bullet-screen is a technique that enables the website users to send real-time\ncomment `bullet' cross the screen. Compared with the traditional review of a\nvideo, bullet-screen provides new features of feeling expression to video\nwatching and more iterations between video viewers. However, since all the\ncomments from the viewers are shown on the screen publicly and simultaneously,\nsome low-quality bullets will reduce the watching enjoyment of the users.\nAlthough the bullet-screen video websites have provided filter functions based\non regular expression, bad bullets can still easily pass the filter through\nmaking a small modification.\n  In this paper, we present SmartBullets, a user-centered bullet-screen filter\nbased on deep learning techniques. A convolutional neural network is trained as\nthe classifier to determine whether a bullet need to be removed according to\nits quality. Moreover, to increase the scalability of the filter, we employ a\ncloud-assisted framework by developing a backend cloud server and a front-end\nbrowser extension. The evaluation of 40 volunteers shows that SmartBullets can\neffectively remove the low-quality bullets and improve the overall watching\nexperience of viewers.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:17:18 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Niu", "Haoran", ""], ["Li", "Jiangnan", ""], ["Zhao", "Yu", ""]]}, {"id": "1905.05927", "submitter": "Anoop Cherian", "authors": "Arvind U. Raghunathan, Anoop Cherian, Devesh K. Jha", "title": "Game Theoretic Optimization via Gradient-based Nikaido-Isoda Function", "comments": "Accepted at International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing Nash equilibrium (NE) of multi-player games has witnessed renewed\ninterest due to recent advances in generative adversarial networks. However,\ncomputing equilibrium efficiently is challenging. To this end, we introduce the\nGradient-based Nikaido-Isoda (GNI) function which serves: (i) as a merit\nfunction, vanishing only at the first-order stationary points of each player's\noptimization problem, and (ii) provides error bounds to a stationary Nash\npoint. Gradient descent is shown to converge sublinearly to a first-order\nstationary point of the GNI function. For the particular case of bilinear\nmin-max games and multi-player quadratic games, the GNI function is convex.\nHence, the application of gradient descent in this case yields linear\nconvergence to an NE (when one exists). In our numerical experiments, we\nobserve that the GNI formulation always converges to the first-order stationary\npoint of each player's optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:20:45 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Raghunathan", "Arvind U.", ""], ["Cherian", "Anoop", ""], ["Jha", "Devesh K.", ""]]}, {"id": "1905.05928", "submitter": "Pengfei Chen", "authors": "Guangyong Chen, Pengfei Chen, Yujun Shi, Chang-Yu Hsieh, Benben Liao,\n  Shengyu Zhang", "title": "Rethinking the Usage of Batch Normalization and Dropout in the Training\n  of Deep Neural Networks", "comments": "Correspondence to:Benben Liao <bliao@tencent.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel technique to boost training efficiency of a\nneural network. Our work is based on an excellent idea that whitening the\ninputs of neural networks can achieve a fast convergence speed. Given the\nwell-known fact that independent components must be whitened, we introduce a\nnovel Independent-Component (IC) layer before each weight layer, whose inputs\nwould be made more independent. However, determining independent components is\na computationally intensive task. To overcome this challenge, we propose to\nimplement an IC layer by combining two popular techniques, Batch Normalization\nand Dropout, in a new manner that we can rigorously prove that Dropout can\nquadratically reduce the mutual information and linearly reduce the correlation\nbetween any pair of neurons with respect to the dropout layer parameter $p$. As\ndemonstrated experimentally, the IC layer consistently outperforms the baseline\napproaches with more stable training process, faster convergence speed and\nbetter convergence limit on CIFAR10/100 and ILSVRC2012 datasets. The\nimplementation of our IC layer makes us rethink the common practices in the\ndesign of neural networks. For example, we should not place Batch Normalization\nbefore ReLU since the non-negative responses of ReLU will make the weight layer\nupdated in a suboptimal way, and we can achieve better performance by combining\nBatch Normalization and Dropout together as an IC layer.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:29:06 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Chen", "Guangyong", ""], ["Chen", "Pengfei", ""], ["Shi", "Yujun", ""], ["Hsieh", "Chang-Yu", ""], ["Liao", "Benben", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1905.05929", "submitter": "Kui Jia", "authors": "Kui Jia, Shuai Li, Yuxin Wen, Tongliang Liu, and Dacheng Tao", "title": "Orthogonal Deep Neural Networks", "comments": "To Appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the algorithms of Orthogonal Deep Neural Networks\n(OrthDNNs) to connect with recent interest of spectrally regularized deep\nlearning methods. OrthDNNs are theoretically motivated by generalization\nanalysis of modern DNNs, with the aim to find solution properties of network\nweights that guarantee better generalization. To this end, we first prove that\nDNNs are of local isometry on data distributions of practical interest; by\nusing a new covering of the sample space and introducing the local isometry\nproperty of DNNs into generalization analysis, we establish a new\ngeneralization error bound that is both scale- and range-sensitive to singular\nvalue spectrum of each of networks' weight matrices. We prove that the optimal\nbound w.r.t. the degree of isometry is attained when each weight matrix has a\nspectrum of equal singular values, among which orthogonal weight matrix or a\nnon-square one with orthonormal rows or columns is the most straightforward\nchoice, suggesting the algorithms of OrthDNNs. We present both algorithms of\nstrict and approximate OrthDNNs, and for the later ones we propose a simple yet\neffective algorithm called Singular Value Bounding (SVB), which performs as\nwell as strict OrthDNNs, but at a much lower computational cost. We also\npropose Bounded Batch Normalization (BBN) to make compatible use of batch\nnormalization with OrthDNNs. We conduct extensive comparative studies by using\nmodern architectures on benchmark image classification. Experiments show the\nefficacy of OrthDNNs.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:34:10 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 13:14:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Jia", "Kui", ""], ["Li", "Shuai", ""], ["Wen", "Yuxin", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1905.05934", "submitter": "Chaoqi Wang", "authors": "Chaoqi Wang, Roger Grosse, Sanja Fidler, Guodong Zhang", "title": "EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the test time resource requirements of a neural network while\npreserving test accuracy is crucial for running inference on\nresource-constrained devices. To achieve this goal, we introduce a novel\nnetwork reparameterization based on the Kronecker-factored eigenbasis (KFE),\nand then apply Hessian-based structured pruning methods in this basis. As\nopposed to existing Hessian-based pruning algorithms which do pruning in\nparameter coordinates, our method works in the KFE where different weights are\napproximately independent, enabling accurate pruning and fast computation. We\ndemonstrate empirically the effectiveness of the proposed method through\nextensive experiments. In particular, we highlight that the improvements are\nespecially significant for more challenging datasets and networks. With\nnegligible loss of accuracy, an iterative-pruning version gives a 10$\\times$\nreduction in model size and a 8$\\times$ reduction in FLOPs on wide ResNet32.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:53:08 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Chaoqi", ""], ["Grosse", "Roger", ""], ["Fidler", "Sanja", ""], ["Zhang", "Guodong", ""]]}, {"id": "1905.05957", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Chen Yu, Tong Zhang, Ji Liu", "title": "DoubleSqueeze: Parallel Stochastic Gradient Descent with Double-Pass\n  Error-Compensated Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard approach in large scale machine learning is distributed stochastic\ngradient training, which requires the computation of aggregated stochastic\ngradients over multiple nodes on a network. Communication is a major bottleneck\nin such applications, and in recent years, compressed stochastic gradient\nmethods such as QSGD (quantized SGD) and sparse SGD have been proposed to\nreduce communication. It was also shown that error compensation can be combined\nwith compression to achieve better convergence in a scheme that each node\ncompresses its local stochastic gradient and broadcast the result to all other\nnodes over the network in a single pass. However, such a single pass broadcast\napproach is not realistic in many practical implementations. For example, under\nthe popular parameter server model for distributed learning, the worker nodes\nneed to send the compressed local gradients to the parameter server, which\nperforms the aggregation. The parameter server has to compress the aggregated\nstochastic gradient again before sending it back to the worker nodes. In this\nwork, we provide a detailed analysis on this two-pass communication model and\nits asynchronous parallel variant, with error-compensated compression both on\nthe worker nodes and on the parameter server. We show that the\nerror-compensated stochastic gradient algorithm admits three very nice\nproperties: 1) it is compatible with an \\emph{arbitrary} compression technique;\n2) it admits an improved convergence rate than the non error-compensated\nstochastic gradient methods such as QSGD and sparse SGD; 3) it admits linear\nspeedup with respect to the number of workers. The empirical study is also\nconducted to validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:07:55 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 00:44:41 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 19:45:13 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Yu", "Chen", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1905.05961", "submitter": "Zijian Wang", "authors": "Zijian Wang, Scott A. Hale, David Adelani, Przemyslaw A. Grabowicz,\n  Timo Hartmann, Fabian Fl\\\"ock, David Jurgens", "title": "Demographic Inference and Representative Population Estimates from\n  Multilingual Social Media Data", "comments": "12 pages, 10 figures, Proceedings of the 2019 World Wide Web\n  Conference (WWW '19)", "journal-ref": "Proceedings of the 2019 World Wide Web Conference (WWW '19), May\n  13--17, 2019, San Francisco, CA, USA", "doi": "10.1145/3308558.3313684", "report-no": null, "categories": "cs.CY cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media provide access to behavioural data at an unprecedented scale and\ngranularity. However, using these data to understand phenomena in a broader\npopulation is difficult due to their non-representativeness and the bias of\nstatistical inference tools towards dominant languages and groups. While\ndemographic attribute inference could be used to mitigate such bias, current\ntechniques are almost entirely monolingual and fail to work in a global\nenvironment. We address these challenges by combining multilingual demographic\ninference with post-stratification to create a more representative population\nsample. To learn demographic attributes, we create a new multimodal deep neural\narchitecture for joint classification of age, gender, and organization-status\nof social media users that operates in 32 languages. This method substantially\noutperforms current state of the art while also reducing algorithmic bias. To\ncorrect for sampling biases, we propose fully interpretable multilevel\nregression methods that estimate inclusion probabilities from inferred joint\npopulation counts and ground-truth population counts. In a large experiment\nover multilingual heterogeneous European regions, we show that our demographic\ninference and bias correction together allow for more accurate estimates of\npopulations and make a significant step towards representative social sensing\nin downstream applications with multilingual social media.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:15:16 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Zijian", ""], ["Hale", "Scott A.", ""], ["Adelani", "David", ""], ["Grabowicz", "Przemyslaw A.", ""], ["Hartmann", "Timo", ""], ["Fl\u00f6ck", "Fabian", ""], ["Jurgens", "David", ""]]}, {"id": "1905.05965", "submitter": "Jonathon Schwartz", "authors": "Jonathon Schwartz, Hanna Kurniawati", "title": "Autonomous Penetration Testing using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing (pentesting) involves performing a controlled attack on a\ncomputer system in order to assess it's security. Although an effective method\nfor testing security, pentesting requires highly skilled practitioners and\ncurrently there is a growing shortage of skilled cyber security professionals.\nOne avenue for alleviating this problem is automate the pentesting process\nusing artificial intelligence techniques. Current approaches to automated\npentesting have relied on model-based planning, however the cyber security\nlandscape is rapidly changing making maintaining up-to-date models of exploits\na challenge. This project investigated the application of model-free\nReinforcement Learning (RL) to automated pentesting. Model-free RL has the key\nadvantage over model-based planning of not requiring a model of the\nenvironment, instead learning the best policy through interaction with the\nenvironment. We first designed and built a fast, low compute simulator for\ntraining and testing autonomous pentesting agents. We did this by framing\npentesting as a Markov Decision Process with the known configuration of the\nnetwork as states, the available scans and exploits as actions, the reward\ndetermined by the value of machines on the network. We then used this simulator\nto investigate the application of model-free RL to pentesting. We tested the\nstandard Q-learning algorithm using both tabular and neural network based\nimplementations. We found that within the simulated environment both tabular\nand neural network implementations were able to find optimal attack paths for a\nrange of different network topologies and sizes without having a model of\naction behaviour. However, the implemented algorithms were only practical for\nsmaller networks and numbers of actions. Further work is needed in developing\nscalable RL algorithms and testing these algorithms in larger and higher\nfidelity environments.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:18:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Schwartz", "Jonathon", ""], ["Kurniawati", "Hanna", ""]]}, {"id": "1905.05976", "submitter": "Takeru Matsuda", "authors": "Takeru Matsuda, Masatoshi Uehara, Aapo Hyvarinen", "title": "Information criteria for non-normalized models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical models are given in the form of non-normalized densities\nwith an intractable normalization constant. Since maximum likelihood estimation\nis computationally intensive for these models, several estimation methods have\nbeen developed which do not require explicit computation of the normalization\nconstant, such as noise contrastive estimation (NCE) and score matching.\nHowever, model selection methods for general non-normalized models have not\nbeen proposed so far. In this study, we develop information criteria for\nnon-normalized models estimated by NCE or score matching. They are\napproximately unbiased estimators of discrepancy measures for non-normalized\nmodels. Simulation results and applications to real data demonstrate that the\nproposed criteria enable selection of the appropriate non-normalized model in a\ndata-driven manner.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:57:47 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 08:33:30 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 09:08:17 GMT"}, {"version": "v4", "created": "Fri, 18 Jun 2021 07:31:56 GMT"}, {"version": "v5", "created": "Tue, 27 Jul 2021 06:00:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Matsuda", "Takeru", ""], ["Uehara", "Masatoshi", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1905.05987", "submitter": "Nana Wang", "authors": "Nana Wang, Li Cui, Xi Huang, Yingcong Xiang, Jing Xiao, Yi Rao", "title": "EasiCS: the objective and fine-grained classification method of cervical\n  spondylosis dysfunction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The precise diagnosis is of great significance in developing precise\ntreatment plans to restore neck function and reduce the burden posed by the\ncervical spondylosis (CS). However, the current available neck function\nassessment method are subjective and coarse-grained. In this paper, based on\nthe relationship among CS, cervical structure, cervical vertebra function, and\nsurface electromyography (sEMG), we seek to develop a clustering algorithms on\nthe sEMG data set collected from the clinical environment and implement the\ndivision. We proposed and developed the framework EasiCS, which consists of\ndimension reduction, clustering algorithm EasiSOM, spectral clustering\nalgorithm EasiSC. The EasiCS outperform the commonly used seven algorithms\noverall.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:19:26 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Nana", ""], ["Cui", "Li", ""], ["Huang", "Xi", ""], ["Xiang", "Yingcong", ""], ["Xiao", "Jing", ""], ["Rao", "Yi", ""]]}, {"id": "1905.05992", "submitter": "Adrian Redder", "authors": "Adrian Redder, Arunselvan Ramaswamy, Daniel E. Quevedo", "title": "Deep reinforcement learning for scheduling in large-scale networked\n  control systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the problem of control and resource scheduling in\nnetworked systems. We present DIRA, a Deep reinforcement learning based\nIterative Resource Allocation algorithm, which is scalable and control-aware.\nOur algorithm is tailored towards large-scale problems where control and\nscheduling need to act jointly to optimize performance. DIRA can be used to\nschedule general time-domain optimization based controllers. In the present\nwork, we focus on control designs based on suitably adapted linear quadratic\nregulators. We apply our algorithm to networked systems with correlated fading\ncommunication channels. Our simulations show that DIRA scales well to large\nscheduling problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:32:06 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 15:41:58 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Redder", "Adrian", ""], ["Ramaswamy", "Arunselvan", ""], ["Quevedo", "Daniel E.", ""]]}, {"id": "1905.06002", "submitter": "Raphael Memmesheimer", "authors": "Raphael Memmesheimer, Ivanna Mykhalchyshyna, Viktor Seib, Dietrich\n  Paulus", "title": "Simitate: A Hybrid Imitation Learning Benchmark", "comments": "6 figures, 2 tables, submitted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present Simitate --- a hybrid benchmarking suite targeting the evaluation\nof approaches for imitation learning. A dataset containing 1938 sequences where\nhumans perform daily activities in a realistic environment is presented. The\ndataset is strongly coupled with an integration into a simulator. RGB and depth\nstreams with a resolution of 960$\\mathbb{\\times}$540 at 30Hz and accurate\nground truth poses for the demonstrator's hand, as well as the object in 6 DOF\nat 120Hz are provided. Along with our dataset we provide the 3D model of the\nused environment, labeled object images and pre-trained models. A benchmarking\nsuite that aims at fostering comparability and reproducibility supports the\ndevelopment of imitation learning approaches. Further, we propose and integrate\nevaluation metrics on assessing the quality of effect and trajectory of the\nimitation performed in simulation. Simitate is available on our project\nwebsite: \\url{https://agas.uni-koblenz.de/data/simitate/}.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:46:33 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Memmesheimer", "Raphael", ""], ["Mykhalchyshyna", "Ivanna", ""], ["Seib", "Viktor", ""], ["Paulus", "Dietrich", ""]]}, {"id": "1905.06004", "submitter": "Qin Wang", "authors": "Qin Wang, Gabriel Michau, Olga Fink", "title": "Domain Adaptive Transfer Learning for Fault Diagnosis", "comments": "Presented at 2019 Prognostics and System Health Management Conference\n  (PHM 2019) in Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to digitization of industrial assets in fleets, the ambitious goal of\ntransferring fault diagnosis models fromone machine to the other has raised\ngreat interest. Solving these domain adaptive transfer learning tasks has the\npotential to save large efforts on manually labeling data and modifying models\nfor new machines in the same fleet. Although data-driven methods have shown\ngreat potential in fault diagnosis applications, their ability to generalize on\nnew machines and new working conditions are limited because of their tendency\nto overfit to the training set in reality. One promising solution to this\nproblem is to use domain adaptation techniques. It aims to improve model\nperformance on the target new machine. Inspired by its successful\nimplementation in computer vision, we introduced Domain-Adversarial Neural\nNetworks (DANN) to our context, along with two other popular methods existing\nin previous fault diagnosis research. We then carefully justify the\napplicability of these methods in realistic fault diagnosis settings, and offer\na unified experimental protocol for a fair comparison between domain adaptation\nmethods for fault diagnosis problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:48:21 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Qin", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "1905.06005", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (DMA, CNRS), Mathieu Blondel, Gabriel Peyr\\'e (DMA,\n  CNRS)", "title": "Geometric Losses for Distributional Learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2019, Long Beach, United States", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building upon recent advances in entropy-regularized optimal transport, and\nupon Fenchel duality between measures and continuous functions , we propose a\ngeneralization of the logistic loss that incorporates a metric or cost between\nclasses. Unlike previous attempts to use optimal transport distances for\nlearning, our loss results in unconstrained convex objective functions,\nsupports infinite (or very large) class spaces, and naturally defines a\ngeometric generalization of the softmax operator. The geometric properties of\nthis loss make it suitable for predicting sparse and singular distributions,\nfor instance supported on curves or hyper-surfaces. We study the theoretical\nproperties of our loss and show-case its effectiveness on two applications:\nordinal regression and drawing generation.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:49:10 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mensch", "Arthur", "", "DMA, CNRS"], ["Blondel", "Mathieu", "", "DMA,\n  CNRS"], ["Peyr\u00e9", "Gabriel", "", "DMA,\n  CNRS"]]}, {"id": "1905.06010", "submitter": "David Laredo Razo", "authors": "David Laredo, Yulin Qin, Oliver Sch\\\"utze, Jian-Qiao Sun", "title": "Automatic Model Selection for Neural Networks", "comments": "31 pages, 6 figures. Preprint Submitted to Elsevier Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and deep learning are changing the way that artificial\nintelligence is being done. Efficiently choosing a suitable network\narchitecture and fine-tune its hyper-parameters for a specific dataset is a\ntime-consuming task given the staggering number of possible alternatives. In\nthis paper, we address the problem of model selection by means of a fully\nautomated framework for efficiently selecting a neural network model for a\ngiven task: classification or regression. The algorithm, named Automatic Model\nSelection, is a modified micro-genetic algorithm that automatically and\nefficiently finds the most suitable neural network model for a given dataset.\nThe main contributions of this method are a simple list based encoding for\nneural networks as genotypes in an evolutionary algorithm, new crossover, and\nmutation operators, the introduction of a fitness function that considers both,\nthe accuracy of the model and its complexity and a method to measure the\nsimilarity between two neural networks. AMS is evaluated on two different\ndatasets. By comparing some models obtained with AMS to state-of-the-art models\nfor each dataset we show that AMS can automatically find efficient neural\nnetwork models. Furthermore, AMS is computationally efficient and can make use\nof distributed computing paradigms to further boost its performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:57:08 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Laredo", "David", ""], ["Qin", "Yulin", ""], ["Sch\u00fctze", "Oliver", ""], ["Sun", "Jian-Qiao", ""]]}, {"id": "1905.06018", "submitter": "Lukas Galke", "authors": "Lukas Galke, Iacopo Vagliano, Ansgar Scherp", "title": "Can Graph Neural Networks Go \"Online\"? An Analysis of Pretraining and\n  Inference", "comments": "5 pages, 1 figure, Representation Learning on Graphs and Manifolds\n  Workshop of the International Conference on Learning Representations (ICLR),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale graph data in real-world applications is often not static but\ndynamic, i. e., new nodes and edges appear over time. Current graph convolution\napproaches are promising, especially, when all the graph's nodes and edges are\navailable during training. When unseen nodes and edges are inserted after\ntraining, it is not yet evaluated whether up-training or re-training from\nscratch is preferable. We construct an experimental setup, in which we insert\npreviously unseen nodes and edges after training and conduct a limited amount\nof inference epochs. In this setup, we compare adapting pretrained graph neural\nnetworks against retraining from scratch. Our results show that pretrained\nmodels yield high accuracy scores on the unseen nodes and that pretraining is\npreferable over retraining from scratch. Our experiments represent a first step\nto evaluate and develop truly online variants of graph neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:11:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Galke", "Lukas", ""], ["Vagliano", "Iacopo", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1905.06023", "submitter": "Hao Song", "authors": "Hao Song, Tom Diethe, Meelis Kull, Peter Flach", "title": "Distribution Calibration for Regression", "comments": "ICML 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with obtaining well-calibrated output distributions from\nregression models. Such distributions allow us to quantify the uncertainty that\nthe model has regarding the predicted target value. We introduce the novel\nconcept of distribution calibration, and demonstrate its advantages over the\nexisting definition of quantile calibration. We further propose a post-hoc\napproach to improving the predictions from previously trained regression\nmodels, using multi-output Gaussian Processes with a novel Beta link function.\nThe proposed method is experimentally verified on a set of common regression\nmodels and shows improvements for both distribution-level and quantile-level\ncalibration.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:21:04 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Song", "Hao", ""], ["Diethe", "Tom", ""], ["Kull", "Meelis", ""], ["Flach", "Peter", ""]]}, {"id": "1905.06052", "submitter": "Brij Rokad", "authors": "Brij Rokad, Tushar Karumudi, Omkar Acharya and Akshay Jagtap", "title": "Survival of the Fittest in PlayerUnknown BattleGround", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper was to predict the placement in the multiplayer game\nPUBG (playerunknown battleground). In the game, up to one hundred players\nparachutes onto an island and scavenge for weapons and equipment to kill\nothers, while avoiding getting killed themselves. The available safe area of\nthe game map decreases in size over time, directing surviving players into\ntighter areas to force encounters. The last player or team standing wins the\nround. In this paper specifically, we have tried to predict the placement of\nthe player in the ultimate survival test. The data set has been taken from\nKaggle. Entire dataset has 29 attributes which are categories to 1\nlabel(winPlacePerc), training set has 4.5 million instances and testing set has\n1.9 million. winPlacePerc is continuous category, which makes it harder to\npredict the survival of the fittest. To overcome this problem, we have applied\nmultiple machine learning models to find the optimum prediction. Model consists\nof LightGBM Regression (Light Gradient Boosting Machine Regression), MultiLayer\nPerceptron, M5P (improvement on C4.5) and Random Forest. To measure the error\nrate, Mean Absolute Error has been used. With the final prediction we have\nachieved MAE of 0.02047, 0.065, 0.0592 and 0634 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 09:39:46 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Rokad", "Brij", ""], ["Karumudi", "Tushar", ""], ["Acharya", "Omkar", ""], ["Jagtap", "Akshay", ""]]}, {"id": "1905.06054", "submitter": "Vagan Terziyan", "authors": "Vagan Terziyan, Anton Nikulin", "title": "Ignorance-Aware Approaches and Algorithms for Prototype Selection in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating with ignorance is an important concern of the Machine Learning\nresearch, especially when the objective is to discover knowledge from the\nimperfect data. Data mining (driven by appropriate knowledge discovery tools)\nis about processing available (observed, known and understood) samples of data\naiming to build a model (e.g., a classifier) to handle data samples, which are\nnot yet observed, known or understood. These tools traditionally take samples\nof the available data (known facts) as an input for learning. We want to\nchallenge the indispensability of this approach and we suggest considering the\nthings the other way around. What if the task would be as follows: how to learn\na model based on our ignorance, i.e. by processing the shape of 'voids' within\nthe available data space? Can we improve traditional classification by modeling\nalso the ignorance? In this paper, we provide some algorithms for the discovery\nand visualizing of the ignorance zones in two-dimensional data spaces and\ndesign two ignorance-aware smart prototype selection techniques (incremental\nand adversarial) to improve the performance of the nearest neighbor\nclassifiers. We present experiments with artificial and real datasets to test\nthe concept of the usefulness of ignorance discovery in machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 09:41:06 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Terziyan", "Vagan", ""], ["Nikulin", "Anton", ""]]}, {"id": "1905.06076", "submitter": "Tim Pearce", "authors": "Tim Pearce, Russell Tsuchida, Mohamed Zaki, Alexandra Brintrup, Andy\n  Neely", "title": "Expressive Priors in Bayesian Neural Networks: Kernel Combinations and\n  Periodic Functions", "comments": null, "journal-ref": "The 35th Conference on Uncertainty in Artificial Intelligence (UAI\n  2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple, flexible approach to creating expressive priors in Gaussian process\n(GP) models makes new kernels from a combination of basic kernels, e.g. summing\na periodic and linear kernel can capture seasonal variation with a long term\ntrend. Despite a well-studied link between GPs and Bayesian neural networks\n(BNNs), the BNN analogue of this has not yet been explored. This paper derives\nBNN architectures mirroring such kernel combinations. Furthermore, it shows how\nBNNs can produce periodic kernels, which are often useful in this context.\nThese ideas provide a principled approach to designing BNNs that incorporate\nprior knowledge about a function. We showcase the practical value of these\nideas with illustrative experiments in supervised and reinforcement learning\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:34:17 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 14:34:41 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Pearce", "Tim", ""], ["Tsuchida", "Russell", ""], ["Zaki", "Mohamed", ""], ["Brintrup", "Alexandra", ""], ["Neely", "Andy", ""]]}, {"id": "1905.06077", "submitter": "Shounak Bhattacharya Mr.", "authors": "Shounak Bhattacharya, Abhik Singla, Abhimanyu, Dhaivat Dholakiya,\n  Shalabh Bhatnagar, Bharadwaj Amrutur, Ashitava Ghosal and Shishir Kolathaya", "title": "Learning Active Spine Behaviors for Dynamic and Efficient Locomotion in\n  Quadruped Robots", "comments": "Submitted to IEEE RO-MAN 2019. Supplementary video:\n  https://youtu.be/INp4aa-8z2E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide a simulation framework to perform systematic studies\non the effects of spinal joint compliance and actuation on bounding performance\nof a 16-DOF quadruped spined robot Stoch 2. Fast quadrupedal locomotion with\nactive spine is an extremely hard problem, and involves a complex coordination\nbetween the various degrees of freedom. Therefore, past attempts at addressing\nthis problem have not seen much success. Deep-Reinforcement Learning seems to\nbe a promising approach, after its recent success in a variety of robot\nplatforms, and the goal of this paper is to use this approach to realize the\naforementioned behaviors. With this learning framework, the robot reached a\nbounding speed of 2.1 m/s with a maximum Froude number of 2. Simulation results\nalso show that use of active spine, indeed, increased the stride length,\nimproved the cost of transport, and also reduced the natural frequency to more\nrealistic values.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:40:15 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 01:17:26 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Bhattacharya", "Shounak", ""], ["Singla", "Abhik", ""], ["Abhimanyu", "", ""], ["Dholakiya", "Dhaivat", ""], ["Bhatnagar", "Shalabh", ""], ["Amrutur", "Bharadwaj", ""], ["Ghosal", "Ashitava", ""], ["Kolathaya", "Shishir", ""]]}, {"id": "1905.06097", "submitter": "Zhou Fan", "authors": "Sheng Xu and Zhou Fan", "title": "Iterative Alpha Expansion for estimating gradient-sparse signals from\n  linear measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating a piecewise-constant image, or a gradient-sparse\nsignal on a general graph, from noisy linear measurements. We propose and study\nan iterative algorithm to minimize a penalized least-squares objective, with a\npenalty given by the \"l_0-norm\" of the signal's discrete graph gradient. The\nmethod proceeds by approximate proximal descent, applying the alpha-expansion\nprocedure to minimize a proximal gradient in each iteration, and using a\ngeometric decay of the penalty parameter across iterations. Under a\ncut-restricted isometry property for the measurement design, we prove global\nrecovery guarantees for the estimated signal. For standard Gaussian designs,\nthe required number of measurements is independent of the graph structure, and\nimproves upon worst-case guarantees for total-variation (TV) compressed sensing\non the 1-D and 2-D lattice graphs by polynomial and logarithmic factors,\nrespectively. The method empirically yields lower mean-squared recovery error\ncompared with TV regularization in regimes of moderate undersampling and\nmoderate to high signal-to-noise, for several examples of changepoint signals\nand gradient-sparse phantom images.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:40:35 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Xu", "Sheng", ""], ["Fan", "Zhou", ""]]}, {"id": "1905.06105", "submitter": "Corey Lammie", "authors": "Corey Lammie, Wei Xiang, and Mostafa Rahimi Azghadi", "title": "Accelerating Deterministic and Stochastic Binarized Neural Networks on\n  FPGAs Using OpenCL", "comments": "4 pages, 3 figures, 1 table", "journal-ref": "2019 IEEE International Midwest Symposium on Circuits and Systems\n  (MWSCAS)", "doi": "10.1109/MWSCAS.2019.8884910", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent technological advances have proliferated the available computing\npower, memory, and speed of modern Central Processing Units (CPUs), Graphics\nProcessing Units (GPUs), and Field Programmable Gate Arrays (FPGAs).\nConsequently, the performance and complexity of Artificial Neural Networks\n(ANNs) is burgeoning. While GPU accelerated Deep Neural Networks (DNNs)\ncurrently offer state-of-the-art performance, they consume large amounts of\npower. Training such networks on CPUs is inefficient, as data throughput and\nparallel computation is limited. FPGAs are considered a suitable candidate for\nperformance critical, low power systems, e.g. the Internet of Things (IOT) edge\ndevices. Using the Xilinx SDAccel or Intel FPGA SDK for OpenCL development\nenvironment, networks described using the high-level OpenCL framework can be\naccelerated on heterogeneous platforms. Moreover, the resource utilization and\npower consumption of DNNs can be further enhanced by utilizing regularization\ntechniques that binarize network weights. In this paper, we introduce, to the\nbest of our knowledge, the first FPGA-accelerated stochastically binarized DNN\nimplementations, and compare them to implementations accelerated using both\nGPUs and FPGAs. Our developed networks are trained and benchmarked using the\npopular MNIST and CIFAR-10 datasets, and achieve near state-of-the-art\nperformance, while offering a >16-fold improvement in power consumption,\ncompared to conventional GPU-accelerated networks. Both our FPGA-accelerated\ndeterminsitic and stochastic BNNs reduce inference times on MNIST and CIFAR-10\nby >9.89x and >9.91x, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:04:36 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lammie", "Corey", ""], ["Xiang", "Wei", ""], ["Azghadi", "Mostafa Rahimi", ""]]}, {"id": "1905.06109", "submitter": "Xiaosen Wang", "authors": "Kun He and Wu Wang and Xiaosen Wang and John E. Hopcroft", "title": "A New Anchor Word Selection Method for the Separable Topic Discovery", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separable Non-negative Matrix Factorization (SNMF) is an important method for\ntopic modeling, where \"separable\" assumes every topic contains at least one\nanchor word, defined as a word that has non-zero probability only on that\ntopic. SNMF focuses on the word co-occurrence patterns to reveal topics by two\nsteps: anchor word selection and topic recovery. The quality of the anchor\nwords strongly influences the quality of the extracted topics. Existing anchor\nword selection algorithm is to greedily find an approximate convex hull in a\nhigh-dimensional word co-occurrence space. In this work, we propose a new\nmethod for the anchor word selection by associating the word co-occurrence\nprobability with the words similarity and assuming that the most different\nwords on semantic are potential candidates for the anchor words. Therefore, if\nthe similarity of a word-pair is very low, then the two words are very likely\nto be the anchor words. According to the statistical information of text\ncorpora, we can get the similarity of all word-pairs. We build the word\nsimilarity graph where the nodes correspond to words and weights on edges stand\nfor the word-pair similarity. Following this way, we design a greedy method to\nfind a minimum edge-weight anchor clique of a given size in the graph for the\nanchor word selection. Extensive experiments on real-world corpus demonstrate\nthe effectiveness of the proposed anchor word selection method that outperforms\nthe common convex hull-based methods on the revealed topic quality. Meanwhile,\nour method is much faster than typical SNMF based method.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:16:10 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["He", "Kun", ""], ["Wang", "Wu", ""], ["Wang", "Xiaosen", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1905.06112", "submitter": "Vuong M. Ngo", "authors": "T.H.H Duong, T.D. Vu, V.M. Ngo", "title": "Detecting Vietnamese Opinion Spam", "comments": "6 pages, in Vietnamese", "journal-ref": "ICTFIT 2012", "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Vietnamese Natural Language Processing has been researched by\nexperts in academic and business. However, the existing papers have been\nfocused only on information classification or extraction from documents.\nNowadays, with quickly development of the e-commerce websites, forums and\nsocial networks, the products, people, organizations or wonders are targeted of\ncomments or reviews of the network communities. Many people often use that\nreviews to make their decision on something. Whereas, there are many people or\norganizations use the reviews to mislead readers. Therefore, it is so necessary\nto detect those bad behaviors in reviews. In this paper, we research this\nproblem and propose an appropriate method for detecting Vietnamese reviews\nbeing spam or non-spam. The accuracy of our method is up to 90%.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:41:16 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Duong", "T. H. H", ""], ["Vu", "T. D.", ""], ["Ngo", "V. M.", ""]]}, {"id": "1905.06113", "submitter": "Andrey Rudenko", "authors": "Andrey Rudenko, Luigi Palmieri, Michael Herman, Kris M. Kitani, Dariu\n  M. Gavrila and Kai O. Arras", "title": "Human Motion Trajectory Prediction: A Survey", "comments": "Submitted to the International Journal of Robotics Research (IJRR),\n  37 pages", "journal-ref": null, "doi": "10.1177/0278364920917446", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing numbers of intelligent autonomous systems in human environments,\nthe ability of such systems to perceive, understand and anticipate human\nbehavior becomes increasingly important. Specifically, predicting future\npositions of dynamic agents and planning considering such predictions are key\ntasks for self-driving vehicles, service robots and advanced surveillance\nsystems. This paper provides a survey of human motion trajectory prediction. We\nreview, analyze and structure a large selection of work from different\ncommunities and propose a taxonomy that categorizes existing methods based on\nthe motion modeling approach and level of contextual information used. We\nprovide an overview of the existing datasets and performance metrics. We\ndiscuss limitations of the state of the art and outline directions for further\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:09:55 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 11:09:46 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 09:27:25 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Rudenko", "Andrey", ""], ["Palmieri", "Luigi", ""], ["Herman", "Michael", ""], ["Kitani", "Kris M.", ""], ["Gavrila", "Dariu M.", ""], ["Arras", "Kai O.", ""]]}, {"id": "1905.06115", "submitter": "Jiangning Chen", "authors": "Jiangning Chen, Zhibo Dai, Juntao Duan, Heinrich Matzinger, Ionel\n  Popescu", "title": "Naive Bayes with Correlation Factor for Text Classification Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naive Bayes estimator is widely used in text classification problems.\nHowever, it doesn't perform well with small-size training dataset. We propose a\nnew method based on Naive Bayes estimator to solve this problem. A correlation\nfactor is introduced to incorporate the correlation among different classes.\nExperimental results show that our estimator achieves a better accuracy\ncompared with traditional Naive Bayes in real world data.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:27:00 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Chen", "Jiangning", ""], ["Dai", "Zhibo", ""], ["Duan", "Juntao", ""], ["Matzinger", "Heinrich", ""], ["Popescu", "Ionel", ""]]}, {"id": "1905.06118", "submitter": "Jon Gillick", "authors": "Jon Gillick, Adam Roberts, Jesse Engel, Douglas Eck, David Bamman", "title": "Learning to Groove with Inverse Sequence Transformations", "comments": "Blog post and links: https://g.co/magenta/groovae", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:2269-2279, 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore models for translating abstract musical ideas (scores, rhythms)\ninto expressive performances using Seq2Seq and recurrent Variational\nInformation Bottleneck (VIB) models. Though Seq2Seq models usually require\npainstakingly aligned corpora, we show that it is possible to adapt an approach\nfrom the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix (Isola\net al., 2017) and Vid2Vid (Wang et al. 2018a)) to sequences, creating large\nvolumes of paired data by performing simple transformations and training\ngenerative models to plausibly invert these transformations. Music, and\ndrumming in particular, provides a strong test case for this approach because\nmany common transformations (quantization, removing voices) have clear\nsemantics, and models for learning to invert them have real-world applications.\nFocusing on the case of drum set players, we create and release a new dataset\nfor this purpose, containing over 13 hours of recordings by professional\ndrummers aligned with fine-grained timing and dynamics information. We also\nexplore some of the creative potential of these models, including demonstrating\nimprovements on state-of-the-art methods for Humanization (instantiating a\nperformance from a musical score).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:25:50 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 17:24:12 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Gillick", "Jon", ""], ["Roberts", "Adam", ""], ["Engel", "Jesse", ""], ["Eck", "Douglas", ""], ["Bamman", "David", ""]]}, {"id": "1905.06125", "submitter": "Yao Hengshuai", "authors": "Borislav Mavrin, Shangtong Zhang, Hengshuai Yao, Linglong Kong, Kaiwen\n  Wu, Yaoliang Yu", "title": "Distributional Reinforcement Learning for Efficient Exploration", "comments": null, "journal-ref": "ICML, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributional reinforcement learning (RL), the estimated distribution of\nvalue function models both the parametric and intrinsic uncertainties. We\npropose a novel and efficient exploration method for deep RL that has two\ncomponents. The first is a decaying schedule to suppress the intrinsic\nuncertainty. The second is an exploration bonus calculated from the upper\nquantiles of the learned distribution. In Atari 2600 games, our method\noutperforms QR-DQN in 12 out of 14 hard games (achieving 483 \\% average gain\nacross 49 games in cumulative rewards over QR-DQN with a big win in Venture).\nWe also compared our algorithm with QR-DQN in a challenging 3D driving\nsimulator (CARLA). Results show that our algorithm achieves near-optimal safety\nrewards twice faster than QRDQN.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:08:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mavrin", "Borislav", ""], ["Zhang", "Shangtong", ""], ["Yao", "Hengshuai", ""], ["Kong", "Linglong", ""], ["Wu", "Kaiwen", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1905.06133", "submitter": "Sheng Wan", "authors": "Sheng Wan and Chen Gong and Ping Zhong and Bo Du and Lefei Zhang and\n  Jian Yang", "title": "Multi-scale Dynamic Graph Convolutional Network for Hyperspectral Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) has demonstrated impressive ability to\nrepresent hyperspectral images and to achieve promising results in\nhyperspectral image classification. However, traditional CNN models can only\noperate convolution on regular square image regions with fixed size and\nweights, so they cannot universally adapt to the distinct local regions with\nvarious object distributions and geometric appearances. Therefore, their\nclassification performances are still to be improved, especially in class\nboundaries. To alleviate this shortcoming, we consider employing the recently\nproposed Graph Convolutional Network (GCN) for hyperspectral image\nclassification, as it can conduct the convolution on arbitrarily structured\nnon-Euclidean data and is applicable to the irregular image regions represented\nby graph topological information. Different from the commonly used GCN models\nwhich work on a fixed graph, we enable the graph to be dynamically updated\nalong with the graph convolution process, so that these two steps can be\nbenefited from each other to gradually produce the discriminative embedded\nfeatures as well as a refined graph. Moreover, to comprehensively deploy the\nmulti-scale information inherited by hyperspectral images, we establish\nmultiple input graphs with different neighborhood scales to extensively exploit\nthe diversified spectral-spatial correlations at multiple scales. Therefore,\nour method is termed 'Multi-scale Dynamic Graph Convolutional Network' (MDGCN).\nThe experimental results on three typical benchmark datasets firmly demonstrate\nthe superiority of the proposed MDGCN to other state-of-the-art methods in both\nqualitative and quantitative aspects.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:27:37 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wan", "Sheng", ""], ["Gong", "Chen", ""], ["Zhong", "Ping", ""], ["Du", "Bo", ""], ["Zhang", "Lefei", ""], ["Yang", "Jian", ""]]}, {"id": "1905.06134", "submitter": "Nadia Fawaz", "authors": "Nadia Fawaz", "title": "Recommending Dream Jobs in a Biased Real World", "comments": "Accepted and presented at Grace Hopper Conference, GHC 2017", "journal-ref": "Grace Hopper Conference, GHC 2017", "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models learn what we teach them to learn. Machine learning\nis at the heart of recommender systems. If a machine learning model is trained\non biased data, the resulting recommender system may reflect the biases in its\nrecommendations. Biases arise at different stages in a recommender system, from\nexisting societal biases in the data such as the professional gender gap, to\nbiases introduced by the data collection or modeling processes. These biases\nimpact the performance of various components of recommender systems, from\noffline training, to evaluation and online serving of recommendations in\nproduction systems. Specific techniques can help reduce bias at each stage of a\nrecommender system. Reducing bias in our recommender systems is crucial to\nsuccessfully recommending dream jobs to hundreds of millions members worldwide,\nwhile being true to LinkedIn's vision: \"To create economic opportunity for\nevery member of the global workforce\".\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 19:26:01 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Fawaz", "Nadia", ""]]}, {"id": "1905.06147", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Claudio Gallicchio and Alessio Micheli and\n  Alessandro Sperduti", "title": "Embeddings and Representation Learning for Structured Data", "comments": "Oral presentation at the 27th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2019) in\n  Bruges, Belgium, on April 24th, 2019", "journal-ref": "Proc. ESANN (2019), 85-94", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing machine learning on structured data is complicated by the fact\nthat such data does not have vectorial form. Therefore, multiple approaches\nhave emerged to construct vectorial representations of structured data, from\nkernel and distance approaches to recurrent, recursive, and convolutional\nneural networks. Recent years have seen heightened attention in this demanding\nfield of research and several new approaches have emerged, such as metric\nlearning on structured data, graph convolutional neural networks, and recurrent\ndecoder networks for structured data. In this contribution, we provide an\nhigh-level overview of the state-of-the-art in representation learning and\nembeddings for structured data across a wide range of machine learning fields.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:57:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1905.06148", "submitter": "Marco A. Mart\\'inez Ram\\'irez", "authors": "Marco A. Mart\\'inez Ram\\'irez, Emmanouil Benetos and Joshua D. Reiss", "title": "A general-purpose deep learning approach to model time-varying audio\n  effects", "comments": "audio files: https://mchijmma.github.io/modeling-time-varying/", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Audio processors whose parameters are modified periodically over time are\noften referred as time-varying or modulation based audio effects. Most existing\nmethods for modeling these type of effect units are often optimized to a very\nspecific circuit and cannot be efficiently generalized to other time-varying\neffects. Based on convolutional and recurrent neural networks, we propose a\ndeep learning architecture for generic black-box modeling of audio processors\nwith long-term memory. We explore the capabilities of deep neural networks to\nlearn such long temporal dependencies and we show the network modeling various\nlinear and nonlinear, time-varying and time-invariant audio effects. In order\nto measure the performance of the model, we propose an objective metric based\non the psychoacoustics of modulation frequency perception. We also analyze what\nthe model is actually learning and how the given task is accomplished.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:57:57 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 11:07:53 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ram\u00edrez", "Marco A. Mart\u00ednez", ""], ["Benetos", "Emmanouil", ""], ["Reiss", "Joshua D.", ""]]}, {"id": "1905.06159", "submitter": "Lizheng Ma", "authors": "Lizheng Ma, Jiaxu Cui, Bo Yang", "title": "Deep Neural Architecture Search with Deep Graph Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is an effective method of finding the global\noptima of black-box functions. Recently BO has been applied to neural\narchitecture search and shows better performance than pure evolutionary\nstrategies. All these methods adopt Gaussian processes (GPs) as surrogate\nfunction, with the handcraft similarity metrics as input. In this work, we\npropose a Bayesian graph neural network as a new surrogate, which can\nautomatically extract features from deep neural architectures, and use such\nlearned features to fit and characterize black-box objectives and their\nuncertainty. Based on the new surrogate, we then develop a graph Bayesian\noptimization framework to address the challenging task of deep neural\narchitecture search. Experiment results show our method significantly\noutperforms the comparative methods on benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:13:04 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ma", "Lizheng", ""], ["Cui", "Jiaxu", ""], ["Yang", "Bo", ""]]}, {"id": "1905.06175", "submitter": "Mohsin Munir", "authors": "Mohsin Munir, Shoaib Ahmed Siddiqui, Ferdinand K\\\"usters, Dominique\n  Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSXplain: Demystification of DNN Decisions for Time-Series using Natural\n  Language and Statistical Features", "comments": "Pre-print", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_43", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) are considered as black-boxes due to the lack of\nexplainability and transparency of their decisions. This significantly hampers\ntheir deployment in environments where explainability is essential along with\nthe accuracy of the system. Recently, significant efforts have been made for\nthe interpretability of these deep networks with the aim to open up the\nblack-box. However, most of these approaches are specifically developed for\nvisual modalities. In addition, the interpretations provided by these systems\nrequire expert knowledge and understanding for intelligibility. This indicates\na vital gap between the explainability provided by the systems and the novice\nuser. To bridge this gap, we present a novel framework i.e. Time-Series\neXplanation (TSXplain) system which produces a natural language based\nexplanation of the decision taken by a NN. It uses the extracted statistical\nfeatures to describe the decision of a NN, merging the deep learning world with\nthat of statistics. The two-level explanation provides ample description of the\ndecision made by the network to aid an expert as well as a novice user alike.\nOur survey and reliability assessment test confirm that the generated\nexplanations are meaningful and correct. We believe that generating natural\nlanguage based descriptions of the network's decisions is a big step towards\nopening up the black-box.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:37:58 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Munir", "Mohsin", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["K\u00fcsters", "Ferdinand", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1905.06179", "submitter": "Jianlong Wu", "authors": "Xingyu Xie, Jianlong Wu, Zhisheng Zhong, Guangcan Liu, Zhouchen Lin", "title": "Differentiable Linearized ADMM", "comments": "Accepted by ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a number of learning-based optimization methods that combine\ndata-driven architectures with the classical optimization algorithms have been\nproposed and explored, showing superior empirical performance in solving\nvarious ill-posed inverse problems, but there is still a scarcity of rigorous\nanalysis about the convergence behaviors of learning-based optimization. In\nparticular, most existing analyses are specific to unconstrained problems but\ncannot apply to the more general cases where some variables of interest are\nsubject to certain constraints. In this paper, we propose Differentiable\nLinearized ADMM (D-LADMM) for solving the problems with linear constraints.\nSpecifically, D-LADMM is a K-layer LADMM inspired deep neural network, which is\nobtained by firstly introducing some learnable weights in the classical\nLinearized ADMM algorithm and then generalizing the proximal operator to some\nlearnable activation function. Notably, we rigorously prove that there exist a\nset of learnable parameters for D-LADMM to generate globally converged\nsolutions, and we show that those desired parameters can be attained by\ntraining D-LADMM in a proper way. To the best of our knowledge, we are the\nfirst to provide the convergence analysis for the learning-based optimization\nmethod on constrained problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:42:25 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Xie", "Xingyu", ""], ["Wu", "Jianlong", ""], ["Zhong", "Zhisheng", ""], ["Liu", "Guangcan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1905.06208", "submitter": "Philip Thomas", "authors": "Erik Learned-Miller and Philip S. Thomas", "title": "A New Confidence Interval for the Mean of a Bounded Random Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for constructing a confidence interval for the mean\nof a bounded random variable from samples of the random variable. We conjecture\nthat the confidence interval has guaranteed coverage, i.e., that it contains\nthe mean with high probability for all distributions on a bounded interval, for\nall samples sizes, and for all confidence levels. This new method provides\nconfidence intervals that are competitive with those produced using Student's\nt-statistic, but does not rely on normality assumptions. In particular, its\nonly requirement is that the distribution be bounded on a known finite\ninterval.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:25:55 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 17:55:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Learned-Miller", "Erik", ""], ["Thomas", "Philip S.", ""]]}, {"id": "1905.06209", "submitter": "William Cohen", "authors": "William W. Cohen and Matthew Siegler and Alex Hofer", "title": "Neural Query Language: A Knowledge Base Query Language for Tensorflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge bases (KBs) are useful for many AI tasks, but are difficult\nto integrate into modern gradient-based learning systems. Here we describe a\nframework for accessing soft symbolic database using only differentiable\noperators. For example, this framework makes it easy to conveniently write\nneural models that adjust confidences associated with facts in a soft KB;\nincorporate prior knowledge in the form of hand-coded KB access rules; or learn\nto instantiate query templates using information extracted from text. NQL can\nwork well with KBs with millions of tuples and hundreds of thousands of\nentities on a single GPU.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:26:24 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Cohen", "William W.", ""], ["Siegler", "Matthew", ""], ["Hofer", "Alex", ""]]}, {"id": "1905.06214", "submitter": "Meng Qu", "authors": "Meng Qu, Yoshua Bengio, Jian Tang", "title": "GMNN: Graph Markov Neural Networks", "comments": "icml 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies semi-supervised object classification in relational data,\nwhich is a fundamental problem in relational data modeling. The problem has\nbeen extensively studied in the literature of both statistical relational\nlearning (e.g. relational Markov networks) and graph neural networks (e.g.\ngraph convolutional networks). Statistical relational learning methods can\neffectively model the dependency of object labels through conditional random\nfields for collective classification, whereas graph neural networks learn\neffective object representations for classification through end-to-end\ntraining. In this paper, we propose the Graph Markov Neural Network (GMNN) that\ncombines the advantages of both worlds. A GMNN models the joint distribution of\nobject labels with a conditional random field, which can be effectively trained\nwith the variational EM algorithm. In the E-step, one graph neural network\nlearns effective object representations for approximating the posterior\ndistributions of object labels. In the M-step, another graph neural network is\nused to model the local label dependency. Experiments on object classification,\nlink classification, and unsupervised node representation learning show that\nGMNN achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:39:33 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 02:41:37 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 19:55:06 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Qu", "Meng", ""], ["Bengio", "Yoshua", ""], ["Tang", "Jian", ""]]}, {"id": "1905.06220", "submitter": "Clement Etienam", "authors": "David E. Bernholdt, Mark R. Cianciosa, Clement Etienam, David L.\n  Green, Kody J. H. Law, and J. M. Park", "title": "Cluster, Classify, Regress: A General Method For Learning Discountinous\n  Functions", "comments": "12 files,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a method for solving the supervised learning problem in\nwhich the output is highly nonlinear and discontinuous. It is proposed to solve\nthis problem in three stages: (i) cluster the pairs of input-output data\npoints, resulting in a label for each point; (ii) classify the data, where the\ncorresponding label is the output; and finally (iii) perform one separate\nregression for each class, where the training data corresponds to the subset of\nthe original input-output pairs which have that label according to the\nclassifier. It has not yet been proposed to combine these 3 fundamental\nbuilding blocks of machine learning in this simple and powerful fashion. This\ncan be viewed as a form of deep learning, where any of the intermediate layers\ncan itself be deep. The utility and robustness of the methodology is\nillustrated on some toy problems, including one example problem arising from\nsimulation of plasma fusion in a tokamak.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:47:55 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 06:11:48 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Bernholdt", "David E.", ""], ["Cianciosa", "Mark R.", ""], ["Etienam", "Clement", ""], ["Green", "David L.", ""], ["Law", "Kody J. H.", ""], ["Park", "J. M.", ""]]}, {"id": "1905.06230", "submitter": "Pedro Mercado", "authors": "Pedro Mercado, Francesco Tudisco and Matthias Hein", "title": "Spectral Clustering of Signed Graphs via Matrix Power Means", "comments": "final version accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed graphs encode positive (attractive) and negative (repulsive) relations\nbetween nodes. We extend spectral clustering to signed graphs via the\none-parameter family of Signed Power Mean Laplacians, defined as the matrix\npower mean of normalized standard and signless Laplacians of positive and\nnegative edges. We provide a thorough analysis of the proposed approach in the\nsetting of a general Stochastic Block Model that includes models such as the\nLabeled Stochastic Block Model and the Censored Block Model. We show that in\nexpectation the signed power mean Laplacian captures the ground truth clusters\nunder reasonable settings where state-of-the-art approaches fail. Moreover, we\nprove that the eigenvalues and eigenvector of the signed power mean Laplacian\nconcentrate around their expectation under reasonable conditions in the general\nStochastic Block Model. Extensive experiments on random graphs and real world\ndatasets confirm the theoretically predicted behaviour of the signed power mean\nLaplacian and show that it compares favourably with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:11:44 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mercado", "Pedro", ""], ["Tudisco", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1905.06236", "submitter": "Wushi Dong", "authors": "Wushi Dong, Murat Keceli, Rafael Vescovi, Hanyu Li, Corey Adams, Elise\n  Jennings, Samuel Flender, Tom Uram, Venkatram Vishwanath, Nicola Ferrier,\n  Narayanan Kasthuri, Peter Littlewood", "title": "Scaling Distributed Training of Flood-Filling Networks on HPC\n  Infrastructure for Brain Mapping", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping all the neurons in the brain requires automatic reconstruction of\nentire cells from volume electron microscopy data. The flood-filling network\n(FFN) architecture has demonstrated leading performance for segmenting\nstructures from this data. However, the training of the network is\ncomputationally expensive. In order to reduce the training time, we implemented\nsynchronous and data-parallel distributed training using the Horovod library,\nwhich is different from the asynchronous training scheme used in the published\nFFN code. We demonstrated that our distributed training scaled well up to 2048\nIntel Knights Landing (KNL) nodes on the Theta supercomputer. Our trained\nmodels achieved similar level of inference performance, but took less training\ntime compared to previous methods. Our study on the effects of different batch\nsizes on FFN training suggests ways to further improve training efficiency. Our\nfindings on optimal learning rate and batch sizes agree with previous works.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:00:52 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 03:27:23 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 17:37:37 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 22:29:23 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Dong", "Wushi", ""], ["Keceli", "Murat", ""], ["Vescovi", "Rafael", ""], ["Li", "Hanyu", ""], ["Adams", "Corey", ""], ["Jennings", "Elise", ""], ["Flender", "Samuel", ""], ["Uram", "Tom", ""], ["Vishwanath", "Venkatram", ""], ["Ferrier", "Nicola", ""], ["Kasthuri", "Narayanan", ""], ["Littlewood", "Peter", ""]]}, {"id": "1905.06242", "submitter": "Rodrigo Berriel", "authors": "Rodrigo Berriel, St\\'ephane Lathuili\\`ere, Moin Nabi, Tassilo Klein,\n  Thiago Oliveira-Santos, Nicu Sebe, Elisa Ricci", "title": "Budget-Aware Adapters for Multi-Domain Learning", "comments": "ICCV 2019", "journal-ref": null, "doi": "10.1109/ICCV.2019.00047", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Domain Learning (MDL) refers to the problem of learning a set of models\nderived from a common deep architecture, each one specialized to perform a task\nin a certain domain (e.g., photos, sketches, paintings). This paper tackles MDL\nwith a particular interest in obtaining domain-specific models with an\nadjustable budget in terms of the number of network parameters and\ncomputational complexity. Our intuition is that, as in real applications the\nnumber of domains and tasks can be very large, an effective MDL approach should\nnot only focus on accuracy but also on having as few parameters as possible. To\nimplement this idea we derive specialized deep models for each domain by\nadapting a pre-trained architecture but, differently from other methods, we\npropose a novel strategy to automatically adjust the computational complexity\nof the network. To this aim, we introduce Budget-Aware Adapters that select the\nmost relevant feature channels to better handle data from a novel domain. Some\nconstraints on the number of active switches are imposed in order to obtain a\nnetwork respecting the desired complexity budget. Experimentally, we show that\nour approach leads to recognition accuracy competitive with state-of-the-art\napproaches but with much lighter networks both in terms of storage and\ncomputation.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:25:04 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:38:44 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 14:18:06 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Berriel", "Rodrigo", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Nabi", "Moin", ""], ["Klein", "Tassilo", ""], ["Oliveira-Santos", "Thiago", ""], ["Sebe", "Nicu", ""], ["Ricci", "Elisa", ""]]}, {"id": "1905.06246", "submitter": "Bamdev Mishra", "authors": "Anil R. Yelundur, Vineet Chaoji, and Bamdev Mishra", "title": "Detection of Review Abuse via Semi-Supervised Binary Multi-Target Tensor\n  Decomposition", "comments": "Accepted to the 25th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, 2019. Contains supplementary material. arXiv admin note: text\n  overlap with arXiv:1804.03836", "journal-ref": null, "doi": "10.1145/3292500.3330678", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product reviews and ratings on e-commerce websites provide customers with\ndetailed insights about various aspects of the product such as quality,\nusefulness, etc. Since they influence customers' buying decisions, product\nreviews have become a fertile ground for abuse by sellers (colluding with\nreviewers) to promote their own products or to tarnish the reputation of\ncompetitor's products. In this paper, our focus is on detecting such abusive\nentities (both sellers and reviewers) by applying tensor decomposition on the\nproduct reviews data. While tensor decomposition is mostly unsupervised, we\nformulate our problem as a semi-supervised binary multi-target tensor\ndecomposition, to take advantage of currently known abusive entities. We\nempirically show that our multi-target semi-supervised model achieves higher\nprecision and recall in detecting abusive entities as compared to unsupervised\ntechniques. Finally, we show that our proposed stochastic partial natural\ngradient inference for our model empirically achieves faster convergence than\nstochastic gradient and Online-EM with sufficient statistics.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:28:12 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 08:15:14 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Yelundur", "Anil R.", ""], ["Chaoji", "Vineet", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1905.06247", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Olivier Caelen,\n  Liyun He-Guelton, Sylvie Calabretto, Michael Granitzer", "title": "Multiple perspectives HMM-based feature engineering for credit card\n  fraud detection", "comments": "Presented as a poster in the conference SAC 2019: 34th ACM/SIGAPP\n  Symposium on Applied Computing in April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However, most studies consider credit card\ntransactions as isolated events and not as a sequence of transactions.\n  In this article, we model a sequence of credit card transactions from three\ndifferent perspectives, namely (i) does the sequence contain a Fraud? (ii) Is\nthe sequence obtained by fixing the card-holder or the payment terminal? (iii)\nIs it a sequence of spent amount or of elapsed time between the current and\nprevious transactions? Combinations of the three binary perspectives give eight\nsets of sequences from the (training) set of transactions. Each one of these\nsets is modelled with a Hidden Markov Model (HMM). Each HMM associates a\nlikelihood to a transaction given its sequence of previous transactions. These\nlikelihoods are used as additional features in a Random Forest classifier for\nfraud detection. This multiple perspectives HMM-based approach enables an\nautomatic feature engineering in order to model the sequential properties of\nthe dataset with respect to the classification task. This strategy allows for a\n15% increase in the precision-recall AUC compared to the state of the art\nfeature engineering strategy for credit card fraud detection.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:29:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["Caelen", "Olivier", ""], ["He-Guelton", "Liyun", ""], ["Calabretto", "Sylvie", ""], ["Granitzer", "Michael", ""]]}, {"id": "1905.06256", "submitter": "Pengfei Li", "authors": "Pengfei Li, Yu Hua, Pengfei Zuo, Jingnan Jia", "title": "A Scalable Learned Index Scheme in Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Index structures are important for efficient data access, which have been\nwidely used to improve the performance in many in-memory systems. Due to high\nin-memory overheads, traditional index structures become difficult to process\nthe explosive growth of data, let alone providing low latency and high\nthroughput performance with limited system resources. The promising learned\nindexes leverage deep-learning models to complement existing index structures\nand obtain significant memory savings. However, the learned indexes fail to\nbecome scalable due to the heavy inter-model dependency and expensive\nretraining. To address these problems, we propose a scalable learned index\nscheme to construct different linear regression models according to the data\ndistribution. Moreover, the used models are independent so as to reduce the\ncomplexity of retraining and become easy to partition and store the data into\ndifferent pages, blocks or distributed systems. Our experimental results show\nthat compared with state-of-the-art schemes, AIDEL improves the insertion\nperformance by about 2$\\times$ and provides comparable lookup performance,\nwhile efficiently supporting scalability.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:14:19 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Li", "Pengfei", ""], ["Hua", "Yu", ""], ["Zuo", "Pengfei", ""], ["Jia", "Jingnan", ""]]}, {"id": "1905.06259", "submitter": "Padraig Corcoran", "authors": "Padraig Corcoran", "title": "Function Space Pooling For Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional layers in graph neural networks are a fundamental type of layer\nwhich output a representation or embedding of each graph vertex. The\nrepresentation typically encodes information about the vertex in question and\nits neighbourhood. If one wishes to perform a graph centric task, such as graph\nclassification, this set of vertex representations must be integrated or pooled\nto form a graph representation.\n  In this article we propose a novel pooling method which maps a set of vertex\nrepresentations to a function space representation. This method is distinct\nfrom existing pooling methods which perform a mapping to either a vector or\nsequence space. Experimental graph classification results demonstrate that the\nproposed method generally outperforms most baseline pooling methods and in some\ncases achieves best performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:54:44 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 09:10:52 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Corcoran", "Padraig", ""]]}, {"id": "1905.06262", "submitter": "Felipe Ducau", "authors": "Felipe N. Ducau, Ethan M. Rudd, Tad M. Heppner, Alex Long, and\n  Konstantin Berlin", "title": "Automatic Malware Description via Attribute Tagging and Similarity\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid proliferation and increased sophistication of malicious\nsoftware (malware), detection methods no longer rely only on manually generated\nsignatures but have also incorporated more general approaches like machine\nlearning detection. Although powerful for conviction of malicious artifacts,\nthese methods do not produce any further information about the type of threat\nthat has been detected neither allows for identifying relationships between\nmalware samples. In this work, we address the information gap between machine\nlearning and signature-based detection methods by learning a representation\nspace for malware samples in which files with similar malicious behaviors\nappear close to each other. We do so by introducing a deep learning based\ntagging model trained to generate human-interpretable semantic descriptions of\nmalicious software, which, at the same time provides potentially more useful\nand flexible information than malware family names.\n  We show that the malware descriptions generated with the proposed approach\ncorrectly identify more than 95% of eleven possible tag descriptions for a\ngiven sample, at a deployable false positive rate of 1% per tag. Furthermore,\nwe use the learned representation space to introduce a similarity index between\nmalware files, and empirically demonstrate using dynamic traces from files'\nexecution, that is not only more effective at identifying samples from the same\nfamilies, but also 32 times smaller than those based on raw feature vectors.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:03:46 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 17:52:08 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 16:09:15 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ducau", "Felipe N.", ""], ["Rudd", "Ethan M.", ""], ["Heppner", "Tad M.", ""], ["Long", "Alex", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1905.06263", "submitter": "Antoine Lesage-Landry", "authors": "Antoine Lesage-Landry, Iman Shames, Joshua A. Taylor", "title": "Predictive Online Convex Optimization", "comments": null, "journal-ref": "Automatica, 113: 108771, March 2020", "doi": "10.1016/j.automatica.2019.108771", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We incorporate future information in the form of the estimated value of\nfuture gradients in online convex optimization. This is motivated by demand\nresponse in power systems, where forecasts about the current round, e.g., the\nweather or the loads' behavior, can be used to improve on predictions made with\nonly past observations. Specifically, we introduce an additional predictive\nstep that follows the standard online convex optimization step when certain\nconditions on the estimated gradient and descent direction are met. We show\nthat under these conditions and without any assumptions on the predictability\nof the environment, the predictive update strictly improves on the performance\nof the standard update. We give two types of predictive update for various\nfamily of loss functions. We provide a regret bound for each of our predictive\nonline convex optimization algorithms. Finally, we apply our framework to an\nexample based on demand response which demonstrates its superior performance to\na standard online convex optimization algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:05:11 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:48:51 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Lesage-Landry", "Antoine", ""], ["Shames", "Iman", ""], ["Taylor", "Joshua A.", ""]]}, {"id": "1905.06265", "submitter": "Martin Wainwright", "authors": "Martin J. Wainwright", "title": "Stochastic approximation with cone-contractive operators: Sharp\n  $\\ell_\\infty$-bounds for $Q$-learning", "comments": "Changes from v1: -- Part of Lemma 1 was incorrect; corrected -- proof\n  of Lemma 2: fixed minor typo in equation (36)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the study of $Q$-learning algorithms in reinforcement learning,\nwe study a class of stochastic approximation procedures based on operators that\nsatisfy monotonicity and quasi-contractivity conditions with respect to an\nunderlying cone. We prove a general sandwich relation on the iterate error at\neach time, and use it to derive non-asymptotic bounds on the error in terms of\na cone-induced gauge norm. These results are derived within a deterministic\nframework, requiring no assumptions on the noise. We illustrate these general\nbounds in application to synchronous $Q$-learning for discounted Markov\ndecision processes with discrete state-action spaces, in particular by deriving\nnon-asymptotic bounds on the $\\ell_\\infty$-norm for a range of stepsizes. These\nresults are the sharpest known to date, and we show via simulation that the\ndependence of our bounds cannot be improved in a worst-case sense. These\nresults show that relative to a model-based $Q$-iteration, the\n$\\ell_\\infty$-based sample complexity of $Q$-learning is suboptimal in terms of\nthe discount factor $\\gamma$.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:06:30 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 17:09:55 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wainwright", "Martin J.", ""]]}, {"id": "1905.06274", "submitter": "Zequn Wang", "authors": "Narendra Patwardhan and Zequn Wang", "title": "Reinforcement Learning for Robotics and Control with Active Uncertainty\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning based methods such as Proximal Policy\nOptimization, or Q-learning typically require thousands of interactions with\nthe environment to approximate the optimum controller which may not always be\nfeasible in robotics due to safety and time consumption. Model-based methods\nsuch as PILCO or BlackDrops, while data-efficient, provide solutions with\nlimited robustness and complexity. To address this tradeoff, we introduce\nactive uncertainty reduction-based virtual environments, which are formed\nthrough limited trials conducted in the original environment. We provide an\nefficient method for uncertainty management, which is used as a metric for\nself-improvement by identification of the points with maximum expected\nimprovement through adaptive sampling. Capturing the uncertainty also allows\nfor better mimicking of the reward responses of the original system. Our\napproach enables the use of complex policy structures and reward functions\nthrough a unique combination of model-based and model-free methods, while still\nretaining the data efficiency. We demonstrate the validity of our method on\nseveral classic reinforcement learning problems in OpenAI gym. We prove that\nour approach offers a better modeling capacity for complex system dynamics as\ncompared to established methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:21:05 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Patwardhan", "Narendra", ""], ["Wang", "Zequn", ""]]}, {"id": "1905.06286", "submitter": "Rongzhi Gu", "authors": "Rongzhi Gu, Jian Wu, Shi-Xiong Zhang, Lianwu Chen, Yong Xu, Meng Yu,\n  Dan Su, Yuexian Zou, Dong Yu", "title": "End-to-End Multi-Channel Speech Separation", "comments": "submitted to interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The end-to-end approach for single-channel speech separation has been studied\nrecently and shown promising results. This paper extended the previous approach\nand proposed a new end-to-end model for multi-channel speech separation. The\nprimary contributions of this work include 1) an integrated waveform-in\nwaveform-out separation system in a single neural network architecture. 2) We\nreformulate the traditional short time Fourier transform (STFT) and\ninter-channel phase difference (IPD) as a function of time-domain convolution\nwith a special kernel. 3) We further relaxed those fixed kernels to be\nlearnable, so that the entire architecture becomes purely data-driven and can\nbe trained from end-to-end. We demonstrate on the WSJ0 far-field speech\nseparation task that, with the benefit of learnable spatial features, our\nproposed end-to-end multi-channel model significantly improved the performance\nof previous end-to-end single-channel method and traditional multi-channel\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:38:16 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 02:02:38 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Gu", "Rongzhi", ""], ["Wu", "Jian", ""], ["Zhang", "Shi-Xiong", ""], ["Chen", "Lianwu", ""], ["Xu", "Yong", ""], ["Yu", "Meng", ""], ["Su", "Dan", ""], ["Zou", "Yuexian", ""], ["Yu", "Dong", ""]]}, {"id": "1905.06287", "submitter": "Wanqian Yang", "authors": "Wanqian Yang, Lars Lorch, Moritz A. Graule, Srivatsan Srinivasan,\n  Anirudh Suresh, Jiayu Yao, Melanie F. Pradier, Finale Doshi-Velez", "title": "Output-Constrained Bayesian Neural Networks", "comments": "Presented at the ICML 2019 Workshop on Uncertainty and Robustness in\n  Deep Learning and Workshop on Understanding and Improving Generalization in\n  Deep Learning. Long Beach, CA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural network (BNN) priors are defined in parameter space, making\nit hard to encode prior knowledge expressed in function space. We formulate a\nprior that incorporates functional constraints about what the output can or\ncannot be in regions of the input space. Output-Constrained BNNs (OC-BNN)\nrepresent an interpretable approach of enforcing a range of constraints, fully\nconsistent with the Bayesian framework and amenable to black-box inference. We\ndemonstrate how OC-BNNs improve model robustness and prevent the prediction of\ninfeasible outputs in two real-world applications of healthcare and robotics.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:44:12 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yang", "Wanqian", ""], ["Lorch", "Lars", ""], ["Graule", "Moritz A.", ""], ["Srinivasan", "Srivatsan", ""], ["Suresh", "Anirudh", ""], ["Yao", "Jiayu", ""], ["Pradier", "Melanie F.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1905.06289", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson", "title": "A Human-Centered Approach to Interactive Machine Learning", "comments": "4 pages, 4th Multidisciplinary Conference on Reinforcement Learning\n  and Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactive machine learning (IML) community aims to augment humans'\nability to learn and make decisions over time through the development of\nautomated decision-making systems. This interaction represents a collaboration\nbetween multiple intelligent systems---humans and machines. A lack of\nappropriate consideration for the humans involved can lead to problematic\nsystem behaviour, and issues of fairness, accountability, and transparency.\nThis work presents a human-centred thinking approach to applying IML methods.\nThis guide is intended to be used by AI practitioners who incorporate human\nfactors in their work. These practitioners are responsible for the health,\nsafety, and well-being of interacting humans. An obligation of responsibility\nfor public interaction means acting with integrity, honesty, fairness, and\nabiding by applicable legal statutes. With these values and principles in mind,\nwe as a research community can better achieve the collective goal of augmenting\nhuman ability. This practical guide aims to support many of the responsible\ndecisions necessary throughout iterative design, development, and dissemination\nof IML systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:46:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mathewson", "Kory W.", ""]]}, {"id": "1905.06312", "submitter": "Ziyuan Zhao", "authors": "Ziyuan Zhao, Kerui Zhang, Xuejie Hao, Jing Tian, Matthew Chin Heng\n  Chua, Li Chen, Xin Xu", "title": "BiRA-Net: Bilinear Attention Net for Diabetic Retinopathy Grading", "comments": "Accepted at ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic retinopathy (DR) is a common retinal disease that leads to\nblindness. For diagnosis purposes, DR image grading aims to provide automatic\nDR grade classification, which is not addressed in conventional research\nmethods of binary DR image classification. Small objects in the eye images,\nlike lesions and microaneurysms, are essential to DR grading in medical\nimaging, but they could easily be influenced by other objects. To address these\nchallenges, we propose a new deep learning architecture, called BiRA-Net, which\ncombines the attention model for feature extraction and bilinear model for\nfine-grained classification. Furthermore, in considering the distance between\ndifferent grades of different DR categories, we propose a new loss function,\ncalled grading loss, which leads to improved training convergence of the\nproposed approach. Experimental results are provided to demonstrate the\nsuperior performance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:38:52 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 04:48:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhao", "Ziyuan", ""], ["Zhang", "Kerui", ""], ["Hao", "Xuejie", ""], ["Tian", "Jing", ""], ["Chua", "Matthew Chin Heng", ""], ["Chen", "Li", ""], ["Xu", "Xin", ""]]}, {"id": "1905.06327", "submitter": "Ali Takbiri-Borujeni", "authors": "Ali Takbiri-Borujeni and Hadi Kazemi and Nasser Nasrabadi", "title": "A data-driven proxy to Stoke's flow in porous media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective for this work is to develop a data-driven proxy to\nhigh-fidelity numerical flow simulations using digital images. The proposed\nmodel can capture the flow field and permeability in a large verity of digital\nporous media based on solid grain geometry and pore size distribution by\ndetailed analyses of the local pore geometry and the local flow fields. To\ndevelop the model, the detailed pore space geometry and simulation runs data\nfrom 3500 two-dimensional high-fidelity Lattice Boltzmann simulation runs are\nused to train and to predict the solutions with a high accuracy in much less\ncomputational time. The proposed methodology harness the enormous amount of\ngenerated data from high-fidelity flow simulations to decode the often\nunder-utilized patterns in simulations and to accurately predict solutions to\nnew cases. The developed model can truly capture the physics of the problem and\nenhance prediction capabilities of the simulations at a much lower cost. These\npredictive models, in essence, do not spatio-temporally reduce the order of the\nproblem. They, however, possess the same numerical resolutions as their Lattice\nBoltzmann simulations equivalents do with the great advantage that their\nsolutions can be achieved by significant reduction in computational costs\n(speed and memory).\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 21:49:58 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Takbiri-Borujeni", "Ali", ""], ["Kazemi", "Hadi", ""], ["Nasrabadi", "Nasser", ""]]}, {"id": "1905.06329", "submitter": "Lei Chu", "authors": "Lei Chu, Ling Pei, Husheng Li, Robert Caiming Qiu", "title": "LEMO: Learn to Equalize for MIMO-OFDM Systems with Low-Resolution ADCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new deep neural network optimized equalization\nframework for massive multiple input multiple output orthogonal frequency\ndivision multiplexing (MIMOOFDM) systems that employ low-resolution\nanalog-to-digital converters (ADCs) at the base station (BS). The use of\nlowresolution ADCs could largely reduce hardware complexity and circuit power\nconsumption, however, it makes the channel station information almost blind to\nthe BS, hence causing difficulty in solving the equalization problem. In this\npaper, we consider a supervised learning architecture, where the goal is to\nlearn a representative function that can predict the targets (constellation\npoints) from the inputs (outputs of the low-resolution ADCs) based on the\nlabeled training data (pilot signals). Especially, our main contributions are\ntwo-fold: 1) First, we design a new activation function, whose outputs are\nclose to the constellation points when the parameters are finally optimized, to\nhelp us fully exploit the stochastic gradient descent method for the discrete\noptimization problem. 2) Second, an unsupervised loss is designed and then\nadded to the optimization objective, aiming to enhance the representation\nability (so-called generalization). Lastly, various experimental results\nconfirm the superiority of the proposed equalizer over some existing ones,\nparticularly when the statistics of the channel state information are unclear.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:53:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:00:02 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Chu", "Lei", ""], ["Pei", "Ling", ""], ["Li", "Husheng", ""], ["Qiu", "Robert Caiming", ""]]}, {"id": "1905.06330", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Hua Li, Mark A. Anastasio", "title": "Approximating the Ideal Observer and Hotelling Observer for binary\n  signal detection tasks by use of supervised learning methods", "comments": "IEEE Transactions on Medical Imaging (Early Access), 2019", "journal-ref": null, "doi": "10.1109/TMI.2019.2911211", "report-no": null, "categories": "eess.SP cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely accepted that optimization of medical imaging system performance\nshould be guided by task-based measures of image quality (IQ). Task-based\nmeasures of IQ quantify the ability of an observer to perform a specific task\nsuch as detection or estimation of a signal (e.g., a tumor). For binary signal\ndetection tasks, the Bayesian Ideal Observer (IO) sets an upper limit of\nobserver performance and has been advocated for use in optimizing medical\nimaging systems and data-acquisition designs. Except in special cases,\ndetermination of the IO test statistic is analytically intractable.\nMarkov-chain Monte Carlo (MCMC) techniques can be employed to approximate IO\ndetection performance, but their reported applications have been limited to\nrelatively simple object models. In cases where the IO test statistic is\ndifficult to compute, the Hotelling Observer (HO) can be employed. To compute\nthe HO test statistic, potentially large covariance matrices must be accurately\nestimated and subsequently inverted, which can present computational\nchallenges. This work investigates supervised learning-based methodologies for\napproximating the IO and HO test statistics. Convolutional neural networks\n(CNNs) and single-layer neural networks (SLNNs) are employed to approximate the\nIO and HO test statistics, respectively. Numerical simulations were conducted\nfor both signal-known-exactly (SKE) and signal-known-statistically (SKS) signal\ndetection tasks. The performances of the supervised learning methods are\nassessed via receiver operating characteristic (ROC) analysis and the results\nare compared to those produced by use of traditional numerical methods or\nanalytical calculations when feasible. The potential advantages of the proposed\nsupervised learning approaches for approximating the IO and HO test statistics\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:19:29 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhou", "Weimin", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "1905.06331", "submitter": "Huaiyu Li", "authors": "Huaiyu Li, Weiming Dong, Xing Mei, Chongyang Ma, Feiyue Huang,\n  Bao-Gang Hu", "title": "LGM-Net: Learning to Generate Matching Networks for Few-Shot Learning", "comments": "To appear in ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel meta-learning approach for few-shot\nclassification, which learns transferable prior knowledge across tasks and\ndirectly produces network parameters for similar unseen tasks with training\nsamples. Our approach, called LGM-Net, includes two key modules, namely,\nTargetNet and MetaNet. The TargetNet module is a neural network for solving a\nspecific task and the MetaNet module aims at learning to generate functional\nweights for TargetNet by observing training samples. We also present an\nintertask normalization strategy for the training process to leverage common\ninformation shared across different tasks. The experimental results on Omniglot\nand miniImageNet datasets demonstrate that LGM-Net can effectively adapt to\nsimilar unseen tasks and achieve competitive performance, and the results on\nsynthetic datasets show that transferable prior knowledge is learned by the\nMetaNet module via mapping training data to functional weights. LGM-Net enables\nfast learning and adaptation since no further tuning steps are required\ncompared to other meta-learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:29:26 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Li", "Huaiyu", ""], ["Dong", "Weiming", ""], ["Mei", "Xing", ""], ["Ma", "Chongyang", ""], ["Huang", "Feiyue", ""], ["Hu", "Bao-Gang", ""]]}, {"id": "1905.06335", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Zhilin Qiu, Guanbin Li, Qing Wang, Wanli Ouyang, Liang Lin", "title": "Contextualized Spatial-Temporal Network for Taxi Origin-Destination\n  Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxi demand prediction has recently attracted increasing research interest\ndue to its huge potential application in large-scale intelligent transportation\nsystems. However, most of the previous methods only considered the taxi demand\nprediction in origin regions, but neglected the modeling of the specific\nsituation of the destination passengers. We believe it is suboptimal to\npreallocate the taxi into each region based solely on the taxi origin demand.\nIn this paper, we present a challenging and worth-exploring task, called taxi\norigin-destination demand prediction, which aims at predicting the taxi demand\nbetween all region pairs in a future time interval. Its main challenges come\nfrom how to effectively capture the diverse contextual information to learn the\ndemand patterns. We address this problem with a novel Contextualized\nSpatial-Temporal Network (CSTN), which consists of three components for the\nmodeling of local spatial context (LSC), temporal evolution context (TEC) and\nglobal correlation context (GCC) respectively. Firstly, an LSC module utilizes\ntwo convolution neural networks to learn the local spatial dependencies of taxi\ndemand respectively from the origin view and the destination view. Secondly, a\nTEC module incorporates both the local spatial features of taxi demand and the\nmeteorological information to a Convolutional Long Short-term Memory Network\n(ConvLSTM) for the analysis of taxi demand evolution. Finally, a GCC module is\napplied to model the correlation between all regions by computing a global\ncorrelation feature as a weighted sum of all regional features, with the\nweights being calculated as the similarity between the corresponding region\npairs. Extensive experiments and evaluations on a large-scale dataset well\ndemonstrate the superiority of our CSTN over other compared methods for taxi\norigin-destination demand prediction.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:21:05 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Liu", "Lingbo", ""], ["Qiu", "Zhilin", ""], ["Li", "Guanbin", ""], ["Wang", "Qing", ""], ["Ouyang", "Wanli", ""], ["Lin", "Liang", ""]]}, {"id": "1905.06336", "submitter": "Zhang Junlin", "authors": "Junlin Zhang, Tongwen Huang, Zhiqi Zhang", "title": "FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Click through rate (CTR) estimation is a fundamental task in personalized\nadvertising and recommender systems. Recent years have witnessed the success of\nboth the deep learning based model and attention mechanism in various tasks in\ncomputer vision (CV) and natural language processing (NLP). How to combine the\nattention mechanism with deep CTR model is a promising direction because it may\nensemble the advantages of both sides. Although some CTR model such as\nAttentional Factorization Machine (AFM) has been proposed to model the weight\nof second order interaction features, we posit the evaluation of feature\nimportance before explicit feature interaction procedure is also important for\nCTR prediction tasks because the model can learn to selectively highlight the\ninformative features and suppress less useful ones if the task has many input\nfeatures. In this paper, we propose a new neural CTR model named Field\nAttentive Deep Field-aware Factorization Machine (FAT-DeepFFM) by combining the\nDeep Field-aware Factorization Machine (DeepFFM) with Compose-Excitation\nnetwork (CENet) field attention mechanism which is proposed by us as an\nenhanced version of Squeeze-Excitation network (SENet) to highlight the feature\nimportance. We conduct extensive experiments on two real-world datasets and the\nexperiment results show that FAT-DeepFFM achieves the best performance and\nobtains different improvements over the state-of-the-art methods. We also\ncompare two kinds of attention mechanisms (attention before explicit feature\ninteraction vs. attention after explicit feature interaction) and demonstrate\nthat the former one outperforms the latter one significantly.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:35:37 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhang", "Junlin", ""], ["Huang", "Tongwen", ""], ["Zhang", "Zhiqi", ""]]}, {"id": "1905.06352", "submitter": "Glen Evenbly", "authors": "Glen Evenbly", "title": "Number-State Preserving Tensor Networks as Classifiers for Supervised\n  Learning", "comments": "Main text: 12 pages, 9 figures. Appendices: 2 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a restricted class of tensor network state, built from\nnumber-state preserving tensors, for supervised learning tasks. This class of\ntensor network is argued to be a natural choice for classifiers as (i) they map\nclassical data to classical data, and thus preserve the interpretability of\ndata under tensor transformations, (ii) they can be efficiently trained to\nmaximize their scalar product against classical data sets, and (iii) they seem\nto be as powerful as generic (unrestricted) tensor networks in this task. Our\nproposal is demonstrated using a variety of benchmark classification problems,\nwhere number-state preserving versions of commonly used networks (including\nMPS, TTN and MERA) are trained as effective classifiers. This work opens the\npath for powerful tensor network methods such as MERA, which were previously\ncomputationally intractable as classifiers, to be employed for difficult tasks\nsuch as image recognition.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:00:27 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Evenbly", "Glen", ""]]}, {"id": "1905.06362", "submitter": "Sebastian Guendel", "authors": "Sebastian Guendel, Florin C. Ghesu, Sasa Grbic, Eli Gibson, Bogdan\n  Georgescu, Andreas Maier, Dorin Comaniciu", "title": "Multi-task Learning for Chest X-ray Abnormality Classification on Noisy\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest X-ray (CXR) is the most common X-ray examination performed in daily\nclinical practice for the diagnosis of various heart and lung abnormalities.\nThe large amount of data to be read and reported, with 100+ studies per day for\na single radiologist, poses a challenge in maintaining consistently high\ninterpretation accuracy. In this work, we propose a method for the\nclassification of different abnormalities based on CXR scans of the human body.\nThe system is based on a novel multi-task deep learning architecture that in\naddition to the abnormality classification, supports the segmentation of the\nlungs and heart and classification of regions where the abnormality is located.\nWe demonstrate that by training these tasks concurrently, one can increase the\nclassification performance of the model. Experiments were performed on an\nextensive collection of 297,541 chest X-ray images from 86,876 patients,\nleading to a state-of-the-art performance level of 0.883 AUC on average for 12\ndifferent abnormalities. We also conducted a detailed performance analysis and\ncompared the accuracy of our system with 3 board-certified radiologists. In\nthis context, we highlight the high level of label noise inherent to this\nproblem. On a reduced subset containing only cases with high confidence\nreference labels based on the consensus of the 3 radiologists, our system\nreached an average AUC of 0.945.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:09:40 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Guendel", "Sebastian", ""], ["Ghesu", "Florin C.", ""], ["Grbic", "Sasa", ""], ["Gibson", "Eli", ""], ["Georgescu", "Bogdan", ""], ["Maier", "Andreas", ""], ["Comaniciu", "Dorin", ""]]}, {"id": "1905.06384", "submitter": "Syed Anwar", "authors": "Aamir Arsalan, Muhammad Majid, Syed Muhammad Anwar, Ulas Bagci", "title": "Classification of Perceived Human Stress using Physiological Signals", "comments": "Accepted for publication in EMBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an experimental study for the classification of\nperceived human stress using non-invasive physiological signals. These include\nelectroencephalography (EEG), galvanic skin response (GSR), and\nphotoplethysmography (PPG). We conducted experiments consisting of steps\nincluding data acquisition, feature extraction, and perceived human stress\nclassification. The physiological data of $28$ participants are acquired in an\nopen eye condition for a duration of three minutes. Four different features are\nextracted in time domain from EEG, GSR and PPG signals and classification is\nperformed using multiple classifiers including support vector machine, the\nNaive Bayes, and multi-layer perceptron (MLP). The best classification accuracy\nof 75% is achieved by using MLP classifier. Our experimental results have shown\nthat our proposed scheme outperforms existing perceived stress classification\nmethods, where no stress inducers are used.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 23:27:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Arsalan", "Aamir", ""], ["Majid", "Muhammad", ""], ["Anwar", "Syed Muhammad", ""], ["Bagci", "Ulas", ""]]}, {"id": "1905.06393", "submitter": "Jie Chen", "authors": "Patrick Ferber, Tengfei Ma, Siyu Huo, Jie Chen, Michael Katz", "title": "IPC: A Benchmark Data Set for Learning with Graph-Structured Data", "comments": "ICML 2019 Workshop on Learning and Reasoning with Graph-Structured\n  Data. The data set is accessible from https://github.com/IBM/IPC-graph-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmark data sets are an indispensable ingredient of the evaluation of\ngraph-based machine learning methods. We release a new data set, compiled from\nInternational Planning Competitions (IPC), for benchmarking graph\nclassification, regression, and related tasks. Apart from the graph\nconstruction (based on AI planning problems) that is interesting in its own\nright, the data set possesses distinctly different characteristics from\npopularly used benchmarks. The data set, named IPC, consists of two\nself-contained versions, grounded and lifted, both including graphs of large\nand skewedly distributed sizes, posing substantial challenges for the\ncomputation of graph models such as graph kernels and graph neural networks.\nThe graphs in this data set are directed and the lifted version is acyclic,\noffering the opportunity of benchmarking specialized models for directed\n(acyclic) structures. Moreover, the graph generator and the labeling are\ncomputer programmed; thus, the data set may be extended easily if a larger\nscale is desired. The data set is accessible from\n\\url{https://github.com/IBM/IPC-graph-data}.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:03:22 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ferber", "Patrick", ""], ["Ma", "Tengfei", ""], ["Huo", "Siyu", ""], ["Chen", "Jie", ""], ["Katz", "Michael", ""]]}, {"id": "1905.06394", "submitter": "Taisuke Yasuda", "authors": "Manuel Fernandez, David P. Woodruff, Taisuke Yasuda", "title": "Tight Kernel Query Complexity of Kernel Ridge Regression and Kernel\n  $k$-means Clustering", "comments": "27 pages, to appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present tight lower bounds on the number of kernel evaluations required to\napproximately solve kernel ridge regression (KRR) and kernel $k$-means\nclustering (KKMC) on $n$ input points. For KRR, our bound for relative error\napproximation to the minimizer of the objective function is\n$\\Omega(nd_{\\mathrm{eff}}^\\lambda/\\varepsilon)$ where\n$d_{\\mathrm{eff}}^\\lambda$ is the effective statistical dimension, which is\ntight up to a $\\log(d_{\\mathrm{eff}}^\\lambda/\\varepsilon)$ factor. For KKMC,\nour bound for finding a $k$-clustering achieving a relative error approximation\nof the objective function is $\\Omega(nk/\\varepsilon)$, which is tight up to a\n$\\log(k/\\varepsilon)$ factor. Our KRR result resolves a variant of an open\nquestion of El Alaoui and Mahoney, asking whether the effective statistical\ndimension is a lower bound on the sampling complexity or not. Furthermore, for\nthe important practical case when the input is a mixture of Gaussians, we\nprovide a KKMC algorithm which bypasses the above lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:04:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Fernandez", "Manuel", ""], ["Woodruff", "David P.", ""], ["Yasuda", "Taisuke", ""]]}, {"id": "1905.06401", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Afra Alishahi", "title": "Correlating neural and symbolic representations of language", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis methods which enable us to better understand the representations and\nfunctioning of neural models of language are increasingly needed as deep\nlearning becomes the dominant approach in NLP. Here we present two methods\nbased on Representational Similarity Analysis (RSA) and Tree Kernels (TK) which\nallow us to directly quantify how strongly the information encoded in neural\nactivation patterns corresponds to information represented by symbolic\nstructures such as syntax trees. We first validate our methods on the case of a\nsimple synthetic language for arithmetic expressions with clearly defined\nsyntax and semantics, and show that they exhibit the expected pattern of\nresults. We then apply our methods to correlate neural representations of\nEnglish sentences with their constituency parse trees.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:09:14 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 14:26:11 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Alishahi", "Afra", ""]]}, {"id": "1905.06407", "submitter": "Lei Shu", "authors": "Lei Shu and Hu Xu and Bing Liu", "title": "Controlled CNN-based Sequence Labeling for Aspect Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key task of fine-grained sentiment analysis on reviews is to extract\naspects or features that users have expressed opinions on. This paper focuses\non supervised aspect extraction using a modified CNN called controlled CNN\n(Ctrl). The modified CNN has two types of control modules. Through asynchronous\nparameter updating, it prevents over-fitting and boosts CNN's performance\nsignificantly. This model achieves state-of-the-art results on standard aspect\nextraction datasets. To the best of our knowledge, this is the first paper to\napply control modules to aspect extraction.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:28:10 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:22:38 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Shu", "Lei", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""]]}, {"id": "1905.06424", "submitter": "Jan Humplik", "authors": "Jan Humplik, Alexandre Galashov, Leonard Hasenclever, Pedro A. Ortega,\n  Yee Whye Teh, Nicolas Heess", "title": "Meta reinforcement learning as task inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans achieve efficient learning by relying on prior knowledge about the\nstructure of naturally occurring tasks. There is considerable interest in\ndesigning reinforcement learning (RL) algorithms with similar properties. This\nincludes proposals to learn the learning algorithm itself, an idea also known\nas meta learning. One formal interpretation of this idea is as a partially\nobservable multi-task RL problem in which task information is hidden from the\nagent. Such unknown task problems can be reduced to Markov decision processes\n(MDPs) by augmenting an agent's observations with an estimate of the belief\nabout the task based on past experience. However estimating the belief state is\nintractable in most partially-observed MDPs. We propose a method that\nseparately learns the policy and the task belief by taking advantage of various\nkinds of privileged information. Our approach can be very effective at solving\nstandard meta-RL environments, as well as a complex continuous control\nenvironment with sparse rewards and requiring long-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 20:21:14 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 15:54:03 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Humplik", "Jan", ""], ["Galashov", "Alexandre", ""], ["Hasenclever", "Leonard", ""], ["Ortega", "Pedro A.", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "1905.06431", "submitter": "Francisco Jacob Avila-Camacho FJ Avila-Camacho", "authors": "Jose de Jesus Rubio, Francisco Jacob Avila, Adolfo Melendez, Juan\n  Manuel Stein, Jesus Alberto Meda, Carlos Aguilar", "title": "Classification via an Embedded Approach", "comments": "16 Pages", "journal-ref": "www.mdpi.com/journal/designs Designs 2017", "doi": "10.3390/designs1010007", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the results of an automated volatile organic compound\n(VOC) classification process implemented by embedding a machine learning\nalgorithm into an Arduino Uno board. An electronic nose prototype is\nconstructed to detect VOCs from three different fruits. The electronic nose is\nconstructed using an array of five tin dioxide (SnO2) gas sensors, an Arduino\nUno board used as a data acquisition section, as well as an intelligent\nclassification module by embedding an approach function which receives data\nsignals from the electronic nose. For the intelligent classification module, a\ntraining algorithm is also implemented to create the base of a portable,\nautomated, fast-response, and economical electronic nose device. This solution\nproposes a portable system to identify and classify VOCs without using a\npersonal computer (PC). Results show an acceptable precision for the embedded\napproach in comparison with the performance of a toolbox used in a PC. This\nconstitutes an embedded solution able to recognize VOCs in a reliable way to\ncreate application products for a wide variety of industries, which are able to\nclassify data acquired by an electronic nose, as VOCs. With this proposed and\nimplemented algorithm, a precision of 99% for classification was achieved into\nthe embedded solution.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 20:51:08 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Rubio", "Jose de Jesus", ""], ["Avila", "Francisco Jacob", ""], ["Melendez", "Adolfo", ""], ["Stein", "Juan Manuel", ""], ["Meda", "Jesus Alberto", ""], ["Aguilar", "Carlos", ""]]}, {"id": "1905.06435", "submitter": "Simeon Spasov Mr", "authors": "Simeon E. Spasov and Pietro Lio", "title": "Dynamic Neural Network Channel Execution for Efficient Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for reducing the computational burden of neural networks at\nrun-time, such as parameter pruning or dynamic computational path selection,\nfocus solely on improving computational efficiency during inference. On the\nother hand, in this work, we propose a novel method which reduces the memory\nfootprint and number of computing operations required for training and\ninference. Our framework efficiently integrates pruning as part of the training\nprocedure by exploring and tracking the relative importance of convolutional\nchannels. At each training step, we select only a subset of highly salient\nchannels to execute according to the combinatorial upper confidence bound\nalgorithm, and run a forward and backward pass only on these activated\nchannels, hence learning their parameters. Consequently, we enable the\nefficient discovery of compact models. We validate our approach empirically on\nstate-of-the-art CNNs - VGGNet, ResNet and DenseNet, and on several image\nclassification datasets. Results demonstrate our framework for dynamic channel\nexecution reduces computational cost up to 4x and parameter count up to 9x,\nthus reducing the memory and computational demands for discovering and training\ncompact neural network models.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 21:10:28 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Spasov", "Simeon E.", ""], ["Lio", "Pietro", ""]]}, {"id": "1905.06452", "submitter": "Andrew Stanton", "authors": "Andrew Stanton, Akhila Ananthram, Congzhe Su, Liangjie Hong", "title": "Revenue, Relevance, Arbitrage and More: Joint Optimization Framework for\n  Search Experiences in Two-Sided Marketplaces", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two-sided marketplaces such as eBay, Etsy and Taobao have two distinct groups\nof customers: buyers who use the platform to seek the most relevant and\ninteresting item to purchase and sellers who view the same platform as a tool\nto reach out to their audience and grow their business. Additionally, platforms\nhave their own objectives ranging from growing both buyer and seller user bases\nto revenue maximization. It is not difficult to see that it would be\nchallenging to obtain a globally favorable outcome for all parties. Taking the\nsearch experience as an example, any interventions are likely to impact either\nbuyers or sellers unfairly to course correct for a greater perceived need. In\nthis paper, we address how a company-aligned search experience can be provided\nwith competing business metrics that E-commerce companies typically tackle. As\nfar as we know, this is a pioneering work to consider multiple different\naspects of business indicators in two-sided marketplaces to optimize a search\nexperience. We demonstrate that many problems are difficult or impossible to\ndecompose down to credit assigned scores on individual documents, rendering\ntraditional methods inadequate. Instead, we express market-level metrics as\nconstraints and discuss to what degree multiple potentially conflicting metrics\ncan be tuned to business needs. We further explore the use of policy learners\nin the form of Evolutionary Strategies to jointly optimize both group-level and\nmarket-level metrics simultaneously, side-stepping traditional cascading\nmethods and manual interventions. We empirically evaluate the effectiveness of\nthe proposed method on Etsy data and demonstrate its potential with insights.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 22:02:44 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Stanton", "Andrew", ""], ["Ananthram", "Akhila", ""], ["Su", "Congzhe", ""], ["Hong", "Liangjie", ""]]}, {"id": "1905.06455", "submitter": "Bai Li", "authors": "Bai Li, Changyou Chen, Wenlin Wang, Lawrence Carin", "title": "On Norm-Agnostic Robustness of Adversarial Training", "comments": "4 pages, 2 figures, presented at the ICML 2019 Workshop on\n  Uncertainty and Robustness in Deep Learning. arXiv admin note: text overlap\n  with arXiv:1809.03113", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are carefully perturbed in-puts for fooling machine\nlearning models. A well-acknowledged defense method against such examples is\nadversarial training, where adversarial examples are injected into training\ndata to increase robustness. In this paper, we propose a new attack to unveil\nan undesired property of the state-of-the-art adversarial training, that is it\nfails to obtain robustness against perturbations in $\\ell_2$ and $\\ell_\\infty$\nnorms simultaneously. We discuss a possible solution to this issue and its\nlimitations as well.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 22:07:19 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Li", "Bai", ""], ["Chen", "Changyou", ""], ["Wang", "Wenlin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1905.06462", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Praneeth Vepakomma, Tristan Swedish, Aalekh Sharan", "title": "Data Markets to support AI for All: Pricing, Valuation and Governance", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a data market technique based on intrinsic (relevance and\nuniqueness) as well as extrinsic value (influenced by supply and demand) of\ndata. For intrinsic value, we explain how to perform valuation of data in\nabsolute terms (i.e just by itself), or relatively (i.e in comparison to\nmultiple datasets) or in conditional terms (i.e valuating new data given\ncurrently existing data).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:41:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Raskar", "Ramesh", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Sharan", "Aalekh", ""]]}, {"id": "1905.06464", "submitter": "Jasper Sebastiaan Wijnands", "authors": "Jasper S. Wijnands, Kerry A. Nice, Jason Thompson, Haifeng Zhao, Mark\n  Stevenson", "title": "Streetscape augmentation using generative adversarial networks: insights\n  related to health and wellbeing", "comments": "20 pages, 8 figures. Preprint accepted for publication in Sustainable\n  Cities and Society", "journal-ref": null, "doi": "10.1016/j.scs.2019.101602", "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning using neural networks has provided advances in image style\ntransfer, merging the content of one image (e.g., a photo) with the style of\nanother (e.g., a painting). Our research shows this concept can be extended to\nanalyse the design of streetscapes in relation to health and wellbeing\noutcomes. An Australian population health survey (n=34,000) was used to\nidentify the spatial distribution of health and wellbeing outcomes, including\ngeneral health and social capital. For each outcome, the most and least\ndesirable locations formed two domains. Streetscape design was sampled using\naround 80,000 Google Street View images per domain. Generative adversarial\nnetworks translated these images from one domain to the other, preserving the\nmain structure of the input image, but transforming the `style' from locations\nwhere self-reported health was bad to locations where it was good. These\ntranslations indicate that areas in Melbourne with good general health are\ncharacterised by sufficient green space and compactness of the urban\nenvironment, whilst streetscape imagery related to high social capital\ncontained more and wider footpaths, fewer fences and more grass. Beyond\nidentifying relationships, the method is a first step towards\ncomputer-generated design interventions that have the potential to improve\npopulation health and wellbeing.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:13:15 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Wijnands", "Jasper S.", ""], ["Nice", "Kerry A.", ""], ["Thompson", "Jason", ""], ["Zhao", "Haifeng", ""], ["Stevenson", "Mark", ""]]}, {"id": "1905.06465", "submitter": "Kira Kempinska", "authors": "Kira Kempinska and Roberto Murcio", "title": "Modelling urban networks using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing question for urban and regional planners pertains to the\nability to describe urban patterns quantitatively. Cities' transport\ninfrastructure, particularly street networks, provides an invaluable source of\ninformation about the urban patterns generated by peoples' movements and their\ninteractions. With the increasing availability of street network datasets and\nthe advancements in deep learning methods, we are presented with an\nunprecedented opportunity to push the frontiers of urban modelling towards more\ndata-driven and accurate models of urban forms. In this study, we present our\ninitial work on applying deep generative models to urban street network data to\ncreate spatially explicit urban models. We based our work on Variational\nAutoencoders (VAEs) which are deep generative models that have recently gained\ntheir popularity due to the ability to generate realistic images. Initial\nresults show that VAEs are capable of capturing key high-level urban network\nmetrics using low-dimensional vectors and generating new urban forms of\ncomplexity matching the cities captured in the street network data.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:36:40 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Kempinska", "Kira", ""], ["Murcio", "Roberto", ""]]}, {"id": "1905.06466", "submitter": "Wang Chi Cheung", "authors": "Wang Chi Cheung", "title": "Exploration-Exploitation Trade-off in Reinforcement Learning on Online\n  Markov Decision Processes with Global Concave Rewards", "comments": "54 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an agent who is involved in a Markov decision process and\nreceives a vector of outcomes every round. Her objective is to maximize a\nglobal concave reward function on the average vectorial outcome. The problem\nmodels applications such as multi-objective optimization, maximum entropy\nexploration, and constrained optimization in Markovian environments. In our\ngeneral setting where a stationary policy could have multiple recurrent\nclasses, the agent faces a subtle yet consequential trade-off in alternating\namong different actions for balancing the vectorial outcomes. In particular,\nstationary policies are in general sub-optimal. We propose a no-regret\nalgorithm based on online convex optimization (OCO) tools (Agrawal and Devanur\n2014) and UCRL2 (Jaksch et al. 2010). Importantly, we introduce a novel\ngradient threshold procedure, which carefully controls the switches among\nactions to handle the subtle trade-off. By delaying the gradient updates, our\nprocedure produces a non-stationary policy that diversifies the outcomes for\noptimizing the objective. The procedure is compatible with a variety of OCO\ntools.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 23:09:05 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Cheung", "Wang Chi", ""]]}, {"id": "1905.06471", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Nils Jansen, Mohammed Alsiekh, and Ufuk Topcu", "title": "Synthesis of Provably Correct Autonomy Protocols for Shared Control", "comments": "Submitted to IEEE Transactions of Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We synthesize shared control protocols subject to probabilistic temporal\nlogic specifications. More specifically, we develop a framework in which a\nhuman and an autonomy protocol can issue commands to carry out a certain task.\nWe blend these commands into a joint input to a robot. We model the interaction\nbetween the human and the robot as a Markov decision process (MDP) that\nrepresents the shared control scenario. Using inverse reinforcement learning,\nwe obtain an abstraction of the human's behavior and decisions. We use\nrandomized strategies to account for randomness in human's decisions, caused by\nfactors such as complexity of the task specifications or imperfect interfaces.\nWe design the autonomy protocol to ensure that the resulting robot behavior\nsatisfies given safety and performance specifications in probabilistic temporal\nlogic. Additionally, the resulting strategies generate behavior as similar to\nthe behavior induced by the human's commands as possible. We solve the\nunderlying problem efficiently using quasiconvex programming. Case studies\ninvolving autonomous wheelchair navigation and unmanned aerial vehicle mission\nplanning showcase the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 23:46:58 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Alsiekh", "Mohammed", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1905.06474", "submitter": "Anish Lahiri", "authors": "Anish Lahiri, Jeffrey A Fessler and Luis Hernandez-Garcia", "title": "Optimizing MRF-ASL Scan Design for Precise Quantification of Brain\n  Hemodynamics using Neural Network Regression", "comments": "Submitted to Magnetic Resonance in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Arterial Spin Labeling (ASL) is a quantitative, non-invasive\nalternative to perfusion imaging with contrast agents. Fixing values of certain\nmodel parameters in traditional ASL, which actually vary from region to region,\nmay introduce bias in perfusion estimates. Adopting Magnetic Resonance\nFingerprinting (MRF) for ASL is an alternative where these parameters are\nestimated alongside perfusion, but multiparametric estimation can degrade\nprecision. We aim to improve the sensitivity of ASL-MRF signals to underlying\nparameters to counter this problem, and provide precise estimates. We also\npropose a regression based estimation framework for MRF-ASL.\n  Methods: To improve the sensitivity of MRF-ASL signals to underlying\nparameters, we optimize ASL labeling durations using the Cramer-Rao Lower Bound\n(CRLB). This paper also proposes a neural network regression based estimation\nframework trained using noisy synthetic signals generated from our ASL signal\nmodel.\n  Results: We test our methods in silico and in vivo, and compare with multiple\npost labeling delay (multi-PLD) ASL and unoptimized MRF-ASL. We present\ncomparisons of estimated maps for six parameters accounted for in our signal\nmodel.\n  Conclusions: The scan design process facilitates precise estimates of\nmultiple hemodynamic parameters and tissue properties from a single scan, in\nregions of gray and white matter, as well as regions with anomalous perfusion\nactivity in the brain. The regression based estimation approach provides\nperfusion estimates rapidly, and bypasses problems with quantization error.\n  Keywords: Arterial Spin Labeling, Magnetic Resonance Fingerprinting,\nOptimization, Cramer-Rao Bound, Scan Design, Regression, Neural Networks, Deep\nLearning, Precision, Estimation, Brain Hemodynamics.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 23:54:13 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Lahiri", "Anish", ""], ["Fessler", "Jeffrey A", ""], ["Hernandez-Garcia", "Luis", ""]]}, {"id": "1905.06484", "submitter": "Wenyuan Li", "authors": "Wenyuan Li, Zichen Wang, Jiayun Li, Jennifer Polson, William Speier,\n  Corey Arnold", "title": "Semi-supervised learning based on generative adversarial network: a\n  comparison between good GAN and bad GAN approach", "comments": "This paper appears at CVPR 2019 Weakly Supervised Learning for\n  Real-World Computer Vision Applications (LID) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, semi-supervised learning methods based on generative adversarial\nnetworks (GANs) have received much attention. Among them, two distinct\napproaches have achieved competitive results on a variety of benchmark\ndatasets. Bad GAN learns a classifier with unrealistic samples distributed on\nthe complement of the support of the input data. Conversely, Triple GAN\nconsists of a three-player game that tries to leverage good generated samples\nto boost classification results. In this paper, we perform a comprehensive\ncomparison of these two approaches on different benchmark datasets. We\ndemonstrate their different properties on image generation, and sensitivity to\nthe amount of labeled data provided. By comprehensively comparing these two\nmethods, we hope to shed light on the future of GAN-based semi-supervised\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 00:43:47 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 01:53:45 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Li", "Wenyuan", ""], ["Wang", "Zichen", ""], ["Li", "Jiayun", ""], ["Polson", "Jennifer", ""], ["Speier", "William", ""], ["Arnold", "Corey", ""]]}, {"id": "1905.06494", "submitter": "Fang Liu", "authors": "Fang Liu and Ness Shroff", "title": "Data Poisoning Attacks on Stochastic Bandits", "comments": "Accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic multi-armed bandits form a class of online learning problems that\nhave important applications in online recommendation systems, adaptive medical\ntreatment, and many others. Even though potential attacks against these\nlearning algorithms may hijack their behavior, causing catastrophic loss in\nreal-world applications, little is known about adversarial attacks on bandit\nalgorithms. In this paper, we propose a framework of offline attacks on bandit\nalgorithms and study convex optimization based attacks on several popular\nbandit algorithms. We show that the attacker can force the bandit algorithm to\npull a target arm with high probability by a slight manipulation of the rewards\nin the data. Then we study a form of online attacks on bandit algorithms and\npropose an adaptive attack strategy against any bandit algorithm without the\nknowledge of the bandit algorithm. Our adaptive attack strategy can hijack the\nbehavior of the bandit algorithm to suffer a linear regret with only a\nlogarithmic cost to the attacker. Our results demonstrate a significant\nsecurity threat to stochastic bandits.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 01:54:31 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Liu", "Fang", ""], ["Shroff", "Ness", ""]]}, {"id": "1905.06501", "submitter": "Raj Agrawal", "authors": "Raj Agrawal, Jonathan H. Huggins, Brian Trippe, Tamara Broderick", "title": "The Kernel Interaction Trick: Fast Bayesian Discovery of Pairwise\n  Interactions in High Dimensions", "comments": "Accepted at ICML 2019. 20 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering interaction effects on a response of interest is a fundamental\nproblem faced in biology, medicine, economics, and many other scientific\ndisciplines. In theory, Bayesian methods for discovering pairwise interactions\nenjoy many benefits such as coherent uncertainty quantification, the ability to\nincorporate background knowledge, and desirable shrinkage properties. In\npractice, however, Bayesian methods are often computationally intractable for\neven moderate-dimensional problems. Our key insight is that many hierarchical\nmodels of practical interest admit a particular Gaussian process (GP)\nrepresentation; the GP allows us to capture the posterior with a vector of O(p)\nkernel hyper-parameters rather than O(p^2) interactions and main effects. With\nthe implicit representation, we can run Markov chain Monte Carlo (MCMC) over\nmodel hyper-parameters in time and memory linear in p per iteration. We focus\non sparsity-inducing models and show on datasets with a variety of covariate\nbehaviors that our method: (1) reduces runtime by orders of magnitude over\nnaive applications of MCMC, (2) provides lower Type I and Type II error\nrelative to state-of-the-art LASSO-based approaches, and (3) offers improved\ncomputational scaling in high dimensions relative to existing Bayesian and\nLASSO-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 02:19:10 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 03:46:06 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Agrawal", "Raj", ""], ["Huggins", "Jonathan H.", ""], ["Trippe", "Brian", ""], ["Broderick", "Tamara", ""]]}, {"id": "1905.06514", "submitter": "Ziqiang Zheng", "authors": "Ziqiang Zheng, Yang Wu, Zhibin Yu, Yang Yang, Haiyong Zheng, Takeo\n  Kanade", "title": "ReshapeGAN: Object Reshaping by Providing A Single Reference Image", "comments": "25 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is learning to reshape the object in an input image to\nan arbitrary new shape, by just simply providing a single reference image with\nan object instance in the desired shape. We propose a new Generative\nAdversarial Network (GAN) architecture for such an object reshaping problem,\nnamed ReshapeGAN. The network can be tailored for handling all kinds of problem\nsettings, including both within-domain (or single-dataset) reshaping and\ncross-domain (typically across mutiple datasets) reshaping, with paired or\nunpaired training data. The appearance of the input object is preserved in all\ncases, and thus it is still identifiable after reshaping, which has never been\nachieved as far as we are aware. We present the tailored models of the proposed\nReshapeGAN for all the problem settings, and have them tested on 8 kinds of\nreshaping tasks with 13 different datasets, demonstrating the ability of\nReshapeGAN on generating convincing and superior results for object reshaping.\nTo the best of our knowledge, we are the first to be able to make one GAN\nframework work on all such object reshaping tasks, especially the cross-domain\ntasks on handling multiple diverse datasets. We present here both ablation\nstudies on our proposed ReshapeGAN models and comparisons with the\nstate-of-the-art models when they are made comparable, using all kinds of\napplicable metrics that we are aware of.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 03:54:12 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zheng", "Ziqiang", ""], ["Wu", "Yang", ""], ["Yu", "Zhibin", ""], ["Yang", "Yang", ""], ["Zheng", "Haiyong", ""], ["Kanade", "Takeo", ""]]}, {"id": "1905.06515", "submitter": "Emanuele Rossi", "authors": "Emanuele Rossi and Federico Monti and Michael Bronstein and Pietro\n  Li\\`o", "title": "ncRNA Classification with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-coding RNA (ncRNA) are RNA sequences which don't code for a gene but\ninstead carry important biological functions. The task of ncRNA classification\nconsists in classifying a given ncRNA sequence into its family. While it has\nbeen shown that the graph structure of an ncRNA sequence folding is of great\nimportance for the prediction of its family, current methods make use of\nmachine learning classifiers on hand-crafted graph features. We improve on the\nstate-of-the-art for this task with a graph convolutional network model which\nachieves an accuracy of 85.73% and an F1-score of 85.61% over 13 classes.\nMoreover, our model learns in an end-to-end fashion from the raw RNA graphs and\nremoves the need for expensive feature extraction. To the best of our\nknowledge, this also represents the first successful application of graph\nconvolutional networks to RNA folding data.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 03:54:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Rossi", "Emanuele", ""], ["Monti", "Federico", ""], ["Bronstein", "Michael", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1905.06517", "submitter": "Jian Liang", "authors": "Jian Liang, Yuren Cao, Chenbin Zhang, Shiyu Chang, Kun Bai, Zenglin Xu", "title": "Additive Adversarial Learning for Unbiased Authentication", "comments": "IEEE Computer Society Conference on Computer Vision and Pattern\n  Recognition (CVPR'2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication is a task aiming to confirm the truth between data instances\nand personal identities. Typical authentication applications include face\nrecognition, person re-identification, authentication based on mobile devices\nand so on. The recently-emerging data-driven authentication process may\nencounter undesired biases, i.e., the models are often trained in one domain\n(e.g., for people wearing spring outfits) while required to apply in other\ndomains (e.g., they change the clothes to summer outfits). To address this\nissue, we propose a novel two-stage method that disentangles the class/identity\nfrom domain-differences, and we consider multiple types of domain-difference.\nIn the first stage, we learn disentangled representations by a one-versus-rest\ndisentangle learning (OVRDL) mechanism. In the second stage, we improve the\ndisentanglement by an additive adversarial learning (AAL) mechanism. Moreover,\nwe discuss the necessity to avoid a learning dilemma due to disentangling\ncausally related types of domain-difference. Comprehensive evaluation results\ndemonstrate the effectiveness and superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 03:58:07 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 09:17:46 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 02:17:45 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Liang", "Jian", ""], ["Cao", "Yuren", ""], ["Zhang", "Chenbin", ""], ["Chang", "Shiyu", ""], ["Bai", "Kun", ""], ["Xu", "Zenglin", ""]]}, {"id": "1905.06518", "submitter": "Jun Xu", "authors": "Jun Xu, Qinghua Tao, Zhen Li, Xiangming Xi, Johan A. K. Suykens,\n  Shuning Wang", "title": "Efficient hinging hyperplanes neural network and its application in\n  nonlinear system identification", "comments": "submitted to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the efficient hinging hyperplanes (EHH) neural network is\nproposed based on the model of hinging hyperplanes (HH). The EHH neural network\nis a distributed representation, the training of which involves solving several\nconvex optimization problems and is fast. It is proved that for every EHH\nneural network, there is an equivalent adaptive hinging hyperplanes (AHH) tree,\nwhich was also proposed based on the model of HH and find good applications in\nsystem identification. The construction of the EHH neural network includes 2\nstages. First the initial structure of the EHH neural network is randomly\ndetermined and the Lasso regression is used to choose the appropriate network.\nTo alleviate the impact of randomness, secondly, the stacking strategy is\nemployed to formulate a more general network structure. Different from other\nneural networks, the EHH neural network has interpretability ability, which can\nbe easily obtained through its ANOVA decomposition (or interaction matrix). The\ninterpretability can then be used as a suggestion for input variable selection.\nThe EHH neural network is applied in nonlinear system identification, the\nsimulation results show that the regression vector selected is reasonable and\nthe identification speed is fast, while at the same time, the simulation\naccuracy is satisfactory.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 01:17:50 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:45:59 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Xu", "Jun", ""], ["Tao", "Qinghua", ""], ["Li", "Zhen", ""], ["Xi", "Xiangming", ""], ["Suykens", "Johan A. K.", ""], ["Wang", "Shuning", ""]]}, {"id": "1905.06526", "submitter": "Zaiwei Zhang", "authors": "Zaiwei Zhang, Xiangru Huang, Qixing Huang, Xiao Zhang, Yuan Li", "title": "Joint Learning of Neural Networks via Iterative Reweighted Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the problem of jointly learning feed-forward\nneural networks across a set of relevant but diverse datasets. Compared to\nlearning a separate network from each dataset in isolation, joint learning\nenables us to extract correlated information across multiple datasets to\nsignificantly improve the quality of learned networks. We formulate this\nproblem as joint learning of multiple copies of the same network architecture\nand enforce the network weights to be shared across these networks. Instead of\nhand-encoding the shared network layers, we solve an optimization problem to\nautomatically determine how layers should be shared between each pair of\ndatasets. Experimental results show that our approach outperforms baselines\nwithout joint learning and those using pretraining-and-fine-tuning. We show the\neffectiveness of our approach on three tasks: image classification, learning\nauto-encoders, and image generation.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 04:38:55 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 04:41:46 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Zhang", "Zaiwei", ""], ["Huang", "Xiangru", ""], ["Huang", "Qixing", ""], ["Zhang", "Xiao", ""], ["Li", "Yuan", ""]]}, {"id": "1905.06527", "submitter": "Lin Lan", "authors": "Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang", "title": "Meta Reinforcement Learning with Task Embedding and Shared Policy", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress, deep reinforcement learning (RL) suffers from\ndata-inefficiency and limited generalization. Recent efforts apply\nmeta-learning to learn a meta-learner from a set of RL tasks such that a novel\nbut related task could be solved quickly. Though specific in some ways,\ndifferent tasks in meta-RL are generally similar at a high level. However, most\nmeta-RL methods do not explicitly and adequately model the specific and shared\ninformation among different tasks, which limits their ability to learn training\ntasks and to generalize to novel tasks. In this paper, we propose to capture\nthe shared information on the one hand and meta-learn how to quickly abstract\nthe specific information about a task on the other hand. Methodologically, we\ntrain an SGD meta-learner to quickly optimize a task encoder for each task,\nwhich generates a task embedding based on past experience. Meanwhile, we learn\na policy which is shared across all tasks and conditioned on task embeddings.\nEmpirical results on four simulated tasks demonstrate that our method has\nbetter learning capacity on both training and novel tasks and attains up to 3\nto 4 times higher returns compared to baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 04:42:25 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 10:31:20 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 02:46:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lan", "Lin", ""], ["Li", "Zhenguo", ""], ["Guan", "Xiaohong", ""], ["Wang", "Pinghui", ""]]}, {"id": "1905.06549", "submitter": "Sung Whan Yoon", "authors": "Sung Whan Yoon, Jun Seo and Jaekyun Moon", "title": "TapNet: Neural Network Augmented with Task-Adaptive Projection for\n  Few-Shot Learning", "comments": "in proceedings of the 36th International Conference on Machine\n  Learning (ICML), Long Beach, PMLR 97:7115-7123, 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:7115-7123, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling previously unseen tasks after given only a few training examples\ncontinues to be a tough challenge in machine learning. We propose TapNets,\nneural networks augmented with task-adaptive projection for improved few-shot\nlearning. Here, employing a meta-learning strategy with episode-based training,\na network and a set of per-class reference vectors are learned across widely\nvarying tasks. At the same time, for every episode, features in the embedding\nspace are linearly projected into a new space as a form of quick task-specific\nconditioning. The training loss is obtained based on a distance metric between\nthe query and the reference vectors in the projection space. Excellent\ngeneralization results in this way. When tested on the Omniglot, miniImageNet\nand tieredImageNet datasets, we obtain state of the art classification\naccuracies under various few-shot scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 06:21:28 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 04:04:58 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Yoon", "Sung Whan", ""], ["Seo", "Jun", ""], ["Moon", "Jaekyun", ""]]}, {"id": "1905.06566", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Furu Wei, Ming Zhou", "title": "HIBERT: Document Level Pre-training of Hierarchical Bidirectional\n  Transformers for Document Summarization", "comments": "to appear in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural extractive summarization models usually employ a hierarchical encoder\nfor document encoding and they are trained using sentence-level labels, which\nare created heuristically using rule-based methods. Training the hierarchical\nencoder with these \\emph{inaccurate} labels is challenging. Inspired by the\nrecent work on pre-training transformer sentence encoders\n\\cite{devlin:2018:arxiv}, we propose {\\sc Hibert} (as shorthand for {\\bf\nHI}erachical {\\bf B}idirectional {\\bf E}ncoder {\\bf R}epresentations from {\\bf\nT}ransformers) for document encoding and a method to pre-train it using\nunlabeled data. We apply the pre-trained {\\sc Hibert} to our summarization\nmodel and it outperforms its randomly initialized counterpart by 1.25 ROUGE on\nthe CNN/Dailymail dataset and by 2.0 ROUGE on a version of New York Times\ndataset. We also achieve the state-of-the-art performance on these two\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:20:21 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhang", "Xingxing", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1905.06576", "submitter": "Hongnian Wang", "authors": "Hongnian Wang and Han Su", "title": "STAR: A Concise Deep Learning Framework for Citywide Human Mobility\n  Prediction", "comments": "Accepted by MDM 2019", "journal-ref": "2019 20th IEEE International Conference on Mobile Data Management\n  (MDM), Hong Kong, 2019, pp. 304-309", "doi": "10.1109/MDM.2019.00-44", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human mobility forecasting in a city is of utmost importance to\ntransportation and public safety, but with the process of urbanization and the\ngeneration of big data, intensive computing and determination of mobility\npattern have become challenging. This study focuses on how to improve the\naccuracy and efficiency of predicting citywide human mobility via a simpler\nsolution. A spatio-temporal mobility event prediction framework based on a\nsingle fully-convolutional residual network (STAR) is proposed. STAR is a\nhighly simple, general and effective method for learning a single tensor\nrepresenting the mobility event. Residual learning is utilized for training the\ndeep network to derive the detailed result for scenarios of citywide\nprediction. Extensive benchmark evaluation results on real-world data\ndemonstrate that STAR outperforms state-of-the-art approaches in single- and\nmulti-step prediction while utilizing fewer parameters and achieving higher\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:42:17 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wang", "Hongnian", ""], ["Su", "Han", ""]]}, {"id": "1905.06586", "submitter": "Hamid Eghbal-zadeh", "authors": "Hamid Eghbal-zadeh, Lukas Fischer, Thomas Hoch", "title": "On Conditioning GANs to Hierarchical Ontologies", "comments": "Under review at MLKgraphs2019: http://www.dexa.org/mlkgraphs2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of Generative Adversarial Networks (GAN) is a result of\ntheir ability to generate high quality images from a latent vector space. An\nimportant application is the generation of images from a text description,\nwhere the text description is encoded and further used in the conditioning of\nthe generated image. Thus the generative network has to additionally learn a\nmapping from the text latent vector space to a highly complex and multi-modal\nimage data distribution, which makes the training of such models challenging.\nTo handle the complexities of fashion image and meta data, we propose Ontology\nGenerative Adversarial Networks (O-GANs) for fashion image synthesis that is\nconditioned on an hierarchical fashion ontology in order to improve the image\ngeneration fidelity. We show that the incorporation of the ontology leads to\nbetter image quality as measured by Fr\\'{e}chet Inception Distance and\nInception Score. Additionally, we show that the O-GAN achieves better\nconditioning results evaluated by implicit similarity between the text and the\ngenerated image.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:07:13 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Eghbal-zadeh", "Hamid", ""], ["Fischer", "Lukas", ""], ["Hoch", "Thomas", ""]]}, {"id": "1905.06596", "submitter": "Jos\\'e A. R. Fonollosa", "authors": "Jos\\'e A. R. Fonollosa, Noe Casas, Marta R. Costa-juss\\`a", "title": "Joint Source-Target Self Attention with Locality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant neural machine translation models are based on the\nencoder-decoder structure, and many of them rely on an unconstrained receptive\nfield over source and target sequences. In this paper we study a new\narchitecture that breaks with both conventions. Our simplified architecture\nconsists in the decoder part of a transformer model, based on self-attention,\nbut with locality constraints applied on the attention receptive field. As\ninput for training, both source and target sentences are fed to the network,\nwhich is trained as a language model. At inference time, the target tokens are\npredicted autoregressively starting with the source sequence as previous\ntokens. The proposed model achieves a new state of the art of 35.7 BLEU on\nIWSLT'14 German-English and matches the best reported results in the literature\non the WMT'14 English-German and WMT'14 English-French translation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:35:12 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Fonollosa", "Jos\u00e9 A. R.", ""], ["Casas", "Noe", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "1905.06597", "submitter": "Xiuyu Wu", "authors": "Xiuyu Wu and Yunfang Wu", "title": "A Simple Dual-decoder Model for Generating Response with Sentiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to generate human like response is one of the most challenging tasks for\nartificial intelligence. In a real application, after reading the same post\ndifferent people might write responses with positive or negative sentiment\naccording to their own experiences and attitudes. To simulate this procedure,\nwe propose a simple but effective dual-decoder model to generate response with\na particular sentiment, by connecting two sentiment decoders to one encoder. To\nsupport this model training, we construct a new conversation dataset with the\nform of (post, resp1, resp2) where two responses contain opposite sentiment.\nExperiment results show that our dual-decoder model can generate diverse\nresponses with target sentiment, which obtains significant performance gain in\nsentiment accuracy and word diversity over the traditional single-decoder\nmodel. We will make our data and code publicly available for further study.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:40:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Wu", "Xiuyu", ""], ["Wu", "Yunfang", ""]]}, {"id": "1905.06598", "submitter": "Gustav Eje Henter", "authors": "Gustav Eje Henter, Simon Alexanderson, Jonas Beskow", "title": "MoGlow: Probabilistic and controllable motion synthesis using\n  normalising flows", "comments": "14 pages, 5 figures, published in ACM Transactions on Graphics and\n  presented at SIGGRAPH Asia 2020", "journal-ref": "ACM Trans. Graph. 39, 4, Article 236 (November 2020), 14 pages", "doi": "10.1145/3414685.3417836", "report-no": null, "categories": "cs.LG cs.GR eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven modelling and synthesis of motion is an active research area with\napplications that include animation, games, and social robotics. This paper\nintroduces a new class of probabilistic, generative, and controllable\nmotion-data models based on normalising flows. Models of this kind can describe\nhighly complex distributions, yet can be trained efficiently using exact\nmaximum likelihood, unlike GANs or VAEs. Our proposed model is autoregressive\nand uses LSTMs to enable arbitrarily long time-dependencies. Importantly, is is\nalso causal, meaning that each pose in the output sequence is generated without\naccess to poses or control inputs from future time steps; this absence of\nalgorithmic latency is important for interactive applications with real-time\nmotion control. The approach can in principle be applied to any type of motion\nsince it does not make restrictive, task-specific assumptions regarding the\nmotion or the character morphology. We evaluate the models on motion-capture\ndatasets of human and quadruped locomotion. Objective and subjective results\nshow that randomly-sampled motion from the proposed method outperforms\ntask-agnostic baselines and attains a motion quality close to recorded motion\ncapture.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:41:12 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 16:19:40 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 16:25:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Henter", "Gustav Eje", ""], ["Alexanderson", "Simon", ""], ["Beskow", "Jonas", ""]]}, {"id": "1905.06600", "submitter": "Xiangxiang Xu", "authors": "Shao-Lun Huang, Xiangxiang Xu, Lizhong Zheng, Gregory W. Wornell", "title": "An Information Theoretic Interpretation to Deep Neural Networks", "comments": "Accepted to ISIT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly believed that the hidden layers of deep neural networks (DNNs)\nattempt to extract informative features for learning tasks. In this paper, we\nformalize this intuition by showing that the features extracted by DNN coincide\nwith the result of an optimization problem, which we call the `universal\nfeature selection' problem, in a local analysis regime. We interpret the\nweights training in DNN as the projection of feature functions between feature\nspaces, specified by the network structure. Our formulation has direct\noperational meaning in terms of the performance for inference tasks, and gives\ninterpretations to the internal computation results of DNNs. Results of\nnumerical experiments are provided to support the analysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:43:39 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Huang", "Shao-Lun", ""], ["Xu", "Xiangxiang", ""], ["Zheng", "Lizhong", ""], ["Wornell", "Gregory W.", ""]]}, {"id": "1905.06635", "submitter": "Seungyong Moon", "authors": "Seungyong Moon, Gaon An, Hyun Oh Song", "title": "Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial\n  Optimization", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving for adversarial examples with projected gradient descent has been\ndemonstrated to be highly effective in fooling the neural network based\nclassifiers. However, in the black-box setting, the attacker is limited only to\nthe query access to the network and solving for a successful adversarial\nexample becomes much more difficult. To this end, recent methods aim at\nestimating the true gradient signal based on the input queries but at the cost\nof excessive queries. We propose an efficient discrete surrogate to the\noptimization problem which does not require estimating the gradient and\nconsequently becomes free of the first order update hyperparameters to tune.\nOur experiments on Cifar-10 and ImageNet show the state of the art black-box\nattack performance with significant reduction in the required queries compared\nto a number of recently proposed methods. The source code is available at\nhttps://github.com/snu-mllab/parsimonious-blackbox-attack.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:14:20 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Moon", "Seungyong", ""], ["An", "Gaon", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1905.06638", "submitter": "Daniel Fleischer", "authors": "Alon Rozental, Zohar Kelrich, Daniel Fleischer", "title": "Latent Universal Task-Specific BERT", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a language representation model which combines the\nBidirectional Encoder Representations from Transformers (BERT) learning\nmechanism described in Devlin et al. (2018) with a generalization of the\nUniversal Transformer model described in Dehghani et al. (2018). We further\nimprove this model by adding a latent variable that represents the persona and\ntopics of interests of the writer for each training example. We also describe a\nsimple method to improve the usefulness of our language representation for\nsolving problems in a specific domain at the expense of its ability to\ngeneralize to other fields. Finally, we release a pre-trained language\nrepresentation model for social texts that was trained on 100 million tweets.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:21:51 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Rozental", "Alon", ""], ["Kelrich", "Zohar", ""], ["Fleischer", "Daniel", ""]]}, {"id": "1905.06641", "submitter": "Lumin Liu", "authors": "Lumin Liu, Jun Zhang, S. H. Song, Khaled B. Letaief", "title": "Client-Edge-Cloud Hierarchical Federated Learning", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a collaborative machine learning framework to train a\ndeep learning model without accessing clients' private data. Previous works\nassume one central parameter server either at the cloud or at the edge. The\ncloud server can access more data but with excessive communication overhead and\nlong latency, while the edge server enjoys more efficient communications with\nthe clients. To combine their advantages, we propose a client-edge-cloud\nhierarchical Federated Learning system, supported with a HierFAVG algorithm\nthat allows multiple edge servers to perform partial model aggregation. In this\nway, the model can be trained faster and better communication-computation\ntrade-offs can be achieved. Convergence analysis is provided for HierFAVG and\nthe effects of key parameters are also investigated, which lead to qualitative\ndesign guidelines. Empirical experiments verify the analysis and demonstrate\nthe benefits of this hierarchical architecture in different data distribution\nscenarios. Particularly, it is shown that by introducing the intermediate edge\nservers, the model training time and the energy consumption of the end devices\ncan be simultaneously reduced compared to cloud-based Federated Learning.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:23:36 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:45:01 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Liu", "Lumin", ""], ["Zhang", "Jun", ""], ["Song", "S. H.", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1905.06642", "submitter": "Luigi Gresele", "authors": "Luigi Gresele, Paul K. Rubenstein, Arash Mehrjou, Francesco Locatello\n  and Bernhard Sch\\\"olkopf", "title": "The Incomplete Rosetta Stone Problem: Identifiability Results for\n  Multi-View Nonlinear ICA", "comments": null, "journal-ref": "Proceedings of the 35th Conference on Uncertainty in Artificial\n  Intelligence, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a common latent source with independent\ncomponents from multiple views. This applies to settings in which a variable is\nmeasured with multiple experimental modalities, and where the goal is to\nsynthesize the disparate measurements into a single unified representation. We\nconsider the case that the observed views are a nonlinear mixing of\ncomponent-wise corruptions of the sources. When the views are considered\nseparately, this reduces to nonlinear Independent Component Analysis (ICA) for\nwhich it is provably impossible to undo the mixing. We present novel\nidentifiability proofs that this is possible when the multiple views are\nconsidered jointly, showing that the mixing can theoretically be undone using\nfunction approximators such as deep neural networks. In contrast to known\nidentifiability results for nonlinear ICA, we prove that independent latent\nsources with arbitrary mixing can be recovered as long as multiple,\nsufficiently different noisy views are available.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:27:04 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 09:57:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Gresele", "Luigi", ""], ["Rubenstein", "Paul K.", ""], ["Mehrjou", "Arash", ""], ["Locatello", "Francesco", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1905.06684", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Formal derivation of Mesh Neural Networks with their Forward-Only\n  gradient Propagation", "comments": null, "journal-ref": null, "doi": "10.1007/s11063-021-10490-1", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Mesh Neural Network (MNN), a novel architecture which\nallows neurons to be connected in any topology, to efficiently route\ninformation. In MNNs, information is propagated between neurons throughout a\nstate transition function. State and error gradients are then directly computed\nfrom state updates without backward computation. The MNN architecture and the\nerror propagation schema is formalized and derived in tensor algebra. The\nproposed computational model can fully supply a gradient descent process, and\nis potentially suitable for very large scale sparse NNs, due to its\nexpressivity and training efficiency, with respect to NNs based on\nback-propagation and computational graphs.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:22:26 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:22:36 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 12:14:11 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 20:06:51 GMT"}, {"version": "v5", "created": "Wed, 7 Jul 2021 14:37:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1905.06707", "submitter": "Jessica Schrouff", "authors": "Jessica Schrouff, Kai Wohlfahrt, Bruno Marnette, Liam Atkinson", "title": "Inferring Javascript types using Graph Neural Networks", "comments": "Published at the Representation Learning on Graphs and Manifolds ICLR\n  2019 workshop (https://rlgm.github.io/papers/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent use of `Big Code' with state-of-the-art deep learning methods\noffers promising avenues to ease program source code writing and correction. As\na first step towards automatic code repair, we implemented a graph neural\nnetwork model that predicts token types for Javascript programs. The\npredictions achieve an accuracy above $90\\%$, which improves on previous\nsimilar work.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:58:50 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Schrouff", "Jessica", ""], ["Wohlfahrt", "Kai", ""], ["Marnette", "Bruno", ""], ["Atkinson", "Liam", ""]]}, {"id": "1905.06723", "submitter": "Yan Wu", "authors": "Yan Wu, Mihaela Rosca, Timothy Lillicrap", "title": "Deep Compressed Sensing", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) provides an elegant framework for recovering sparse\nsignals from compressed measurements. For example, CS can exploit the structure\nof natural images and recover an image from only a few random measurements. CS\nis flexible and data efficient, but its application has been restricted by the\nstrong assumption of sparsity and costly reconstruction process. A recent\napproach that combines CS with neural network generators has removed the\nconstraint of sparsity, but reconstruction remains slow. Here we propose a\nnovel framework that significantly improves both the performance and speed of\nsignal recovery by jointly training a generator and the optimisation process\nfor reconstruction via meta-learning. We explore training the measurements with\ndifferent objectives, and derive a family of models based on minimising\nmeasurement errors. We show that Generative Adversarial Nets (GANs) can be\nviewed as a special case in this family of models. Borrowing insights from the\nCS perspective, we develop a novel way of improving GANs using gradient\ninformation from the discriminator.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 13:15:52 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 12:18:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wu", "Yan", ""], ["Rosca", "Mihaela", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1905.06731", "submitter": "Abhijit Guha Roy", "authors": "Abhijit Guha Roy, Shayan Siddiqui, Sebastian P\\\"olsterl, Nassir Navab,\n  Christian Wachinger", "title": "BrainTorrent: A Peer-to-Peer Environment for Decentralized Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to sufficient annotated data is a common challenge in training deep\nneural networks on medical images. As annotating data is expensive and\ntime-consuming, it is difficult for an individual medical center to reach large\nenough sample sizes to build their own, personalized models. As an alternative,\ndata from all centers could be pooled to train a centralized model that\neveryone can use. However, such a strategy is often infeasible due to the\nprivacy-sensitive nature of medical data. Recently, federated learning (FL) has\nbeen introduced to collaboratively learn a shared prediction model across\ncenters without the need for sharing data. In FL, clients are locally training\nmodels on site-specific datasets for a few epochs and then sharing their model\nweights with a central server, which orchestrates the overall training process.\nImportantly, the sharing of models does not compromise patient privacy. A\ndisadvantage of FL is the dependence on a central server, which requires all\nclients to agree on one trusted central body, and whose failure would disrupt\nthe training process of all clients. In this paper, we introduce BrainTorrent,\na new FL framework without a central server, particularly targeted towards\nmedical applications. BrainTorrent presents a highly dynamic peer-to-peer\nenvironment, where all centers directly interact with each other without\ndepending on a central body. We demonstrate the overall effectiveness of FL for\nthe challenging task of whole brain segmentation and observe that the proposed\nserver-less BrainTorrent approach does not only outperform the traditional\nserver-based one but reaches a similar performance to a model trained on pooled\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 13:23:49 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Roy", "Abhijit Guha", ""], ["Siddiqui", "Shayan", ""], ["P\u00f6lsterl", "Sebastian", ""], ["Navab", "Nassir", ""], ["Wachinger", "Christian", ""]]}, {"id": "1905.06744", "submitter": "Weisi Guo", "authors": "Chengyao Sun and Weisi Guo", "title": "Forecasting Wireless Demand with Extreme Values using Feature Embedding\n  in Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless traffic prediction is a fundamental enabler to proactive network\noptimisation in beyond 5G. Forecasting extreme demand spikes and troughs due to\ntraffic mobility is essential to avoiding outages and improving energy\nefficiency. Current state-of-the-art deep learning forecasting methods\npredominantly focus on overall forecast performance and do not offer\nprobabilistic uncertainty quantification (UQ). Whilst Gaussian Process (GP)\nmodels have UQ capability, it is not able to predict extreme values very well.\nHere, we design a feature embedding (FE) kernel for a GP model to forecast\ntraffic demand with extreme values. Using real 4G base station data, we compare\nour FE-GP performance against both conventional naive GPs, ARIMA models, as\nwell as demonstrate the UQ output. For short-term extreme value prediction, we\ndemonstrated a 32\\% reduction vs. S-ARIMA and 17\\% reduction vs. Naive-GP. For\nlong-term average value prediction, we demonstrated a 21\\% reduction vs.\nS-ARIMA and 12\\% reduction vs. Naive-GP. The FE kernel also enabled us to\ncreate a flexible trade-off between overall forecast accuracy against\npeak-trough accuracy. The advantage over neural network (e.g. CNN, LSTM) is\nthat the probabilistic forecast uncertainty can inform us of the risk of\npredictions, as well as the full posterior distribution of the forecast.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:16:59 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 09:25:16 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sun", "Chengyao", ""], ["Guo", "Weisi", ""]]}, {"id": "1905.06750", "submitter": "Ruohan Wang", "authors": "Ruohan Wang, Carlo Ciliberto, Pierluigi Amadori, Yiannis Demiris", "title": "Random Expert Distillation: Imitation Learning via Expert Policy Support\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of imitation learning from a finite set of expert\ntrajectories, without access to reinforcement signals. The classical approach\nof extracting the expert's reward function via inverse reinforcement learning,\nfollowed by reinforcement learning is indirect and may be computationally\nexpensive. Recent generative adversarial methods based on matching the policy\ndistribution between the expert and the agent could be unstable during\ntraining. We propose a new framework for imitation learning by estimating the\nsupport of the expert policy to compute a fixed reward function, which allows\nus to re-frame imitation learning within the standard reinforcement learning\nsetting. We demonstrate the efficacy of our reward function on both discrete\nand continuous domains, achieving comparable or better performance than the\nstate of the art under different reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 13:43:38 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 16:16:41 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Wang", "Ruohan", ""], ["Ciliberto", "Carlo", ""], ["Amadori", "Pierluigi", ""], ["Demiris", "Yiannis", ""]]}, {"id": "1905.06782", "submitter": "Waren Long", "authors": "Waren Long, Vadim Markovtsev, Hugo Mougard, Egor Bulychev, Jan Hula", "title": "Identifying collaborators in large codebases", "comments": "4 pages; Workshop on Machine Learning for Software Engineering 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The way developers collaborate inside and particularly across teams often\nescapes management's attention, despite a formal organization with designated\nteams being defined. Observability of the actual, organically formed\nengineering structure provides decision makers invaluable additional tools to\nmanage their talent pool. To identify existing inter and intra-team\ninteractions - and suggest relevant opportunities for suitable collaborations -\nthis paper studies contributors' commit activity, usage of programming\nlanguages, and code identifier topics by embedding and clustering them. We\nevaluate our findings collaborating with the GitLab organization, analyzing 117\nof their open source projects. We show that we are able to restore their\nengineering organization in broad strokes, and also reveal hidden coding\ncollaborations as well as justify in-house technical decisions.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:38:58 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Long", "Waren", ""], ["Markovtsev", "Vadim", ""], ["Mougard", "Hugo", ""], ["Bulychev", "Egor", ""], ["Hula", "Jan", ""]]}, {"id": "1905.06821", "submitter": "James Grant", "authors": "James A Grant, Alexis Boukouvalas, Ryan-Rhys Griffiths, David S\n  Leslie, Sattar Vakili, Enrique Munoz de Cote", "title": "Adaptive Sensor Placement for Continuous Spaces", "comments": "13 pages, accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adaptively placing sensors along an interval to\ndetect stochastically-generated events. We present a new formulation of the\nproblem as a continuum-armed bandit problem with feedback in the form of\npartial observations of realisations of an inhomogeneous Poisson process. We\ndesign a solution method by combining Thompson sampling with nonparametric\ninference via increasingly granular Bayesian histograms and derive an\n$\\tilde{O}(T^{2/3})$ bound on the Bayesian regret in $T$ rounds. This is\ncoupled with the design of an efficent optimisation approach to select actions\nin polynomial time. In simulations we demonstrate our approach to have\nsubstantially lower and less variable regret than competitor algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 15:01:53 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Grant", "James A", ""], ["Boukouvalas", "Alexis", ""], ["Griffiths", "Ryan-Rhys", ""], ["Leslie", "David S", ""], ["Vakili", "Sattar", ""], ["de Cote", "Enrique Munoz", ""]]}, {"id": "1905.06836", "submitter": "Karthik Abinav Sankararaman", "authors": "Karthik Abinav Sankararaman and Anand Louis and Navin Goyal", "title": "Stability of Linear Structural Equation Models of Causal Inference", "comments": "To appear in UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the numerical stability of the parameter recovery problem in\nLinear Structural Equation Model ($\\LSEM$) of causal inference. A long line of\nwork starting from Wright (1920) has focused on understanding which sub-classes\nof $\\LSEM$ allow for efficient parameter recovery. Despite decades of study,\nthis question is not yet fully resolved. The goal of this paper is\ncomplementary to this line of work; we want to understand the stability of the\nrecovery problem in the cases when efficient recovery is possible. Numerical\nstability of Pearl's notion of causality was first studied in Schulman and\nSrivastava (2016) using the concept of condition number where they provide\nill-conditioned examples. In this work, we provide a condition number analysis\nfor the $\\LSEM$. First we prove that under a sufficient condition, for a\ncertain sub-class of $\\LSEM$ that are \\emph{bow-free} (Brito and Pearl (2002)),\nthe parameter recovery is stable. We further prove that \\emph{randomly} chosen\ninput parameters for this family satisfy the condition with a substantial\nprobability. Hence for this family, on a large subset of parameter space,\nrecovery is numerically stable. Next we construct an example of $\\LSEM$ on four\nvertices with \\emph{unbounded} condition number. We then corroborate our\ntheoretical findings via simulations as well as real-world experiments for a\nsociology application. Finally, we provide a general heuristic for estimating\nthe condition number of any $\\LSEM$ instance.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 15:26:03 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 02:52:32 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 05:38:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sankararaman", "Karthik Abinav", ""], ["Louis", "Anand", ""], ["Goyal", "Navin", ""]]}, {"id": "1905.06845", "submitter": "Friso H. Kingma", "authors": "Friso H. Kingma, Pieter Abbeel, Jonathan Ho", "title": "Bit-Swap: Recursive Bits-Back Coding for Lossless Compression with\n  Hierarchical Latent Variables", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bits-back argument suggests that latent variable models can be turned\ninto lossless compression schemes. Translating the bits-back argument into\nefficient and practical lossless compression schemes for general latent\nvariable models, however, is still an open problem. Bits-Back with Asymmetric\nNumeral Systems (BB-ANS), recently proposed by Townsend et al. (2019), makes\nbits-back coding practically feasible for latent variable models with one\nlatent layer, but it is inefficient for hierarchical latent variable models. In\nthis paper we propose Bit-Swap, a new compression scheme that generalizes\nBB-ANS and achieves strictly better compression rates for hierarchical latent\nvariable models with Markov chain structure. Through experiments we verify that\nBit-Swap results in lossless compression rates that are empirically superior to\nexisting techniques. Our implementation is available at\nhttps://github.com/fhkingma/bitswap.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 15:32:35 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 17:10:45 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 05:51:17 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 09:57:24 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Kingma", "Friso H.", ""], ["Abbeel", "Pieter", ""], ["Ho", "Jonathan", ""]]}, {"id": "1905.06860", "submitter": "Barry-John Theobald", "authors": "Ahmed Hussen Abdelaziz, Barry-John Theobald, Justin Binder, Gabriele\n  Fanelli, Paul Dixon, Nicholas Apostoloff, Thibaut Weise, Sachin Kajareker", "title": "Speaker-Independent Speech-Driven Visual Speech Synthesis using\n  Domain-Adapted Acoustic Models", "comments": "9 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-driven visual speech synthesis involves mapping features extracted\nfrom acoustic speech to the corresponding lip animation controls for a face\nmodel. This mapping can take many forms, but a powerful approach is to use deep\nneural networks (DNNs). However, a limitation is the lack of synchronized\naudio, video, and depth data required to reliably train the DNNs, especially\nfor speaker-independent models. In this paper, we investigate adapting an\nautomatic speech recognition (ASR) acoustic model (AM) for the visual speech\nsynthesis problem. We train the AM on ten thousand hours of audio-only data.\nThe AM is then adapted to the visual speech synthesis domain using ninety hours\nof synchronized audio-visual speech. Using a subjective assessment test, we\ncompared the performance of the AM-initialized DNN to one with a random\ninitialization. The results show that viewers significantly prefer animations\ngenerated from the AM-initialized DNN than the ones generated using the\nrandomly initialized model. We conclude that visual speech synthesis can\nsignificantly benefit from the powerful representation of speech in the ASR\nacoustic models.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:23:58 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Abdelaziz", "Ahmed Hussen", ""], ["Theobald", "Barry-John", ""], ["Binder", "Justin", ""], ["Fanelli", "Gabriele", ""], ["Dixon", "Paul", ""], ["Apostoloff", "Nicholas", ""], ["Weise", "Thibaut", ""], ["Kajareker", "Sachin", ""]]}, {"id": "1905.06863", "submitter": "Farzad Eskandanian", "authors": "Farzad Eskandanian, Bamshad Mobasher", "title": "Modeling the Dynamics of User Preferences for Sequence-Aware\n  Recommendation Using Hidden Markov Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.00272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a variety of online settings involving interaction with end-users it is\ncritical for the systems to adapt to changes in user preferences. User\npreferences on items tend to change over time due to a variety of factors such\nas change in context, the task being performed, or other short-term or\nlong-term external factors. Recommender systems need to be able to capture\nthese dynamics in user preferences in order to remain tuned to the most current\ninterests of users. In this work we present a recommendation framework which\ntakes into account the dynamics of user preferences. We propose an approach\nbased on Hidden Markov Models (HMM) to identify change-points in the sequence\nof user interactions which reflect significant changes in preference according\nto the sequential behavior of all the users in the data. The proposed framework\nleverages the identified change points to generate recommendations using a\nsequence-aware non-negative matrix factorization model. We empirically\ndemonstrate the effectiveness of the HMM-based change detection method as\ncompared to standard baseline methods. Additionally, we evaluate the\nperformance of the proposed recommendation method and show that it compares\nfavorably to state-of-the-art sequence-aware recommendation models.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 19:56:57 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Eskandanian", "Farzad", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1905.06874", "submitter": "Qiwei Chen", "authors": "Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, Wenwu Ou", "title": "Behavior Sequence Transformer for E-commerce Recommendation in Alibaba", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based methods have been widely used in industrial\nrecommendation systems (RSs). Previous works adopt an Embedding&MLP paradigm:\nraw features are embedded into low-dimensional vectors, which are then fed on\nto MLP for final recommendations. However, most of these works just concatenate\ndifferent features, ignoring the sequential nature of users' behaviors. In this\npaper, we propose to use the powerful Transformer model to capture the\nsequential signals underlying users' behavior sequences for recommendation in\nAlibaba. Experimental results demonstrate the superiority of the proposed\nmodel, which is then deployed online at Taobao and obtain significant\nimprovements in online Click-Through-Rate (CTR) comparing to two baselines.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:51:59 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Chen", "Qiwei", ""], ["Zhao", "Huan", ""], ["Li", "Wei", ""], ["Huang", "Pipei", ""], ["Ou", "Wenwu", ""]]}, {"id": "1905.06876", "submitter": "Jessica Morley", "authors": "Jessica Morley, Luciano Floridi, Libby Kinsey and Anat Elhalal", "title": "From What to How: An Initial Review of Publicly Available AI Ethics\n  Tools, Methods and Research to Translate Principles into Practices", "comments": "15 pages, links to typology available on the web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate about the ethical implications of Artificial Intelligence dates\nfrom the 1960s. However, in recent years symbolic AI has been complemented and\nsometimes replaced by Neural Networks and Machine Learning techniques. This has\nvastly increased its potential utility and impact on society, with the\nconsequence that the ethical debate has gone mainstream. Such debate has\nprimarily focused on principles - the what of AI ethics - rather than on\npractices, the how. Awareness of the potential issues is increasing at a fast\nrate, but the AI community's ability to take action to mitigate the associated\nrisks is still at its infancy. Therefore, our intention in presenting this\nresearch is to contribute to closing the gap between principles and practices\nby constructing a typology that may help practically-minded developers apply\nethics at each stage of the pipeline, and to signal to researchers where\nfurther work is needed. The focus is exclusively on Machine Learning, but it is\nhoped that the results of this research may be easily applicable to other\nbranches of AI. The article outlines the research method for creating this\ntypology, the initial findings, and provides a summary of future research\nneeds.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:38:44 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 12:10:32 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Morley", "Jessica", ""], ["Floridi", "Luciano", ""], ["Kinsey", "Libby", ""], ["Elhalal", "Anat", ""]]}, {"id": "1905.06886", "submitter": "Felix Petersen", "authors": "Felix Petersen, Christian Borgelt, Oliver Deussen", "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "comments": "preprint, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks revolutionized many areas of computer science in\nrecent years since they provide solutions to a number of previously unsolved\nproblems. On the other hand, for many problems, classic algorithms exist, which\ntypically exceed the accuracy and stability of neural networks. To combine\nthese two concepts, we present a new kind of neural networks$-$algorithmic\nneural networks (AlgoNets). These networks integrate smooth versions of classic\nalgorithms into the topology of neural networks. A forward AlgoNet includes\nalgorithmic layers into existing architectures while a backward AlgoNet can\nsolve inverse problems without or with only weak supervision. In addition, we\npresent the $\\texttt{algonet}$ package, a PyTorch based library that includes,\ninter alia, a smoothly evaluated programming language, a smooth 3D mesh\nrenderer, and smooth sorting algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:22:52 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:42:06 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Petersen", "Felix", ""], ["Borgelt", "Christian", ""], ["Deussen", "Oliver", ""]]}, {"id": "1905.06889", "submitter": "Mohammadreza Zandehshahvar", "authors": "Yashar Kiarashinejad, Sajjad Abdollahramezani, Mohammadreza\n  Zandehshahvar, Omid Hemmatyar, Ali Adibi", "title": "Deep Learning Reveals Underlying Physics of Light-matter Interactions in\n  Nanophotonic Devices", "comments": null, "journal-ref": null, "doi": "10.1002/adts.201900088", "report-no": null, "categories": "physics.optics cs.LG physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep learning-based (DL-based) algorithm, as a\npurely mathematical platform, for providing intuitive understanding of the\nproperties of electromagnetic (EM) wave-matter interaction in nanostructures.\nThis approach is based on using the dimensionality reduction (DR) technique to\nsignificantly reduce the dimensionality of a generic EM wave-matter interaction\nproblem without imposing significant error. Such an approach implicitly\nprovides useful information about the role of different features (or design\nparameters such as geometry) of the nanostructure in its response\nfunctionality. To demonstrate the practical capabilities of this DL-based\ntechnique, we apply it to a reconfigurable optical metadevice enabling\ndual-band and triple-band optical absorption in the telecommunication window.\nCombination of the proposed approach with existing commercialized full-wave\nsimulation tools offers a powerful toolkit to extract basic mechanisms of\nwave-matter interaction in complex EM devices and facilitate the design and\noptimization of nanostructures for a large range of applications including\nimaging, spectroscopy, and signal processing. It is worth to mention that the\ndemonstrated approach is general and can be used in a large range of problems\nas long as enough training data can be provided.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 01:32:37 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kiarashinejad", "Yashar", ""], ["Abdollahramezani", "Sajjad", ""], ["Zandehshahvar", "Mohammadreza", ""], ["Hemmatyar", "Omid", ""], ["Adibi", "Ali", ""]]}, {"id": "1905.06893", "submitter": "Bogdan Mazoure", "authors": "Bogdan Mazoure, Thang Doan, Audrey Durand, R Devon Hjelm, Joelle\n  Pineau", "title": "Leveraging exploration in off-policy algorithms via normalizing flows", "comments": "Accepted to 3rd Conference on Robot Learning (CoRL 2019); Keywords:\n  Exploration, soft actor-critic, normalizing flow, off-policy; maximum\n  entropy, reinforcement learning; deceptive reward; sparse reward; inverse\n  autoregressive flow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to discover approximately optimal policies in domains with sparse\nrewards is crucial to applying reinforcement learning (RL) in many real-world\nscenarios. Approaches such as neural density models and continuous exploration\n(e.g., Go-Explore) have been proposed to maintain the high exploration rate\nnecessary to find high performing and generalizable policies. Soft\nactor-critic(SAC) is another method for improving exploration that aims to\ncombine efficient learning via off-policy updates while maximizing the policy\nentropy. In this work, we extend SAC to a richer class of probability\ndistributions (e.g., multimodal) through normalizing flows (NF) and show that\nthis significantly improves performance by accelerating the discovery of good\npolicies while using much smaller policy representations. Our approach, which\nwe call SAC-NF, is a simple, efficient,easy-to-implement modification and\nimprovement to SAC on continuous control baselines such as MuJoCo and PyBullet\nRoboschool domains. Finally, SAC-NF does this while being significantly\nparameter efficient, using as few as 5.5% the parameters for an equivalent SAC\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:33:24 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 19:59:59 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 16:35:47 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Mazoure", "Bogdan", ""], ["Doan", "Thang", ""], ["Durand", "Audrey", ""], ["Hjelm", "R Devon", ""], ["Pineau", "Joelle", ""]]}, {"id": "1905.06907", "submitter": "Jun Wang", "authors": "Jun Wang, Dan Su, Jie Chen, Shulin Feng, Dongpeng Ma, Na Li, Dong Yu", "title": "Learning discriminative features in sequence training without requiring\n  framewise labelled data", "comments": "Accepted in ICASSP 2019 lecture session", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we try to answer two questions: Can deeply learned features\nwith discriminative power benefit an ASR system's robustness to acoustic\nvariability? And how to learn them without requiring framewise labelled\nsequence training data? As existing methods usually require knowing where the\nlabels occur in the input sequence, they have so far been limited to many\nreal-world sequence learning tasks. We propose a novel method which\nsimultaneously models both the sequence discriminative training and the feature\ndiscriminative learning within a single network architecture, so that it can\nlearn discriminative deep features in sequence training that obviates the need\nfor presegmented training data. Our experiment in a realistic industrial ASR\ntask shows that, without requiring any specific fine-tuning or additional\ncomplexity, our proposed models have consistently outperformed state-of-the-art\nmodels and significantly reduced Word Error Rate (WER) under all test\nconditions, and especially with highest improvements under unseen noise\nconditions, by relative 12.94%, 8.66% and 5.80%, showing our proposed models\ncan generalize better to acoustic variability.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:58:25 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Wang", "Jun", ""], ["Su", "Dan", ""], ["Chen", "Jie", ""], ["Feng", "Shulin", ""], ["Ma", "Dongpeng", ""], ["Li", "Na", ""], ["Yu", "Dong", ""]]}, {"id": "1905.06913", "submitter": "Samantha Kleinberg", "authors": "Zahra Ebrahimzadeh, Min Zheng, Selcuk Karakas, and Samantha Kleinberg", "title": "Deep Learning for Multi-Scale Changepoint Detection in Multivariate Time\n  Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world time series, such as in health, have changepoints where the\nsystem's structure or parameters change. Since changepoints can indicate\ncritical events such as onset of illness, it is highly important to detect\nthem. However, existing methods for changepoint detection (CPD) often require\nuser-specified models and cannot recognize changes that occur gradually or at\nmultiple time-scales. To address both, we show how CPD can be treated as a\nsupervised learning problem, and propose a new deep neural network architecture\nto efficiently identify both abrupt and gradual changes at multiple timescales\nfrom multivariate data. Our proposed pyramid recurrent neural network (PRN)\nprovides scale-invariance using wavelets and pyramid analysis techniques from\nmulti-scale signal processing. Through experiments on synthetic and real-world\ndatasets, we show that PRN can detect abrupt and gradual changes with higher\naccuracy than the state of the art and can extrapolate to detect changepoints\nat novel scales not seen in training.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:17:55 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ebrahimzadeh", "Zahra", ""], ["Zheng", "Min", ""], ["Karakas", "Selcuk", ""], ["Kleinberg", "Samantha", ""]]}, {"id": "1905.06916", "submitter": "Owen Levin", "authors": "Owen Levin, Zihang Meng, Vikas Singh, Xiaojin Zhu", "title": "Fooling Computer Vision into Inferring the Wrong Body Mass Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it's been shown that neural networks can use images of human faces\nto accurately predict Body Mass Index (BMI), a widely used health indicator. In\nthis paper we demonstrate that a neural network performing BMI inference is\nindeed vulnerable to test-time adversarial attacks. This extends test-time\nadversarial attacks from classification tasks to regression. The application we\nhighlight is BMI inference in the insurance industry, where such adversarial\nattacks imply a danger of insurance fraud.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:29:08 GMT"}], "update_date": "2019-05-18", "authors_parsed": [["Levin", "Owen", ""], ["Meng", "Zihang", ""], ["Singh", "Vikas", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1905.06922", "submitter": "Ben Poole", "authors": "Ben Poole, Sherjil Ozair, Aaron van den Oord, Alexander A. Alemi,\n  George Tucker", "title": "On Variational Bounds of Mutual Information", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating and optimizing Mutual Information (MI) is core to many problems in\nmachine learning; however, bounding MI in high dimensions is challenging. To\nestablish tractable and scalable objectives, recent work has turned to\nvariational bounds parameterized by neural networks, but the relationships and\ntradeoffs between these bounds remains unclear. In this work, we unify these\nrecent developments in a single framework. We find that the existing\nvariational lower bounds degrade when the MI is large, exhibiting either high\nbias or high variance. To address this problem, we introduce a continuum of\nlower bounds that encompasses previous bounds and flexibly trades off bias and\nvariance. On high-dimensional, controlled problems, we empirically characterize\nthe bias and variance of the bounds and their gradients and demonstrate the\neffectiveness of our new bounds for estimation and representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:31:53 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Poole", "Ben", ""], ["Ozair", "Sherjil", ""], ["Oord", "Aaron van den", ""], ["Alemi", "Alexander A.", ""], ["Tucker", "George", ""]]}, {"id": "1905.06939", "submitter": "Sheshera Mysore", "authors": "Sheshera Mysore, Zach Jensen, Edward Kim, Kevin Huang, Haw-Shiuan\n  Chang, Emma Strubell, Jeffrey Flanigan, Andrew McCallum, Elsa Olivetti", "title": "The Materials Science Procedural Text Corpus: Annotating Materials\n  Synthesis Procedures with Shallow Semantic Structures", "comments": "Accepted as a long paper at the Linguistic Annotation Workshop (LAW)\n  at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Materials science literature contains millions of materials synthesis\nprocedures described in unstructured natural language text. Large-scale\nanalysis of these synthesis procedures would facilitate deeper scientific\nunderstanding of materials synthesis and enable automated synthesis planning.\nSuch analysis requires extracting structured representations of synthesis\nprocedures from the raw text as a first step. To facilitate the training and\nevaluation of synthesis extraction models, we introduce a dataset of 230\nsynthesis procedures annotated by domain experts with labeled graphs that\nexpress the semantics of the synthesis sentences. The nodes in this graph are\nsynthesis operations and their typed arguments, and labeled edges specify\nrelations between the nodes. We describe this new resource in detail and\nhighlight some specific challenges to annotating scientific text with shallow\nsemantic structure. We make the corpus available to the community to promote\nfurther research and development of scientific information extraction systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:57:35 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 21:52:48 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mysore", "Sheshera", ""], ["Jensen", "Zach", ""], ["Kim", "Edward", ""], ["Huang", "Kevin", ""], ["Chang", "Haw-Shiuan", ""], ["Strubell", "Emma", ""], ["Flanigan", "Jeffrey", ""], ["McCallum", "Andrew", ""], ["Olivetti", "Elsa", ""]]}, {"id": "1905.06945", "submitter": "Seongok Ryu", "authors": "Seongok Ryu, Yongchan Kwon, Woo Youn Kim", "title": "Uncertainty quantification of molecular property prediction using\n  Bayesian neural network models", "comments": "Workshop on \"Machine Learning for Molecules and Materials\", NIPS\n  2018. arXiv admin note: substantial text overlap with arXiv:1903.08375", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In chemistry, deep neural network models have been increasingly utilized in a\nvariety of applications such as molecular property predictions, novel molecule\ndesigns, and planning chemical reactions. Despite the rapid increase in the use\nof state-of-the-art models and algorithms, deep neural network models often\nproduce poor predictions in real applications because model performance is\nhighly dependent on the quality of training data. In the field of molecular\nanalysis, data are mostly obtained from either complicated chemical experiments\nor approximate mathematical equations, and then quality of data may be\nquestioned.In this paper, we quantify uncertainties of prediction using\nBayesian neural networks in molecular property predictions. We estimate both\nmodel-driven and data-driven uncertainties, demonstrating the usefulness of\nuncertainty quantification as both a quality checker and a confidence indicator\nwith the three experiments. Our results manifest that uncertainty\nquantification is necessary for more reliable molecular applications and\nBayesian neural network models can be a practical approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 02:22:56 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ryu", "Seongok", ""], ["Kwon", "Yongchan", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1905.06978", "submitter": "Mohamad Kazem Shirani Faradonbeh", "authors": "Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, George Michailidis", "title": "Randomized Algorithms for Data-Driven Stabilization of Stochastic Linear\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.RO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven control strategies for dynamical systems with unknown parameters\nare popular in theory and applications. An essential problem is to prevent\nstochastic linear systems becoming destabilized, due to the uncertainty of the\ndecision-maker about the dynamical parameter. Two randomized algorithms are\nproposed for this problem, but the performance is not sufficiently\ninvestigated. Further, the effect of key parameters of the algorithms such as\nthe magnitude and the frequency of applying the randomizations is not currently\navailable. This work studies the stabilization speed and the failure\nprobability of data-driven procedures. We provide numerical analyses for the\nperformance of two methods: stochastic feedback, and stochastic parameter. The\npresented results imply that as long as the number of statistically independent\nrandomizations is not too small, fast stabilization is guaranteed.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:13:07 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Tewari", "Ambuj", ""], ["Michailidis", "George", ""]]}, {"id": "1905.06982", "submitter": "Issam Hadj Laradji", "authors": "Issam H. Laradji, Mark Schmidt, Vladimir Pavlovic, Minyoung Kim", "title": "Efficient Deep Gaussian Process Models for Variable-Sized Input", "comments": "Accepted in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian processes (DGP) have appealing Bayesian properties, can handle\nvariable-sized data, and learn deep features. Their limitation is that they do\nnot scale well with the size of the data. Existing approaches address this\nusing a deep random feature (DRF) expansion model, which makes inference\ntractable by approximating DGPs. However, DRF is not suitable for\nvariable-sized input data such as trees, graphs, and sequences. We introduce\nthe GP-DRF, a novel Bayesian model with an input layer of GPs, followed by DRF\nlayers. The key advantage is that the combination of GP and DRF leads to a\ntractable model that can both handle a variable-sized input as well as learn\ndeep long-range dependency structures of the data. We provide a novel efficient\nmethod to simultaneously infer the posterior of GP's latent vectors and infer\nthe posterior of DRF's internal weights and random frequencies. Our experiments\nshow that GP-DRF outperforms the standard GP model and DRF model across many\ndatasets. Furthermore, they demonstrate that GP-DRF enables improved\nuncertainty quantification compared to GP and DRF alone, with respect to a\nBhattacharyya distance assessment. Source code is available at\nhttps://github.com/IssamLaradji/GP_DRF.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:26:53 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Laradji", "Issam H.", ""], ["Schmidt", "Mark", ""], ["Pavlovic", "Vladimir", ""], ["Kim", "Minyoung", ""]]}, {"id": "1905.06987", "submitter": "Adarsh Kyadige", "authors": "Adarsh Kyadige, Ethan M. Rudd, Konstantin Berlin", "title": "Learning from Context: Exploiting and Interpreting File Path Information\n  for Better Malware Detection", "comments": "Submitted to ACM CCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) used for static portable executable (PE) malware\ndetection typically employs per-file numerical feature vector representations\nas input with one or more target labels during training. However, there is much\northogonal information that can be gleaned from the \\textit{context} in which\nthe file was seen. In this paper, we propose utilizing a static source of\ncontextual information -- the path of the PE file -- as an auxiliary input to\nthe classifier. While file paths are not malicious or benign in and of\nthemselves, they do provide valuable context for a malicious/benign\ndetermination. Unlike dynamic contextual information, file paths are available\nwith little overhead and can seamlessly be integrated into a multi-view static\nML detector, yielding higher detection rates at very high throughput with\nminimal infrastructural changes. Here we propose a multi-view neural network,\nwhich takes feature vectors from PE file content as well as corresponding file\npaths as inputs and outputs a detection score. To ensure realistic evaluation,\nwe use a dataset of approximately 10 million samples -- files and file paths\nfrom user endpoints of an actual security vendor network. We then conduct an\ninterpretability analysis via LIME modeling to ensure that our classifier has\nlearned a sensible representation and see which parts of the file path most\ncontributed to change in the classifier's score. We find that our model learns\nuseful aspects of the file path for classification, while also learning\nartifacts from customers testing the vendor's product, e.g., by downloading a\ndirectory of malware samples each named as their hash. We prune these artifacts\nfrom our test dataset and demonstrate reductions in false negative rate of\n32.3% at a $10^{-3}$ false positive rate (FPR) and 33.1% at $10^{-4}$ FPR, over\na similar topology single input PE file content only model.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:36:55 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kyadige", "Adarsh", ""], ["Rudd", "Ethan M.", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1905.07006", "submitter": "Alex Beatson", "authors": "Alex Beatson and Ryan P. Adams", "title": "Efficient Optimization of Loops and Limits with Randomized Telescoping\n  Sums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimization problems in which the objective requires an inner\nloop with many steps or is the limit of a sequence of increasingly costly\napproximations. Meta-learning, training recurrent neural networks, and\noptimization of the solutions to differential equations are all examples of\noptimization problems with this character. In such problems, it can be\nexpensive to compute the objective function value and its gradient, but\ntruncating the loop or using less accurate approximations can induce biases\nthat damage the overall solution. We propose randomized telescope (RT) gradient\nestimators, which represent the objective as the sum of a telescoping series\nand sample linear combinations of terms to provide cheap unbiased gradient\nestimates. We identify conditions under which RT estimators achieve\noptimization convergence rates independent of the length of the loop or the\nrequired accuracy of the approximation. We also derive a method for tuning RT\nestimators online to maximize a lower bound on the expected decrease in loss\nper unit of computation. We evaluate our adaptive RT estimators on a range of\napplications including meta-optimization of learning rates, variational\ninference of ODE parameters, and training an LSTM to model long sequences.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 19:33:49 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Beatson", "Alex", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1905.07018", "submitter": "Amrit Singh Bedi", "authors": "Rishabh Dixit, Amrit Singh Bedi, and Ketan Rajawat", "title": "Online Learning over Dynamic Graphs via Distributed Proximal Gradient\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of tracking the minimum of a time-varying convex\noptimization problem over a dynamic graph. Motivated by target tracking and\nparameter estimation problems in intermittently connected robotic and sensor\nnetworks, the goal is to design a distributed algorithm capable of handling\nnon-differentiable regularization penalties. The proposed proximal online\ngradient descent algorithm is built to run in a fully decentralized manner and\nutilizes consensus updates over possibly disconnected graphs. The performance\nof the proposed algorithm is analyzed by developing bounds on its dynamic\nregret in terms of the cumulative path length of the time-varying optimum. It\nis shown that as compared to the centralized case, the dynamic regret incurred\nby the proposed algorithm over $T$ time slots is worse by a factor of $\\log(T)$\nonly, despite the disconnected and time-varying network topology. The empirical\nperformance of the proposed algorithm is tested on the distributed dynamic\nsparse recovery problem, where it is shown to incur a dynamic regret that is\nclose to that of the centralized algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:07:48 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Dixit", "Rishabh", ""], ["Bedi", "Amrit Singh", ""], ["Rajawat", "Ketan", ""]]}, {"id": "1905.07019", "submitter": "Zhe Yu", "authors": "Zhe Yu, Fahmid M. Fahid, Tim Menzies, Gregg Rothermel, Kyle Patrick,\n  Snehit Cherian", "title": "TERMINATOR: Better Automated UI Test Case Prioritization", "comments": "10+2 pages, 4 figures, 3 tables, ESEC/FSE 2019 industry track", "journal-ref": null, "doi": "10.1145/3338906.3340448", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated UI testing is an important component of the continuous integration\nprocess of software development. A modern web-based UI is an amalgam of reports\nfrom dozens of microservices written by multiple teams. Queries on a page that\nopens up another will fail if any of that page's microservices fails. As a\nresult, the overall cost for automated UI testing is high since the UI elements\ncannot be tested in isolation. For example, the entire automated UI testing\nsuite at LexisNexis takes around 30 hours (3-5 hours on the cloud) to execute,\nwhich slows down the continuous integration process.\n  To mitigate this problem and give developers faster feedback on their code,\ntest case prioritization techniques are used to reorder the automated UI test\ncases so that more failures can be detected earlier. Given that much of the\nautomated UI testing is \"black box\" in nature, very little information (only\nthe test case descriptions and testing results) can be utilized to prioritize\nthese automated UI test cases. Hence, this paper evaluates 17 \"black box\" test\ncase prioritization approaches that do not rely on source code information.\nAmong these, we propose a novel TCP approach, that dynamically re-prioritizes\nthe test cases when new failures are detected, by applying and adapting a state\nof the art framework from the total recall problem. Experimental results on\nLexisNexis automated UI testing data show that our new approach (which we call\nTERMINATOR), outperformed prior state of the art approaches in terms of failure\ndetection rates with negligible CPU overhead.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:07:53 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:25:56 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Yu", "Zhe", ""], ["Fahid", "Fahmid M.", ""], ["Menzies", "Tim", ""], ["Rothermel", "Gregg", ""], ["Patrick", "Kyle", ""], ["Cherian", "Snehit", ""]]}, {"id": "1905.07026", "submitter": "Vaishak Belle", "authors": "Michael Varley, Vaishak Belle", "title": "Fairness in Machine Learning with Tractable Models", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence\n  (StarAI), 2020. (This is the extended version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning techniques have become pervasive across a range of different\napplications, and are now widely used in areas as disparate as recidivism\nprediction, consumer credit-risk analysis and insurance pricing. The prevalence\nof machine learning techniques has raised concerns about the potential for\nlearned algorithms to become biased against certain groups. Many definitions\nhave been proposed in the literature, but the fundamental task of reasoning\nabout probabilistic events is a challenging one, owing to the intractability of\ninference.\n  The focus of this paper is taking steps towards the application of tractable\nmodels to fairness. Tractable probabilistic models have emerged that guarantee\nthat conditional marginal can be computed in time linear in the size of the\nmodel. In particular, we show that sum product networks (SPNs) enable an\neffective technique for determining the statistical relationships between\nprotected attributes and other training variables. If a subset of these\ntraining variables are found by the SPN to be independent of the training\nattribute then they can be considered `safe' variables, from which we can train\na classification model without concern that the resulting classifier will\nresult in disparate outcomes for different demographic groups.\n  Our initial experiments on the `German Credit' data set indicate that this\nprocessing technique significantly reduces disparate treatment of male and\nfemale credit applicants, with a small reduction in classification accuracy\ncompared to state of the art. We will also motivate the concept of \"fairness\nthrough percentile equivalence\", a new definition predicated on the notion that\nindividuals at the same percentile of their respective distributions should be\ntreated equivalently, and this prevents unfair penalisation of those\nindividuals who lie at the extremities of their respective distributions.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:31:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 13:25:33 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Varley", "Michael", ""], ["Belle", "Vaishak", ""]]}, {"id": "1905.07027", "submitter": "Francis Lagor", "authors": "John Graff, Xianzhang Xu, Francis D. Lagor, and Tarunraj Singh", "title": "Reduced-order modeling using Dynamic Mode Decomposition and Least Angle\n  Regression", "comments": "14 pages, 2 Figures, Submitted to AIAA Aviation Conference 2019", "journal-ref": null, "doi": "10.2514/6.2019-3072", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Mode Decomposition (DMD) yields a linear, approximate model of a\nsystem's dynamics that is built from data. We seek to reduce the order of this\nmodel by identifying a reduced set of modes that best fit the output. We adopt\na model selection algorithm from statistics and machine learning known as Least\nAngle Regression (LARS). We modify LARS to be complex-valued and utilize LARS\nto select DMD modes. We refer to the resulting algorithm as Least Angle\nRegression for Dynamic Mode Decomposition (LARS4DMD). Sparsity-Promoting\nDynamic Mode Decomposition (DMDSP), a popular mode-selection algorithm, serves\nas a benchmark for comparison. Numerical results from a Poiseuille flow test\nproblem show that LARS4DMD yields reduced-order models that have comparable\nperformance to DMDSP. LARS4DMD has the added benefit that the regularization\nweighting parameter required for DMDSP is not needed.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:35:09 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 03:58:08 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Graff", "John", ""], ["Xu", "Xianzhang", ""], ["Lagor", "Francis D.", ""], ["Singh", "Tarunraj", ""]]}, {"id": "1905.07033", "submitter": "Daniel Vieira Mr.", "authors": "Daniel Vieira, Joao Paixao", "title": "Vector Field Neural Networks", "comments": "121 pages, 141 figures. Masters Dissertation presented at\n  Universidade Federal do Rio de Janeiro, Brazil. TL DR: Construction and\n  motivation of Vector Field Neural Networks and evidence of learning in simple\n  situations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work begins by establishing a mathematical formalization between\ndifferent geometrical interpretations of Neural Networks, providing a first\ncontribution. From this starting point, a new interpretation is explored, using\nthe idea of implicit vector fields moving data as particles in a flow. A new\narchitecture, Vector Fields Neural Networks(VFNN), is proposed based on this\ninterpretation, with the vector field becoming explicit. A specific\nimplementation of the VFNN using Euler's method to solve ordinary differential\nequations (ODEs) and gaussian vector fields is tested. The first experiments\npresent visual results remarking the important features of the new architecture\nand providing another contribution with the geometrically interpretable\nregularization of model parameters. Then, the new architecture is evaluated for\ndifferent hyperparameters and inputs, with the objective of evaluating the\ninfluence on model performance, computational time, and complexity. The VFNN\nmodel is compared against the known basic models Naive Bayes, Feed Forward\nNeural Networks, and Support Vector Machines(SVM), showing comparable, or\nbetter, results for different datasets. Finally, the conclusion provides many\nnew questions and ideas for improvement of the model that can be used to\nincrease model performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 21:09:10 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Vieira", "Daniel", ""], ["Paixao", "Joao", ""]]}, {"id": "1905.07034", "submitter": "Karthik Devarajan", "authors": "Karthik Devarajan", "title": "Non-negative matrix factorization based on generalized dual divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A theoretical framework for non-negative matrix factorization based on\ngeneralized dual Kullback-Leibler divergence, which includes members of the\nexponential family of models, is proposed. A family of algorithms is developed\nusing this framework and its convergence proven using the\nExpectation-Maximization algorithm. The proposed approach generalizes some\nexisting methods for different noise structures and contrasts with the recently\nproposed quasi-likelihood approach, thus providing a useful alternative for\nnon-negative matrix factorizations. A measure to evaluate the goodness-of-fit\nof the resulting factorization is described. This framework can be adapted to\ninclude penalty, kernel and discriminant functions as well as tensors.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 21:10:23 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Devarajan", "Karthik", ""]]}, {"id": "1905.07039", "submitter": "Siddharth Siddharth", "authors": "Siddharth Siddharth, Tzyy-Ping Jung, and Terrence J. Sejnowski", "title": "Utilizing Deep Learning Towards Multi-modal Bio-sensing and Vision-based\n  Affective Computing", "comments": "Accepted for publication in IEEE Transactions on Affective Computing.\n  This version on the arXiv is the updated version of the same manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of bio-sensing signals such as electroencephalogram\n(EEG), electrocardiogram (ECG), etc. have garnered interest towards\napplications in affective computing. The parallel trend of deep-learning has\nled to a huge leap in performance towards solving various vision-based research\nproblems such as object detection. Yet, these advances in deep-learning have\nnot adequately translated into bio-sensing research. This work applies novel\ndeep-learning-based methods to various bio-sensing and video data of four\npublicly available multi-modal emotion datasets. For each dataset, we first\nindividually evaluate the emotion-classification performance obtained by each\nmodality. We then evaluate the performance obtained by fusing the features from\nthese modalities. We show that our algorithms outperform the results reported\nby other studies for emotion/valence/arousal/liking classification on DEAP and\nMAHNOB-HCI datasets and set up benchmarks for the newer AMIGOS and DREAMER\ndatasets. We also evaluate the performance of our algorithms by combining the\ndatasets and by using transfer learning to show that the proposed method\novercomes the inconsistencies between the datasets. Hence, we do a thorough\nanalysis of multi-modal affective data from more than 120 subjects and 2,800\ntrials. Finally, utilizing a convolution-deconvolution network, we propose a\nnew technique towards identifying salient brain regions corresponding to\nvarious affective states.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 21:19:52 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Siddharth", "Siddharth", ""], ["Jung", "Tzyy-Ping", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1905.07043", "submitter": "Omer Ben-Porat", "authors": "Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown, Moshe Tennenholtz", "title": "Fiduciary Bandits", "comments": "Published in The Thirty-seventh International Conference on Machine\n  Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems often face exploration-exploitation tradeoffs: the\nsystem can only learn about the desirability of new options by recommending\nthem to some user. Such systems can thus be modeled as multi-armed bandit\nsettings; however, users are self-interested and cannot be made to follow\nrecommendations. We ask whether exploration can nevertheless be performed in a\nway that scrupulously respects agents' interests---i.e., by a system that acts\nas a fiduciary. More formally, we introduce a model in which a recommendation\nsystem faces an exploration-exploitation tradeoff under the constraint that it\ncan never recommend any action that it knows yields lower reward in expectation\nthan an agent would achieve if it acted alone. Our main contribution is a\npositive result: an asymptotically optimal, incentive compatible, and ex-ante\nindividually rational recommendation algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 21:38:39 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 14:20:45 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 12:10:29 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bahar", "Gal", ""], ["Ben-Porat", "Omer", ""], ["Leyton-Brown", "Kevin", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "1905.07061", "submitter": "Rajhans Singh", "authors": "Rajhans Singh (1), Pavan Turaga (1), Suren Jayasuriya (1), Ravi Garg\n  (2), Martin W. Braun (2) ((1) Arizona State University, (2) Intel\n  Corporation)", "title": "Non-Parametric Priors For Generative Adversarial Networks", "comments": null, "journal-ref": "International Conference on Machine Learning (2019)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of generative adversarial networks (GAN) has enabled new\ncapabilities in synthesis, interpolation, and data augmentation heretofore\nconsidered very challenging. However, one of the common assumptions in most GAN\narchitectures is the assumption of simple parametric latent-space\ndistributions. While easy to implement, a simple latent-space distribution can\nbe problematic for uses such as interpolation. This is due to distributional\nmismatches when samples are interpolated in the latent space. We present a\nstraightforward formalization of this problem; using basic results from\nprobability theory and off-the-shelf-optimization tools, we develop ways to\narrive at appropriate non-parametric priors. The obtained prior exhibits\nunusual qualitative properties in terms of its shape, and quantitative benefits\nin terms of lower divergence with its mid-point distribution. We demonstrate\nthat our designed prior helps improve image generation along any Euclidean\nstraight line during interpolation, both qualitatively and quantitatively,\nwithout any additional training or architectural modifications. The proposed\nformulation is quite flexible, paving the way to impose newer constraints on\nthe latent-space statistics.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 23:31:20 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Singh", "Rajhans", ""], ["Turaga", "Pavan", ""], ["Jayasuriya", "Suren", ""], ["Garg", "Ravi", ""], ["Braun", "Martin W.", ""]]}, {"id": "1905.07065", "submitter": "Li Chen", "authors": "Li Chen", "title": "Privacy Preserving Adjacency Spectral Embedding on Stochastic\n  Blockmodels", "comments": "Accepted at Learning and Reasoning with Graph-Structured\n  Representations at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs generated from stochastic blockmodels, adjacency spectral\nembedding is asymptotically consistent. Further, adjacency spectral embedding\ncomposed with universally consistent classifiers is universally consistent to\nachieve the Bayes error. However when the graph contains private or sensitive\ninformation, treating the data as non-private can potentially leak privacy and\nincur disclosure risks. In this paper, we propose a differentially private\nadjacency spectral embedding algorithm for stochastic blockmodels. We\ndemonstrate that our proposed methodology can estimate the latent positions\nclose to, in Frobenius norm, the latent positions by adjacency spectral\nembedding and achieve comparable accuracy at desired privacy parameters in\nsimulated and real world networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 23:43:45 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "1905.07072", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Naveen Suda, Radu Marculescu", "title": "Dream Distillation: A Data-Independent Model Compression Framework", "comments": "Presented at the ICML 2019 Joint Workshop on On-Device Machine\n  Learning & Compact Deep Neural Network Representations (ODML-CDNNR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is eminently suited for deploying deep learning on\nIoT-devices. However, existing model compression techniques rely on access to\nthe original or some alternate dataset. In this paper, we address the model\ncompression problem when no real data is available, e.g., when data is private.\nTo this end, we propose Dream Distillation, a data-independent model\ncompression framework. Our experiments show that Dream Distillation can achieve\n88.5% accuracy on the CIFAR-10 test set without actually training on the\noriginal data!\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 00:28:49 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Suda", "Naveen", ""], ["Marculescu", "Radu", ""]]}, {"id": "1905.07088", "submitter": "Yang Song", "authors": "Yang Song, Sahaj Garg, Jiaxin Shi, Stefano Ermon", "title": "Sliced Score Matching: A Scalable Approach to Density and Score\n  Estimation", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score matching is a popular method for estimating unnormalized statistical\nmodels. However, it has been so far limited to simple, shallow models or\nlow-dimensional data, due to the difficulty of computing the Hessian of\nlog-density functions. We show this difficulty can be mitigated by projecting\nthe scores onto random vectors before comparing them. This objective, called\nsliced score matching, only involves Hessian-vector products, which can be\neasily implemented using reverse-mode automatic differentiation. Therefore,\nsliced score matching is amenable to more complex models and higher dimensional\ndata compared to score matching. Theoretically, we prove the consistency and\nasymptotic normality of sliced score matching estimators. Moreover, we\ndemonstrate that sliced score matching can be used to learn deep score\nestimators for implicit distributions. In our experiments, we show sliced score\nmatching can learn deep energy-based models effectively, and can produce\naccurate score estimates for applications such as variational inference with\nimplicit distributions and training Wasserstein Auto-Encoders.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 02:02:30 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 08:00:36 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Song", "Yang", ""], ["Garg", "Sahaj", ""], ["Shi", "Jiaxin", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.07089", "submitter": "Yu Gong", "authors": "Yu Gong, Yu Zhu, Lu Duan, Qingwen Liu, Ziyu Guan, Fei Sun, Wenwu Ou,\n  Kenny Q. Zhu", "title": "Exact-K Recommendation via Maximal Clique Optimization", "comments": "SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets to a novel but practical recommendation problem named\nexact-K recommendation. It is different from traditional top-K recommendation,\nas it focuses more on (constrained) combinatorial optimization which will\noptimize to recommend a whole set of K items called card, rather than ranking\noptimization which assumes that \"better\" items should be put into top\npositions. Thus we take the first step to give a formal problem definition, and\ninnovatively reduce it to Maximum Clique Optimization based on graph. To tackle\nthis specific combinatorial optimization problem which is NP-hard, we propose\nGraph Attention Networks (GAttN) with a Multi-head Self-attention encoder and a\ndecoder with attention mechanism. It can end-to-end learn the joint\ndistribution of the K items and generate an optimal card rather than rank\nindividual items by prediction scores. Then we propose Reinforcement Learning\nfrom Demonstrations (RLfD) which combines the advantages in behavior cloning\nand reinforcement learning, making it sufficient- and-efficient to train the\nmodel. Extensive experiments on three datasets demonstrate the effectiveness of\nour proposed GAttN with RLfD method, it outperforms several strong baselines\nwith a relative improvement of 7.7% and 4.7% on average in Precision and Hit\nRatio respectively, and achieves state-of-the-art (SOTA) performance for the\nexact-K recommendation problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 02:02:59 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Gong", "Yu", ""], ["Zhu", "Yu", ""], ["Duan", "Lu", ""], ["Liu", "Qingwen", ""], ["Guan", "Ziyu", ""], ["Sun", "Fei", ""], ["Ou", "Wenwu", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1905.07095", "submitter": "Jason T. L. Wang", "authors": "Hao Liu, Chang Liu, Jason T. L. Wang, Haimin Wang", "title": "Predicting Solar Flares Using a Long Short-Term Memory Network", "comments": "19 pages, 10 figures", "journal-ref": "The Astrophysical Journal, 877:121 (14pp), 2019", "doi": "10.3847/1538-4357/ab1b3c", "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a long short-term memory (LSTM) network for predicting whether an\nactive region (AR) would produce a gamma-class flare within the next 24 hours.\nWe consider three gamma classes, namely >=M5.0 class, >=M class, and >=C class,\nand build three LSTM models separately, each corresponding to a gamma class.\nEach LSTM model is used to make predictions of its corresponding gamma-class\nflares. The essence of our approach is to model data samples in an AR as time\nseries and use LSTMs to capture temporal information of the data samples. Each\ndata sample has 40 features including 25 magnetic parameters obtained from the\nSpace-weather HMI Active Region Patches (SHARP) and related data products as\nwell as 15 flare history parameters. We survey the flare events that occurred\nfrom 2010 May to 2018 May, using the GOES X-ray flare catalogs provided by the\nNational Centers for Environmental Information (NCEI), and select flares with\nidentified ARs in the NCEI flare catalogs. These flare events are used to build\nthe labels (positive vs. negative) of the data samples. Experimental results\nshow that (i) using only 14-22 most important features including both flare\nhistory and magnetic parameters can achieve better performance than using all\nthe 40 features together; (ii) our LSTM network outperforms related machine\nlearning methods in predicting the labels of the data samples. To our\nknowledge, this is the first time that LSTMs have been used for solar flare\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 02:57:13 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Liu", "Hao", ""], ["Liu", "Chang", ""], ["Wang", "Jason T. L.", ""], ["Wang", "Haimin", ""]]}, {"id": "1905.07102", "submitter": "Darwin Bautista", "authors": "Darwin Bautista and Raimarc Dionido", "title": "Mastering the Game of Sungka from Random Play", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent work in reinforcement learning demonstrated that learning solely\nthrough self-play is not only possible, but could also result in novel\nstrategies that humans never would have thought of. However, optimization\nmethods cast as a game between two players require careful tuning to prevent\nsuboptimal results. Hence, we look at random play as an alternative method. In\nthis paper, we train a DQN agent to play Sungka, a two-player turn-based board\ngame wherein the players compete to obtain more stones than the other. We show\nthat even with purely random play, our training algorithm converges very fast\nand is stable. Moreover, we test our trained agent against several baselines\nand show its ability to consistently win against these.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 03:41:10 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Bautista", "Darwin", ""], ["Dionido", "Raimarc", ""]]}, {"id": "1905.07107", "submitter": "Mahsa Mozaffari", "authors": "Mahsa Mozaffari and Yasin Yilmaz", "title": "Online Multivariate Anomaly Detection and Localization for\n  High-dimensional Settings", "comments": "16 pages, LaTeX; references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the real-time detection of anomalies in high-dimensional\nsystems. The goal is to detect anomalies quickly and accurately so that the\nappropriate countermeasures could be taken in time, before the system possibly\ngets harmed. We propose a sequential and multivariate anomaly detection method\nthat scales well to high-dimensional datasets. The proposed method follows a\nnonparametric, i.e., data-driven, and semi-supervised approach, i.e., trains\nonly on nominal data. Thus, it is applicable to a wide range of applications\nand data types. Thanks to its multivariate nature, it can quickly and\naccurately detect challenging anomalies, such as changes in the correlation\nstructure and stealth low-rate cyberattacks. Its asymptotic optimality and\ncomputational complexity are comprehensively analyzed. In conjunction with the\ndetection method, an effective technique for localizing the anomalous data\ndimensions is also proposed. We further extend the proposed detection and\nlocalization methods to a supervised setup where an additional anomaly dataset\nis available, and combine the proposed semi-supervised and supervised\nalgorithms to obtain an online learning algorithm under the semi-supervised\nframework. The practical use of proposed algorithms are demonstrated in DDoS\nattack mitigation, and their performances are evaluated using a real IoT-botnet\ndataset and simulations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 03:55:58 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 23:13:32 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Mozaffari", "Mahsa", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "1905.07111", "submitter": "Saikat  Chatterjee", "authors": "Saikat Chatterjee and Alireza M. Javid and Mostafa Sadeghi and Shumpei\n  Kikuta and Dong Liu and Partha P. Mitra and Mikael Skoglund", "title": "SSFN -- Self Size-estimating Feed-forward Network with Low Complexity,\n  Limited Need for Human Intervention, and Consistent Behaviour across Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a self size-estimating feed-forward network (SSFN) using a joint\noptimization approach for estimation of number of layers, number of nodes and\nlearning of weight matrices. The learning algorithm has a low computational\ncomplexity, preferably within few minutes using a laptop. In addition the\nalgorithm has a limited need for human intervention to tune parameters. SSFN\ngrows from a small-size network to a large-size network, guaranteeing a\nmonotonically non-increasing cost with addition of nodes and layers. The\nlearning approach uses judicious a combination of `lossless flow property' of\nsome activation functions, convex optimization and instance of random matrix.\nConsistent performance -- low variation across Monte-Carlo trials -- is found\nfor inference performance (classification accuracy) and estimation of network\nsize.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 04:20:19 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:30:03 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Chatterjee", "Saikat", ""], ["Javid", "Alireza M.", ""], ["Sadeghi", "Mostafa", ""], ["Kikuta", "Shumpei", ""], ["Liu", "Dong", ""], ["Mitra", "Partha P.", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1905.07112", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "A critique of the DeepSec Platform for Security Analysis of Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At IEEE S&P 2019, the paper \"DeepSec: A Uniform Platform for Security\nAnalysis of Deep Learning Model\" aims to to \"systematically evaluate the\nexisting adversarial attack and defense methods.\" While the paper's goals are\nlaudable, it fails to achieve them and presents results that are fundamentally\nflawed and misleading. We explain the flaws in the DeepSec work, along with how\nits analysis fails to meaningfully evaluate the various attacks and defenses.\nSpecifically, DeepSec (1) evaluates each defense obliviously, using attacks\ncrafted against undefended models; (2) evaluates attacks and defenses using\nincorrect implementations that greatly under-estimate their effectiveness; (3)\nevaluates the robustness of each defense as an average, not based on the most\neffective attack against that defense; (4) performs several statistical\nanalyses incorrectly and fails to report variance; and, (5) as a result of\nthese errors draws invalid conclusions and makes sweeping generalizations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 04:26:52 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "1905.07121", "submitter": "Chuan Guo", "authors": "Chuan Guo, Jacob R. Gardner, Yurong You, Andrew Gordon Wilson, Kilian\n  Q. Weinberger", "title": "Simple Black-box Adversarial Attacks", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an intriguingly simple method for the construction of adversarial\nimages in the black-box setting. In constrast to the white-box scenario,\nconstructing black-box adversarial images has the additional constraint on\nquery budget, and efficient attacks remain an open problem to date. With only\nthe mild assumption of continuous-valued confidence scores, our highly\nquery-efficient algorithm utilizes the following simple iterative principle: we\nrandomly sample a vector from a predefined orthonormal basis and either add or\nsubtract it to the target image. Despite its simplicity, the proposed method\ncan be used for both untargeted and targeted attacks -- resulting in previously\nunprecedented query efficiency in both settings. We demonstrate the efficacy\nand efficiency of our algorithm on several real world settings including the\nGoogle Cloud Vision API. We argue that our proposed algorithm should serve as a\nstrong baseline for future black-box attacks, in particular because it is\nextremely fast and its implementation requires less than 20 lines of PyTorch\ncode.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 06:00:41 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 14:12:57 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Guo", "Chuan", ""], ["Gardner", "Jacob R.", ""], ["You", "Yurong", ""], ["Wilson", "Andrew Gordon", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1905.07136", "submitter": "Shota Harada", "authors": "Shota Harada, Hideaki Hayashi, Seiichi Uchida", "title": "Biosignal Generation and Latent Variable Analysis with Recurrent\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of biosignal generation and data augmentation with\nbiosignal generative models based on generative adversarial networks (GANs),\nwhich are a type of deep learning technique, was demonstrated in our previous\npaper. GAN-based generative models only learn the projection between a random\ndistribution as input data and the distribution of training data.Therefore, the\nrelationship between input and generated data is unclear, and the\ncharacteristics of the data generated from this model cannot be controlled.\nThis study proposes a method for generating time-series data based on GANs and\nexplores their ability to generate biosignals with certain classes and\ncharacteristics. Moreover, in the proposed method, latent variables are\nanalyzed using canonical correlation analysis (CCA) to represent the\nrelationship between input and generated data as canonical loadings. Using\nthese loadings, we can control the characteristics of the data generated by the\nproposed method. The influence of class labels on generated data is analyzed by\nfeeding the data interpolated between two class labels into the generator of\nthe proposed GANs. The CCA of the latent variables is shown to be an effective\nmethod of controlling the generated data characteristics. We are able to model\nthe distribution of the time-series data without requiring domain-dependent\nknowledge using the proposed method. Furthermore, it is possible to control the\ncharacteristics of these data by analyzing the model trained using the proposed\nmethod. To the best of our knowledge, this work is the first to generate\nbiosignals using GANs while controlling the characteristics of the generated\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:23:45 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Harada", "Shota", ""], ["Hayashi", "Hideaki", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1905.07144", "submitter": "Shotaro Kamiya", "authors": "Kota Nakashima, Shotaro Kamiya, Kazuki Ohtsu, Koji Yamamoto, Takayuki\n  Nishio, Masahiro Morikura", "title": "Deep Reinforcement Learning-Based Channel Allocation for Wireless LANs\n  with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last year, IEEE 802.11 Extremely High Throughput Study Group (EHT Study\nGroup) was established to initiate discussions on new IEEE 802.11 features.\nCoordinated control methods of the access points (APs) in the wireless local\narea networks (WLANs) are discussed in EHT Study Group. The present study\nproposes a deep reinforcement learning-based channel allocation scheme using\ngraph convolutional networks (GCNs). As a deep reinforcement learning method,\nwe use a well-known method double deep Q-network. In densely deployed WLANs,\nthe number of the available topologies of APs is extremely high, and thus we\nextract the features of the topological structures based on GCNs. We apply GCNs\nto a contention graph where APs within their carrier sensing ranges are\nconnected to extract the features of carrier sensing relationships.\nAdditionally, to improve the learning speed especially in an early stage of\nlearning, we employ a game theory-based method to collect the training data\nindependently of the neural network model. The simulation results indicate that\nthe proposed method can appropriately control the channels when compared to\nextant methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:36:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Nakashima", "Kota", ""], ["Kamiya", "Shotaro", ""], ["Ohtsu", "Kazuki", ""], ["Yamamoto", "Koji", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""]]}, {"id": "1905.07187", "submitter": "Evgeniy Golikov", "authors": "Eugene Golikov", "title": "An Essay on Optimization Mystery of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the huge empirical success of deep learning, theoretical\nunderstanding of neural networks learning process is still lacking. This is the\nreason, why some of its features seem \"mysterious\". We emphasize two mysteries\nof deep learning: generalization mystery, and optimization mystery. In this\nessay we review and draw connections between several selected works concerning\nthe latter.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:28:06 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Golikov", "Eugene", ""]]}, {"id": "1905.07188", "submitter": "Guangyao Xu", "authors": "Zengyou He, Guangyao Xu, Chaohua Sheng, Bo Xu, Quan Zou", "title": "Reference-Based Sequence Classification", "comments": null, "journal-ref": "in IEEE Access, vol. 8, pp. 218199-218214, 2020", "doi": "10.1109/ACCESS.2020.3042757", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence classification is an important data mining task in many real world\napplications. Over the past few decades, many sequence classification methods\nhave been proposed from different aspects. In particular, the pattern-based\nmethod is one of the most important and widely studied sequence classification\nmethods in the literature. In this paper, we present a reference-based sequence\nclassification framework, which can unify existing pattern-based sequence\nclassification methods under the same umbrella. More importantly, this\nframework can be used as a general platform for developing new sequence\nclassification algorithms. By utilizing this framework as a tool, we propose\nnew sequence classification algorithms that are quite different from existing\nsolutions. Experimental results show that new methods developed under the\nproposed framework are capable of achieving comparable classification accuracy\nto those state-of-the-art sequence classification algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:38:31 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:48:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["He", "Zengyou", ""], ["Xu", "Guangyao", ""], ["Sheng", "Chaohua", ""], ["Xu", "Bo", ""], ["Zou", "Quan", ""]]}, {"id": "1905.07189", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Distant Learning for Entity Linking with Automatic Noise Detection", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate entity linkers have been produced for domains and languages where\nannotated data (i.e., texts linked to a knowledge base) is available. However,\nlittle progress has been made for the settings where no or very limited amounts\nof labeled data are present (e.g., legal or most scientific domains). In this\nwork, we show how we can learn to link mentions without having any labeled\nexamples, only a knowledge base and a collection of unannotated texts from the\ncorresponding domain. In order to achieve this, we frame the task as a\nmulti-instance learning problem and rely on surface matching to create initial\nnoisy labels. As the learning signal is weak and our surrogate labels are\nnoisy, we introduce a noise detection component in our model: it lets the model\ndetect and disregard examples which are likely to be noisy. Our method, jointly\nlearning to detect noise and link entities, greatly outperforms the surface\nmatching baseline. For a subset of entity categories, it even approaches the\nperformance of supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:49:47 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:43:50 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1905.07193", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Akhil Sathuluri, Balaraman Ravindran", "title": "MaMiC: Macro and Micro Curriculum for Robotic Reinforcement Learning", "comments": "To appear in the Proceedings of the 18th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2019). (Extended Abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shaping in humans and animals has been shown to be a powerful tool for\nlearning complex tasks as compared to learning in a randomized fashion. This\nmakes the problem less complex and enables one to solve the easier sub task at\nhand first. Generating a curriculum for such guided learning involves\nsubjecting the agent to easier goals first, and then gradually increasing their\ndifficulty. This paper takes a similar direction and proposes a dual curriculum\nscheme for solving robotic manipulation tasks with sparse rewards, called\nMaMiC. It includes a macro curriculum scheme which divides the task into\nmultiple sub-tasks followed by a micro curriculum scheme which enables the\nagent to learn between such discovered sub-tasks. We show how combining macro\nand micro curriculum strategies help in overcoming major exploratory\nconstraints considered in robot manipulation tasks without having to engineer\nany complex rewards. We also illustrate the meaning of the individual curricula\nand how they can be used independently based on the task. The performance of\nsuch a dual curriculum scheme is analyzed on the Fetch environments.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 10:55:58 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Tomar", "Manan", ""], ["Sathuluri", "Akhil", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1905.07210", "submitter": "Naoya Yoshida", "authors": "Naoya Yoshida, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto, and\n  Ryo Yonetani", "title": "Hybrid-FL for Wireless Networks: Cooperative Learning Mechanism Using\n  Non-IID Data", "comments": null, "journal-ref": "Proc. IEEE ICC 2019, Dublin, Ireland, June 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a cooperative mechanism for mitigating the performance\ndegradation due to non-independent-and-identically-distributed (non-IID) data\nin collaborative machine learning (ML), namely federated learning (FL), which\ntrains an ML model using the rich data and computational resources of mobile\nclients without gathering their data to central systems. The data of mobile\nclients is typically non-IID owing to diversity among mobile clients' interests\nand usage, and FL with non-IID data could degrade the model performance.\nTherefore, to mitigate the degradation induced by non-IID data, we assume that\na limited number (e.g., less than 1%) of clients allow their data to be\nuploaded to a server, and we propose a hybrid learning mechanism referred to as\nHybrid-FL, wherein the server updates the model using the data gathered from\nthe clients and aggregates the model with the models trained by clients. The\nHybrid-FL solves both client- and data-selection problems via heuristic\nalgorithms, which try to select the optimal sets of clients who train models\nwith their own data, clients who upload their data to the server, and data\nuploaded to the server. The algorithms increase the number of clients\nparticipating in FL and make more data gather in the server IID, thereby\nimproving the prediction accuracy of the aggregated model. Evaluations, which\nconsist of network simulations and ML experiments, demonstrate that the\nproposed scheme achieves a 13.5% higher classification accuracy than those of\nthe previously proposed schemes for the non-IID case.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 11:34:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:45:15 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 07:17:13 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Yoshida", "Naoya", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""], ["Yonetani", "Ryo", ""]]}, {"id": "1905.07234", "submitter": "Siavash Haghiri", "authors": "Siavash Haghiri, Patricia Rubisch, Robert Geirhos, Felix Wichmann,\n  Ulrike von Luxburg", "title": "Comparison-Based Framework for Psychophysics: Lab versus Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, psychophysical experiments are conducted by repeated\nmeasurements on a few well-trained participants under well-controlled\nconditions, often resulting in, if done properly, high quality data. In recent\nyears, however, crowdsourcing platforms are becoming increasingly popular means\nof data collection, measuring many participants at the potential cost of\nobtaining data of worse quality. In this paper we study whether the use of\ncomparison-based (ordinal) data, combined with machine learning algorithms, can\nboost the reliability of crowdsourcing studies for psychophysics, such that\nthey can achieve performance close to a lab experiment. To this end, we compare\nthree setups: simulations, a psychophysics lab experiment, and the same\nexperiment on Amazon Mechanical Turk. All these experiments are conducted in a\ncomparison-based setting where participants have to answer triplet questions of\nthe form \"is object x closer to y or to z?\". We then use machine learning to\nsolve the triplet prediction problem: given a subset of triplet questions with\ncorresponding answers, we predict the answer to the remaining questions.\nConsidering the limitations and noise on MTurk, we find that the accuracy of\ntriplet prediction is surprisingly close---but not equal---to our lab study.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:43:49 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:34:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Haghiri", "Siavash", ""], ["Rubisch", "Patricia", ""], ["Geirhos", "Robert", ""], ["Wichmann", "Felix", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1905.07237", "submitter": "Longxiang Shi", "authors": "Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Pan", "title": "TBQ($\\sigma$): Improving Efficiency of Trace Utilization for Off-Policy\n  Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning with eligibility traces is challenging\nbecause of the discrepancy between target policy and behavior policy. One\ncommon approach is to measure the difference between two policies in a\nprobabilistic way, such as importance sampling and tree-backup. However,\nexisting off-policy learning methods based on probabilistic policy measurement\nare inefficient when utilizing traces under a greedy target policy, which is\nineffective for control problems. The traces are cut immediately when a\nnon-greedy action is taken, which may lose the advantage of eligibility traces\nand slow down the learning process. Alternatively, some non-probabilistic\nmeasurement methods such as General Q($\\lambda$) and Naive Q($\\lambda$) never\ncut traces, but face convergence problems in practice. To address the above\nissues, this paper introduces a new method named TBQ($\\sigma$), which\neffectively unifies the tree-backup algorithm and Naive Q($\\lambda$). By\nintroducing a new parameter $\\sigma$ to illustrate the \\emph{degree} of\nutilizing traces, TBQ($\\sigma$) creates an effective integration of\nTB($\\lambda$) and Naive Q($\\lambda$) and continuous role shift between them.\nThe contraction property of TB($\\sigma$) is theoretically analyzed for both\npolicy evaluation and control settings. We also derive the online version of\nTBQ($\\sigma$) and give the convergence proof. We empirically show that, for\n$\\epsilon\\in(0,1]$ in $\\epsilon$-greedy policies, there exists some degree of\nutilizing traces for $\\lambda\\in[0,1]$, which can improve the efficiency in\ntrace utilization for off-policy reinforcement learning, to both accelerate the\nlearning process and improve the performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:36:48 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Shi", "Longxiang", ""], ["Li", "Shijian", ""], ["Cao", "Longbing", ""], ["Yang", "Long", ""], ["Pan", "Gang", ""]]}, {"id": "1905.07245", "submitter": "Zhewei Wei", "authors": "Yuan Yin and Zhewei Wei", "title": "Scalable Graph Embeddings via Sparse Transpose Proximities", "comments": "ACM SIGKDD2019", "journal-ref": null, "doi": "10.1145/3292500.333086", "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding learns low-dimensional representations for nodes in a graph\nand effectively preserves the graph structure. Recently, a significant amount\nof progress has been made toward this emerging research area. However, there\nare several fundamental problems that remain open. First, existing methods fail\nto preserve the out-degree distributions on directed graphs. Second, many\nexisting methods employ random walk based proximities and thus suffer from\nconflicting optimization goals on undirected graphs. Finally, existing\nfactorization methods are unable to achieve scalability and non-linearity\nsimultaneously.\n  This paper presents an in-depth study on graph embedding techniques on both\ndirected and undirected graphs. We analyze the fundamental reasons that lead to\nthe distortion of out-degree distributions and to the conflicting optimization\ngoals. We propose {\\em transpose proximity}, a unified approach that solves\nboth problems. Based on the concept of transpose proximity, we design \\strap, a\nfactorization based graph embedding algorithm that achieves scalability and\nnon-linearity simultaneously. \\strap makes use of the {\\em backward push}\nalgorithm to efficiently compute the sparse {\\em Personalized PageRank (PPR)}\nas its transpose proximities. By imposing the sparsity constraint, we are able\nto apply non-linear operations to the proximity matrix and perform efficient\nmatrix factorization to derive the embedding vectors. Finally, we present an\nextensive experimental study that evaluates the effectiveness of various graph\nembedding algorithms, and we show that \\strap outperforms the state-of-the-art\nmethods in terms of effectiveness and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 05:20:09 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Yin", "Yuan", ""], ["Wei", "Zhewei", ""]]}, {"id": "1905.07261", "submitter": "Donghyeon Park", "authors": "Donghyeon Park, Keonwoo Kim, Yonggyu Park, Jungwoon Shin and Jaewoo\n  Kang", "title": "KitcheNette: Predicting and Recommending Food Ingredient Pairings using\n  Siamese Neural Networks", "comments": "Accepted and to be appeared in IJCAI-2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/822", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a vast number of ingredients exist in the culinary world, there are\ncountless food ingredient pairings, but only a small number of pairings have\nbeen adopted by chefs and studied by food researchers. In this work, we propose\nKitcheNette which is a model that predicts food ingredient pairing scores and\nrecommends optimal ingredient pairings. KitcheNette employs Siamese neural\nnetworks and is trained on our annotated dataset containing 300K scores of\npairings generated from numerous ingredients in food recipes. As the results\ndemonstrate, our model not only outperforms other baseline models but also can\nrecommend complementary food pairings and discover novel ingredient pairings.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:02:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Park", "Donghyeon", ""], ["Kim", "Keonwoo", ""], ["Park", "Yonggyu", ""], ["Shin", "Jungwoon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1905.07264", "submitter": "Marek Herde", "authors": "Tom Hanika, Marek Herde, Jochen Kuhn, Jan Marco Leimeister, Paul\n  Lukowicz, Sarah Oeste-Rei{\\ss}, Albrecht Schmidt, Bernhard Sick, Gerd Stumme,\n  Sven Tomforde and Katharina Anna Zweig", "title": "Collaborative Interactive Learning -- A clarification of terms and a\n  differentiation from other research fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of collaborative interactive learning (CIL) aims at developing and\ninvestigating the technological foundations for a new generation of smart\nsystems that support humans in their everyday life. While the concept of CIL\nhas already been carved out in detail (including the fields of dedicated CIL\nand opportunistic CIL) and many research objectives have been stated, there is\nstill the need to clarify some terms such as information, knowledge, and\nexperience in the context of CIL and to differentiate CIL from recent and\nongoing research in related fields such as active learning, collaborative\nlearning, and others. Both aspects are addressed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 14:59:53 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Hanika", "Tom", ""], ["Herde", "Marek", ""], ["Kuhn", "Jochen", ""], ["Leimeister", "Jan Marco", ""], ["Lukowicz", "Paul", ""], ["Oeste-Rei\u00df", "Sarah", ""], ["Schmidt", "Albrecht", ""], ["Sick", "Bernhard", ""], ["Stumme", "Gerd", ""], ["Tomforde", "Sven", ""], ["Zweig", "Katharina Anna", ""]]}, {"id": "1905.07289", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada, Hitoshi Iyatomi, Yoshifumi Seki", "title": "Conversion Prediction Using Multi-task Conditional Attention Networks to\n  Support the Creation of Effective Ad Creative", "comments": "9 pages, 6 figures. Accepted at The 25th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD 2019) as an applied data science\n  paper", "journal-ref": "Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD '19), August 4--8, 2019, Anchorage,\n  AK, USA", "doi": "10.1145/3292500.3330789", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting conversions in advertisements is generally a\nchallenging task, because such conversions do not occur frequently. In this\npaper, we propose a new framework to support creating high-performing ad\ncreatives, including the accurate prediction of ad creative text conversions\nbefore delivering to the consumer. The proposed framework includes three key\nideas: multi-task learning, conditional attention, and attention highlighting.\nMulti-task learning is an idea for improving the prediction accuracy of\nconversion, which predicts clicks and conversions simultaneously, to solve the\ndifficulty of data imbalance. Furthermore, conditional attention focuses\nattention of each ad creative with the consideration of its genre and target\ngender, thus improving conversion prediction accuracy. Attention highlighting\nvisualizes important words and/or phrases based on conditional attention. We\nevaluated the proposed framework with actual delivery history data (14,000\ncreatives displayed more than a certain number of times from Gunosy Inc.), and\nconfirmed that these ideas improve the prediction performance of conversions,\nand visualize noteworthy words according to the creatives' attributes.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:25:27 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""], ["Seki", "Yoshifumi", ""]]}, {"id": "1905.07290", "submitter": "Mohamed Zahran", "authors": "Ahmad El Sallab, Ibrahim Sobh, Mohamed Zahran and Nader Essam", "title": "LiDAR Sensor modeling and Data augmentation with GANs for Autonomous\n  driving", "comments": "Accepted at ICML Workshop on AI for Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the autonomous driving domain, data collection and annotation from real\nvehicles are expensive and sometimes unsafe. Simulators are often used for data\naugmentation, which requires realistic sensor models that are hard to formulate\nand model in closed forms. Instead, sensors models can be learned from real\ndata. The main challenge is the absence of paired data set, which makes\ntraditional supervised learning techniques not suitable. In this work, we\nformulate the problem as image translation from unpaired data and employ\nCycleGANs to solve the sensor modeling problem for LiDAR, to produce realistic\nLiDAR from simulated LiDAR (sim2real). Further, we generate high-resolution,\nrealistic LiDAR from lower resolution one (real2real). The LiDAR 3D point cloud\nis processed in Bird-eye View and Polar 2D representations. The experimental\nresults show a high potential of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:30:07 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Sallab", "Ahmad El", ""], ["Sobh", "Ibrahim", ""], ["Zahran", "Mohamed", ""], ["Essam", "Nader", ""]]}, {"id": "1905.07293", "submitter": "Julien Schroeter", "authors": "Julien Schroeter, Kirill Sidorov, David Marshall", "title": "Weakly-Supervised Temporal Localization via Occurrence Count Learning", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model for temporal detection and localization which allows\nthe training of deep neural networks using only counts of event occurrences as\ntraining labels. This powerful weakly-supervised framework alleviates the\nburden of the imprecise and time-consuming process of annotating event\nlocations in temporal data. Unlike existing methods, in which localization is\nexplicitly achieved by design, our model learns localization implicitly as a\nbyproduct of learning to count instances. This unique feature is a direct\nconsequence of the model's theoretical properties. We validate the\neffectiveness of our approach in a number of experiments (drum hit and piano\nonset detection in audio, digit detection in images) and demonstrate\nperformance comparable to that of fully-supervised state-of-the-art methods,\ndespite much weaker training requirements.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:37:50 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Schroeter", "Julien", ""], ["Sidorov", "Kirill", ""], ["Marshall", "David", ""]]}, {"id": "1905.07297", "submitter": "Hongjiao Guan", "authors": "Hongjiao Guan", "title": "MOBA: A multi-objective bounded-abstention model for two-class\n  cost-sensitive problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstaining classifiers have been widely used in cost-sensitive applications\nto avoid ambiguous classification and reduce the cost of misclassification.\nPrevious abstaining classification models rely on cost information, such as a\ncost matrix or cost ratio. However, it is difficult to obtain or estimate costs\nin practical applications. Furthermore, these abstention models are typically\nrestricted to a single optimization metric, which may not be the expected\nindicator when evaluating classification performance. To overcome such\nproblems, a multi-objective bounded-abstention (MOBA) model is proposed to\noptimize essential metrics. Specifically, the MOBA model minimizes the error\nrate of each class under class-dependent abstention constraints. The MOBA model\nis then solved using the non-dominated sorting genetic algorithm II, which is a\npopular evolutionary multi-objective optimization algorithm. A set of\nPareto-optimal solutions will be generated and the best one can be selected\naccording to provided conditions (whether costs are known) or performance\ndemands (e.g., obtaining a high accuracy, F-measure, and etc). Hence, the MOBA\nmodel is robust towards variations in the conditions and requirements. Compared\nto state-of-the-art abstention models, MOBA achieves lower expected costs when\ncost information is considered, and better performance-abstention trade-offs\nwhen it is not.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:40:17 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Guan", "Hongjiao", ""]]}, {"id": "1905.07299", "submitter": "Fr\\'ed\\'eric Branchaud-Charron", "authors": "Frederic Branchaud-Charron and Andrew Achkar and Pierre-Marc Jodoin", "title": "Spectral Metric for Dataset Complexity Assessment", "comments": "10 pages, 5 figures, Supplementary 2 pages 1 figures, accepted at\n  CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new measure to gauge the complexity of image\nclassification problems. Given an annotated image dataset, our method computes\na complexity measure called the cumulative spectral gradient (CSG) which\nstrongly correlates with the test accuracy of convolutional neural networks\n(CNN). The CSG measure is derived from the probabilistic divergence between\nclasses in a spectral clustering framework. We show that this metric correlates\nwith the overall separability of the dataset and thus its inherent complexity.\nAs will be shown, our metric can be used for dataset reduction, to assess which\nclasses are more difficult to disentangle, and approximate the accuracy one\ncould expect to get with a CNN. Results obtained on 11 datasets and three CNN\nmodels reveal that our method is more accurate and faster than previous\ncomplexity measures.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:40:58 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Branchaud-Charron", "Frederic", ""], ["Achkar", "Andrew", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "1905.07302", "submitter": "Katarina Domijan PhD", "authors": "Manokamna Singh, Katarina Domijan", "title": "Comparison of Machine Learning Models in Food Authentication Studies", "comments": "Accepted for 2019 30th Irish Signals and Systems Conference (ISSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying objective of food authentication studies is to determine\nwhether unknown food samples have been correctly labelled. In this paper we\nstudy three near infrared (NIR) spectroscopic datasets from food samples of\ndifferent types: meat samples (labelled by species), olive oil samples\n(labelled by their geographic origin) and honey samples (labelled as pure or\nadulterated by different adulterants). We apply and compare a large number of\nclassification, dimension reduction and variable selection approaches to these\ndatasets. NIR data pose specific challenges to classification and variable\nselection: the datasets are high - dimensional where the number of cases ($n$)\n$<<$ number of features ($p$) and the recorded features are highly serially\ncorrelated. In this paper we carry out comparative analysis of different\napproaches and find that partial least squares, a classic tool employed for\nthese types of data, outperforms all the other approaches considered.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:43:09 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Singh", "Manokamna", ""], ["Domijan", "Katarina", ""]]}, {"id": "1905.07318", "submitter": "John Martin Jr", "authors": "John D. Martin, Michal Lyskawinski, Xiaohu Li, Brendan Englot", "title": "Stochastically Dominant Distributional Reinforcement Learning", "comments": "Accepted to the 2020 International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new approach for managing aleatoric uncertainty in the\nReinforcement Learning (RL) paradigm. Instead of selecting actions according to\na single statistic, we propose a distributional method based on the\nsecond-order stochastic dominance (SSD) relation. This compares the inherent\ndispersion of random returns induced by actions, producing a more comprehensive\nand robust evaluation of the environment's uncertainty. The necessary\nconditions for SSD require estimators to predict accurate second moments. To\naccommodate this, we map the distributional RL problem to a Wasserstein\ngradient flow, treating the distributional Bellman residual as a potential\nenergy functional. We propose a particle-based algorithm for which we prove\noptimality and convergence. Our experiments characterize the algorithm\nperformance and demonstrate how uncertainty and performance are better balanced\nusing an \\textsc{ssd} policy than with other risk measures.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:15:08 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 16:57:49 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 23:16:27 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 15:27:25 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Martin", "John D.", ""], ["Lyskawinski", "Michal", ""], ["Li", "Xiaohu", ""], ["Englot", "Brendan", ""]]}, {"id": "1905.07320", "submitter": "Hui Zhu", "authors": "Hui Zhu, Zhulin An, Chuanguang Yang, Kaiqiang Xu, Erhu Zhao, Yongjun\n  Xu", "title": "EENA: Efficient Evolution of Neural Architecture", "comments": "Accepted by ICCV2019 Neural Architects Workshop (ICCVW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest algorithms for automatic neural architecture search perform remarkable\nbut are basically directionless in search space and computational expensive in\ntraining of every intermediate architecture. In this paper, we propose a method\nfor efficient architecture search called EENA (Efficient Evolution of Neural\nArchitecture). Due to the elaborately designed mutation and crossover\noperations, the evolution process can be guided by the information have already\nbeen learned. Therefore, less computational effort will be required while the\nsearching and training time can be reduced significantly. On CIFAR-10\nclassification, EENA using minimal computational resources (0.65 GPU-days) can\ndesign highly effective neural architecture which achieves 2.56% test error\nwith 8.47M parameters. Furthermore, the best architecture discovered is also\ntransferable for CIFAR-100.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 02:34:23 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 02:25:44 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 03:32:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Zhu", "Hui", ""], ["An", "Zhulin", ""], ["Yang", "Chuanguang", ""], ["Xu", "Kaiqiang", ""], ["Zhao", "Erhu", ""], ["Xu", "Yongjun", ""]]}, {"id": "1905.07325", "submitter": "Mor Shpigel Nacson", "authors": "Mor Shpigel Nacson, Suriya Gunasekar, Jason D. Lee, Nathan Srebro,\n  Daniel Soudry", "title": "Lexicographic and Depth-Sensitive Margins in Homogeneous and\n  Non-Homogeneous Deep Models", "comments": "ICML Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an eye toward understanding complexity control in deep learning, we\nstudy how infinitesimal regularization or gradient descent optimization lead to\nmargin maximizing solutions in both homogeneous and non-homogeneous models,\nextending previous work that focused on infinitesimal regularization only in\nhomogeneous models. To this end we study the limit of loss minimization with a\ndiverging norm constraint (the \"constrained path\"), relate it to the limit of a\n\"margin path\" and characterize the resulting solution. For non-homogeneous\nensemble models, which output is a sum of homogeneous sub-models, we show that\nthis solution discards the shallowest sub-models if they are unnecessary. For\nhomogeneous models, we show convergence to a \"lexicographic max-margin\nsolution\", and provide conditions under which max-margin solutions are also\nattained as the limit of unconstrained gradient descent.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:24:33 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Nacson", "Mor Shpigel", ""], ["Gunasekar", "Suriya", ""], ["Lee", "Jason D.", ""], ["Srebro", "Nathan", ""], ["Soudry", "Daniel", ""]]}, {"id": "1905.07339", "submitter": "Hang Zou", "authors": "Hang Zou, Chao Zhang, Samson Lasaulce, Lucas Saludjian and Patrick\n  Panciatici", "title": "Decision-Oriented Communications: Application to Energy-Efficient\n  Resource Allocation", "comments": null, "journal-ref": "WINCOM2018", "doi": "10.1109/WINCOM.2018.8629632", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we introduce the problem of decision-oriented communications,\nthat is, the goal of the source is to send the right amount of information in\norder for the intended destination to execute a task. More specifically, we\nrestrict our attention to how the source should quantize information so that\nthe destination can maximize a utility function which represents the task to be\nexecuted only knowing the quantized information. For example, for utility\nfunctions under the form $u\\left(\\boldsymbol{x};\\ \\boldsymbol{g}\\right)$,\n$\\boldsymbol{x}$ might represent a decision in terms of using some radio\nresources and $\\boldsymbol{g}$ the system state which is only observed through\nits quantized version $Q(\\boldsymbol{g})$. Both in the case where the utility\nfunction is known and the case where it is only observed through its\nrealizations, we provide solutions to determine such a quantizer. We show how\nthis approach applies to energy-efficient power allocation. In particular, it\nis seen that quantizing the state very roughly is perfectly suited to\nsum-rate-type function maximization, whereas energy-efficiency metrics are more\nsensitive to imperfections.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:55:07 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Zou", "Hang", ""], ["Zhang", "Chao", ""], ["Lasaulce", "Samson", ""], ["Saludjian", "Lucas", ""], ["Panciatici", "Patrick", ""]]}, {"id": "1905.07342", "submitter": "Christophe Giraud", "authors": "Christophe Giraud and Yann Issartel and Luc Leh\\'ericy and Matthieu\n  Lerasle", "title": "Pair-Matching: Links Prediction with Adaptive Queries", "comments": "58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pair-matching problem appears in many applications where one wants to\ndiscover good matches between pairs of entities or individuals. Formally, the\nset of individuals is represented by the nodes of a graph where the edges,\nunobserved at first, represent the good matches. The algorithm queries pairs of\nnodes and observes the presence/absence of edges. Its goal is to discover as\nmany edges as possible with a fixed budget of queries. Pair-matching is a\nparticular instance of multi-armed bandit problem in which the arms are pairs\nof individuals and the rewards are edges linking these pairs. This bandit\nproblem is non-standard though, as each arm can only be played once.\n  Given this last constraint, sublinear regret can be expected only if the\ngraph presents some underlying structure. This paper shows that sublinear\nregret is achievable in the case where the graph is generated according to a\nStochastic Block Model (SBM) with two communities. Optimal regret bounds are\ncomputed for this pair-matching problem. They exhibit a phase transition\nrelated to the Kesten-Stigum threshold for community detection in SBM. The\npair-matching problem is considered in the case where each node is constrained\nto be sampled less than a given amount of times. We show how optimal regret\nrates depend on this constraint. The paper is concluded by a conjecture\nregarding the optimal regret when the number of communities is larger than 2.\nContrary to the two communities case, we argue that a statistical-computational\ngap would appear in this problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:57:37 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:07:56 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Giraud", "Christophe", ""], ["Issartel", "Yann", ""], ["Leh\u00e9ricy", "Luc", ""], ["Lerasle", "Matthieu", ""]]}, {"id": "1905.07346", "submitter": "Stylianos Venieris", "authors": "Mario Almeida, Stefanos Laskaridis, Ilias Leontiadis, Stylianos I.\n  Venieris, Nicholas D. Lane", "title": "EmBench: Quantifying Performance Variations of Deep Neural Networks\n  across Modern Commodity Devices", "comments": "Accepted at MobiSys 2019: 3rd International Workshop on Embedded and\n  Mobile Deep Learning (EMDL), 2019", "journal-ref": null, "doi": "10.1145/3325413.3329793", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, advances in deep learning have resulted in unprecedented\nleaps in diverse tasks spanning from speech and object recognition to context\nawareness and health monitoring. As a result, an increasing number of\nAI-enabled applications are being developed targeting ubiquitous and mobile\ndevices. While deep neural networks (DNNs) are getting bigger and more complex,\nthey also impose a heavy computational and energy burden on the host devices,\nwhich has led to the integration of various specialized processors in commodity\ndevices. Given the broad range of competing DNN architectures and the\nheterogeneity of the target hardware, there is an emerging need to understand\nthe compatibility between DNN-platform pairs and the expected performance\nbenefits on each platform. This work attempts to demystify this landscape by\nsystematically evaluating a collection of state-of-the-art DNNs on a wide\nvariety of commodity devices. In this respect, we identify potential\nbottlenecks in each architecture and provide important guidelines that can\nassist the community in the co-design of more efficient DNNs and accelerators.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:03:29 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Almeida", "Mario", ""], ["Laskaridis", "Stefanos", ""], ["Leontiadis", "Ilias", ""], ["Venieris", "Stylianos I.", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "1905.07350", "submitter": "Edvinas Byla", "authors": "Edvinas Byla and Wei Pang", "title": "DeepSwarm: Optimising Convolutional Neural Networks using Swarm\n  Intelligence", "comments": "13 pages, 6 figures, to access DeepSwarm code go to\n  https://github.com/Pattio/DeepSwarm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose DeepSwarm, a novel neural architecture search (NAS)\nmethod based on Swarm Intelligence principles. At its core DeepSwarm uses Ant\nColony Optimization (ACO) to generate ant population which uses the pheromone\ninformation to collectively search for the best neural architecture.\nFurthermore, by using local and global pheromone update rules our method\nensures the balance between exploitation and exploration. On top of this, to\nmake our method more efficient we combine progressive neural architecture\nsearch with weight reusability. Furthermore, due to the nature of ACO our\nmethod can incorporate heuristic information which can further speed up the\nsearch process. After systematic and extensive evaluation, we discover that on\nthree different datasets (MNIST, Fashion-MNIST, and CIFAR-10) when compared to\nexisting systems our proposed method demonstrates competitive performance.\nFinally, we open source DeepSwarm as a NAS library and hope it can be used by\nmore deep learning researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:13:38 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Byla", "Edvinas", ""], ["Pang", "Wei", ""]]}, {"id": "1905.07356", "submitter": "Matthijs Westera", "authors": "Matthijs Westera and Gemma Boleda", "title": "Don't Blame Distributional Semantics if it can't do Entailment", "comments": "To appear in Proceedings of the 13th International Conference on\n  Computational Semantics (IWCS 2019), Gothenburg, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional semantics has had enormous empirical success in Computational\nLinguistics and Cognitive Science in modeling various semantic phenomena, such\nas semantic similarity, and distributional models are widely used in\nstate-of-the-art Natural Language Processing systems. However, the theoretical\nstatus of distributional semantics within a broader theory of language and\ncognition is still unclear: What does distributional semantics model? Can it\nbe, on its own, a fully adequate model of the meanings of linguistic\nexpressions? The standard answer is that distributional semantics is not fully\nadequate in this regard, because it falls short on some of the central aspects\nof formal semantic approaches: truth conditions, entailment, reference, and\ncertain aspects of compositionality. We argue that this standard answer rests\non a misconception: These aspects do not belong in a theory of expression\nmeaning, they are instead aspects of speaker meaning, i.e., communicative\nintentions in a particular context. In a slogan: words do not refer, speakers\ndo. Clearing this up enables us to argue that distributional semantics on its\nown is an adequate model of expression meaning. Our proposal sheds light on the\nrole of distributional semantics in a broader theory of language and cognition,\nits relationship to formal semantics, and its place in computational models.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:26:05 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Westera", "Matthijs", ""], ["Boleda", "Gemma", ""]]}, {"id": "1905.07357", "submitter": "Philipp Becker", "authors": "Philipp Becker, Harit Pandya, Gregor Gebhardt, Cheng Zhao, James\n  Taylor, Gerhard Neumann", "title": "Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep\n  Feature Spaces", "comments": "accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to integrate uncertainty estimates into deep time-series modelling,\nKalman Filters (KFs) (Kalman et al., 1960) have been integrated with deep\nlearning models, however, such approaches typically rely on approximate\ninference techniques such as variational inference which makes learning more\ncomplex and often less scalable due to approximation errors. We propose a new\ndeep approach to Kalman filtering which can be learned directly in an\nend-to-end manner using backpropagation without additional approximations. Our\napproach uses a high-dimensional factorized latent state representation for\nwhich the Kalman updates simplify to scalar operations and thus avoids hard to\nbackpropagate, computationally heavy and potentially unstable matrix\ninversions. Moreover, we use locally linear dynamic models to efficiently\npropagate the latent state to the next time step. The resulting network\narchitecture, which we call Recurrent Kalman Network (RKN), can be used for any\ntime-series data, similar to a LSTM (Hochreiter & Schmidhuber, 1997) but uses\nan explicit representation of uncertainty. As shown by our experiments, the RKN\nobtains much more accurate uncertainty estimates than an LSTM or Gated\nRecurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly\nimproved prediction performance and outperforms various recent generative\nmodels on an image imputation task.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:26:44 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Becker", "Philipp", ""], ["Pandya", "Harit", ""], ["Gebhardt", "Gregor", ""], ["Zhao", "Cheng", ""], ["Taylor", "James", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1905.07360", "submitter": "Tapabrata Chakraborti", "authors": "Tapabrata Chakraborti, Arijit Patra, Alison Noble", "title": "Contrastive Fairness in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Was it fair that Harry was hired but not Barry? Was it fair that Pam was\nfired instead of Sam? How can one ensure fairness when an intelligent algorithm\ntakes these decisions instead of a human? How can one ensure that the decisions\nwere taken based on merit and not on protected attributes like race or sex?\nThese are the questions that must be answered now that many decisions in real\nlife can be made through machine learning. However research in fairness of\nalgorithms has focused on the counterfactual questions \"what if?\" or \"why?\",\nwhereas in real life most subjective questions of consequence are contrastive:\n\"why this but not that?\". We introduce concepts and mathematical tools using\ncausal inference to address contrastive fairness in algorithmic decision-making\nwith illustrative examples.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:31:34 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:11:09 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 08:55:54 GMT"}, {"version": "v4", "created": "Sat, 7 Sep 2019 17:12:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chakraborti", "Tapabrata", ""], ["Patra", "Arijit", ""], ["Noble", "Alison", ""]]}, {"id": "1905.07366", "submitter": "Christian Schroeder de Witt", "authors": "Christian Schroeder de Witt, Thomas Hornigold", "title": "Stratospheric Aerosol Injection as a Deep Reinforcement Learning Problem", "comments": "Awarded Poster and Spotlight Oral at Climate Change: How Can AI Help?\n  (Workshop) at International Conference on Machine Learning, Long Beach,\n  California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As global greenhouse gas emissions continue to rise, the use of stratospheric\naerosol injection (SAI), a form of solar geoengineering, is increasingly\nconsidered in order to artificially mitigate climate change effects. However,\ninitial research in simulation suggests that naive SAI can have catastrophic\nregional consequences, which may induce serious geostrategic conflicts. Current\ngeo-engineering research treats SAI control in low-dimensional approximation\nonly. We suggest treating SAI as a high-dimensional control problem, with\npolicies trained according to a context-sensitive reward function within the\nDeep Reinforcement Learning (DRL) paradigm. In order to facilitate training in\nsimulation, we suggest to emulate HadCM3, a widely used General Circulation\nModel, using deep learning techniques. We believe this is the first application\nof DRL to the climate sciences.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:36:00 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["de Witt", "Christian Schroeder", ""], ["Hornigold", "Thomas", ""]]}, {"id": "1905.07370", "submitter": "Farhan Khawar", "authors": "Farhan Khawar and Nevin L. Zhang", "title": "Cleaned Similarity for Better Memory-Based Recommenders", "comments": "To appear in SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331310", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-based collaborative filtering methods like user or item k-nearest\nneighbors (kNN) are a simple yet effective solution to the recommendation\nproblem. The backbone of these methods is the estimation of the empirical\nsimilarity between users/items. In this paper, we analyze the spectral\nproperties of the Pearson and the cosine similarity estimators, and we use\ntools from random matrix theory to argue that they suffer from noise and\neigenvalues spreading. We argue that, unlike the Pearson correlation, the\ncosine similarity naturally possesses the desirable property of eigenvalue\nshrinkage for large eigenvalues. However, due to its zero-mean assumption, it\noverestimates the largest eigenvalues. We quantify this overestimation and\npresent a simple re-scaling and noise cleaning scheme. This results in better\nperformance of the memory-based methods compared to their vanilla counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:44:05 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Khawar", "Farhan", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1905.07376", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Jorn W.T. Peters, Rianne van den Berg, Max Welling", "title": "Integer Discrete Flows and Lossless Compression", "comments": "Accepted as a conference paper at Neural Information Processing\n  Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossless compression methods shorten the expected representation size of data\nwithout loss of information, using a statistical model. Flow-based models are\nattractive in this setting because they admit exact likelihood optimization,\nwhich is equivalent to minimizing the expected number of bits per message.\nHowever, conventional flows assume continuous data, which may lead to\nreconstruction errors when quantized for compression. For that reason, we\nintroduce a flow-based generative model for ordinal discrete data called\nInteger Discrete Flow (IDF): a bijective integer map that can learn rich\ntransformations on high-dimensional data. As building blocks for IDFs, we\nintroduce a flexible transformation layer called integer discrete coupling. Our\nexperiments show that IDFs are competitive with other flow-based generative\nmodels. Furthermore, we demonstrate that IDF based compression achieves\nstate-of-the-art lossless compression rates on CIFAR10, ImageNet32, and\nImageNet64. To the best of our knowledge, this is the first lossless\ncompression method that uses invertible neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:07:58 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 18:00:10 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 16:55:38 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 10:15:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Peters", "Jorn W. T.", ""], ["Berg", "Rianne van den", ""], ["Welling", "Max", ""]]}, {"id": "1905.07382", "submitter": "Zoe Guan", "authors": "Zoe Guan, Giovanni Parmigiani, Prasad Patil", "title": "Merging versus Ensembling in Multi-Study Prediction: Theoretical Insight\n  from Random Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical decision point when training predictors using multiple studies is\nwhether these studies should be combined or treated separately. We compare two\nmulti-study learning approaches in the presence of potential heterogeneity in\npredictor-outcome relationships across datasets. We consider 1) merging all of\nthe datasets and training a single learner, and 2) multi-study ensembling,\nwhich involves training a separate learner on each dataset and combining the\npredictions resulting from each learner. In a linear regression setting, we\nshow analytically and confirm via simulation that merging yields lower\nprediction error than ensembling when the predictor-outcome relationships are\nrelatively homogeneous across studies. However, as cross-study heterogeneity\nincreases, there exists a transition point beyond which ensembling outperforms\nmerging. We provide analytic expressions for the transition point in various\nscenarios, study asymptotic properties, and illustrate how transition point\ntheory can be used for deciding when studies should be combined with an\napplication from metabolomics.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:28:39 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 15:40:32 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 12:30:31 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Guan", "Zoe", ""], ["Parmigiani", "Giovanni", ""], ["Patil", "Prasad", ""]]}, {"id": "1905.07387", "submitter": "Ching-Yun Ko", "authors": "Ching-Yun Ko, Zhaoyang Lyu, Tsui-Wei Weng, Luca Daniel, Ngai Wong,\n  Dahua Lin", "title": "POPQORN: Quantifying Robustness of Recurrent Neural Networks", "comments": "10 pages, Ching-Yun Ko and Zhaoyang Lyu contributed equally, accepted\n  to ICML 2019. Please see arXiv source codes for the appendix by clicking\n  [Other formats]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability to adversarial attacks has been a critical issue for deep\nneural networks. Addressing this issue requires a reliable way to evaluate the\nrobustness of a network. Recently, several methods have been developed to\ncompute $\\textit{robustness quantification}$ for neural networks, namely,\ncertified lower bounds of the minimum adversarial perturbation. Such methods,\nhowever, were devised for feed-forward networks, e.g. multi-layer perceptron or\nconvolutional networks. It remains an open problem to quantify robustness for\nrecurrent networks, especially LSTM and GRU. For such networks, there exist\nadditional challenges in computing the robustness quantification, such as\nhandling the inputs at multiple steps and the interaction between gates and\nstates. In this work, we propose $\\textit{POPQORN}$\n($\\textbf{P}$ropagated-$\\textbf{o}$ut$\\textbf{p}$ut $\\textbf{Q}$uantified\nR$\\textbf{o}$bustness for $\\textbf{RN}$Ns), a general algorithm to quantify\nrobustness of RNNs, including vanilla RNNs, LSTMs, and GRUs. We demonstrate its\neffectiveness on different network architectures and show that the robustness\nquantification on individual steps can lead to new insights.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:35:04 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Ko", "Ching-Yun", ""], ["Lyu", "Zhaoyang", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""], ["Wong", "Ngai", ""], ["Lin", "Dahua", ""]]}, {"id": "1905.07389", "submitter": "Davoud Ataee Tarzanagh", "authors": "Davoud Ataee Tarzanagh, Mohamad Kazem Shirani Faradonbeh, George\n  Michailidis", "title": "Online Distributed Estimation of Principal Eigenspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal components analysis (PCA) is a widely used dimension reduction\ntechnique with an extensive range of applications. In this paper, an online\ndistributed algorithm is proposed for recovering the principal eigenspaces. We\nfurther establish its rate of convergence and show how it relates to the number\nof nodes employed in the distributed computation, the effective rank of the\ndata matrix under consideration, and the gap in the spectrum of the underlying\npopulation covariance matrix. The proposed algorithm is illustrated on low-rank\napproximation and $\\boldsymbol{k}$-means clustering tasks. The numerical\nresults show a substantial computational speed-up vis-a-vis standard\ndistributed PCA algorithms, without compromising learning accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:37:54 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Tarzanagh", "Davoud Ataee", ""], ["Faradonbeh", "Mohamad Kazem Shirani", ""], ["Michailidis", "George", ""]]}, {"id": "1905.07394", "submitter": "Ching-Yun Ko", "authors": "Ching-Yun Ko, Rui Lin, Shu Li, Ngai Wong", "title": "MiSC: Mixed Strategies Crowdsourcing", "comments": "8 pages, accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular crowdsourcing techniques mostly focus on evaluating workers' labeling\nquality before adjusting their weights during label aggregation. Recently,\nanother cohort of models regard crowdsourced annotations as incomplete tensors\nand recover unfilled labels by tensor completion. However, mixed strategies of\nthe two methodologies have never been comprehensively investigated, leaving\nthem as rather independent approaches. In this work, we propose $\\textit{MiSC}$\n($\\textbf{Mi}$xed $\\textbf{S}$trategies $\\textbf{C}$rowdsourcing), a versatile\nframework integrating arbitrary conventional crowdsourcing and tensor\ncompletion techniques. In particular, we propose a novel iterative Tucker label\naggregation algorithm that outperforms state-of-the-art methods in extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:42:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ko", "Ching-Yun", ""], ["Lin", "Rui", ""], ["Li", "Shu", ""], ["Wong", "Ngai", ""]]}, {"id": "1905.07435", "submitter": "Harkirat Behl", "authors": "Harkirat Singh Behl, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Philip H.S. Torr", "title": "Alpha MAML: Adaptive Model-Agnostic Meta-Learning", "comments": "6th ICML Workshop on Automated Machine Learning (2019)", "journal-ref": "ICML Workshop on Automated Machine Learning (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-agnostic meta-learning (MAML) is a meta-learning technique to train a\nmodel on a multitude of learning tasks in a way that primes the model for\nfew-shot learning of new tasks. The MAML algorithm performs well on few-shot\nlearning problems in classification, regression, and fine-tuning of policy\ngradients in reinforcement learning, but comes with the need for costly\nhyperparameter tuning for training stability. We address this shortcoming by\nintroducing an extension to MAML, called Alpha MAML, to incorporate an online\nhyperparameter adaptation scheme that eliminates the need to tune meta-learning\nand learning rates. Our results with the Omniglot database demonstrate a\nsubstantial reduction in the need to tune MAML training hyperparameters and\nimprovement to training stability with less sensitivity to hyperparameter\nchoice.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 18:45:25 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Behl", "Harkirat Singh", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1905.07436", "submitter": "Michael Muehlebach", "authors": "Michael Muehlebach and Michael I. Jordan", "title": "A Dynamical Systems Perspective on Nesterov Acceleration", "comments": "11 pages, 4 figures, to appear in the Proceedings of the 36th\n  International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dynamical system framework for understanding Nesterov's\naccelerated gradient method. In contrast to earlier work, our derivation does\nnot rely on a vanishing step size argument. We show that Nesterov acceleration\narises from discretizing an ordinary differential equation with a semi-implicit\nEuler integration scheme. We analyze both the underlying differential equation\nas well as the discretization to obtain insights into the phenomenon of\nacceleration. The analysis suggests that a curvature-dependent damping term\nlies at the heart of the phenomenon. We further establish connections between\nthe discretized and the continuous-time dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 18:45:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Muehlebach", "Michael", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1905.07442", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Vinicius C. Azevedo, Markus Gross, Barbara Solenthaler", "title": "Transport-Based Neural Style Transfer for Smoke Simulations", "comments": "ACM Transaction on Graphics (SIGGRAPH ASIA 2019), additional\n  materials: http://www.byungsoo.me/project/neural-flow-style", "journal-ref": "ACM Trans. Graph. 38, 6, Article 188 (November 2019), 11 pages", "doi": "10.1145/3355089.3356560", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artistically controlling fluids has always been a challenging task.\nOptimization techniques rely on approximating simulation states towards target\nvelocity or density field configurations, which are often handcrafted by\nartists to indirectly control smoke dynamics. Patch synthesis techniques\ntransfer image textures or simulation features to a target flow field. However,\nthese are either limited to adding structural patterns or augmenting coarse\nflows with turbulent structures, and hence cannot capture the full spectrum of\ndifferent styles and semantically complex structures. In this paper, we propose\nthe first Transport-based Neural Style Transfer (TNST) algorithm for volumetric\nsmoke data. Our method is able to transfer features from natural images to\nsmoke simulations, enabling general content-aware manipulations ranging from\nsimple patterns to intricate motifs. The proposed algorithm is physically\ninspired, since it computes the density transport from a source input smoke to\na desired target configuration. Our transport-based approach allows direct\ncontrol over the divergence of the stylization velocity field by optimizing\nincompressible and irrotational potentials that transport smoke towards\nstylization. Temporal consistency is ensured by transporting and aligning\nsubsequent stylized velocities, and 3D reconstructions are computed by\nseamlessly merging stylizations from different camera viewpoints.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 18:55:27 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 14:33:08 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kim", "Byungsoo", ""], ["Azevedo", "Vinicius C.", ""], ["Gross", "Markus", ""], ["Solenthaler", "Barbara", ""]]}, {"id": "1905.07443", "submitter": "Tonmoy Saikia", "authors": "Tonmoy Saikia, Yassine Marrakchi, Arber Zela, Frank Hutter, Thomas\n  Brox", "title": "AutoDispNet: Improving Disparity Estimation With AutoML", "comments": "In Proceedings of the 2019 IEEE International Conference on Computer\n  Vision (ICCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research work in computer vision is being spent on optimizing existing\nnetwork architectures to obtain a few more percentage points on benchmarks.\nRecent AutoML approaches promise to relieve us from this effort. However, they\nare mainly designed for comparatively small-scale classification tasks. In this\nwork, we show how to use and extend existing AutoML techniques to efficiently\noptimize large-scale U-Net-like encoder-decoder architectures. In particular,\nwe leverage gradient-based neural architecture search and Bayesian optimization\nfor hyperparameter search. The resulting optimization does not require a\nlarge-scale compute cluster. We show results on disparity estimation that\nclearly outperform the manually optimized baseline and reach state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:05:25 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 20:19:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Saikia", "Tonmoy", ""], ["Marrakchi", "Yassine", ""], ["Zela", "Arber", ""], ["Hutter", "Frank", ""], ["Brox", "Thomas", ""]]}, {"id": "1905.07444", "submitter": "Zain Din", "authors": "Zain ul abi Din (1), Panagiotis Tigas (2), Samuel T. King (1 and 5),\n  Benjamin Livshits (3 and 4) ((1) UC Davis, (2) Oxford University, (3) Brave\n  Software, (4) Imperial College London, (5) Bouncer Technologies)", "title": "Percival: Making In-Browser Perceptual Ad Blocking Practical With Deep\n  Learning", "comments": "13 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present Percival, a browser-embedded, lightweight, deep\nlearning-powered ad blocker. Percival embeds itself within the browser's image\nrendering pipeline, which makes it possible to intercept every image obtained\nduring page execution and to perform blocking based on applying machine\nlearning for image classification to flag potential ads. Our implementation\ninside both Chromium and Brave browsers shows only a minor rendering\nperformance overhead of 4.55%, demonstrating the feasibility of deploying\ntraditionally heavy models (i.e. deep neural networks) inside the critical path\nof the rendering engine of a browser. We show that our image-based ad blocker\ncan replicate EasyList rules with an accuracy of 96.76%. To show the\nversatility of the Percival's approach we present case studies that demonstrate\nthat Percival 1) does surprisingly well on ads in languages other than English;\n2) Percival also performs well on blocking first-party Facebook ads, which have\npresented issues for other ad blockers. Percival proves that image-based\nperceptual ad blocking is an attractive complement to today's dominant approach\nof block lists\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:08:01 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 04:31:21 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 01:30:24 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Din", "Zain ul abi", "", "1 and 5"], ["Tigas", "Panagiotis", "", "1 and 5"], ["King", "Samuel T.", "", "1 and 5"], ["Livshits", "Benjamin", "", "3 and 4"]]}, {"id": "1905.07446", "submitter": "Azin Asgarian", "authors": "Azin Asgarian, Shun Zhao, Ahmed B. Ashraf, M. Erin Browne, Kenneth M.\n  Prkachin, Alex Mihailidis, Thomas Hadjistavropoulos, and Babak Taati", "title": "Limitations and Biases in Facial Landmark Detection -- An Empirical\n  Study on Older Adults with Dementia", "comments": "Face and Gesture Analysis for Health Informatics (FGAHI) Workshop at\n  CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate facial expression analysis is an essential step in various clinical\napplications that involve physical and mental health assessments of older\nadults (e.g. diagnosis of pain or depression). Although remarkable progress has\nbeen achieved toward developing robust facial landmark detection methods,\nstate-of-the-art methods still face many challenges when encountering\nuncontrolled environments, different ranges of facial expressions, and\ndifferent demographics of the population. A recent study has revealed that the\nhealth status of individuals can also affect the performance of facial landmark\ndetection methods on front views of faces. In this work, we investigate this\nmatter in a much greater context using seven facial landmark detection methods.\nWe perform our evaluation not only on frontal faces but also on profile faces\nand in various regions of the face. Our results shed light on limitations of\nthe existing methods and challenges of applying these methods in clinical\nsettings by indicating: 1) a significant difference between the performance of\nstate-of-the-art when tested on the profile or frontal faces of individuals\nwith vs. without dementia; 2) insights on the existing bias for all regions of\nthe face; and 3) the presence of this bias despite re-training/fine-tuning with\nvarious configurations of six datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:15:15 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Asgarian", "Azin", ""], ["Zhao", "Shun", ""], ["Ashraf", "Ahmed B.", ""], ["Browne", "M. Erin", ""], ["Prkachin", "Kenneth M.", ""], ["Mihailidis", "Alex", ""], ["Hadjistavropoulos", "Thomas", ""], ["Taati", "Babak", ""]]}, {"id": "1905.07447", "submitter": "Dinesh Jayaraman", "authors": "Brian Yang, Jesse Zhang, Vitchyr Pong, Sergey Levine, and Dinesh\n  Jayaraman", "title": "REPLAB: A Reproducible Low-Cost Arm Benchmark Platform for Robotic\n  Learning", "comments": "Extended version of paper accepted to ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardized evaluation measures have aided in the progress of machine\nlearning approaches in disciplines such as computer vision and machine\ntranslation. In this paper, we make the case that robotic learning would also\nbenefit from benchmarking, and present the \"REPLAB\" platform for benchmarking\nvision-based manipulation tasks. REPLAB is a reproducible and self-contained\nhardware stack (robot arm, camera, and workspace) that costs about 2000 USD,\noccupies a cuboid of size 70x40x60 cm, and permits full assembly within a few\nhours. Through this low-cost, compact design, REPLAB aims to drive wide\nparticipation by lowering the barrier to entry into robotics and to enable easy\nscaling to many robots. We envision REPLAB as a framework for reproducible\nresearch across manipulation tasks, and as a step in this direction, we define\na template for a grasping benchmark consisting of a task definition, evaluation\nprotocol, performance measures, and a dataset of 92k grasp attempts. We\nimplement, evaluate, and analyze several previously proposed grasping\napproaches to establish baselines for this benchmark. Finally, we also\nimplement and evaluate a deep reinforcement learning approach for 3D reaching\ntasks on our REPLAB platform. Project page with assembly instructions, code,\nand videos: https://goo.gl/5F9dP4.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:16:54 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Brian", ""], ["Zhang", "Jesse", ""], ["Pong", "Vitchyr", ""], ["Levine", "Sergey", ""], ["Jayaraman", "Dinesh", ""]]}, {"id": "1905.07451", "submitter": "Junteng Jia", "authors": "Junteng Jia, Michael T. Schaub, Santiago Segarra, Austin R. Benson", "title": "Graph-based Semi-Supervised & Active Learning for Edge Flows", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330872", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph-based semi-supervised learning (SSL) method for learning\nedge flows defined on a graph. Specifically, given flow measurements on a\nsubset of edges, we want to predict the flows on the remaining edges. To this\nend, we develop a computational framework that imposes certain constraints on\nthe overall flows, such as (approximate) flow conservation. These constraints\nrender our approach different from classical graph-based SSL for vertex labels,\nwhich posits that tightly connected nodes share similar labels and leverages\nthe graph structure accordingly to extrapolate from a few vertex labels to the\nunlabeled vertices. We derive bounds for our method's reconstruction error and\ndemonstrate its strong performance on synthetic and real-world flow networks\nfrom transportation, physical infrastructure, and the Web. Furthermore, we\nprovide two active learning algorithms for selecting informative edges on which\nto measure flow, which has applications for optimal sensor deployment. The\nfirst strategy selects edges to minimize the reconstruction error bound and\nworks well on flows that are approximately divergence-free. The second approach\nclusters the graph and selects bottleneck edges that cross cluster-boundaries,\nwhich works well on flows with global trends.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:30:42 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Jia", "Junteng", ""], ["Schaub", "Michael T.", ""], ["Segarra", "Santiago", ""], ["Benson", "Austin R.", ""]]}, {"id": "1905.07457", "submitter": "Saswat Padhi", "authors": "Saswat Padhi, Todd Millstein, Aditya Nori, Rahul Sharma", "title": "Overfitting in Synthesis: Theory and Practice (Extended Version)", "comments": "24 pages (5 pages of appendices), 7 figures, includes proofs of\n  theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In syntax-guided synthesis (SyGuS), a synthesizer's goal is to automatically\ngenerate a program belonging to a grammar of possible implementations that\nmeets a logical specification. We investigate a common limitation across\nstate-of-the-art SyGuS tools that perform counterexample-guided inductive\nsynthesis (CEGIS). We empirically observe that as the expressiveness of the\nprovided grammar increases, the performance of these tools degrades\nsignificantly.\n  We claim that this degradation is not only due to a larger search space, but\nalso due to overfitting. We formally define this phenomenon and prove\nno-free-lunch theorems for SyGuS, which reveal a fundamental tradeoff between\nsynthesizer performance and grammar expressiveness.\n  A standard approach to mitigate overfitting in machine learning is to run\nmultiple learners with varying expressiveness in parallel. We demonstrate that\nthis insight can immediately benefit existing SyGuS tools. We also propose a\nnovel single-threaded technique called hybrid enumeration that interleaves\ndifferent grammars and outperforms the winner of the 2018 SyGuS competition\n(Inv track), solving more problems and achieving a $5\\times$ mean speedup.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:07:16 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 15:17:06 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 00:31:22 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Padhi", "Saswat", ""], ["Millstein", "Todd", ""], ["Nori", "Aditya", ""], ["Sharma", "Rahul", ""]]}, {"id": "1905.07465", "submitter": "Luchen Li", "authors": "Luchen Li, Matthieu Komorowski, Aldo A. Faisal", "title": "Optimizing Sequential Medical Treatments with Auto-Encoding Heuristic\n  Search in POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health-related data is noisy and stochastic in implying the true\nphysiological states of patients, limiting information contained in\nsingle-moment observations for sequential clinical decision making. We model\npatient-clinician interactions as partially observable Markov decision\nprocesses (POMDPs) and optimize sequential treatment based on belief states\ninferred from history sequence. To facilitate inference, we build a variational\ngenerative model and boost state representation with a recurrent neural network\n(RNN), incorporating an auxiliary loss from sequence auto-encoding. Meanwhile,\nwe optimize a continuous policy of drug levels with an actor-critic method\nwhere policy gradients are obtained from a stablized off-policy estimate of\nadvantage function, with the value of belief state backed up by parallel\nbest-first suffix trees. We exploit our methodology in optimizing dosages of\nvasopressor and intravenous fluid for sepsis patients using a retrospective\nintensive care dataset and evaluate the learned policy with off-policy policy\nevaluation (OPPE). The results demonstrate that modelling as POMDPs yields\nbetter performance than MDPs, and that incorporating heuristic search improves\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:33:21 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Li", "Luchen", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo A.", ""]]}, {"id": "1905.07469", "submitter": "Clement Etienam", "authors": "Clement Etienam", "title": "4D Seismic History Matching Incorporating Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG math.OC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The work discussed and presented in this paper focuses on the history\nmatching of reservoirs by integrating 4D seismic data into the inversion\nprocess using machine learning techniques. A new integrated scheme for the\nreconstruction of petrophysical properties with a modified Ensemble Smoother\nwith Multiple Data Assimilation (ES-MDA) in a synthetic reservoir is proposed.\nThe permeability field inside the reservoir is parametrised with an\nunsupervised learning approach, namely K-means with Singular Value\nDecomposition (K-SVD). This is combined with the Orthogonal Matching Pursuit\n(OMP) technique which is very typical for sparsity promoting regularisation\nschemes. Moreover, seismic attributes, in particular, acoustic impedance, are\nparametrised with the Discrete Cosine Transform (DCT). This novel combination\nof techniques from machine learning, sparsity regularisation, seismic imaging\nand history matching aims to address the ill-posedness of the inversion of\nhistorical production data efficiently using ES-MDA. In the numerical\nexperiments provided, I demonstrate that these sparse representations of the\npetrophysical properties and the seismic attributes enables to obtain better\nproduction data matches to the true production data and to quantify the\npropagating waterfront better compared to more traditional methods that do not\nuse comparable parametrisation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 06:27:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Etienam", "Clement", ""]]}, {"id": "1905.07471", "submitter": "Jacob Beckerman", "authors": "Jacob Beckerman and Theodore Christakis", "title": "Learning Open Information Extraction of Implicit Relations from Reading\n  Comprehension Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The relationship between two entities in a sentence is often implied by word\norder and common sense, rather than an explicit predicate. For example, it is\nevident that \"Fed chair Powell indicates rate hike\" implies (Powell, is a, Fed\nchair) and (Powell, works for, Fed). These tuples are just as significant as\nthe explicit-predicate tuple (Powell, indicates, rate hike), but have much\nlower recall under traditional Open Information Extraction (OpenIE) systems.\nImplicit tuples are our term for this type of extraction where the relation is\nnot present in the input sentence. There is very little OpenIE training data\navailable relative to other NLP tasks and none focused on implicit relations.\nWe develop an open source, parse-based tool for converting large reading\ncomprehension datasets to OpenIE datasets and release a dataset 35x larger than\npreviously available by sentence count. A baseline neural model trained on this\ndata outperforms previous methods on the implicit extraction task.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:02:35 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Beckerman", "Jacob", ""], ["Christakis", "Theodore", ""]]}, {"id": "1905.07473", "submitter": "Christopher Aicher", "authors": "Christopher Aicher, Nicholas J. Foti, Emily B. Fox", "title": "Adaptively Truncating Backpropagation Through Time to Control Gradient\n  Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truncated backpropagation through time (TBPTT) is a popular method for\nlearning in recurrent neural networks (RNNs) that saves computation and memory\nat the cost of bias by truncating backpropagation after a fixed number of lags.\nIn practice, choosing the optimal truncation length is difficult: TBPTT will\nnot converge if the truncation length is too small, or will converge slowly if\nit is too large. We propose an adaptive TBPTT scheme that converts the problem\nfrom choosing a temporal lag to one of choosing a tolerable amount of gradient\nbias. For many realistic RNNs, the TBPTT gradients decay geometrically in\nexpectation for large lags; under this condition, we can control the bias by\nvarying the truncation length adaptively. For RNNs with smooth activation\nfunctions, we prove that this bias controls the convergence rate of SGD with\nbiased gradients for our non-convex loss. Using this theory, we develop a\npractical method for adaptively estimating the truncation length during\ntraining. We evaluate our adaptive TBPTT method on synthetic data and language\nmodeling tasks and find that our adaptive TBPTT ameliorates the computational\npitfalls of fixed TBPTT.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:51:15 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 20:18:33 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Aicher", "Christopher", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily B.", ""]]}, {"id": "1905.07478", "submitter": "Bryan Seybold", "authors": "Bryan Seybold, Emily Fertig, Alex Alemi, Ian Fischer", "title": "Dueling Decoders: Regularizing Variational Autoencoder Latent Spaces", "comments": "16 pages, 9 figures, supplemental", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders learn unsupervised data representations, but these\nmodels frequently converge to minima that fail to preserve meaningful semantic\ninformation. For example, variational autoencoders with autoregressive decoders\noften collapse into autodecoders, where they learn to ignore the encoder input.\nIn this work, we demonstrate that adding an auxiliary decoder to regularize the\nlatent space can prevent this collapse, but successful auxiliary decoding tasks\nare domain dependent. Auxiliary decoders can increase the amount of semantic\ninformation encoded in the latent space and visible in the reconstructions. The\nsemantic information in the variational autoencoder's representation is only\nweakly correlated with its rate, distortion, or evidence lower bound. Compared\nto other popular strategies that modify the training objective, our\nregularization of the latent space generally increased the semantic information\ncontent.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 21:01:59 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Seybold", "Bryan", ""], ["Fertig", "Emily", ""], ["Alemi", "Alex", ""], ["Fischer", "Ian", ""]]}, {"id": "1905.07479", "submitter": "Zehui Xiong", "authors": "Jiawen Kang, Zehui Xiong, Dusit Niyato, Han Yu, Ying-Chang Liang, Dong\n  In Kim", "title": "Incentive Design for Efficient Federated Learning in Mobile Networks: A\n  Contract Theory Approach", "comments": "submitted to the conference for potential publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To strengthen data privacy and security, federated learning as an emerging\nmachine learning technique is proposed to enable large-scale nodes, e.g.,\nmobile devices, to distributedly train and globally share models without\nrevealing their local data. This technique can not only significantly improve\nprivacy protection for mobile devices, but also ensure good performance of the\ntrained results collectively. Currently, most the existing studies focus on\noptimizing federated learning algorithms to improve model training performance.\nHowever, incentive mechanisms to motivate the mobile devices to join model\ntraining have been largely overlooked. The mobile devices suffer from\nconsiderable overhead in terms of computation and communication during the\nfederated model training process. Without well-designed incentive,\nself-interested mobile devices will be unwilling to join federated learning\ntasks, which hinders the adoption of federated learning. To bridge this gap, in\nthis paper, we adopt the contract theory to design an effective incentive\nmechanism for simulating the mobile devices with high-quality (i.e.,\nhigh-accuracy) data to participate in federated learning. Numerical results\ndemonstrate that the proposed mechanism is efficient for federated learning\nwith improved learning accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:50:19 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:13:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kang", "Jiawen", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Yu", "Han", ""], ["Liang", "Ying-Chang", ""], ["Kim", "Dong In", ""]]}, {"id": "1905.07488", "submitter": "David Greenberg", "authors": "David S. Greenberg, Marcel Nonnenmacher, Jakob H. Macke", "title": "Automatic Posterior Transformation for Likelihood-Free Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can one perform Bayesian inference on stochastic simulators with\nintractable likelihoods? A recent approach is to learn the posterior from\nadaptively proposed simulations using neural network-based conditional density\nestimators. However, existing methods are limited to a narrow range of proposal\ndistributions or require importance weighting that can limit performance in\npractice. Here we present automatic posterior transformation (APT), a new\nsequential neural posterior estimation method for simulation-based inference.\nAPT can modify the posterior estimate using arbitrary, dynamically updated\nproposals, and is compatible with powerful flow-based density estimators. It is\nmore flexible, scalable and efficient than previous simulation-based inference\ntechniques. APT can operate directly on high-dimensional time series and image\ndata, opening up new applications for likelihood-free inference.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 21:50:55 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Greenberg", "David S.", ""], ["Nonnenmacher", "Marcel", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1905.07490", "submitter": "Jongrae Kim", "authors": "Jongrae Kim", "title": "Sequential training algorithm for neural networks", "comments": "5 pages, 3 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequential training method for large-scale feedforward neural networks is\npresented. Each layer of the neural network is decoupled and trained\nseparately. After the training is completed for each layer, they are combined\ntogether. The performance of the network would be sub-optimal compared to the\nfull network training if the optimal solution would be achieved. However,\nachieving the optimal solution for the full network would be infeasible or\nrequire long computing time. The proposed sequential approach reduces the\nrequired computer resources significantly and would have better convergences as\na single layer is optimised for each optimisation step. The required\nmodifications of existing algorithms to implement the sequential training are\nminimal. The performance is verified by a simple example.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 21:52:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kim", "Jongrae", ""]]}, {"id": "1905.07497", "submitter": "Fahimeh Bahmaninezhad", "authors": "Fahimeh Bahmaninezhad, Jian Wu, Rongzhi Gu, Shi-Xiong Zhang, Yong Xu,\n  Meng Yu, and Dong Yu", "title": "A comprehensive study of speech separation: spectrogram vs waveform\n  separation", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech separation has been studied widely for single-channel close-talk\nmicrophone recordings over the past few years; developed solutions are mostly\nin frequency-domain. Recently, a raw audio waveform separation network (TasNet)\nis introduced for single-channel data, with achieving high Si-SNR\n(scale-invariant source-to-noise ratio) and SDR (source-to-distortion ratio)\ncomparing against the state-of-the-art solution in frequency-domain. In this\nstudy, we incorporate effective components of the TasNet into a\nfrequency-domain separation method. We compare both for alternative scenarios.\nWe introduce a solution for directly optimizing the separation criterion in\nfrequency-domain networks. In addition to speech separation objective and\nsubjective measurements, we evaluate the separation performance on a speech\nrecognition task as well. We study the speech separation problem for far-field\ndata (more similar to naturalistic audio streams) and develop multi-channel\nsolutions for both frequency and time-domain separators with utilizing\nspectral, spatial and speaker location information. For our experiments, we\nsimulated multi-channel spatialized reverberate WSJ0-2mix dataset. Our\nexperimental results show that spectrogram separation can achieve competitive\nperformance with better network design. Multi-channel framework as well is\nshown to improve the single-channel performance relatively up to +35.5% and\n+46% in terms of WER and SDR, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 22:54:08 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 20:35:45 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bahmaninezhad", "Fahimeh", ""], ["Wu", "Jian", ""], ["Gu", "Rongzhi", ""], ["Zhang", "Shi-Xiong", ""], ["Xu", "Yong", ""], ["Yu", "Meng", ""], ["Yu", "Dong", ""]]}, {"id": "1905.07499", "submitter": "Brian Trippe", "authors": "Brian L. Trippe, Jonathan H. Huggins, Raj Agrawal and Tamara Broderick", "title": "LR-GLM: High-Dimensional Bayesian Inference Using Low-Rank Data\n  Approximations", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the ease of modern data collection, applied statisticians often have\naccess to a large set of covariates that they wish to relate to some observed\noutcome. Generalized linear models (GLMs) offer a particularly interpretable\nframework for such an analysis. In these high-dimensional problems, the number\nof covariates is often large relative to the number of observations, so we face\nnon-trivial inferential uncertainty; a Bayesian approach allows coherent\nquantification of this uncertainty. Unfortunately, existing methods for\nBayesian inference in GLMs require running times roughly cubic in parameter\ndimension, and so are limited to settings with at most tens of thousand\nparameters. We propose to reduce time and memory costs with a low-rank\napproximation of the data in an approach we call LR-GLM. When used with the\nLaplace approximation or Markov chain Monte Carlo, LR-GLM provides a full\nBayesian posterior approximation and admits running times reduced by a full\nfactor of the parameter dimension. We rigorously establish the quality of our\napproximation and show how the choice of rank allows a tunable\ncomputational-statistical trade-off. Experiments support our theory and\ndemonstrate the efficacy of LR-GLM on real large-scale datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 22:59:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Trippe", "Brian L.", ""], ["Huggins", "Jonathan H.", ""], ["Agrawal", "Raj", ""], ["Broderick", "Tamara", ""]]}, {"id": "1905.07501", "submitter": "Panos Stinis", "authors": "Panos Stinis", "title": "Enforcing constraints for time series prediction in supervised,\n  unsupervised and reinforcement learning", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "PNNL-SA-143654", "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assume that we are given a time series of data from a dynamical system and\nour task is to learn the flow map of the dynamical system. We present a\ncollection of results on how to enforce constraints coming from the dynamical\nsystem in order to accelerate the training of deep neural networks to represent\nthe flow map of the system as well as increase their predictive ability. In\nparticular, we provide ways to enforce constraints during training for all\nthree major modes of learning, namely supervised, unsupervised and\nreinforcement learning. In general, the dynamic constraints need to include\nterms which are analogous to memory terms in model reduction formalisms. Such\nmemory terms act as a restoring force which corrects the errors committed by\nthe learned flow map during prediction.\n  For supervised learning, the constraints are added to the objective function.\nFor the case of unsupervised learning, in particular generative adversarial\nnetworks, the constraints are introduced by augmenting the input of the\ndiscriminator. Finally, for the case of reinforcement learning and in\nparticular actor-critic methods, the constraints are added to the reward\nfunction. In addition, for the reinforcement learning case, we present a novel\napproach based on homotopy of the action-value function in order to stabilize\nand accelerate training. We use numerical results for the Lorenz system to\nillustrate the various constructions.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 23:41:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Stinis", "Panos", ""]]}, {"id": "1905.07504", "submitter": "Zhongyang Li", "authors": "Zhongyang Li, Xiao Ding and Ting Liu", "title": "Story Ending Prediction by Transferable BERT", "comments": "Accepted and to appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances, such as GPT and BERT, have shown success in incorporating a\npre-trained transformer language model and fine-tuning operation to improve\ndownstream NLP systems. However, this framework still has some fundamental\nproblems in effectively incorporating supervised knowledge from other related\ntasks. In this study, we investigate a transferable BERT (TransBERT) training\nframework, which can transfer not only general language knowledge from\nlarge-scale unlabeled data but also specific kinds of knowledge from various\nsemantically related supervised tasks, for a target task. Particularly, we\npropose utilizing three kinds of transfer tasks, including natural language\ninference, sentiment classification, and next action prediction, to further\ntrain BERT based on a pre-trained model. This enables the model to get a better\ninitialization for the target task. We take story ending prediction as the\ntarget task to conduct experiments. The final result, an accuracy of 91.8%,\ndramatically outperforms previous state-of-the-art baseline methods. Several\ncomparative experiments give some helpful suggestions on how to select transfer\ntasks. Error analysis shows what are the strength and weakness of BERT-based\nmodels for story ending prediction.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 23:52:08 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 02:37:11 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Li", "Zhongyang", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""]]}, {"id": "1905.07508", "submitter": "Piper Armstrong", "authors": "Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Emily\n  Hales, and Kevin Seppi", "title": "Cross-referencing using Fine-grained Topic Modeling", "comments": "6 figures 1 table 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-referencing, which links passages of text to other related passages,\ncan be a valuable study aid for facilitating comprehension of a text. However,\ncross-referencing requires first, a comprehensive thematic knowledge of the\nentire corpus, and second, a focused search through the corpus specifically to\nfind such useful connections. Due to this, cross-reference resources are\nprohibitively expensive and exist only for the most well-studied texts (e.g.\nreligious texts). We develop a topic-based system for automatically producing\ncandidate cross-references which can be easily verified by human annotators.\nOur system utilizes fine-grained topic modeling with thousands of highly\nnuanced and specific topics to identify verse pairs which are topically\nrelated. We demonstrate that our system can be cost effective compared to\nhaving annotators acquire the expertise necessary to produce cross-reference\nresources unaided.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 00:28:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lund", "Jeffrey", ""], ["Armstrong", "Piper", ""], ["Fearn", "Wilson", ""], ["Cowley", "Stephen", ""], ["Hales", "Emily", ""], ["Seppi", "Kevin", ""]]}, {"id": "1905.07515", "submitter": "Yajie Zhao", "authors": "Yajie Zhao, Zeng Huang, Tianye Li, Weikai Chen, Chloe LeGendre,\n  Xinglei Ren, Jun Xing, Ari Shapiro, and Hao Li", "title": "Learning Perspective Undistortion of Portraits", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-range portrait photographs often contain perspective distortion\nartifacts that bias human perception and challenge both facial recognition and\nreconstruction techniques. We present the first deep learning based approach to\nremove such artifacts from unconstrained portraits. In contrast to the previous\nstate-of-the-art approach, our method handles even portraits with extreme\nperspective distortion, as we avoid the inaccurate and error-prone step of\nfirst fitting a 3D face model. Instead, we predict a distortion correction flow\nmap that encodes a per-pixel displacement that removes distortion artifacts\nwhen applied to the input image. Our method also automatically infers missing\nfacial features, i.e. occluded ears caused by strong perspective distortion,\nwith coherent details. We demonstrate that our approach significantly\noutperforms the previous state-of-the-art both qualitatively and\nquantitatively, particularly for portraits with extreme perspective distortion\nor facial expressions. We further show that our technique benefits a number of\nfundamental tasks, significantly improving the accuracy of both face\nrecognition and 3D reconstruction and enables a novel camera calibration\ntechnique from a single portrait. Moreover, we also build the first perspective\nportrait database with a large diversity in identities, expression and poses,\nwhich will benefit the related research in this area.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 01:08:47 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhao", "Yajie", ""], ["Huang", "Zeng", ""], ["Li", "Tianye", ""], ["Chen", "Weikai", ""], ["LeGendre", "Chloe", ""], ["Ren", "Xinglei", ""], ["Xing", "Jun", ""], ["Shapiro", "Ari", ""], ["Li", "Hao", ""]]}, {"id": "1905.07529", "submitter": "Xiawu Zheng", "authors": "Xiawu Zheng, Rongrong Ji, Lang Tang, Baochang Zhang, Jianzhuang Liu,\n  Qi Tian", "title": "Multinomial Distribution Learning for Effective Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectures obtained by Neural Architecture Search (NAS) have achieved\nhighly competitive performance in various computer vision tasks. However, the\nprohibitive computation demand of forward-backward propagation in deep neural\nnetworks and searching algorithms makes it difficult to apply NAS in practice.\nIn this paper, we propose a Multinomial Distribution Learning for extremely\neffective NAS,which considers the search space as a joint multinomial\ndistribution, i.e., the operation between two nodes is sampled from this\ndistribution, and the optimal network structure is obtained by the operations\nwith the most likely probability in this distribution. Therefore, NAS can be\ntransformed to a multinomial distribution learning problem, i.e., the\ndistribution is optimized to have a high expectation of the performance.\nBesides, a hypothesis that the performance ranking is consistent in every\ntraining epoch is proposed and demonstrated to further accelerate the learning\nprocess. Experiments on CIFAR10 and ImageNet demonstrate the effectiveness of\nour method. On CIFAR-10, the structure searched by our method achieves 2.55%\ntest error, while being 6.0x (only 4 GPU hours on GTX1080Ti) faster compared\nwith state-of-the-art NAS algorithms. On ImageNet, our model achieves 75.2%\ntop1 accuracy under MobileNet settings (MobileNet V1/V2), while being 1.2x\nfaster with measured GPU latency. Test code with pre-trained models are\navailable at https://github.com/tanglang96/MDENAS\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 03:30:47 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 07:18:24 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 02:41:43 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Zheng", "Xiawu", ""], ["Ji", "Rongrong", ""], ["Tang", "Lang", ""], ["Zhang", "Baochang", ""], ["Liu", "Jianzhuang", ""], ["Tian", "Qi", ""]]}, {"id": "1905.07540", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Seungjin Choi", "title": "Practical Bayesian Optimization with Threshold-Guided Marginal\n  Likelihood Maximization", "comments": "8 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical Bayesian optimization method using Gaussian process\nregression, of which the marginal likelihood is maximized where the number of\nmodel selection steps is guided by a pre-defined threshold. Since Bayesian\noptimization consumes a large portion of its execution time in finding the\noptimal free parameters for Gaussian process regression, our simple, but\nstraightforward method is able to mitigate the time complexity and speed up the\noverall Bayesian optimization procedure. Finally, the experimental results show\nthat our method is effective to reduce the execution time in most of cases,\nwith less loss of optimization quality.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 05:52:57 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 07:39:40 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kim", "Jungtaek", ""], ["Choi", "Seungjin", ""]]}, {"id": "1905.07558", "submitter": "Arnaud Joly", "authors": "Arnaud Joly, Louis Wehenkel and Pierre Geurts", "title": "Gradient tree boosting with random output projections for multi-label\n  classification and multi-output regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of supervised learning, multiple classification or\nregression outputs have to be predicted jointly. We consider several extensions\nof gradient boosting to address such problems. We first propose a\nstraightforward adaptation of gradient boosting exploiting multiple output\nregression trees as base learners. We then argue that this method is only\nexpected to be optimal when the outputs are fully correlated, as it forces the\npartitioning induced by the tree base learners to be shared by all outputs. We\nthen propose a novel extension of gradient tree boosting to specifically\naddress this issue. At each iteration of this new method, a regression tree\nstructure is grown to fit a single random projection of the current residuals\nand the predictions of this tree are fitted linearly to the current residuals\nof all the outputs, independently. Because of this linear fit, the method can\nadapt automatically to any output correlation structure. Extensive experiments\nare conducted with this method, as well as other algorithmic variants, on\nseveral artificial and real problems. Randomly projecting the output space is\nshown to provide a better adaptation to different output correlation patterns\nand is therefore competitive with the best of the other methods in most\nsettings. Thanks to model sharing, the convergence speed is also improved,\nreducing the computing times (or the complexity of the model) to reach a\nspecific accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 08:59:23 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Joly", "Arnaud", ""], ["Wehenkel", "Louis", ""], ["Geurts", "Pierre", ""]]}, {"id": "1905.07570", "submitter": "Xiaoshuang Chen", "authors": "Xiaoshuang Chen, Yin Zheng, Jiaxing Wang, Wenye Ma, Junzhou Huang", "title": "RaFM: Rank-Aware Factorization Machines", "comments": "9 pages, 4 figures, accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization machines (FM) are a popular model class to learn pairwise\ninteractions by a low-rank approximation. Different from existing FM-based\napproaches which use a fixed rank for all features, this paper proposes a\nRank-Aware FM (RaFM) model which adopts pairwise interactions from embeddings\nwith different ranks. The proposed model achieves a better performance on\nreal-world datasets where different features have significantly varying\nfrequencies of occurrences. Moreover, we prove that the RaFM model can be\nstored, evaluated, and trained as efficiently as one single FM, and under some\nreasonable conditions it can be even significantly more efficient than FM. RaFM\nimproves the performance of FMs in both regression tasks and classification\ntasks while incurring less computational burden, therefore also has attractive\npotential in industrial applications.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 10:03:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chen", "Xiaoshuang", ""], ["Zheng", "Yin", ""], ["Wang", "Jiaxing", ""], ["Ma", "Wenye", ""], ["Huang", "Junzhou", ""]]}, {"id": "1905.07573", "submitter": "Sherif Saad", "authors": "Sherif Saad, William Briguglio and Haytham Elmiligi", "title": "The Curious Case of Machine Learning In Malware Detection", "comments": "9 pages", "journal-ref": "5th International Conference on Information Systems Security and\n  Privacy, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that machine learning techniques are not ready for\nmalware detection in the wild. Given the current trend in malware development\nand the increase of unconventional malware attacks, we expect that dynamic\nmalware analysis is the future for antimalware detection and prevention\nsystems. A comprehensive review of machine learning for malware detection is\npresented. Then, we discuss how malware detection in the wild present unique\nchallenges for the current state-of-the-art machine learning techniques. We\ndefined three critical problems that limit the success of malware detectors\npowered by machine learning in the wild. Next, we discuss possible solutions to\nthese challenges and present the requirements of next-generation malware\ndetection. Finally, we outline potential research directions in machine\nlearning for malware detection.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 10:34:36 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Saad", "Sherif", ""], ["Briguglio", "William", ""], ["Elmiligi", "Haytham", ""]]}, {"id": "1905.07579", "submitter": "Francesco Sovrano", "authors": "Francesco Sovrano", "title": "Combining Experience Replay with Exploration by Random Network\n  Distillation", "comments": "8 pages, 6 figures, accepted as full-paper at IEEE Conference on\n  Games (CoG) 2019", "journal-ref": null, "doi": "10.1109/CIG.2019.8848046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is a simple extension of the paper \"Exploration by Random Network\nDistillation\". More in detail, we show how to efficiently combine Intrinsic\nRewards with Experience Replay in order to achieve more efficient and robust\nexploration (with respect to PPO/RND) and consequently better results in terms\nof agent performances and sample efficiency. We are able to do it by using a\nnew technique named Prioritized Oversampled Experience Replay (POER), that has\nbeen built upon the definition of what is the important experience useful to\nreplay. Finally, we evaluate our technique on the famous Atari game Montezuma's\nRevenge and some other hard exploration Atari games.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 12:32:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sovrano", "Francesco", ""]]}, {"id": "1905.07581", "submitter": "Shangeth Rajaa", "authors": "Shangeth Rajaa, Jajati Keshari Sahoo", "title": "Convolutional Feature Extraction and Neural Arithmetic Logic Units for\n  Stock Prediction", "comments": "Accepted at ICACDS 2019 - Springer CCIS", "journal-ref": null, "doi": "10.1007/978-981-13-9939-8_31", "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stock prediction is a topic undergoing intense study for many years. Finance\nexperts and mathematicians have been working on a way to predict the future\nstock price so as to decide to buy the stock or sell it to make profit. Stock\nexperts or economists, usually analyze on the previous stock values using\ntechnical indicators, sentiment analysis etc to predict the future stock price.\nIn recent years, many researches have extensively used machine learning for\npredicting the stock behaviour. In this paper we propose data driven deep\nlearning approach to predict the future stock value with the previous price\nwith the feature extraction property of convolutional neural network and to use\nNeural Arithmetic Logic Units with it.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:01:46 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rajaa", "Shangeth", ""], ["Sahoo", "Jajati Keshari", ""]]}, {"id": "1905.07619", "submitter": "Samuel Otto", "authors": "Samuel E. Otto and Clarence W. Rowley", "title": "A Discrete Empirical Interpolation Method for Interpretable Immersion\n  and Embedding of Nonlinear Manifolds", "comments": "Minor typos corrected in version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning techniques seek to discover structure-preserving mappings\nof high-dimensional data into low-dimensional spaces.\n  While the new sets of coordinates specified by these mappings can closely\nparameterize the data, they are generally complicated nonlinear functions of\nthe original variables. This makes them difficult to interpret physically.\n  Furthermore, in data-driven model reduction applications the governing\nequations may have structure that is destroyed by nonlinear mapping into\ncoordinates on an inertial manifold, creating a computational bottleneck for\nsimulations.\n  Instead, we propose to identify a small collection of the original variables\nwhich are capable of uniquely determining all others either locally via\nimmersion or globally via embedding of the underlying manifold.\n  When the data lies on a low-dimensional subspace the existing discrete\nempirical interpolation method (DEIM) accomplishes this with recent variants\nemploying greedy algorithms based on pivoted QR (PQR) factorizations.\n  However, low-dimensional manifolds coming from a variety of applications,\nparticularly from advection-dominated PDEs, do not lie in or near any\nlow-dimensional subspace.\n  Our proposed approach extends DEIM to data lying near nonlinear manifolds by\napplying a similar pivoted QR procedure simultaneously on collections of\npatches making up locally linear approximations of the manifold, resulting in a\nnovel simultaneously pivoted QR (SimPQR) algorithm.\n  The immersion provided by SimPQR can be extended to an embedding by applying\nSimPQR a second time to a modified collection of vectors.\n  The SimPQR method for computing these `nonlinear DEIM' (NLDEIM) coordinates\nis successfully applied to real-world data lying near an inertial manifold in a\ncylinder wake flow as well as data coming from a viscous Burgers equation with\ndifferent initial conditions.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 18:05:48 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 15:43:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Otto", "Samuel E.", ""], ["Rowley", "Clarence W.", ""]]}, {"id": "1905.07624", "submitter": "Hessam Sokooti", "authors": "Hessam Sokooti, Gorkem Saygili, Ben Glocker, Boudewijn P.F.\n  Lelieveldt, Marius Staring", "title": "Quantitative Error Prediction of Medical Image Registration using\n  Regression Forests", "comments": null, "journal-ref": "Medical Image Analysis, 2019, ISSN 1361-8415", "doi": "10.1016/j.media.2019.05.005", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting registration error can be useful for evaluation of registration\nprocedures, which is important for the adoption of registration techniques in\nthe clinic. In addition, quantitative error prediction can be helpful in\nimproving the registration quality. The task of predicting registration error\nis demanding due to the lack of a ground truth in medical images. This paper\nproposes a new automatic method to predict the registration error in a\nquantitative manner, and is applied to chest CT scans. A random regression\nforest is utilized to predict the registration error locally. The forest is\nbuilt with features related to the transformation model and features related to\nthe dissimilarity after registration. The forest is trained and tested using\nmanually annotated corresponding points between pairs of chest CT scans in two\nexperiments: SPREAD (trained and tested on SPREAD) and inter-database\n(including three databases SPREAD, DIR-Lab-4DCT and DIR-Lab-COPDgene). The\nresults show that the mean absolute errors of regression are 1.07 $\\pm$ 1.86\nand 1.76 $\\pm$ 2.59 mm for the SPREAD and inter-database experiment,\nrespectively. The overall accuracy of classification in three classes (correct,\npoor and wrong registration) is 90.7% and 75.4%, for SPREAD and inter-database\nrespectively. The good performance of the proposed method enables important\napplications such as automatic quality control in large-scale image analysis.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 18:46:59 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Sokooti", "Hessam", ""], ["Saygili", "Gorkem", ""], ["Glocker", "Ben", ""], ["Lelieveldt", "Boudewijn P. F.", ""], ["Staring", "Marius", ""]]}, {"id": "1905.07628", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust and Anthony Francis and Dar Mehta", "title": "Evolving Rewards to Automate Reinforcement Learning", "comments": "Accepted to 6th AutoML@ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many continuous control tasks have easily formulated objectives, yet using\nthem directly as a reward in reinforcement learning (RL) leads to suboptimal\npolicies. Therefore, many classical control tasks guide RL training using\ncomplex rewards, which require tedious hand-tuning. We automate the reward\nsearch with AutoRL, an evolutionary layer over standard RL that treats reward\ntuning as hyperparameter optimization and trains a population of RL agents to\nfind a reward that maximizes the task objective. AutoRL, evaluated on four\nMujoco continuous control tasks over two RL algorithms, shows improvements over\nbaselines, with the the biggest uplift for more complex tasks. The video can be\nfound at: \\url{https://youtu.be/svdaOFfQyC8}.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 19:20:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Faust", "Aleksandra", ""], ["Francis", "Anthony", ""], ["Mehta", "Dar", ""]]}, {"id": "1905.07631", "submitter": "Chandan Singh", "authors": "Summer Devlin, Chandan Singh, W. James Murdoch, Bin Yu", "title": "Disentangled Attribution Curves for Interpreting Random Forests and\n  Boosted Trees", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tree ensembles, such as random forests and AdaBoost, are ubiquitous machine\nlearning models known for achieving strong predictive performance across a wide\nvariety of domains. However, this strong performance comes at the cost of\ninterpretability (i.e. users are unable to understand the relationships a\ntrained random forest has learned and why it is making its predictions). In\nparticular, it is challenging to understand how the contribution of a\nparticular feature, or group of features, varies as their value changes. To\naddress this, we introduce Disentangled Attribution Curves (DAC), a method to\nprovide interpretations of tree ensemble methods in the form of (multivariate)\nfeature importance curves. For a given variable, or group of variables, DAC\nplots the importance of a variable(s) as their value changes. We validate DAC\non real data by showing that the curves can be used to increase the accuracy of\nlogistic regression while maintaining interpretability, by including DAC as an\nadditional feature. In simulation studies, DAC is shown to out-perform\ncompeting methods in the recovery of conditional expectations. Finally, through\na case-study on the bike-sharing dataset, we demonstrate the use of DAC to\nuncover novel insights into a dataset.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 19:46:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Devlin", "Summer", ""], ["Singh", "Chandan", ""], ["Murdoch", "W. James", ""], ["Yu", "Bin", ""]]}, {"id": "1905.07645", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Lawrence Carin", "title": "Scalable Gromov-Wasserstein Learning for Graph Partitioning and Matching", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable Gromov-Wasserstein learning (S-GWL) method and\nestablish a novel and theoretically-supported paradigm for large-scale graph\nanalysis. The proposed method is based on the fact that Gromov-Wasserstein\ndiscrepancy is a pseudometric on graphs. Given two graphs, the optimal\ntransport associated with their Gromov-Wasserstein discrepancy provides the\ncorrespondence between their nodes and achieves graph matching. When one of the\ngraphs has isolated but self-connected nodes ($i.e.$, a disconnected graph),\nthe optimal transport indicates the clustering structure of the other graph and\nachieves graph partitioning. Using this concept, we extend our method to\nmulti-graph partitioning and matching by learning a Gromov-Wasserstein\nbarycenter graph for multiple observed graphs; the barycenter graph plays the\nrole of the disconnected graph, and since it is learned, so is the clustering.\nOur method combines a recursive $K$-partition mechanism with a regularized\nproximal gradient algorithm, whose time complexity is $\\mathcal{O}(K(E+V)\\log_K\nV)$ for graphs with $V$ nodes and $E$ edges. To our knowledge, our method is\nthe first attempt to make Gromov-Wasserstein discrepancy applicable to\nlarge-scale graph analysis and unify graph partitioning and matching into the\nsame framework. It outperforms state-of-the-art graph partitioning and matching\nmethods, achieving a trade-off between accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 20:55:42 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 16:21:02 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 03:51:17 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 17:37:12 GMT"}, {"version": "v5", "created": "Wed, 9 Oct 2019 14:53:25 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1905.07653", "submitter": "Yonghae Kim", "authors": "Yonghae Kim, Hyesoon Kim", "title": "A Case Study: Exploiting Neural Machine Translation to Translate CUDA to\n  OpenCL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequence-to-sequence (seq2seq) model for neural machine translation has\nsignificantly improved the accuracy of language translation. There have been\nnew efforts to use this seq2seq model for program language translation or\nprogram comparisons. In this work, we present the detailed steps of using a\nseq2seq model to translate CUDA programs to OpenCL programs, which both have\nvery similar programming styles. Our work shows (i) a training input set\ngeneration method, (ii) pre/post processing, and (iii) a case study using\nPolybench-gpu-1.0, NVIDIA SDK, and Rodinia benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 22:12:42 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kim", "Yonghae", ""], ["Kim", "Hyesoon", ""]]}, {"id": "1905.07659", "submitter": "Avleen S. Bijral", "authors": "Avleen S. Bijral", "title": "On Selecting Stable Predictors in Time Series Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the feature selection methodology to dependent data and propose a\nnovel time series predictor selection scheme that accommodates statistical\ndependence in a more typical i.i.d sub-sampling based framework. Furthermore,\nthe machinery of mixing stationary processes allows us to quantify the\nimprovements of our approach over any base predictor selection method (such as\nlasso) even in a finite sample setting. Using the lasso as a base procedure we\ndemonstrate the applicability of our methods to simulated and several real time\nseries datasets.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 23:45:32 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Bijral", "Avleen S.", ""]]}, {"id": "1905.07672", "submitter": "Fu Song", "authors": "Lei Bu, Yuchao Duan, Fu Song, Zhe Zhao", "title": "Taking Care of The Discretization Problem: A Comprehensive Study of the\n  Discretization Problem and A Black-Box Adversarial Attack in Discrete Integer\n  Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous methods for crafting adversarial examples were proposed recently\nwith high success rate. Since most existing machine learning based classifiers\nnormalize images into some continuous, real vector, domain firstly, attacks\noften craft adversarial examples in such domain. However, \"adversarial\"\nexamples may become benign after denormalizing them back into the discrete\ninteger domain, known as the discretization problem. This problem was mentioned\nin some work, but has received relatively little attention.\n  In this work, we first conduct a comprehensive study of existing methods and\ntools for crafting. We theoretically analyze 34 representative methods and\nempirically study 20 representative open source tools for crafting adversarial\nimages. Our study reveals that the discretization problem is far more serious\nthan originally thought. This suggests that the discretization problem should\nbe taken into account seriously when crafting adversarial examples and\nmeasuring attack success rate. As a first step towards addressing this problem\nin black-box scenario, we propose a black-box method which reduces the\nadversarial example searching problem to a derivative-free optimization\nproblem. Our method is able to craft adversarial images by derivative-free\nsearch in the discrete integer domain. Experimental results show that our\nmethod is comparable to recent white-box methods (e.g., FGSM, BIM and C\\&W) and\nachieves significantly higher success rate in terms of adversarial examples in\nthe discrete integer domain than recent black-box methods (e.g., ZOO, NES-PGD\nand Bandits). Moreover, our method is able to handle models that is\nnon-differentiable and successfully break the winner of NIPS 2017 competition\non defense with 95\\% success rate. Our results suggest that discrete\noptimization algorithms open up a promising area of research into effective\nblack-box attacks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 02:12:13 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 16:23:27 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 04:29:19 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 15:02:00 GMT"}, {"version": "v5", "created": "Sun, 26 Apr 2020 06:38:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bu", "Lei", ""], ["Duan", "Yuchao", ""], ["Song", "Fu", ""], ["Zhao", "Zhe", ""]]}, {"id": "1905.07679", "submitter": "Sina Mohseni", "authors": "Sina Mohseni and Akshay Jagadeesh and Zhangyang Wang", "title": "Predicting Model Failure using Saliency Maps in Autonomous Driving\n  Systems", "comments": "Presented at ICML 2019 Workshop on Uncertainty and Robustness in Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning systems show high success rate in many complex tasks,\nresearch shows they can also fail in very unexpected situations. Rise of\nmachine learning products in safety-critical industries cause an increase in\nattention in evaluating model robustness and estimating failure probability in\nmachine learning systems. In this work, we propose a design to train a student\nmodel -- a failure predictor -- to predict the main model's error for input\ninstances based on their saliency map. We implement and review the preliminary\nresults of our failure predictor model on an autonomous vehicle steering\ncontrol system as an example of safety-critical applications.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 03:16:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Mohseni", "Sina", ""], ["Jagadeesh", "Akshay", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1905.07685", "submitter": "Pedram Rooshenas", "authors": "MohamadAli Torkamani, Phillip Wallis, Shiv Shankar, Amirmohammad\n  Rooshenas", "title": "Learning Compact Neural Networks Using Ordinary Differential Equations\n  as Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep neural networks use simple, fixed activation functions, such as\nsigmoids or rectified linear units, regardless of domain or network structure.\nWe introduce differential equation units (DEUs), an improvement to modern\nneural networks, which enables each neuron to learn a particular nonlinear\nactivation function from a family of solutions to an ordinary differential\nequation. Specifically, each neuron may change its functional form during\ntraining based on the behavior of the other parts of the network. We show that\nusing neurons with DEU activation functions results in a more compact network\ncapable of achieving comparable, if not superior, performance when is compared\nto much larger networks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 03:49:52 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Torkamani", "MohamadAli", ""], ["Wallis", "Phillip", ""], ["Shankar", "Shiv", ""], ["Rooshenas", "Amirmohammad", ""]]}, {"id": "1905.07686", "submitter": "Raghu Raj", "authors": "Raghu G. Raj", "title": "An Online Stochastic Kernel Machine for Robust Signal Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel variation of online kernel machines in which we exploit a\nconsensus based optimization mechanism to guide the evolution of decision\nfunctions drawn from a reproducing kernel Hilbert space, which efficiently\nmodels the observed stationary process.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 03:59:29 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 20:00:53 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Raj", "Raghu G.", ""]]}, {"id": "1905.07697", "submitter": "Amit Sharma", "authors": "Ramaravind Kommiya Mothilal, Amit Sharma, Chenhao Tan", "title": "Explaining Machine Learning Classifiers through Diverse Counterfactual\n  Explanations", "comments": "13 pages", "journal-ref": "Conference on Fairness, Accountability, and Transparency (FAT*\n  2020)", "doi": "10.1145/3351095.3372850", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanations of machine learning models are crucial for people to\nunderstand and act on algorithmic predictions. An intriguing class of\nexplanations is through counterfactuals, hypothetical examples that show people\nhow to obtain a different prediction. We posit that effective counterfactual\nexplanations should satisfy two properties: feasibility of the counterfactual\nactions given user context and constraints, and diversity among the\ncounterfactuals presented. To this end, we propose a framework for generating\nand evaluating a diverse set of counterfactual explanations based on\ndeterminantal point processes. To evaluate the actionability of\ncounterfactuals, we provide metrics that enable comparison of\ncounterfactual-based methods to other local explanation methods. We further\naddress necessary tradeoffs and point to causal implications in optimizing for\ncounterfactuals. Our experiments on four real-world datasets show that our\nframework can generate a set of counterfactuals that are diverse and well\napproximate local decision boundaries, outperforming prior approaches to\ngenerating diverse counterfactuals. We provide an implementation of the\nframework at https://github.com/microsoft/DiCE.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:23:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 12:26:41 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mothilal", "Ramaravind Kommiya", ""], ["Sharma", "Amit", ""], ["Tan", "Chenhao", ""]]}, {"id": "1905.07720", "submitter": "Feng Liu", "authors": "Feng Liu, Jie Lu, Bo Han, Gang Niu, Guangquan Zhang, Masashi Sugiyama", "title": "Butterfly: One-step Approach towards Wildly Unsupervised Domain\n  Adaptation", "comments": "Previous version of this paper has been accepted by the NeurIPS2019\n  Workshop on Learning Transferable Skills\n  (https://www.skillsworkshop.ai/schedule.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In unsupervised domain adaptation (UDA), classifiers for the target domain\n(TD) are trained with clean labeled data from the source domain (SD) and\nunlabeled data from TD. However, in the wild, it is difficult to acquire a\nlarge amount of perfectly clean labeled data in SD given limited budget. Hence,\nwe consider a new, more realistic and more challenging problem setting, where\nclassifiers have to be trained with noisy labeled data from SD and unlabeled\ndata from TD -- we name it wildly UDA (WUDA). We show that WUDA ruins all UDA\nmethods if taking no care of label noise in SD, and to this end, we propose a\nButterfly framework, a powerful and efficient solution to WUDA. Butterfly\nmaintains four deep networks simultaneously, where two take care of all\nadaptations (i.e., noisy-to-clean, labeled-to-unlabeled, and\nSD-to-TD-distributional) and then the other two can focus on classification in\nTD. As a consequence, Butterfly possesses all the conceptually necessary\ncomponents for solving WUDA. Experiments demonstrate that, under WUDA,\nButterfly significantly outperforms existing baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 10:25:32 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:19:22 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 02:53:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Liu", "Feng", ""], ["Lu", "Jie", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Zhang", "Guangquan", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1905.07726", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, George C. Alexandropoulos, Chau Yuen, and M\\'erouane\n  Debbah", "title": "Indoor Signal Focusing with Deep Learning Designed Reconfigurable\n  Intelligent Surfaces", "comments": "5 pages, Accepted by SPAWC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable Intelligent Surfaces (RISs) comprised of tunable unit elements\nhave been recently considered in indoor communication environments for focusing\nsignal reflections to intended user locations. However, the current proofs of\nconcept require complex operations for the RIS configuration, which are mainly\nrealized via wired control connections. In this paper, we present a deep\nlearning method for efficient online wireless configuration of RISs when\ndeployed in indoor communication environments. According to the proposed\nmethod, a database of coordinate fingerprints is implemented during an offline\ntraining phase. This fingerprinting database is used to train the weights and\nbias of a properly designed Deep Neural Network (DNN), whose role is to unveil\nthe mapping between the measured coordinate information at a user location and\nthe configuration of the RIS's unit cells that maximizes this user's received\nsignal strength. During the online phase of the presented method, the trained\nDNN is fed with the measured position information at the target user to output\nthe optimal phase configurations of the RIS for signal power focusing on this\nintended location. Our realistic simulation results using ray tracing on a\nthree dimensional indoor environment demonstrate that the proposed DNN-based\nconfiguration method exhibits its merits for all considered cases, and\neffectively increases the achievable throughput at the target user location.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 11:24:43 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Huang", "Chongwen", ""], ["Alexandropoulos", "George C.", ""], ["Yuen", "Chau", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1905.07727", "submitter": "Mehran Attar", "authors": "Mehran Attar, and Mohammadreza Dabirian", "title": "Reinforcement Learning for Learning of Dynamical Systems in Uncertain\n  Environment: a Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a review of model-free reinforcement learning for learning of\ndynamical systems in uncertain environments has discussed. For this purpose,\nthe Markov Decision Process (MDP) will be reviewed. Furthermore, some learning\nalgorithms such as Temporal Difference (TD) learning, Q-Learning, and\nApproximate Q-learning as model-free algorithms which constitute the main part\nof this article have been investigated, and benefits and drawbacks of each\nalgorithm will be discussed. The discussed concepts in each section are\nexplaining with details and examples.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 11:29:01 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Attar", "Mehran", ""], ["Dabirian", "Mohammadreza", ""]]}, {"id": "1905.07733", "submitter": "Thomas Brunner", "authors": "Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll", "title": "Leveraging Semantic Embeddings for Safety-Critical Applications", "comments": "Accepted at CVPR 2019 Workshop: Safe Artificial Intelligence for\n  Automated Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Embeddings are a popular way to represent knowledge in the field of\nzero-shot learning. We observe their interpretability and discuss their\npotential utility in a safety-critical context. Concretely, we propose to use\nthem to add introspection and error detection capabilities to neural network\nclassifiers. First, we show how to create embeddings from symbolic domain\nknowledge. We discuss how to use them for interpreting mispredictions and\npropose a simple error detection scheme. We then introduce the concept of\nsemantic distance: a real-valued score that measures confidence in the semantic\nspace. We evaluate this score on a traffic sign classifier and find that it\nachieves near state-of-the-art performance, while being significantly faster to\ncompute than other confidence scores. Our approach requires no changes to the\noriginal network and is thus applicable to any task for which domain knowledge\nis available.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 12:42:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Brunner", "Thomas", ""], ["Diehl", "Frederik", ""], ["Le", "Michael Truong", ""], ["Knoll", "Alois", ""]]}, {"id": "1905.07754", "submitter": "Fredrik Vatsendvik", "authors": "{\\AA}smund Brekke, Fredrik Vatsendvik, Frank Lindseth", "title": "Multimodal 3D Object Detection from Simulated Pretraining", "comments": "12 pages, part of proceedings for the NAIS 2019 symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for simulated data in autonomous driving applications has become\nincreasingly important, both for validation of pretrained models and for\ntraining new models. In order for these models to generalize to real-world\napplications, it is critical that the underlying dataset contains a variety of\ndriving scenarios and that simulated sensor readings closely mimics real-world\nsensors. We present the Carla Automated Dataset Extraction Tool (CADET), a\nnovel tool for generating training data from the CARLA simulator to be used in\nautonomous driving research. The tool is able to export high-quality,\nsynchronized LIDAR and camera data with object annotations, and offers\nconfiguration to accurately reflect a real-life sensor array. Furthermore, we\nuse this tool to generate a dataset consisting of 10 000 samples and use this\ndataset in order to train the 3D object detection network AVOD-FPN, with\nfinetuning on the KITTI dataset in order to evaluate the potential for\neffective pretraining. We also present two novel LIDAR feature map\nconfigurations in Bird's Eye View for use with AVOD-FPN that can be easily\nmodified. These configurations are tested on the KITTI and CADET datasets in\norder to evaluate their performance as well as the usability of the simulated\ndataset for pretraining. Although insufficient to fully replace the use of real\nworld data, and generally not able to exceed the performance of systems fully\ntrained on real data, our results indicate that simulated data can considerably\nreduce the amount of training on real data required to achieve satisfactory\nlevels of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 15:13:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Brekke", "\u00c5smund", ""], ["Vatsendvik", "Fredrik", ""], ["Lindseth", "Frank", ""]]}, {"id": "1905.07773", "submitter": "Aviv Rosenberg", "authors": "Aviv Rosenberg and Yishay Mansour", "title": "Online Convex Optimization in Adversarial Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning in episodic loop-free Markov decision processes\n(MDPs), where the loss function can change arbitrarily between episodes, and\nthe transition function is not known to the learner. We show\n$\\tilde{O}(L|X|\\sqrt{|A|T})$ regret bound, where $T$ is the number of episodes,\n$X$ is the state space, $A$ is the action space, and $L$ is the length of each\nepisode. Our online algorithm is implemented using entropic regularization\nmethodology, which allows to extend the original adversarial MDP model to\nhandle convex performance criteria (different ways to aggregate the losses of a\nsingle episode) , as well as improve previous regret bounds.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:56:22 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Rosenberg", "Aviv", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.07777", "submitter": "Zhiqin Xu", "authors": "Yaoyu Zhang, Zhi-Qin John Xu, Tao Luo, Zheng Ma", "title": "A type of generalization error induced by initialization in deep neural\n  networks", "comments": "Accepted by MSML Revised the proof of Lemma 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How initialization and loss function affect the learning of a deep neural\nnetwork (DNN), specifically its generalization error, is an important problem\nin practice. In this work, by exploiting the linearity of DNN training dynamics\nin the NTK regime \\citep{jacot2018neural,lee2019wide}, we provide an explicit\nand quantitative answer to this problem. Focusing on regression problem, we\nprove that, in the NTK regime, for any loss in a general class of functions,\nthe DNN finds the same \\emph{global} minima---the one that is nearest to the\ninitial value in the parameter space, or equivalently, the one that is closest\nto the initial DNN output in the corresponding reproducing kernel Hilbert\nspace. Using these optimization problems, we quantify the impact of initial\noutput and prove that a random non-zero one increases the generalization error.\nWe further propose an antisymmetrical initialization (ASI) trick that\neliminates this type of error and accelerates the training. To understand\nwhether the above results hold in general, we also perform experiments for DNNs\nin the non-NTK regime, which demonstrate the effectiveness of our theoretical\nresults and the ASI trick in a qualitative sense. Overall, our work serves as a\nbaseline for the further investigation of the impact of initialization and loss\nfunction on the generalization of DNNs, which can potentially guide and improve\nthe training of DNNs in practice.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:11:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 13:52:46 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 09:54:18 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhang", "Yaoyu", ""], ["Xu", "Zhi-Qin John", ""], ["Luo", "Tao", ""], ["Ma", "Zheng", ""]]}, {"id": "1905.07785", "submitter": "Rahul Mehta", "authors": "Rahul Mehta", "title": "Sparse Transfer Learning via Winning Lottery Tickets", "comments": "15 pages, 9 figures. Workshop on Learning Transferable Skills, 33rd\n  Conference on Neural Information Processing Systems, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recently proposed Lottery Ticket Hypothesis of Frankle and Carbin (2019)\nsuggests that the performance of over-parameterized deep networks is due to the\nrandom initialization seeding the network with a small fraction of favorable\nweights. These weights retain their dominant status throughout training -- in a\nvery real sense, this sub-network \"won the lottery\" during initialization. The\nauthors find sub-networks via unstructured magnitude pruning with 85-95% of\nparameters removed that train to the same accuracy as the original network at a\nsimilar speed, which they call winning tickets. In this paper, we extend the\nLottery Ticket Hypothesis to a variety of transfer learning tasks. We show that\nsparse sub-networks with approximately 90-95% of weights removed achieve (and\noften exceed) the accuracy of the original dense network in several realistic\nsettings. We experimentally validate this by transferring the sparse\nrepresentation found via pruning on CIFAR-10 to SmallNORB and FashionMNIST for\nobject recognition tasks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:48:29 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 21:17:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mehta", "Rahul", ""]]}, {"id": "1905.07790", "submitter": "Vitalii Zhelezniak", "authors": "Vitalii Zhelezniak, Aleksandar Savkov, April Shen, Nils Y. Hammerla", "title": "Correlation Coefficients and Semantic Textual Similarity", "comments": "Accepted as a long paper at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of research into semantic textual similarity has focused on\nconstructing state-of-the-art embeddings using sophisticated modelling, careful\nchoice of learning signals and many clever tricks. By contrast, little\nattention has been devoted to similarity measures between these embeddings,\nwith cosine similarity being used unquestionably in the majority of cases. In\nthis work, we illustrate that for all common word vectors, cosine similarity is\nessentially equivalent to the Pearson correlation coefficient, which provides\nsome justification for its use. We thoroughly characterise cases where Pearson\ncorrelation (and thus cosine similarity) is unfit as similarity measure.\nImportantly, we show that Pearson correlation is appropriate for some word\nvectors but not others. When it is not appropriate, we illustrate how common\nnon-parametric rank correlation coefficients can be used instead to\nsignificantly improve performance. We support our analysis with a series of\nevaluations on word-level and sentence-level semantic textual similarity\nbenchmarks. On the latter, we show that even the simplest averaged word vectors\ncompared by rank correlation easily rival the strongest deep representations\ncompared by cosine similarity.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 18:23:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Savkov", "Aleksandar", ""], ["Shen", "April", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1905.07799", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, Armand Joulin", "title": "Adaptive Attention Span in Transformers", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel self-attention mechanism that can learn its optimal\nattention span. This allows us to extend significantly the maximum context size\nused in Transformer, while maintaining control over their memory footprint and\ncomputational time. We show the effectiveness of our approach on the task of\ncharacter level language modeling, where we achieve state-of-the-art\nperformances on text8 and enwiki8 by using a maximum context of 8k characters.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 19:43:14 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 06:58:31 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Joulin", "Armand", ""]]}, {"id": "1905.07817", "submitter": "Shehroz Khan", "authors": "Shehroz S. Khan, Jacob Nogas, Alex Mihailidis", "title": "Spatio-Temporal Adversarial Learning for Detecting Unseen Falls", "comments": "17 pages, 10 figures, 4 tables, 39 references", "journal-ref": "Pattern Analysis and Applications, 2020", "doi": "10.1007/s10044-020-00901-9", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fall detection is an important problem from both the health and machine\nlearning perspective. A fall can lead to severe injuries, long term impairments\nor even death in some cases. In terms of machine learning, it presents a\nseverely class imbalance problem with very few or no training data for falls\nowing to the fact that falls occur rarely. In this paper, we take an alternate\nphilosophy to detect falls in the absence of their training data, by training\nthe classifier on only the normal activities (that are available in abundance)\nand identifying a fall as an anomaly. To realize such a classifier, we use an\nadversarial learning framework, which comprises of a spatio-temporal\nautoencoder for reconstructing input video frames and a spatio-temporal\nconvolution network to discriminate them against original video frames. 3D\nconvolutions are used to learn spatial and temporal features from the input\nvideo frames. The adversarial learning of the spatio-temporal autoencoder will\nenable reconstructing the normal activities of daily living efficiently; thus,\nrendering detecting unseen falls plausible within this framework. We tested the\nperformance of the proposed framework on camera sensing modalities that may\npreserve an individual's privacy (fully or partially), such as thermal and\ndepth camera. Our results on three publicly available datasets show that the\nproposed spatio-temporal adversarial framework performed better than other\nbaseline frame based (or spatial) adversarial learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 22:19:17 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:57:23 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Khan", "Shehroz S.", ""], ["Nogas", "Jacob", ""], ["Mihailidis", "Alex", ""]]}, {"id": "1905.07822", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic, G\\\"unther Koliander", "title": "Minimal Achievable Sufficient Statistic Learning", "comments": "Published in the International Conference on Machine Learning (ICML\n  2019), 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Minimal Achievable Sufficient Statistic (MASS) Learning, a\ntraining method for machine learning models that attempts to produce minimal\nsufficient statistics with respect to a class of functions (e.g. deep networks)\nbeing optimized over. In deriving MASS Learning, we also introduce Conserved\nDifferential Information (CDI), an information-theoretic quantity that - unlike\nstandard mutual information - can be usefully applied to\ndeterministically-dependent continuous random variables like the input and\noutput of a deep network. In a series of experiments, we show that deep\nnetworks trained with MASS Learning achieve competitive performance on\nsupervised learning and uncertainty quantification benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 22:46:23 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 19:22:43 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Cvitkovic", "Milan", ""], ["Koliander", "G\u00fcnther", ""]]}, {"id": "1905.07831", "submitter": "Yuchi Tian", "authors": "Yuchi Tian, Ziyuan Zhong, Vicente Ordonez, Gail Kaiser, Baishakhi Ray", "title": "Testing DNN Image Classifiers for Confusion & Bias Errors", "comments": null, "journal-ref": null, "doi": "10.1145/3377811.3380400", "report-no": null, "categories": "cs.SE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers are an important component of today's software, from\nconsumer and business applications to safety-critical domains. The advent of\nDeep Neural Networks (DNNs) is the key catalyst behind such wide-spread\nsuccess. However, wide adoption comes with serious concerns about the\nrobustness of software systems dependent on DNNs for image classification, as\nseveral severe erroneous behaviors have been reported under sensitive and\ncritical circumstances. We argue that developers need to rigorously test their\nsoftware's image classifiers and delay deployment until acceptable. We present\nan approach to testing image classifier robustness based on class property\nviolations.\n  We found that many of the reported erroneous cases in popular DNN image\nclassifiers occur because the trained models confuse one class with another or\nshow biases towards some classes over others. These bugs usually violate some\nclass properties of one or more of those classes. Most DNN testing techniques\nfocus on per-image violations, so fail to detect class-level confusions or\nbiases.\n  We developed a testing technique to automatically detect class-based\nconfusion and bias errors in DNN-driven image classification software. We\nevaluated our implementation, DeepInspect, on several popular image classifiers\nwith precision up to 100% (avg.~72.6%) for confusion errors, and up to 84.3%\n(avg.~66.8%) for bias errors. DeepInspect found hundreds of classification\nmistakes in widely-used models, many exposing errors indicating confusion or\nbias.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 00:00:24 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 23:02:13 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:32:09 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Tian", "Yuchi", ""], ["Zhong", "Ziyuan", ""], ["Ordonez", "Vicente", ""], ["Kaiser", "Gail", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1905.07833", "submitter": "Carlo Baldassi", "authors": "Carlo Baldassi, Fabrizio Pittorino, Riccardo Zecchina", "title": "Shaping the learning landscape in neural networks around wide flat\n  minima", "comments": "37 pages (16 main text), 10 figures (7 main text)", "journal-ref": "Proceedings of the National Academy of Sciences, 2020 Jan 7, 117\n  (1) 161-170", "doi": "10.1073/pnas.1908636117", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning in Deep Neural Networks (DNN) takes place by minimizing a non-convex\nhigh-dimensional loss function, typically by a stochastic gradient descent\n(SGD) strategy. The learning process is observed to be able to find good\nminimizers without getting stuck in local critical points, and that such\nminimizers are often satisfactory at avoiding overfitting. How these two\nfeatures can be kept under control in nonlinear devices composed of millions of\ntunable connections is a profound and far reaching open question. In this paper\nwe study basic non-convex one- and two-layer neural network models which learn\nrandom patterns, and derive a number of basic geometrical and algorithmic\nfeatures which suggest some answers. We first show that the error loss function\npresents few extremely wide flat minima (WFM) which coexist with narrower\nminima and critical points. We then show that the minimizers of the\ncross-entropy loss function overlap with the WFM of the error loss. We also\nshow examples of learning devices for which WFM do not exist. From the\nalgorithmic perspective we derive entropy driven greedy and message passing\nalgorithms which focus their search on wide flat regions of minimizers. In the\ncase of SGD and cross-entropy loss, we show that a slow reduction of the norm\nof the weights along the learning process also leads to WFM. We corroborate the\nresults by a numerical study of the correlations between the volumes of the\nminimizers, their Hessian and their generalization performance on real data.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 00:33:54 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 16:59:37 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 15:37:59 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 13:51:08 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Baldassi", "Carlo", ""], ["Pittorino", "Fabrizio", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1905.07835", "submitter": "Furao Shen", "authors": "Xu Zhang, Yang Yao, Baile Xu, Lekun Mao, Furao Shen, Jian Zhao, and\n  Qingwei Lin", "title": "Label Mapping Neural Networks with Response Consolidation for Class\n  Incremental Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class incremental learning refers to a special multi-class classification\ntask, in which the number of classes is not fixed but is increasing with the\ncontinual arrival of new data. Existing researches mainly focused on solving\ncatastrophic forgetting problem in class incremental learning. To this end,\nhowever, these models still require the old classes cached in the auxiliary\ndata structure or models, which is inefficient in space or time. In this paper,\nit is the first time to discuss the difficulty without support of old classes\nin class incremental learning, which is called as softmax suppression problem.\nTo address these challenges, we develop a new model named Label Mapping with\nResponse Consolidation (LMRC), which need not access the old classes anymore.\nWe propose the Label Mapping algorithm combined with the multi-head neural\nnetwork for mitigating the softmax suppression problem, and propose the\nResponse Consolidation method to overcome the catastrophic forgetting problem.\nExperimental results on the benchmark datasets show that our proposed method\nachieves much better performance compared to the related methods in different\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 01:10:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Xu", ""], ["Yao", "Yang", ""], ["Xu", "Baile", ""], ["Mao", "Lekun", ""], ["Shen", "Furao", ""], ["Zhao", "Jian", ""], ["Lin", "Qingwei", ""]]}, {"id": "1905.07845", "submitter": "Yang Kang", "authors": "Jose Blanchet, Yang Kang, Fan Zhang, and Zhangyi Hu", "title": "A Distributionally Robust Boosting Algorithm", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": "10.1109/WSC40007.2019.9004804", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally Robust Optimization (DRO) has been shown to provide a\nflexible framework for decision making under uncertainty and statistical\nestimation. For example, recent works in DRO have shown that popular\nstatistical estimators can be interpreted as the solutions of suitable\nformulated data-driven DRO problems. In turn, this connection is used to\noptimally select tuning parameters in terms of a principled approach informed\nby robustness considerations. This paper contributes to this growing\nliterature, connecting DRO and statistics, by showing how boosting algorithms\ncan be studied via DRO. We propose a boosting type algorithm, named\nDRO-Boosting, as a procedure to solve our DRO formulation. Our DRO-Boosting\nalgorithm recovers Adaptive Boosting (AdaBoost) in particular, thus showing\nthat AdaBoost is effectively solving a DRO problem. We apply our algorithm to a\nfinancial dataset on credit card default payment prediction. We find that our\napproach compares favorably to alternative boosting methods which are widely\nused in practice.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 02:06:55 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Blanchet", "Jose", ""], ["Kang", "Yang", ""], ["Zhang", "Fan", ""], ["Hu", "Zhangyi", ""]]}, {"id": "1905.07852", "submitter": "Evgeny Burnaev", "authors": "Alexey Bokhovkin and Evgeny Burnaev", "title": "Boundary Loss for Remote Sensing Imagery Semantic Segmentation", "comments": "14 pages, 10 figures", "journal-ref": "Proceedings of 16th International Symposium on Neural Networks,\n  2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the growing importance of geospatial data, its analysis\nincluding semantic segmentation becomes an increasingly popular task in\ncomputer vision today. Convolutional neural networks are powerful visual models\nthat yield hierarchies of features and practitioners widely use them to process\nremote sensing data. When performing remote sensing image segmentation,\nmultiple instances of one class with precisely defined boundaries are often the\ncase, and it is crucial to extract those boundaries accurately. The accuracy of\nsegments boundaries delineation influences the quality of the whole segmented\nareas explicitly. However, widely-used segmentation loss functions such as BCE,\nIoU loss or Dice loss do not penalize misalignment of boundaries sufficiently.\nIn this paper, we propose a novel loss function, namely a differentiable\nsurrogate of a metric accounting accuracy of boundary detection. We can use the\nloss function with any neural network for binary segmentation. We performed\nvalidation of our loss function with various modifications of UNet on a\nsynthetic dataset, as well as using real-world data (ISPRS Potsdam, INRIA AIL).\nTrained with the proposed loss function, models outperform baseline methods in\nterms of IoU score.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:02:44 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Bokhovkin", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.07853", "submitter": "Xingyu Liu", "authors": "Xingyu Liu, Joon-Young Lee, Hailin Jin", "title": "Learning Video Representations from Correspondence Proposals", "comments": "CVPR 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correspondences between frames encode rich information about dynamic content\nin videos. However, it is challenging to effectively capture and learn those\ndue to their irregular structure and complex dynamics. In this paper, we\npropose a novel neural network that learns video representations by aggregating\ninformation from potential correspondences. This network, named $CPNet$, can\nlearn evolving 2D fields with temporal consistency. In particular, it can\neffectively learn representations for videos by mixing appearance and\nlong-range motion with an RGB-only input. We provide extensive ablation\nexperiments to validate our model. CPNet shows stronger performance than\nexisting methods on Kinetics and achieves the state-of-the-art performance on\nSomething-Something and Jester. We provide analysis towards the behavior of our\nmodel and show its robustness to errors in proposals.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:07:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Liu", "Xingyu", ""], ["Lee", "Joon-Young", ""], ["Jin", "Hailin", ""]]}, {"id": "1905.07854", "submitter": "Xiang Wang", "authors": "Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua", "title": "KGAT: Knowledge Graph Attention Network for Recommendation", "comments": "KDD 2019 research track", "journal-ref": null, "doi": "10.1145/3292500.3330989", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide more accurate, diverse, and explainable recommendation, it is\ncompulsory to go beyond modeling user-item interactions and take side\ninformation into account. Traditional methods like factorization machine (FM)\ncast it as a supervised learning problem, which assumes each interaction as an\nindependent instance with side information encoded. Due to the overlook of the\nrelations among instances or items (e.g., the director of a movie is also an\nactor of another movie), these methods are insufficient to distill the\ncollaborative signal from the collective behaviors of users. In this work, we\ninvestigate the utility of knowledge graph (KG), which breaks down the\nindependent interaction assumption by linking items with their attributes. We\nargue that in such a hybrid structure of KG and user-item graph, high-order\nrelations --- which connect two items with one or multiple linked attributes\n--- are an essential factor for successful recommendation. We propose a new\nmethod named Knowledge Graph Attention Network (KGAT) which explicitly models\nthe high-order connectivities in KG in an end-to-end fashion. It recursively\npropagates the embeddings from a node's neighbors (which can be users, items,\nor attributes) to refine the node's embedding, and employs an attention\nmechanism to discriminate the importance of the neighbors. Our KGAT is\nconceptually advantageous to existing KG-based recommendation methods, which\neither exploit high-order relations by extracting paths or implicitly modeling\nthem with regularization. Empirical results on three public benchmarks show\nthat KGAT significantly outperforms state-of-the-art methods like Neural FM and\nRippleNet. Further studies verify the efficacy of embedding propagation for\nhigh-order relation modeling and the interpretability benefits brought by the\nattention mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:08:11 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 02:49:37 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Xiang", ""], ["He", "Xiangnan", ""], ["Cao", "Yixin", ""], ["Liu", "Meng", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1905.07855", "submitter": "Evgeny Burnaev", "authors": "Evgenii Egorov and Kirill Neklydov and Ruslan Kostoev and Evgeny\n  Burnaev", "title": "MaxEntropy Pursuit Variational Inference", "comments": "10 pages, 1 figure", "journal-ref": "16th International Symposium on Neural Networks, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core problems in variational inference is a choice of approximate\nposterior distribution. It is crucial to trade-off between efficient inference\nwith simple families as mean-field models and accuracy of inference. We propose\na variant of a greedy approximation of the posterior distribution with\ntractable base learners. Using Max-Entropy approach, we obtain a well-defined\noptimization problem. We demonstrate the ability of the method to capture\ncomplex multimodal posterior via continual learning setting for neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:12:32 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Egorov", "Evgenii", ""], ["Neklydov", "Kirill", ""], ["Kostoev", "Ruslan", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.07857", "submitter": "Shubham Sharma", "authors": "Shubham Sharma, Jette Henderson and Joydeep Ghosh", "title": "CERTIFAI: Counterfactual Explanations for Robustness, Transparency,\n  Interpretability, and Fairness of Artificial Intelligence models", "comments": null, "journal-ref": null, "doi": "10.1145/3375627.3375812", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence plays an increasingly important role in our\nsociety, there are ethical and moral obligations for both businesses and\nresearchers to ensure that their machine learning models are designed,\ndeployed, and maintained responsibly. These models need to be rigorously\naudited for fairness, robustness, transparency, and interpretability. A variety\nof methods have been developed that focus on these issues in isolation,\nhowever, managing these methods in conjunction with model development can be\ncumbersome and timeconsuming. In this paper, we introduce a unified and\nmodel-agnostic approach to address these issues: Counterfactual Explanations\nfor Robustness, Transparency, Interpretability, and Fairness of Artificial\nIntelligence models (CERTIFAI). Unlike previous methods in this domain,\nCERTIFAI is a general tool that can be applied to any black-box model and any\ntype of input data. Given a model and an input instance, CERTIFAI uses a custom\ngenetic algorithm to generate counterfactuals: instances close to the input\nthat change the prediction of the model. We demonstrate how these\ncounterfactuals can be used to examine issues of robustness, interpretability,\ntransparency, and fairness. Additionally, we introduce CERScore, the first\nblack-box model robustness score that performs comparably to methods that have\naccess to model internals.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:15:06 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Sharma", "Shubham", ""], ["Henderson", "Jette", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1905.07859", "submitter": "Evgeny Burnaev", "authors": "Oleg Sudakov and Dmitri Koroteev and Boris Belozerov and Evgeny\n  Burnaev", "title": "Artificial Neural Network Surrogate Modeling of Oil Reservoir: a Case\n  Study", "comments": "10 pages, 5 figures", "journal-ref": "16th International Symposium on Neural Networks, ISNN 2019", "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG physics.comp-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a data-driven model, introducing recent advances in machine\nlearning to reservoir simulation. We use a conventional reservoir modeling tool\nto generate training set and a special ensemble of artificial neural networks\n(ANNs) to build a predictive model. The ANN-based model allows to reproduce the\ntime dependence of fluids and pressure distribution within the computational\ncells of the reservoir model. We compare the performance of the ANN-based model\nwith conventional reservoir modeling and illustrate that ANN-based model (1) is\nable to capture all the output parameters of the conventional model with very\nhigh accuracy and (2) demonstrate much higher computational performance. We\nfinally elaborate on further options for research and developments within the\narea of reservoir modeling.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:34:47 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Sudakov", "Oleg", ""], ["Koroteev", "Dmitri", ""], ["Belozerov", "Boris", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.07861", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Charles L. Isbell", "title": "Perceptual Values from Observation", "comments": "Accepted into the Workshop on Self-Supervised Learning at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation by observation is an approach for learning from expert\ndemonstrations that lack action information, such as videos. Recent approaches\nto this problem can be placed into two broad categories: training dynamics\nmodels that aim to predict the actions taken between states, and learning\nrewards or features for computing them for Reinforcement Learning (RL). In this\npaper, we introduce a novel approach that learns values, rather than rewards,\ndirectly from observations. We show that by using values, we can significantly\nspeed up RL by removing the need to bootstrap action-values, as compared to\nsparse-reward specifications.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 03:59:44 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Isbell", "Charles L.", ""]]}, {"id": "1905.07866", "submitter": "Xingyu Lin", "authors": "Xingyu Lin, Harjatin Singh Baweja and David Held", "title": "Reinforcement Learning without Ground-Truth State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform robot manipulation tasks, a low-dimensional state of the\nenvironment typically needs to be estimated. However, designing a state\nestimator can sometimes be difficult, especially in environments with\ndeformable objects. An alternative is to learn an end-to-end policy that maps\ndirectly from high-dimensional sensor inputs to actions. However, if this\npolicy is trained with reinforcement learning, then without a state estimator,\nit is hard to specify a reward function based on high-dimensional observations.\nTo meet this challenge, we propose a simple indicator reward function for\ngoal-conditioned reinforcement learning: we only give a positive reward when\nthe robot's observation exactly matches a target goal observation. We show that\nby relabeling the original goal with the achieved goal to obtain positive\nrewards (Andrychowicz et al., 2017), we can learn with the indicator reward\nfunction even in continuous state spaces. We propose two methods to further\nspeed up convergence with indicator rewards: reward balancing and reward\nfiltering. We show comparable performance between our method and an oracle\nwhich uses the ground-truth state for computing rewards. We show that our\nmethod can perform complex tasks in continuous state spaces such as rope\nmanipulation from RGB-D images, without knowledge of the ground-truth state.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 04:17:03 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 06:44:33 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lin", "Xingyu", ""], ["Baweja", "Harjatin Singh", ""], ["Held", "David", ""]]}, {"id": "1905.07870", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit\n  Bansal and Yi Luan", "title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "comments": "12 pages. Accepted by ACL 2019 Code and resource is available at\n  https://github.com/EagleW/PaperRobot", "journal-ref": null, "doi": "10.18653/v1/P19-1191", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a PaperRobot who performs as an automatic research assistant by\n(1) conducting deep understanding of a large collection of human-written papers\nin a target domain and constructing comprehensive background knowledge graphs\n(KGs); (2) creating new ideas by predicting links from the background KGs, by\ncombining graph attention and contextual text attention; (3) incrementally\nwriting some key elements of a new paper based on memory-attention networks:\nfrom the input title along with predicted related entities to generate a paper\nabstract, from the abstract to generate conclusion and future work, and finally\nfrom future work to generate a title for a follow-on paper. Turing Tests, where\na biomedical domain expert is asked to compare a system output and a\nhuman-authored string, show PaperRobot generated abstracts, conclusion and\nfuture work sections, and new titles are chosen over human-written ones up to\n30%, 24% and 12% of the time, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 04:41:10 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 15:47:13 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 13:03:52 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 06:51:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Huang", "Lifu", ""], ["Jiang", "Zhiying", ""], ["Knight", "Kevin", ""], ["Ji", "Heng", ""], ["Bansal", "Mohit", ""], ["Luan", "Yi", ""]]}, {"id": "1905.07875", "submitter": "Ramin Norouzi", "authors": "Ramin Norouzi, Amirreza Kosari, Mohammad Hossein Sabour", "title": "Investigating Flight Envelope Variation Predictability of Impaired\n  Aircraft using Least-Squares Regression Analysis", "comments": "Accepted version, Journal of Aerospace Information Systems", "journal-ref": null, "doi": "10.2514/1.I010760", "report-no": null, "categories": "cs.SY cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aircraft failures alter the aircraft dynamics and cause maneuvering flight\nenvelope to change. Such envelope variations are nonlinear and generally\nunpredictable by the pilot as they are governed by the aircraft's complex\ndynamics. Hence, in order to prevent in-flight Loss of Control it is crucial to\npractically predict the impaired aircraft's flight envelope variation due to\nany a-priori unknown failure degree. This paper investigates the predictability\nof the number of trim points within the maneuvering flight envelope and its\ncentroid using both linear and nonlinear least-squares estimation methods. To\ndo so, various polynomial models and nonlinear models based on hyperbolic\ntangent function are developed and compared which incorporate the influencing\nfactors on the envelope variations as the inputs and estimate the centroid and\nthe number of trim points of the maneuvering flight envelope at any intended\nfailure degree. Results indicate that both the polynomial and hyperbolic\ntangent function-based models are capable of predicting the impaired fight\nenvelope variation with good precision. Furthermore, it is shown that the\nregression equation of the best polynomial fit enables direct assessment of the\nimpaired aircraft's flight envelope contraction and displacement sensitivity to\nthe specific parameters characterizing aircraft failure and flight condition.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 05:22:07 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:36:31 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Norouzi", "Ramin", ""], ["Kosari", "Amirreza", ""], ["Sabour", "Mohammad Hossein", ""]]}, {"id": "1905.07877", "submitter": "Evgeny Burnaev", "authors": "Maria Kolos and Anton Marin and Alexey Artemov and Evgeny Burnaev", "title": "Procedural Synthesis of Remote Sensing Images for Robust Change\n  Detection with Neural Networks", "comments": "17 pages, 11 figures", "journal-ref": "16th International Symposium on Neural Networks, ISNN 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods such as convolutional neural networks (CNNs) are known to\ndeliver state-of-the-art performance on image recognition tasks when the\ntraining data are abundant. However, in some instances, such as change\ndetection in remote sensing images, annotated data cannot be obtained in\nsufficient quantities. In this work, we propose a simple and efficient method\nfor creating realistic targeted synthetic datasets in the remote sensing\ndomain, leveraging the opportunities offered by game development engines. We\nprovide a description of the pipeline for procedural geometry generation and\nrendering as well as an evaluation of the efficiency of produced datasets in a\nchange detection scenario. Our evaluations demonstrate that our pipeline helps\nto improve the performance and convergence of deep learning models when the\namount of real-world data is severely limited.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 05:24:33 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kolos", "Maria", ""], ["Marin", "Anton", ""], ["Artemov", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.07892", "submitter": "Evgeny Burnaev", "authors": "D. Smolyakov and N. Sviridenko and V. Ishimtsev and E. Burikov and E.\n  Burnaev", "title": "Learning Ensembles of Anomaly Detectors on Synthetic Data", "comments": "15 pages, 6 figures", "journal-ref": "16th International Symposium on Neural Networks, ISNN 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main aim of this work is to develop and implement an automatic anomaly\ndetection algorithm for meteorological time-series. To achieve this goal we\ndevelop an approach to constructing an ensemble of anomaly detectors in\ncombination with adaptive threshold selection based on artificially generated\nanomalies. We demonstrate the efficiency of the proposed method by integrating\nthe corresponding implementation into ``Minimax-94'' road weather information\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:02:18 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Smolyakov", "D.", ""], ["Sviridenko", "N.", ""], ["Ishimtsev", "V.", ""], ["Burikov", "E.", ""], ["Burnaev", "E.", ""]]}, {"id": "1905.07900", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "PAC-Bayes under potentially heavy tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive PAC-Bayesian learning guarantees for heavy-tailed losses, and\nobtain a novel optimal Gibbs posterior which enjoys finite-sample excess risk\nbounds at logarithmic confidence. Our core technique itself makes use of\nPAC-Bayesian inequalities in order to derive a robust risk estimator, which by\ndesign is easy to compute. In particular, only assuming that the first three\nmoments of the loss distribution are bounded, the learning algorithm derived\nfrom this estimator achieves nearly sub-Gaussian statistical error, up to the\nquality of the prior.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:30:09 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 09:34:50 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "1905.07902", "submitter": "Evgeny Burnaev", "authors": "Rodrigo Rivera-Castro and Ivan Nazarov and Yuke Xiang and Alexander\n  Pletneev and Ivan Maksimov and Evgeny Burnaev", "title": "Demand forecasting techniques for build-to-order lean manufacturing\n  supply chains", "comments": "10 pages, 2 figures", "journal-ref": "16th International Symposium on Neural Networks, ISNN 2019", "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Build-to-order (BTO) supply chains have become common-place in industries\nsuch as electronics, automotive and fashion. They enable building products\nbased on individual requirements with a short lead time and minimum inventory\nand production costs. Due to their nature, they differ significantly from\ntraditional supply chains. However, there have not been studies dedicated to\ndemand forecasting methods for this type of setting. This work makes two\ncontributions. First, it presents a new and unique data set from a manufacturer\nin the BTO sector. Second, it proposes a novel data transformation technique\nfor demand forecasting of BTO products. Results from thirteen forecasting\nmethods show that the approach compares well to the state-of-the-art while\nbeing easy to implement and to explain to decision-makers.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:33:53 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Nazarov", "Ivan", ""], ["Xiang", "Yuke", ""], ["Pletneev", "Alexander", ""], ["Maksimov", "Ivan", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.07923", "submitter": "Cyrille Morin", "authors": "Cyrille Morin (MARACAS), Leonardo Cardoso (MARACAS), Jakob Hoydis,\n  Jean-Marie Gorce (MARACAS), Thibaud Vial", "title": "Transmitter Classification With Supervised Deep Learning", "comments": null, "journal-ref": "Crowncom, Jun 2019, Poznan, Poland", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware imperfections in RF transmitters introduce features that can be used\nto identify a specific transmitter amongst others. Supervised deep learning has\nshown good performance in this task but using datasets not applicable to real\nworld situations where topologies evolve over time. To remedy this, the work\nrests on a series of datasets gathered in the Future Internet of Things /\nCognitive Radio Testbed [4] (FIT/CorteXlab) to train a convolutional neural\nnetwork (CNN), where focus has been given to reduce channel bias that has\nplagued previous works and constrained them to a constant environment or to\nsimulations. The most challenging scenarios provide the trained neural network\nwith resilience and show insight on the best signal type to use for\nidentification , namely packet preamble. The generated datasets are published\non the Machine Learning For Communications Emerging Technologies Initiatives\nweb site 4 in the hope that they serve as stepping stones for future progress\nin the area. The community is also invited to reproduce the studied scenarios\nand results by generating new datasets in FIT/CorteXlab.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 07:36:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Morin", "Cyrille", "", "MARACAS"], ["Cardoso", "Leonardo", "", "MARACAS"], ["Hoydis", "Jakob", "", "MARACAS"], ["Gorce", "Jean-Marie", "", "MARACAS"], ["Vial", "Thibaud", ""]]}, {"id": "1905.07931", "submitter": "Sangkyun Lee", "authors": "Sangkyun Lee and Jeonghyun Lee", "title": "Compressed Learning of Deep Neural Networks for OpenCL-Capable Embedded\n  Systems", "comments": null, "journal-ref": "Applied Sciences, 2019", "doi": "10.3390/app9081669", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been quite successful in solving many\ncomplex learning problems. However, DNNs tend to have a large number of\nlearning parameters, leading to a large memory and computation requirement. In\nthis paper, we propose a model compression framework for efficient training and\ninference of deep neural networks on embedded systems. Our framework provides\ndata structures and kernels for OpenCL-based parallel forward and backward\ncomputation in a compressed form. In particular, our method learns sparse\nrepresentations of parameters using $\\ell_1$-based sparse coding while\ntraining, storing them in compressed sparse matrices. Unlike the previous\nworks, our method does not require a pre-trained model as an input and\ntherefore can be more versatile for different application environments. Even\nthough the use of $\\ell_1$-based sparse coding for model compression is not\nnew, we show that it can be far more effective than previously reported when we\nuse proximal point algorithms and the technique of debiasing. Our experiments\nshow that our method can produce minimal learning models suitable for small\nembedded devices.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 08:02:24 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lee", "Sangkyun", ""], ["Lee", "Jeonghyun", ""]]}, {"id": "1905.07953", "submitter": "Wei-Lin Chiang", "authors": "Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui\n  Hsieh", "title": "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph\n  Convolutional Networks", "comments": "In Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD'19)", "journal-ref": null, "doi": "10.1145/3292500.3330925", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) has been successfully applied to many\ngraph-based applications; however, training a large-scale GCN remains\nchallenging. Current SGD-based algorithms suffer from either a high\ncomputational cost that exponentially grows with number of GCN layers, or a\nlarge space requirement for keeping the entire graph and the embedding of each\nnode in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm\nthat is suitable for SGD-based training by exploiting the graph clustering\nstructure. Cluster-GCN works as the following: at each step, it samples a block\nof nodes that associate with a dense subgraph identified by a graph clustering\nalgorithm, and restricts the neighborhood search within this subgraph. This\nsimple but effective strategy leads to significantly improved memory and\ncomputational efficiency while being able to achieve comparable test accuracy\nwith previous algorithms. To test the scalability of our algorithm, we create a\nnew Amazon2M data with 2 million nodes and 61 million edges which is more than\n5 times larger than the previous largest publicly available dataset (Reddit).\nFor training a 3-layer GCN on this data, Cluster-GCN is faster than the\nprevious state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much\nless memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this\ndata, our algorithm can finish in around 36 minutes while all the existing GCN\ntraining algorithms fail to train due to the out-of-memory issue. Furthermore,\nCluster-GCN allows us to train much deeper GCN without much time and memory\noverhead, which leads to improved prediction accuracy---using a 5-layer\nCluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI\ndataset, while the previous best result was 98.71 by [16]. Our codes are\npublicly available at\nhttps://github.com/google-research/google-research/tree/master/cluster_gcn.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:16:44 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 16:42:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Chiang", "Wei-Lin", ""], ["Liu", "Xuanqing", ""], ["Si", "Si", ""], ["Li", "Yang", ""], ["Bengio", "Samy", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1905.07960", "submitter": "Alberto Dalla Libera", "authors": "Alberto Dalla Libera, Ruggero Carli, Gianluigi Pillonetto", "title": "A novel Multiplicative Polynomial Kernel for Volterra series\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volterra series are especially useful for nonlinear system identification,\nalso thanks to their capability to approximate a broad range of input-output\nmaps. However, their identification from a finite set of data is hard, due to\nthe curse of dimensionality. Recent approaches have shown how regularized\nkernel-based methods can be useful for this task. In this paper, we propose a\nnew regularization network for Volterra models identification. It relies on a\nnew kernel given by the product of basic building blocks. Each block contains\nsome unknown parameters that can be estimated from data using marginal\nlikelihood optimization. In comparison with other algorithms proposed in the\nliterature, numerical experiments show that our approach allows to better\nselect the monomials that really influence the system output, much increasing\nthe prediction capability of the model.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:44:51 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 08:49:09 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Libera", "Alberto Dalla", ""], ["Carli", "Ruggero", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1905.07961", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban", "title": "Guiding Inferences in Connection Tableau by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset and experiments on applying recurrent neural networks\n(RNNs) for guiding clause selection in the connection tableau proof calculus.\nThe RNN encodes a sequence of literals from the current branch of the partial\nproof tree to a hidden vector state; using it, the system selects a clause for\nextending the proof tree. The training data and learning setup are described,\nand the results are discussed and compared with state of the art using gradient\nboosted trees. Additionally, we perform a conjecturing experiment in which the\nRNN does not just select an existing clause, but completely constructs the next\ntableau goal.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:47:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:56:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "1905.08008", "submitter": "Wang Zheng", "authors": "Zheng Wang, Jianwu Li, Ge Song, Tieling Li", "title": "Less Memory, Faster Speed: Refining Self-Attention Module for Image\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention (SA) mechanisms can capture effectively global dependencies in\ndeep neural networks, and have been applied to natural language processing and\nimage processing successfully. However, SA modules for image reconstruction\nhave high time and space complexity, which restrict their applications to\nhigher-resolution images. In this paper, we refine the SA module in\nself-attention generative adversarial networks (SAGAN) via adapting a non-local\noperation, revising the connectivity among the units in SA module and\nre-implementing its computational pattern, such that its time and space\ncomplexity is reduced from $\\text{O}(n^2)$ to $\\text{O}(n)$, but it is still\nequivalent to the original SA module. Further, we explore the principles behind\nthe module and discover that our module is a special kind of channel attention\nmechanisms. Experimental results based on two benchmark datasets of image\nreconstruction, verify that under the same computational environment, two\nmodels can achieve comparable effectiveness for image reconstruction, but the\nproposed one runs faster and takes up less memory space.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 11:43:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Zheng", ""], ["Li", "Jianwu", ""], ["Song", "Ge", ""], ["Li", "Tieling", ""]]}, {"id": "1905.08022", "submitter": "Caifa Zhou", "authors": "Caifa Zhou and Andreas Wieser", "title": "An iterative scheme for feature based positioning using a weighted\n  dissimilarity measure", "comments": "18 pages, 9 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an iterative scheme for feature-based positioning using a new\nweighted dissimilarity measure with the goal of reducing the impact of large\nerrors among the measured or modeled features. The weights are computed from\nthe location-dependent standard deviations of the features and stored as part\nof the reference fingerprint map (RFM). Spatial filtering and kernel smoothing\nof the kinematically collected raw data allow efficiently estimating the\nstandard deviations during RFM generation. In the positioning stage, the\nweights control the contribution of each feature to the dissimilarity measure,\nwhich in turn quantifies the difference between the set of online measured\nfeatures and the fingerprints stored in the RFM. Features with little\nvariability contribute more to the estimated position than features with high\nvariability. Iterations are necessary because the variability depends on the\nlocation, and the location is initially unknown when estimating the position.\nUsing real WiFi signal strength data from extended test measurements with\nground truth in an office building, we show that the standard deviations of\nthese features vary considerably within the region of interest and are neither\nsimple functions of the signal strength nor of the distances from the\ncorresponding access points. This is the motivation to include the empirical\nstandard deviations in the RFM. We then analyze the deviations of the estimated\npositions with and without the location-dependent weighting. In the present\nexample the maximum radial positioning error from ground truth are reduced by\n40% comparing to kNN without the weighted dissimilarity measure.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 12:12:38 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 14:56:24 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhou", "Caifa", ""], ["Wieser", "Andreas", ""]]}, {"id": "1905.08027", "submitter": "Yuanfu Lu", "authors": "Yuanfu Lu, Chuan Shi, Linmei Hu, Zhiyuan Liu", "title": "Relation Structure-Aware Heterogeneous Information Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information network (HIN) embedding aims to embed multiple\ntypes of nodes into a low-dimensional space. Although most existing HIN\nembedding methods consider heterogeneous relations in HINs, they usually employ\none single model for all relations without distinction, which inevitably\nrestricts the capability of network embedding. In this paper, we take the\nstructural characteristics of heterogeneous relations into consideration and\npropose a novel Relation structure-aware Heterogeneous Information Network\nEmbedding model (RHINE). By exploring the real-world networks with thorough\nmathematical analysis, we present two structure-related measures which can\nconsistently distinguish heterogeneous relations into two categories:\nAffiliation Relations (ARs) and Interaction Relations (IRs). To respect the\ndistinctive characteristics of relations, in our RHINE, we propose different\nmodels specifically tailored to handle ARs and IRs, which can better capture\nthe structures and semantics of the networks. At last, we combine and optimize\nthese models in a unified and elegant manner. Extensive experiments on three\nreal-world datasets demonstrate that our model significantly outperforms the\nstate-of-the-art methods in various tasks, including node clustering, link\nprediction, and node classification.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:44:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lu", "Yuanfu", ""], ["Shi", "Chuan", ""], ["Hu", "Linmei", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1905.08031", "submitter": "Farzad Eskandanian", "authors": "Farzad Eskandanian, Nasim Sonboli, Bamshad Mobasher", "title": "Power of the Few: Analyzing the Impact of Influential Users in\n  Collaborative Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3320435.3320464", "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Like other social systems, in collaborative filtering a small number of\n\"influential\" users may have a large impact on the recommendations of other\nusers, thus affecting the overall behavior of the system. Identifying\ninfluential users and studying their impact on other users is an important\nproblem because it provides insight into how small groups can inadvertently or\nintentionally affect the behavior of the system as a whole. Modeling these\ninfluences can also shed light on patterns and relationships that would\notherwise be difficult to discern, hopefully leading to more transparency in\nhow the system generates personalized content. In this work we first formalize\nthe notion of \"influence\" in collaborative filtering using an Influence\nDiscrimination Model. We then empirically identify and characterize influential\nusers and analyze their impact on the system under different underlying\nrecommendation algorithms and across three different recommendation domains:\njob, movie and book recommendations. Insights from these experiments can help\nin designing systems that are not only optimized for accuracy, but are also\ntuned to mitigate the impact of influential users when it might lead to\npotential imbalance or unfairness in the system's outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 19:57:06 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Eskandanian", "Farzad", ""], ["Sonboli", "Nasim", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1905.08037", "submitter": "Thuy Pham", "authors": "Thuy M. Pham, Ronan Farrell, Le-Nam Tran", "title": "On Estimating Maximum Sum Rate of MIMO Systems with Successive\n  Zero-Forcing Dirty Paper Coding and Per-antenna Power Constraint", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the sum rate maximization for successive zero-forcing\ndirty-paper coding (SZFDPC) with per-antenna power constraint (PAPC). Although\nSZFDPC is a low-complexity alternative to the optimal dirty paper coding (DPC),\nefficient algorithms to compute its sum rate are still open problems especially\nunder practical PAPC. The existing solution to the considered problem is\ncomputationally inefficient due to employing high-complexity interior-point\nmethod. In this study, we propose two new low-complexity approaches to this\nimportant problem. More specifically, the first algorithm achieves the optimal\nsolution by transforming the original problem in the broadcast channel into an\nequivalent problem in the multiple access channel, then the resulting problem\nis solved by alternating optimization together with successive convex\napproximation. We also derive a suboptimal solution based on machine learning\nto which simple linear regressions are applicable. The approaches are analyzed\nand validated extensively to demonstrate their superiors over the existing\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:57:33 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Pham", "Thuy M.", ""], ["Farrell", "Ronan", ""], ["Tran", "Le-Nam", ""]]}, {"id": "1905.08048", "submitter": "Xiaokang Zhang", "authors": "Xiaokang Zhang and Inge Jonassen", "title": "A Comparative Analysis of Feature Selection Methods for Biomarker\n  Discovery in Study of Toxicant-treated Atlantic Cod (Gadus morhua) Liver", "comments": "11 pages, 4 figures, 2019 NAIS Symposium", "journal-ref": "Nordic Artificial Intelligence Research and Development. NAIS\n  2019. Communications in Computer and Information Science, vol 1056. Springer,\n  Cham (2019) pp 114-123", "doi": "10.1007/978-3-030-35664-4_11", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Univariate and multivariate feature selection methods can be used for\nbiomarker discovery in analysis of toxicant exposure. Among the univariate\nmethods, differential expression analysis (DEA) is often applied for its\nsimplicity and interpretability. A characteristic of methods for DEA is that\nthey treat genes individually, disregarding the correlation that exists between\nthem. On the other hand, some multivariate feature selection methods are\nproposed for biomarker discovery. Provided with various biomarker discovery\nmethods, how to choose the most suitable method for a specific dataset becomes\na problem. In this paper, we present a framework for comparison of potential\nbiomarker discovery methods: three methods that stem from different theories\nare compared by how stable they are and how well they can improve the\nclassification accuracy. The three methods we have considered are: Significance\nAnalysis of Microarrays (SAM) which identifies the differentially expressed\ngenes; minimum Redundancy Maximum Relevance (mRMR) based on information theory;\nand Characteristic Direction (GeoDE) inspired by a graphical perspective.\nTested on the gene expression data from two experiments exposing the cod fish\nto two different toxicants (MeHg and PCB 153), different methods stand out in\ndifferent cases, so a decision upon the most suitable method should be made\nbased on the dataset under study and the research interest.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 12:40:01 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Xiaokang", ""], ["Jonassen", "Inge", ""]]}, {"id": "1905.08054", "submitter": "Aly El Gamal", "authors": "Xiwen Zhang, Tolunay Seyfi, Shengtai Ju, Sharan Ramjee, Aly El Gamal,\n  Yonina C. Eldar", "title": "Deep Learning for Interference Identification: Band, Training SNR, and\n  Sample Selection", "comments": "5 pages, 8 figures, In Proc. IEEE International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of interference source identification, through the lens\nof recognizing one of 15 different channels that belong to 3 different wireless\ntechnologies: Bluetooth, Zigbee, and WiFi. We employ deep learning algorithms\ntrained on received samples taken from a 10 MHz band in the 2.4 GHz ISM Band.\nWe obtain a classification accuracy of around 89.5% using any of four different\ndeep neural network architectures: CNN, ResNet, CLDNN, and LSTM, which\ndemonstrate the generality of the effectiveness of deep learning at the\nconsidered task. Interestingly, our proposed CNN architecture requires\napproximately 60% of the training time required by the state of the art while\nachieving slightly larger classification accuracy. We then focus on the CNN\narchitecture and further optimize its training time while incurring minimal\nloss in classification accuracy using three different approaches: 1- Band\nSelection, where we only use samples belonging to the lower and uppermost 2 MHz\nbands, 2- SNR Selection, where we only use training samples belonging to a\nsingle SNR value, and 3- Sample Selection, where we try various sub-Nyquist\nsampling methods to select the subset of samples most relevant to the\nclassification task. Our results confirm the feasibility of fast deep learning\nfor wireless interference identification, by showing that the training time can\nbe reduced by as much as 30x with minimal loss in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 21:08:59 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Xiwen", ""], ["Seyfi", "Tolunay", ""], ["Ju", "Shengtai", ""], ["Ramjee", "Sharan", ""], ["Gamal", "Aly El", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1905.08059", "submitter": "Alexander Neergaard Olesen", "authors": "Alexander Neergaard Olesen, Stanislas Chambon, Valentin Thorey, Poul\n  Jennum, Emmanuel Mignot, Helge B. D. Sorensen", "title": "Towards a Flexible Deep Learning Method for Automatic Detection of\n  Clinically Relevant Multi-Modal Events in the Polysomnogram", "comments": "Accepted for publication in 41st International Engineering in\n  Medicine and Biology Conference (EMBC), July 23-27, 2019", "journal-ref": "2019 41st Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC), Berlin, Germany, 2019, pp. 556-561", "doi": "10.1109/EMBC.2019.8856570", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much attention has been given to automatic sleep staging algorithms in past\nyears, but the detection of discrete events in sleep studies is also crucial\nfor precise characterization of sleep patterns and possible diagnosis of sleep\ndisorders. We propose here a deep learning model for automatic detection and\nannotation of arousals and leg movements. Both of these are commonly seen\nduring normal sleep, while an excessive amount of either is linked to disrupted\nsleep patterns, excessive daytime sleepiness impacting quality of life, and\nvarious sleep disorders. Our model was trained on 1,485 subjects and tested on\n1,000 separate recordings of sleep. We tested two different experimental setups\nand found optimal arousal detection was attained by including a recurrent\nneural network module in our default model with a dynamic default event window\n(F1 = 0.75), while optimal leg movement detection was attained using a static\nevent window (F1 = 0.65). Our work show promise while still allowing for\nimprovements. Specifically, future research will explore the proposed model as\na general-purpose sleep analysis model.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:30:40 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Olesen", "Alexander Neergaard", ""], ["Chambon", "Stanislas", ""], ["Thorey", "Valentin", ""], ["Jennum", "Poul", ""], ["Mignot", "Emmanuel", ""], ["Sorensen", "Helge B. D.", ""]]}, {"id": "1905.08067", "submitter": "Jason R.C. Nurse Dr", "authors": "Mariam Nouh and Jason R. C. Nurse and Michael Goldsmith", "title": "Understanding the Radical Mind: Identifying Signals to Detect Extremist\n  Content on Twitter", "comments": null, "journal-ref": "17th IEEE International Conference on Intelligence and Security\n  Informatics (ISI), 2019", "doi": "10.1109/ISI.2019.8823548", "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet and, in particular, Online Social Networks have changed the way\nthat terrorist and extremist groups can influence and radicalise individuals.\nRecent reports show that the mode of operation of these groups starts by\nexposing a wide audience to extremist material online, before migrating them to\nless open online platforms for further radicalization. Thus, identifying\nradical content online is crucial to limit the reach and spread of the\nextremist narrative. In this paper, our aim is to identify measures to\nautomatically detect radical content in social media. We identify several\nsignals, including textual, psychological and behavioural, that together allow\nfor the classification of radical messages. Our contribution is three-fold: (1)\nwe analyze propaganda material published by extremist groups and create a\ncontextual text-based model of radical content, (2) we build a model of\npsychological properties inferred from these material, and (3) we evaluate\nthese models on Twitter to determine the extent to which it is possible to\nautomatically identify online radical tweets. Our results show that radical\nusers do exhibit distinguishable textual, psychological, and behavioural\nproperties. We find that the psychological properties are among the most\ndistinguishing features. Additionally, our results show that textual models\nusing vector embedding features significantly improves the detection over\nTF-IDF features. We validate our approach on two experiments achieving high\naccuracy. Our findings can be utilized as signals for detecting online\nradicalization activities.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:14:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nouh", "Mariam", ""], ["Nurse", "Jason R. C.", ""], ["Goldsmith", "Michael", ""]]}, {"id": "1905.08076", "submitter": "Dorien Herremans", "authors": "Dorien herremans, David Martens, Kenneth S\\\"orensen", "title": "Dance Hit Song Prediction", "comments": null, "journal-ref": "Journal of New music Research. 43:302 (2014)", "doi": "10.1080/09298215.2014.881888", "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record companies invest billions of dollars in new talent around the globe\neach year. Gaining insight into what actually makes a hit song would provide\ntremendous benefits for the music industry. In this research we tackle this\nquestion by focussing on the dance hit song classification problem. A database\nof dance hit songs from 1985 until 2013 is built, including basic musical\nfeatures, as well as more advanced features that capture a temporal aspect. A\nnumber of different classifiers are used to build and test dance hit prediction\nmodels. The resulting best model has a good performance when predicting whether\na song is a \"top 10\" dance hit versus a lower listed position.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:01:10 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["herremans", "Dorien", ""], ["Martens", "David", ""], ["S\u00f6rensen", "Kenneth", ""]]}, {"id": "1905.08077", "submitter": "Benedikt Pf\\\"ulb", "authors": "B. Pf\\\"ulb, A. Gepperth, S. Abdullah and A. Kilian", "title": "Catastrophic forgetting: still a problem for DNNs", "comments": "10 pages, 11 figures, Artificial Neural Networks and Machine Learning\n  - ICANN 2018", "journal-ref": null, "doi": "10.1007/978-3-030-01418-6_48", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of DNNs when trained on class-incremental\nvisual problems consisting of initial training, followed by retraining with\nadded visual classes. Catastrophic forgetting (CF) behavior is measured using a\nnew evaluation procedure that aims at an application-oriented view of\nincremental learning. In particular, it imposes that model selection must be\nperformed on the initial dataset alone, as well as demanding that retraining\ncontrol be performed only using the retraining dataset, as initial dataset is\nusually too large to be kept. Experiments are conducted on class-incremental\nproblems derived from MNIST, using a variety of different DNN models, some of\nthem recently proposed to avoid catastrophic forgetting. When comparing our new\nevaluation procedure to previous approaches for assessing CF, we find their\nfindings are completely negated, and that none of the tested methods can avoid\nCF in all experiments. This stresses the importance of a realistic empirical\nmeasurement procedure for catastrophic forgetting, and the need for further\nresearch in incremental learning for DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:06:30 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Pf\u00fclb", "B.", ""], ["Gepperth", "A.", ""], ["Abdullah", "S.", ""], ["Kilian", "A.", ""]]}, {"id": "1905.08087", "submitter": "Zheng Tian Mr", "authors": "Zheng Tian, Ying Wen, Zhichen Gong, Faiz Punakkath, Shihao Zou, Jun\n  Wang", "title": "A Regularized Opponent Model with Maximum Entropy Objective", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCA2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\nan inference problem by introducing a binary random variable o, which stands\nfor the \"optimality\". In this paper, we redefine the binary random variable o\nin multi-agent setting and formalize multi-agent reinforcement learning (MARL)\nas probabilistic inference. We derive a variational lower bound of the\nlikelihood of achieving the optimality and name it as Regularized Opponent\nModel with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\nperspective on opponent modeling and show how it can improve the performance of\ntraining agents theoretically and empirically in cooperative games. To optimize\nROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\nconvergence. We extend the exact algorithm to complex environments by proposing\nan approximate version, ROMMEO-AC. We evaluate these two algorithms on the\nchallenging iterated matrix game and differential game respectively and show\nthat they can outperform strong MARL baselines.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:30:59 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:26:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tian", "Zheng", ""], ["Wen", "Ying", ""], ["Gong", "Zhichen", ""], ["Punakkath", "Faiz", ""], ["Zou", "Shihao", ""], ["Wang", "Jun", ""]]}, {"id": "1905.08088", "submitter": "Yasushi Kawase", "authors": "Yasushi Kawase, Yuko Kuroki, Atsushi Miyauchi", "title": "Graph Mining Meets Crowdsourcing: Extracting Experts for Answer\n  Aggregation", "comments": "Accepted to IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating responses from crowd workers is a fundamental task in the process\nof crowdsourcing. In cases where a few experts are overwhelmed by a large\nnumber of non-experts, most answer aggregation algorithms such as the majority\nvoting fail to identify the correct answers. Therefore, it is crucial to\nextract reliable experts from the crowd workers. In this study, we introduce\nthe notion of \"expert core\", which is a set of workers that is very unlikely to\ncontain a non-expert. We design a graph-mining-based efficient algorithm that\nexactly computes the expert core. To answer the aggregation task, we propose\ntwo types of algorithms. The first one incorporates the expert core into\nexisting answer aggregation algorithms such as the majority voting, whereas the\nsecond one utilizes information provided by the expert core extraction\nalgorithm pertaining to the reliability of workers. We then give a theoretical\njustification for the first type of algorithm. Computational experiments using\nsynthetic and real-world datasets demonstrate that our proposed answer\naggregation algorithms outperform state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:49:50 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kawase", "Yasushi", ""], ["Kuroki", "Yuko", ""], ["Miyauchi", "Atsushi", ""]]}, {"id": "1905.08094", "submitter": "Linfeng Zhang", "authors": "Linfeng Zhang, Jiebo Song, Anni Gao, Jingwei Chen, Chenglong Bao,\n  Kaisheng Ma", "title": "Be Your Own Teacher: Improve the Performance of Convolutional Neural\n  Networks via Self Distillation", "comments": "10pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been widely deployed in various\napplication scenarios. In order to extend the applications' boundaries to some\naccuracy-crucial domains, researchers have been investigating approaches to\nboost accuracy through either deeper or wider network structures, which brings\nwith them the exponential increment of the computational and storage cost,\ndelaying the responding time. In this paper, we propose a general training\nframework named self distillation, which notably enhances the performance\n(accuracy) of convolutional neural networks through shrinking the size of the\nnetwork rather than aggrandizing it. Different from traditional knowledge\ndistillation - a knowledge transformation methodology among networks, which\nforces student neural networks to approximate the softmax layer outputs of\npre-trained teacher neural networks, the proposed self distillation framework\ndistills knowledge within network itself. The networks are firstly divided into\nseveral sections. Then the knowledge in the deeper portion of the networks is\nsqueezed into the shallow ones. Experiments further prove the generalization of\nthe proposed self distillation framework: enhancement of accuracy at average\nlevel is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 as\nmaximum. In addition, it can also provide flexibility of depth-wise scalable\ninference on resource-limited edge devices.Our codes will be released on github\nsoon.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 08:46:50 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhang", "Linfeng", ""], ["Song", "Jiebo", ""], ["Gao", "Anni", ""], ["Chen", "Jingwei", ""], ["Bao", "Chenglong", ""], ["Ma", "Kaisheng", ""]]}, {"id": "1905.08099", "submitter": "Pouyan Asgharzadeh", "authors": "Pouyan Asgharzadeh, Oliver R\\\"ohrle, Bettina M. Willie, Annette I.\n  Birkhold", "title": "Decoding the Rejuvenating Effects of Mechanical Loading on Skeletal\n  Maturation using in Vivo Imaging and Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.actbio.2020.02.007", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the process of aging, deterioration of bone macro- and\nmicro-architecture, as well as material decomposition result in a loss of\nstrength and therefore in an increased likelihood of fractures. To date,\nprecise contributions of age-related changes in bone (re)modeling and\n(de)mineralization dynamics and its effect on the loss of functional integrity\nare not completely understood. Here, we present an image-based deep learning\napproach to quantitatively describe the dynamic effects of short-term aging and\nadaptive response to treatment in proximal mouse tibia and fibula. Our approach\nallowed us to perform an end-to-end age prediction based on $\\mu$CT images to\ndetermine the dynamic biological process of tissue maturation during a two week\nperiod, therefore permitting a short-term bone aging prediction with $95\\%$\naccuracy. In a second application, our radiomics analysis reveals that two\nweeks of in vivo mechanical loading are associated with an underlying\nrejuvenating effect of 5 days. Additionally, by quantitatively analyzing the\nlearning process, we could, for the first time, identify the localization of\nthe age-relevant encoded information and demonstrate $89\\%$ load-induced\nsimilarity of these locations in the loaded tibia with younger bones. These\ndata suggest that our method enables identifying a general prognostic phenotype\nof a certain bone age as well as a temporal and localized loading-treatment\neffect on this apparent bone age. Future translational applications of this\nmethod may provide an improved decision-support method for osteoporosis\ntreatment at low cost.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:26:48 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Asgharzadeh", "Pouyan", ""], ["R\u00f6hrle", "Oliver", ""], ["Willie", "Bettina M.", ""], ["Birkhold", "Annette I.", ""]]}, {"id": "1905.08101", "submitter": "Benedikt Pf\\\"ulb", "authors": "B. Pf\\\"ulb and A. Gepperth", "title": "A comprehensive, application-oriented study of catastrophic forgetting\n  in DNNs", "comments": "14 pages, 12 + 23 figures, ICLR | 2019 Seventh International\n  Conference on Learning Representations", "journal-ref": "ICLR 2019 International Conference on Learning Representations", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale empirical study of catastrophic forgetting (CF) in\nmodern Deep Neural Network (DNN) models that perform sequential (or:\nincremental) learning. A new experimental protocol is proposed that enforces\ntypical constraints encountered in application scenarios. As the investigation\nis empirical, we evaluate CF behavior on the hitherto largest number of visual\nclassification datasets, from each of which we construct a representative\nnumber of Sequential Learning Tasks (SLTs) in close alignment to previous works\non CF. Our results clearly indicate that there is no model that avoids CF for\nall investigated datasets and SLTs under application conditions. We conclude\nwith a discussion of potential solutions and workarounds to CF, notably for the\nEWC and IMM models.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:29:19 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Pf\u00fclb", "B.", ""], ["Gepperth", "A.", ""]]}, {"id": "1905.08108", "submitter": "Xiang Wang", "authors": "Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, Tat-Seng Chua", "title": "Neural Graph Collaborative Filtering", "comments": "SIGIR 2019; the latest version of NGCF paper, which is distinct from\n  the version published in ACM Digital Library", "journal-ref": null, "doi": "10.1145/3331184.3331267", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning vector representations (aka. embeddings) of users and items lies at\nthe core of modern recommender systems. Ranging from early matrix factorization\nto recently emerged deep learning based methods, existing efforts typically\nobtain a user's (or an item's) embedding by mapping from pre-existing features\nthat describe the user (or the item), such as ID and attributes. We argue that\nan inherent drawback of such methods is that, the collaborative signal, which\nis latent in user-item interactions, is not encoded in the embedding process.\nAs such, the resultant embeddings may not be sufficient to capture the\ncollaborative filtering effect.\n  In this work, we propose to integrate the user-item interactions -- more\nspecifically the bipartite graph structure -- into the embedding process. We\ndevelop a new recommendation framework Neural Graph Collaborative Filtering\n(NGCF), which exploits the user-item graph structure by propagating embeddings\non it. This leads to the expressive modeling of high-order connectivity in\nuser-item graph, effectively injecting the collaborative signal into the\nembedding process in an explicit manner. We conduct extensive experiments on\nthree public benchmarks, demonstrating significant improvements over several\nstate-of-the-art models like HOP-Rec and Collaborative Memory Network. Further\nanalysis verifies the importance of embedding propagation for learning better\nuser and item representations, justifying the rationality and effectiveness of\nNGCF. Codes are available at\nhttps://github.com/xiangwang1223/neural_graph_collaborative_filtering.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:41:16 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:24:44 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wang", "Xiang", ""], ["He", "Xiangnan", ""], ["Wang", "Meng", ""], ["Feng", "Fuli", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1905.08110", "submitter": "Yiyu Wang", "authors": "Yiyu Wang, Jungang Xu, Yingfei Sun, Ben He", "title": "Image Captioning based on Deep Learning Methods: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning is a challenging task and attracting more and more attention\nin the field of Artificial Intelligence, and which can be applied to efficient\nimage retrieval, intelligent blind guidance and human-computer interaction,\netc. In this paper, we present a survey on advances in image captioning based\non Deep Learning methods, including Encoder-Decoder structure, improved methods\nin Encoder, improved methods in Decoder, and other improvements. Furthermore,\nwe discussed future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:43:52 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Yiyu", ""], ["Xu", "Jungang", ""], ["Sun", "Yingfei", ""], ["He", "Ben", ""]]}, {"id": "1905.08114", "submitter": "Konda Reddy Mopuri", "authors": "Gaurav Kumar Nayak, Konda Reddy Mopuri, Vaisakh Shaj, R. Venkatesh\n  Babu, Anirban Chakraborty", "title": "Zero-Shot Knowledge Distillation in Deep Networks", "comments": "Accepted in ICML 2019, codes will be available at\n  https://github.com/vcl-iisc/ZSKD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation deals with the problem of training a smaller model\n(Student) from a high capacity source model (Teacher) so as to retain most of\nits performance. Existing approaches use either the training data or meta-data\nextracted from it in order to train the Student. However, accessing the dataset\non which the Teacher has been trained may not always be feasible if the dataset\nis very large or it poses privacy or safety concerns (e.g., bio-metric or\nmedical data). Hence, in this paper, we propose a novel data-free method to\ntrain the Student from the Teacher. Without even using any meta-data, we\nsynthesize the Data Impressions from the complex Teacher model and utilize\nthese as surrogates for the original training data samples to transfer its\nlearning to Student via knowledge distillation. We, therefore, dub our method\n\"Zero-Shot Knowledge Distillation\" and demonstrate that our framework results\nin competitive generalization performance as achieved by distillation using the\nactual training data samples on multiple benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:49:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Nayak", "Gaurav Kumar", ""], ["Mopuri", "Konda Reddy", ""], ["Shaj", "Vaisakh", ""], ["Babu", "R. Venkatesh", ""], ["Chakraborty", "Anirban", ""]]}, {"id": "1905.08119", "submitter": "Honglin Li", "authors": "Honglin Li, Shirin Enshaeifar, Frieder Ganz, Payam Barnaghi", "title": "Continual Learning in Deep Neural Network by Using a Kalman Optimiser", "comments": "accepted by ICML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and adapting to new distributions or learning new tasks sequentially\nwithout forgetting the previously learned knowledge is a challenging phenomenon\nin continual learning models. Most of the conventional deep learning models are\nnot capable of learning new tasks sequentially in one model without forgetting\nthe previously learned ones. We address this issue by using a Kalman Optimiser.\nThe Kalman Optimiser divides the neural network into two parts: the long-term\nand short-term memory units. The long-term memory unit is used to remember the\nlearned tasks and the short-term memory unit is to adapt to the new task. We\nhave evaluated our method on MNIST, CIFAR10, CIFAR100 datasets and compare our\nresults with state-of-the-art baseline models. The results show that our\napproach enables the model to continually learn and adapt to the new changes\nwithout forgetting the previously learned tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:00:14 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 10:04:20 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 10:03:04 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Li", "Honglin", ""], ["Enshaeifar", "Shirin", ""], ["Ganz", "Frieder", ""], ["Barnaghi", "Payam", ""]]}, {"id": "1905.08138", "submitter": "Huibing Wang", "authors": "Lin Feng, Xiangzhu Meng, Huibing Wang", "title": "Multi-view Locality Low-rank Embedding for Dimension Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, we have witnessed a surge of interests of learning a\nlow-dimensional space with discriminative information from one single view.\nEven though most of them can achieve satisfactory performance in some certain\nsituations, they fail to fully consider the information from multiple views\nwhich are highly relevant but sometimes look different from each other.\nBesides, correlations between features from multiple views always vary greatly,\nwhich challenges multi-view subspace learning. Therefore, how to learn an\nappropriate subspace which can maintain valuable information from multi-view\nfeatures is of vital importance but challenging. To tackle this problem, this\npaper proposes a novel multi-view dimension reduction method named Multi-view\nLocality Low-rank Embedding for Dimension Reduction (MvL2E). MvL2E makes full\nuse of correlations between multi-view features by adopting low-rank\nrepresentations. Meanwhile, it aims to maintain the correlations and construct\na suitable manifold space to capture the low-dimensional embedding for\nmulti-view features. A centroid based scheme is designed to force multiple\nviews to learn from each other. And an iterative alternating strategy is\ndeveloped to obtain the optimal solution of MvL2E. The proposed method is\nevaluated on 5 benchmark datasets. Comprehensive experiments show that our\nproposed MvL2E can achieve comparable performance with previous approaches\nproposed in recent literatures.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:30:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Feng", "Lin", ""], ["Meng", "Xiangzhu", ""], ["Wang", "Huibing", ""]]}, {"id": "1905.08152", "submitter": "Weiye Zhao", "authors": "Wei-Ye Zhao, Xi-Ya Guan, Yang Liu, Xiaoming Zhao, Jian Peng", "title": "Stochastic Variance Reduction for Deep Q-learning", "comments": "this is the full paper version, its extended abstract has been\n  published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning have achieved human-level\nperformance on a variety of real-world applications. However, the current\nalgorithms still suffer from poor gradient estimation with excessive variance,\nresulting in unstable training and poor sample efficiency. In our paper, we\nproposed an innovative optimization strategy by utilizing stochastic variance\nreduced gradient (SVRG) techniques. With extensive experiments on Atari domain,\nour method outperforms the deep q-learning baselines on 18 out of 20 games.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:56:22 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Zhao", "Wei-Ye", ""], ["Guan", "Xi-Ya", ""], ["Liu", "Yang", ""], ["Zhao", "Xiaoming", ""], ["Peng", "Jian", ""]]}, {"id": "1905.08165", "submitter": "Pierre Menard", "authors": "Pierre M\\'enard", "title": "Gradient Ascent for Active Exploration in Bandit Problems", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm based on an gradient ascent for a general Active\nExploration bandit problem in the fixed confidence setting. This problem\nencompasses several well studied problems such that the Best Arm Identification\nor Thresholding Bandits. It consists of a new sampling rule based on an online\nlazy mirror ascent. We prove that this algorithm is asymptotically optimal and,\nmost importantly, computationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:23:13 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["M\u00e9nard", "Pierre", ""]]}, {"id": "1905.08170", "submitter": "Shashank Singh", "authors": "Shashank Singh, Ashish Khetan, Zohar Karnin", "title": "DARC: Differentiable ARchitecture Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many learning situations, resources at inference time are significantly\nmore constrained than resources at training time. This paper studies a general\nparadigm, called Differentiable ARchitecture Compression (DARC), that combines\nmodel compression and architecture search to learn models that are\nresource-efficient at inference time. Given a resource-intensive base\narchitecture, DARC utilizes the training data to learn which sub-components can\nbe replaced by cheaper alternatives. The high-level technique can be applied to\nany neural architecture, and we report experiments on state-of-the-art\nconvolutional neural networks for image classification. For a WideResNet with\n$97.2\\%$ accuracy on CIFAR-10, we improve single-sample inference speed by\n$2.28\\times$ and memory footprint by $5.64\\times$, with no accuracy loss. For a\nResNet with $79.15\\%$ Top1 accuracy on ImageNet, we improve batch inference\nspeed by $1.29\\times$ and memory footprint by $3.57\\times$ with $1\\%$ accuracy\nloss. We also give theoretical Rademacher complexity bounds in simplified\ncases, showing how DARC avoids overfitting despite over-parameterization.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:30:06 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Singh", "Shashank", ""], ["Khetan", "Ashish", ""], ["Karnin", "Zohar", ""]]}, {"id": "1905.08188", "submitter": "Esther Derman", "authors": "Esther Derman and Daniel Mankowitz and Timothy Mann and Shie Mannor", "title": "A Bayesian Approach to Robust Reinforcement Learning", "comments": "Accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Markov Decision Processes (RMDPs) intend to ensure robustness with\nrespect to changing or adversarial system behavior. In this framework,\ntransitions are modeled as arbitrary elements of a known and properly\nstructured uncertainty set and a robust optimal policy can be derived under the\nworst-case scenario. In this study, we address the issue of learning in RMDPs\nusing a Bayesian approach. We introduce the Uncertainty Robust Bellman Equation\n(URBE) which encourages safe exploration for adapting the uncertainty set to\nnew observations while preserving robustness. We propose a URBE-based\nalgorithm, DQN-URBE, that scales this method to higher dimensional domains. Our\nexperiments show that the derived URBE-based strategy leads to a better\ntrade-off between less conservative solutions and robustness in the presence of\nmodel misspecification. In addition, we show that the DQN-URBE algorithm can\nadapt significantly faster to changing dynamics online compared to existing\nrobust techniques with fixed uncertainty sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:03:30 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 22:07:27 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Derman", "Esther", ""], ["Mankowitz", "Daniel", ""], ["Mann", "Timothy", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.08193", "submitter": "Farrukh Nauman", "authors": "Farrukh Nauman, Joonas N\\\"attil\\\"a", "title": "Exploring helical dynamos with machine learning", "comments": "accepted by A&A, 11 pages, 6 figures, 3 tables, data + IPython\n  notebooks: https://github.com/fnauman/ML_alpha2", "journal-ref": "A&A 629, A89 (2019)", "doi": "10.1051/0004-6361/201935945", "report-no": "NORDITA 2019-046", "categories": "astro-ph.SR astro-ph.GA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use ensemble machine learning algorithms to study the evolution of\nmagnetic fields in magnetohydrodynamic (MHD) turbulence that is helically\nforced. We perform direct numerical simulations of helically forced turbulence\nusing mean field formalism, with electromotive force (EMF) modeled both as a\nlinear and non-linear function of the mean magnetic field and current density.\nThe form of the EMF is determined using regularized linear regression and\nrandom forests. We also compare various analytical models to the data using\nBayesian inference with Markov Chain Monte Carlo (MCMC) sampling. Our results\ndemonstrate that linear regression is largely successful at predicting the EMF\nand the use of more sophisticated algorithms (random forests, MCMC) do not lead\nto significant improvement in the fits. We conclude that the data we are\nlooking at is effectively low dimensional and essentially linear. Finally, to\nencourage further exploration by the community, we provide all of our\nsimulation data and analysis scripts as open source IPython notebooks.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:18:33 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:27:12 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 16:59:46 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Nauman", "Farrukh", ""], ["N\u00e4ttil\u00e4", "Joonas", ""]]}, {"id": "1905.08196", "submitter": "Martin Trapp", "authors": "Martin Trapp and Robert Peharz and Franz Pernkopf", "title": "Optimisation of Overparametrized Sum-Product Networks", "comments": "Workshop on Tractable Probabilistic Models (TPM) at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It seems to be a pearl of conventional wisdom that parameter learning in deep\nsum-product networks is surprisingly fast compared to shallow mixture models.\nThis paper examines the effects of overparameterization in sum-product networks\non the speed of parameter optimisation. Using theoretical analysis and\nempirical experiments, we show that deep sum-product networks exhibit an\nimplicit acceleration compared to their shallow counterpart. In fact,\ngradient-based optimisation in deep tree-structured sum-product networks is\nequal to gradient ascend with adaptive and time-varying learning rates and\nadditional momentum terms.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:23:10 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 08:56:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Trapp", "Martin", ""], ["Peharz", "Robert", ""], ["Pernkopf", "Franz", ""]]}, {"id": "1905.08224", "submitter": "Abbas Kazerouni", "authors": "Abbas Kazerouni and Lawrence M. Wein", "title": "Best Arm Identification in Generalized Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by drug design, we consider the best-arm identification problem in\ngeneralized linear bandits. More specifically, we assume each arm has a vector\nof covariates, there is an unknown vector of parameters that is common across\nthe arms, and a generalized linear model captures the dependence of rewards on\nthe covariate and parameter vectors. The problem is to minimize the number of\narm pulls required to identify an arm that is sufficiently close to optimal\nwith a sufficiently high probability. Building on recent progress in best-arm\nidentification for linear bandits (Xu et al. 2018), we propose the first\nalgorithm for best-arm identification for generalized linear bandits, provide\ntheoretical guarantees on its accuracy and sampling efficiency, and evaluate\nits performance in various scenarios via simulation.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:25:47 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kazerouni", "Abbas", ""], ["Wein", "Lawrence M.", ""]]}, {"id": "1905.08232", "submitter": "Parsa Saadatpanah", "authors": "Ali Shafahi, Parsa Saadatpanah, Chen Zhu, Amin Ghiasi, Christoph\n  Studer, David Jacobs, Tom Goldstein", "title": "Adversarially robust transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, in which a network is trained on one task and re-purposed\non another, is often used to produce neural network classifiers when data is\nscarce or full-scale training is too costly. When the goal is to produce a\nmodel that is not only accurate but also adversarially robust, data scarcity\nand computational limitations become even more cumbersome. We consider robust\ntransfer learning, in which we transfer not only performance but also\nrobustness from a source model to a target domain. We start by observing that\nrobust networks contain robust feature extractors. By training classifiers on\ntop of these feature extractors, we produce new models that inherit the\nrobustness of their parent networks. We then consider the case of fine tuning a\nnetwork by re-training end-to-end in the target domain. When using lifelong\nlearning strategies, this process preserves the robustness of the source\nnetwork while achieving high accuracy. By using such strategies, it is possible\nto produce accurate and robust models with little data, and without the cost of\nadversarial training. Additionally, we can improve the generalization of\nadversarially trained models, while maintaining their robustness.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:57:57 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:51:23 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shafahi", "Ali", ""], ["Saadatpanah", "Parsa", ""], ["Zhu", "Chen", ""], ["Ghiasi", "Amin", ""], ["Studer", "Christoph", ""], ["Jacobs", "David", ""], ["Goldstein", "Tom", ""]]}, {"id": "1905.08233", "submitter": "Egor Zakharov", "authors": "Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, Victor Lempitsky", "title": "Few-Shot Adversarial Learning of Realistic Neural Talking Head Models", "comments": "UPDATE: the data we used for evaluation is available for download!\n  See https://drive.google.com/open?id=1PeGG6zO3ZjrHk2GAXItB8khwMhPPyDHe and\n  refer to the README for description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have shown how highly realistic human head images can be\nobtained by training convolutional neural networks to generate them. In order\nto create a personalized talking head model, these works require training on a\nlarge dataset of images of a single person. However, in many practical\nscenarios, such personalized talking head models need to be learned from a few\nimage views of a person, potentially even a single image. Here, we present a\nsystem with such few-shot capability. It performs lengthy meta-learning on a\nlarge dataset of videos, and after that is able to frame few- and one-shot\nlearning of neural talking head models of previously unseen people as\nadversarial training problems with high capacity generators and discriminators.\nCrucially, the system is able to initialize the parameters of both the\ngenerator and the discriminator in a person-specific way, so that training can\nbe based on just a few images and done quickly, despite the need to tune tens\nof millions of parameters. We show that such an approach is able to learn\nhighly realistic and personalized talking head models of new people and even\nportrait paintings.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:58:04 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 11:16:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Zakharov", "Egor", ""], ["Shysheya", "Aliaksandra", ""], ["Burkov", "Egor", ""], ["Lempitsky", "Victor", ""]]}, {"id": "1905.08287", "submitter": "Uthsav Chitra", "authors": "Uthsav Chitra and Benjamin J Raphael", "title": "Random Walks on Hypergraphs with Edge-Dependent Vertex Weights", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraphs are used in machine learning to model higher-order relationships\nin data. While spectral methods for graphs are well-established, spectral\ntheory for hypergraphs remains an active area of research. In this paper, we\nuse random walks to develop a spectral theory for hypergraphs with\nedge-dependent vertex weights: hypergraphs where every vertex $v$ has a weight\n$\\gamma_e(v)$ for each incident hyperedge $e$ that describes the contribution\nof $v$ to the hyperedge $e$. We derive a random walk-based hypergraph\nLaplacian, and bound the mixing time of random walks on such hypergraphs.\nMoreover, we give conditions under which random walks on such hypergraphs are\nequivalent to random walks on graphs. As a corollary, we show that current\nmachine learning methods that rely on Laplacians derived from random walks on\nhypergraphs with edge-independent vertex weights do not utilize higher-order\nrelationships in the data. Finally, we demonstrate the advantages of\nhypergraphs with edge-dependent vertex weights on ranking applications using\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:32:01 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Chitra", "Uthsav", ""], ["Raphael", "Benjamin J", ""]]}, {"id": "1905.08293", "submitter": "Nicholas Denis", "authors": "Nicholas Denis", "title": "Issues concerning realizability of Blackwell optimal policies in\n  reinforcement learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N-discount optimality was introduced as a hierarchical form of policy- and\nvalue-function optimality, with Blackwell optimality lying at the top level of\nthe hierarchy Veinott (1969); Blackwell (1962). We formalize notions of myopic\ndiscount factors, value functions and policies in terms of Blackwell optimality\nin MDPs, and we provide a novel concept of regret, called Blackwell regret,\nwhich measures the regret compared to a Blackwell optimal policy. Our main\nanalysis focuses on long horizon MDPs with sparse rewards. We show that\nselecting the discount factor under which zero Blackwell regret can be achieved\nbecomes arbitrarily hard. Moreover, even with oracle knowledge of such a\ndiscount factor that can realize a Blackwell regret-free value function, an\n$\\epsilon$-Blackwell optimal value function may not even be gain optimal.\nDifficulties associated with this class of problems is discussed, and the\nnotion of a policy gap is defined as the difference in expected return between\na given policy and any other policy that differs at that state; we prove\ncertain properties related to this gap. Finally, we provide experimental\nresults that further support our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:54:52 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Denis", "Nicholas", ""]]}, {"id": "1905.08300", "submitter": "Hansenclever Bassani", "authors": "Hansenclever F. Bassani, Aluizio F. R. Araujo", "title": "A Neural Network Architecture for Learning Word-Referent Associations in\n  Multiple Contexts", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.05.017", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article proposes a biologically inspired neurocomputational architecture\nwhich learns associations between words and referents in different contexts,\nconsidering evidence collected from the literature of Psycholinguistics and\nNeurolinguistics. The multi-layered architecture takes as input raw images of\nobjects (referents) and streams of word's phonemes (labels), builds an adequate\nrepresentation, recognizes the current context, and associates label with\nreferents incrementally, by employing a Self-Organizing Map which creates new\nassociation nodes (prototypes) as required, adjusts the existing prototypes to\nbetter represent the input stimuli and removes prototypes that become\nobsolete/unused. The model takes into account the current context to retrieve\nthe correct meaning of words with multiple meanings. Simulations show that the\nmodel can reach up to 78% of word-referent association accuracy in ambiguous\nsituations and approximates well the learning rates of humans as reported by\nthree different authors in five Cross-Situational Word Learning experiments,\nalso displaying similar learning patterns in the different learning conditions.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:05:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Araujo", "Aluizio F. R.", ""]]}, {"id": "1905.08302", "submitter": "Cl\\'ement Canonne", "authors": "Jayadev Acharya and Cl\\'ement L. Canonne and Himanshu Tyagi", "title": "Inference under Information Constraints II: Communication Constraints\n  and Shared Randomness", "comments": "To appear in IEEE Transactions on Information Theory. An abridged\n  version of this work appeared in the 2019 International Conference on Machine\n  Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A central server needs to perform statistical inference based on samples that\nare distributed over multiple users who can each send a message of limited\nlength to the center. We study problems of distribution learning and identity\ntesting in this distributed inference setting and examine the role of shared\nrandomness as a resource. We propose a general-purpose simulate-and-infer\nstrategy that uses only private-coin communication protocols and is\nsample-optimal for distribution learning. This general strategy turns out to be\nsample-optimal even for distribution testing among private-coin protocols.\nInterestingly, we propose a public-coin protocol that outperforms\nsimulate-and-infer for distribution testing and is, in fact, sample-optimal.\nUnderlying our public-coin protocol is a random hash that when applied to the\nsamples minimally contracts the chi-squared distance of their distribution to\nthe uniform distribution.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:18:47 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 04:56:00 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1905.08313", "submitter": "Hong Zhao", "authors": "Hong Zhao", "title": "Inferring Global Dynamics of a Black-Box System Using Machine Learning", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.SR math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present that, instead of establishing the equations of motion, one can\nmodel-freely reveal the dynamical properties of a black-box system using a\nlearning machine. Trained only by a segment of time series of a state variable\nrecorded at present parameters values, the dynamics of the learning machine at\ndifferent training stages can be mapped to the dynamics of the target system\nalong a particular path in its parameter space, following an appropriate\ntraining strategy that monotonously decreases the cost function. This path is\nimportant, because along that, the primary dynamical properties of the target\nsystem will subsequently emerge, in the simple-to-complex order, matching\nclosely the evolution law of certain self-evolved systems in nature. Why such a\npath can be reproduced is attributed to our training strategy. This particular\nfunction of the learning machine opens up a novel way to probe the global\ndynamical properties of a black-box system without artificially establish the\nequations of motion, and as such it might have countless applications. As an\nexample, this method is applied to infer what dynamical stages a variable star\nhas experienced and how it will evolve in future, by using the light curve\nobserved presently.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:31:19 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 10:24:01 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Zhao", "Hong", ""]]}, {"id": "1905.08314", "submitter": "Yuan Lin", "authors": "Yuan Lin, John McPhee, and Nasser L. Azad", "title": "Longitudinal Dynamic versus Kinematic Models for Car-Following Control\n  Using Deep Reinforcement Learning", "comments": "Accepted to 2019 IEEE Intelligent Transportation Systems Conference", "journal-ref": null, "doi": "10.1109/ITSC.2019.8916781", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of current studies on autonomous vehicle control via deep\nreinforcement learning (DRL) utilize point-mass kinematic models, neglecting\nvehicle dynamics which includes acceleration delay and acceleration command\ndynamics. The acceleration delay, which results from sensing and actuation\ndelays, results in delayed execution of the control inputs. The acceleration\ncommand dynamics dictates that the actual vehicle acceleration does not rise up\nto the desired command acceleration instantaneously due to dynamics. In this\nwork, we investigate the feasibility of applying DRL controllers trained using\nvehicle kinematic models to more realistic driving control with vehicle\ndynamics. We consider a particular longitudinal car-following control, i.e.,\nAdaptive Cruise Control (ACC), problem solved via DRL using a point-mass\nkinematic model. When such a controller is applied to car following with\nvehicle dynamics, we observe significantly degraded car-following performance.\nTherefore, we redesign the DRL framework to accommodate the acceleration delay\nand acceleration command dynamics by adding the delayed control inputs and the\nactual vehicle acceleration to the reinforcement learning environment state,\nrespectively. The training results show that the redesigned DRL controller\nresults in near-optimal control performance of car following with vehicle\ndynamics considered when compared with dynamic programming solutions.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 18:39:29 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 14:29:09 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lin", "Yuan", ""], ["McPhee", "John", ""], ["Azad", "Nasser L.", ""]]}, {"id": "1905.08315", "submitter": "Shanka Subhra Mondal", "authors": "Shanka Subhra Mondal, Rachana Sathish, Debdoot Sheet", "title": "Multitask Learning of Temporal Connectionism in Convolutional Networks\n  using a Joint Distribution Loss Function to Simultaneously Identify Tools and\n  Phase in Surgical Videos", "comments": "15 pages, 8 figures, 5th MedImage Workshop of 11th Indian Conference\n  on Computer Vision, Graphics and Image Processing, Hyderabad, India, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgical workflow analysis is of importance for understanding onset and\npersistence of surgical phases and individual tool usage across surgery and in\neach phase. It is beneficial for clinical quality control and to hospital\nadministrators for understanding surgery planning. Video acquired during\nsurgery typically can be leveraged for this task. Currently, a combination of\nconvolutional neural network (CNN) and recurrent neural networks (RNN) are\npopularly used for video analysis in general, not only being restricted to\nsurgical videos. In this paper, we propose a multi-task learning framework\nusing CNN followed by a bi-directional long short term memory (Bi-LSTM) to\nlearn to encapsulate both forward and backward temporal dependencies. Further,\nthe joint distribution indicating set of tools associated with a phase is used\nas an additional loss during learning to correct for their co-occurrence in any\npredictions. Experimental evaluation is performed using the Cholec80 dataset.\nWe report a mean average precision (mAP) score of 0.99 and 0.86 for tool and\nphase identification respectively which are higher compared to prior-art in the\nfield.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:42:40 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 16:38:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Mondal", "Shanka Subhra", ""], ["Sathish", "Rachana", ""], ["Sheet", "Debdoot", ""]]}, {"id": "1905.08318", "submitter": "Simon Wiedemann", "authors": "Simon Wiedemann, Heiner Kirchhoffer, Stefan Matlage, Paul Haase,\n  Arturo Marban, Talmaj Marinc, David Neumann, Ahmed Osman, Detlev Marpe, Heiko\n  Schwarz, Thomas Wiegand, Wojciech Samek", "title": "DeepCABAC: Context-adaptive binary arithmetic coding for deep neural\n  network compression", "comments": "ICML 2019, Joint Workshop on On-Device Machine Learning and Compact\n  Deep Neural Network Representations (ODML-CDNNR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeepCABAC, a novel context-adaptive binary arithmetic coder for\ncompressing deep neural networks. It quantizes each weight parameter by\nminimizing a weighted rate-distortion function, which implicitly takes the\nimpact of quantization on to the accuracy of the network into account.\nSubsequently, it compresses the quantized values into a bitstream\nrepresentation with minimal redundancies. We show that DeepCABAC is able to\nreach very high compression ratios across a wide set of different network\narchitectures and datasets. For instance, we are able to compress by x63.6 the\nVGG16 ImageNet model with no loss of accuracy, thus being able to represent the\nentire network with merely 8.7MB.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:36:27 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wiedemann", "Simon", ""], ["Kirchhoffer", "Heiner", ""], ["Matlage", "Stefan", ""], ["Haase", "Paul", ""], ["Marban", "Arturo", ""], ["Marinc", "Talmaj", ""], ["Neumann", "David", ""], ["Osman", "Ahmed", ""], ["Marpe", "Detlev", ""], ["Schwarz", "Heiko", ""], ["Wiegand", "Thomas", ""], ["Samek", "Wojciech", ""]]}, {"id": "1905.08320", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Milan Lopuha\\\"a-Zwakenberg, Zitao Li, Boris Skoric,\n  Ninghui Li", "title": "Locally Differentially Private Frequency Estimation with Consistency", "comments": "NDSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy (LDP) protects user privacy from the data\ncollector. LDP protocols have been increasingly deployed in the industry. A\nbasic building block is frequency oracle (FO) protocols, which estimate\nfrequencies of values. While several FO protocols have been proposed, the\ndesign goal does not lead to optimal results for answering many queries. In\nthis paper, we show that adding post-processing steps to FO protocols by\nexploiting the knowledge that all individual frequencies should be non-negative\nand they sum up to one can lead to significantly better accuracy for a wide\nrange of tasks, including frequencies of individual values, frequencies of the\nmost frequent values, and frequencies of subsets of values. We consider 10\ndifferent methods that exploit this knowledge differently. We establish\ntheoretical relationships between some of them and conducted extensive\nexperimental evaluations to understand which methods should be used for\ndifferent query tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:49:52 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:56:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Tianhao", ""], ["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Li", "Zitao", ""], ["Skoric", "Boris", ""], ["Li", "Ninghui", ""]]}, {"id": "1905.08325", "submitter": "Omer Katz", "authors": "Omer Katz, Yuval Olshaker, Yoav Goldberg, Eran Yahav", "title": "Towards Neural Decompilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of automatic decompilation, converting a program in\nlow-level representation back to a higher-level human-readable programming\nlanguage. The problem of decompilation is extremely important for security\nresearchers. Finding vulnerabilities and understanding how malware operates is\nmuch easier when done over source code.\n  The importance of decompilation has motivated the construction of\nhand-crafted rule-based decompilers. Such decompilers have been designed by\nexperts to detect specific control-flow structures and idioms in low-level code\nand lift them to source level. The cost of supporting additional languages or\nnew language features in these models is very high.\n  We present a novel approach to decompilation based on neural machine\ntranslation. The main idea is to automatically learn a decompiler from a given\ncompiler. Given a compiler from a source language S to a target language T ,\nour approach automatically trains a decompiler that can translate (decompile) T\nback to S . We used our framework to decompile both LLVM IR and x86 assembly to\nC code with high success rates. Using our LLVM and x86 instantiations, we were\nable to successfully decompile over 97% and 88% of our benchmarks respectively.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 20:02:53 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Katz", "Omer", ""], ["Olshaker", "Yuval", ""], ["Goldberg", "Yoav", ""], ["Yahav", "Eran", ""]]}, {"id": "1905.08337", "submitter": "Subhasis Dasgupta", "authors": "Subhasis Dasgupta, Aditya Bagchi and Amarnath Gupta", "title": "Ingesting High-Velocity Streaming Graphs from Social Media Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data science applications like social network analysis use graphs as\ntheir primary form of data. However, acquiring graph-structured data from\nsocial media presents some interesting challenges. The first challenge is the\nhigh data velocity and bursty nature of the social media data. The second\nchallenge is that the complex nature of the data makes the ingestion process\nexpensive. If we want to store the streaming graph data in a graph database, we\nface a third challenge -- the database is very often unable to sustain the\ningestion of high-velocity, high-burst data. We have developed an adaptive\nbuffering mechanism and a graph compression technique that effectively\nmitigates the problem. A novel aspect of our method is that the adaptive\nbuffering algorithm uses the data rate, the data content as well as the CPU\nresources of the database machine to determine an optimal data ingestion\nmechanism. We further show that an ingestion-time graph-compression strategy\nimproves the efficiency of the data ingestion into the database. We have\nverified the efficacy of our ingestion optimization strategy through extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 20:29:44 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Dasgupta", "Subhasis", ""], ["Bagchi", "Aditya", ""], ["Gupta", "Amarnath", ""]]}, {"id": "1905.08352", "submitter": "Vincent Lostanlen", "authors": "Vincent Lostanlen, Justin Salamon, Andrew Farnsworth, Steve Kelling,\n  Juan Pablo Bello", "title": "Robust sound event detection in bioacoustic sensor networks", "comments": "32 pages, in English. Submitted to PLOS ONE journal in February 2019;\n  revised August 2019; published October 2019", "journal-ref": null, "doi": "10.1371/journal.pone.0214168", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bioacoustic sensors, sometimes known as autonomous recording units (ARUs),\ncan record sounds of wildlife over long periods of time in scalable and\nminimally invasive ways. Deriving per-species abundance estimates from these\nsensors requires detection, classification, and quantification of animal\nvocalizations as individual acoustic events. Yet, variability in ambient noise,\nboth over time and across sensors, hinders the reliability of current automated\nsystems for sound event detection (SED), such as convolutional neural networks\n(CNN) in the time-frequency domain. In this article, we develop, benchmark, and\ncombine several machine listening techniques to improve the generalizability of\nSED models across heterogeneous acoustic environments. As a case study, we\nconsider the problem of detecting avian flight calls from a ten-hour recording\nof nocturnal bird migration, recorded by a network of six ARUs in the presence\nof heterogeneous background noise. Starting from a CNN yielding\nstate-of-the-art accuracy on this task, we introduce two noise adaptation\ntechniques, respectively integrating short-term (60 milliseconds) and long-term\n(30 minutes) context. First, we apply per-channel energy normalization (PCEN)\nin the time-frequency domain, which applies short-term automatic gain control\nto every subband in the mel-frequency spectrogram. Secondly, we replace the\nlast dense layer in the network by a context-adaptive neural network (CA-NN)\nlayer. Combining them yields state-of-the-art results that are unmatched by\nartificial data augmentation alone. We release a pre-trained version of our\nbest performing system under the name of BirdVoxDetect, a ready-to-use detector\nof avian flight calls in field recordings.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:25:48 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 01:31:33 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lostanlen", "Vincent", ""], ["Salamon", "Justin", ""], ["Farnsworth", "Andrew", ""], ["Kelling", "Steve", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1905.08360", "submitter": "Daniel Chicharro", "authors": "Daniel Chicharro, Stefano Panzeri, and Ilya Shpitser", "title": "Conditionally-additive-noise Models for Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constraint-based structure learning algorithms infer the causal structure of\nmultivariate systems from observational data by determining an equivalent class\nof causal structures compatible with the conditional independencies in the\ndata. Methods based on additive-noise (AN) models have been proposed to further\ndiscriminate between causal structures that are equivalent in terms of\nconditional independencies. These methods rely on a particular form of the\ngenerative functional equations, with an additive noise structure, which allows\ninferring the directionality of causation by testing the independence between\nthe residuals of a nonlinear regression and the predictors\n(nrr-independencies). Full causal structure identifiability has been proven for\nsystems that contain only additive-noise equations and have no hidden\nvariables. We extend the AN framework in several ways. We introduce alternative\nregression-free tests of independence based on conditional variances\n(cv-independencies). We consider conditionally-additive-noise (CAN) models, in\nwhich the equations may have the AN form only after conditioning. We exploit\nasymmetries in nrr-independencies or cv-independencies resulting from the CAN\nform to derive a criterion that infers the causal relation between a pair of\nvariables in a multivariate system without any assumption about the form of the\nequations or the presence of hidden variables.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 22:06:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Chicharro", "Daniel", ""], ["Panzeri", "Stefano", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1905.08389", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris, Aleksandr Aravkin, Rajesh Rao, Bingni Wen\n  Brunton", "title": "Time-varying Autoregression with Low Rank Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a windowed technique to learn parsimonious time-varying\nautoregressive models from multivariate timeseries. This unsupervised method\nuncovers interpretable spatiotemporal structure in data via non-smooth and\nnon-convex optimization. In each time window, we assume the data follow a\nlinear model parameterized by a system matrix, and we model this stack of\npotentially different system matrices as a low rank tensor. Because of its\nstructure, the model is scalable to high-dimensional data and can easily\nincorporate priors such as smoothness over time. We find the components of the\ntensor using alternating minimization and prove that any stationary point of\nthis algorithm is a local minimum. We demonstrate on a synthetic example that\nour method identifies the true rank of a switching linear system in the\npresence of noise. We illustrate our model's utility and superior scalability\nover extant methods when applied to several synthetic and real-world example:\ntwo types of time-varying linear systems, worm behavior, sea surface\ntemperature, and monkey brain datasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:04:07 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 22:05:09 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Harris", "Kameron Decker", ""], ["Aravkin", "Aleksandr", ""], ["Rao", "Rajesh", ""], ["Brunton", "Bingni Wen", ""]]}, {"id": "1905.08392", "submitter": "Md. Iftekhar Tanveer", "authors": "Md Iftekhar Tanveer, Md Kamrul Hasan, Daniel Gildea, M. Ehsan Hoque", "title": "A Causality-Guided Prediction of the TED Talk Ratings from the\n  Speech-Transcripts using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated prediction of public speaking performance enables novel systems for\ntutoring public speaking skills. We use the largest open repository---TED\nTalks---to predict the ratings provided by the online viewers. The dataset\ncontains over 2200 talk transcripts and the associated meta information\nincluding over 5.5 million ratings from spontaneous visitors to the website. We\ncarefully removed the bias present in the dataset (e.g., the speakers'\nreputations, popularity gained by publicity, etc.) by modeling the data\ngenerating process using a causal diagram. We use a word sequence based\nrecurrent architecture and a dependency tree based recursive architecture as\nthe neural networks for predicting the TED talk ratings. Our neural network\nmodels can predict the ratings with an average F-score of 0.77 which largely\noutperforms the competitive baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:32:21 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Tanveer", "Md Iftekhar", ""], ["Hasan", "Md Kamrul", ""], ["Gildea", "Daniel", ""], ["Hoque", "M. Ehsan", ""]]}, {"id": "1905.08419", "submitter": "Zhao Kang", "authors": "Zhao Kang, Honghui Xu, Boyu Wang, Hongyuan Zhu, Zenglin Xu", "title": "Clustering with Similarity Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based clustering has shown promising performance in many tasks. A key\nstep of graph-based approach is the similarity graph construction. In general,\nlearning graph in kernel space can enhance clustering accuracy due to the\nincorporation of nonlinearity. However, most existing kernel-based graph\nlearning mechanisms is not similarity-preserving, hence leads to sub-optimal\nperformance. To overcome this drawback, we propose a more discriminative graph\nlearning method which can preserve the pairwise similarities between samples in\nan adaptive manner for the first time. Specifically, we require the learned\ngraph be close to a kernel matrix, which serves as a measure of similarity in\nraw data. Moreover, the structure is adaptively tuned so that the number of\nconnected components of the graph is exactly equal to the number of clusters.\nFinally, our method unifies clustering and graph learning which can directly\nobtain cluster indicators from the graph itself without performing further\nclustering step. The effectiveness of this approach is examined on both single\nand multiple kernel learning scenarios in several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 03:11:30 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kang", "Zhao", ""], ["Xu", "Honghui", ""], ["Wang", "Boyu", ""], ["Zhu", "Hongyuan", ""], ["Xu", "Zenglin", ""]]}, {"id": "1905.08443", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Romain Cosentino, Behnaam Aazhang, Richard\n  Baraniuk", "title": "The Geometry of Deep Networks: Power Diagram Subdivision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the geometry of deep (neural) networks (DNs) with piecewise affine\nand convex nonlinearities. The layers of such DNs have been shown to be {\\em\nmax-affine spline operators} (MASOs) that partition their input space and apply\na region-dependent affine mapping to their input to produce their output. We\ndemonstrate that each MASO layer's input space partitioning corresponds to a\n{\\em power diagram} (an extension of the classical Voronoi tiling) with a\nnumber of regions that grows exponentially with respect to the number of units\n(neurons). We further show that a composition of MASO layers (e.g., the entire\nDN) produces a progressively subdivided power diagram and provide its\nanalytical form. The subdivision process constrains the affine maps on the\n(exponentially many) power diagram regions to greatly reduce their complexity.\nFor classification problems, we obtain a formula for a MASO DN's decision\nboundary in the input space plus a measure of its curvature that depends on the\nDN's nonlinearities, weights, and architecture. Numerous numerical experiments\nsupport and extend our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 05:07:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Balestriero", "Randall", ""], ["Cosentino", "Romain", ""], ["Aazhang", "Behnaam", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1905.08448", "submitter": "Kirankumar Shiragur", "authors": "Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "Efficient Profile Maximum Likelihood for Universal Symmetric Property\n  Estimation", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating symmetric properties of a distribution, e.g. support size,\ncoverage, entropy, distance to uniformity, are among the most fundamental\nproblems in algorithmic statistics. While each of these properties have been\nstudied extensively and separate optimal estimators are known for each, in\nstriking recent work, Acharya et al. 2016 showed that there is a single\nestimator that is competitive for all symmetric properties. This work proved\nthat computing the distribution that approximately maximizes \\emph{profile\nlikelihood (PML)}, i.e. the probability of observed frequency of frequencies,\nand returning the value of the property on this distribution is sample\ncompetitive with respect to a broad class of estimators of symmetric\nproperties. Further, they showed that even computing an approximation of the\nPML suffices to achieve such a universal plug-in estimator. Unfortunately,\nprior to this work there was no known polynomial time algorithm to compute an\napproximate PML and it was open to obtain a polynomial time universal plug-in\nestimator through the use of approximate PML. In this paper we provide a\nalgorithm (in number of samples) that, given $n$ samples from a distribution,\ncomputes an approximate PML distribution up to a multiplicative error of\n$\\exp(n^{2/3} \\mathrm{poly} \\log(n))$ in time nearly linear in $n$.\nGeneralizing work of Acharya et al. 2016 on the utility of approximate PML we\nshow that our algorithm provides a nearly linear time universal plug-in\nestimator for all symmetric functions up to accuracy $\\epsilon =\n\\Omega(n^{-0.166})$. Further, we show how to extend our work to provide\nefficient polynomial-time algorithms for computing a $d$-dimensional\ngeneralization of PML (for constant $d$) that allows for universal plug-in\nestimation of symmetric relationships between distributions.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 05:39:05 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "1905.08451", "submitter": "Shuai Yuan", "authors": "Shuai Yuan, Pang-Ning Tan, Kendra Spence Cheruvelil, Sarah M. Collins,\n  Patricia A. Soranno", "title": "Spatially Constrained Spectral Clustering Algorithms for Region\n  Delineation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regionalization is the task of dividing up a landscape into homogeneous\npatches with similar properties. Although this task has a wide range of\napplications, it has two notable challenges. First, it is assumed that the\nresulting regions are both homogeneous and spatially contiguous. Second, it is\nwell-recognized that landscapes are hierarchical such that fine-scale regions\nare nested wholly within broader-scale regions. To address these two\nchallenges, first, we develop a spatially constrained spectral clustering\nframework for region delineation that incorporates the tradeoff between region\nhomogeneity and spatial contiguity. The framework uses a flexible, truncated\nexponential kernel to represent the spatial contiguity constraints, which is\nintegrated with the landscape feature similarity matrix for region delineation.\nTo address the second challenge, we extend the framework to create fine-scale\nregions that are nested within broader-scaled regions using a greedy, recursive\nbisection approach. We present a case study of a terrestrial ecology data set\nin the United States that compares the proposed framework with several baseline\nmethods for regionalization. Experimental results suggest that the proposed\nframework for regionalization outperforms the baseline methods, especially in\nterms of balancing region contiguity and homogeneity, as well as creating\nregions of more similar size, which is often a desired trait of regions.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 05:54:10 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yuan", "Shuai", ""], ["Tan", "Pang-Ning", ""], ["Cheruvelil", "Kendra Spence", ""], ["Collins", "Sarah M.", ""], ["Soranno", "Patricia A.", ""]]}, {"id": "1905.08454", "submitter": "Wei Jiang", "authors": "Wei Jiang and Yan Tang", "title": "A Seq-to-Seq Transformer Premised Temporal Convolutional Network for\n  Chinese Word Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalent approaches of Chinese word segmentation task almost rely on the\nBi-LSTM neural network. However, the methods based the Bi-LSTM have some\ninherent drawbacks: hard to parallel computing, little efficient in applying\nthe Dropout method to inhibit the Overfitting and little efficient in capturing\nthe character information at the more distant site of a long sentence for the\nword segmentation task. In this work, we propose a sequence-to-sequence\ntransformer model for Chinese word segmentation, which is premised a type of\nconvolutional neural network named temporal convolutional network. The model\nuses the temporal convolutional network to construct an encoder, and uses one\nlayer of fully-connected neural network to build a decoder, and applies the\nDropout method to inhibit the Overfitting, and captures the character\ninformation at the distant site of a sentence by adding the layers of the\nencoder, and binds Conditional Random Fields model to train parameters, and\nuses the Viterbi algorithm to infer the final result of the Chinese word\nsegmentation. The experiments on traditional Chinese corpora and simplified\nChinese corpora show that the performance of Chinese word segmentation of the\nmodel is equivalent to the performance of the methods based the Bi-LSTM, and\nthe model has a tremendous growth in parallel computing than the models based\nthe Bi-LSTM.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 06:12:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Jiang", "Wei", ""], ["Tang", "Yan", ""]]}, {"id": "1905.08459", "submitter": "Wei Ping", "authors": "Kainan Peng, Wei Ping, Zhao Song, Kexin Zhao", "title": "Non-Autoregressive Neural Text-to-Speech", "comments": "Published at ICML 2020. (v3 changed paper title)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose ParaNet, a non-autoregressive seq2seq model that\nconverts text to spectrogram. It is fully convolutional and brings 46.7 times\nspeed-up over the lightweight Deep Voice 3 at synthesis, while obtaining\nreasonably good speech quality. ParaNet also produces stable alignment between\ntext and speech on the challenging test sentences by iteratively improving the\nattention in a layer-by-layer manner. Furthermore, we build the parallel\ntext-to-speech system and test various parallel neural vocoders, which can\nsynthesize speech from text through a single feed-forward pass. We also explore\na novel VAE-based approach to train the inverse autoregressive flow (IAF) based\nparallel vocoder from scratch, which avoids the need for distillation from a\nseparately trained WaveNet as previous work.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 06:36:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 21:28:26 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 20:15:59 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Peng", "Kainan", ""], ["Ping", "Wei", ""], ["Song", "Zhao", ""], ["Zhao", "Kexin", ""]]}, {"id": "1905.08464", "submitter": "Pavel Gurevich", "authors": "Pavel Gurevich, Hannes Stuke", "title": "Robustness Against Outliers For Deep Neural Networks By Gradient\n  Conjugate Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new robust method for the reconstruction of probability\ndistributions of observed data in the presence of output outliers. It is based\non a so-called gradient conjugate prior (GCP) network which outputs the\nparameters of a prior. By rigorously studying the dynamics of the GCP learning\nprocess, we derive an explicit formula for correcting the obtained variance of\nthe marginal distribution and removing the bias caused by outliers in the\ntraining set. Assuming a Gaussian (input-dependent) ground truth distribution\ncontaminated with a proportion $\\varepsilon$ of outliers, we show that the\nfitted mean is in a $c e^{-1/\\varepsilon}$-neighborhood of the ground truth\nmean and the corrected variance is in a $b\\varepsilon$-neighborhood of the\nground truth variance, whereas the uncorrected variance of the marginal\ndistribution can even be infinite. We explicitly find $b$ as a function of the\noutput of the GCP network, without a priori knowledge of the outliers (possibly\ninput-dependent) distribution. Experiments with synthetic and real-world data\nsets indicate that the GCP network fitted with a standard optimizer outperforms\nother robust methods for regression.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 07:10:16 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Gurevich", "Pavel", ""], ["Stuke", "Hannes", ""]]}, {"id": "1905.08486", "submitter": "Eunwoo Song", "authors": "Ohsung Kwon, Eunwoo Song, Jae-Min Kim, Hong-Goo Kang", "title": "Effective parameter estimation methods for an ExcitNet model in\n  generative text-to-speech systems", "comments": "5 pages, 3 figures, 3 tables, submitted to Speech Synthesis Workshop\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a high-quality generative text-to-speech (TTS)\nsystem using an effective spectrum and excitation estimation method. Our\nprevious research verified the effectiveness of the ExcitNet-based speech\ngeneration model in a parametric TTS framework. However, the challenge remains\nto build a high-quality speech synthesis system because auxiliary conditional\nfeatures estimated by a simple deep neural network often contain large\nprediction errors, and the errors are inevitably propagated throughout the\nautoregressive generation process of the ExcitNet vocoder. To generate more\nnatural speech signals, we exploited a sequence-to-sequence (seq2seq) acoustic\nmodel with an attention-based generative network (e.g., Tacotron 2) to estimate\nthe condition parameters of the ExcitNet vocoder. Because the seq2seq acoustic\nmodel accurately estimates spectral parameters, and because the ExcitNet model\neffectively generates the corresponding time-domain excitation signals,\ncombining these two models can synthesize natural speech signals. Furthermore,\nwe verified the merit of the proposed method in producing expressive speech\nsegments by adopting a global style token-based emotion embedding method. The\nexperimental results confirmed that the proposed system significantly\noutperforms the systems with a similarly configured conventional WaveNet\nvocoder and our best prior parametric TTS counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:24:06 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kwon", "Ohsung", ""], ["Song", "Eunwoo", ""], ["Kim", "Jae-Min", ""], ["Kang", "Hong-Goo", ""]]}, {"id": "1905.08494", "submitter": "Patrick Kidger", "authors": "Patric Bonnier and Patrick Kidger and Imanol Perez Arribas and\n  Cristopher Salvi and Terry Lyons", "title": "Deep Signature Transforms", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The signature is an infinite graded sequence of statistics known to\ncharacterise a stream of data up to a negligible equivalence class. It is a\ntransform which has previously been treated as a fixed feature transformation,\non top of which a model may be built. We propose a novel approach which\ncombines the advantages of the signature transform with modern deep learning\nframeworks. By learning an augmentation of the stream prior to the signature\ntransform, the terms of the signature may be selected in a data-dependent way.\nMore generally, we describe how the signature transform may be used as a layer\nanywhere within a neural network. In this context it may be interpreted as a\npooling operation. We present the results of empirical experiments to back up\nthe theoretical justification. Code available at\nhttps://github.com/patrick-kidger/Deep-Signature-Transforms.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:39:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 20:51:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bonnier", "Patric", ""], ["Kidger", "Patrick", ""], ["Arribas", "Imanol Perez", ""], ["Salvi", "Cristopher", ""], ["Lyons", "Terry", ""]]}, {"id": "1905.08495", "submitter": "Mengxiao Hu", "authors": "Mengxiao Hu, Jinlong Li", "title": "Exploring Bias in GAN-based Data Augmentation for Small Samples", "comments": "rejected by SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning task, lacking sufficient samples mean the trained model\nhas low confidence to approach the ground truth function. Until recently, after\nthe generative adversarial networks (GAN) had been proposed, we see the hope of\nsmall samples data augmentation (DA) with realistic fake data, and many works\nvalidated the viability of GAN-based DA. Although most of the works pointed out\nhigher accuracy can be achieved using GAN-based DA, some researchers stressed\nthat the fake data generated from GAN has inherent bias, and in this paper, we\nexplored when the bias is so low that it cannot hurt the performance, we set\nexperiments to depict the bias in different GAN-based DA setting, and from the\nresults, we design a pipeline to inspect specific dataset is\nefficiently-augmentable with GAN-based DA or not. And finally, depending on our\ntrial to reduce the bias, we proposed some advice to mitigate bias in GAN-based\nDA application.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:40:42 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Hu", "Mengxiao", ""], ["Li", "Jinlong", ""]]}, {"id": "1905.08500", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Evan Lohn, Pieter Abbeel", "title": "Compression with Flows via Local Bits-Back Coding", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-based generative models are the backbones of lossless compression\ndue to the guaranteed existence of codes with lengths close to negative log\nlikelihood. However, there is no guaranteed existence of computationally\nefficient codes that achieve these lengths, and coding algorithms must be\nhand-tailored to specific types of generative models to ensure computational\nefficiency. Such coding algorithms are known for autoregressive models and\nvariational autoencoders, but not for general types of flow models. To fill in\nthis gap, we introduce local bits-back coding, a new compression technique for\nflow models. We present efficient algorithms that instantiate our technique for\nmany popular types of flows, and we demonstrate that our algorithms closely\nachieve theoretical codelengths for state-of-the-art flow models on\nhigh-dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:45:45 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 23:31:43 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 04:22:02 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ho", "Jonathan", ""], ["Lohn", "Evan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1905.08501", "submitter": "Yosuke Kaga", "authors": "Yosuke Kaga, Masakazu Fujio, Kenta Takahashi, Tetsushi Ohki, Masakatsu\n  Nishigaki", "title": "PDH : Probabilistic deep hashing based on MAP estimation of Hamming\n  distance", "comments": "Accepted by the 26th IEEE International Conference on Image\n  Processing(ICIP2019)", "journal-ref": "2019 26th IEEE International Conference on Image Processing (ICIP)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of image on the web, research on hashing which enables\nhigh-speed image retrieval has been actively studied. In recent years, various\nhashing methods based on deep neural networks have been proposed and achieved\nhigher precision than the other hashing methods. In these methods, multiple\nlosses for hash codes and the parameters of neural networks are defined. They\ngenerate hash codes that minimize the weighted sum of the losses. Therefore, an\nexpert has to tune the weights for the losses heuristically, and the\nprobabilistic optimality of the loss function cannot be explained. In order to\ngenerate explainable hash codes without weight tuning, we theoretically derive\na single loss function with no hyperparameters for the hash code from the\nprobability distribution of the images. By generating hash codes that minimize\nthis loss function, highly accurate image retrieval with probabilistic\noptimality is performed. We evaluate the performance of hashing using MNIST,\nCIFAR-10, SVHN and show that the proposed method outperforms the\nstate-of-the-art hashing methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:51:02 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kaga", "Yosuke", ""], ["Fujio", "Masakazu", ""], ["Takahashi", "Kenta", ""], ["Ohki", "Tetsushi", ""], ["Nishigaki", "Masakatsu", ""]]}, {"id": "1905.08503", "submitter": "Corrado Possieri", "authors": "Giuseppe C. Calafiore, Stephane Gaubert, Member and Corrado Possieri", "title": "A Universal Approximation Result for Difference of log-sum-exp Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a neural network whose output is obtained as the difference of\nthe outputs of two feedforward networks with exponential activation function in\nthe hidden layer and logarithmic activation function in the output node (LSE\nnetworks) is a smooth universal approximator of continuous functions over\nconvex, compact sets. By using a logarithmic transform, this class of networks\nmaps to a family of subtraction-free ratios of generalized posynomials, which\nwe also show to be universal approximators of positive functions over\nlog-convex, compact subsets of the positive orthant. The main advantage of\nDifference-LSE networks with respect to classical feedforward neural networks\nis that, after a standard training phase, they provide surrogate models for\ndesign that possess a specific difference-of-convex-functions form, which makes\nthem optimizable via relatively efficient numerical methods. In particular, by\nadapting an existing difference-of-convex algorithm to these models, we obtain\nan algorithm for performing effective optimization-based design. We illustrate\nthe proposed approach by applying it to data-driven design of a diet for a\npatient with type-2 diabetes.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:54:21 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Gaubert", "Stephane", ""], ["Member", "", ""], ["Possieri", "Corrado", ""]]}, {"id": "1905.08506", "submitter": "Jiapeng Liu", "authors": "Jiapeng Liu, Milosz Kadzinski, Xiuwu Liao, Xiaoxin Mao", "title": "Data-driven preference learning methods for value-driven multiple\n  criteria sorting with interacting criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of predictive models for data-driven decision support has been a\nprevalent topic in many fields. However, construction of models that would\ncapture interactions among input variables is a challenging task. In this\npaper, we present a new preference learning approach for multiple criteria\nsorting with potentially interacting criteria. It employs an additive\npiecewise-linear value function as the basic preference model, which is\naugmented with components for handling the interactions. To construct such a\nmodel from a given set of assignment examples concerning reference\nalternatives, we develop a convex quadratic programming model. Since its\ncomplexity does not depend on the number of training samples, the proposed\napproach is capable for dealing with data-intensive tasks. To improve the\ngeneralization of the constructed model on new instances and to overcome the\nproblem of over-fitting, we employ the regularization techniques. We also\npropose a few novel methods for classifying non-reference alternatives in order\nto enhance the applicability of our approach to different datasets. The\npractical usefulness of the proposed method is demonstrated on a problem of\nparametric evaluation of research units, whereas its predictive performance is\nstudied on several monotone learning datasets. The experimental results\nindicate that our approach compares favourably with the classical UTADIS method\nand the Choquet integral-based sorting model.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:08:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Liu", "Jiapeng", ""], ["Kadzinski", "Milosz", ""], ["Liao", "Xiuwu", ""], ["Mao", "Xiaoxin", ""]]}, {"id": "1905.08509", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Rui Bu, Mingchao Sun", "title": "Mutual Information Maximization in Graph Neural Networks", "comments": "Accepted for presentation at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of graph neural networks (GNNs) frameworks for representation\nlearning on graphs have been recently developed. These frameworks rely on\naggregation and iteration scheme to learn the representation of nodes. However,\ninformation between nodes is inevitably lost in the scheme during learning. In\norder to reduce the loss, we extend the GNNs frameworks by exploring the\naggregation and iteration scheme in the methodology of mutual information. We\npropose a new approach of enlarging the normal neighborhood in the aggregation\nof GNNs, which aims at maximizing mutual information. Based on a series of\nexperiments conducted on several benchmark datasets, we show that the proposed\napproach improves the state-of-the-art performance for four types of graph\ntasks, including supervised and semi-supervised graph classification, graph\nlink prediction and graph edge generation and classification.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:15:10 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 07:42:49 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 04:42:31 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 02:54:08 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Bu", "Rui", ""], ["Sun", "Mingchao", ""]]}, {"id": "1905.08513", "submitter": "Ce Ju", "authors": "Ce Ju", "title": "Stochastic Inverse Reinforcement Learning", "comments": "8+2 pages, 5 figures, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the inverse reinforcement learning (IRL) problem is to recover\nthe reward functions from expert demonstrations. However, the IRL problem like\nany ill-posed inverse problem suffers the congenital defect that the policy may\nbe optimal for many reward functions, and expert demonstrations may be optimal\nfor many policies. In this work, we generalize the IRL problem to a well-posed\nexpectation optimization problem stochastic inverse reinforcement learning\n(SIRL) to recover the probability distribution over reward functions. We adopt\nthe Monte Carlo expectation-maximization (MCEM) method to estimate the\nparameter of the probability distribution as the first solution to the SIRL\nproblem. The solution is succinct, robust, and transferable for a learning task\nand can generate alternative solutions to the IRL problem. Through our\nformulation, it is possible to observe the intrinsic property for the IRL\nproblem from a global viewpoint, and our approach achieves a considerable\nperformance on the objectworld.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:29:18 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:11:46 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 08:55:28 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 11:31:49 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 06:48:32 GMT"}, {"version": "v6", "created": "Wed, 9 Sep 2020 07:47:59 GMT"}, {"version": "v7", "created": "Fri, 11 Sep 2020 03:42:17 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ju", "Ce", ""]]}, {"id": "1905.08527", "submitter": "Roberto Dess\\'i", "authors": "Roberto Dess\\`i and Marco Baroni", "title": "CNNs found to jump around more skillfully than RNNs: Compositional\n  generalization in seq2seq convolutional networks", "comments": "accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lake and Baroni (2018) introduced the SCAN dataset probing the ability of\nseq2seq models to capture compositional generalizations, such as inferring the\nmeaning of \"jump around\" 0-shot from the component words. Recurrent networks\n(RNNs) were found to completely fail the most challenging generalization cases.\nWe test here a convolutional network (CNN) on these tasks, reporting hugely\nimproved performance with respect to RNNs. Despite the big improvement, the CNN\nhas however not induced systematic rules, suggesting that the difference\nbetween compositional and non-compositional behaviour is not clear-cut.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:14:12 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.08537", "submitter": "Shinichi Shirakawa", "authors": "Youhei Akimoto, Shinichi Shirakawa, Nozomu Yoshinari, Kento Uchida,\n  Shota Saito, Kouhei Nishida", "title": "Adaptive Stochastic Natural Gradient Method for One-Shot Neural\n  Architecture Search", "comments": "Accepted to ICML 2019. Code is available at\n  https://github.com/shirakawas/ASNG-NAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High sensitivity of neural architecture search (NAS) methods against their\ninput such as step-size (i.e., learning rate) and search space prevents\npractitioners from applying them out-of-the-box to their own problems, albeit\nits purpose is to automate a part of tuning process. Aiming at a fast, robust,\nand widely-applicable NAS, we develop a generic optimization framework for NAS.\nWe turn a coupled optimization of connection weights and neural architecture\ninto a differentiable optimization by means of stochastic relaxation. It\naccepts arbitrary search space (widely-applicable) and enables to employ a\ngradient-based simultaneous optimization of weights and architecture (fast). We\npropose a stochastic natural gradient method with an adaptive step-size\nmechanism built upon our theoretical investigation (robust). Despite its\nsimplicity and no problem-dependent parameter tuning, our method exhibited near\nstate-of-the-art performances with low computational budgets both on image\nclassification and inpainting tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:39:04 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Akimoto", "Youhei", ""], ["Shirakawa", "Shinichi", ""], ["Yoshinari", "Nozomu", ""], ["Uchida", "Kento", ""], ["Saito", "Shota", ""], ["Nishida", "Kouhei", ""]]}, {"id": "1905.08539", "submitter": "Patrick Kidger", "authors": "Patrick Kidger and Terry Lyons", "title": "Universal Approximation with Deep Narrow Networks", "comments": "Accepted at COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Universal Approximation Theorem holds for neural networks of\narbitrary width and bounded depth. Here we consider the natural `dual' scenario\nfor networks of bounded width and arbitrary depth. Precisely, let $n$ be the\nnumber of inputs neurons, $m$ be the number of output neurons, and let $\\rho$\nbe any nonaffine continuous function, with a continuous nonzero derivative at\nsome point. Then we show that the class of neural networks of arbitrary depth,\nwidth $n + m + 2$, and activation function $\\rho$, is dense in $C(K;\n\\mathbb{R}^m)$ for $K \\subseteq \\mathbb{R}^n$ with $K$ compact. This covers\nevery activation function possible to use in practice, and also includes\npolynomial activation functions, which is unlike the classical version of the\ntheorem, and provides a qualitative difference between deep narrow networks and\nshallow wide networks. We then consider several extensions of this result. In\nparticular we consider nowhere differentiable activation functions, density in\nnoncompact domains with respect to the $L^p$-norm, and how the width may be\nreduced to just $n + m + 1$ for `most' activation functions.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:47:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:08:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kidger", "Patrick", ""], ["Lyons", "Terry", ""]]}, {"id": "1905.08547", "submitter": "Sebastiano Barbieri", "authors": "Sebastiano Barbieri, James Kemp, Oscar Perez-Concha, Sradha Kotwal,\n  Martin Gallagher, Angus Ritchie, Louisa Jorm", "title": "Benchmarking Deep Learning Architectures for Predicting Readmission to\n  the ICU and Describing Patients-at-Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To compare different deep learning architectures for predicting\nthe risk of readmission within 30 days of discharge from the intensive care\nunit (ICU). The interpretability of attention-based models is leveraged to\ndescribe patients-at-risk. Methods: Several deep learning architectures making\nuse of attention mechanisms, recurrent layers, neural ordinary differential\nequations (ODEs), and medical concept embeddings with time-aware attention were\ntrained using publicly available electronic medical record data (MIMIC-III)\nassociated with 45,298 ICU stays for 33,150 patients. Bayesian inference was\nused to compute the posterior over weights of an attention-based model. Odds\nratios associated with an increased risk of readmission were computed for\nstatic variables. Diagnoses, procedures, medications, and vital signs were\nranked according to the associated risk of readmission. Results: A recurrent\nneural network, with time dynamics of code embeddings computed by neural ODEs,\nachieved the highest average precision of 0.331 (AUROC: 0.739, F1-Score:\n0.372). Predictive accuracy was comparable across neural network architectures.\nGroups of patients at risk included those suffering from infectious\ncomplications, with chronic or progressive conditions, and for whom standard\nmedical care was not suitable. Conclusions: Attention-based networks may be\npreferable to recurrent networks if an interpretable model is required, at only\nmarginal cost in predictive accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:08:31 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 23:11:24 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 00:12:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Barbieri", "Sebastiano", ""], ["Kemp", "James", ""], ["Perez-Concha", "Oscar", ""], ["Kotwal", "Sradha", ""], ["Gallagher", "Martin", ""], ["Ritchie", "Angus", ""], ["Jorm", "Louisa", ""]]}, {"id": "1905.08550", "submitter": "Xiaoting Shao", "authors": "Xiaoting Shao, Alejandro Molina, Antonio Vergari, Karl Stelzner,\n  Robert Peharz, Thomas Liebig, and Kristian Kersting", "title": "Conditional Sum-Product Networks: Imposing Structure on Deep\n  Probabilistic Architectures", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are a central tool in AI; however, they are\ngenerally not as expressive as deep neural models, and inference is notoriously\nhard and slow. In contrast, deep probabilistic models such as sum-product\nnetworks (SPNs) capture joint distributions in a tractable fashion, but still\nlack the expressive power of intractable models based on deep neural networks.\nTherefore, we introduce conditional SPNs (CSPNs), conditional density\nestimators for multivariate and potentially hybrid domains which allow\nharnessing the expressive power of neural networks while still maintaining\ntractability guarantees. One way to implement CSPNs is to use an existing SPN\nstructure and condition its parameters on the input, e.g., via a deep neural\nnetwork. This approach, however, might misrepresent the conditional\nindependence structure present in data. Consequently, we also develop a\nstructure-learning approach that derives both the structure and parameters of\nCSPNs from data. Our experimental evidence demonstrates that CSPNs are\ncompetitive with other probabilistic models and yield superior performance on\nmultilabel image classification compared to mean field and mixture density\nnetworks. Furthermore, they can successfully be employed as building blocks for\nstructured probabilistic models, such as autoregressive image models.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:13:17 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 11:41:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Shao", "Xiaoting", ""], ["Molina", "Alejandro", ""], ["Vergari", "Antonio", ""], ["Stelzner", "Karl", ""], ["Peharz", "Robert", ""], ["Liebig", "Thomas", ""], ["Kersting", "Kristian", ""]]}, {"id": "1905.08557", "submitter": "Liming Shi", "authors": "Liming Shi, Jesper Kjaer Nielsen, Jesper Rindom Jensen, Max A. Little,\n  Mads Graesboll Christensen", "title": "Bayesian Pitch Tracking Based on the Harmonic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental frequency is one of the most important characteristics of speech\nand audio signals. Harmonic model-based fundamental frequency estimators offer\na higher estimation accuracy and robustness against noise than the widely used\nautocorrelation-based methods. However, the traditional harmonic model-based\nestimators do not take the temporal smoothness of the fundamental frequency,\nthe model order, and the voicing into account as they process each data segment\nindependently. In this paper, a fully Bayesian fundamental frequency tracking\nalgorithm based on the harmonic model and a first-order Markov process model is\nproposed. Smoothness priors are imposed on the fundamental frequencies, model\norders, and voicing using first-order Markov process models. Using these Markov\nmodels, fundamental frequency estimation and voicing detection errors can be\nreduced. Using the harmonic model, the proposed fundamental frequency tracker\nhas an improved robustness to noise. An analytical form of the likelihood\nfunction, which can be computed efficiently, is derived. Compared to the\nstate-of-the-art neural network and non-parametric approaches, the proposed\nfundamental frequency tracking algorithm reduces the mean absolute errors and\ngross errors by 15\\% and 20\\% on the Keele pitch database and 36\\% and 26\\% on\nsustained /a/ sounds from a database of Parkinson's disease voices under 0 dB\nwhite Gaussian noise. A MATLAB version of the proposed algorithm is made freely\navailable for reproduction of the results\\footnote{An implementation of the\nproposed algorithm using MATLAB may be found in\n\\url{https://tinyurl.com/yxn4a543}\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:24:16 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Shi", "Liming", ""], ["Nielsen", "Jesper Kjaer", ""], ["Jensen", "Jesper Rindom", ""], ["Little", "Max A.", ""], ["Christensen", "Mads Graesboll", ""]]}, {"id": "1905.08575", "submitter": "Ahmad Mani-Varnosfaderani Dr.", "authors": "Ahmad Mani-Varnosfaderani and Mohammad Javad Masroor", "title": "Exploring the effects of Lx-norm penalty terms in multivariate curve\n  resolution methods for resolving LC/GC-MS data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are different problems for resolution of complex LC-MS or GC-MS data,\nsuch as the existence of embedded chromatographic peaks, continuum background\nand overlapping in mass channels for different components. These problems cause\nrotational ambiguity in recovered profiles calculated using multivariate curve\nresolution (MCR) methods. Since mass spectra are sparse in nature, sparsity has\nbeen proposed recently as a constraint in MCR methods for analyzing LC-MS data.\nThere are different ways for implementation of the sparsity constraint, and\nmajority of methods rely on imposing a penalty based on the L0-, L1- and\nL2-norms of recovered mass spectra. Ridge regression and least absolute\nshrinkage and selection operator (Lasso) can be used for implementation of L2-\nand L1-norm penalties in MCR, respectively. The main question is which Lx-norm\npenalty is more worthwhile for implementation of the sparsity constraint in MCR\nmethods. In order to address this question, two and three component LC-MS data\nwere simulated and used for the case study in this work. The areas of feasible\nsolutions (AFS) were calculated using the grid search strategy. Calculating\nLx-norms values in AFS for x between zero and two revealed that the gradient of\noptimization surface increased from x values equal to two to x values near\nzero. However, for x equal to zero, the optimization surface was similar to a\nplateau, which increased the risk of sticking in local minima. Generally,\nresults in this work, recommend the use of L1-norm penalty methods like Lasso\nfor implementation of sparsity constraint in MCR-ALS algorithm for finding more\nsparse solutions and reducing the extent of rotational ambiguity.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 12:20:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Mani-Varnosfaderani", "Ahmad", ""], ["Masroor", "Mohammad Javad", ""]]}, {"id": "1905.08594", "submitter": "Salimeh Yasaei Sekeh", "authors": "Salimeh Yasaei Sekeh and Alfred O. Hero", "title": "Geometric Estimation of Multivariate Dependency", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": "10.3390/e21080787", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a geometric estimator of dependency between a pair of\nmultivariate samples. The proposed estimator of dependency is based on a\nrandomly permuted geometric graph (the minimal spanning tree) over the two\nmultivariate samples. This estimator converges to a quantity that we call the\ngeometric mutual information (GMI), which is equivalent to the Henze-Penrose\ndivergence [1] between the joint distribution of the multivariate samples and\nthe product of the marginals. The GMI has many of the same properties as\nstandard MI but can be estimated from empirical data without density\nestimation; making it scalable to large datasets. The proposed empirical\nestimator of GMI is simple to implement, involving the construction of an MST\nspanning over both the original data and a randomly permuted version of this\ndata. We establish asymptotic convergence of the estimator and convergence\nrates of the bias and variance for smooth multivariate density functions\nbelonging to a H\\\"{o}lder class. We demonstrate the advantages of our proposed\ngeometric dependency estimator in a series of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 12:59:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Sekeh", "Salimeh Yasaei", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1905.08604", "submitter": "Takaharu Yaguchi", "authors": "Takashi Matsubara, Ai Ishikawa and Takaharu Yaguchi", "title": "Deep Energy-Based Modeling of Discrete-Time Physics", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS2020) as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical phenomena in the real world are often described by energy-based\nmodeling theories, such as Hamiltonian mechanics or the Landau theory, which\nyield various physical laws. Recent developments in neural networks have\nenabled the mimicking of the energy conservation law by learning the underlying\ncontinuous-time differential equations. However, this may not be possible in\ndiscrete time, which is often the case in practical learning and computation.\nMoreover, other physical laws have been overlooked in the previous neural\nnetwork models. In this study, we propose a deep energy-based physical model\nthat admits a specific differential geometric structure. From this structure,\nthe conservation or dissipation law of energy and the mass conservation law\nfollow naturally. To ensure the energetic behavior in discrete time, we also\npropose an automatic discrete differential algorithm that enables neural\nnetworks to employ the discrete gradient method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:21:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 04:24:08 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 10:02:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Matsubara", "Takashi", ""], ["Ishikawa", "Ai", ""], ["Yaguchi", "Takaharu", ""]]}, {"id": "1905.08611", "submitter": "Soumick Chatterjee", "authors": "Rupali Khatun and Soumick Chatterjee", "title": "Machine learning approach for segmenting glands in colon histology\n  images using local intensity and texture features", "comments": null, "journal-ref": "8th International Advance Computing Conference (IACC), 2018", "doi": "10.1109/IADCC.2018.8692135", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colon Cancer is one of the most common types of cancer. The treatment is\nplanned to depend on the grade or stage of cancer. One of the preconditions for\ngrading of colon cancer is to segment the glandular structures of tissues.\nManual segmentation method is very time-consuming, and it leads to life risk\nfor the patients. The principal objective of this project is to assist the\npathologist to accurate detection of colon cancer. In this paper, the authors\nhave proposed an algorithm for an automatic segmentation of glands in colon\nhistology using local intensity and texture features. Here the dataset images\nare cropped into patches with different window sizes and taken the intensity of\nthose patches, and also calculated texture-based features. Random forest\nclassifier has been used to classify this patch into different labels. A\nmultilevel random forest technique in a hierarchical way is proposed. This\nsolution is fast, accurate and it is very much applicable in a clinical setup.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:40:14 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Khatun", "Rupali", ""], ["Chatterjee", "Soumick", ""]]}, {"id": "1905.08612", "submitter": "Mohamed Nafzi", "authors": "Mohamed Nafzi and Michael Brauckmann and Tobias Glasmachers", "title": "Vehicle Shape and Color Classification Using Convolutional Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a module of vehicle reidentification based on make/model\nand color classification. It could be used by the Automated Vehicular\nSurveillance (AVS) or by the fast analysis of video data. Many of problems,\nthat are related to this topic, had to be addressed. In order to facilitate and\naccelerate the progress in this subject, we will present our way to collect and\nto label a large scale data set. We used deeper neural networks in our\ntraining. They showed a good classification accuracy. We show the results of\nmake/model and color classification on controlled and video data set. We\ndemonstrate with the help of a developed application the re-identification of\nvehicles on video images based on make/model and color classification. This\nwork was partially funded under the grant.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:10:18 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Nafzi", "Mohamed", ""], ["Brauckmann", "Michael", ""], ["Glasmachers", "Tobias", ""]]}, {"id": "1905.08613", "submitter": "Cyprien Ruffino", "authors": "Cyprien Ruffino (LITIS, INSA Rouen Normandie, NU), Romain H\\'erault\n  (DocApp - LITIS), Eric Laloy (SCK-CEN), Gilles Gasso (LITIS)", "title": "Dilated Spatial Generative Adversarial Networks for Ergodic Image\n  Generation", "comments": null, "journal-ref": "Conf{\\'e}rence sur l'Apprentissage Automatique, Jun 2018, Rouen,\n  France", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have recently received renewed attention as a result of\nadversarial learning. Generative adversarial networks consist of samples\ngeneration model and a discrimination model able to distinguish between genuine\nand synthetic samples. In combination with convolutional (for the\ndiscriminator) and de-convolutional (for the generator) layers, they are\nparticularly suitable for image generation, especially of natural scenes.\nHowever, the presence of fully connected layers adds global dependencies in the\ngenerated images. This may lead to high and global variations in the generated\nsample for small local variations in the input noise. In this work we propose\nto use architec-tures based on fully convolutional networks (including among\nothers dilated layers), architectures specifically designed to generate\nglobally ergodic images, that is images without global dependencies. Conducted\nexperiments reveal that these architectures are well suited for generating\nnatural textures such as geologic structures .\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:12:53 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Ruffino", "Cyprien", "", "LITIS, INSA Rouen Normandie, NU"], ["H\u00e9rault", "Romain", "", "DocApp - LITIS"], ["Laloy", "Eric", "", "SCK-CEN"], ["Gasso", "Gilles", "", "LITIS"]]}, {"id": "1905.08615", "submitter": "Hiroshi Kaizuka", "authors": "Hiroshi Kaizuka, Yasuhiro Nagasaki, Ryo Sako", "title": "ROI Regularization for Semi-supervised and Supervised Learning", "comments": "14 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ROI regularization (ROIreg) as a semi-supervised learning method\nfor image classification. ROIreg focuses on the maximum probability of a\nposterior probability distribution g(x) obtained when inputting an unlabeled\ndata sample x into a convolutional neural network (CNN). ROIreg divides the\npixel set of x into multiple blocks and evaluates, for each block, its\ncontribution to the maximum probability. A masked data sample x_ROI is\ngenerated by replacing blocks with relatively small degrees of contribution\nwith random images. Then, ROIreg trains CNN so that g(x_ROI ) does not change\nas much as possible from g(x). Therefore, ROIreg can be said to refine the\nclassification ability of CNN more. On the other hand, Virtual Adverserial\nTraining (VAT), which is an excellent semi-supervised learning method,\ngenerates data sample x_VAT by perturbing x in the direction in which g(x)\nchanges most. Then, VAT trains CNN so that g(x_VAT ) does not change from g(x)\nas much as possible. Therefore, VAT can be said to be a method to improve CNN's\nweakness. Thus, ROIreg and VAT have complementary training effects. In fact,\nthe combination of VAT and ROIreg improves the results obtained when using VAT\nor ROIreg alone. This combination also improves the state-of-the-art on \"SVHN\nwith and without data augmentation\" and \"CIFAR-10 without data augmentation\".\nWe also propose a method called ROI augmentation (ROIaug) as a method to apply\nROIreg to data augmentation in supervised learning. However, the evaluation\nfunction used there is different from the standard cross-entropy. ROIaug\nimproves the performance of supervised learning for both SVHN and CIFAR-10.\nFinally, we investigate the performance degradation of VAT and VAT+ROIreg when\ndata samples not belonging to classification classes are included in unlabeled\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:54:24 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kaizuka", "Hiroshi", ""], ["Nagasaki", "Yasuhiro", ""], ["Sako", "Ryo", ""]]}, {"id": "1905.08616", "submitter": "Alex Wong", "authors": "Alex Wong, Xiaohan Fei, Stephanie Tsuei, Stefano Soatto", "title": "Unsupervised Depth Completion from Visual Inertial Odometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe a method to infer dense depth from camera motion and sparse depth\nas estimated using a visual-inertial odometry system. Unlike other scenarios\nusing point clouds from lidar or structured light sensors, we have few hundreds\nto few thousand points, insufficient to inform the topology of the scene. Our\nmethod first constructs a piecewise planar scaffolding of the scene, and then\nuses it to infer dense depth using the image along with the sparse points. We\nuse a predictive cross-modal criterion, akin to `self-supervision,' measuring\nphotometric consistency across time, forward-backward pose consistency, and\ngeometric compatibility with the sparse point cloud. We also launch the first\nvisual-inertial + depth dataset, which we hope will foster additional\nexploration into combining the complementary strengths of visual and inertial\nsensors. To compare our method to prior work, we adopt the unsupervised KITTI\ndepth completion benchmark, and show state-of-the-art performance on it. Code\navailable at:\nhttps://github.com/alexklwong/unsupervised-depth-completion-visual-inertial-odometry.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 03:47:18 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 23:20:01 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 03:51:28 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 11:21:08 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wong", "Alex", ""], ["Fei", "Xiaohan", ""], ["Tsuei", "Stephanie", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.08622", "submitter": "Mingyuan Zhou", "authors": "Hao Zhang, Bo Chen, Long Tian, Zhengjue Wang, Mingyuan Zhou", "title": "Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For bidirectional joint image-text modeling, we develop variational\nhetero-encoder (VHE) randomized generative adversarial network (GAN), a\nversatile deep generative model that integrates a probabilistic text decoder,\nprobabilistic image encoder, and GAN into a coherent end-to-end multi-modality\nlearning framework. VHE randomized GAN (VHE-GAN) encodes an image to decode its\nassociated text, and feeds the variational posterior as the source of\nrandomness into the GAN image generator. We plug three off-the-shelf modules,\nincluding a deep topic model, a ladder-structured image encoder, and\nStackGAN++, into VHE-GAN, which already achieves competitive performance. This\nfurther motivates the development of VHE-raster-scan-GAN that generates\nphoto-realistic images in not only a multi-scale low-to-high-resolution manner,\nbut also a hierarchical-semantic coarse-to-fine fashion. By capturing and\nrelating hierarchical semantic and visual concepts with end-to-end training,\nVHE-raster-scan-GAN achieves state-of-the-art performance in a wide variety of\nimage-text multi-modality learning and generation tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:58:12 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:43:14 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 20:51:34 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Bo", ""], ["Tian", "Long", ""], ["Wang", "Zhengjue", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.08628", "submitter": "Bob Stienen", "authors": "Sascha Caron, Tom Heskes, Sydney Otten and Bob Stienen", "title": "Constraining the Parameters of High-Dimensional Models with Active\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1140/epjc/s10052-019-7437-5", "report-no": null, "categories": "cs.LG astro-ph.IM hep-ex hep-ph hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraining the parameters of physical models with $>5-10$ parameters is a\nwidespread problem in fields like particle physics and astronomy. The\ngeneration of data to explore this parameter space often requires large amounts\nof computational resources. The commonly used solution of reducing the number\nof relevant physical parameters hampers the generality of the results. In this\npaper we show that this problem can be alleviated by the use of active\nlearning. We illustrate this with examples from high energy physics, a field\nwhere simulations are often expensive and parameter spaces are\nhigh-dimensional. We show that the active learning techniques\nquery-by-committee and query-by-dropout-committee allow for the identification\nof model points in interesting regions of high-dimensional parameter spaces\n(e.g. around decision boundaries). This makes it possible to constrain model\nparameters more efficiently than is currently done with the most common\nsampling algorithms and to train better performing machine learning models on\nthe same amount of data. Code implementing the experiments in this paper can be\nfound on GitHub.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 18:30:48 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:11:41 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Caron", "Sascha", ""], ["Heskes", "Tom", ""], ["Otten", "Sydney", ""], ["Stienen", "Bob", ""]]}, {"id": "1905.08632", "submitter": "Andrew Huang", "authors": "Andrew Huang and Puwei Bao", "title": "Human Vocal Sentiment Analysis", "comments": "NYU Shanghai CSCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use several techniques with conventional vocal feature\nextraction (MFCC, STFT), along with deep-learning approaches such as CNN, and\nalso context-level analysis, by providing the textual data, and combining\ndifferent approaches for improved emotion-level classification. We explore\nmodels that have not been tested to gauge the difference in performance and\naccuracy. We apply hyperparameter sweeps and data augmentation to improve\nperformance. Finally, we see if a real-time approach is feasible, and can be\nreadily integrated into existing systems.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 06:27:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Huang", "Andrew", ""], ["Bao", "Puwei", ""]]}, {"id": "1905.08636", "submitter": "S\\'ebastien Lerique", "authors": "S\\'ebastien Lerique (1), Jacob Levy Abitbol (1), M\\'arton Karsai (1,2)\n  ((1) IXXI, LIP (UMR 5668, Univ Lyon-ENS de Lyon-Inria-CNRS-UCB Lyon 1), (2)\n  Department of Network and Data Science, Central European University)", "title": "Joint embedding of structure and features via graph convolutional\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The creation of social ties is largely determined by the entangled effects of\npeople's similarities in terms of individual characters and friends. However,\nfeature and structural characters of people usually appear to be correlated,\nmaking it difficult to determine which has greater responsibility in the\nformation of the emergent network structure. We propose \\emph{AN2VEC}, a node\nembedding method which ultimately aims at disentangling the information shared\nby the structure of a network and the features of its nodes. Building on the\nrecent developments of Graph Convolutional Networks (GCN), we develop a\nmultitask GCN Variational Autoencoder where different dimensions of the\ngenerated embeddings can be dedicated to encoding feature information, network\nstructure, and shared feature-network information. We explore the interaction\nbetween these disentangled characters by comparing the embedding reconstruction\nperformance to a baseline case where no shared information is extracted. We use\nsynthetic datasets with different levels of interdependency between feature and\nnetwork characters and show (i) that shallow embeddings relying on shared\ninformation perform better than the corresponding reference with unshared\ninformation, (ii) that this performance gap increases with the correlation\nbetween network and feature structure, and (iii) that our embedding is able to\ncapture joint information of structure and features. Our method can be relevant\nfor the analysis and prediction of any featured network structure ranging from\nonline social systems to network medicine.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:43:26 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 08:28:49 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 22:34:29 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 15:31:55 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Lerique", "S\u00e9bastien", ""], ["Abitbol", "Jacob Levy", ""], ["Karsai", "M\u00e1rton", ""]]}, {"id": "1905.08645", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou and Peter Richt\\'arik", "title": "Revisiting Randomized Gossip Algorithms: General Framework, Convergence\n  Rates and Novel Block and Accelerated Protocols", "comments": "44 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new framework for the analysis and design of\nrandomized gossip algorithms for solving the average consensus problem. We show\nhow classical randomized iterative methods for solving linear systems can be\ninterpreted as gossip algorithms when applied to special systems encoding the\nunderlying network and explain in detail their decentralized nature. Our\ngeneral framework recovers a comprehensive array of well-known gossip\nalgorithms as special cases, including the pairwise randomized gossip algorithm\nand path averaging gossip, and allows for the development of provably faster\nvariants. The flexibility of the new approach enables the design of a number of\nnew specific gossip methods. For instance, we propose and analyze novel block\nand the first provably accelerated randomized gossip protocols, and dual\nrandomized gossip algorithms.\n  From a numerical analysis viewpoint, our work is the first that explores in\ndepth the decentralized nature of randomized iterative methods for linear\nsystems and proposes them as methods for solving the average consensus problem.\n  We evaluate the performance of the proposed gossip protocols by performing\nextensive experimental testing on typical wireless network topologies.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:36:59 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:41:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.08654", "submitter": "Fl\\'avia Dias Casagrande", "authors": "Flavia Dias Casagrande and Evi Zouganeli", "title": "Activity Recognition and Prediction in Real Homes", "comments": "12 pages, Symposium of the Norwegian AI Society NAIS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present work in progress on activity recognition and\nprediction in real homes using either binary sensor data or depth video data.\nWe present our field trial and set-up for collecting and storing the data, our\nmethods, and our current results. We compare the accuracy of predicting the\nnext binary sensor event using probabilistic methods and Long Short-Term Memory\n(LSTM) networks, include the time information to improve prediction accuracy,\nas well as predict both the next sensor event and its mean time of occurrence\nusing one LSTM model. We investigate transfer learning between apartments and\nshow that it is possible to pre-train the model with data from other apartments\nand achieve good accuracy in a new apartment straight away. In addition, we\npresent preliminary results from activity recognition using low-resolution\ndepth video data from seven apartments, and classify four activities - no\nmovement, standing up, sitting down, and TV interaction - by using a relatively\nsimple processing method where we apply an Infinite Impulse Response (IIR)\nfilter to extract movements from the frames prior to feeding them to a\nconvolutional LSTM network for the classification.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:14:55 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Casagrande", "Flavia Dias", ""], ["Zouganeli", "Evi", ""]]}, {"id": "1905.08671", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh, Andreas Otto", "title": "Topological Feature Vectors for Chatter Detection in Turning Processes", "comments": "Implementations of parallel computing and Bezier curve approximation\n  for persistence diagram computation are added into the manuscript. Abstract\n  and results section are updated with respect to the results obtained from\n  persistence diagrams computed with Bezier approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machining processes are most accurately described using complex dynamical\nsystems that include nonlinearities, time delays, and stochastic effects. Due\nto the nature of these models as well as the practical challenges which include\ntime-varying parameters, the transition from numerical/analytical modeling of\nmachining to the analysis of real cutting signals remains challenging. Some\nstudies have focused on studying the time series of cutting processes using\nmachine learning algorithms with the goal of identifying and predicting\nundesirable vibrations during machining referred to as chatter. These tools\ntypically decompose the signal using Wavelet Packet Transforms (WPT) or\nEnsemble Empirical Mode Decomposition (EEMD). However, these methods require a\nsignificant overhead in identifying the feature vectors before a classifier can\nbe trained. In this study, we present an alternative approach based on\nfeaturizing the time series of the cutting process using its topological\nfeatures. We first embed the time series as a point cloud using Takens\nembedding. We then utilize Support Vector Machine, Logistic Regression, Random\nForest and Gradient Boosting classifier combined with feature vectors derived\nfrom persistence diagrams, a tool from persistent homology, to encode chatter's\ndistinguishing characteristics. We present the results for several choices of\nthe topological feature vectors, and we compare our results to the WPT and EEMD\nmethods using experimental turning data. Our results show that in two out of\nfour cutting configurations the TDA-based features yield accuracies as high as\n97%. We also show that combining Bezier curve approximation method and parallel\ncomputing can reduce runtime for persistence diagram computation of a single\ntime series to less than a second thus making our approach suitable for online\nchatter detection.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:36:52 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 20:15:08 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 21:35:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""], ["Otto", "Andreas", ""]]}, {"id": "1905.08711", "submitter": "Alexander Kozlov", "authors": "Alexander Kozlov, Vadim Andronov, Yana Gritsenko", "title": "Lightweight Network Architecture for Real-Time Action Recognition", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a new efficient approach to Human Action Recognition\ncalled Video Transformer Network (VTN). It leverages the latest advances in\nComputer Vision and Natural Language Processing and applies them to video\nunderstanding. The proposed method allows us to create lightweight CNN models\nthat achieve high accuracy and real-time speed using just an RGB mono camera\nand general purpose CPU. Furthermore, we explain how to improve accuracy by\ndistilling from multiple models with different modalities into a single model.\nWe conduct a comparison with state-of-the-art methods and show that our\napproach performs on par with most of them on famous Action Recognition\ndatasets. We benchmark the inference time of the models using the modern\ninference framework and argue that our approach compares favorably with other\nmethods in terms of speed/accuracy trade-off, running at 56 FPS on CPU. The\nmodels and the training code are available.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:50:24 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kozlov", "Alexander", ""], ["Andronov", "Vadim", ""], ["Gritsenko", "Yana", ""]]}, {"id": "1905.08716", "submitter": "Nirav Bhatt", "authors": "Satya Jayadev P., Shankar Narasimhan, Nirav Bhatt", "title": "Learning Conserved Networks from Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenging problem in complex networks is the network reconstruction\nproblem from data. This work deals with a class of networks denoted as\nconserved networks, in which a flow associated with every edge and the flows\nare conserved at all non-source and non-sink nodes. We propose a novel\npolynomial time algorithm to reconstruct conserved networks from flow data by\nexploiting graph theoretic properties of conserved networks combined with\nlearning techniques. We prove that exact network reconstruction is possible for\narborescence networks. We also extend the methodology for reconstructing\nnetworks from noisy data and explore the reconstruction performance on\narborescence networks with different structural characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:54:51 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 12:16:05 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["P.", "Satya Jayadev", ""], ["Narasimhan", "Shankar", ""], ["Bhatt", "Nirav", ""]]}, {"id": "1905.08721", "submitter": "Ben Day", "authors": "Ezra Webb, Ben Day, Helena Andres-Terre and Pietro Li\\'o", "title": "Factorised Neural Relational Inference for Multi-Interaction Systems", "comments": "4 page workshop paper accepted for presentation at the ICML 2019\n  Workshop on Learning and Reasoning with Graph-Structured Representations with\n  6 pages of supplementary materials and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex natural and cultural phenomena are well modelled by systems of\nsimple interactions between particles. A number of architectures have been\ndeveloped to articulate this kind of structure, both implicitly and explicitly.\nWe consider an unsupervised explicit model, the NRI model, and make a series of\nrepresentational adaptations and physically motivated changes. Most notably we\nfactorise the inferred latent interaction graph into a multiplex graph,\nallowing each layer to encode for a different interaction-type. This fNRI model\nis smaller in size and significantly outperforms the original in both edge and\ntrajectory prediction, establishing a new state-of-the-art. We also present a\nsimplified variant of our model, which demonstrates the NRI's formulation as a\nvariational auto-encoder is not necessary for good performance, and make an\nadaptation to the NRI's training routine, significantly improving its ability\nto model complex physical dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:59:57 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Webb", "Ezra", ""], ["Day", "Ben", ""], ["Andres-Terre", "Helena", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1905.08723", "submitter": "Ting-Shuo Yo", "authors": "Ting-Shuo Yo and Edwin de Jong", "title": "A comparison of evaluation methods in coevolution", "comments": "8 pages, 7 figures, GECCO '07: Proceedings of the 9th annual\n  conference on Genetic and evolutionary computation", "journal-ref": null, "doi": "10.1145/1276958.1277060", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, we compare four different evaluation methods in coevolution\non the Majority Function problem. The size of the problem is selected such that\nevaluation against all possible test cases is feasible. Two measures are used\nfor the comparisons, i.e., the objective fitness derived from evaluating\nsolutions against all test cases, and the objective fitness correlation (OFC),\nwhich is defined as the correlation coefficient between subjective and\nobjective fitness. The results of our experiments suggest that a combination of\naverage score and weighted informativeness may provide a more accurate\nevaluation in coevolution. In order to confirm this difference, a series of\nt-tests on the preference between each pair of the evaluation methods is\nperformed. The resulting significance is affirmative, and the tests for two\nquality measures show similar preference on four evaluation methods. %This\nstudy is the first time OFC is actually computed on a real problem. Experiments\non Majority Function problems with larger sizes and Parity problems are in\nprogress, and their results will be added in the final version.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:11:00 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yo", "Ting-Shuo", ""], ["de Jong", "Edwin", ""]]}, {"id": "1905.08731", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "Heterogeneous Stochastic Interactions for Multiple Agents in a\n  Multi-armed Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and analyze a multi-agent multi-armed bandit problem in which\ndecision-making agents can observe the choices and rewards of their neighbors.\nNeighbors are defined by a network graph with heterogeneous and stochastic\ninterconnections. These interactions are determined by the sociability of each\nagent, which corresponds to the probability that the agent observes its\nneighbors. We design an algorithm for each agent to maximize its own expected\ncumulative reward and prove performance bounds that depend on the sociability\nof the agents and the network structure. We use the bounds to predict the rank\nordering of agents according to their performance and verify the accuracy\nanalytically and computationally.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:22:38 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "1905.08732", "submitter": "Ting-Shuo Yo", "authors": "Chu-Ren Huang, Ting-Shuo Yo, Petr Simon, Shu-Kai Hsieh", "title": "A realistic and robust model for Chinese word segmentation", "comments": "Proceedings of the 20th Conference on Computational Linguistics and\n  Speech Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A realistic Chinese word segmentation tool must adapt to textual variations\nwith minimal training input and yet robust enough to yield reliable\nsegmentation result for all variants. Various lexicon-driven approaches to\nChinese segmentation, e.g. [1,16], achieve high f-scores yet require massive\ntraining for any variation. Text-driven approach, e.g. [12], can be easily\nadapted for domain and genre changes yet has difficulty matching the high\nf-scores of the lexicon-driven approaches. In this paper, we refine and\nimplement an innovative text-driven word boundary decision (WBD) segmentation\nmodel proposed in [15]. The WBD model treats word segmentation simply and\nefficiently as a binary decision on whether to realize the natural textual\nbreak between two adjacent characters as a word boundary. The WBD model allows\nsimple and quick training data preparation converting characters as contextual\nvectors for learning the word boundary decision. Machine learning experiments\nwith four different classifiers show that training with 1,000 vectors and 1\nmillion vectors achieve comparable and reliable results. In addition, when\napplied to SigHAN Bakeoff 3 competition data, the WBD model produces OOV recall\nrates that are higher than all published results. Unlike all previous work, our\nOOV recall rate is comparable to our own F-score. Both experiments support the\nclaim that the WBD model is a realistic model for Chinese word segmentation as\nit can be easily adapted for new variants with the robust result. In\nconclusion, we will discuss linguistic ramifications as well as future\nimplications for the WBD approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:22:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Huang", "Chu-Ren", ""], ["Yo", "Ting-Shuo", ""], ["Simon", "Petr", ""], ["Hsieh", "Shu-Kai", ""]]}, {"id": "1905.08736", "submitter": "Ting-Shuo Yo", "authors": "Shih-Hao Su and Jung-Lien Chu and Ting-Shuo Yo and Lee-Yaw Lin", "title": "Identification of synoptic weather types over Taiwan area with multiple\n  classifiers", "comments": "journal article, open access", "journal-ref": "Atmos Sci Lett.2018;e861", "doi": "10.1002/asl.861", "report-no": null, "categories": "physics.ao-ph cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a novel machine learning approach was used to classify three\ntypes of synoptic weather events in Taiwan area from 2001 to 2010. We used\nreanalysis data with three machine learning algorithms to recognize weather\nsystems and evaluated their performance. Overall, the classifiers successfully\nidentified 52-83% of weather events (hit rate), which is higher than the\nperformance of traditional objective methods. The results showed that the\nmachine learning approach gave low false alarm rate in general, while the\nsupport vector machine (SVM) with more principal components of reanalysis data\nhad higher hit rate on all tested weather events. The sensitivity tests of grid\ndata resolution indicated that the differences between the high- and\nlow-resolution datasets are limited, which implied that the proposed method can\nachieve reasonable performance in weather forecasting with minimal resources.\nBy identifying daily weather systems in historical reanalysis data, this method\ncan be used to study long-term weather changes, to monitor climatological-scale\nvariations, and to provide a better estimate of climate projections.\nFurthermore, this method can also serve as an alternative to model output\nstatistics and potentially be used for synoptic weather forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:29:27 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Su", "Shih-Hao", ""], ["Chu", "Jung-Lien", ""], ["Yo", "Ting-Shuo", ""], ["Lin", "Lee-Yaw", ""]]}, {"id": "1905.08744", "submitter": "David Peer", "authors": "David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez", "title": "Limitation of capsule networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed method in deep learning groups multiple neurons to\ncapsules such that each capsule represents an object or part of an object.\nRouting algorithms route the output of capsules from lower-level layers to\nupper-level layers. In this paper, we prove that state-of-the-art routing\nprocedures decrease the expressivity of capsule networks. More precisely, it is\nshown that EM-routing and routing-by-agreement prevent capsule networks from\ndistinguishing inputs and their negative counterpart. Therefore, only symmetric\nfunctions can be expressed by capsule networks, and it can be concluded that\nthey are not universal approximators. We also theoretically motivate and\nempirically show that this limitation affects the training of deep capsule\nnetworks negatively. Therefore, we present an incremental improvement for\nstate-of-the-art routing algorithms that solves the aforementioned limitation\nand stabilizes the training of capsule networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:45:13 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 19:23:28 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 14:25:22 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 07:57:33 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Peer", "David", ""], ["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""]]}, {"id": "1905.08760", "submitter": "Martin Jansche", "authors": "Martin Jansche, Alexander Gutkin", "title": "Sampling from Stochastic Finite Automata with Applications to CTC\n  Decoding", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2019-2740", "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stochastic finite automata arise naturally in many language and speech\nprocessing tasks. They include stochastic acceptors, which represent certain\nprobability distributions over random strings. We consider the problem of\nefficient sampling: drawing random string variates from the probability\ndistribution represented by stochastic automata and transformations of those.\nWe show that path-sampling is effective and can be efficient if the\nepsilon-graph of a finite automaton is acyclic. We provide an algorithm that\nensures this by conflating epsilon-cycles within strongly connected components.\nSampling is also effective in the presence of non-injective transformations of\nstrings. We illustrate this in the context of decoding for Connectionist\nTemporal Classification (CTC), where the predictive probabilities yield\nauxiliary sequences which are transformed into shorter labeling strings. We can\nsample efficiently from the transformed labeling distribution and use this in\ntwo different strategies for finding the most probable CTC labeling.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:26:39 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jansche", "Martin", ""], ["Gutkin", "Alexander", ""]]}, {"id": "1905.08764", "submitter": "Yihui Ren", "authors": "Yihui Ren, Shinjae Yoo and Adolfy Hoisie", "title": "Performance Analysis of Deep Learning Workloads on Leading-edge Systems", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the performance of leading-edge systems designed for\nmachine learning computing, including the NVIDIA DGX-2, Amazon Web Services\n(AWS) P3, IBM Power System Accelerated Compute Server AC922, and a\nconsumer-grade Exxact TensorEX TS4 GPU server. Representative deep learning\nworkloads from the fields of computer vision and natural language processing\nare the focus of the analysis. Performance analysis is performed along with a\nnumber of important dimensions. Performance of the communication interconnects\nand large and high-throughput deep learning models are considered. Different\npotential use models for the systems as standalone and in the cloud also are\nexamined. The effect of various optimization of the deep learning models and\nsystem configurations is included in the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:33:19 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 20:59:22 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ren", "Yihui", ""], ["Yoo", "Shinjae", ""], ["Hoisie", "Adolfy", ""]]}, {"id": "1905.08770", "submitter": "Antoine H\\'ebert", "authors": "Antoine H\\'ebert, Timoth\\'ee Gu\\'edon, Tristan Glatard, Brigitte\n  Jaumard", "title": "High-Resolution Road Vehicle Collision Prediction for the City of\n  Montreal", "comments": null, "journal-ref": "2019 IEEE International Conference on Big Data, pp. 1804-1813", "doi": "10.1109/BigData47090.2019.9006009", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road accidents are an important issue of our modern societies, responsible\nfor millions of deaths and injuries every year in the world. In Quebec only, in\n2018, road accidents are responsible for 359 deaths and 33 thousands of\ninjuries. In this paper, we show how one can leverage open datasets of a city\nlike Montreal, Canada, to create high-resolution accident prediction models,\nusing big data analytics. Compared to other studies in road accident\nprediction, we have a much higher prediction resolution, i.e., our models\npredict the occurrence of an accident within an hour, on road segments defined\nby intersections. Such models could be used in the context of road accident\nprevention, but also to identify key factors that can lead to a road accident,\nand consequently, help elaborate new policies.\n  We tested various machine learning methods to deal with the severe class\nimbalance inherent to accident prediction problems. In particular, we\nimplemented the Balanced Random Forest algorithm, a variant of the Random\nForest machine learning algorithm in Apache Spark. Interestingly, we found that\nin our case, Balanced Random Forest does not perform significantly better than\nRandom Forest.\n  Experimental results show that 85% of road vehicle collisions are detected by\nour model with a false positive rate of 13%. The examples identified as\npositive are likely to correspond to high-risk situations. In addition, we\nidentify the most important predictors of vehicle collisions for the area of\nMontreal: the count of accidents on the same road segment during previous\nyears, the temperature, the day of the year, the hour and the visibility.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:41:23 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:05:50 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 18:50:44 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["H\u00e9bert", "Antoine", ""], ["Gu\u00e9don", "Timoth\u00e9e", ""], ["Glatard", "Tristan", ""], ["Jaumard", "Brigitte", ""]]}, {"id": "1905.08772", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "A Text Classification Framework for Simple and Effective Early\n  Depression Detection Over Social Media Streams", "comments": "Highlights: (*) A novel text classifier having the ability to\n  visually explain its rationale; (*) Domain-independent classification that\n  does not require feature engineering; (*) Support for incremental learning\n  and text classification over streams; (*) Efficient framework for addressing\n  early risk detection problems; (*) State-of-the-art performance on early\n  depression detection task", "journal-ref": "18 May 2019, Volume 133, Expert Systems With Applications,\n  Elsevier", "doi": "10.1016/j.eswa.2019.05.023", "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of the Internet, there is a growing need to build intelligent\nsystems that are capable of efficiently dealing with early risk detection (ERD)\nproblems on social media, such as early depression detection, early rumor\ndetection or identification of sexual predators. These systems, nowadays mostly\nbased on machine learning techniques, must be able to deal with data streams\nsince users provide their data over time. In addition, these systems must be\nable to decide when the processed data is sufficient to actually classify\nusers. Moreover, since ERD tasks involve risky decisions by which people's\nlives could be affected, such systems must also be able to justify their\ndecisions. However, most standard and state-of-the-art supervised machine\nlearning models (such as SVM, MNB, Neural Networks, etc.) are not well suited\nto deal with this scenario. This is due to the fact that they either act as\nblack boxes or do not support incremental classification/learning. In this\npaper we introduce SS3, a novel supervised learning model for text\nclassification that naturally supports these aspects. SS3 was designed to be\nused as a general framework to deal with ERD problems. We evaluated our model\non the CLEF's eRisk2017 pilot task on early depression detection. Most of the\n30 contributions submitted to this competition used state-of-the-art methods.\nExperimental results show that our classifier was able to outperform these\nmodels and standard classifiers, despite being less computationally expensive\nand having the ability to explain its rationale.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 15:46:38 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1905.08775", "submitter": "Evangelos Pournaras", "authors": "David Castells-Graells, Christopher Salahub, Evangelos Pournaras", "title": "On Cycling Risk and Discomfort: Urban Safety Mapping and Bike Route\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike usage in Smart Cities becomes paramount for sustainable urban\ndevelopment. Cycling provides tremendous opportunities for a more healthy\nlifestyle, lower energy consumption and carbon emissions as well as reduction\nof traffic jams. While the number of cyclists increase along with the expansion\nof bike sharing initiatives and infrastructures, the number of bike accidents\nrises drastically threatening to jeopardize the bike urban movement. This paper\nstudies cycling risk and discomfort using a diverse spectrum of data sources\nabout geolocated bike accidents and their severity. Empirical continuous\nspatial risk estimations are calculated via kernel density contours that map\nsafety in a case study of Zurich city. The role of weather, time, accident type\nand severity are illustrated. Given the predominance of self-caused accidents,\nan open-source software artifact for personalized route recommendations is\nintroduced. The software is also used to collect open baseline route data that\nare compared with alternative ones that minimize risk or discomfort. These\ncontributions can provide invaluable insights for urban planners to improve\ninfrastructure. They can also improve the risk awareness of existing cyclists'\nas well as support new cyclists, such as tourists, to safely explore a new\nurban environment by bike.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:50:31 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Castells-Graells", "David", ""], ["Salahub", "Christopher", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "1905.08776", "submitter": "Aliaksandra Shysheya Ms", "authors": "Aliaksandra Shysheya (Samsung AI Center, Skolkovo Institute of Science\n  and Technology), Egor Zakharov (Samsung AI Center, Skolkovo Institute of\n  Science and Technology), Kara-Ali Aliev (Samsung AI Center), Renat Bashirov\n  (Samsung AI Center), Egor Burkov (Samsung AI Center, Skolkovo Institute of\n  Science and Technology), Karim Iskakov (Samsung AI Center), Aleksei\n  Ivakhnenko (Samsung AI Center), Yury Malkov (Samsung AI Center), Igor\n  Pasechnik (Samsung AI Center), Dmitry Ulyanov (Samsung AI Center, Skolkovo\n  Institute of Science and Technology), Alexander Vakhitov (Samsung AI Center,\n  Skolkovo Institute of Science and Technology) and Victor Lempitsky (Samsung\n  AI Center, Skolkovo Institute of Science and Technology)", "title": "Textured Neural Avatars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for learning full-body neural avatars, i.e. deep networks\nthat produce full-body renderings of a person for varying body pose and camera\nposition. Our system takes the middle path between the classical graphics\npipeline and the recent deep learning approaches that generate images of humans\nusing image-to-image translation. In particular, our system estimates an\nexplicit two-dimensional texture map of the model surface. At the same time, it\nabstains from explicit shape modeling in 3D. Instead, at test time, the system\nuses a fully-convolutional network to directly map the configuration of body\nfeature points w.r.t. the camera to the 2D texture coordinates of individual\npixels in the image frame. We show that such a system is capable of learning to\ngenerate realistic renderings while being trained on videos annotated with 3D\nposes and foreground masks. We also demonstrate that maintaining an explicit\ntexture representation helps our system to achieve better generalization\ncompared to systems that use direct image-to-image translation.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:46:16 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Shysheya", "Aliaksandra", "", "Samsung AI Center, Skolkovo Institute of Science\n  and Technology"], ["Zakharov", "Egor", "", "Samsung AI Center, Skolkovo Institute of\n  Science and Technology"], ["Aliev", "Kara-Ali", "", "Samsung AI Center"], ["Bashirov", "Renat", "", "Samsung AI Center"], ["Burkov", "Egor", "", "Samsung AI Center, Skolkovo Institute of\n  Science and Technology"], ["Iskakov", "Karim", "", "Samsung AI Center"], ["Ivakhnenko", "Aleksei", "", "Samsung AI Center"], ["Malkov", "Yury", "", "Samsung AI Center"], ["Pasechnik", "Igor", "", "Samsung AI Center"], ["Ulyanov", "Dmitry", "", "Samsung AI Center, Skolkovo\n  Institute of Science and Technology"], ["Vakhitov", "Alexander", "", "Samsung AI Center,\n  Skolkovo Institute of Science and Technology"], ["Lempitsky", "Victor", "", "Samsung\n  AI Center, Skolkovo Institute of Science and Technology"]]}, {"id": "1905.08786", "submitter": "Rui Zhao", "authors": "Rui Zhao, Xudong Sun, Volker Tresp", "title": "Maximum Entropy-Regularized Multi-Goal Reinforcement Learning", "comments": "Published in International Conference on Machine Learning (ICML\n  2019), Long Beach, USA. arXiv admin note: text overlap with arXiv:1902.08039", "journal-ref": "PMLR 97:7553-7562, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Multi-Goal Reinforcement Learning, an agent learns to achieve multiple\ngoals with a goal-conditioned policy. During learning, the agent first collects\nthe trajectories into a replay buffer, and later these trajectories are\nselected randomly for replay. However, the achieved goals in the replay buffer\nare often biased towards the behavior policies. From a Bayesian perspective,\nwhen there is no prior knowledge about the target goal distribution, the agent\nshould learn uniformly from diverse achieved goals. Therefore, we first propose\na novel multi-goal RL objective based on weighted entropy. This objective\nencourages the agent to maximize the expected return, as well as to achieve\nmore diverse goals. Secondly, we developed a maximum entropy-based\nprioritization framework to optimize the proposed objective. For evaluation of\nthis framework, we combine it with Deep Deterministic Policy Gradient, both\nwith or without Hindsight Experience Replay. On a set of multi-goal robotic\ntasks of OpenAI Gym, we compare our method with other baselines and show\npromising improvements in both performance and sample-efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:38:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 13:03:52 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:21:11 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Sun", "Xudong", ""], ["Tresp", "Volker", ""]]}, {"id": "1905.08790", "submitter": "Zirui Xu", "authors": "Zirui Xu, Fuxun Yu, Xiang Chen", "title": "DoPa: A Comprehensive CNN Detection Methodology against Physical\n  Adversarial Attacks", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolutional Neural Networks (CNNs) demonstrate a considerable\nvulnerability to adversarial attacks, which can be easily misled by adversarial\nperturbations. With more aggressive methods proposed, adversarial attacks can\nbe also applied to the physical world, causing practical issues to various CNN\npowered applications. To secure CNNs, adversarial attack detection is\nconsidered as the most critical approach. However, most existing works focus on\nsuperficial patterns and merely search a particular method to differentiate the\nadversarial inputs and natural inputs, ignoring the analysis of CNN inner\nvulnerability. Therefore, they can only target to specific physical adversarial\nattacks, lacking expected versatility to different attacks. To address this\nissue, we propose DoPa -- a comprehensive CNN detection methodology for various\nphysical adversarial attacks. By interpreting the CNN's vulnerability, we find\nthat non-semantic adversarial perturbations can activate CNN with significantly\nabnormal activations and even overwhelm other semantic input patterns'\nactivations. Therefore, we add a self-verification stage to analyze the\nsemantics of distinguished activation patterns, which improves the CNN\nrecognition process. We apply such a detection methodology into both image and\naudio CNN recognition scenarios. Experiments show that DoPa can achieve an\naverage rate of 90% success for image attack detection and 92% success for\naudio attack detection.\n  Announcement:[The original DoPa draft on arXiv was modified and submitted to\na conference already, while this short abstract was submitted only for a\npresentation at the KDD 2019 AIoT Workshop.]\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:53:38 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 18:56:50 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 20:38:44 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2019 15:07:07 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Xu", "Zirui", ""], ["Yu", "Fuxun", ""], ["Chen", "Xiang", ""]]}, {"id": "1905.08793", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "Revisiting hard thresholding for DNN pruning", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.04239", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common method for DNN pruning is hard thresholding of network\nweights, followed by retraining to recover any lost accuracy. Recently\ndeveloped smart pruning algorithms use the DNN response over the training set\nfor a variety of cost functions to determine redundant network weights, leading\nto less accuracy degradation and possibly less retraining time. For experiments\non the total pruning time (pruning time + retraining time) we show that hard\nthresholding followed by retraining remains the most efficient way of reducing\nthe number of network parameters. However smart pruning algorithms still have\nadvantages when retraining is not possible. In this context we propose a novel\nsmart pruning algorithm based on difference of convex functions optimisation\nand show that it is often orders of magnitude faster than competing approaches\nwhile achieving the lowest classification accuracy degradation. Furthermore we\ninvestigate theoretically the effect of hard thresholding on DNN accuracy. We\nshow that accuracy degradation increases with remaining network depth from the\npruned layer. We also discover a link between the latent dimensionality of the\ntraining data manifold and network robustness to hard thresholding.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:59:13 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1905.08795", "submitter": "Avi Caciularu", "authors": "Avi Caciularu, David Burshtein", "title": "Unsupervised Linear and Nonlinear Channel Equalization and Decoding\n  using Variational Autoencoders", "comments": "Submitted for publication. Includes 33 pages, 17 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for blind channel equalization and decoding, variational\ninference, and variational autoencoders (VAEs) in particular, is introduced. We\nfirst consider the reconstruction of uncoded data symbols transmitted over a\nnoisy linear intersymbol interference (ISI) channel, with an unknown impulse\nresponse, without using pilot symbols. We derive an approximate maximum\nlikelihood estimate to the channel parameters and reconstruct the transmitted\ndata. We demonstrate significant and consistent improvements in the error rate\nof the reconstructed symbols, compared to existing blind equalization methods\nsuch as constant modulus, thus enabling faster channel acquisition. The VAE\nequalizer uses a convolutional neural network with a small number of free\nparameters. These results are extended to blind equalization over a noisy\nnonlinear ISI channel with unknown parameters. We then consider coded\ncommunication using low-density parity-check (LDPC) codes transmitted over a\nnoisy linear or nonlinear ISI channel. The goal is to reconstruct the\ntransmitted message from the channel observations corresponding to a\ntransmitted codeword, without using pilot symbols. We demonstrate improvements\ncompared to the expectation maximization (EM) algorithm using turbo\nequalization. Furthermore, unlike EM, the computational complexity of our\nmethod does not have exponential dependence on the size of the channel impulse\nresponse.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:32:06 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 10:56:24 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Caciularu", "Avi", ""], ["Burshtein", "David", ""]]}, {"id": "1905.08796", "submitter": "Suyoun Kim", "authors": "Suyoun Kim and Florian Metze", "title": "Acoustic-to-Word Models with Conversational Context Information", "comments": "NAACL 2019. arXiv admin note: text overlap with arXiv:1808.02171", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational context information, higher-level knowledge that spans across\nsentences, can help to recognize a long conversation. However, existing speech\nrecognition models are typically built at a sentence level, and thus it may not\ncapture important conversational context information. The recent progress in\nend-to-end speech recognition enables integrating context with other available\ninformation (e.g., acoustic, linguistic resources) and directly recognizing\nwords from speech. In this work, we present a direct acoustic-to-word,\nend-to-end speech recognition model capable of utilizing the conversational\ncontext to better process long conversations. We evaluate our proposed approach\non the Switchboard conversational speech corpus and show that our system\noutperforms a standard end-to-end speech recognition system.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:44:03 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kim", "Suyoun", ""], ["Metze", "Florian", ""]]}, {"id": "1905.08831", "submitter": "Indu Manickam", "authors": "Indu Manickam, Andrew S. Lan, Gautam Dasarathy, Richard G. Baraniuk", "title": "IdeoTrace: A Framework for Ideology Tracing with a Case Study on the\n  2016 U.S. Presidential Election", "comments": "9 pages, 4 figures, submitted to ASONAM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2016 United States presidential election has been characterized as a\nperiod of extreme divisiveness that was exacerbated on social media by the\ninfluence of fake news, trolls, and social bots. However, the extent to which\nthe public became more polarized in response to these influences over the\ncourse of the election is not well understood. In this paper we propose\nIdeoTrace, a framework for (i) jointly estimating the ideology of social media\nusers and news websites and (ii) tracing changes in user ideology over time. We\napply this framework to the last two months of the election period for a group\nof 47508 Twitter users and demonstrate that both liberal and conservative users\nbecame more polarized over time.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:03:46 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 15:02:54 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Manickam", "Indu", ""], ["Lan", "Andrew S.", ""], ["Dasarathy", "Gautam", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1905.08838", "submitter": "Paidamoyo Chapfuwa", "authors": "Paidamoyo Chapfuwa, Chenyang Tao, Lawrence Carin, Ricardo Henao", "title": "Survival Function Matching for Calibrated Time-to-Event Predictions", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3029631", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for predicting the time of a future event are crucial for risk\nassessment, across a diverse range of applications. Existing time-to-event\n(survival) models have focused primarily on preserving pairwise ordering of\nestimated event times, or relative risk. Model calibration is relatively under\nexplored, despite its critical importance in time-to-event applications. We\npresent a survival function estimator for probabilistic predictions in\ntime-to-event models, based on a neural network model for draws from the\ndistribution of event times, without explicit assumptions on the form of the\ndistribution. This is done like in adversarial learning, but we achieve\nlearning without a discriminator or adversarial objective. The proposed\nestimator can be used in practice as a means of estimating and comparing\nconditional survival distributions, while accounting for the predictive\nuncertainty of probabilistic models. Extensive experiments show that the\nproposed model outperforms existing approaches, trained both with and without\nadversarial learning, in terms of both calibration and concentration of\ntime-to-event distributions.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:15:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Chapfuwa", "Paidamoyo", ""], ["Tao", "Chenyang", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1905.08846", "submitter": "Emilio Ferrara", "authors": "Homa Hosseinmardi, Hsien-Te Kao, Kristina Lerman, Emilio Ferrara", "title": "Discovering Hidden Structure in High Dimensional Human Behavioral Data\n  via Tensor Factorization", "comments": "2018 WSDM Heteronam Workshop", "journal-ref": "2018 ACM International WSDM Conference, Heteronam Workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the rapid growth in technology has increased the opportunity\nfor longitudinal human behavioral studies. Rich multimodal data, from wearables\nlike Fitbit, online social networks, mobile phones etc. can be collected in\nnatural environments. Uncovering the underlying low-dimensional structure of\nnoisy multi-way data in an unsupervised setting is a challenging problem.\nTensor factorization has been successful in extracting the interconnected\nlow-dimensional descriptions of multi-way data. In this paper, we apply\nnon-negative tensor factorization on a real-word wearable sensor data,\nStudentLife, to find latent temporal factors and group of similar individuals.\nMeta data is available for the semester schedule, as well as the individuals'\nperformance and personality. We demonstrate that non-negative tensor\nfactorization can successfully discover clusters of individuals who exhibit\nhigher academic performance, as well as those who frequently engage in leisure\nactivities. The recovered latent temporal patterns associated with these groups\nare validated against ground truth data to demonstrate the accuracy of our\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:47:47 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Hosseinmardi", "Homa", ""], ["Kao", "Hsien-Te", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1905.08848", "submitter": "Robert Anderson", "authors": "Robert Anderson, Yun Sing Koh, Gillian Dobbie, Albert Bifet", "title": "Recurring Concept Meta-learning for Evolving Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When concept drift is detected during classification in a data stream, a\ncommon remedy is to retrain a framework's classifier. However, this loses\nuseful information if the classifier has learnt the current concept well, and\nthis concept will recur again in the future. Some frameworks retain and reuse\nclassifiers, but it can be time-consuming to select an appropriate classifier\nto reuse. These frameworks rarely match the accuracy of state-of-the-art\nensemble approaches. For many data stream tasks, speed is important: fast,\naccurate frameworks are needed for time-dependent applications. We propose the\nEnhanced Concept Profiling Framework (ECPF), which aims to recognise recurring\nconcepts and reuse a classifier trained previously, enabling accurate\nclassification immediately following a drift. The novelty of ECPF is in how it\nuses similarity of classifications on new data, between a new classifier and\nexisting classifiers, to quickly identify the best classifier to reuse. It\nalways trains both a new classifier and a reused classifier, and retains the\nmore accurate classifier when concept drift occurs. Finally, it creates a copy\nof reused classifiers, so a classifier well-suited for a recurring concept will\nnot be impacted by being trained on a different concept. In our experiments,\nECPF classifies significantly more accurately than a state-of-the-art\nclassifier reuse framework (Diversity Pool) and a state-of-the-art ensemble\ntechnique (Adaptive Random Forest) on synthetic datasets with recurring\nconcepts. It classifies real-world datasets five times faster than Diversity\nPool, and six times faster than Adaptive Random Forest and is not significantly\nless accurate than either.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 20:02:17 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Anderson", "Robert", ""], ["Koh", "Yun Sing", ""], ["Dobbie", "Gillian", ""], ["Bifet", "Albert", ""]]}, {"id": "1905.08850", "submitter": "Sergul Aydore", "authors": "Tianhao Zhu and Sergul Aydore", "title": "Time-Smoothed Gradients for Online Forecasting", "comments": "ICML 2019, time series workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we study different update rules in stochastic gradient descent (SGD)\nfor online forecasting problems. The selection of the learning rate parameter\nis critical in SGD. However, it may not be feasible to tune this parameter in\nonline learning. Therefore, it is necessary to have an update rule that is not\nsensitive to the selection of the learning parameter. Inspired by the local\nregret metric that we introduced previously, we propose to use time-smoothed\ngradients within SGD update. Using the public data set-- GEFCom2014, we\nvalidate that our approach yields more stable results than the other existing\napproaches. Furthermore, we show that such a simple approach is computationally\nefficient compared to the alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 20:05:52 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Zhu", "Tianhao", ""], ["Aydore", "Sergul", ""]]}, {"id": "1905.08865", "submitter": "Namyong Park", "authors": "Namyong Park, Andrey Kan, Xin Luna Dong, Tong Zhao, Christos Faloutsos", "title": "Estimating Node Importance in Knowledge Graphs Using Graph Neural\n  Networks", "comments": "KDD 2019 Research Track. 11 pages. Changelog: Type 3 font removed,\n  and minor updates made in the Appendix (v2)", "journal-ref": null, "doi": "10.1145/3292500.3330855", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we estimate the importance of nodes in a knowledge graph (KG)? A KG\nis a multi-relational graph that has proven valuable for many tasks including\nquestion answering and semantic search. In this paper, we present GENI, a\nmethod for tackling the problem of estimating node importance in KGs, which\nenables several downstream applications such as item recommendation and\nresource allocation. While a number of approaches have been developed to\naddress this problem for general graphs, they do not fully utilize information\navailable in KGs, or lack flexibility needed to model complex relationship\nbetween entities and their importance. To address these limitations, we explore\nsupervised machine learning algorithms. In particular, building upon recent\nadvancement of graph neural networks (GNNs), we develop GENI, a GNN-based\nmethod designed to deal with distinctive challenges involved with predicting\nnode importance in KGs. Our method performs an aggregation of importance scores\ninstead of aggregating node embeddings via predicate-aware attention mechanism\nand flexible centrality adjustment. In our evaluation of GENI and existing\nmethods on predicting node importance in real-world KGs with different\ncharacteristics, GENI achieves 5-17% higher NDCG@100 than the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 20:48:42 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 04:26:24 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Park", "Namyong", ""], ["Kan", "Andrey", ""], ["Dong", "Xin Luna", ""], ["Zhao", "Tong", ""], ["Faloutsos", "Christos", ""]]}, {"id": "1905.08871", "submitter": "Elisa Ferrari", "authors": "Elisa Ferrari, Alessandra Retico, Davide Bacciu", "title": "Measuring the effects of confounders in medical supervised\n  classification problems: the Confounding Index (CI)", "comments": "This is the accepted manuscript. The edited version is freely\n  available until 23/03/2020 at the following link:\n  https://authors.elsevier.com/a/1aVYZ3KEGa9GJo", "journal-ref": "Artificial Intelligence in Medicine, 101804 (2020)", "doi": "10.1016/j.artmed.2020.101804", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, there has been growing interest in using Machine Learning\ntechniques for biomedical data processing. When tackling these tasks, one needs\nto bear in mind that biomedical data depends on a variety of characteristics,\nsuch as demographic aspects (age, gender, etc) or the acquisition technology,\nwhich might be unrelated with the target of the analysis. In supervised tasks,\nfailing to match the ground truth targets with respect to such characteristics,\ncalled confounders, may lead to very misleading estimates of the predictive\nperformance. Many strategies have been proposed to handle confounders, ranging\nfrom data selection, to normalization techniques, up to the use of training\nalgorithm for learning with imbalanced data. However, all these solutions\nrequire the confounders to be known a priori. To this aim, we introduce a novel\nindex that is able to measure the confounding effect of a data attribute in a\nbias-agnostic way. This index can be used to quantitatively compare the\nconfounding effects of different variables and to inform correction methods\nsuch as normalization procedures or ad-hoc-prepared learning algorithms. The\neffectiveness of this index is validated on both simulated data and real-world\nneuroimaging data.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:04:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 21:11:12 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ferrari", "Elisa", ""], ["Retico", "Alessandra", ""], ["Bacciu", "Davide", ""]]}, {"id": "1905.08874", "submitter": "Arinbj\\\"orn Kolbeinsson", "authors": "Naman Shukla, Arinbj\\\"orn Kolbeinsson, Lavanya Marla, Kartik\n  Yellepeddi", "title": "Adaptive Model Selection Framework: An Application to Airline Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple machine learning and prediction models are often used for the same\nprediction or recommendation task. In our recent work, where we develop and\ndeploy airline ancillary pricing models in an online setting, we found that\namong multiple pricing models developed, no one model clearly dominates other\nmodels for all incoming customer requests. Thus, as algorithm designers, we\nface an exploration - exploitation dilemma. In this work, we introduce an\nadaptive meta-decision framework that uses Thompson sampling, a popular\nmulti-armed bandit solution method, to route customer requests to various\npricing models based on their online performance. We show that this adaptive\napproach outperform a uniformly random selection policy by improving the\nexpected revenue per offer by 43% and conversion score by 58% in an offline\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:12:23 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Shukla", "Naman", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Marla", "Lavanya", ""], ["Yellepeddi", "Kartik", ""]]}, {"id": "1905.08880", "submitter": "Anshul Kanakia", "authors": "Anshul Kanakia (1), Zhihong Shen (1), Darrin Eide (1), Kuansan Wang\n  (1) ((1) Microsoft Research)", "title": "A Scalable Hybrid Research Paper Recommender System for Microsoft\n  Academic", "comments": "7 pages, 7 figures. Short paper at The Web Conference 2019, San\n  Francisco, USA", "journal-ref": "In The World Wide Web Conference (WWW '19). ACM, New York, NY,\n  USA, 2893-2899", "doi": "10.1145/3308558.3313700", "report-no": null, "categories": "cs.DL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and methodology for the large scale hybrid paper\nrecommender system used by Microsoft Academic. The system provides\nrecommendations for approximately 160 million English research papers and\npatents. Our approach handles incomplete citation information while also\nalleviating the cold-start problem that often affects other recommender\nsystems. We use the Microsoft Academic Graph (MAG), titles, and available\nabstracts of research papers to build a recommendation list for all documents,\nthereby combining co-citation and content based approaches. Tuning system\nparameters also allows for blending and prioritization of each approach which,\nin turn, allows us to balance paper novelty versus authority in recommendation\nresults. We evaluate the generated recommendations via a user study of 40\nparticipants, with over 2400 recommendation pairs graded and discuss the\nquality of the results using P@10 and nDCG scores. We see that there is a\nstrong correlation between participant scores and the similarity rankings\nproduced by our system but that additional focus needs to be put towards\nimproving recommender precision, particularly for content based\nrecommendations. The results of the user survey and associated analysis scripts\nare made available via GitHub and the recommendations produced by our system\nare available as part of the MAG on Azure to facilitate further research and\nlight up novel research paper recommendation applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:46:33 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kanakia", "Anshul", "", "Microsoft Research"], ["Shen", "Zhihong", "", "Microsoft Research"], ["Eide", "Darrin", "", "Microsoft Research"], ["Wang", "Kuansan", "", "Microsoft Research"]]}, {"id": "1905.08883", "submitter": "Jochen Garcke", "authors": "Ribana Roscher, Bastian Bohn, Marco F. Duarte, and Jochen Garcke", "title": "Explainable Machine Learning for Scientific Insights and Discoveries", "comments": null, "journal-ref": "IEEE Access, vol. 8, pp. 42200-42216, 2020", "doi": "10.1109/ACCESS.2020.2976199", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have been remarkably successful for a wide range of\napplication areas in the extraction of essential information from data. An\nexciting and relatively recent development is the uptake of machine learning in\nthe natural sciences, where the major goal is to obtain novel scientific\ninsights and discoveries from observational or simulated data. A prerequisite\nfor obtaining a scientific outcome is domain knowledge, which is needed to gain\nexplainability, but also to enhance scientific consistency. In this article we\nreview explainable machine learning in view of applications in the natural\nsciences and discuss three core elements which we identified as relevant in\nthis context: transparency, interpretability, and explainability. With respect\nto these core elements, we provide a survey of recent scientific works that\nincorporate machine learning and the way that explainable machine learning is\nused in combination with domain knowledge from the application areas.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:56:18 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 16:34:55 GMT"}, {"version": "v3", "created": "Sun, 12 Jan 2020 23:29:16 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Roscher", "Ribana", ""], ["Bohn", "Bastian", ""], ["Duarte", "Marco F.", ""], ["Garcke", "Jochen", ""]]}, {"id": "1905.08885", "submitter": "Benjamin Inden", "authors": "Benjamin Inden and J\\\"urgen Jost", "title": "Evolving neural networks to follow trajectories of arbitrary complexity", "comments": null, "journal-ref": "Neural Networks, Volume 116, 2019, Pages 224-236, ISSN 0893-6080", "doi": "10.1016/j.neunet.2019.04.013", "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many experiments have been performed that use evolutionary algorithms for\nlearning the topology and connection weights of a neural network that controls\na robot or virtual agent. These experiments are not only performed to better\nunderstand basic biological principles, but also with the hope that with\nfurther progress of the methods, they will become competitive for automatically\ncreating robot behaviors of interest. However, current methods are limited with\nrespect to the (Kolmogorov) complexity of evolved behavior. Using the evolution\nof robot trajectories as an example, we show that by adding four features,\nnamely (1) freezing of previously evolved structure, (2) temporal scaffolding,\n(3) a homogeneous transfer function for output nodes, and (4) mutations that\ncreate new pathways to outputs, to standard methods for the evolution of neural\nnetworks, we can achieve an approximately linear growth of the complexity of\nbehavior over thousands of generations. Overall, evolved complexity is up to\ntwo orders of magnitude over that achieved by standard methods in the\nexperiments reported here, with the major limiting factor for further growth\nbeing the available run time. Thus, the set of methods proposed here promises\nto be a useful addition to various current neuroevolution methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 22:07:38 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Inden", "Benjamin", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1905.08898", "submitter": "Umar Farooq Minhas", "authors": "Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan\n  Li, Hantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\n  David Lomet, Tim Kraska", "title": "ALEX: An Updatable Adaptive Learned Index", "comments": null, "journal-ref": null, "doi": "10.1145/3318464.3389711", "report-no": "MSR-TR-2020-12", "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on \"learned indexes\" has changed the way we look at the\ndecades-old field of DBMS indexing. The key idea is that indexes can be thought\nof as \"models\" that predict the position of a key in a dataset. Indexes can,\nthus, be learned. The original work by Kraska et al. shows that a learned index\nbeats a B+Tree by a factor of up to three in search time and by an order of\nmagnitude in memory footprint. However, it is limited to static, read-only\nworkloads.\n  In this paper, we present a new learned index called ALEX which addresses\npractical issues that arise when implementing learned indexes for workloads\nthat contain a mix of point lookups, short range queries, inserts, updates, and\ndeletes. ALEX effectively combines the core insights from learned indexes with\nproven storage and indexing techniques to achieve high performance and low\nmemory footprint. On read-only workloads, ALEX beats the learned index from\nKraska et al. by up to 2.2X on performance with up to 15X smaller index size.\nAcross the spectrum of read-write workloads, ALEX beats B+Trees by up to 4.1X\nwhile never performing worse, with up to 2000X smaller index size. We believe\nALEX presents a key step towards making learned indexes practical for a broader\nclass of database workloads with dynamic updates.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 23:22:01 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:12:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ding", "Jialin", ""], ["Minhas", "Umar Farooq", ""], ["Yu", "Jia", ""], ["Wang", "Chi", ""], ["Do", "Jaeyoung", ""], ["Li", "Yinan", ""], ["Zhang", "Hantian", ""], ["Chandramouli", "Badrish", ""], ["Gehrke", "Johannes", ""], ["Kossmann", "Donald", ""], ["Lomet", "David", ""], ["Kraska", "Tim", ""]]}, {"id": "1905.08900", "submitter": "Shibo Yao", "authors": "Shibo Yao, Dantong Yu, Keli Xiao", "title": "Enhancing Domain Word Embedding via Latent Semantic Imputation", "comments": "ACM SIGKDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330926", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method named Latent Semantic Imputation (LSI) to transfer\nexternal knowledge into semantic space for enhancing word embedding. The method\nintegrates graph theory to extract the latent manifold structure of the\nentities in the affinity space and leverages non-negative least squares with\nstandard simplex constraints and power iteration method to derive spectral\nembeddings. It provides an effective and efficient approach to combining entity\nrepresentations defined in different Euclidean spaces. Specifically, our\napproach generates and imputes reliable embedding vectors for low-frequency\nwords in the semantic space and benefits downstream language tasks that depend\non word embedding. We conduct comprehensive experiments on a carefully designed\nclassification problem and language modeling and demonstrate the superiority of\nthe enhanced embedding via LSI over several well-known benchmark embeddings. We\nalso confirm the consistency of the results under different parameter settings\nof our method.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 23:31:45 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Yao", "Shibo", ""], ["Yu", "Dantong", ""], ["Xiao", "Keli", ""]]}, {"id": "1905.08909", "submitter": "Shahin Jabbari", "authors": "Jinshuo Dong and Hadi Elzayn and Shahin Jabbari and Michael Kearns and\n  Zachary Schutzman", "title": "Equilibrium Characterization for Data Acquisition Games", "comments": "The short version of this paper appears in the proceedings of\n  IJCAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a game between two firms in which each provide a service based on\nmachine learning. The firms are presented with the opportunity to purchase a\nnew corpus of data, which will allow them to potentially improve the quality of\ntheir products. The firms can decide whether or not they want to buy the data,\nas well as which learning model to build with that data. We demonstrate a\nreduction from this potentially complicated action space to a one-shot,\ntwo-action game in which each firm only decides whether or not to buy the data.\nThe game admits several regimes which depend on the relative strength of the\ntwo firms at the outset and the price at which the data is being offered. We\nanalyze the game's Nash equilibria in all parameter regimes and demonstrate\nthat, in expectation, the outcome of the game is that the initially stronger\nfirm's market position weakens whereas the initially weaker firm's market\nposition becomes stronger. Finally, we consider the perspective of the users of\nthe service and demonstrate that the expected outcome at equilibrium is not the\none which maximizes the welfare of the consumers.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 00:41:24 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 12:17:00 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Dong", "Jinshuo", ""], ["Elzayn", "Hadi", ""], ["Jabbari", "Shahin", ""], ["Kearns", "Michael", ""], ["Schutzman", "Zachary", ""]]}, {"id": "1905.08920", "submitter": "Luisa M\\\"arz", "authors": "Luisa M\\\"arz and Dietrich Trautmann and Benjamin Roth", "title": "Domain adaptation for part-of-speech tagging of noisy user-generated\n  text", "comments": "6 pages, NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a Part-of-speech (POS) tagger is highly dependent on the\ndomain ofthe processed text, and for many domains there is no or only very\nlittle training data available. This work addresses the problem of POS tagging\nnoisy user-generated text using a neural network. We propose an architecture\nthat trains an out-of-domain model on a large newswire corpus, and transfers\nthose weights by using them as a prior for a model trained on the target domain\n(a data-set of German Tweets) for which there is very little an-notations\navailable. The neural network has two standard bidirectional LSTMs at its core.\nHowever, we find it crucial to also encode a set of task-specific features, and\nto obtain reliable (source-domain and target-domain) word representations.\nExperiments with different regularization techniques such as early stopping,\ndropout and fine-tuning the domain adaptation prior weights are conducted. Our\nbest model uses external weights from the out-of-domain model, as well as\nfeature embeddings, pre-trained word and sub-word embeddings and achieves a\ntagging accuracy of slightly over 90%, improving on the previous state of the\nart for this task.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:33:06 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["M\u00e4rz", "Luisa", ""], ["Trautmann", "Dietrich", ""], ["Roth", "Benjamin", ""]]}, {"id": "1905.08922", "submitter": "Stefan Carlsson", "authors": "Stefan Carlsson", "title": "Geometry of Deep Convolutional Networks", "comments": "Work in progress (to be updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formal procedure for computing preimages of convolutional network\noutputs using the dual basis defined from the set of hyperplanes associated\nwith the layers of the network. We point out the special symmetry associated\nwith arrangements of hyperplanes of convolutional networks that take the form\nof regular multidimensional polyhedral cones. We discuss the efficiency of\nlarge number of layers of nested cones that result from incremental small size\nconvolutions in order to give a good compromise between efficient contraction\nof data to low dimensions and shaping of preimage manifolds. We demonstrate how\na specific network flattens a non linear input manifold to an affine output\nmanifold and discuss its relevance to understanding classification properties\nof deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:04:29 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Carlsson", "Stefan", ""]]}, {"id": "1905.08924", "submitter": "Peng Xu", "authors": "Peng Xu, Zhaohong Deng, Kup-Sze Choi, Jun Wang, Shitong Wang", "title": "Joint Information Preservation for Heterogeneous Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to assist the modeling tasks of the target domain with\nknowledge of the source domain. The two domains often lie in different feature\nspaces due to diverse data collection methods, which leads to the more\nchallenging task of heterogeneous domain adaptation (HDA). A core issue of HDA\nis how to preserve the information of the original data during adaptation. In\nthis paper, we propose a joint information preservation method to deal with the\nproblem. The method preserves the information of the original data from two\naspects. On the one hand, although paired samples often exist between the two\ndomains of the HDA, current algorithms do not utilize such information\nsufficiently. The proposed method preserves the paired information by\nmaximizing the correlation of the paired samples in the shared subspace. On the\nother hand, the proposed method improves the strategy of preserving the\nstructural information of the original data, where the local and global\nstructural information are preserved simultaneously. Finally, the joint\ninformation preservation is integrated by distribution matching. Experimental\nresults show the superiority of the proposed method over the state-of-the-art\nHDA algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 02:15:18 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Xu", "Peng", ""], ["Deng", "Zhaohong", ""], ["Choi", "Kup-Sze", ""], ["Wang", "Jun", ""], ["Wang", "Shitong", ""]]}, {"id": "1905.08926", "submitter": "Deepali Jain", "authors": "Deepali Jain, Atil Iscen, Ken Caluwaerts", "title": "Hierarchical Reinforcement Learning for Quadruped Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legged locomotion is a challenging task for learning algorithms, especially\nwhen the task requires a diverse set of primitive behaviors. To solve these\nproblems, we introduce a hierarchical framework to automatically decompose\ncomplex locomotion tasks. A high-level policy issues commands in a latent space\nand also selects for how long the low-level policy will execute the latent\ncommand. Concurrently, the low-level policy uses the latent command and only\nthe robot's on-board sensors to control the robot's actuators. Our approach\nallows the high-level policy to run at a lower frequency than the low-level\none. We test our framework on a path-following task for a dynamic quadruped\nrobot and we show that steering behaviors automatically emerge in the latent\ncommand space as low-level skills are needed for this task. We then show\nefficient adaptation of the trained policy to a different task by transfer of\nthe trained low-level policy. Finally, we validate the policies on a real\nquadruped robot. To the best of our knowledge, this is the first application of\nend-to-end hierarchical learning to a real robotic locomotion task.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 02:28:39 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Jain", "Deepali", ""], ["Iscen", "Atil", ""], ["Caluwaerts", "Ken", ""]]}, {"id": "1905.08930", "submitter": "Alexander Kushkuley", "authors": "Alexander Kushkuley", "title": "Heavy Hitters and Bernoulli Convolutions", "comments": "1) fixed some typos and a reference 2) expanded section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A very simple event frequency approximation algorithm that is sensitive to\nevent timeliness is suggested. The algorithm iteratively updates categorical\nclick-distribution, producing (path of) a random walk on a standard\n$n$-dimensional simplex. Under certain conditions, this random walk is\nself-similar and corresponds to a biased Bernoulli convolution. Algorithm\nevaluation naturally leads to estimation of moments of biased (finite and\ninfinite) Bernoulli convolutions.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 02:49:09 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:26:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kushkuley", "Alexander", ""]]}, {"id": "1905.08942", "submitter": "Micah Smith", "authors": "Micah J. Smith, Carles Sala, James Max Kanter, Kalyan Veeramachaneni", "title": "The Machine Learning Bazaar: Harnessing the ML Ecosystem for Effective\n  System Development", "comments": "To appear in SIGMOD '20", "journal-ref": "In Proceedings of the 2020 ACM SIGMOD International Conference on\n  Management of Data (SIGMOD '20). Association for Computing Machinery, New\n  York, NY, USA, 785-800", "doi": "10.1145/3318464.3386146", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is applied more widely, data scientists often struggle to\nfind or create end-to-end machine learning systems for specific tasks. The\nproliferation of libraries and frameworks and the complexity of the tasks have\nled to the emergence of \"pipeline jungles\" - brittle, ad hoc ML systems. To\naddress these problems, we introduce the Machine Learning Bazaar, a new\nframework for developing machine learning and automated machine learning\nsoftware systems. First, we introduce ML primitives, a unified API and\nspecification for data processing and ML components from different software\nlibraries. Next, we compose primitives into usable ML pipelines, abstracting\naway glue code, data flow, and data storage. We further pair these pipelines\nwith a hierarchy of AutoML strategies - Bayesian optimization and bandit\nlearning. We use these components to create a general-purpose, multi-task,\nend-to-end AutoML system that provides solutions to a variety of data\nmodalities (image, text, graph, tabular, relational, etc.) and problem types\n(classification, regression, anomaly detection, graph matching, etc.). We\ndemonstrate 5 real-world use cases and 2 case studies of our approach. Finally,\nwe present an evaluation suite of 456 real-world ML tasks and describe the\ncharacteristics of 2.5 million pipelines searched over this task suite.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 03:56:18 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 20:22:33 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 16:32:08 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2020 14:01:57 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Smith", "Micah J.", ""], ["Sala", "Carles", ""], ["Kanter", "James Max", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1905.08948", "submitter": "Kaixuan Chen", "authors": "Kaixuan Chen, Lina Yao, Dalin Zhang, Bin Guo, Zhiwen Yu", "title": "Multi-agent Attentional Activity Recognition", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modality is an important feature of sensor based activity recognition.\nIn this work, we consider two inherent characteristics of human activities, the\nspatially-temporally varying salience of features and the relations between\nactivities and corresponding body part motions. Based on these, we propose a\nmulti-agent spatial-temporal attention model. The spatial-temporal attention\nmechanism helps intelligently select informative modalities and their active\nperiods. And the multiple agents in the proposed model represent activities\nwith collective motions across body parts by independently selecting modalities\nassociated with single motions. With a joint recognition goal, the agents share\ngained information and coordinate their selection policies to learn the optimal\nrecognition model. The experimental results on four real-world datasets\ndemonstrate that the proposed model outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 04:17:55 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Chen", "Kaixuan", ""], ["Yao", "Lina", ""], ["Zhang", "Dalin", ""], ["Guo", "Bin", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1905.08975", "submitter": "Pedro Cisneros-Velarde", "authors": "Pedro Cisneros-Velarde, Sang-Yun Oh, Alexander Petersen", "title": "Distributionally Robust Formulation and Model Selection for the\n  Graphical Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on a recent framework for distributionally robust optimization, we\nconsider estimation of the inverse covariance matrix for multivariate data. We\nprovide a novel notion of a Wasserstein ambiguity set specifically tailored to\nthis estimation problem, leading to a tractable class of regularized\nestimators. Special cases include penalized likelihood estimators for Gaussian\ndata, specifically the graphical lasso estimator. As a consequence of this\nformulation, the radius of the Wasserstein ambiguity set is directly related to\nthe regularization parameter in the estimation problem. Using this\nrelationship, the level of robustness of the estimation procedure can be shown\nto correspond to the level of confidence with which the ambiguity set contains\na distribution with the population covariance. Furthermore, a unique feature of\nour formulation is that the radius can be expressed in closed-form as a\nfunction of the ordinary sample covariance matrix. Taking advantage of this\nfinding, we develop a simple algorithm to determine a regularization parameter\nfor graphical lasso, using only the bootstrapped sample covariance matrices,\nmeaning that computationally expensive repeated evaluation of the graphical\nlasso algorithm is not necessary. Alternatively, the distributionally robust\nformulation can also quantify the robustness of the corresponding estimator if\none uses an off-the-shelf method such as cross-validation. Finally, we\nnumerically study the obtained regularization criterion and analyze the\nrobustness of other automated tuning procedures used in practice.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 06:24:32 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 10:07:02 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Cisneros-Velarde", "Pedro", ""], ["Oh", "Sang-Yun", ""], ["Petersen", "Alexander", ""]]}, {"id": "1905.08983", "submitter": "Babak Namazi", "authors": "Babak Namazi, Ganesh Sankaranarayanan, Venkat Devarajan", "title": "LapTool-Net: A Contextual Detector of Surgical Tools in Laparoscopic\n  Videos Based on Recurrent Convolutional Neural Networks", "comments": "18 pages, 4 figures, Submitted to Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new multilabel classifier, called LapTool-Net to detect the\npresence of surgical tools in each frame of a laparoscopic video. The novelty\nof LapTool-Net is the exploitation of the correlation among the usage of\ndifferent tools and, the tools and tasks - namely, the context of the tools'\nusage. Towards this goal, the pattern in the co-occurrence of the tools is\nutilized for designing a decision policy for a multilabel classifier based on a\nRecurrent Convolutional Neural Network (RCNN) architecture to simultaneously\nextract the spatio-temporal features. In contrast to the previous multilabel\nclassification methods, the RCNN and the decision model are trained in an\nend-to-end manner using a multitask learning scheme. To overcome the high\nimbalance and avoid overfitting caused by the lack of variety in the training\ndata, a high down-sampling rate is chosen based on the more frequent\ncombinations. Furthermore, at the post-processing step, the prediction for all\nthe frames of a video are corrected by designing a bi-directional RNN to model\nthe long-term task's order. LapTool-net was trained using a publicly available\ndataset of laparoscopic cholecystectomy. The results show LapTool-Net\noutperforms existing methods significantly, even while using fewer training\nsamples and a shallower architecture.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 06:55:41 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Namazi", "Babak", ""], ["Sankaranarayanan", "Ganesh", ""], ["Devarajan", "Venkat", ""]]}, {"id": "1905.08990", "submitter": "Prasanna Chaporkar", "authors": "Kumar Yashashwi and Deepak Anand and Sibi Raj B Pillai and Prasanna\n  Chaporkar and K Ganesh", "title": "MIST: A Novel Training Strategy for Low-latency Scalable Neural Net\n  Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a low latency, robust and scalable neural net based\ndecoder for convolutional and low-density parity-check (LPDC) coding schemes.\nThe proposed decoders are demonstrated to have bit error rate (BER) and block\nerror rate (BLER) performances at par with the state-of-the-art neural net\nbased decoders while achieving more than 8 times higher decoding speed. The\nenhanced decoding speed is due to the use of convolutional neural network (CNN)\nas opposed to recurrent neural network (RNN) used in the best known neural net\nbased decoders. This contradicts existing doctrine that only RNN based decoders\ncan provide a performance close to the optimal ones. The key ingredient to our\napproach is a novel Mixed-SNR Independent Samples based Training (MIST), which\nallows for training of CNN with only 1\\% of possible datawords, even for block\nlength as high as 1000. The proposed decoder is robust as, once trained, the\nsame decoder can be used for a wide range of SNR values. Finally, in the\npresence of channel outages, the proposed decoders outperform the best known\ndecoders, {\\it viz.} unquantized Viterbi decoder for convolutional code, and\nbelief propagation for LDPC. This gives the CNN decoder a significant advantage\nin 5G millimeter wave systems, where channel outages are prevalent.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 07:17:06 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Yashashwi", "Kumar", ""], ["Anand", "Deepak", ""], ["Pillai", "Sibi Raj B", ""], ["Chaporkar", "Prasanna", ""], ["Ganesh", "K", ""]]}, {"id": "1905.09027", "submitter": "Ji Feng", "authors": "Ji Feng, Qi-Zhi Cai, Zhi-Hua Zhou", "title": "Learning to Confuse: Generating Training Time Adversarial Data with\n  Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider one challenging training time attack by modifying\ntraining data with bounded perturbation, hoping to manipulate the behavior\n(both targeted or non-targeted) of any corresponding trained classifier during\ntest time when facing clean samples. To achieve this, we proposed to use an\nauto-encoder-like network to generate the pertubation on the training data\npaired with one differentiable system acting as the imaginary victim\nclassifier. The perturbation generator will learn to update its weights by\nwatching the training procedure of the imaginary classifier in order to produce\nthe most harmful and imperceivable noise which in turn will lead the lowest\ngeneralization power for the victim classifier. This can be formulated into a\nnon-linear equality constrained optimization problem. Unlike GANs, solving such\nproblem is computationally challenging, we then proposed a simple yet effective\nprocedure to decouple the alternating updates for the two networks for\nstability. The method proposed in this paper can be easily extended to the\nlabel specific setting where the attacker can manipulate the predictions of the\nvictim classifiers according to some predefined rules rather than only making\nwrong predictions. Experiments on various datasets including CIFAR-10 and a\nreduced version of ImageNet confirmed the effectiveness of the proposed method\nand empirical results showed that, such bounded perturbation have good\ntransferability regardless of which classifier the victim is actually using on\nimage data.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:06:40 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Feng", "Ji", ""], ["Cai", "Qi-Zhi", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1905.09033", "submitter": "Davide Mazzini", "authors": "Davide Mazzini, Raimondo Schettini", "title": "Spatial Sampling Network for Fast Scene Understanding", "comments": "Accepted at CVPR2019 Workshop on Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a network architecture to perform efficient scene understanding.\nThis work presents three main novelties: the first is an Improved Guided\nUpsampling Module that can replace in toto the decoder part in common semantic\nsegmentation networks. Our second contribution is the introduction of a new\nmodule based on spatial sampling to perform Instance Segmentation. It provides\na very fast instance segmentation, needing only thresholding as post-processing\nstep at inference time. Finally, we propose a novel efficient network design\nthat includes the new modules and test it against different datasets for\noutdoor scene understanding. To our knowledge, our network is one of the\nthemost efficient architectures for scene understanding published to date,\nfurthermore being 8.6% more accurate than the fastest competitor on semantic\nsegmentation and almost five times faster than the most efficient network for\ninstance segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:24:17 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Mazzini", "Davide", ""], ["Schettini", "Raimondo", ""]]}, {"id": "1905.09045", "submitter": "Lorenzo Cerrone", "authors": "Lorenzo Cerrone, Alexander Zeilmann, Fred A. Hamprecht", "title": "End-to-End Learned Random Walker for Seeded Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an end-to-end learned algorithm for seeded segmentation. Our\nmethod is based on the Random Walker algorithm, where we predict the edge\nweights of the underlying graph using a convolutional neural network. This can\nbe interpreted as learning context-dependent diffusivities for a linear\ndiffusion process. Besides calculating the exact gradient for optimizing these\ndiffusivities, we also propose simplifications that sparsely sample the\ngradient and still yield competitive results. The proposed method achieves the\ncurrently best results on a seeded version of the CREMI neuron segmentation\nchallenge.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:56:04 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Cerrone", "Lorenzo", ""], ["Zeilmann", "Alexander", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1905.09054", "submitter": "Mete Ozay", "authors": "Mete Ozay", "title": "Fine-grained Optimization of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, several asymptotic upper bounds on generalization errors\non deep neural networks (DNNs) are theoretically derived. These bounds are\nfunctions of several norms of weights of the DNNs, such as the Frobenius and\nspectral norms, and they are computed for weights grouped according to either\ninput and output channels of the DNNs. In this work, we conjecture that if we\ncan impose multiple constraints on weights of DNNs to upper bound the norms of\nthe weights, and train the DNNs with these weights, then we can attain\nempirical generalization errors closer to the derived theoretical bounds, and\nimprove accuracy of the DNNs.\n  To this end, we pose two problems. First, we aim to obtain weights whose\ndifferent norms are all upper bounded by a constant number, e.g. 1.0. To\nachieve these bounds, we propose a two-stage renormalization procedure; (i)\nnormalization of weights according to different norms used in the bounds, and\n(ii) reparameterization of the normalized weights to set a constant and finite\nupper bound of their norms. In the second problem, we consider training DNNs\nwith these renormalized weights. To this end, we first propose a strategy to\nconstruct joint spaces (manifolds) of weights according to different\nconstraints in DNNs. Next, we propose a fine-grained SGD algorithm (FG-SGD) for\noptimization on the weight manifolds to train DNNs with assurance of\nconvergence to minima. Experimental results show that image classification\naccuracy of baseline DNNs can be boosted using FG-SGD on collections of\nmanifolds identified by multiple constraints.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:18:58 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Ozay", "Mete", ""]]}, {"id": "1905.09056", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "Learning Networked Exponential Families with Network Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose networked exponential families to jointly leverage the information\nin the topology as well as the attributes (features) of networked data points.\nNetworked exponential families are a flexible probabilistic model for\nheterogeneous datasets with intrinsic network structure. These models can be\nlearnt efficiently using network Lasso which implicitly pools or clusters the\ndata points according to the intrinsic network structure and the local\nlikelihood. The resulting method can be formulated as a non-smooth convex\noptimization problem which we solve using a primal-dual splitting method. This\nprimal-dual method is appealing for big data applications as it can be\nimplemented as a highly scalable message passing algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:34:09 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:35:11 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 13:10:13 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 17:19:43 GMT"}, {"version": "v5", "created": "Thu, 1 Aug 2019 11:21:14 GMT"}, {"version": "v6", "created": "Wed, 25 Sep 2019 07:48:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1905.09068", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Vera Goebel, Thomas\n  Plagemann, Knut Liest{\\o}l, Mohan Kankanhalli", "title": "Augmenting Physiological Time Series Data: A Case Study for Sleep Apnea\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning applications in the health domain often face the\nproblem of insufficient training datasets. The quantity of labelled data is\nsmall due to privacy concerns and the cost of data acquisition and labelling by\na medical expert. Furthermore, it is quite common that collected data are\nunbalanced and getting enough data to personalize models for individuals is\nvery expensive or even infeasible. This paper addresses these problems by (1)\ndesigning a recurrent Generative Adversarial Network to generate realistic\nsynthetic data and to augment the original dataset, (2) enabling the generation\nof balanced datasets based on heavily unbalanced dataset, and (3) to control\nthe data generation in such a way that the generated data resembles data from\nspecific individuals. We apply these solutions for sleep apnea detection and\nstudy in the evaluation the performance of four well-known techniques, i.e.,\nK-Nearest Neighbour, Random Forest, Multi-Layer Perceptron, and Support Vector\nMachine. All classifiers exhibit in the experiments a consistent increase in\nsensitivity and a kappa statistic increase by between 0.007 and 0.182.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:01:34 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Goebel", "Vera", ""], ["Plagemann", "Thomas", ""], ["Liest\u00f8l", "Knut", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1905.09086", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Dimitar Marinov, Abdullah Gok, and Goran Nenadic", "title": "From web crawled text to project descriptions: automatic summarizing of\n  social innovation projects", "comments": "Keywords: Summarization, evaluation metrics, text mining, natural\n  language processing, social innovation, SVM, neural networks Accepted for\n  publication in Proceedings of 24th International Conference on Applications\n  of Natural Language to Information Systems (NLDB2019)", "journal-ref": "Preceeding of 24th International Conference on Applications of\n  Natural Language to Information Systems (NLDB2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past decade, social innovation projects have gained the attention of\npolicy makers, as they address important social issues in an innovative manner.\nA database of social innovation is an important source of information that can\nexpand collaboration between social innovators, drive policy and serve as an\nimportant resource for research. Such a database needs to have projects\ndescribed and summarized. In this paper, we propose and compare several methods\n(e.g. SVM-based, recurrent neural network based, ensambled) for describing\nprojects based on the text that is available on project websites. We also\naddress and propose a new metric for automated evaluation of summaries based on\ntopic modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:49:37 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Milosevic", "Nikola", ""], ["Marinov", "Dimitar", ""], ["Gok", "Abdullah", ""], ["Nenadic", "Goran", ""]]}, {"id": "1905.09087", "submitter": "Akanda Wahid -Ul- Ashraf", "authors": "Akanda Wahid -Ul- Ashraf, Marcin Budka, Katarzyna Musial", "title": "Simulation and Augmentation of Social Networks for Building Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A limitation of the Graph Convolutional Networks (GCNs) is that it assumes at\na particular $l^{th}$ layer of the neural network model only the $l^{th}$ order\nneighbourhood nodes of a social network are influential. Furthermore, the GCN\nhas been evaluated on citation and knowledge graphs, but not extensively on\nfriendship-based social graphs. The drawback associated with the dependencies\nbetween layers and the order of node neighbourhood for the GCN can be more\nprevalent for friendship-based graphs. The evaluation of the full potential of\nthe GCN on friendship-based social network requires openly available datasets\nin larger quantities. However, most available social network datasets are not\ncomplete. Also, the majority of the available social network datasets do not\ncontain both the features and ground truth labels. In this work, firstly, we\nprovide a guideline on simulating dynamic social networks, with ground truth\nlabels and features, both coupled with the topology. Secondly, we introduce an\nopen-source Python-based simulation library. We argue that the topology of the\nnetwork is driven by a set of latent variables, termed as the social DNA\n(sDNA). We consider the sDNA as labels for the nodes. Finally, by evaluating on\nour simulated datasets, we propose four new variants of the GCN, mainly to\novercome the limitation of dependency between the order of node-neighbourhood\nand a particular layer of the model. We then evaluate the performance of all\nthe models and our results show that on 27 out of the 30 simulated datasets our\nproposed GCN variants outperform the original model.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:54:16 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 18:11:10 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 09:23:49 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ashraf", "Akanda Wahid -Ul-", ""], ["Budka", "Marcin", ""], ["Musial", "Katarzyna", ""]]}, {"id": "1905.09107", "submitter": "Michael Schaub", "authors": "Michael T. Schaub and Santiago Segarra and John N. Tsitsiklis", "title": "Blind identification of stochastic block models from dynamical\n  observations", "comments": "33 pages; 4 figures", "journal-ref": "SIAM Journal on Mathematics of Data Science 2020 2:2, 335-367", "doi": "10.1137/19M1263340", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a blind identification problem in which we aim to recover a\nstatistical model of a network without knowledge of the network's edges, but\nbased solely on nodal observations of a certain process. More concretely, we\nfocus on observations that consist of single snapshots taken from multiple\ntrajectories of a diffusive process that evolves over the unknown network. We\nmodel the network as generated from an independent draw from a latent\nstochastic block model (SBM), and our goal is to infer both the partition of\nthe nodes into blocks, as well as the parameters of this SBM. We discuss some\nnon-identifiability issues related to this problem and present simple spectral\nalgorithms that provably solve the partition recovery and parameter estimation\nproblems with high accuracy. Our analysis relies on recent results in random\nmatrix theory and covariance estimation, and associated concentration\ninequalities. We illustrate our results with several numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 12:45:04 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 12:28:04 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Schaub", "Michael T.", ""], ["Segarra", "Santiago", ""], ["Tsitsiklis", "John N.", ""]]}, {"id": "1905.09130", "submitter": "Stefano Giovanni Rizzo", "authors": "Stefano Giovanni Rizzo, Ji Lucas, Zoi Kaoudi, Jorge-Arnulfo\n  Quiane-Ruiz, Sanjay Chawla", "title": "AI-CARGO: A Data-Driven Air-Cargo Revenue Management System", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AI-CARGO, a revenue management system for air-cargo that combines\nmachine learning prediction with decision-making using mathematical\noptimization methods. AI-CARGO addresses a problem that is unique to the\nair-cargo business, namely the wide discrepancy between the quantity (weight or\nvolume) that a shipper will book and the actual received amount at departure\ntime by the airline. The discrepancy results in sub-optimal and inefficient\nbehavior by both the shipper and the airline resulting in the overall loss of\npotential revenue for the airline. AI-CARGO also includes a data cleaning\ncomponent to deal with the heterogeneous forms in which booking data is\ntransmitted to the airline cargo system. AI-CARGO is deployed in the production\nenvironment of a large commercial airline company. We have validated the\nbenefits of AI-CARGO using real and synthetic datasets. Especially, we have\ncarried out simulations using dynamic programming techniques to elicit the\nimpact on offloading costs and revenue generation of our proposed system. Our\nresults suggest that combining prediction within a decision-making framework\ncan help dramatically to reduce offloading costs and optimize revenue\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:34:45 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Rizzo", "Stefano Giovanni", ""], ["Lucas", "Ji", ""], ["Kaoudi", "Zoi", ""], ["Quiane-Ruiz", "Jorge-Arnulfo", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1905.09148", "submitter": "Jingjing Zhang", "authors": "Jingjing Zhang and Osvaldo Simeone", "title": "LAGC: Lazily Aggregated Gradient Coding for Straggler-Tolerant and\n  Communication-Efficient Distributed Learning", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based distributed learning in Parameter Server (PS) computing\narchitectures is subject to random delays due to straggling worker nodes, as\nwell as to possible communication bottlenecks between PS and workers. Solutions\nhave been recently proposed to separately address these impairments based on\nthe ideas of gradient coding, worker grouping, and adaptive worker selection.\nThis paper provides a unified analysis of these techniques in terms of\nwall-clock time, communication, and computation complexity measures.\nFurthermore, in order to combine the benefits of gradient coding and grouping\nin terms of robustness to stragglers with the communication and computation\nload gains of adaptive selection, novel strategies, named Lazily Aggregated\nGradient Coding (LAGC) and Grouped-LAG (G-LAG), are introduced. Analysis and\nresults show that G-LAG provides the best wall-clock time and communication\nperformance, while maintaining a low computational cost, for two representative\ndistributions of the computing times of the worker nodes.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:00:13 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 13:22:40 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Zhang", "Jingjing", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1905.09153", "submitter": "Timothy Miller", "authors": "Timothy A Miller", "title": "Simplified Neural Unsupervised Domain Adaptation", "comments": "To be presented at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) is the task of modifying a statistical\nmodel trained on labeled data from a source domain to achieve better\nperformance on data from a target domain, with access to only unlabeled data in\nthe target domain. Existing state-of-the-art UDA approaches use neural networks\nto learn representations that can predict the values of subset of important\nfeatures called \"pivot features.\" In this work, we show that it is possible to\nimprove on these methods by jointly training the representation learner with\nthe task learner, and examine the importance of existing pivot selection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:11:30 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Miller", "Timothy A", ""]]}, {"id": "1905.09165", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade,\n  Vinod Ganapathy", "title": "A framework for the extraction of Deep Neural Networks by leveraging\n  public data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained on confidential datasets are increasingly\nbeing deployed for profit. Machine Learning as a Service (MLaaS) has made such\nmodels easily accessible to end-users. Prior work has developed model\nextraction attacks, in which an adversary extracts an approximation of MLaaS\nmodels by making black-box queries to it. However, none of these works is able\nto satisfy all the three essential criteria for practical model extraction: (1)\nthe ability to work on deep learning models, (2) the non-requirement of domain\nknowledge and (3) the ability to work with a limited query budget. We design a\nmodel extraction framework that makes use of active learning and large public\ndatasets to satisfy them. We demonstrate that it is possible to use this\nframework to steal deep classifiers trained on a variety of datasets from image\nand text domains. By querying a model via black-box access for its top\nprediction, our framework improves performance on an average over a uniform\nnoise baseline by 4.70x for image tasks and 2.11x for text tasks respectively,\nwhile using only 30% (30,000 samples) of the public dataset at its disposal.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:26:04 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Shukla", "Aditya", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""], ["Ganapathy", "Vinod", ""]]}, {"id": "1905.09173", "submitter": "Shervin Rahimzadeh Arashloo", "authors": "Shervin Rahimzadeh Arashloo and Josef Kittler", "title": "Multi-Task Kernel Null-Space for One-Class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one-class kernel spectral regression (OC-KSR), the regression-based\nformulation of the kernel null-space approach has been found to be an effective\nFisher criterion-based methodology for one-class classification (OCC),\nachieving state-of-the-art performance in one-class classification while\nproviding relatively high robustness against data corruption. This work extends\nthe OC-KSR methodology to a multi-task setting where multiple one-class\nproblems share information for improved performance. By viewing the multi-task\nstructure learning problem as one of compositional function learning, first,\nthe OC-KSR method is extended to learn multiple tasks' structure\n\\textit{linearly} by posing it as an instantiation of the separable kernel\nlearning problem in a vector-valued reproducing kernel Hilbert space where an\noutput kernel encodes tasks' structure while another kernel captures input\nsimilarities. Next, a non-linear structure learning mechanism is proposed which\ncaptures multiple tasks' relationships \\textit{non-linearly} via an output\nkernel. The non-linear structure learning method is then extended to a sparse\nsetting where different tasks compete in an output composition mechanism,\nleading to a sparse non-linear structure among multiple problems. Through\nextensive experiments on different data sets, the merits of the proposed\nmulti-task kernel null-space techniques are verified against the baseline as\nwell as other existing multi-task one-class learning techniques.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:41:29 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Arashloo", "Shervin Rahimzadeh", ""], ["Kittler", "Josef", ""]]}, {"id": "1905.09186", "submitter": "Jonathan Aigrain", "authors": "Jonathan Aigrain, Marcin Detyniecki", "title": "Detecting Adversarial Examples and Other Misclassifications in Neural\n  Networks by Introspection", "comments": "5 pages, 2 figures, Presented at the ICML 2019 Workshop on\n  Uncertainty and Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite having excellent performances for a wide variety of tasks, modern\nneural networks are unable to provide a reliable confidence value allowing to\ndetect misclassifications. This limitation is at the heart of what is known as\nan adversarial example, where the network provides a wrong prediction\nassociated with a strong confidence to a slightly modified image. Moreover,\nthis overconfidence issue has also been observed for regular errors and\nout-of-distribution data. We tackle this problem by what we call introspection,\ni.e. using the information provided by the logits of an already pretrained\nneural network. We show that by training a simple 3-layers neural network on\ntop of the logit activations, we are able to detect misclassifications at a\ncompetitive level.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:12:50 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Aigrain", "Jonathan", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1905.09190", "submitter": "Daniel LeJeune", "authors": "Daniel LeJeune, Gautam Dasarathy, Richard G. Baraniuk", "title": "Thresholding Graph Bandits with GrAPL", "comments": "14 pages, 3 figures. To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a new online decision making paradigm that we\ncall Thresholding Graph Bandits. The main goal is to efficiently identify a\nsubset of arms in a multi-armed bandit problem whose means are above a\nspecified threshold. While traditionally in such problems, the arms are assumed\nto be independent, in our paradigm we further suppose that we have access to\nthe similarity between the arms in the form of a graph, allowing us gain\ninformation about the arm means in fewer samples. Such settings play a key role\nin a wide range of modern decision making problems where rapid decisions need\nto be made in spite of the large number of options available at each time. We\npresent GrAPL, a novel algorithm for the thresholding graph bandit problem. We\ndemonstrate theoretically that this algorithm is effective in taking advantage\nof the graph structure when available and the reward function homophily (that\nstrongly connected arms have similar rewards) when favorable. We confirm these\ntheoretical findings via experiments on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:21:56 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 16:52:00 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 18:54:25 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["LeJeune", "Daniel", ""], ["Dasarathy", "Gautam", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1905.09191", "submitter": "Takuya Hiraoka", "authors": "Takuya Hiraoka, Takahisa Imagawa, Tatsuya Mori, Takashi Onishi,\n  Yoshimasa Tsuruoka", "title": "Learning Robust Options by Conditional Value at Risk Optimization", "comments": "NeurIPS 2019. Video demo:\n  https://drive.google.com/open?id=1xXgSeEa_nNG397ZkIayk3CwYPy_BPy8X Source\n  codes:\n  https://github.com/TakuyaHiraoka/Learning-Robust-Options-by-Conditional-Value-at-Risk-Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Options are generally learned by using an inaccurate environment model (or\nsimulator), which contains uncertain model parameters. While there are several\nmethods to learn options that are robust against the uncertainty of model\nparameters, these methods only consider either the worst case or the average\n(ordinary) case for learning options. This limited consideration of the cases\noften produces options that do not work well in the unconsidered case. In this\npaper, we propose a conditional value at risk (CVaR)-based method to learn\noptions that work well in both the average and worst cases. We extend the\nCVaR-based policy gradient method proposed by Chow and Ghavamzadeh (2014) to\ndeal with robust Markov decision processes and then apply the extended method\nto learning robust options. We conduct experiments to evaluate our method in\nmulti-joint robot control tasks (HopperIceBlock, Half-Cheetah, and Walker2D).\nExperimental results show that our method produces options that 1) give better\nworst-case performance than the options learned only to minimize the\naverage-case loss, and 2) give better average-case performance than the options\nlearned only to minimize the worst-case loss.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:23:08 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 09:26:07 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 07:21:59 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 06:10:40 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Hiraoka", "Takuya", ""], ["Imagawa", "Takahisa", ""], ["Mori", "Tatsuya", ""], ["Onishi", "Takashi", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1905.09195", "submitter": "Satoshi Hayakawa", "authors": "Satoshi Hayakawa, Taiji Suzuki", "title": "On the minimax optimality and superiority of deep neural network\n  learning over sparse parameter spaces", "comments": "33 pages", "journal-ref": null, "doi": "10.1016/j.neunet.2019.12.014", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been applied to various tasks in the field of machine\nlearning and has shown superiority to other common procedures such as kernel\nmethods. To provide a better theoretical understanding of the reasons for its\nsuccess, we discuss the performance of deep learning and other methods on a\nnonparametric regression problem with a Gaussian noise. Whereas existing\ntheoretical studies of deep learning have been based mainly on mathematical\ntheories of well-known function classes such as H\\\"{o}lder and Besov classes,\nwe focus on function classes with discontinuity and sparsity, which are those\nnaturally assumed in practice. To highlight the effectiveness of deep learning,\nwe compare deep learning with a class of linear estimators representative of a\nclass of shallow estimators. It is shown that the minimax risk of a linear\nestimator on the convex hull of a target function class does not differ from\nthat of the original target function class. This results in the suboptimality\nof linear methods over a simple but non-convex function class, on which deep\nlearning can attain nearly the minimax-optimal rate. In addition to this\nextreme case, we consider function classes with sparse wavelet coefficients. On\nthese function classes, deep learning also attains the minimax rate up to log\nfactors of the sample size, and linear methods are still suboptimal if the\nassumed sparsity is strong. We also point out that the parameter sharing of\ndeep neural networks can remarkably reduce the complexity of the model in our\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:35:40 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 14:43:41 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Hayakawa", "Satoshi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1905.09201", "submitter": "Jonas Kohler", "authors": "Jonas Kohler, Leonard Adolphs, Aurelien Lucchi", "title": "Adaptive norms for deep learning with regularized Newton methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of regularized Newton methods with adaptive norms for\noptimizing neural networks. This approach can be seen as a second-order\ncounterpart of adaptive gradient methods, which we here show to be\ninterpretable as first-order trust region methods with ellipsoidal constraints.\nIn particular, we prove that the preconditioning matrix used in RMSProp and\nAdam satisfies the necessary conditions for provable convergence of\nsecond-order trust region methods with standard worst-case complexities on\ngeneral non-convex objectives. Furthermore, we run experiments across different\nneural architectures and datasets to find that the ellipsoidal constraints\nconstantly outperform their spherical counterpart both in terms of number of\nbackpropagations and asymptotic loss value. Finally, we find comparable\nperformance to state-of-the-art first-order methods in terms of\nbackpropagations, but further advances in hardware are needed to render Newton\nmethods competitive in terms of computational time.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:45:24 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 16:15:44 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 08:43:06 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 11:38:58 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kohler", "Jonas", ""], ["Adolphs", "Leonard", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "1905.09205", "submitter": "William La Cava", "authors": "William La Cava, Heather Williams, Weixuan Fu, Steve Vitale, Durga\n  Srivatsan, Jason H. Moore", "title": "Evaluating recommender systems for AI-driven biomedical informatics", "comments": "17 pages, 8 figures. this version fixes link to pennai in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Many researchers with domain expertise are unable to easily apply\nmachine learning to their bioinformatics data due to a lack of machine learning\nand/or coding expertise. Methods that have been proposed thus far to automate\nmachine learning mostly require programming experience as well as expert\nknowledge to tune and apply the algorithms correctly. Here, we study a method\nof automating biomedical data science using a web-based platform that uses AI\nto recommend model choices and conduct experiments. We have two goals in mind:\nfirst, to make it easy to construct sophisticated models of biomedical\nprocesses; and second, to provide a fully automated AI agent that can choose\nand conduct promising experiments for the user, based on the user's experiments\nas well as prior knowledge. To validate this framework, we experiment with\nhundreds of classification problems, comparing to state-of-the-art, automated\napproaches. Finally, we use this tool to develop predictive models of septic\nshock in critical care patients.\n  Results: We find that matrix factorization-based recommendation systems\noutperform meta-learning methods for automating machine learning. This result\nmirrors the results of earlier recommender systems research in other domains.\nThe proposed AI is competitive with state-of-the-art automated machine learning\nmethods in terms of choosing optimal algorithm configurations for datasets. In\nour application to prediction of septic shock, the AI-driven analysis produces\na competent machine learning model (AUROC 0.85 +/- 0.02) that performs on par\nwith state-of-the-art deep learning results for this task, with much less\ncomputational effort.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:53:53 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 21:26:56 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 18:53:25 GMT"}, {"version": "v4", "created": "Tue, 28 Apr 2020 15:46:33 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["La Cava", "William", ""], ["Williams", "Heather", ""], ["Fu", "Weixuan", ""], ["Vitale", "Steve", ""], ["Srivatsan", "Durga", ""], ["Moore", "Jason H.", ""]]}, {"id": "1905.09207", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Akbar Siami Namin", "title": "Deep Reinforcement Learning for Detecting Malicious Websites", "comments": "8 pages, 2 figures, COMPSAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is the simplest form of cybercrime with the objective of baiting\npeople into giving away delicate information such as individually recognizable\ndata, banking and credit card details, or even credentials and passwords. This\ntype of simple yet most effective cyber-attack is usually launched through\nemails, phone calls, or instant messages. The credential or private data stolen\nare then used to get access to critical records of the victims and can result\nin extensive fraud and monetary loss. Hence, sending malicious messages to\nvictims is a stepping stone of the phishing procedure. A \\textit{phisher}\nusually setups a deceptive website, where the victims are conned into entering\ncredentials and sensitive information. It is therefore important to detect\nthese types of malicious websites before causing any harmful damages to\nvictims. Inspired by the evolving nature of the phishing websites, this paper\nintroduces a novel approach based on deep reinforcement learning to model and\ndetect malicious URLs. The proposed model is capable of adapting to the dynamic\nbehavior of the phishing websites and thus learn the features associated with\nphishing website detection.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:55:22 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1905.09209", "submitter": "Zachary Charles", "authors": "Zachary Charles, Shashank Rajput, Stephen Wright, Dimitris\n  Papailiopoulos", "title": "Convergence and Margin of Adversarial Training on Separable Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a technique for training robust machine learning\nmodels. To encourage robustness, it iteratively computes adversarial examples\nfor the model, and then re-trains on these examples via some update rule. This\nwork analyzes the performance of adversarial training on linearly separable\ndata, and provides bounds on the number of iterations required for large\nmargin. We show that when the update rule is given by an arbitrary empirical\nrisk minimizer, adversarial training may require exponentially many iterations\nto obtain large margin. However, if gradient or stochastic gradient update\nrules are used, only polynomially many iterations are required to find a\nlarge-margin separator. By contrast, without the use of adversarial examples,\ngradient methods may require exponentially many iterations to achieve large\nmargin. Our results are derived by showing that adversarial training with\ngradient updates minimizes a robust version of the empirical risk at a\n$\\mathcal{O}(\\ln(t)^2/t)$ rate, despite non-smoothness. We corroborate our\ntheory empirically.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:00:25 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Charles", "Zachary", ""], ["Rajput", "Shashank", ""], ["Wright", "Stephen", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1905.09219", "submitter": "Shiqiang Wang", "authors": "Tiffany Tuor, Shiqiang Wang, Kin K. Leung, Bong Jun Ko", "title": "Online Collection and Forecasting of Resource Utilization in Large-Scale\n  Distributed Systems", "comments": "Accepted at IEEE International Conference on Distributed Computing\n  Systems (ICDCS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed computing systems often contain thousands of\ndistributed nodes (machines). Monitoring the conditions of these nodes is\nimportant for system management purposes, which, however, can be extremely\nresource demanding as this requires collecting local measurements of each\nindividual node and constantly sending those measurements to a central\ncontroller. Meanwhile, it is often useful to forecast the future system\nconditions for various purposes such as resource planning/allocation and\nanomaly detection, but it is usually too resource-consuming to have one\nforecasting model running for each node, which may also neglect correlations in\nobserved metrics across different nodes. In this paper, we propose a mechanism\nfor collecting and forecasting the resource utilization of machines in a\ndistributed computing system in a scalable manner. We present an algorithm that\nallows each local node to decide when to transmit its most recent measurement\nto the central node, so that the transmission frequency is kept below a given\nconstraint value. Based on the measurements received from local nodes, the\ncentral node summarizes the received data into a small number of clusters.\nSince the cluster partitioning can change over time, we also present a method\nto capture the evolution of clusters and their centroids. As an effective way\nto reduce the amount of computation, time-series forecasting models are trained\non the time-varying centroids of each cluster, to forecast the future resource\nutilizations of a group of local nodes. The effectiveness of our proposed\napproach is confirmed by extensive experiments using multiple real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:14:14 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Tuor", "Tiffany", ""], ["Wang", "Shiqiang", ""], ["Leung", "Kin K.", ""], ["Ko", "Bong Jun", ""]]}, {"id": "1905.09239", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis, Behzad Tabibian, Moein Khajehnejad, Adish Singla,\n  Bernhard Sch\\\"olkopf, Manuel Gomez-Rodriguez", "title": "Optimal Decision Making Under Strategic Behavior", "comments": "New method of estimating the outcome probabilities and setting the\n  cost function values. New experiments on credit card data. Performance\n  optimization in the presence of non-actionable features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are witnessing an increasing use of data-driven predictive models to\ninform decisions. As decisions have implications for individuals and society,\nthere is increasing pressure on decision makers to be transparent about their\ndecision policies. At the same time, individuals may use knowledge, gained by\ntransparency, to invest effort strategically in order to maximize their chances\nof receiving a beneficial decision. Our goal is to find decision policies that\nare optimal in terms of utility in such a strategic setting. To this end, we\nfirst characterize how strategic investment of effort by individuals leads to a\nchange in the feature distribution. Using this characterization, we first show\nthat, in general, we cannot expect to find optimal decision policies in\npolynomial time and there are cases in which deterministic policies are\nsuboptimal. Then, we demonstrate that, if the cost individuals pay to change\ntheir features satisfies a natural monotonicity assumption, we can narrow down\nthe search for the optimal policy to a particular family of decision policies\nwith a set of desirable properties, which allow for a highly effective\npolynomial time heuristic search algorithm using dynamic programming. Finally,\nunder no assumptions on the cost individuals pay to change their features, we\ndevelop an iterative search algorithm that is guaranteed to find locally\noptimal decision policies also in polynomial time. Experiments on synthetic and\nreal credit card data illustrate our theoretical findings and show that the\ndecision policies found by our algorithms achieve higher utility than those\nthat do not account for strategic behavior.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:55:24 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 08:08:52 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 08:38:35 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 22:11:06 GMT"}, {"version": "v5", "created": "Mon, 21 Sep 2020 10:53:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["Tabibian", "Behzad", ""], ["Khajehnejad", "Moein", ""], ["Singla", "Adish", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1905.09263", "submitter": "Yi Ren", "authors": "Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan\n  Liu", "title": "FastSpeech: Fast, Robust and Controllable Text to Speech", "comments": "Accepted by NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based end-to-end text to speech (TTS) has significantly\nimproved the quality of synthesized speech. Prominent methods (e.g., Tacotron\n2) usually first generate mel-spectrogram from text, and then synthesize speech\nfrom the mel-spectrogram using vocoder such as WaveNet. Compared with\ntraditional concatenative and statistical parametric approaches, neural network\nbased end-to-end models suffer from slow inference speed, and the synthesized\nspeech is usually not robust (i.e., some words are skipped or repeated) and\nlack of controllability (voice speed or prosody control). In this work, we\npropose a novel feed-forward network based on Transformer to generate\nmel-spectrogram in parallel for TTS. Specifically, we extract attention\nalignments from an encoder-decoder based teacher model for phoneme duration\nprediction, which is used by a length regulator to expand the source phoneme\nsequence to match the length of the target mel-spectrogram sequence for\nparallel mel-spectrogram generation. Experiments on the LJSpeech dataset show\nthat our parallel model matches autoregressive models in terms of speech\nquality, nearly eliminates the problem of word skipping and repeating in\nparticularly hard cases, and can adjust voice speed smoothly. Most importantly,\ncompared with autoregressive Transformer TTS, our model speeds up\nmel-spectrogram generation by 270x and the end-to-end speech synthesis by 38x.\nTherefore, we call our model FastSpeech.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:50:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 17:32:34 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 07:27:40 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 15:54:15 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2019 09:37:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ren", "Yi", ""], ["Ruan", "Yangjun", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Sheng", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.09264", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Stephanie Walker, Dylan Shah, Michael Levin, Rebecca\n  Kramer-Bottiglio, Josh Bongard", "title": "Automated shapeshifting for function recovery in damaged robots", "comments": null, "journal-ref": "Proceedings of Robotics: Science and Systems (2019)", "doi": "10.15607/RSS.2019.XV.028", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot's mechanical parts routinely wear out from normal functioning and can\nbe lost to injury. For autonomous robots operating in isolated or hostile\nenvironments, repair from a human operator is often not possible. Thus, much\nwork has sought to automate damage recovery in robots. However, every case\nreported in the literature to date has accepted the damaged mechanical\nstructure as fixed, and focused on learning new ways to control it. Here we\nshow for the first time a robot that automatically recovers from unexpected\ndamage by deforming its resting mechanical structure without changing its\ncontrol policy. We found that, especially in the case of \"deep insult\", such as\nremoval of all four of the robot's legs, the damaged machine evolves shape\nchanges that not only recover the original level of function (locomotion) as\nbefore, but can in fact surpass the original level of performance (speed). This\nsuggests that shape change, instead of control readaptation, may be a better\nmethod to recover function after damage in some cases.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:50:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kriegman", "Sam", ""], ["Walker", "Stephanie", ""], ["Shah", "Dylan", ""], ["Levin", "Michael", ""], ["Kramer-Bottiglio", "Rebecca", ""], ["Bongard", "Josh", ""]]}, {"id": "1905.09272", "submitter": "Olivier H\\'enaff", "authors": "Olivier J. H\\'enaff, Aravind Srinivas, Jeffrey De Fauw, Ali Razavi,\n  Carl Doersch, S. M. Ali Eslami, Aaron van den Oord", "title": "Data-Efficient Image Recognition with Contrastive Predictive Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human observers can learn to recognize new categories of images from a\nhandful of examples, yet doing so with artificial ones remains an open\nchallenge. We hypothesize that data-efficient recognition is enabled by\nrepresentations which make the variability in natural signals more predictable.\nWe therefore revisit and improve Contrastive Predictive Coding, an unsupervised\nobjective for learning such representations. This new implementation produces\nfeatures which support state-of-the-art linear classification accuracy on the\nImageNet dataset. When used as input for non-linear classification with deep\nneural networks, this representation allows us to use 2-5x less labels than\nclassifiers trained directly on image pixels. Finally, this unsupervised\nrepresentation substantially improves transfer learning to object detection on\nthe PASCAL VOC dataset, surpassing fully supervised pre-trained ImageNet\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:57:49 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:35:23 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 11:22:05 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["H\u00e9naff", "Olivier J.", ""], ["Srinivas", "Aravind", ""], ["De Fauw", "Jeffrey", ""], ["Razavi", "Ali", ""], ["Doersch", "Carl", ""], ["Eslami", "S. M. Ali", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1905.09275", "submitter": "Nicholas Watters", "authors": "Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess,\n  Alexander Lerchner", "title": "COBRA: Data-Efficient Model-Based RL through Unsupervised Object\n  Discovery and Curiosity-Driven Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data efficiency and robustness to task-irrelevant perturbations are\nlong-standing challenges for deep reinforcement learning algorithms. Here we\nintroduce a modular approach to addressing these challenges in a continuous\ncontrol environment, without using hand-crafted or supervised information. Our\nCurious Object-Based seaRch Agent (COBRA) uses task-free intrinsically\nmotivated exploration and unsupervised learning to build object-based models of\nits environment and action space. Subsequently, it can learn a variety of tasks\nthrough model-based search in very few steps and excel on structured hold-out\ntests of policy robustness.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:59:32 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 10:36:39 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Watters", "Nicholas", ""], ["Matthey", "Loic", ""], ["Bosnjak", "Matko", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1905.09314", "submitter": "Jung Hun Oh", "authors": "Jung Hun Oh, Maryam Pouryahya, Aditi Iyer, Aditya P. Apte, Allen\n  Tannenbaum, Joseph O. Deasy", "title": "Kernel Wasserstein Distance", "comments": "10 pages, 4 figures", "journal-ref": "Comput Biol Med. 2020", "doi": "10.1016/j.compbiomed.2020.103731", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance is a powerful metric based on the theory of optimal\ntransport. It gives a natural measure of the distance between two distributions\nwith a wide range of applications. In contrast to a number of the common\ndivergences on distributions such as Kullback-Leibler or Jensen-Shannon, it is\n(weakly) continuous, and thus ideal for analyzing corrupted data. To date,\nhowever, no kernel methods for dealing with nonlinear data have been proposed\nvia the Wasserstein distance. In this work, we develop a novel method to\ncompute the L2-Wasserstein distance in a kernel space implemented using the\nkernel trick. The latter is a general method in machine learning employed to\nhandle data in a nonlinear manner. We evaluate the proposed approach in\nidentifying computerized tomography (CT) slices with dental artifacts in head\nand neck cancer, performing unsupervised hierarchical clustering on the\nresulting Wasserstein distance matrix that is computed on imaging texture\nfeatures extracted from each CT slice. Our experiments show that the kernel\napproach outperforms classical non-kernel approaches in identifying CT slices\nwith artifacts.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 18:19:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Oh", "Jung Hun", ""], ["Pouryahya", "Maryam", ""], ["Iyer", "Aditi", ""], ["Apte", "Aditya P.", ""], ["Tannenbaum", "Allen", ""], ["Deasy", "Joseph O.", ""]]}, {"id": "1905.09334", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Sherjil Ozair, Yoshua Bengio", "title": "The Journey is the Reward: Unsupervised Learning of Influential\n  Trajectories", "comments": "ICML'19 ERL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised exploration and representation learning become increasingly\nimportant when learning in diverse and sparse environments. The\ninformation-theoretic principle of empowerment formalizes an unsupervised\nexploration objective through an agent trying to maximize its influence on the\nfuture states of its environment. Previous approaches carry certain limitations\nin that they either do not employ closed-loop feedback or do not have an\ninternal state. As a consequence, a privileged final state is taken as an\ninfluence measure, rather than the full trajectory. We provide a model-free\nmethod which takes into account the whole trajectory while still offering the\nbenefits of option-based approaches. We successfully apply our approach to\nsettings with large action spaces, where discovery of meaningful action\nsequences is particularly difficult.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:18:39 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Binas", "Jonathan", ""], ["Ozair", "Sherjil", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1905.09335", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Imitation Learning from Video by Leveraging Proprioception", "comments": "International Joint Conference on Artificial Intelligence (IJCAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classically, imitation learning algorithms have been developed for idealized\nsituations, e.g., the demonstrations are often required to be collected in the\nexact same environment and usually include the demonstrator's actions.\nRecently, however, the research community has begun to address some of these\nshortcomings by offering algorithmic solutions that enable imitation learning\nfrom observation (IfO), e.g., learning to perform a task from visual\ndemonstrations that may be in a different environment and do not include\nactions. Motivated by the fact that agents often also have access to their own\ninternal states (i.e., proprioception), we propose and study an IfO algorithm\nthat leverages this information in the policy learning process. The proposed\narchitecture learns policies over proprioceptive state representations and\ncompares the resulting trajectories visually to the demonstration data. We\nexperimentally test the proposed technique on several MuJoCo domains and show\nthat it outperforms other imitation from observation algorithms by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:21:05 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 03:59:10 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1905.09340", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Kimmo Karkkainen, Orpaz Goldstein, Sajad Darabi,\n  Majid Sarrafzadeh", "title": "Generative Imputation and Stochastic Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, we are faced with incomplete datasets.\nIn the literature, missing data imputation techniques have been mostly\nconcerned with filling missing values. However, the existence of missing values\nis synonymous with uncertainties not only over the distribution of missing\nvalues but also over target class assignments that require careful\nconsideration. In this paper, we propose a simple and effective method for\nimputing missing features and estimating the distribution of target assignments\ngiven incomplete data. In order to make imputations, we train a simple and\neffective generator network to generate imputations that a discriminator\nnetwork is tasked to distinguish. Following this, a predictor network is\ntrained using the imputed samples from the generator network to capture the\nclassification uncertainties and make predictions accordingly. The proposed\nmethod is evaluated on CIFAR-10 and MNIST image datasets as well as five\nreal-world tabular classification datasets, under different missingness rates\nand structures. Our experimental results show the effectiveness of the proposed\nmethod in generating imputations as well as providing estimates for the class\nuncertainties in a classification task when faced with missing values.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:29:46 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 03:24:52 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 00:38:38 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 04:44:09 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Goldstein", "Orpaz", ""], ["Darabi", "Sajad", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1905.09356", "submitter": "Biyi Fang", "authors": "Biyi Fang and Diego Klabjan", "title": "Convergence Analyses of Online ADAM Algorithm in Convex Setting and\n  Two-Layer ReLU Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, online learning is an appealing learning paradigm, which is of\ngreat interest in practice due to the recent emergence of large scale\napplications such as online advertising placement and online web ranking.\nStandard online learning assumes a finite number of samples while in practice\ndata is streamed infinitely. In such a setting gradient descent with a\ndiminishing learning rate does not work. We first introduce regret with rolling\nwindow, a new performance metric for online streaming learning, which measures\nthe performance of an algorithm on every fixed number of contiguous samples. At\nthe same time, we propose a family of algorithms based on gradient descent with\na constant or adaptive learning rate and provide very technical analyses\nestablishing regret bound properties of the algorithms. We cover the convex\nsetting showing the regret of the order of the square root of the size of the\nwindow in the constant and dynamic learning rate scenarios. Our proof is\napplicable also to the standard online setting where we provide the first\nanalysis of the same regret order (the previous proofs have flaws). We also\nstudy a two layer neural network setting with ReLU activation. In this case we\nestablish that if initial weights are close to a stationary point, the same\nsquare root regret bound is attainable. We conduct computational experiments\ndemonstrating a superior performance of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:37:48 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 00:57:49 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Fang", "Biyi", ""], ["Klabjan", "Diego", ""]]}, {"id": "1905.09368", "submitter": "Bruno Silva", "authors": "Bruno L\\'egora Souza da Silva, Fernando Kentaro Inaba, Evandro Ottoni\n  Teatini Salles, Patrick Marques Ciarelli", "title": "Outlier Robust Extreme Learning Machine for Multi-Target Regression", "comments": "Submitted to Expert Systems With Applications in April 16, 2019.\n  Currently under review. Highlights: Handles Multi-Target Regression Problems,\n  Generalized Outlier Robust Extreme Learning Machine, Shows robustness when\n  training data is contaminated with outliers, Training time is similar to\n  Generalized and Outlier-Robust Extreme Learning Machines, An incremental\n  version of the method is presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of algorithms based on Extreme Learning Machine (ELM), which\ncan be used to train Single Layer Feedforward Neural Networks (SLFN), has\nincreased in the past years. They have been successfully applied to a wide\nrange of classification and regression tasks. The most commonly used methods\nare the ones based on minimizing the $\\ell_2$ norm of the error, which is not\nsuitable to deal with outliers, essentially in regression tasks. The use of\n$\\ell_1$ norm was proposed in Outlier Robust ELM (OR-ELM), which is defined to\none-dimensional outputs. In this paper, we generalize OR-ELM to deal with\nmulti-target regression problems, using the error $\\ell_{2,1}$ norm and the\nElastic Net theory, which can result in a more sparse network, resulting in our\nmethod, Generalized Outlier Robust ELM (GOR-ELM). We use Alternating Direction\nMethod of Multipliers (ADMM) to solve the resulting optimization problem. An\nincremental version of GOR-ELM is also proposed. We chose 15 public real-world\nmulti-target regression datasets to test our methods. Our conducted experiments\nshow that they are statistically better than other ELM-based techniques, when\nconsidering data contaminated with outliers, and equivalent to them, otherwise.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:16:55 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 17:58:35 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["da Silva", "Bruno L\u00e9gora Souza", ""], ["Inaba", "Fernando Kentaro", ""], ["Salles", "Evandro Ottoni Teatini", ""], ["Ciarelli", "Patrick Marques", ""]]}, {"id": "1905.09369", "submitter": "Arvind Prasadan", "authors": "Arvind Prasadan, Raj Rao Nadakuditi, Debashis Paul", "title": "Sparse Equisigned PCA: Algorithms and Performance Bounds in the Noisy\n  Rank-1 Setting", "comments": "To appear, Electronic Journal of Statistics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Singular value decomposition (SVD) based principal component analysis (PCA)\nbreaks down in the high-dimensional and limited sample size regime below a\ncertain critical eigen-SNR that depends on the dimensionality of the system and\nthe number of samples. Below this critical eigen-SNR, the estimates returned by\nthe SVD are asymptotically uncorrelated with the latent principal components.\nWe consider a setting where the left singular vector of the underlying rank one\nsignal matrix is assumed to be sparse and the right singular vector is assumed\nto be equisigned, that is, having either only nonnegative or only nonpositive\nentries. We consider six different algorithms for estimating the sparse\nprincipal component based on different statistical criteria and prove that by\nexploiting sparsity, we recover consistent estimates in the low eigen-SNR\nregime where the SVD fails. Our analysis reveals conditions under which a\ncoordinate selection scheme based on a \\textit{sum-type decision statistic}\noutperforms schemes that utilize the $\\ell_1$ and $\\ell_2$ norm-based\nstatistics. We derive lower bounds on the size of detectable coordinates of the\nprincipal left singular vector and utilize these lower bounds to derive lower\nbounds on the worst-case risk. Finally, we verify our findings with numerical\nsimulations and illustrate the performance with a video data example, where the\ninterest is in identifying objects.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:17:37 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 16:12:30 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Prasadan", "Arvind", ""], ["Nadakuditi", "Raj Rao", ""], ["Paul", "Debashis", ""]]}, {"id": "1905.09381", "submitter": "Kaiyu Yang", "authors": "Kaiyu Yang, Jia Deng", "title": "Learning to Prove Theorems via Interacting with Proof Assistants", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans prove theorems by relying on substantial high-level reasoning and\nproblem-specific insights. Proof assistants offer a formalism that resembles\nhuman mathematical reasoning, representing theorems in higher-order logic and\nproofs as high-level tactics. However, human experts have to construct proofs\nmanually by entering tactics into the proof assistant. In this paper, we study\nthe problem of using machine learning to automate the interaction with proof\nassistants. We construct CoqGym, a large-scale dataset and learning environment\ncontaining 71K human-written proofs from 123 projects developed with the Coq\nproof assistant. We develop ASTactic, a deep learning-based model that\ngenerates tactics as programs in the form of abstract syntax trees (ASTs).\nExperiments show that ASTactic trained on CoqGym can generate effective tactics\nand can be used to prove new theorems not previously provable by automated\nmethods. Code is available at https://github.com/princeton-vl/CoqGym.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:56:02 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yang", "Kaiyu", ""], ["Deng", "Jia", ""]]}, {"id": "1905.09383", "submitter": "Touqir Sajed", "authors": "Touqir Sajed, Or Sheffet", "title": "An Optimal Private Stochastic-MAB Algorithm Based on an Optimal Private\n  Stopping Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a provably optimal differentially private algorithm for the\nstochastic multi-arm bandit problem, as opposed to the private analogue of the\nUCB-algorithm [Mishra and Thakurta, 2015; Tossou and Dimitrakakis, 2016] which\ndoesn't meet the recently discovered lower-bound of $\\Omega\n\\left(\\frac{K\\log(T)}{\\epsilon} \\right)$ [Shariff and Sheffet, 2018]. Our\nconstruction is based on a different algorithm, Successive Elimination\n[Even-Dar et al. 2002], that repeatedly pulls all remaining arms until an arm\nis found to be suboptimal and is then eliminated. In order to devise a private\nanalogue of Successive Elimination we visit the problem of private stopping\nrule, that takes as input a stream of i.i.d samples from an unknown\ndistribution and returns a multiplicative $(1 \\pm \\alpha)$-approximation of the\ndistribution's mean, and prove the optimality of our private stopping rule. We\nthen present the private Successive Elimination algorithm which meets both the\nnon-private lower bound [Lai and Robbins, 1985] and the above-mentioned private\nlower bound. We also compare empirically the performance of our algorithm with\nthe private UCB algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 22:27:44 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Sajed", "Touqir", ""], ["Sheffet", "Or", ""]]}, {"id": "1905.09388", "submitter": "Soorya Gopalakrishnan", "authors": "Soorya Gopalakrishnan, Metehan Cekic, Upamanyu Madhow", "title": "Robust Wireless Fingerprinting via Complex-Valued Neural Networks", "comments": "Accepted at IEEE Global Communications Conference (Globecom) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \"wireless fingerprint\" which exploits hardware imperfections unique to each\ndevice is a potentially powerful tool for wireless security. Such a fingerprint\nshould be able to distinguish between devices sending the same message, and\nshould be robust against standard spoofing techniques. Since the information in\nwireless signals resides in complex baseband, in this paper, we explore the use\nof neural networks with complex-valued weights to learn fingerprints using\nsupervised learning. We demonstrate that, while there are potential benefits to\nusing sections of the signal beyond just the preamble to learn fingerprints,\nthe network cheats when it can, using information such as transmitter ID (which\ncan be easily spoofed) to artificially inflate performance. We also show that\nnoise augmentation by inserting additional white Gaussian noise can lead to\nsignificant performance gains, which indicates that this counter-intuitive\nstrategy helps in learning more robust fingerprints. We provide results for two\ndifferent wireless protocols, WiFi and ADS-B, demonstrating the effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 19:47:15 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 05:58:26 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gopalakrishnan", "Soorya", ""], ["Cekic", "Metehan", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "1905.09395", "submitter": "Dirk Van Essendelft", "authors": "Kyle Buchheit, Opeoluwa Owoyele, Terry Jordan, Dirk Van Essendelft", "title": "The Stabilized Explicit Variable-Load Solver with Machine Learning\n  Acceleration for the Rapid Solution of Stiff Chemical Kinetics", "comments": "25 pages, 14 Figures, 2 Tables, 56 Equations, Original research into\n  accelerating CFD with ML/AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.GR cs.LG cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, a fast and stable machine-learned hybrid algorithm implemented\nin TensorFlow for the integration of stiff chemical kinetics is introduced.\nNumerical solutions to differential equations are at the core of computational\nfluid dynamics calculations. As the size and complexity of the simulations\ngrow, so does the need for computational power and time. Many efforts have been\nmade to implement stiff chemistry solvers on GPUs but have not been highly\nsuccessful because of the logical divergence in traditional stiff solver\nalgorithms. Because of these constrains, a novel Explicit Stabilized\nVariable-load (STEV) solver has been developed. Overstepping due to the\nrelatively large time steps is prevented by introducing limits to the maximum\nchanges of chemical species per time step. To prevent oscillations, a discrete\nFourier transform is introduced to dampen ringing. In contrast to conventional\nexplicit approaches, a variable-load approach is used where each cell in the\ncomputational domain is advanced with its unique time step. This approach\nallows cells to be integrated simultaneously while maintaining warp convergence\nbut finish at different iterations and be removed from the workload. To improve\nthe computational performance of the introduced solver, specific thermodynamic\nquantities of interest were estimated using shallow neural networks in place of\npolynomial fits, leading to an additional 10% savings in clock time with\nminimal training and implementation requirements. However ML specific hardware\ncould increase the time savings to as much as 28%. While the complexity of\nthese particular machine learning models is not high by modern standards, the\nimpact on computational efficiency should not be ignored. The results show a\ndramatic decrease in total chemistry solution time (over 200 times) while\nmaintaining a similar degree of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:10:35 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:26:27 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 21:14:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Buchheit", "Kyle", ""], ["Owoyele", "Opeoluwa", ""], ["Jordan", "Terry", ""], ["Van Essendelft", "Dirk", ""]]}, {"id": "1905.09397", "submitter": "David Bourgin", "authors": "David D. Bourgin, Joshua C. Peterson, Daniel Reichman, Thomas L.\n  Griffiths, Stuart J. Russell", "title": "Cognitive Model Priors for Predicting Human Decisions", "comments": "ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:5133-5141, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-making underlies all economic behavior. For the past four\ndecades, human decision-making under uncertainty has continued to be explained\nby theoretical models based on prospect theory, a framework that was awarded\nthe Nobel Prize in Economic Sciences. However, theoretical models of this kind\nhave developed slowly, and robust, high-precision predictive models of human\ndecisions remain a challenge. While machine learning is a natural candidate for\nsolving these problems, it is currently unclear to what extent it can improve\npredictions obtained by current theories. We argue that this is mainly due to\ndata scarcity, since noisy human behavior requires massive sample sizes to be\naccurately captured by off-the-shelf machine learning methods. To solve this\nproblem, what is needed are machine learning models with appropriate inductive\nbiases for capturing human behavior, and larger datasets. We offer two\ncontributions towards this end: first, we construct \"cognitive model priors\" by\npretraining neural networks with synthetic data generated by cognitive models\n(i.e., theoretical models developed by cognitive psychologists). We find that\nfine-tuning these networks on small datasets of real human decisions results in\nunprecedented state-of-the-art improvements on two benchmark datasets. Second,\nwe present the first large-scale dataset for human decision-making, containing\nover 240,000 human judgments across over 13,000 decision problems. This dataset\nreveals the circumstances where cognitive model priors are useful, and provides\na new standard for benchmarking prediction of human decisions under\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 23:05:53 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Bourgin", "David D.", ""], ["Peterson", "Joshua C.", ""], ["Reichman", "Daniel", ""], ["Griffiths", "Thomas L.", ""], ["Russell", "Stuart J.", ""]]}, {"id": "1905.09414", "submitter": "Francois Belletti", "authors": "Francois Belletti, Minmin Chen and Ed H. Chi", "title": "Quantifying Long Range Dependence in Language and User Behavior to\n  improve RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Characterizing temporal dependence patterns is a critical step in\nunderstanding the statistical properties of sequential data. Long Range\nDependence (LRD) --- referring to long-range correlations decaying as a power\nlaw rather than exponentially w.r.t. distance --- demands a different set of\ntools for modeling the underlying dynamics of the sequential data. While it has\nbeen widely conjectured that LRD is present in language modeling and sequential\nrecommendation, the amount of LRD in the corresponding sequential datasets has\nnot yet been quantified in a scalable and model-independent manner. We propose\na principled estimation procedure of LRD in sequential datasets based on\nestablished LRD theory for real-valued time series and apply it to sequences of\nsymbols with million-item-scale dictionaries. In our measurements, the\nprocedure estimates reliably the LRD in the behavior of users as they write\nWikipedia articles and as they interact with YouTube. We further show that\nmeasuring LRD better informs modeling decisions in particular for RNNs whose\nability to capture LRD is still an active area of research. The quantitative\nmeasure informs new Evolutive Recurrent Neural Networks (EvolutiveRNNs)\ndesigns, leading to state-of-the-art results on language understanding and\nsequential recommendation tasks at a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 01:01:57 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Belletti", "Francois", ""], ["Chen", "Minmin", ""], ["Chi", "Ed H.", ""]]}, {"id": "1905.09419", "submitter": "Hanten Chang", "authors": "Hanten Chang, Shinji Nakaoka, and Hiroyasu Ando", "title": "Effect of shapes of activation functions on predictability in the echo\n  state network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate prediction accuracy for time series of Echo state networks\nwith respect to several kinds of activation functions. As a result, we found\nthat some kinds of activation functions with an appropriate nonlinearity show\nhigh performance compared to the conventional sigmoid function.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:07:06 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chang", "Hanten", ""], ["Nakaoka", "Shinji", ""], ["Ando", "Hiroyasu", ""]]}, {"id": "1905.09432", "submitter": "Yeonwoo Jeong", "authors": "Yeonwoo Jeong, Hyun Oh Song", "title": "Learning Discrete and Continuous Factors of Data via Alternating\n  Disentanglement", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised disentanglement of discrete and\ncontinuous explanatory factors of data. We first show a simple procedure for\nminimizing the total correlation of the continuous latent variables without\nhaving to use a discriminator network or perform importance sampling, via\ncascading the information flow in the $\\beta$-vae framework. Furthermore, we\npropose a method which avoids offloading the entire burden of jointly modeling\nthe continuous and discrete factors to the variational encoder by employing a\nseparate discrete inference procedure.\n  This leads to an interesting alternating minimization problem which switches\nbetween finding the most likely discrete configuration given the continuous\nfactors and updating the variational encoder based on the computed discrete\nfactors. Experiments show that the proposed method clearly disentangles\ndiscrete factors and significantly outperforms current disentanglement methods\nbased on the disentanglement score and inference network classification score.\nThe source code is available at\nhttps://github.com/snu-mllab/DisentanglementICML19.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:06:50 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Jeong", "Yeonwoo", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1905.09433", "submitter": "Tongwen Huang", "authors": "Tongwen Huang, Zhiqi Zhang, Junlin Zhang", "title": "FiBiNET: Combining Feature Importance and Bilinear feature Interaction\n  for Click-Through Rate Prediction", "comments": "8 pages,5 figures", "journal-ref": "ACM Conference on Recommender Systems (RecSys '19), September\n  16--20, 2019, Copenhagen, Denmark", "doi": "10.1145/3298689.3347043", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advertising and feed ranking are essential to many Internet companies such as\nFacebook and Sina Weibo. Among many real-world advertising and feed ranking\nsystems, click through rate (CTR) prediction plays a central role. There are\nmany proposed models in this field such as logistic regression, tree based\nmodels, factorization machine based models and deep learning based CTR models.\nHowever, many current works calculate the feature interactions in a simple way\nsuch as Hadamard product and inner product and they care less about the\nimportance of features. In this paper, a new model named FiBiNET as an\nabbreviation for Feature Importance and Bilinear feature Interaction NETwork is\nproposed to dynamically learn the feature importance and fine-grained feature\ninteractions. On the one hand, the FiBiNET can dynamically learn the importance\nof features via the Squeeze-Excitation network (SENET) mechanism; on the other\nhand, it is able to effectively learn the feature interactions via bilinear\nfunction. We conduct extensive experiments on two real-world datasets and show\nthat our shallow model outperforms other shallow models such as factorization\nmachine(FM) and field-aware factorization machine(FFM). In order to improve\nperformance further, we combine a classical deep neural network(DNN) component\nwith the shallow model to be a deep model. The deep FiBiNET consistently\noutperforms the other state-of-the-art deep models such as DeepFM and extreme\ndeep factorization machine(XdeepFM).\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:10:17 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Huang", "Tongwen", ""], ["Zhang", "Zhiqi", ""], ["Zhang", "Junlin", ""]]}, {"id": "1905.09435", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, Soummya Kar", "title": "MATCHA: Speeding Up Decentralized SGD via Matching Decomposition\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of error-runtime trade-off, typically\nencountered in decentralized training based on stochastic gradient descent\n(SGD) using a given network. While a denser (sparser) network topology results\nin faster (slower) error convergence in terms of iterations, it incurs more\n(less) communication time/delay per iteration. In this paper, we propose\nMATCHA, an algorithm that can achieve a win-win in this error-runtime trade-off\nfor any arbitrary network topology. The main idea of MATCHA is to parallelize\ninter-node communication by decomposing the topology into matchings. To\npreserve fast error convergence speed, it identifies and communicates more\nfrequently over critical links, and saves communication time by using other\nlinks less frequently. Experiments on a suite of datasets and deep neural\nnetworks validate the theoretical analyses and demonstrate that MATCHA takes up\nto $5\\times$ less time than vanilla decentralized SGD to reach the same\ntraining loss.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:13:14 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 05:35:45 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 16:04:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wang", "Jianyu", ""], ["Sahu", "Anit Kumar", ""], ["Yang", "Zhouyi", ""], ["Joshi", "Gauri", ""], ["Kar", "Soummya", ""]]}, {"id": "1905.09442", "submitter": "Jie Qiao", "authors": "Ruichu Cai, Jie Qiao, Kun Zhang, Zhenjie Zhang, Zhifeng Hao", "title": "Causal Discovery with Cascade Nonlinear Additive Noise Models", "comments": "Appears in the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of causal direction between a causal-effect pair from observed\ndata has recently attracted much attention. Various methods based on functional\ncausal models have been proposed to solve this problem, by assuming the causal\nprocess satisfies some (structural) constraints and showing that the reverse\ndirection violates such constraints. The nonlinear additive noise model has\nbeen demonstrated to be effective for this purpose, but the model class is not\ntransitive--even if each direct causal relation follows this model, indirect\ncausal influences, which result from omitted intermediate causal variables and\nare frequently encountered in practice, do not necessarily follow the model\nconstraints; as a consequence, the nonlinear additive noise model may fail to\ncorrectly discover causal direction. In this work, we propose a cascade\nnonlinear additive noise model to represent such causal influences--each direct\ncausal relation follows the nonlinear additive noise model but we observe only\nthe initial cause and final effect. We further propose a method to estimate the\nmodel, including the unmeasured intermediate variables, from data, under the\nvariational auto-encoder framework. Our theoretical results show that with our\nmodel, causal direction is identifiable under suitable technical conditions on\nthe data generation process. Simulation results illustrate the power of the\nproposed method in identifying indirect causal relations across various\nsettings, and experimental results on real data suggest that the proposed model\nand method greatly extend the applicability of causal discovery based on\nfunctional causal models in nonlinear cases.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 03:00:13 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 07:45:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cai", "Ruichu", ""], ["Qiao", "Jie", ""], ["Zhang", "Kun", ""], ["Zhang", "Zhenjie", ""], ["Hao", "Zhifeng", ""]]}, {"id": "1905.09449", "submitter": "Chen Liu", "authors": "Yanwei Fu and Chen Liu and Donghao Li and Zuyuan Zhong and Xinwei Sun\n  and Jinshan Zeng and Yuan Yao", "title": "Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces", "comments": "This is the journal extension version of the ICML conference paper,\n  \"DessiLBI: Exploring Structural Sparsity of Deep Networks via Differential\n  Inclusion Paths\"", "journal-ref": "International Conference on Machine Learning. PMLR, 2020, pp.\n  3315--3326", "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great success of deep neural networks is built upon their\nover-parameterization, which smooths the optimization landscape without\ndegrading the generalization ability. Despite the benefits of\nover-parameterization, a huge amount of parameters makes deep networks\ncumbersome in daily life applications. Though techniques such as pruning and\ndistillation are developed, they are expensive in fully training a dense\nnetwork as backward selection methods, and there is still a void on\nsystematically exploring forward selection methods for learning structural\nsparsity in deep networks. To fill in this gap, this paper proposes a new\napproach based on differential inclusions of inverse scale spaces, which\ngenerate a family of models from simple to complex ones along the dynamics via\ncoupling a pair of parameters, such that over-parameterized deep models and\ntheir structural sparsity can be explored simultaneously. This kind of\ndifferential inclusion scheme has a simple discretization, dubbed Deep\nstructure splitting Linearized Bregman Iteration (DessiLBI), whose global\nconvergence in learning deep networks could be established under the\nKurdyka-Lojasiewicz framework. Experimental evidence shows that our method\nachieves comparable and even better performance than the competitive optimizers\nin exploring the sparse structure of several widely used backbones on the\nbenchmark datasets. Remarkably, with early stopping, our method unveils\n`winning tickets' in early epochs: the effective sparse network structures with\ncomparable test accuracy to fully trained over-parameterized models, that are\nfurther transferable to similar alternative tasks. Furthermore, our method is\nable to grow networks efficiently with adaptive filter configurations,\ndemonstrating a good performance with much less computational cost. Codes and\nmodels can be downloaded at {https://github.com/DessiLBI2020/DessiLBI}.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 03:27:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 01:21:13 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 17:31:45 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 05:49:04 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fu", "Yanwei", ""], ["Liu", "Chen", ""], ["Li", "Donghao", ""], ["Zhong", "Zuyuan", ""], ["Sun", "Xinwei", ""], ["Zeng", "Jinshan", ""], ["Yao", "Yuan", ""]]}, {"id": "1905.09453", "submitter": "Oscar Chang", "authors": "Oscar Chang, Yuling Yao, David Williams-King, Hod Lipson", "title": "Ensemble Model Patching: A Parameter-Efficient Variational Bayesian\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main obstacles preventing the widespread adoption of variational Bayesian\nneural networks are the high parameter overhead that makes them infeasible on\nlarge networks, and the difficulty of implementation, which can be thought of\nas \"programming overhead.\" MC dropout [Gal and Ghahramani, 2016] is popular\nbecause it sidesteps these obstacles. Nevertheless, dropout is often harmful to\nmodel performance when used in networks with batch normalization layers [Li et\nal., 2018], which are an indispensable part of modern neural networks. We\nconstruct a general variational family for ensemble-based Bayesian neural\nnetworks that encompasses dropout as a special case. We further present two\nspecific members of this family that work well with batch normalization layers,\nwhile retaining the benefits of low parameter and programming overhead,\ncomparable to non-Bayesian training. Our proposed methods improve predictive\naccuracy and achieve almost perfect calibration on a ResNet-18 trained with\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 03:58:59 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chang", "Oscar", ""], ["Yao", "Yuling", ""], ["Williams-King", "David", ""], ["Lipson", "Hod", ""]]}, {"id": "1905.09472", "submitter": "Lubna Shibly Mokatren", "authors": "Lubna Shibly Mokatren, Rashid Ansari, Ahmet Enis Cetin, Alex D Leow,\n  Heide Klumpp, Olusola Ajilore, Fatos Yarman Vural", "title": "EEG Classification by factoring in Sensor Configuration", "comments": "arXiv admin note: text overlap with arXiv:1812.02865", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) serves as an effective diagnostic tool for\nmental disorders and neurological abnormalities. Enhanced analysis and\nclassification of EEG signals can help improve detection performance. A new\napproach is examined here for enhancing EEG classification performance by\nleveraging knowledge of spatial layout of EEG sensors. Performance of two\nclassification models - model 1 that ignores the sensor layout and model 2 that\nfactors it in - is investigated and found to achieve consistently higher\ndetection accuracy. The analysis is based on the information content of these\nsignals represented in two different ways: concatenation of the channels of the\nfrequency bands and an image-like 2D representation of the EEG channel\nlocations. Performance of these models is examined on two tasks, social anxiety\ndisorder (SAD) detection, and emotion recognition using a dataset for emotion\nanalysis using physiological signals (DEAP). We hypothesized that model 2 will\nsignificantly outperform model 1 and this was validated in our results as model\n2 yielded $5$--$8\\%$ higher accuracy in all machine learning algorithms\ninvestigated. Convolutional Neural Networks (CNN) provided the best performance\nfar exceeding that of Support Vector Machine (SVM) and k-Nearest Neighbors\n(kNNs) algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:09:24 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 00:51:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mokatren", "Lubna Shibly", ""], ["Ansari", "Rashid", ""], ["Cetin", "Ahmet Enis", ""], ["Leow", "Alex D", ""], ["Klumpp", "Heide", ""], ["Ajilore", "Olusola", ""], ["Vural", "Fatos Yarman", ""]]}, {"id": "1905.09492", "submitter": "Lianjiang Li", "authors": "Lianjiang Li, Yunrong Yang, Bingna Li", "title": "Combine PPO with NES to Improve Exploration", "comments": "18 pages, 14 figures", "journal-ref": "arXiv:1905.09492v1 [cs.LG] 23 May 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two approaches for combining neural evolution strategy (NES) and\nproximal policy optimization (PPO): parameter transfer and parameter space\nnoise. Parameter transfer is a PPO agent with parameters transferred from a NES\nagent. Parameter space noise is to directly add noise to the PPO agent`s\nparameters. We demonstrate that PPO could benefit from both methods through\nexperimental comparison on discrete action environments as well as continuous\ncontrol tasks\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 06:32:07 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 05:03:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Li", "Lianjiang", ""], ["Yang", "Yunrong", ""], ["Li", "Bingna", ""]]}, {"id": "1905.09509", "submitter": "Mert Ozer", "authors": "Mehmet Yigit Yildirim, Mert Ozer, Hasan Davulcu", "title": "Leveraging Uncertainty in Deep Learning for Selective Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide and rapid adoption of deep learning by practitioners brought\nunintended consequences in many situations such as in the infamous case of\nGoogle Photos' racist image recognition algorithm; thus, necessitated the\nutilization of the quantified uncertainty for each prediction. There have been\nrecent efforts towards quantifying uncertainty in conventional deep learning\nmethods (e.g., dropout as Bayesian approximation); however, their optimal use\nin decision making is often overlooked and understudied. In this study, we\npropose a mixed-integer programming framework for classification with reject\noption (also known as selective classification), that investigates and combines\nmodel uncertainty and predictive mean to identify optimal classification and\nrejection regions. Our results indicate superior performance of our framework\nboth in non-rejected accuracy and rejection quality on several publicly\navailable datasets. Moreover, we extend our framework to cost-sensitive\nsettings and show that our approach outperforms industry standard methods\nsignificantly for online fraud management in real-world settings.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 07:28:36 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yildirim", "Mehmet Yigit", ""], ["Ozer", "Mert", ""], ["Davulcu", "Hasan", ""]]}, {"id": "1905.09522", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Robert Burduk", "title": "Combination of linear classifiers using score function -- analysis of\n  possible combination strategies", "comments": null, "journal-ref": "In Advances in Intelligent Systems and Computing (pp. 348-359)\n  (2019)", "doi": "10.1007/978-3-030-19738-4_35", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we addressed the issue of combining linear classifiers using\ntheir score functions. The value of the scoring function depends on the\ndistance from the decision boundary. Two score functions have been tested and\nfour different combination strategies were investigated. During the\nexperimental study, the proposed approach was applied to the heterogeneous\nensemble and it was compared to two reference methods -- majority voting and\nmodel averaging respectively. The comparison was made in terms of seven\ndifferent quality criteria. The result shows that combination strategies based\non simple average, and trimmed average are the best combination strategies of\nthe geometrical combination.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:10:12 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Trajdos", "Pawel", ""], ["Burduk", "Robert", ""]]}, {"id": "1905.09523", "submitter": "Niels Hellinga", "authors": "Niels Hellinga, Vlado Menkovski", "title": "Hierarchical Annotation of Images with Two-Alternative-Forced-Choice\n  Metric Learning", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks such as retrieval and recommendations can significantly benefit\nfrom structuring the data, commonly in a hierarchical way. To achieve this\nthrough annotations of high dimensional data such as images or natural text can\nbe significantly labor intensive. We propose an approach for uncovering the\nhierarchical structure of data based on efficient discriminative testing rather\nthan annotations of individual datapoints. Using two-alternative-forced-choice\n(2AFC) testing and deep metric learning we achieve embedding of the data in\nsemantic space where we are able to successfully hierarchically cluster. We\nactively select triplets for the 2AFC test such that the modeling process is\nhighly efficient with respect to the number of tests presented to the\nannotator. We empirically demonstrate the feasibility of the method by\nconfirming the shape bias on synthetic data and extract hierarchical structure\non the Fashion-MNIST dataset to a finer granularity than the original labels.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:11:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 13:55:18 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hellinga", "Niels", ""], ["Menkovski", "Vlado", ""]]}, {"id": "1905.09538", "submitter": "Amir Rubin", "authors": "Amir Rubin, Shay Kels, Danny Hendler", "title": "AMSI-Based Detection of Malicious PowerShell Code Using Contextual\n  Embeddings", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PowerShell is a command-line shell, supporting a scripting language. It is\nwidely used in organizations for configuration management and task automation\nbut is also increasingly used by cybercriminals for launching cyberattacks\nagainst organizations, mainly because it is pre-installed on Windows machines\nand exposes strong functionality that may be leveraged by attackers. This makes\nthe problem of detecting malicious PowerShell code both urgent and challenging.\nMicrosoft's Antimalware Scan Interface (AMSI) allows defending systems to scan\nall the code passed to scripting engines such as PowerShell prior to its\nexecution. In this work, we conduct the first study of malicious PowerShell\ncode detection using the information made available by AMSI.\n  We present several novel deep-learning based detectors of malicious\nPowerShell code that employ pretrained contextual embeddings of words from the\nPowerShell \"language\". A known problem in the cybersecurity domain is that\nlabeled data is relatively scarce in comparison with unlabeled data, making it\ndifficult to devise effective supervised detection of malicious activity of\nmany types. This is also the case with PowerShell code. Our work shows that\nthis problem can be mitigated by learning a pretrained contextual embedding\nbased on unlabeled data.\n  We trained and evaluated our models using real-world data, collected using\nAMSI from a large antimalware vendor. Our performance analysis establishes that\nthe use of unlabeled data for the embedding significantly improved the\nperformance of our detectors. Our best-performing model uses an architecture\nthat enables the processing of textual signals from both the character and\ntoken levels and obtains a true positive rate of nearly 90% while maintaining a\nlow false-positive rate of less than 0.1%.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:53:52 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 05:37:35 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Rubin", "Amir", ""], ["Kels", "Shay", ""], ["Hendler", "Danny", ""]]}, {"id": "1905.09545", "submitter": "Takashi Takahashi", "authors": "Takashi Takahashi, Yoshiyuki Kabashima", "title": "Replicated Vector Approximate Message Passing For Resampling Problem", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resampling techniques are widely used in statistical inference and ensemble\nlearning, in which estimators' statistical properties are essential. However,\nexisting methods are computationally demanding, because repetitions of\nestimation/learning via numerical optimization/integral for each resampled data\nare required. In this study, we introduce a computationally efficient method to\nresolve such problem: replicated vector approximate message passing. This is\nbased on a combination of the replica method of statistical physics and an\naccurate approximate inference algorithm, namely the vector approximate message\npassing of information theory. The method provides tractable densities without\nrepeating estimation/learning, and the densities approximately offer an\narbitrary degree of the estimators' moment in practical time. In the\nexperiment, we apply the proposed method to the stability selection method,\nwhich is commonly used in variable selection problems. The numerical results\nshow its fast convergence and high approximation accuracy for problems\ninvolving both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:11:06 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Takahashi", "Takashi", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "1905.09550", "submitter": "Hoang Nt", "authors": "Hoang NT and Takanori Maehara", "title": "Revisiting Graph Neural Networks: All We Have is Low-Pass Filters", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have become one of the most important techniques to\nsolve machine learning problems on graph-structured data. Recent work on vertex\nclassification proposed deep and distributed learning models to achieve high\nperformance and scalability. However, we find that the feature vectors of\nbenchmark datasets are already quite informative for the classification task,\nand the graph structure only provides a means to denoise the data. In this\npaper, we develop a theoretical framework based on graph signal processing for\nanalyzing graph neural networks. Our results indicate that graph neural\nnetworks only perform low-pass filtering on feature vectors and do not have the\nnon-linear manifold learning property. We further investigate their resilience\nto feature noise and propose some insights on GCN-based graph neural network\ndesign.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:27:21 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 05:21:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["NT", "Hoang", ""], ["Maehara", "Takanori", ""]]}, {"id": "1905.09558", "submitter": "Nuo Xu", "authors": "Nuo Xu, Pinghui Wang, Long Chen, Jing Tao, Junzhou Zhao", "title": "MR-GNN: Multi-Resolution and Dual Graph Neural Network for Predicting\n  Structured Entity Interactions", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/551", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting interactions between structured entities lies at the core of\nnumerous tasks such as drug regimen and new material design. In recent years,\ngraph neural networks have become attractive. They represent structured\nentities as graphs and then extract features from each individual graph using\ngraph convolution operations. However, these methods have some limitations: i)\ntheir networks only extract features from a fix-sized subgraph structure (i.e.,\na fix-sized receptive field) of each node, and ignore features in substructures\nof different sizes, and ii) features are extracted by considering each entity\nindependently, which may not effectively reflect the interaction between two\nentities. To resolve these problems, we present MR-GNN, an end-to-end graph\nneural network with the following features: i) it uses a multi-resolution based\narchitecture to extract node features from different neighborhoods of each\nnode, and, ii) it uses dual graph-state long short-term memory networks\n(L-STMs) to summarize local features of each graph and extracts the interaction\nfeatures between pairwise graphs. Experiments conducted on real-world datasets\nshow that MR-GNN improves the prediction of state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:49:37 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Xu", "Nuo", ""], ["Wang", "Pinghui", ""], ["Chen", "Long", ""], ["Tao", "Jing", ""], ["Zhao", "Junzhou", ""]]}, {"id": "1905.09561", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Mohammad Ghavamzadeh and Tara Javidi", "title": "Binary Classification with Bounded Abstention Rate", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of binary classification with abstention in the\nrelatively less studied \\emph{bounded-rate} setting. We begin by obtaining a\ncharacterization of the Bayes optimal classifier for an arbitrary input-label\ndistribution $P_{XY}$. Our result generalizes and provides an alternative proof\nfor the result first obtained by \\cite{chow1957optimum}, and then re-derived by\n\\citet{denis2015consistency}, under a continuity assumption on $P_{XY}$. We\nthen propose a plug-in classifier that employs unlabeled samples to decide the\nregion of abstention and derive an upper-bound on the excess risk of our\nclassifier under standard \\emph{H\\\"older smoothness} and \\emph{margin}\nassumptions. Unlike the plug-in rule of \\citet{denis2015consistency}, our\nconstructed classifier satisfies the abstention constraint with high\nprobability and can also deal with discontinuities in the empirical cdf. We\nalso derive lower-bounds that demonstrate the minimax near-optimality of our\nproposed algorithm. To address the excessive complexity of the plug-in\nclassifier in high dimensions, we propose a computationally efficient algorithm\nthat builds upon prior work on convex loss surrogates, and obtain bounds on its\nexcess risk in the \\emph{realizable} case. We empirically compare the\nperformance of the proposed algorithm with a baseline on a number of UCI\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:55:09 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Ghavamzadeh", "Mohammad", ""], ["Javidi", "Tara", ""]]}, {"id": "1905.09562", "submitter": "Pierre Thodoroff", "authors": "Pierre Thodoroff, Nishanth Anand, Lucas Caccia, Doina Precup, Joelle\n  Pineau", "title": "Recurrent Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent successes in Reinforcement Learning, value-based methods often\nsuffer from high variance hindering performance. In this paper, we illustrate\nthis in a continuous control setting where state of the art methods perform\npoorly whenever sensor noise is introduced. To overcome this issue, we\nintroduce Recurrent Value Functions (RVFs) as an alternative to estimate the\nvalue function of a state. We propose to estimate the value function of the\ncurrent state using the value function of past states visited along the\ntrajectory. Due to the nature of their formulation, RVFs have a natural way of\nlearning an emphasis function that selectively emphasizes important states.\nFirst, we establish RVF's asymptotic convergence properties in tabular\nsettings. We then demonstrate their robustness on a partially observable domain\nand continuous control tasks. Finally, we provide a qualitative interpretation\nof the learned emphasis function.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:01:29 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Thodoroff", "Pierre", ""], ["Anand", "Nishanth", ""], ["Caccia", "Lucas", ""], ["Precup", "Doina", ""], ["Pineau", "Joelle", ""]]}, {"id": "1905.09568", "submitter": "Stephan Fahrenkrog-Petersen", "authors": "Stephan A. Fahrenkrog-Petersen, Niek Tax, Irene Teinemaa, Marlon\n  Dumas, Massimiliano de Leoni, Fabrizio Maria Maggi, Matthias Weidlich", "title": "Fire Now, Fire Later: Alarm-Based Systems for Prescriptive Process\n  Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring is a family of techniques to analyze events\nproduced during the execution of a business process in order to predict the\nfuture state or the final outcome of running process instances. Existing\ntechniques in this field are able to predict, at each step of a process\ninstance, the likelihood that it will lead to an undesired outcome.These\ntechniques, however, focus on generating predictions and do not prescribe when\nand how process workers should intervene to decrease the cost of undesired\noutcomes. This paper proposes a framework for prescriptive process monitoring,\nwhich extends predictive monitoring with the ability to generate alarms that\ntrigger interventions to prevent an undesired outcome or mitigate its effect.\nThe framework incorporates a parameterized cost model to assess the\ncost-benefit trade-off of generating alarms. We show how to optimize the\ngeneration of alarms given an event log of past process executions and a set of\ncost model parameters. The proposed approaches are empirically evaluated using\na range of real-life event logs. The experimental results show that the net\ncost of undesired outcomes can be minimized by changing the threshold for\ngenerating alarms, as the process instance progresses. Moreover, introducing\ndelays for triggering alarms, instead of triggering them as soon as the\nprobability of an undesired outcome exceeds a threshold, leads to lower net\ncosts.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:18:25 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 12:33:08 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Fahrenkrog-Petersen", "Stephan A.", ""], ["Tax", "Niek", ""], ["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["de Leoni", "Massimiliano", ""], ["Maggi", "Fabrizio Maria", ""], ["Weidlich", "Matthias", ""]]}, {"id": "1905.09570", "submitter": "Guillaume Salha", "authors": "Guillaume Salha, Stratis Limnios, Romain Hennequin, Viet Anh Tran,\n  Michalis Vazirgiannis", "title": "Gravity-Inspired Graph Autoencoders for Directed Link Prediction", "comments": "ACM International Conference on Information and Knowledge Management\n  (CIKM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph autoencoders (AE) and variational autoencoders (VAE) recently emerged\nas powerful node embedding methods. In particular, graph AE and VAE were\nsuccessfully leveraged to tackle the challenging link prediction problem,\naiming at figuring out whether some pairs of nodes from a graph are connected\nby unobserved edges. However, these models focus on undirected graphs and\ntherefore ignore the potential direction of the link, which is limiting for\nnumerous real-life applications. In this paper, we extend the graph AE and VAE\nframeworks to address link prediction in directed graphs. We present a new\ngravity-inspired decoder scheme that can effectively reconstruct directed\ngraphs from a node embedding. We empirically evaluate our method on three\ndifferent directed link prediction tasks, for which standard graph AE and VAE\nperform poorly. We achieve competitive results on three real-world graphs,\noutperforming several popular baselines.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:20:01 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 13:39:02 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 10:18:09 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 13:50:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Salha", "Guillaume", ""], ["Limnios", "Stratis", ""], ["Hennequin", "Romain", ""], ["Tran", "Viet Anh", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1905.09589", "submitter": "Qijian Chen", "authors": "Qijian Chen, Lihui Wang, Li Wang, Zeyu Deng, Jian Zhang and Yuemin Zhu", "title": "Glioma Grade Prediction Using Wavelet Scattering-Based Radiomics", "comments": null, "journal-ref": "in IEEE Access, vol. 8, pp. 106564-106575, 2020", "doi": "10.1109/ACCESS.2020.3000895", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glioma grading before surgery is very critical for the prognosis prediction\nand treatment plan making. We present a novel wavelet scattering-based radiomic\nmethod to predict noninvasively and accurately the glioma grades. The method\nconsists of wavelet scattering feature extraction, dimensionality reduction,\nand glioma grade prediction. The dimensionality reduction was achieved using\npartial least squares (PLS) regression and the glioma grade prediction using\nsupport vector machine (SVM), logistic regression (LR) and random forest (RF).\nThe prediction obtained on multimodal magnetic resonance images of 285 patients\nwith well-labeled intratumoral and peritumoral regions showed that the area\nunder the receiver operating characteristic curve (AUC) of glioma grade\nprediction was increased up to 0.99 when considering both intratumoral and\nperitumoral features in multimodal images, which represents an increase of\nabout 13% compared to traditional radiomics. In addition, the features\nextracted from peritumoral regions further increase the accuracy of glioma\ngrading.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:25:20 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 07:39:31 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Chen", "Qijian", ""], ["Wang", "Lihui", ""], ["Wang", "Li", ""], ["Deng", "Zeyu", ""], ["Zhang", "Jian", ""], ["Zhu", "Yuemin", ""]]}, {"id": "1905.09591", "submitter": "Huaxia Wang", "authors": "Huaxia Wang and Chun-Nam Yu", "title": "A Direct Approach to Robust Deep Learning Using Adversarial Networks", "comments": "15 pages", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to perform well in many classical\nmachine learning problems, especially in image classification tasks. However,\nresearchers have found that neural networks can be easily fooled, and they are\nsurprisingly sensitive to small perturbations imperceptible to humans.\nCarefully crafted input images (adversarial examples) can force a well-trained\nneural network to provide arbitrary outputs. Including adversarial examples\nduring training is a popular defense mechanism against adversarial attacks. In\nthis paper we propose a new defensive mechanism under the generative\nadversarial network (GAN) framework. We model the adversarial noise using a\ngenerative network, trained jointly with a classification discriminative\nnetwork as a minimax game. We show empirically that our adversarial network\napproach works well against black box attacks, with performance on par with\nstate-of-art methods such as ensemble adversarial training and adversarial\ntraining with projected gradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:32:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Wang", "Huaxia", ""], ["Yu", "Chun-Nam", ""]]}, {"id": "1905.09595", "submitter": "Thang Nguyen Kim", "authors": "Christoph D\\\"urr, Nguyen Kim Thang, Abhinav Srivastav, L\\'eo Tible", "title": "Non-monotone DR-submodular Maximization: Approximation and Regret\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diminishing-returns (DR) submodular optimization is an important field with\nmany real-world applications in machine learning, economics and communication\nsystems. It captures a subclass of non-convex optimization that provides both\npractical and theoretical guarantees. In this paper, we study the fundamental\nproblem of maximizing non-monotone DR-submodular functions over down-closed and\ngeneral convex sets in both offline and online settings. First, we show that\nfor offline maximizing non-monotone DR-submodular functions over a general\nconvex set, the Frank-Wolfe algorithm achieves an approximation guarantee which\ndepends on the convex set. Next, we show that the Stochastic Gradient Ascent\nalgorithm achieves a 1/4-approximation ratio with the regret of $O(1/\\sqrt{T})$\nfor the problem of maximizing non-monotone DR-submodular functions over\ndown-closed convex sets. These are the first approximation guarantees in the\ncorresponding settings. Finally we benchmark these algorithms on problems\narising in machine learning domain with the real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:38:52 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["D\u00fcrr", "Christoph", ""], ["Thang", "Nguyen Kim", ""], ["Srivastav", "Abhinav", ""], ["Tible", "L\u00e9o", ""]]}, {"id": "1905.09608", "submitter": "Yuantao Gu", "authors": "Xingyu Xv and Gen Li and Yuantao Gu", "title": "Unraveling the Veil of Subspace RIP Through Near-Isometry on Subspaces", "comments": "40 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is a popular approach to tackle high-dimensional\ndata with low-dimensional nature. Subspace Restricted Isometry Property, a\nnewly-proposed concept, has proved to be a useful tool in analyzing the effect\nof dimensionality reduction algorithms on subspaces. In this paper, we provide\na characterization of subspace Restricted Isometry Property, asserting that\nmatrices which act as a near-isometry on low-dimensional subspaces possess\nsubspace Restricted Isometry Property. This points out a unified approach to\ndiscuss subspace Restricted Isometry Property. Its power is further\ndemonstrated by the possibility to prove with this result the subspace RIP for\na large variety of random matrices encountered in theory and practice,\nincluding subgaussian matrices, partial Fourier matrices, partial Hadamard\nmatrices, partial circulant/Toeplitz matrices, matrices with independent\nstrongly regular rows (for instance, matrices with independent entries having\nuniformly bounded $4+\\epsilon$ moments), and log-concave ensembles. Thus our\nresult could extend the applicability of random projections in subspace-based\nmachine learning algorithms including subspace clustering and allow for the\napplication of some useful random matrices which are easier to implement on\nhardware or are more efficient to compute.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 12:11:02 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 19:24:43 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Xv", "Xingyu", ""], ["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1905.09614", "submitter": "Shih-Wen Tsou", "authors": "Shih-Wen Tsou, Chun-Yian Su and Chien-Ming Wu", "title": "Learning the Representations of Moist Convection with Convolutional\n  Neural Networks", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representations of atmospheric moist convection in general circulation\nmodels have been one of the most challenging tasks due to its complexity in\nphysical processes, and the interaction between processes under different\ntime/spatial scales. This study proposes a new method to predict the effects of\nmoist convection on the environment using convolutional neural networks. With\nthe help of considering the gradient of physical fields between adjacent grids\nin the grey zone resolution, the effects of moist convection predicted by the\nconvolutional neural networks are more realistic compared to the effects\npredicted by other machine learning models. The result also suggests that the\nmethod proposed in this study has the potential to replace the conventional\ncumulus parameterization in the general circulation models.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 12:25:05 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Tsou", "Shih-Wen", ""], ["Su", "Chun-Yian", ""], ["Wu", "Chien-Ming", ""]]}, {"id": "1905.09635", "submitter": "Junjun Pan", "authors": "Ye Liu, Junjun Pan and Michael Ng", "title": "Tucker Decomposition Network: Expressive Power and Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved a great success in solving many machine\nlearning and computer vision problems. The main contribution of this paper is\nto develop a deep network based on Tucker tensor decomposition, and analyze its\nexpressive power. It is shown that the expressiveness of Tucker network is more\npowerful than that of shallow network. In general, it is required to use an\nexponential number of nodes in a shallow network in order to represent a Tucker\nnetwork. Experimental results are also given to compare the performance of the\nproposed Tucker network with hierarchical tensor network and shallow network,\nand demonstrate the usefulness of Tucker network in image classification\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:12:15 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Liu", "Ye", ""], ["Pan", "Junjun", ""], ["Ng", "Michael", ""]]}, {"id": "1905.09638", "submitter": "William Clements", "authors": "William R. Clements, Bastien Van Delft, Beno\\^it-Marie Robaglia, Reda\n  Bahi Slaoui, S\\'ebastien Toth", "title": "Estimating Risk and Uncertainty in Deep Reinforcement Learning", "comments": "Work presented at the ICML 2020 Workshop on Uncertainty and\n  Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents are faced with two types of uncertainty.\nEpistemic uncertainty stems from limited data and is useful for exploration,\nwhereas aleatoric uncertainty arises from stochastic environments and must be\naccounted for in risk-sensitive applications. We highlight the challenges\ninvolved in simultaneously estimating both of them, and propose a framework for\ndisentangling and estimating these uncertainties on learned Q-values. We derive\nunbiased estimators of these uncertainties and introduce an uncertainty-aware\nDQN algorithm, which we show exhibits safe learning behavior and outperforms\nother DQN variants on the MinAtar testbed.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:13:56 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 12:42:57 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:51:03 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 15:09:22 GMT"}, {"version": "v5", "created": "Wed, 9 Sep 2020 15:44:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Clements", "William R.", ""], ["Van Delft", "Bastien", ""], ["Robaglia", "Beno\u00eet-Marie", ""], ["Slaoui", "Reda Bahi", ""], ["Toth", "S\u00e9bastien", ""]]}, {"id": "1905.09642", "submitter": "Enkhbold Bataa", "authors": "Enkhbold Bataa and Joshua Wu", "title": "An Investigation of Transfer Learning-Based Sentiment Analysis in\n  Japanese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text classification approaches have usually required task-specific model\narchitectures and huge labeled datasets. Recently, thanks to the rise of\ntext-based transfer learning techniques, it is possible to pre-train a language\nmodel in an unsupervised manner and leverage them to perform effective on\ndownstream tasks. In this work we focus on Japanese and show the potential use\nof transfer learning techniques in text classification. Specifically, we\nperform binary and multi-class sentiment classification on the Rakuten product\nreview and Yahoo movie review datasets. We show that transfer learning-based\napproaches perform better than task-specific models trained on 3 times as much\ndata. Furthermore, these approaches perform just as well for language modeling\npre-trained on only 1/30 of the data. We release our pre-trained models and\ncode as open source.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:24:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:07:41 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 08:58:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Bataa", "Enkhbold", ""], ["Wu", "Joshua", ""]]}, {"id": "1905.09653", "submitter": "Tangui Aladjidi", "authors": "Tangui Aladjidi, Fran\\c{c}ois Pasqualini", "title": "New methods for SVM feature selection", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines have been a popular topic for quite some time now,\nand as they develop, a need for new methods of feature selection arises. This\nwork presents various approaches SVM feature selection developped using new\ntools such as entropy measurement and K-medoid clustering. The work focuses on\nthe use of one-class SVM's for wafer testing, with a numerical implementation\nin R.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:45:51 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 09:37:42 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Aladjidi", "Tangui", ""], ["Pasqualini", "Fran\u00e7ois", ""]]}, {"id": "1905.09668", "submitter": "Domingo Esteban", "authors": "Domingo Esteban, Leonel Rozo, Darwin G. Caldwell", "title": "Hierarchical Reinforcement Learning for Concurrent Discovery of Compound\n  and Composable Policies", "comments": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy to deal with the expensive reinforcement learning (RL) of\ncomplex tasks is to decompose them into a collection of subtasks that are\nusually simpler to learn as well as reusable for new problems. However, when a\nrobot learns the policies for these subtasks, common approaches treat every\npolicy learning process separately. Therefore, all these individual\n(composable) policies need to be learned before tackling the learning process\nof the complex task through policies composition. Moreover, such composition of\nindividual policies is usually performed sequentially, which is not suitable\nfor tasks that require to perform the subtasks concurrently. In this paper, we\npropose to combine a set of composable Gaussian policies corresponding to these\nsubtasks using a set of activation vectors, resulting in a complex Gaussian\npolicy that is a function of the means and covariances matrices of the\ncomposable policies. Moreover, we propose an algorithm for learning both\ncompound and composable policies within the same learning process by exploiting\nthe off-policy data generated from the compound policy. The algorithm is built\non a maximum entropy RL approach to favor exploration during the learning\nprocess. The results of the experiments show that the experience collected with\nthe compound policy permits not only to solve the complex task but also to\nobtain useful composable policies that successfully perform in their\ncorresponding subtasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:08:35 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 17:29:20 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Esteban", "Domingo", ""], ["Rozo", "Leonel", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1905.09670", "submitter": "Th\\'eo Galy-Fajou", "authors": "Th\\'eo Galy-Fajou, Florian Wenzel, Christian Donner and Manfred Opper", "title": "Multi-Class Gaussian Process Classification Made Conjugate: Efficient\n  Inference via Data Augmentation", "comments": "Accepted at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scalable multi-class Gaussian process classification\napproach building on a novel modified softmax likelihood function. The new\nlikelihood has two benefits: it leads to well-calibrated uncertainty estimates\nand allows for an efficient latent variable augmentation. The augmented model\nhas the advantage that it is conditionally conjugate leading to a fast\nvariational inference method via block coordinate ascent updates. Previous\napproaches suffered from a trade-off between uncertainty calibration and speed.\nOur experiments show that our method leads to well-calibrated uncertainty\nestimates and competitive predictive performance while being up to two orders\nfaster than the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:13:11 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Galy-Fajou", "Th\u00e9o", ""], ["Wenzel", "Florian", ""], ["Donner", "Christian", ""], ["Opper", "Manfred", ""]]}, {"id": "1905.09673", "submitter": "Jivitesh Sharma", "authors": "Jivitesh Sharma, Per-Arne Andersen, Ole-Chrisoffer Granmo and Morten\n  Goodwin", "title": "Deep Q-Learning with Q-Matrix Transfer Learning for Novel Fire\n  Evacuation Environment", "comments": "21 pages, 14 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We focus on the important problem of emergency evacuation, which clearly\ncould benefit from reinforcement learning that has been largely unaddressed.\nEmergency evacuation is a complex task which is difficult to solve with\nreinforcement learning, since an emergency situation is highly dynamic, with a\nlot of changing variables and complex constraints that makes it difficult to\ntrain on. In this paper, we propose the first fire evacuation environment to\ntrain reinforcement learning agents for evacuation planning. The environment is\nmodelled as a graph capturing the building structure. It consists of realistic\nfeatures like fire spread, uncertainty and bottlenecks. We have implemented the\nenvironment in the OpenAI gym format, to facilitate future research. We also\npropose a new reinforcement learning approach that entails pretraining the\nnetwork weights of a DQN based agents to incorporate information on the\nshortest path to the exit. We achieved this by using tabular Q-learning to\nlearn the shortest path on the building model's graph. This information is\ntransferred to the network by deliberately overfitting it on the Q-matrix.\nThen, the pretrained DQN model is trained on the fire evacuation environment to\ngenerate the optimal evacuation path under time varying conditions. We perform\ncomparisons of the proposed approach with state-of-the-art reinforcement\nlearning algorithms like PPO, VPG, SARSA, A2C and ACKTR. The results show that\nour method is able to outperform state-of-the-art models by a huge margin\nincluding the original DQN based models. Finally, we test our model on a large\nand complex real building consisting of 91 rooms, with the possibility to move\nto any other room, hence giving 8281 actions. We use an attention based\nmechanism to deal with large action spaces. Our model achieves near optimal\nperformance on the real world emergency environment.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:15:51 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:35:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Sharma", "Jivitesh", ""], ["Andersen", "Per-Arne", ""], ["Granmo", "Ole-Chrisoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "1905.09676", "submitter": "Xiaoxi He", "authors": "Xiaoxi He, Dawei Gao, Zimu Zhou, Yongxin Tong, Lothar Thiele", "title": "Pruning-Aware Merging for Efficient Multitask Inference", "comments": "Accepted to KDD'21 as research track paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications demand selective execution of multiple correlated\ndeep learning inference tasks on resource-constrained platforms. Given a set of\ndeep neural networks, each pre-trained for a single task, it is desired that\nexecuting arbitrary combinations of tasks yields minimal computation cost.\nPruning each network separately yields suboptimal computation cost due to task\nrelatedness. A promising remedy is to merge the networks into a multitask\nnetwork to eliminate redundancy across tasks before network pruning. However,\npruning a multitask network combined by existing network merging schemes cannot\nminimise the computation cost of every task combination because they do not\nconsider such a future pruning. To this end, we theoretically identify the\nconditions such that pruning a multitask network minimises the computation of\nall task combinations. On this basis, we propose Pruning-Aware Merging (PAM), a\nheuristic network merging scheme to construct a multitask network that\napproximates these conditions. The merged network is then ready to be further\npruned by existing network pruning methods. Evaluations with different pruning\nschemes, datasets, and network architectures show that PAM achieves up to 4.87x\nless computation against the baseline without network merging, and up to 2.01x\nless computation against the baseline with a state-of-the-art network merging\nscheme.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:23:46 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:35:47 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["He", "Xiaoxi", ""], ["Gao", "Dawei", ""], ["Zhou", "Zimu", ""], ["Tong", "Yongxin", ""], ["Thiele", "Lothar", ""]]}, {"id": "1905.09677", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Andreas Loukas, Mike Davies, Pierre Vandergheynst", "title": "The role of invariance in spectral complexity-based generalization\n  bounds", "comments": "arXiv admin note: text overlap with arXiv:1801.00171", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have been shown to be able to fit a\nrandom labeling over data while still being able to generalize well for normal\nlabels. Describing CNN capacity through a posteriori measures of complexity has\nbeen recently proposed to tackle this apparent paradox. These complexity\nmeasures are usually validated by showing that they correlate empirically with\nGE; being empirically larger for networks trained on random vs normal labels.\nFocusing on the case of spectral complexity we investigate theoretically and\nempirically the insensitivity of the complexity measure to invariances relevant\nto CNNs, and show several limitations of spectral complexity that occur as a\nresult. For a specific formulation of spectral complexity we show that it\nresults in the same upper bound complexity estimates for convolutional and\nlocally connected architectures (which don't have the same favorable invariance\nproperties). This is contrary to common intuition and empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:23:50 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 11:42:56 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Loukas", "Andreas", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1905.09680", "submitter": "Hyunghun Cho", "authors": "Hyunghun Cho, Yongjin Kim, Eunjung Lee, Daeyoung Choi, Yongjae Lee,\n  Wonjong Rhee", "title": "DEEP-BO for Hyperparameter Optimization of Deep Networks", "comments": "26 pages, NeurIPS19 under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks (DNN) is very sensitive to the\nparticular choice of hyper-parameters. To make it worse, the shape of the\nlearning curve can be significantly affected when a technique like batchnorm is\nused. As a result, hyperparameter optimization of deep networks can be much\nmore challenging than traditional machine learning models. In this work, we\nstart from well known Bayesian Optimization solutions and provide enhancement\nstrategies specifically designed for hyperparameter optimization of deep\nnetworks. The resulting algorithm is named as DEEP-BO (Diversified,\nEarly-termination-Enabled, and Parallel Bayesian Optimization). When evaluated\nover six DNN benchmarks, DEEP-BO easily outperforms or shows comparable\nperformance with some of the well-known solutions including GP-Hedge,\nHyperband, BOHB, Median Stopping Rule, and Learning Curve Extrapolation. The\ncode used is made publicly available at https://github.com/snu-adsl/DEEP-BO.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:25:33 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Cho", "Hyunghun", ""], ["Kim", "Yongjin", ""], ["Lee", "Eunjung", ""], ["Choi", "Daeyoung", ""], ["Lee", "Yongjae", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1905.09683", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Phuong D.H. Nguyen, Stefan Wermter", "title": "From semantics to execution: Integrating action planning with\n  reinforcement learning for robotic causal problem-solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is an appropriate and successful method to robustly\nperform low-level robot control under noisy conditions. Symbolic action\nplanning is useful to resolve causal dependencies and to break a causally\ncomplex problem down into a sequence of simpler high-level actions. A problem\nwith the integration of both approaches is that action planning is based on\ndiscrete high-level action- and state spaces, whereas reinforcement learning is\nusually driven by a continuous reward function. However, recent advances in\nreinforcement learning, specifically, universal value function approximators\nand hindsight experience replay, have focused on goal-independent methods based\non sparse rewards. In this article, we build on these novel methods to\nfacilitate the integration of action planning with reinforcement learning by\nexploiting the reward-sparsity as a bridge between the high-level and low-level\nstate- and control spaces. As a result, we demonstrate that the integrated\nneuro-symbolic method is able to solve object manipulation problems that\ninvolve tool use and non-trivial causal dependencies under noisy conditions,\nexploiting both data and knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:34:38 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 14:15:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Eppe", "Manfred", ""], ["Nguyen", "Phuong D. H.", ""], ["Wermter", "Stefan", ""]]}, {"id": "1905.09684", "submitter": "Ryo Yonetani", "authors": "Ryo Yonetani, Tomohiro Takahashi, Atsushi Hashimoto, Yoshitaka Ushiku", "title": "Decentralized Learning of Generative Adversarial Networks from Non-iid\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses a new problem that learns generative adversarial networks\n(GANs) from multiple data collections that are each i) owned separately by\ndifferent clients and ii) drawn from a non-identical distribution that\ncomprises different classes. Given such non-iid data as input, we aim to learn\na distribution involving all the classes input data can belong to, while\nkeeping the data decentralized in each client storage. Our key contribution to\nthis end is a new decentralized approach for learning GANs from non-iid data\ncalled Forgiver-First Update (F2U), which a) asks clients to train an\nindividual discriminator with their own data and b) updates a generator to fool\nthe most `forgiving' discriminators who deem generated samples as the most\nreal. Our theoretical analysis proves that this updating strategy allows the\ndecentralized GAN to achieve a generator's distribution with all the input\nclasses as its global optimum based on f-divergence minimization. Moreover, we\npropose a relaxed version of F2U called Forgiver-First Aggregation (F2A) that\nperforms well in practice, which adaptively aggregates the discriminators while\nemphasizing forgiving ones. Our empirical evaluations with image generation\ntasks demonstrated the effectiveness of our approach over state-of-the-art\ndecentralized learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:41:54 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 02:04:11 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Yonetani", "Ryo", ""], ["Takahashi", "Tomohiro", ""], ["Hashimoto", "Atsushi", ""], ["Ushiku", "Yoshitaka", ""]]}, {"id": "1905.09688", "submitter": "Ole-Christoffer Granmo", "authors": "Ole-Christoffer Granmo and Sondre Glimsdal and Lei Jiao and Morten\n  Goodwin and Christian W. Omlin and Geir Thore Berge", "title": "The Convolutional Tsetlin Machine", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have obtained astounding successes for\nimportant pattern recognition tasks, but they suffer from high computational\ncomplexity and the lack of interpretability. The recent Tsetlin Machine (TM)\nattempts to address this lack by using easy-to-interpret conjunctive clauses in\npropositional logic to solve complex pattern recognition problems. The TM\nprovides competitive accuracy in several benchmarks, while keeping the\nimportant property of interpretability. It further facilitates hardware-near\nimplementation since inputs, patterns, and outputs are expressed as bits, while\nrecognition and learning rely on straightforward bit manipulation. In this\npaper, we exploit the TM paradigm by introducing the Convolutional Tsetlin\nMachine (CTM), as an interpretable alternative to CNNs. Whereas the TM\ncategorizes an image by employing each clause once to the whole image, the CTM\nuses each clause as a convolution filter. That is, a clause is evaluated\nmultiple times, once per image patch taking part in the convolution. To make\nthe clauses location-aware, each patch is further augmented with its\ncoordinates within the image. The output of a convolution clause is obtained\nsimply by ORing the outcome of evaluating the clause on each patch. In the\nlearning phase of the TM, clauses that evaluate to 1 are contrasted against the\ninput. For the CTM, we instead contrast against one of the patches, randomly\nselected among the patches that made the clause evaluate to 1. Accordingly, the\nstandard Type I and Type II feedback of the classic TM can be employed\ndirectly, without further modification. The CTM obtains a peak test accuracy of\n99.4% on MNIST, 96.31% on Kuzushiji-MNIST, 91.5% on Fashion-MNIST, and 100.0%\non the 2D Noisy XOR Problem, which is competitive with results reported for\nsimple 4-layer CNNs, BinaryConnect, Logistic Circuits and an FPGA-accelerated\nBinary CNN.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:47:33 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 06:51:38 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 16:10:14 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 01:33:09 GMT"}, {"version": "v5", "created": "Fri, 27 Dec 2019 11:25:56 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Granmo", "Ole-Christoffer", ""], ["Glimsdal", "Sondre", ""], ["Jiao", "Lei", ""], ["Goodwin", "Morten", ""], ["Omlin", "Christian W.", ""], ["Berge", "Geir Thore", ""]]}, {"id": "1905.09690", "submitter": "Takahiro Omi", "authors": "Takahiro Omi, Naonori Ueda, Kazuyuki Aihara", "title": "Fully Neural Network based Model for General Temporal Point Processes", "comments": null, "journal-ref": "Neurips 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A temporal point process is a mathematical model for a time series of\ndiscrete events, which covers various applications. Recently, recurrent neural\nnetwork (RNN) based models have been developed for point processes and have\nbeen found effective. RNN based models usually assume a specific functional\nform for the time course of the intensity function of a point process (e.g.,\nexponentially decreasing or increasing with the time since the most recent\nevent). However, such an assumption can restrict the expressive power of the\nmodel. We herein propose a novel RNN based model in which the time course of\nthe intensity function is represented in a general manner. In our approach, we\nfirst model the integral of the intensity function using a feedforward neural\nnetwork and then obtain the intensity function as its derivative. This approach\nenables us to both obtain a flexible model of the intensity function and\nexactly evaluate the log-likelihood function, which contains the integral of\nthe intensity function, without any numerical approximations. Our model\nachieves competitive or superior performances compared to the previous\nstate-of-the-art methods for both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:52:56 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 08:23:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 06:57:31 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Omi", "Takahiro", ""], ["Ueda", "Naonori", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "1905.09691", "submitter": "Bryan Lim", "authors": "Bryan Lim, Stefan Zohren, Stephen Roberts", "title": "Population-based Global Optimisation Methods for Learning Long-term\n  Dependencies with RNNs", "comments": "To appear at ICML 2019 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent innovations in network architectures and loss functions,\ntraining RNNs to learn long-term dependencies remains difficult due to\nchallenges with gradient-based optimisation methods. Inspired by the success of\nDeep Neuroevolution in reinforcement learning (Such et al. 2017), we explore\nthe use of gradient-free population-based global optimisation (PBO) techniques\n-- training RNNs to capture long-term dependencies in time-series data. Testing\nevolution strategies (ES) and particle swarm optimisation (PSO) on an\napplication in volatility forecasting, we demonstrate that PBO methods lead to\nperformance improvements in general, with ES exhibiting the most consistent\nresults across a variety of architectures.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:55:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1905.09698", "submitter": "Muhammad Aminul Islam", "authors": "Muhammad Aminul Islam, Derek T. Anderson, John E. Ball, Nicolas H.\n  Younan", "title": "Fusion of heterogeneous bands and kernels in hyperspectral image\n  processing", "comments": null, "journal-ref": "J. Appl. Remote Sens. 13(2), 026508 (2019)", "doi": "10.1117/1.JRS.13.026508", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral imaging is a powerful technology that is plagued by large\ndimensionality. Herein, we explore a way to combat that hindrance via\nnon-contiguous and contiguous (simpler to realize sensor) band grouping for\ndimensionality reduction. Our approach is different in the respect that it is\nflexible and it follows a well-studied process of visual clustering in\nhigh-dimensional spaces. Specifically, we extend the improved visual assessment\nof cluster tendency and clustering in ordered dissimilarity data unsupervised\nclustering algorithms for supervised hyperspectral learning. In addition, we\npropose a way to extract diverse features via the use of different proximity\nmetrics (ways to measure the similarity between bands) and kernel functions.\nThe discovered features are fused with $l_{\\infty}$-norm multiple kernel\nlearning. Experiments are conducted on two benchmark datasets and our results\nare compared to related work. These datasets indicate that contiguous or not is\napplication specific, but heterogeneous features and kernels usually lead to\nperformance gain.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:21:36 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Islam", "Muhammad Aminul", ""], ["Anderson", "Derek T.", ""], ["Ball", "John E.", ""], ["Younan", "Nicolas H.", ""]]}, {"id": "1905.09700", "submitter": "Chen Tessler", "authors": "Chen Tessler, Tom Zahavy, Deborah Cohen, Daniel J. Mankowitz and Shie\n  Mannor", "title": "Action Assembly: Sparse Imitation Learning for Text Based Games with\n  Combinatorial Action Spaces", "comments": "Under review at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computationally efficient algorithm that combines compressed\nsensing with imitation learning to solve text-based games with combinatorial\naction spaces. Specifically, we introduce a new compressed sensing algorithm,\nnamed IK-OMP, which can be seen as an extension to the Orthogonal Matching\nPursuit (OMP). We incorporate IK-OMP into a supervised imitation learning\nsetting and show that the combined approach (Sparse Imitation Learning,\nSparse-IL) solves the entire text-based game of Zork1 with an action space of\napproximately 10 million actions given both perfect and noisy demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:06:55 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 09:13:40 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 09:58:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tessler", "Chen", ""], ["Zahavy", "Tom", ""], ["Cohen", "Deborah", ""], ["Mankowitz", "Daniel J.", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.09704", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alon Cohen, Haim Kaplan, Yishay Mansour", "title": "Unknown mixing times in apprenticeship and reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive and analyze learning algorithms for apprenticeship learning, policy\nevaluation, and policy gradient for average reward criteria. Existing\nalgorithms explicitly require an upper bound on the mixing time. In contrast,\nwe build on ideas from Markov chain theory and derive sampling algorithms that\ndo not require such an upper bound. For these algorithms, we provide\ntheoretical bounds on their sample-complexity and running time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:11:02 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 11:27:43 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zahavy", "Tom", ""], ["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.09710", "submitter": "Tom Zahavy", "authors": "Stav Belogolovsky, Philip Korsunsky, Shie Mannor, Chen Tessler, Tom\n  Zahavy", "title": "Inverse Reinforcement Learning in Contextual MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of Inverse Reinforcement Learning in Contextual Markov\nDecision Processes (MDPs). In this setting, contexts, which define the reward\nand transition kernel, are sampled from a distribution. In addition, although\nthe reward is a function of the context, it is not provided to the agent.\nInstead, the agent observes demonstrations from an optimal policy. The goal is\nto learn the reward mapping, such that the agent will act optimally even when\nencountering previously unseen contexts, also known as zero-shot transfer. We\nformulate this problem as a non-differential convex optimization problem and\npropose a novel algorithm to compute its subgradients. Based on this scheme, we\nanalyze several methods both theoretically, where we compare the sample\ncomplexity and scalability, and empirically. Most importantly, we show both\ntheoretically and empirically that our algorithms perform zero-shot transfer\n(generalize to new and unseen contexts). Specifically, we present empirical\nexperiments in a dynamic treatment regime, where the goal is to learn a reward\nfunction which explains the behavior of expert physicians based on recorded\ndata of them treating patients diagnosed with sepsis.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:14:43 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:24:08 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 16:51:16 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 13:54:14 GMT"}, {"version": "v5", "created": "Wed, 30 Dec 2020 18:11:45 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Belogolovsky", "Stav", ""], ["Korsunsky", "Philip", ""], ["Mannor", "Shie", ""], ["Tessler", "Chen", ""], ["Zahavy", "Tom", ""]]}, {"id": "1905.09712", "submitter": "Jinke Ren", "authors": "Jinke Ren, Guanding Yu, and Guangyao Ding", "title": "Accelerating DNN Training in Wireless Federated Edge Learning Systems", "comments": "To be published in IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training task in classical machine learning models, such as deep neural\nnetworks, is generally implemented at a remote cloud center for centralized\nlearning, which is typically time-consuming and resource-hungry. It also incurs\nserious privacy issue and long communication latency since a large amount of\ndata are transmitted to the centralized node. To overcome these shortcomings,\nwe consider a newly-emerged framework, namely federated edge learning, to\naggregate local learning updates at the network edge in lieu of users' raw\ndata. Aiming at accelerating the training process, we first define a novel\nperformance evaluation criterion, called learning efficiency. We then formulate\na training acceleration optimization problem in the CPU scenario, where each\nuser device is equipped with CPU. The closed-form expressions for joint\nbatchsize selection and communication resource allocation are developed and\nsome insightful results are highlighted. Further, we extend our learning\nframework to the GPU scenario. The optimal solution in this scenario is\nmanifested to have the similar structure as that of the CPU scenario,\nrecommending that our proposed algorithm is applicable in more general systems.\nFinally, extensive experiments validate the theoretical analysis and\ndemonstrate that the proposed algorithm can reduce the training time and\nimprove the learning accuracy simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:18:03 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 03:05:15 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 01:48:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ren", "Jinke", ""], ["Yu", "Guanding", ""], ["Ding", "Guangyao", ""]]}, {"id": "1905.09718", "submitter": "Chengtai Cao", "authors": "Fan Zhou, Chengtai Cao, Kunpeng Zhang, Goce Trajcevski, Ting Zhong, Ji\n  Geng", "title": "Meta-GNN: On Few-shot Node Classification in Graph Meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has received a tremendous recent attention as a possible\napproach for mimicking human intelligence, i.e., acquiring new knowledge and\nskills with little or even no demonstration. Most of the existing meta-learning\nmethods are proposed to tackle few-shot learning problems such as image and\ntext, in rather Euclidean domain. However, there are very few works applying\nmeta-learning to non-Euclidean domains, and the recently proposed graph neural\nnetworks (GNNs) models do not perform effectively on graph few-shot learning\nproblems. Towards this, we propose a novel graph meta-learning framework --\nMeta-GNN -- to tackle the few-shot node classification problem in graph\nmeta-learning settings. It obtains the prior knowledge of classifiers by\ntraining on many similar few-shot learning tasks and then classifies the nodes\nfrom new classes with only few labeled samples. Additionally, Meta-GNN is a\ngeneral model that can be straightforwardly incorporated into any existing\nstate-of-the-art GNN. Our experiments conducted on three benchmark datasets\ndemonstrate that our proposed approach not only improves the node\nclassification performance by a large margin on few-shot learning problems in\nmeta-learning paradigm, but also learns a more general and flexible model for\ntask adaption.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:24:00 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhou", "Fan", ""], ["Cao", "Chengtai", ""], ["Zhang", "Kunpeng", ""], ["Trajcevski", "Goce", ""], ["Zhong", "Ting", ""], ["Geng", "Ji", ""]]}, {"id": "1905.09746", "submitter": "Evgenii Kanin", "authors": "Evgenii Kanin, Andrei Osiptsov, Albert Vainshtein, Evgeny Burnaev", "title": "A Predictive Model for Steady-State Multiphase Pipe Flow: Machine\n  Learning on Lab Data", "comments": null, "journal-ref": null, "doi": "10.1016/j.petrol.2019.05.055", "report-no": null, "categories": "physics.data-an cs.LG physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engineering simulators used for steady-state multiphase pipe flows are\ncommonly utilized to predict pressure drop. Such simulators are typically based\non either empirical correlations or first-principles mechanistic models. The\nsimulators allow evaluating the pressure drop in multiphase pipe flow with\nacceptable accuracy. However, the only shortcoming of these correlations and\nmechanistic models is their applicability. In order to extend the applicability\nand the accuracy of the existing accessible methods, a method of pressure drop\ncalculation in the pipeline is proposed. The method is based on well\nsegmentation and calculation of the pressure gradient in each segment using\nthree surrogate models based on Machine Learning algorithms trained on a\nrepresentative lab data set from the open literature. The first model predicts\nthe value of a liquid holdup in the segment, the second one determines the flow\npattern, and the third one is used to estimate the pressure gradient. To build\nthese models, several ML algorithms are trained such as Random Forest, Gradient\nBoosting Decision Trees, Support Vector Machine, and Artificial Neural Network,\nand their predictive abilities are cross-compared. The proposed method for\npressure gradient calculation yields $R^2 = 0.95$ by using the Gradient\nBoosting algorithm as compared with $R^2 = 0.92$ in case of Mukherjee and Brill\ncorrelation and $R^2 = 0.91$ when a combination of Ansari and Xiao mechanistic\nmodels is utilized. The method for pressure drop prediction is also validated\non three real field cases. Validation indicates that the proposed model yields\nthe following coefficients of determination: $R^2 = 0.806, 0.815$ and 0.99 as\ncompared with the highest values obtained by commonly used techniques: $R^2 =\n0.82$ (Beggs and Brill correlation), $R^2 = 0.823$ (Mukherjee and Brill\ncorrelation) and $R^2 = 0.98$ (Beggs and Brill correlation).\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:08:57 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kanin", "Evgenii", ""], ["Osiptsov", "Andrei", ""], ["Vainshtein", "Albert", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1905.09747", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Liam Fowl, Soheil Feizi, Tom Goldstein", "title": "Adversarially Robust Distillation", "comments": "Accepted to AAAI Conference on Artificial Intelligence, 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5816", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation is effective for producing small, high-performance\nneural networks for classification, but these small networks are vulnerable to\nadversarial attacks. This paper studies how adversarial robustness transfers\nfrom teacher to student during knowledge distillation. We find that a large\namount of robustness may be inherited by the student even when distilled on\nonly clean images. Second, we introduce Adversarially Robust Distillation (ARD)\nfor distilling robustness onto student networks. In addition to producing small\nmodels with high test accuracy like conventional distillation, ARD also passes\nthe superior robustness of large networks onto the student. In our experiments,\nwe find that ARD student models decisively outperform adversarially trained\nnetworks of identical architecture in terms of robust accuracy, surpassing\nstate-of-the-art methods on standard robustness benchmarks. Finally, we adapt\nrecent fast adversarial training methods to ARD for accelerated robust\ndistillation.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:09:20 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 22:37:09 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Goldblum", "Micah", ""], ["Fowl", "Liam", ""], ["Feizi", "Soheil", ""], ["Goldstein", "Tom", ""]]}, {"id": "1905.09755", "submitter": "Bora Edizel", "authors": "Bora Edizel, Aleksandra Piktus, Piotr Bojanowski, Rui Ferreira,\n  Edouard Grave, Fabrizio Silvestri", "title": "Misspelling Oblivious Word Embeddings", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method to learn word embeddings that are resilient\nto misspellings. Existing word embeddings have limited applicability to\nmalformed texts, which contain a non-negligible amount of out-of-vocabulary\nwords. We propose a method combining FastText with subwords and a supervised\ntask of learning misspelling patterns. In our method, misspellings of each word\nare embedded close to their correct variants. We train these embeddings on a\nnew dataset we are releasing publicly. Finally, we experimentally show the\nadvantages of this approach on both intrinsic and extrinsic NLP tasks using\npublic test sets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:28:08 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Edizel", "Bora", ""], ["Piktus", "Aleksandra", ""], ["Bojanowski", "Piotr", ""], ["Ferreira", "Rui", ""], ["Grave", "Edouard", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "1905.09763", "submitter": "Leo Torres", "authors": "Leo Torres, Kevin S Chan, Tina Eliassi-Rad", "title": "GLEE: Geometric Laplacian Eigenmap Embedding", "comments": null, "journal-ref": null, "doi": "10.1093/comnet/cnaa007", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding seeks to build a low-dimensional representation of a graph G.\nThis low-dimensional representation is then used for various downstream tasks.\nOne popular approach is Laplacian Eigenmaps, which constructs a graph embedding\nbased on the spectral properties of the Laplacian matrix of G. The intuition\nbehind it, and many other embedding techniques, is that the embedding of a\ngraph must respect node similarity: similar nodes must have embeddings that are\nclose to one another. Here, we dispose of this distance-minimization\nassumption. Instead, we use the Laplacian matrix to find an embedding with\ngeometric properties instead of spectral ones, by leveraging the so-called\nsimplex geometry of G. We introduce a new approach, Geometric Laplacian\nEigenmap Embedding (or GLEE for short), and demonstrate that it outperforms\nvarious other techniques (including Laplacian Eigenmaps) in the tasks of graph\nreconstruction and link prediction.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:35:23 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 15:49:28 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Torres", "Leo", ""], ["Chan", "Kevin S", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1905.09768", "submitter": "Paul Micaelli", "authors": "Paul Micaelli and Amos Storkey", "title": "Zero-shot Knowledge Transfer via Adversarial Belief Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Performing knowledge transfer from a large teacher network to a smaller\nstudent is a popular task in modern deep learning applications. However, due to\ngrowing dataset sizes and stricter privacy regulations, it is increasingly\ncommon not to have access to the data that was used to train the teacher. We\npropose a novel method which trains a student to match the predictions of its\nteacher without using any data or metadata. We achieve this by training an\nadversarial generator to search for images on which the student poorly matches\nthe teacher, and then using them to train the student. Our resulting student\nclosely approximates its teacher for simple datasets like SVHN, and on CIFAR10\nwe improve on the state-of-the-art for few-shot distillation (with 100 images\nper class), despite using no data. Finally, we also propose a metric to\nquantify the degree of belief matching between teacher and student in the\nvicinity of decision boundaries, and observe a significantly higher match\nbetween our zero-shot student and the teacher, than between a student distilled\nwith real data and the teacher. Code available at:\nhttps://github.com/polo5/ZeroShotKnowledgeTransfer\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:44:08 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 15:52:36 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 16:37:52 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 20:50:29 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Micaelli", "Paul", ""], ["Storkey", "Amos", ""]]}, {"id": "1905.09771", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang, Marco Fiore, Paul Patras", "title": "Multi-Service Mobile Traffic Forecasting via Convolutional Long\n  Short-Term Memories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing is increasingly used to partition network infrastructure\nbetween different mobile services. Precise service-wise mobile traffic\nforecasting becomes essential in this context, as mobile operators seek to\npre-allocate resources to each slice in advance, to meet the distinct\nrequirements of individual services. This paper attacks the problem of\nmulti-service mobile traffic forecasting using a sequence-to-sequence (S2S)\nlearning paradigm and convolutional long short-term memories (ConvLSTMs). The\nproposed architecture is designed so as to effectively extract complex\nspatiotemporal features of mobile network traffic and predict with high\naccuracy the future demands for individual services at city scale. We conduct\nexperiments on a mobile traffic dataset collected in a large European\nmetropolis, demonstrating that the proposed S2S-ConvLSTM can forecast the\nmobile traffic volume produced by tens of different services in advance of up\nto one hour, by just using measurements taken during the past hour. In\nparticular, our solution achieves mean absolute errors (MAE) at antenna level\nthat are below 13KBps, outperforming other deep learning approaches by up to\n31.2%.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:50:54 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Fiore", "Marco", ""], ["Patras", "Paul", ""]]}, {"id": "1905.09780", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim and Michael McCourt and Tackgeun You and Saehoon Kim and\n  Seungjin Choi", "title": "Bayesian Optimization with Approximate Set Kernels", "comments": "18 pages, 7 figures, 5 tables, accepted for publication in Machine\n  Learning Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical Bayesian optimization method over sets, to minimize a\nblack-box function that takes a set as a single input. Because set inputs are\npermutation-invariant, traditional Gaussian process-based Bayesian optimization\nstrategies which assume vector inputs can fall short. To address this, we\ndevelop a Bayesian optimization method with \\emph{set kernel} that is used to\nbuild surrogate functions. This kernel accumulates similarity over set elements\nto enforce permutation-invariance, but this comes at a greater computational\ncost. To reduce this burden, we propose two key components: (i) a more\nefficient approximate set kernel which is still positive-definite and is an\nunbiased estimator of the true set kernel with upper-bounded variance in terms\nof the number of subsamples, (ii) a constrained acquisition function\noptimization over sets, which uses symmetry of the feasible region that defines\na set input. Finally, we present several numerical experiments which\ndemonstrate that our method outperforms other methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:08:49 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:04:17 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 04:12:19 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kim", "Jungtaek", ""], ["McCourt", "Michael", ""], ["You", "Tackgeun", ""], ["Kim", "Saehoon", ""], ["Choi", "Seungjin", ""]]}, {"id": "1905.09788", "submitter": "Hiroshi Inoue", "authors": "Hiroshi Inoue", "title": "Multi-Sample Dropout for Accelerated Training and Better Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a simple but efficient regularization technique for achieving\nbetter generalization of deep neural networks (DNNs); hence it is widely used\nin tasks based on DNNs. During training, dropout randomly discards a portion of\nthe neurons to avoid overfitting. This paper presents an enhanced dropout\ntechnique, which we call multi-sample dropout, for both accelerating training\nand improving generalization over the original dropout. The original dropout\ncreates a randomly selected subset (called a dropout sample) from the input in\neach training iteration while the multi-sample dropout creates multiple dropout\nsamples. The loss is calculated for each sample, and then the sample losses are\naveraged to obtain the final loss. This technique can be easily implemented by\nduplicating a part of the network after the dropout layer while sharing the\nweights among the duplicated fully connected layers. Experimental results using\nimage classification tasks including ImageNet, CIFAR-10, and CIFAR-100 showed\nthat multi-sample dropout accelerates training. Moreover, the networks trained\nusing multi-sample dropout achieved lower error rates compared to networks\ntrained with the original dropout. The additional computation cost due to the\nduplicated operations is not significant for deep convolutional networks\nbecause most of the computation time is consumed in the convolution layers\nbefore the dropout layer, which are not duplicated.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:22:57 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 06:25:23 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 02:39:55 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Inoue", "Hiroshi", ""]]}, {"id": "1905.09791", "submitter": "Ivana Bala\\v{z}evi\\'c", "authors": "Ivana Bala\\v{z}evi\\'c, Carl Allen and Timothy Hospedales", "title": "Multi-relational Poincar\\'e Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic embeddings have recently gained attention in machine learning due\nto their ability to represent hierarchical data more accurately and succinctly\nthan their Euclidean analogues. However, multi-relational knowledge graphs\noften exhibit multiple simultaneous hierarchies, which current hyperbolic\nmodels do not capture. To address this, we propose a model that embeds\nmulti-relational graph data in the Poincar\\'e ball model of hyperbolic space.\nOur Multi-Relational Poincar\\'e model (MuRP) learns relation-specific\nparameters to transform entity embeddings by M\\\"obius matrix-vector\nmultiplication and M\\\"obius addition. Experiments on the hierarchical WN18RR\nknowledge graph show that our Poincar\\'e embeddings outperform their Euclidean\ncounterpart and existing embedding methods on the link prediction task,\nparticularly at lower dimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:31:40 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 12:22:40 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 13:30:06 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bala\u017eevi\u0107", "Ivana", ""], ["Allen", "Carl", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1905.09796", "submitter": "Konstantin Klemmer", "authors": "Konstantin Klemmer, Adriano Koshiyama, Sebastian Flennerhag", "title": "Augmenting correlation structures in spatial data using deep generative\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep learning methods have shown a remarkable capacity to\nmodel complex data domains, but struggle with geospatial data. In this paper,\nwe introduce SpaceGAN, a novel generative model for geospatial domains that\nlearns neighbourhood structures through spatial conditioning. We propose to\nenhance spatial representation beyond mere spatial coordinates, by conditioning\neach data point on feature vectors of its spatial neighbours, thus allowing for\na more flexible representation of the spatial structure. To overcome issues of\ntraining convergence, we employ a metric capturing the loss in local spatial\nautocorrelation between real and generated data as stopping criterion for\nSpaceGAN parametrization. This way, we ensure that the generator produces\nsynthetic samples faithful to the spatial patterns observed in the input.\nSpaceGAN is successfully applied for data augmentation and outperforms compared\nto other methods of synthetic spatial data generation. Finally, we propose an\nensemble learning framework for the geospatial domain, taking augmented\nSpaceGAN samples as training data for a set of ensemble learners. We\nempirically show the superiority of this approach over conventional ensemble\nlearning approaches and rivaling spatial data augmentation methods, using\nsynthetic and real-world prediction tasks. Our findings suggest that SpaceGAN\ncan be used as a tool for (1) artificially inflating sparse geospatial data and\n(2) improving generalization of geospatial models.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:39:23 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Klemmer", "Konstantin", ""], ["Koshiyama", "Adriano", ""], ["Flennerhag", "Sebastian", ""]]}, {"id": "1905.09797", "submitter": "Tianyuan Zhang", "authors": "Tianyuan Zhang, Zhanxing Zhu", "title": "Interpreting Adversarially Trained Convolutional Neural Networks", "comments": "To apper in ICML19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attempt to interpret how adversarially trained convolutional neural\nnetworks (AT-CNNs) recognize objects. We design systematic approaches to\ninterpret AT-CNNs in both qualitative and quantitative ways and compare them\nwith normally trained models. Surprisingly, we find that adversarial training\nalleviates the texture bias of standard CNNs when trained on object recognition\ntasks, and helps CNNs learn a more shape-biased representation. We validate our\nhypothesis from two aspects. First, we compare the salience maps of AT-CNNs and\nstandard CNNs on clean images and images under different transformations. The\ncomparison could visually show that the prediction of the two types of CNNs is\nsensitive to dramatically different types of features. Second, to achieve\nquantitative verification, we construct additional test datasets that destroy\neither textures or shapes, such as style-transferred version of clean data,\nsaturated images and patch-shuffled ones, and then evaluate the classification\naccuracy of AT-CNNs and normal CNNs on these datasets. Our findings shed some\nlight on why AT-CNNs are more robust than those normally trained ones and\ncontribute to a better understanding of adversarial training over CNNs from an\ninterpretation perspective.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:40:41 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhang", "Tianyuan", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1905.09803", "submitter": "Julius Berner", "authors": "Julius Berner, Dennis Elbr\\\"achter, Philipp Grohs", "title": "How degenerate is the parametrization of neural networks with the ReLU\n  activation function?", "comments": "Accepted at NeurIPS 2019", "journal-ref": "Advances in Neural Information Processing Systems 32, 2019, pp.\n  7790-7801", "doi": null, "report-no": null, "categories": "cs.LG math.FA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training is usually accomplished by solving a non-convex\noptimization problem using stochastic gradient descent. Although one optimizes\nover the networks parameters, the main loss function generally only depends on\nthe realization of the neural network, i.e. the function it computes. Studying\nthe optimization problem over the space of realizations opens up new ways to\nunderstand neural network training. In particular, usual loss functions like\nmean squared error and categorical cross entropy are convex on spaces of neural\nnetwork realizations, which themselves are non-convex. Approximation\ncapabilities of neural networks can be used to deal with the latter\nnon-convexity, which allows us to establish that for sufficiently large\nnetworks local minima of a regularized optimization problem on the realization\nspace are almost optimal. Note, however, that each realization has many\ndifferent, possibly degenerate, parametrizations. In particular, a local\nminimum in the parametrization space needs not correspond to a local minimum in\nthe realization space. To establish such a connection, inverse stability of the\nrealization map is required, meaning that proximity of realizations must imply\nproximity of corresponding parametrizations. We present pathologies which\nprevent inverse stability in general, and, for shallow networks, proceed to\nestablish a restricted space of parametrizations on which we have inverse\nstability w.r.t. to a Sobolev norm. Furthermore, we show that by optimizing\nover such restricted sets, it is still possible to learn any function which can\nbe learned by optimization over unrestricted sets.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:53:08 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:27:37 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Berner", "Julius", ""], ["Elbr\u00e4chter", "Dennis", ""], ["Grohs", "Philipp", ""]]}, {"id": "1905.09808", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Michael Chang, Grace Zhang, Pieter Abbeel, Sergey Levine", "title": "MCP: Learning Composable Hierarchical Control with Multiplicative\n  Compositional Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to perform a myriad of sophisticated tasks by drawing upon\nskills acquired through prior experience. For autonomous agents to have this\ncapability, they must be able to extract reusable skills from past experience\nthat can be recombined in new ways for subsequent tasks. Furthermore, when\ncontrolling complex high-dimensional morphologies, such as humanoid bodies,\ntasks often require coordination of multiple skills simultaneously. Learning\ndiscrete primitives for every combination of skills quickly becomes\nprohibitive. Composable primitives that can be recombined to create a large\nvariety of behaviors can be more suitable for modeling this combinatorial\nexplosion. In this work, we propose multiplicative compositional policies\n(MCP), a method for learning reusable motor skills that can be composed to\nproduce a range of complex behaviors. Our method factorizes an agent's skills\ninto a collection of primitives, where multiple primitives can be activated\nsimultaneously via multiplicative composition. This flexibility allows the\nprimitives to be transferred and recombined to elicit new behaviors as\nnecessary for novel tasks. We demonstrate that MCP is able to extract\ncomposable skills for highly complex simulated characters from pre-training\ntasks, such as motion imitation, and then reuse these skills to solve\nchallenging continuous control tasks, such as dribbling a soccer ball to a\ngoal, and picking up an object and transporting it to a target location.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:56:52 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Peng", "Xue Bin", ""], ["Chang", "Michael", ""], ["Zhang", "Grace", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1905.09820", "submitter": "Pawel Trajdos", "authors": "Pawel Trajdos, Marek Kurzynski", "title": "Randomized Reference Classifier with Gaussian Distribution and Soft\n  Confusion Matrix Applied to the Improving Weak Classifiers", "comments": "arXiv admin note: text overlap with arXiv:1901.08827", "journal-ref": null, "doi": "10.1007/978-3-030-19738-4_33", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an issue of building the RRC model using probability\ndistributions other than beta distribution is addressed. More precisely, in\nthis paper, we propose to build the RRR model using the truncated normal\ndistribution. Heuristic procedures for expected value and the variance of the\ntruncated-normal distribution are also proposed. The proposed approach is\ntested using SCM-based model for testing the consequences of applying the\ntruncated normal distribution in the RRC model. The experimental evaluation is\nperformed using four different base classifiers and seven quality measures. The\nresults showed that the proposed approach is comparable to the RRC model built\nusing beta distribution. What is more, for some base classifiers, the\ntruncated-normal-based SCM algorithm turned out to be better at discovering\nobjects coming from minority classes.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 05:34:21 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Trajdos", "Pawel", ""], ["Kurzynski", "Marek", ""]]}, {"id": "1905.09849", "submitter": "Enguerrand Horel", "authors": "Enguerrand Horel, Kay Giesecke", "title": "Computationally Efficient Feature Significance and Importance for\n  Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a simple and computationally efficient significance test for the\nfeatures of a machine learning model. Our forward-selection approach applies to\nany model specification, learning task and variable type. The test is\nnon-asymptotic, straightforward to implement, and does not require model\nrefitting. It identifies the statistically significant features as well as\nfeature interactions of any order in a hierarchical manner, and generates a\nmodel-free notion of feature importance. Experimental and empirical results\nillustrate its performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:09:56 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 23:30:06 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Horel", "Enguerrand", ""], ["Giesecke", "Kay", ""]]}, {"id": "1905.09855", "submitter": "Chen Tessler", "authors": "Chen Tessler, Guy Tennenholtz, Shie Mannor", "title": "Distributional Policy Optimization: An Alternative Approach for\n  Continuous Control", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a fundamental problem in policy gradient-based methods in\ncontinuous control. As policy gradient methods require the agent's underlying\nprobability distribution, they limit policy representation to parametric\ndistribution classes. We show that optimizing over such sets results in local\nmovement in the action space and thus convergence to sub-optimal solutions. We\nsuggest a novel distributional framework, able to represent arbitrary\ndistribution functions over the continuous action space. Using this framework,\nwe construct a generative scheme, trained using an off-policy actor-critic\nparadigm, which we call the Generative Actor Critic (GAC). Compared to policy\ngradient methods, GAC does not require knowledge of the underlying probability\ndistribution, thereby overcoming these limitations. Empirical evaluation shows\nthat our approach is comparable and often surpasses current state-of-the-art\nbaselines in continuous domains.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:22:06 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 13:26:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tessler", "Chen", ""], ["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.09856", "submitter": "Andriy Drozdyuk", "authors": "Vasileios Lioutas and Andriy Drozdyuk", "title": "Copy this Sentence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is an operation that selects some largest element from some set,\nwhere the notion of largest is defined elsewhere. Applying this operation to\nsequence to sequence mapping results in significant improvements to the task at\nhand. In this paper we provide the mathematical definition of attention and\nexamine its application to sequence to sequence models. We highlight the exact\ncorrespondences between machine learning implementations of attention and our\nmathematical definition. We provide clear evidence of effectiveness of\nattention mechanisms evaluating models with varying degrees of attention on a\nvery simple task: copying a sentence. We find that models that make greater use\nof attention perform much better on sequence to sequence mapping tasks,\nconverge faster and are more stable.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:25:35 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Drozdyuk", "Andriy", ""]]}, {"id": "1905.09863", "submitter": "Yulong Lu", "authors": "Yulong Lu, Jianfeng Lu, James Nolen", "title": "Accelerating Langevin Sampling with Birth-death", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in Bayesian inference and statistical machine learning\nis to efficiently sample from multimodal distributions. Due to metastability,\nmultimodal distributions are difficult to sample using standard Markov chain\nMonte Carlo methods. We propose a new sampling algorithm based on a birth-death\nmechanism to accelerate the mixing of Langevin diffusion. Our algorithm is\nmotivated by its mean field partial differential equation (PDE), which is a\nFokker-Planck equation supplemented by a nonlocal birth-death term. This PDE\ncan be viewed as a gradient flow of the Kullback-Leibler divergence with\nrespect to the Wasserstein-Fisher-Rao metric. We prove that under some\nassumptions the asymptotic convergence rate of the nonlocal PDE is independent\nof the potential barrier, in contrast to the exponential dependence in the case\nof the Langevin diffusion. We illustrate the efficiency of the birth-death\naccelerated Langevin method through several analytical examples and numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:39:26 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lu", "Yulong", ""], ["Lu", "Jianfeng", ""], ["Nolen", "James", ""]]}, {"id": "1905.09864", "submitter": "Varun Kumar", "authors": "Varun Kumar, Alison Smith-Renner, Leah Findlater, Kevin Seppi and\n  Jordan Boyd-Graber", "title": "Why Didn't You Listen to Me? Comparing User Control of Human-in-the-Loop\n  Topic Models", "comments": "In proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To address the lack of comparative evaluation of Human-in-the-Loop Topic\nModeling (HLTM) systems, we implement and evaluate three contrasting HLTM\nmodeling approaches using simulation experiments. These approaches extend\npreviously proposed frameworks, including constraints and informed prior-based\nmethods. Users should have a sense of control in HLTM systems, so we propose a\ncontrol metric to measure whether refinement operations' results match users'\nexpectations. Informed prior-based methods provide better control than\nconstraints, but constraints yield higher quality topics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:40:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:24:03 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kumar", "Varun", ""], ["Smith-Renner", "Alison", ""], ["Findlater", "Leah", ""], ["Seppi", "Kevin", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1905.09865", "submitter": "Long Ho", "authors": "Long V. Ho, Melissa D. Aczon, David Ledbetter, Randall Wetzel", "title": "Interpreting a Recurrent Neural Network's Predictions of ICU Mortality\n  Risk", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2021.103672", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning has demonstrated success in many applications; however, their\nuse in healthcare has been limited due to the lack of transparency into how\nthey generate predictions. Algorithms such as Recurrent Neural Networks (RNNs)\nwhen applied to Electronic Medical Records (EMR) introduce additional barriers\nto transparency because of the sequential processing of the RNN and the\nmulti-modal nature of EMR data. This work seeks to improve transparency by: 1)\nintroducing Learned Binary Masks (LBM) as a method for identifying which EMR\nvariables contributed to an RNN model's risk of mortality (ROM) predictions for\ncritically ill children; and 2) applying KernelSHAP for the same purpose. Given\nan individual patient, LBM and KernelSHAP both generate an attribution matrix\nthat shows the contribution of each input feature to the RNN's sequence of\npredictions for that patient. Attribution matrices can be aggregated in many\nways to facilitate different levels of analysis of the RNN model and its\npredictions. Presented are three methods of aggregations and analyses: 1) over\nvolatile time periods within individual patient predictions, 2) over\npopulations of ICU patients sharing specific diagnoses, and 3) across the\ngeneral population of critically ill children.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:41:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 22:21:17 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 22:06:12 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 19:38:02 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Ho", "Long V.", ""], ["Aczon", "Melissa D.", ""], ["Ledbetter", "David", ""], ["Wetzel", "Randall", ""]]}, {"id": "1905.09870", "submitter": "Atsushi Nitanda", "authors": "Atsushi Nitanda, Geoffrey Chinot, Taiji Suzuki", "title": "Gradient Descent can Learn Less Over-parameterized Two-layer Neural\n  Networks on Classification Problems", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have proven the global convergence and\ngeneralization abilities of the gradient descent method for two-layer ReLU\nnetworks. Most studies especially focused on the regression problems with the\nsquared loss function, except for a few, and the importance of the positivity\nof the neural tangent kernel has been pointed out. On the other hand, the\nperformance of gradient descent on classification problems using the logistic\nloss function has not been well studied, and further investigation of this\nproblem structure is possible. In this work, we demonstrate that the\nseparability assumption using a neural tangent model is more reasonable than\nthe positivity condition of the neural tangent kernel and provide a refined\nconvergence analysis of the gradient descent for two-layer networks with smooth\nactivations. A remarkable point of our result is that our convergence and\ngeneralization bounds have much better dependence on the network width in\ncomparison to related studies. Consequently, our theory provides a\ngeneralization guarantee for less over-parameterized two-layer networks, while\nmost studies require much higher over-parameterization.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:57:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 12:36:49 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 13:59:10 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Nitanda", "Atsushi", ""], ["Chinot", "Geoffrey", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1905.09871", "submitter": "Haidar Khan", "authors": "Haidar Khan, Daniel Park, Azer Khan, B\\\"ulent Yener", "title": "Thwarting finite difference adversarial attacks with output\n  randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples pose a threat to deep neural network models in a variety\nof scenarios, from settings where the adversary has complete knowledge of the\nmodel and to the opposite \"black box\" setting. Black box attacks are\nparticularly threatening as the adversary only needs access to the input and\noutput of the model. Defending against black box adversarial example generation\nattacks is paramount as currently proposed defenses are not effective. Since\nthese types of attacks rely on repeated queries to the model to estimate\ngradients over input dimensions, we investigate the use of randomization to\nthwart such adversaries from successfully creating adversarial examples.\nRandomization applied to the output of the deep neural network model has the\npotential to confuse potential attackers, however this introduces a tradeoff\nbetween accuracy and robustness. We show that for certain types of\nrandomization, we can bound the probability of introducing errors by carefully\nsetting distributional parameters. For the particular case of finite difference\nblack box attacks, we quantify the error introduced by the defense in the\nfinite difference estimate of the gradient. Lastly, we show empirically that\nthe defense can thwart two adaptive black box adversarial attack algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:58:39 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Khan", "Haidar", ""], ["Park", "Daniel", ""], ["Khan", "Azer", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1905.09872", "submitter": "Haizhao Yang", "authors": "Yunru Liu and Tingran Gao and Haizhao Yang", "title": "SelectNet: Learning to Sample from the Wild for Imbalanced Data Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning from training data with imbalanced class sizes, a\ncommonly encountered scenario in real applications such as anomaly/fraud\ndetection, has long been considered a significant challenge in machine\nlearning. Motivated by recent progress in curriculum and self-paced learning,\nwe propose to adopt a semi-supervised learning paradigm by training a deep\nneural network, referred to as SelectNet, to selectively add unlabelled data\ntogether with their predicted labels to the training dataset. Unlike existing\ntechniques designed to tackle the difficulty in dealing with class imbalanced\ntraining data such as resampling, cost-sensitive learning, and margin-based\nlearning, SelectNet provides an end-to-end approach for learning from important\nunlabelled data \"in the wild\" that most likely belong to the under-sampled\nclasses in the training data, thus gradually mitigates the imbalance in the\ndata used for training the classifier. We demonstrate the efficacy of SelectNet\nthrough extensive numerical experiments on standard datasets in computer\nvision.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:00:03 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Liu", "Yunru", ""], ["Gao", "Tingran", ""], ["Yang", "Haizhao", ""]]}, {"id": "1905.09874", "submitter": "Francois Belletti", "authors": "Francois Belletti, Karthik Lakshmanan, Walid Krichene, Nicolas\n  Mayoraz, Yi-Fan Chen, John Anderson, Taylor Robie, Tayo Oguntebi, Dan\n  Shirron, Amit Bleiwess", "title": "Scaling Up Collaborative Filtering Data Sets through Randomized Fractal\n  Expansions", "comments": "arXiv admin note: substantial text overlap with arXiv:1901.08910", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommender system research suffers from a disconnect between the size of\nacademic data sets and the scale of industrial production systems. In order to\nbridge that gap, we propose to generate large-scale user/item interaction data\nsets by expanding pre-existing public data sets. Our key contribution is a\ntechnique that expands user/item incidence matrices matrices to large numbers\nof rows (users), columns (items), and non-zero values (interactions). The\nproposed method adapts Kronecker Graph Theory to preserve key higher order\nstatistical properties such as the fat-tailed distribution of user engagements,\nitem popularity, and singular value spectra of user/item interaction matrices.\nPreserving such properties is key to building large realistic synthetic data\nsets which in turn can be employed reliably to benchmark recommender systems\nand the systems employed to train them. We further apply our stochastic\nexpansion algorithm to the binarized MovieLens 20M data set, which comprises\n20M interactions between 27K movies and 138K users. The resulting expanded data\nset has 1.2B ratings, 2.2M users, and 855K items, which can be scaled up or\ndown.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:56:38 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Belletti", "Francois", ""], ["Lakshmanan", "Karthik", ""], ["Krichene", "Walid", ""], ["Mayoraz", "Nicolas", ""], ["Chen", "Yi-Fan", ""], ["Anderson", "John", ""], ["Robie", "Taylor", ""], ["Oguntebi", "Tayo", ""], ["Shirron", "Dan", ""], ["Bleiwess", "Amit", ""]]}, {"id": "1905.09876", "submitter": "Haidar Khan", "authors": "Haidar Khan, Lara Marcuse, B\\\"ulent Yener", "title": "Deep density ratio estimation for change point detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose new objective functions to train deep neural network\nbased density ratio estimators and apply it to a change point detection\nproblem. Existing methods use linear combinations of kernels to approximate the\ndensity ratio function by solving a convex constrained minimization problem.\nApproximating the density ratio function using a deep neural network requires\ndefining a suitable objective function to optimize. We formulate and compare\nobjective functions that can be minimized using gradient descent and show that\nthe network can effectively learn to approximate the density ratio function.\nUsing our deep density ratio estimation objective function results in better\nperformance on a seizure detection task than other (kernel and neural network\nbased) density ratio estimation methods and other window-based change point\ndetection algorithms. We also show that the method can still support other\nneural network architectures, such as convolutional networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:04:56 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Khan", "Haidar", ""], ["Marcuse", "Lara", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1905.09877", "submitter": "Haizhao Yang", "authors": "Yong Zheng Ong and Charles K. Chui and Haizhao Yang", "title": "CASS: Cross Adversarial Source Separation via Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a cross adversarial source separation (CASS) framework\nvia autoencoder, a new model that aims at separating an input signal consisting\nof a mixture of multiple components into individual components defined via\nadversarial learning and autoencoder fitting. CASS unifies popular generative\nnetworks like auto-encoders (AEs) and generative adversarial networks (GANs) in\na single framework. The basic building block that filters the input signal and\nreconstructs the $i$-th target component is a pair of deep neural networks\n$\\mathcal{EN}_i$ and $\\mathcal{DE}_i$ as an encoder for dimension reduction and\na decoder for component reconstruction, respectively. The decoder\n$\\mathcal{DE}_i$ as a generator is enhanced by a discriminator network\n$\\mathcal{D}_i$ that favors signal structures of the $i$-th component in the\n$i$-th given dataset as guidance through adversarial learning. In contrast with\nexisting practices in AEs which trains each Auto-Encoder independently, or in\nGANs that share the same generator, we introduce cross adversarial training\nthat emphasizes adversarial relation between any arbitrary network pairs\n$(\\mathcal{DE}_i,\\mathcal{D}_j)$, achieving state-of-the-art performance\nespecially when target components share similar data structures.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:13:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ong", "Yong Zheng", ""], ["Chui", "Charles K.", ""], ["Yang", "Haizhao", ""]]}, {"id": "1905.09882", "submitter": "Cheolmin Kim", "authors": "Cheolmin Kim, Youngseok Kim, Diego Klabjan", "title": "Scale Invariant Power Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power iteration has been generalized to solve many interesting problems in\nmachine learning and statistics. Despite its striking success, theoretical\nunderstanding of when and how such an algorithm enjoys good convergence\nproperty is limited. In this work, we introduce a new class of optimization\nproblems called scale invariant problems and prove that they can be efficiently\nsolved by scale invariant power iteration (SCI-PI) with a generalized\nconvergence guarantee of power iteration. By deriving that a stationary point\nis an eigenvector of the Hessian evaluated at the point, we show that scale\ninvariant problems indeed resemble the leading eigenvector problem near a local\noptimum. Also, based on a novel reformulation, we geometrically derive SCI-PI\nwhich has a general form of power iteration. The convergence analysis shows\nthat SCI-PI attains local linear convergence with a rate being proportional to\nthe top two eigenvalues of the Hessian at the optimum. Moreover, we discuss\nsome extended settings of scale invariant problems and provide similar\nconvergence results for them. In numerical experiments, we introduce\napplications to independent component analysis, Gaussian mixtures, and\nnon-negative matrix factorization. Experimental results demonstrate that SCI-PI\nis competitive to state-of-the-art benchmark algorithms and often yield better\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:24:52 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 05:25:50 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kim", "Cheolmin", ""], ["Kim", "Youngseok", ""], ["Klabjan", "Diego", ""]]}, {"id": "1905.09883", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Maxim Raginsky", "title": "Neural Stochastic Differential Equations: Deep Latent Gaussian Models in\n  the Diffusion Limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep latent Gaussian models, the latent variable is generated by a\ntime-inhomogeneous Markov chain, where at each time step we pass the current\nstate through a parametric nonlinear map, such as a feedforward neural net, and\nadd a small independent Gaussian perturbation. This work considers the\ndiffusion limit of such models, where the number of layers tends to infinity,\nwhile the step size and the noise variance tend to zero. The limiting latent\nobject is an It\\^o diffusion process that solves a stochastic differential\nequation (SDE) whose drift and diffusion coefficient are implemented by neural\nnets. We develop a variational inference framework for these \\textit{neural\nSDEs} via stochastic automatic differentiation in Wiener space, where the\nvariational approximations to the posterior are obtained by Girsanov\n(mean-shift) transformation of the standard Wiener process and the computation\nof gradients is based on the theory of stochastic flows. This permits the use\nof black-box SDE solvers and automatic differentiation for end-to-end\ninference. Experimental results with synthetic data are provided.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:30:16 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:15:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tzen", "Belinda", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1905.09884", "submitter": "Armin Askari", "authors": "Armin Askari, Alexandre d'Aspremont, Laurent El Ghaoui", "title": "Naive Feature Selection: Sparsity in Naive Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its linear complexity, naive Bayes classification remains an\nattractive supervised learning method, especially in very large-scale settings.\nWe propose a sparse version of naive Bayes, which can be used for feature\nselection. This leads to a combinatorial maximum-likelihood problem, for which\nwe provide an exact solution in the case of binary data, or a bound in the\nmultinomial case. We prove that our bound becomes tight as the marginal\ncontribution of additional features decreases. Both binary and multinomial\nsparse models are solvable in time almost linear in problem size, representing\na very small extra relative cost compared to the classical naive Bayes.\nNumerical experiments on text data show that the naive Bayes feature selection\nmethod is as statistically effective as state-of-the-art feature selection\nmethods such as recursive feature elimination, $l_1$-penalized logistic\nregression and LASSO, while being orders of magnitude faster. For a large data\nset, having more than with $1.6$ million training points and about $12$ million\nfeatures, and with a non-optimized CPU implementation, our sparse naive Bayes\nmodel can be trained in less than 15 seconds.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:30:51 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 18:15:31 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Askari", "Armin", ""], ["d'Aspremont", "Alexandre", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "1905.09885", "submitter": "Omar Mahmood", "authors": "Omar Mahmood, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "A COLD Approach to Generating Optimal Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimising discrete data for a desired characteristic using gradient-based\nmethods involves projecting the data into a continuous latent space and\ncarrying out optimisation in this space. Carrying out global optimisation is\ndifficult as optimisers are likely to follow gradients into regions of the\nlatent space that the model has not been exposed to during training; samples\ngenerated from these regions are likely to be too dissimilar to the training\ndata to be useful. We propose Constrained Optimisation with Latent\nDistributions (COLD), a constrained global optimisation procedure to find\nsamples with high values of a desired property that are similar to yet distinct\nfrom the training data. We find that on MNIST, our procedure yields optima for\neach of three different objectives, and that enforcing tighter constraints\nimproves the quality and increases the diversity of the generated images. On\nthe ChEMBL molecular dataset, our method generates a diverse set of new\nmolecules with drug-likeness scores similar to those of the highest-scoring\nmolecules in the training data. We also demonstrate a computationally efficient\nway to approximate the constraint when evaluating it exactly is computationally\nexpensive.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:32:03 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Mahmood", "Omar", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1905.09888", "submitter": "Farzad Khalvati", "authors": "Yucheng Zhang, Edrise M. Lobo-Mueller, Paul Karanicolas, Steven\n  Gallinger, Masoom A. Haider, Farzad Khalvati", "title": "Prognostic Value of Transfer Learning Based Features in Resectable\n  Pancreatic Ductal Adenocarcinoma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pancreatic Ductal Adenocarcinoma (PDAC) is one of the most aggressive cancers\nwith an extremely poor prognosis. Radiomics has shown prognostic ability in\nmultiple types of cancer including PDAC. However, the prognostic value of\ntraditional radiomics pipelines, which are based on hand-crafted radiomic\nfeatures alone is limited. Convolutional neural networks (CNNs) have been shown\nto outperform these feature-based models in computer vision tasks. However,\ntraining a CNN from scratch needs a large sample size which is not feasible in\nmost medical imaging studies. As an alternative solution, CNN-based transfer\nlearning has shown potential for achieving reasonable performance using small\ndatasets. In this work, we developed and validated a CNN-based transfer\nlearning approach for prognostication of PDAC patients for overall survival\nusing two independent resectable PDAC cohorts. The proposed deep transfer\nlearning model for prognostication of PDAC achieved the area under the receiver\noperating characteristic curve of 0.74, which was significantly higher than\nthat of the traditional radiomics model (0.56) as well as a CNN model trained\nfrom scratch (0.50). These results suggest that deep transfer learning may\nsignificantly improve prognosis performance using small datasets in medical\nimaging.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:35:41 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 15:16:00 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Zhang", "Yucheng", ""], ["Lobo-Mueller", "Edrise M.", ""], ["Karanicolas", "Paul", ""], ["Gallinger", "Steven", ""], ["Haider", "Masoom A.", ""], ["Khalvati", "Farzad", ""]]}, {"id": "1905.09889", "submitter": "Yunchuan Kong", "authors": "Yunchuan Kong and Tianwei Yu", "title": "forgeNet: A graph deep neural network model using tree-based ensemble\n  classifiers for feature extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unique challenge in predictive model building for omics data has been the\nsmall number of samples $(n)$ versus the large amount of features $(p)$. This\n\"$n\\ll p$\" property brings difficulties for disease outcome classification\nusing deep learning techniques. Sparse learning by incorporating external gene\nnetwork information such as the graph-embedded deep feedforward network (GEDFN)\nmodel has been a solution to this issue. However, such methods require an\nexisting feature graph, and potential mis-specification of the feature graph\ncan be harmful on classification and feature selection. To address this\nlimitation and develop a robust classification model without relying on\nexternal knowledge, we propose a \\underline{for}est\n\\underline{g}raph-\\underline{e}mbedded deep feedforward \\underline{net}work\n(forgeNet) model, to integrate the GEDFN architecture with a forest feature\ngraph extractor, so that the feature graph can be learned in a supervised\nmanner and specifically constructed for a given prediction task. To validate\nthe method's capability, we experimented the forgeNet model with both synthetic\nand real datasets. The resulting high classification accuracy suggests that the\nmethod is a valuable addition to sparse deep learning models for omics data.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:37:30 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Kong", "Yunchuan", ""], ["Yu", "Tianwei", ""]]}, {"id": "1905.09892", "submitter": "Phil Breen", "authors": "Philip G. Breen, Christopher N. Foley", "title": "A Bulirsch-Stoer algorithm using Gaussian processes", "comments": "comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we treat the problem of evaluating the asymptotic error in a\nnumerical integration scheme as one with inherent uncertainty. Adding to the\ngrowing field of probabilistic numerics, we show that Gaussian process\nregression (GPR) can be embedded into a numerical integration scheme to allow\nfor (i) robust selection of the adaptive step-size parameter and; (ii)\nuncertainty quantification in predictions of putatively converged numerical\nsolutions. We present two examples of our approach using Richardson's\nextrapolation technique and the Bulirsch-Stoer algorithm. In scenarios where\nthe error-surface is smooth and bounded, our proposed approach can match the\nresults of the traditional polynomial (parametric) extrapolation methods. In\nscenarios where the error surface is not well approximated by a finite-order\npolynomial, e.g. in the vicinity of a pole or in the assessment of a chaotic\nsystem, traditional methods can fail, however, the non-parametric GPR approach\ndemonstrates the potential to continue to furnish reasonable solutions in these\nsituations.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:44:59 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Breen", "Philip G.", ""], ["Foley", "Christopher N.", ""]]}, {"id": "1905.09894", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Radu State, Jean Hilger", "title": "PHom-GeM: Persistent Homology for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative neural network models, including Generative Adversarial Network\n(GAN) and Auto-Encoders (AE), are among the most popular neural network models\nto generate adversarial data. The GAN model is composed of a generator that\nproduces synthetic data and of a discriminator that discriminates between the\ngenerator's output and the true data. AE consist of an encoder which maps the\nmodel distribution to a latent manifold and of a decoder which maps the latent\nmanifold to a reconstructed distribution. However, generative models are known\nto provoke chaotically scattered reconstructed distribution during their\ntraining, and consequently, incomplete generated adversarial distributions.\nCurrent distance measures fail to address this problem because they are not\nable to acknowledge the shape of the data manifold, i.e. its topological\nfeatures, and the scale at which the manifold should be analyzed. We propose\nPersistent Homology for Generative Models, PHom-GeM, a new methodology to\nassess and measure the distribution of a generative model. PHom-GeM minimizes\nan objective function between the true and the reconstructed distributions and\nuses persistent homology, the study of the topological features of a space at\ndifferent spatial resolutions, to compare the nature of the true and the\ngenerated distributions. Our experiments underline the potential of persistent\nhomology for Wasserstein GAN in comparison to Wasserstein AE and Variational\nAE. The experiments are conducted on a real-world data set particularly\nchallenging for traditional distance measures and generative neural network\nmodels. PHom-GeM is the first methodology to propose a topological distance\nmeasure, the bottleneck distance, for generative models used to compare\nadversarial samples in the context of credit card transactions.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:48:29 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Charlier", "Jeremy", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.09897", "submitter": "Holden Lee", "authors": "Holden Lee, Cyril Zhang", "title": "Robust guarantees for learning an autoregressive filter", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal predictor for a linear dynamical system (with hidden state and\nGaussian noise) takes the form of an autoregressive linear filter, namely the\nKalman filter. However, a fundamental problem in reinforcement learning and\ncontrol theory is to make optimal predictions in an unknown dynamical system.\nTo this end, we take the approach of directly learning an autoregressive filter\nfor time-series prediction under unknown dynamics. Our analysis differs from\nprevious statistical analyses in that we regress not only on the inputs to the\ndynamical system, but also the outputs, which is essential to dealing with\nprocess noise. The main challenge is to estimate the filter under worst case\ninput (in $\\mathcal H_\\infty$ norm), for which we use an $L^\\infty$-based\nobjective rather than ordinary least-squares. For learning an autoregressive\nmodel, our algorithm has optimal sample complexity in terms of the rollout\nlength, which does not seem to be attained by naive least-squares.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:59:17 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lee", "Holden", ""], ["Zhang", "Cyril", ""]]}, {"id": "1905.09898", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Eva Tardos, Drishti Wali", "title": "Feedback graph regret bounds for Thompson Sampling and UCB", "comments": "Appeared in ALT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic multi-armed bandit problem with the graph-based\nfeedback structure introduced by Mannor and Shamir. We analyze the performance\nof the two most prominent stochastic bandit algorithms, Thompson Sampling and\nUpper Confidence Bound (UCB), in the graph-based feedback setting. We show that\nthese algorithms achieve regret guarantees that combine the graph structure and\nthe gaps between the means of the arm distributions. Surprisingly this holds\ndespite the fact that these algorithms do not explicitly use the graph\nstructure to select arms; they observe the additional feedback but do not\nexplore based on it. Towards this result we introduce a \"layering technique\"\nhighlighting the commonalities in the two algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:05:06 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 23:02:41 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 05:02:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Tardos", "Eva", ""], ["Wali", "Drishti", ""]]}, {"id": "1905.09899", "submitter": "Shuai Zheng", "authors": "Shuai Zheng and James T. Kwok", "title": "Blockwise Adaptivity: Faster Training and Better Generalization in Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic methods with coordinate-wise adaptive stepsize (such as RMSprop\nand Adam) have been widely used in training deep neural networks. Despite their\nfast convergence, they can generalize worse than stochastic gradient descent.\nIn this paper, by revisiting the design of Adagrad, we propose to split the\nnetwork parameters into blocks, and use a blockwise adaptive stepsize.\nIntuitively, blockwise adaptivity is less aggressive than adaptivity to\nindividual coordinates, and can have a better balance between adaptivity and\ngeneralization. We show theoretically that the proposed blockwise adaptive\ngradient descent has comparable convergence rate as its counterpart with\ncoordinate-wise adaptive stepsize, but is faster up to some constant. We also\nstudy its uniform stability and show that blockwise adaptivity can lead to\nlower generalization error than coordinate-wise adaptivity. Experimental\nresults show that blockwise adaptive gradient descent converges faster and\nimproves generalization performance over Nesterov's accelerated gradient and\nAdam.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:06:10 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zheng", "Shuai", ""], ["Kwok", "James T.", ""]]}, {"id": "1905.09902", "submitter": "Leonard Wossnig", "authors": "Nathan Wiebe and Leonard Wossnig", "title": "Generative training of quantum Boltzmann machines with hidden units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we provide a method for fully quantum generative training of\nquantum Boltzmann machines with both visible and hidden units while using\nquantum relative entropy as an objective. This is significant because prior\nmethods were not able to do so due to mathematical challenges posed by the\ngradient evaluation. We present two novel methods for solving this problem. The\nfirst proposal addresses it, for a class of restricted quantum Boltzmann\nmachines with mutually commuting Hamiltonians on the hidden units, by using a\nvariational upper bound on the quantum relative entropy. The second one uses\nhigh-order divided difference methods and linear-combinations of unitaries to\napproximate the exact gradient of the relative entropy for a generic quantum\nBoltzmann machine. Both methods are efficient under the assumption that Gibbs\nstate preparation is efficient and that the Hamiltonian are given by a sparse\nrow-computable matrix.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:10:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Wiebe", "Nathan", ""], ["Wossnig", "Leonard", ""]]}, {"id": "1905.09904", "submitter": "Zheng Shou", "authors": "Jiawei Ma, Zheng Shou, Alireza Zareian, Hassan Mansour, Anthony Vetro,\n  Shih-Fu Chang", "title": "CDSA: Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time\n  Series Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve multivariate, geo-tagged time series\ndata: at each location, multiple sensors record corresponding measurements. For\nexample, air quality monitoring system records PM2.5, CO, etc. The resulting\ntime-series data often has missing values due to device outages or\ncommunication errors. In order to impute the missing values, state-of-the-art\nmethods are built on Recurrent Neural Networks (RNN), which process each time\nstamp sequentially, prohibiting the direct modeling of the relationship between\ndistant time stamps. Recently, the self-attention mechanism has been proposed\nfor sequence modeling tasks such as machine translation, significantly\noutperforming RNN because the relationship between each two time stamps can be\nmodeled explicitly. In this paper, we are the first to adapt the self-attention\nmechanism for multivariate, geo-tagged time series data. In order to jointly\ncapture the self-attention across multiple dimensions, including time, location\nand the sensor measurements, while maintain low computational complexity, we\npropose a novel approach called Cross-Dimensional Self-Attention (CDSA) to\nprocess each dimension sequentially, yet in an order-independent manner. Our\nextensive experiments on four real-world datasets, including three standard\nbenchmarks and our newly collected NYC-traffic dataset, demonstrate that our\napproach outperforms the state-of-the-art imputation and forecasting methods. A\ndetailed systematic analysis confirms the effectiveness of our design choices.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:13:12 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 06:15:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Ma", "Jiawei", ""], ["Shou", "Zheng", ""], ["Zareian", "Alireza", ""], ["Mansour", "Hassan", ""], ["Vetro", "Anthony", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1905.09905", "submitter": "Niall Twomey", "authors": "Niall Twomey, Micha{\\l} Koz{\\l}owski, Ra\\'ul Santos-Rodr\\'iguez", "title": "Neural ODEs with stochastic vector field mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It was recently shown that neural ordinary differential equation models\ncannot solve fundamental and seemingly straightforward tasks even with\nhigh-capacity vector field representations. This paper introduces two other\nfundamental tasks to the set that baseline methods cannot solve, and proposes\nmixtures of stochastic vector fields as a model class that is capable of\nsolving these essential problems. Dynamic vector field selection is of critical\nimportance for our model, and our approach is to propagate component\nuncertainty over the integration interval with a technique based on forward\nfiltering. We also formalise several loss functions that encourage desirable\nproperties on the trajectory paths, and of particular interest are those that\ndirectly encourage fewer expected function evaluations. Experimentally, we\ndemonstrate that our model class is capable of capturing the natural dynamics\nof human behaviour; a notoriously volatile application area. Baseline\napproaches cannot adequately model this problem.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:14:39 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Twomey", "Niall", ""], ["Koz\u0142owski", "Micha\u0142", ""], ["Santos-Rodr\u00edguez", "Ra\u00fal", ""]]}, {"id": "1905.09906", "submitter": "Zhenyu Shou", "authors": "Zhenyu Shou, Xuan Di, Jieping Ye, Hongtu Zhu, Hua Zhang, Robert\n  Hampshire", "title": "Optimal Passenger-Seeking Policies on E-hailing Platforms Using Markov\n  Decision Process and Imitation Learning", "comments": "23 pages, 16 figures, published in Transportation Research Part C 111\n  (2020) 91-113", "journal-ref": "Transportation Research Part C 111 (2020) 91-113", "doi": "10.1016/j.trc.2019.12.005", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vacant taxi drivers' passenger seeking process in a road network generates\nadditional vehicle miles traveled, adding congestion and pollution into the\nroad network and the environment. This paper aims to employ a Markov Decision\nProcess (MDP) to model idle e-hailing drivers' optimal sequential decisions in\npassenger-seeking. Transportation network companies (TNC) or e-hailing (e.g.,\nDidi, Uber) drivers exhibit different behaviors from traditional taxi drivers\nbecause e-hailing drivers do not need to actually search for passengers.\nInstead, they reposition themselves so that the matching platform can match a\npassenger. Accordingly, we incorporate e-hailing drivers' new features into our\nMDP model. The reward function used in the MDP model is uncovered by leveraging\nan inverse reinforcement learning technique. We then use 44,160 Didi drivers'\n3-day trajectories to train the model. To validate the effectiveness of the\nmodel, a Monte Carlo simulation is conducted to simulate the performance of\ndrivers under the guidance of the optimal policy, which is then compared with\nthe performance of drivers following one baseline heuristic, namely, the local\nhotspot strategy. The results show that our model is able to achieve a 17.5%\nimprovement over the local hotspot strategy in terms of the rate of return. The\nproposed MDP model captures the supply-demand ratio considering the fact that\nthe number of drivers in this study is sufficiently large and thus the number\nof unmatched orders is assumed to be negligible. To better incorporate the\ncompetition among multiple drivers into the model, we have also devised and\ncalibrated a dynamic adjustment strategy of the order matching probability.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:24:29 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 06:44:30 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:51:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shou", "Zhenyu", ""], ["Di", "Xuan", ""], ["Ye", "Jieping", ""], ["Zhu", "Hongtu", ""], ["Zhang", "Hua", ""], ["Hampshire", "Robert", ""]]}, {"id": "1905.09916", "submitter": "Ali Malik", "authors": "Ali Malik, Mike Wu, Vrinda Vasavada, Jinpeng Song, Madison Coots, John\n  Mitchell, Noah Goodman, Chris Piech", "title": "Generative Grading: Near Human-level Accuracy for Automated Feedback on\n  Richly Structured Problems", "comments": "10 pages of content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to high-quality education at scale is limited by the difficulty of\nproviding student feedback on open-ended assignments in structured domains like\ncomputer programming, graphics, and short response questions. This problem has\nproven to be exceptionally difficult: for humans, it requires large amounts of\nmanual work, and for computers, until recently, achieving anything near\nhuman-level accuracy has been unattainable. In this paper, we present\ngenerative grading: a novel computational approach for providing feedback at\nscale that is capable of accurately grading student work and providing nuanced,\ninterpretable feedback. Our approach uses generative descriptions of student\ncognition, written as probabilistic programs, to synthesise millions of\nlabelled example solutions to a problem; we then learn to infer feedback for\nreal student solutions based on this cognitive model.\n  We apply our methods to three settings. In block-based coding, we achieve a\n50% improvement upon the previous best results for feedback, achieving\nsuper-human accuracy. In two other widely different domains -- graphical tasks\nand short text answers -- we achieve major improvement over the previous state\nof the art by about 4x and 1.5x respectively, approaching human accuracy. In a\nreal classroom, we ran an experiment where we used our system to augment human\ngraders, yielding doubled grading accuracy while halving grading time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:47:22 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 08:39:18 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 05:38:42 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 20:08:08 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 18:07:20 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Malik", "Ali", ""], ["Wu", "Mike", ""], ["Vasavada", "Vrinda", ""], ["Song", "Jinpeng", ""], ["Coots", "Madison", ""], ["Mitchell", "John", ""], ["Goodman", "Noah", ""], ["Piech", "Chris", ""]]}, {"id": "1905.09917", "submitter": "Zheyang Shen", "authors": "Zheyang Shen, Markus Heinonen, Samuel Kaski", "title": "Learning spectrograms with convolutional spectral kernels", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the convolutional spectral kernel (CSK), a novel family of\nnon-stationary, nonparametric covariance kernels for Gaussian process (GP)\nmodels, derived from the convolution between two imaginary radial basis\nfunctions. We present a principled framework to interpret CSK, as well as other\ndeep probabilistic models, using approximated Fourier transform, yielding a\nconcise representation of input-frequency spectrogram. Observing through the\nlens of the spectrogram, we provide insight on the interpretability of deep\nmodels. We then infer the functional hyperparameters using scalable variational\nand MCMC methods. On small- and medium-sized spatiotemporal datasets, we\ndemonstrate improved generalization of GP models when equipped with CSK, and\ntheir capability to extract non-stationary periodic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:49:26 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:58:17 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Shen", "Zheyang", ""], ["Heinonen", "Markus", ""], ["Kaski", "Samuel", ""]]}, {"id": "1905.09922", "submitter": "Mihaela Rosca", "authors": "Cyprien de Masson d'Autume, Mihaela Rosca, Jack Rae and Shakir Mohamed", "title": "Training language GANs from Scratch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) enjoy great success at image\ngeneration, but have proven difficult to train in the domain of natural\nlanguage. Challenges with gradient estimation, optimization instability, and\nmode collapse have lead practitioners to resort to maximum likelihood\npre-training, followed by small amounts of adversarial fine-tuning. The\nbenefits of GAN fine-tuning for language generation are unclear, as the\nresulting models produce comparable or worse samples than traditional language\nmodels. We show it is in fact possible to train a language GAN from scratch --\nwithout maximum likelihood pre-training. We combine existing techniques such as\nlarge batch sizes, dense rewards and discriminator regularization to stabilize\nand improve language GANs. The resulting model, ScratchGAN, performs comparably\nto maximum likelihood training on EMNLP2017 News and WikiText-103 corpora\naccording to quality and diversity metrics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:01:24 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:43:40 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["d'Autume", "Cyprien de Masson", ""], ["Rosca", "Mihaela", ""], ["Rae", "Jack", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1905.09943", "submitter": "Alvaro Henrique Chaim Correia", "authors": "Alvaro H. C. Correia, James Cussens, Cassio de Campos", "title": "On Pruning for Score-Based Bayesian Network Structure Learning", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020), in PMLR 108:2709-2718", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many algorithms for score-based Bayesian network structure learning (BNSL),\nin particular exact ones, take as input a collection of potentially optimal\nparent sets for each variable in the data. Constructing such collections\nnaively is computationally intensive since the number of parent sets grows\nexponentially with the number of variables. Thus, pruning techniques are not\nonly desirable but essential. While good pruning rules exist for the Bayesian\nInformation Criterion (BIC), current results for the Bayesian Dirichlet\nequivalent uniform (BDeu) score reduce the search space very modestly,\nhampering the use of the (often preferred) BDeu. We derive new non-trivial\ntheoretical upper bounds for the BDeu score that considerably improve on the\nstate-of-the-art. Since the new bounds are mathematically proven to be tighter\nthan previous ones and at little extra computational cost, they are a promising\naddition to BNSL methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:45:27 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:03:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Correia", "Alvaro H. C.", ""], ["Cussens", "James", ""], ["de Campos", "Cassio", ""]]}, {"id": "1905.09944", "submitter": "David Clark", "authors": "David G. Clark, Jesse A. Livezey, Kristofer E. Bouchard", "title": "Unsupervised Discovery of Temporal Structure in Noisy Data with\n  Dynamical Components Analysis", "comments": "22 pages, 10 figures; updated appendix with additional analyses", "journal-ref": "NeurIPS 14267-14278 (2019)", "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear dimensionality reduction methods are commonly used to extract\nlow-dimensional structure from high-dimensional data. However, popular methods\ndisregard temporal structure, rendering them prone to extracting noise rather\nthan meaningful dynamics when applied to time series data. At the same time,\nmany successful unsupervised learning methods for temporal, sequential and\nspatial data extract features which are predictive of their surrounding\ncontext. Combining these approaches, we introduce Dynamical Components Analysis\n(DCA), a linear dimensionality reduction method which discovers a subspace of\nhigh-dimensional time series data with maximal predictive information, defined\nas the mutual information between the past and future. We test DCA on synthetic\nexamples and demonstrate its superior ability to extract dynamical structure\ncompared to commonly used linear methods. We also apply DCA to several\nreal-world datasets, showing that the dimensions extracted by DCA are more\nuseful than those extracted by other methods for predicting future states and\ndecoding auxiliary variables. Overall, DCA robustly extracts dynamical\nstructure in noisy, high-dimensional data while retaining the computational\nefficiency and geometric interpretability of linear dimensionality reduction\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:47:56 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 23:28:52 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Clark", "David G.", ""], ["Livezey", "Jesse A.", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "1905.09950", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, James L. McClelland", "title": "Zero-shot task adaptation by homoiconic meta-mapping", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can deep learning systems flexibly reuse their knowledge? Toward this\ngoal, we propose a new class of challenges, and a class of architectures that\ncan solve them. The challenges are meta-mappings, which involve systematically\ntransforming task behaviors to adapt to new tasks zero-shot. The key to\nachieving these challenges is representing the task being performed in such a\nway that this task representation is itself transformable. We therefore draw\ninspiration from functional programming and recent work in meta-learning to\npropose a class of Homoiconic Meta-Mapping (HoMM) approaches that represent\ndata points and tasks in a shared latent space, and learn to infer\ntransformations of that space. HoMM approaches can be applied to any type of\nmachine learning task. We demonstrate the utility of this perspective by\nexhibiting zero-shot remapping of behavior to adapt to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:05:32 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 11:02:03 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 18:09:57 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 22:40:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "1905.09951", "submitter": "Or Raveh", "authors": "Or Raveh, Ron Meir", "title": "PAC Guarantees for Cooperative Multi-Agent Reinforcement Learning with\n  Restricted Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We develop model free PAC performance guarantees for multiple concurrent\nMDPs, extending recent works where a single learner interacts with multiple\nnon-interacting agents in a noise free environment. Our framework allows noisy\nand resource limited communication between agents, and develops novel PAC\nguarantees in this extended setting. By allowing communication between the\nagents themselves, we suggest improved PAC-exploration algorithms that can\novercome the communication noise and lead to improved sample complexity bounds.\nWe provide a theoretically motivated algorithm that optimally combines\ninformation from the resource limited agents, thereby analyzing the interaction\nbetween noise and communication constraints that are ubiquitous in real-world\nsystems. We present empirical results for a simple task that supports our\ntheoretical formulations and improve upon naive information fusion methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:07:10 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 07:57:07 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Raveh", "Or", ""], ["Meir", "Ron", ""]]}, {"id": "1905.09952", "submitter": "Wenshuo Guo", "authors": "Wenshuo Guo, Nhat Ho, Michael I. Jordan", "title": "Fast Algorithms for Computational Optimal Transport and Wasserstein\n  Barycenter", "comments": "18 pages, 35 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide theoretical complexity analysis for new algorithms to compute the\noptimal transport (OT) distance between two discrete probability distributions,\nand demonstrate their favorable practical performance over state-of-art\nprimal-dual algorithms and their capability in solving other problems in\nlarge-scale, such as the Wasserstein barycenter problem for multiple\nprobability distributions. First, we introduce the \\emph{accelerated\nprimal-dual randomized coordinate descent} (APDRCD) algorithm for computing the\nOT distance. We provide its complexity upper bound\n$\\bigOtil(\\frac{n^{5/2}}{\\varepsilon})$ where $n$ stands for the number of\natoms of these probability measures and $\\varepsilon > 0$ is the desired\naccuracy. This complexity bound matches the best known complexities of\nprimal-dual algorithms for the OT problems, including the adaptive primal-dual\naccelerated gradient descent (APDAGD) and the adaptive primal-dual accelerated\nmirror descent (APDAMD) algorithms. Then, we demonstrate the better performance\nof the APDRCD algorithm over the APDAGD and APDAMD algorithms through extensive\nexperimental studies, and further improve its practical performance by\nproposing a greedy version of it, which we refer to as \\emph{accelerated\nprimal-dual greedy coordinate descent} (APDGCD). Finally, we generalize the\nAPDRCD and APDGCD algorithms to distributed algorithms for computing the\nWasserstein barycenter for multiple probability distributions.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:13:27 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 01:57:16 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 10:50:02 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 06:00:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Guo", "Wenshuo", ""], ["Ho", "Nhat", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1905.09957", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha", "title": "Robust Attribution Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging problem in trustworthy machine learning is to train models that\nproduce robust interpretations for their predictions. We take a step towards\nsolving this problem through the lens of axiomatic attribution of neural\nnetworks. Our theory is grounded in the recent work, Integrated Gradients (IG),\nin axiomatically attributing a neural network's output change to its input\nchange. We propose training objectives in classic robust optimization models to\nachieve robust IG attributions. Our objectives give principled generalizations\nof previous objectives designed for robust predictions, and they naturally\ndegenerate to classic soft-margin training for one-layer neural networks. We\nalso generalize previous theory and prove that the objectives for different\nrobust optimization models are closely related. Experiments demonstrate the\neffectiveness of our method, and also point to intriguing problems which hint\nat the need for better optimization techniques or better neural network\narchitectures for robust attribution training.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:35:41 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:04:59 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 20:19:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chen", "Jiefeng", ""], ["Wu", "Xi", ""], ["Rastogi", "Vaibhav", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "1905.09959", "submitter": "Chiao-Yu Yang", "authors": "Chiao-Yu Yang, Eric Xia, Nhat Ho, Michael I. Jordan", "title": "Posterior Distribution for the Number of Clusters in Dirichlet Process\n  Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dirichlet process mixture models (DPMM) play a central role in Bayesian\nnonparametrics, with applications throughout statistics and machine learning.\nDPMMs are generally used in clustering problems where the number of clusters is\nnot known in advance, and the posterior distribution is treated as providing\ninference for this number. Recently, however, it has been shown that the DPMM\nis inconsistent in inferring the true number of components in certain cases.\nThis is an asymptotic result, and it would be desirable to understand whether\nit holds with finite samples, and to more fully understand the full posterior.\nIn this work, we provide a rigorous study for the posterior distribution of the\nnumber of clusters in DPMM under different prior distributions on the\nparameters and constraints on the distributions of the data. We provide novel\nlower bounds on the ratios of probabilities between $s+1$ clusters and $s$\nclusters when the prior distributions on parameters are chosen to be Gaussian\nor uniform distributions.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:51:15 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 00:17:53 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Chiao-Yu", ""], ["Xia", "Eric", ""], ["Ho", "Nhat", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1905.09961", "submitter": "Anand Joshi", "authors": "Haleh Akrami, Anand A. Joshi, Jian Li, Sergul Aydore, and Richard M.\n  Leahy", "title": "Robust Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods often need a large amount of labeled training data.\nSince the training data is assumed to be the ground truth, outliers can\nseverely degrade learned representations and performance of trained models.\nHere we apply concepts from robust statistics to derive a novel variational\nautoencoder that is robust to outliers in the training data. Variational\nautoencoders (VAEs) extract a lower-dimensional encoded feature representation\nfrom which we can generate new data samples. Robustness of autoencoders to\noutliers is critical for generating a reliable representation of particular\ndata types in the encoded space when using corrupted training data. Our robust\nVAE is based on beta-divergence rather than the standard Kullback-Leibler (KL)\ndivergence. Our proposed lower bound lead to a RVAE model that has the same\ncomputational complexity as the VAE and contains a single tuning parameter to\ncontrol the degree of robustness. We demonstrate the performance of our\n$\\beta$-divergence based autoencoder for a range of image datasets, showing\nimproved robustness to outliers both qualitatively and quantitatively. We also\nillustrate the use of our robust VAE for outlier detection.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:58:14 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 22:04:28 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Akrami", "Haleh", ""], ["Joshi", "Anand A.", ""], ["Li", "Jian", ""], ["Aydore", "Sergul", ""], ["Leahy", "Richard M.", ""]]}, {"id": "1905.09970", "submitter": "Vlad Paunescu", "authors": "Andretti Naiden, Vlad Paunescu, Gyeongmo Kim, ByeongMoon Jeon, Marius\n  Leordeanu", "title": "Shift R-CNN: Deep Monocular 3D Object Detection with Closed-Form\n  Geometric Constraints", "comments": "v1: Accepted to be published in 2019 IEEE International Conference on\n  Image Processing, Sep 22-25, 2019, Taipei. IEEE Copyright notice added. Minor\n  changes for camera-ready version. (updated May. 15, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Shift R-CNN, a hybrid model for monocular 3D object detection,\nwhich combines deep learning with the power of geometry. We adapt a Faster\nR-CNN network for regressing initial 2D and 3D object properties and combine it\nwith a least squares solution for the inverse 2D to 3D geometric mapping\nproblem, using the camera projection matrix. The closed-form solution of the\nmathematical system, along with the initial output of the adapted Faster R-CNN\nare then passed through a final ShiftNet network that refines the result using\nour newly proposed Volume Displacement Loss. Our novel, geometrically\nconstrained deep learning approach to monocular 3D object detection obtains top\nresults on KITTI 3D Object Detection Benchmark, being the best among all\nmonocular methods that do not use any pre-trained network for depth estimation.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 23:41:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Naiden", "Andretti", ""], ["Paunescu", "Vlad", ""], ["Kim", "Gyeongmo", ""], ["Jeon", "ByeongMoon", ""], ["Leordeanu", "Marius", ""]]}, {"id": "1905.09972", "submitter": "Adel Abusitta", "authors": "Adel Abusitta, Esma A\\\"imeur, Omar Abdel Wahab", "title": "Generative Adversarial Networks for Mitigating Biases in Machine\n  Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new framework for mitigating biases in machine\nlearning systems. The problem of the existing mitigation approaches is that\nthey are model-oriented in the sense that they focus on tuning the training\nalgorithms to produce fair results, while overlooking the fact that the\ntraining data can itself be the main reason for biased outcomes. Technically\nspeaking, two essential limitations can be found in such model-based\napproaches: 1) the mitigation cannot be achieved without degrading the accuracy\nof the machine learning models, and 2) when the data used for training are\nlargely biased, the training time automatically increases so as to find\nsuitable learning parameters that help produce fair results. To address these\nshortcomings, we propose in this work a new framework that can largely mitigate\nthe biases and discriminations in machine learning systems while at the same\ntime enhancing the prediction accuracy of these systems. The proposed framework\nis based on conditional Generative Adversarial Networks (cGANs), which are used\nto generate new synthetic fair data with selective properties from the original\ndata. We also propose a framework for analyzing data biases, which is important\nfor understanding the amount and type of data that need to be synthetically\nsampled and labeled for each population group. Experimental results show that\nthe proposed solution can efficiently mitigate different types of biases, while\nat the same time enhancing the prediction accuracy of the underlying machine\nlearning model.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 23:49:19 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Abusitta", "Adel", ""], ["A\u00efmeur", "Esma", ""], ["Wahab", "Omar Abdel", ""]]}, {"id": "1905.09982", "submitter": "Tetsuya Sato", "authors": "Borja Balle, Gilles Barthe, Marco Gaboardi, Justin Hsu and Tetsuya\n  Sato", "title": "Hypothesis Testing Interpretations and Renyi Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a de facto standard in data privacy, with\napplications in the public and private sectors. A way to explain differential\nprivacy, which is particularly appealing to statistician and social scientists\nis by means of its statistical hypothesis testing interpretation. Informally,\none cannot effectively test whether a specific individual has contributed her\ndata by observing the output of a private mechanism---any test cannot have both\nhigh significance and high power.\n  In this paper, we identify some conditions under which a privacy definition\ngiven in terms of a statistical divergence satisfies a similar interpretation.\nThese conditions are useful to analyze the distinguishability power of\ndivergences and we use them to study the hypothesis testing interpretation of\nsome relaxations of differential privacy based on Renyi divergence. This\nanalysis also results in an improved conversion rule between these definitions\nand differential privacy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 00:53:24 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 15:44:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Balle", "Borja", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Hsu", "Justin", ""], ["Sato", "Tetsuya", ""]]}, {"id": "1905.09983", "submitter": "Sebastian D\\\"orner", "authors": "Daniel Tandler, Sebastian D\\\"orner, Sebastian Cammerer, Stephan ten\n  Brink", "title": "On Recurrent Neural Networks for Sequence-based Processing in\n  Communications", "comments": "Presented at Asilomar Conf. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the capabilities and practical limitations of neural\nnetworks (NNs) for sequence-based signal processing which can be seen as an\nomnipresent property in almost any modern communication systems. In particular,\nwe train multiple state-of-the-art recurrent neural network (RNN) structures to\nlearn how to decode convolutional codes allowing a clear benchmarking with the\ncorresponding maximum likelihood (ML) Viterbi decoder. We examine the decoding\nperformance for various kinds of NN architectures, beginning with classical\ntypes like feedforward layers and gated recurrent unit (GRU)-layers, up to more\nrecently introduced architectures such as temporal convolutional networks\n(TCNs) and differentiable neural computers (DNCs) with external memory. As a\nkey limitation, it turns out that the training complexity increases\nexponentially with the length of the encoding memory $\\nu$ and, thus,\npractically limits the achievable bit error rate (BER) performance. To overcome\nthis limitation, we introduce a new training-method by gradually increasing the\nnumber of ones within the training sequences, i.e., we constrain the amount of\npossible training sequences in the beginning until first convergence. By\nconsecutively adding more and more possible sequences to the training set, we\nfinally achieve training success in cases that did not converge before via\nnaive training. Further, we show that our network can learn to jointly detect\nand decode a quadrature phase shift keying (QPSK) modulated code with\nsub-optimal (anti-Gray) labeling in one-shot at a performance that would\nrequire iterations between demapper and decoder in classic detection schemes.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:03:28 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 13:34:08 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 15:45:03 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Tandler", "Daniel", ""], ["D\u00f6rner", "Sebastian", ""], ["Cammerer", "Sebastian", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1905.09989", "submitter": "Diego Ihara", "authors": "Diego Ihara, Neshat Mohammadi, Francesco Sgherzi and Anastasios\n  Sidiropoulos", "title": "Robust Mahalanobis Metric Learning via Geometric Approximation\n  Algorithms", "comments": "9 pages, 5 figures. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Mahalanobis metric spaces is an important problem that has found\nnumerous applications. Several algorithms have been designed for this problem,\nincluding Information Theoretic Metric Learning (ITML) [Davis et al. 2007] and\nLarge Margin Nearest Neighbor (LMNN) classification [Weinberger and Saul 2009].\nWe study the problem of learning a Mahalanobis metric space in the presence of\nadversarial label noise. To that end, we consider a formulation of Mahalanobis\nmetric learning as an optimization problem, where the objective is to minimize\nthe number of violated similarity/dissimilarity constraints. We show that for\nany fixed ambient dimension, there exists a fully polynomial-time approximation\nscheme (FPTAS) with nearly-linear running time. This result is obtained using\ntools from the theory of linear programming in low dimensions. As a\nconsequence, we obtain a fully-parallelizable algorithm that recovers a\nnearly-optimal metric space, even when a small fraction of the labels is\ncorrupted adversarially. We also discuss improvements of the algorithm in\npractice, and present experimental results on real-world, synthetic, and\npoisoned data sets.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:30:53 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:48:57 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 19:26:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ihara", "Diego", ""], ["Mohammadi", "Neshat", ""], ["Sgherzi", "Francesco", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1905.09992", "submitter": "Frederic Koehler", "authors": "Frederic Koehler", "title": "Fast Convergence of Belief Propagation to Global Optima: Beyond\n  Correlation Decay", "comments": "24 pages; comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation is a fundamental message-passing algorithm for\nprobabilistic reasoning and inference in graphical models. While it is known to\nbe exact on trees, in most applications belief propagation is run on graphs\nwith cycles. Understanding the behavior of \"loopy\" belief propagation has been\na major challenge for researchers in machine learning, and positive convergence\nresults for BP are known under strong assumptions which imply the underlying\ngraphical model exhibits decay of correlations. We show that under a natural\ninitialization, BP converges quickly to the global optimum of the Bethe free\nenergy for Ising models on arbitrary graphs, as long as the Ising model is\n\\emph{ferromagnetic} (i.e. neighbors prefer to be aligned). This holds even\nthough such models can exhibit long range correlations and may have multiple\nsuboptimal BP fixed points. We also show an analogous result for iterating the\n(naive) mean-field equations; perhaps surprisingly, both results are\ndimension-free in the sense that a constant number of iterations already\nprovides a good estimate to the Bethe/mean-field free energy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:42:31 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Koehler", "Frederic", ""]]}, {"id": "1905.09997", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Aaron Mishkin, Issam Laradji, Mark Schmidt, Gauthier\n  Gidel, Simon Lacoste-Julien", "title": "Painless Stochastic Gradient: Interpolation, Line-Search, and\n  Convergence Rates", "comments": "Added a citation to the related work of Paul Tseng, and citations to\n  methods that had previously explored line-searches for deep learning\n  empirically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that stochastic gradient descent (SGD) achieves the\nfast convergence rates of full-batch gradient descent for over-parameterized\nmodels satisfying certain interpolation conditions. However, the step-size used\nin these works depends on unknown quantities and SGD's practical performance\nheavily relies on the choice of this step-size. We propose to use line-search\ntechniques to automatically set the step-size when training models that can\ninterpolate the data. In the interpolation setting, we prove that SGD with a\nstochastic variant of the classic Armijo line-search attains the deterministic\nconvergence rates for both convex and strongly-convex functions. Under\nadditional assumptions, SGD with Armijo line-search is shown to achieve fast\nconvergence for non-convex functions. Furthermore, we show that stochastic\nextra-gradient with a Lipschitz line-search attains linear convergence for an\nimportant class of non-convex functions and saddle-point problems satisfying\ninterpolation. To improve the proposed methods' practical performance, we give\nheuristics to use larger step-sizes and acceleration. We compare the proposed\nalgorithms against numerous optimization methods on standard classification\ntasks using both kernel methods and deep networks. The proposed methods result\nin competitive performance across all models and datasets, while being robust\nto the precise choices of hyper-parameters. For multi-class classification\nusing deep networks, SGD with Armijo line-search results in both faster\nconvergence and better generalization.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:51:54 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 22:55:44 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 22:34:46 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 01:21:11 GMT"}, {"version": "v5", "created": "Fri, 4 Jun 2021 14:21:45 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Vaswani", "Sharan", ""], ["Mishkin", "Aaron", ""], ["Laradji", "Issam", ""], ["Schmidt", "Mark", ""], ["Gidel", "Gauthier", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1905.10000", "submitter": "Yongxi Lu", "authors": "Yongxi Lu, Ziyao Tang and Tara Javidi", "title": "Implicit Label Augmentation on Partially Annotated Clips via\n  Temporally-Adaptive Features Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially annotated clips contain rich temporal contexts that can complement\nthe sparse key frame annotations in providing supervision for model training.\nWe present a novel paradigm called Temporally-Adaptive Features (TAF) learning\nthat can utilize such data to learn better single frame models. By imposing\ndistinct temporal change rate constraints on different factors in the model,\nTAF enables learning from unlabeled frames using context to enhance model\naccuracy. TAF generalizes \"slow feature\" learning and we present much stronger\nempirical evidence than prior works, showing convincing gains for the\nchallenging semantic segmentation task over a variety of architecture designs\nand on two popular datasets. TAF can be interpreted as an implicit label\naugmentation method but is a more principled formulation compared to existing\nexplicit augmentation techniques. Our work thus connects two promising methods\nthat utilize partially annotated clips for single frame model training and can\ninspire future explorations in this direction.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:02:35 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lu", "Yongxi", ""], ["Tang", "Ziyao", ""], ["Javidi", "Tara", ""]]}, {"id": "1905.10003", "submitter": "Michael Minyi Zhang", "authors": "Michael Minyi Zhang, Bianca Dumitrascu, Sinead A. Williamson, Barbara\n  E. Engelhardt", "title": "Sequential Gaussian Processes for Online Learning of Nonstationary\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be framed in the context of estimating\nfunctions, and often these are time-dependent functions that are estimated in\nreal-time as observations arrive. Gaussian processes (GPs) are an attractive\nchoice for modeling real-valued nonlinear functions due to their flexibility\nand uncertainty quantification. However, the typical GP regression model\nsuffers from several drawbacks: i) Conventional GP inference scales $O(N^{3})$\nwith respect to the number of observations; ii) updating a GP model\nsequentially is not trivial; and iii) covariance kernels often enforce\nstationarity constraints on the function, while GPs with non-stationary\ncovariance kernels are often intractable to use in practice. To overcome these\nissues, we propose an online sequential Monte Carlo algorithm to fit mixtures\nof GPs that capture non-stationary behavior while allowing for fast,\ndistributed inference. By formulating hyperparameter optimization as a\nmulti-armed bandit problem, we accelerate mixing for real time inference. Our\napproach empirically improves performance over state-of-the-art methods for\nonline GP estimation in the context of prediction for simulated non-stationary\ndata and hospital time series data.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:29:49 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 15:54:41 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Zhang", "Michael Minyi", ""], ["Dumitrascu", "Bianca", ""], ["Williamson", "Sinead A.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1905.10006", "submitter": "Markus N Rabe", "authors": "Aditya Paliwal, Sarah Loos, Markus Rabe, Kshitij Bansal, Christian\n  Szegedy", "title": "Graph Representations for Higher-Order Logic and Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first use of graph neural networks (GNNs) for\nhigher-order proof search and demonstrates that GNNs can improve upon\nstate-of-the-art results in this domain. Interactive, higher-order theorem\nprovers allow for the formalization of most mathematical theories and have been\nshown to pose a significant challenge for deep learning. Higher-order logic is\nhighly expressive and, even though it is well-structured with a clearly defined\ngrammar and semantics, there still remains no well-established method to\nconvert formulas into graph-based representations. In this paper, we consider\nseveral graphical representations of higher-order logic and evaluate them\nagainst the HOList benchmark for higher-order theorem proving.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:42:22 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 00:06:34 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Paliwal", "Aditya", ""], ["Loos", "Sarah", ""], ["Rabe", "Markus", ""], ["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""]]}, {"id": "1905.10009", "submitter": "Yingjing Lu", "authors": "Yingjing Lu, Runde Yang", "title": "Not All Features Are Equal: Feature Leveling Deep Neural Networks for\n  Better Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-explaining models are models that reveal decision making parameters in\nan interpretable manner so that the model reasoning process can be directly\nunderstood by human beings. General Linear Models (GLMs) are self-explaining\nbecause the model weights directly show how each feature contributes to the\noutput value. However, deep neural networks (DNNs) are in general not\nself-explaining due to the non-linearity of the activation functions, complex\narchitectures, obscure feature extraction and transformation process. In this\nwork, we illustrate the fact that existing deep architectures are hard to\ninterpret because each hidden layer carries a mix of low level features and\nhigh level features. As a solution, we propose a novel feature leveling\narchitecture that isolates low level features from high level features on a\nper-layer basis to better utilize the GLM layer in the proposed architecture\nfor interpretation. Experimental results show that our modified models are able\nto achieve competitive results comparing to main-stream architectures on\nstandard datasets while being more self-explainable. Our implementations and\nconfigurations are publicly available for reproductions\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:53:45 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 21:01:43 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lu", "Yingjing", ""], ["Yang", "Runde", ""]]}, {"id": "1905.10010", "submitter": "Lukas Hirsch", "authors": "Lukas Hirsch, Yu Huang, Lucas C Parra", "title": "Segmentation of MRI head anatomy using deep volumetric networks and\n  multiple spatial priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Purpose: Conventional automated segmentation of the head anatomy in MRI\ndistinguishes different brain and non-brain tissues based on image intensities\nand prior tissue probability maps (TPM). This works well for normal head\nanatomies, but fails in the presence of unexpected lesions. Deep convolutional\nneural networks leverage instead spatial patterns and can learn to segment\nlesions, but often ignore prior probabilities. Approach: We add three sources\nof prior information to a three-dimensional convolutional network, namely,\nspatial priors with a TPM, morphological priors with conditional random fields,\nand spatial context with a wider field-of-view at lower resolution. We train\nand test these networks on 3D images of 43 stroke patients and 4 healthy\nindividuals which have been manually segmented. Results: We demonstrate the\nbenefits of each sources of prior information, and we show that the new\narchitecture, which we call Multiprior network, improves the performance of\nexisting segmentation software, such as SPM, FSL, and DeepMedic for abnormal\nanatomies. The relevance of the different priors was compared and the TPM was\nfound to be most beneficial. The benefit of adding a TPM is generic in that it\ncan boost the performance of established segmentation networks such as the\nDeepMedic and a UNet. We also provide an out-of-sample validation and clinical\napplication of the approach on an additional 47 patients with disorders of\nconsciousness. We make the code and trained networks freely available.\nConclusions: Biomedical images follow imaging protocols that can be leveraged\nas prior information into deep convolutional neural networks to improve\nperformance. The network segmentations match human manual corrections performed\nin 3D, and are comparable in performance to human segmentations obtained from\nscratch in 2D for abnormal brain anatomies.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:54:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:29:22 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 19:22:16 GMT"}, {"version": "v4", "created": "Mon, 11 May 2020 16:18:57 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 14:32:28 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Hirsch", "Lukas", ""], ["Huang", "Yu", ""], ["Parra", "Lucas C", ""]]}, {"id": "1905.10013", "submitter": "Guangyu Zhu", "authors": "Guangyu Zhu and Tingting Zhao", "title": "Deep-gKnock: nonlinear group-feature selection with deep neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is central to contemporary high-dimensional data analysis.\nGrouping structure among features arises naturally in various scientific\nproblems. Many methods have been proposed to incorporate the grouping structure\ninformation into feature selection. However, these methods are normally\nrestricted to a linear regression setting. To relax the linear constraint, we\ncombine the deep neural networks (DNNs) with the recent Knockoffs technique,\nwhich has been successful in an individual feature selection context. We\npropose Deep-gKnock (Deep group-feature selection using Knockoffs) as a\nmethodology for model interpretation and dimension reduction. Deep-gKnock\nperforms model-free group-feature selection by controlling group-wise False\nDiscovery Rate (gFDR). Our method improves the interpretability and\nreproducibility of DNNs. Experimental results on both synthetic and real data\ndemonstrate that our method achieves superior power and accurate gFDR control\ncompared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:07:37 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 11:57:10 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhu", "Guangyu", ""], ["Zhao", "Tingting", ""]]}, {"id": "1905.10016", "submitter": "Changjian Li", "authors": "Changjian Li, Krzysztof Czarnecki", "title": "A Micro-Objective Perspective of Reinforcement Learning", "comments": "accepted at RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The standard reinforcement learning (RL) formulation considers the\nexpectation of the (discounted) cumulative reward. This is limiting in\napplications where we are concerned with not only the expected performance, but\nalso the distribution of the performance. In this paper, we introduce\nmicro-objective reinforcement learning --- an alternative RL formalism that\novercomes this issue. In this new formulation, a RL task is specified by a set\nof micro-objectives, which are constructs that specify the desirability or\nundesirability of events. In addition, micro-objectives allow prior knowledge\nin the form of temporal abstraction to be incorporated into the global RL\nobjective. The generality of this formalism, and its relations to\nsingle/multi-objective RL, and hierarchical RL are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:19:59 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:03:26 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Li", "Changjian", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1905.10018", "submitter": "Francesco Orabona", "authors": "Ashok Cutkosky and Francesco Orabona", "title": "Momentum-Based Variance Reduction in Non-Convex SGD", "comments": "Added Ack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction has emerged in recent years as a strong competitor to\nstochastic gradient descent in non-convex problems, providing the first\nalgorithms to improve upon the converge rate of stochastic gradient descent for\nfinding first-order critical points. However, variance reduction techniques\ntypically require carefully tuned learning rates and willingness to use\nexcessively large \"mega-batches\" in order to achieve their improved results. We\npresent a new algorithm, STORM, that does not require any batches and makes use\nof adaptive learning rates, enabling simpler implementation and less\nhyperparameter tuning. Our technique for removing the batches uses a variant of\nmomentum to achieve variance reduction in non-convex optimization. On smooth\nlosses $F$, STORM finds a point $\\boldsymbol{x}$ with $\\mathbb{E}[\\|\\nabla\nF(\\boldsymbol{x})\\|]\\le O(1/\\sqrt{T}+\\sigma^{1/3}/T^{1/3})$ in $T$ iterations\nwith $\\sigma^2$ variance in the gradients, matching the optimal rate but\nwithout requiring knowledge of $\\sigma$.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:21:07 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 19:33:32 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 18:39:25 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Orabona", "Francesco", ""]]}, {"id": "1905.10022", "submitter": "Taoran Ji", "authors": "Taoran Ji, Zhiqian Chen, Nathan Self, Kaiqun Fu, Chang-Tien Lu, Naren\n  Ramakrishnan", "title": "Patent Citation Dynamics Modeling via Multi-Attention Recurrent Networks", "comments": null, "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and forecasting forward citations to a patent is a central task for\nthe discovery of emerging technologies and for measuring the pulse of inventive\nprogress. Conventional methods for forecasting these forward citations cast the\nproblem as analysis of temporal point processes which rely on the conditional\nintensity of previously received citations. Recent approaches model the\nconditional intensity as a chain of recurrent neural networks to capture memory\ndependency in hopes of reducing the restrictions of the parametric form of the\nintensity function. For the problem of patent citations, we observe that\nforecasting a patent's chain of citations benefits from not only the patent's\nhistory itself but also from the historical citations of assignees and\ninventors associated with that patent. In this paper, we propose a\nsequence-to-sequence model which employs an attention-of-attention mechanism to\ncapture the dependencies of these multiple time sequences. Furthermore, the\nproposed model is able to forecast both the timestamp and the category of a\npatent's next citation. Extensive experiments on a large patent citation\ndataset collected from USPTO demonstrate that the proposed model outperforms\nstate-of-the-art models at forward citation forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:11:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ji", "Taoran", ""], ["Chen", "Zhiqian", ""], ["Self", "Nathan", ""], ["Fu", "Kaiqun", ""], ["Lu", "Chang-Tien", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1905.10027", "submitter": "Qi Cai", "authors": "Qi Cai, Zhuoran Yang, Jason D. Lee, Zhaoran Wang", "title": "Neural Temporal-Difference and Q-Learning Provably Converge to Global\n  Optima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-difference learning (TD), coupled with neural networks, is among the\nmost fundamental building blocks of deep reinforcement learning. However, due\nto the nonlinearity in value function approximation, such a coupling leads to\nnonconvexity and even divergence in optimization. As a result, the global\nconvergence of neural TD remains unclear. In this paper, we prove for the first\ntime that neural TD converges at a sublinear rate to the global optimum of the\nmean-squared projected Bellman error for policy evaluation. In particular, we\nshow how such global convergence is enabled by the overparametrization of\nneural networks, which also plays a vital role in the empirical success of\nneural TD. Beyond policy evaluation, we establish the global convergence of\nneural (soft) Q-learning, which is further connected to that of policy gradient\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 04:36:42 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 07:34:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Lee", "Jason D.", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1905.10029", "submitter": "Ming Jin", "authors": "Ming Jin, Heng Chang, Wenwu Zhu, Somayeh Sojoudi", "title": "Power up! Robust Graph Convolutional Network against Evasion Attacks\n  based on Graph Powering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are powerful tools for graph-structured\ndata. However, they have been recently shown to be prone to topological\nattacks. Despite substantial efforts to search for new architectures, it still\nremains a challenge to improve performance in both benign and adversarial\nsituations simultaneously. In this paper, we re-examine the fundamental\nbuilding block of GCN---the Laplacian operator---and highlight some basic flaws\nin the spatial and spectral domains. As an alternative, we propose an operator\nbased on graph powering, and prove that it enjoys a desirable property of\n\"spectral separation.\" Based on the operator, we propose a robust learning\nparadigm, where the network is trained on a family of \"'smoothed\" graphs that\nspan a spatial and spectral range for generalizability. We also use the new\noperator in replacement of the classical Laplacian to construct an architecture\nwith improved spectral robustness, expressivity and interpretability. The\nenhanced performance and robustness are demonstrated in extensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 04:43:38 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Jin", "Ming", ""], ["Chang", "Heng", ""], ["Zhu", "Wenwu", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1905.10040", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Vidya Muthukumar, Peter L. Bartlett", "title": "OSOM: A simultaneously optimal algorithm for multi-armed and linear\n  contextual bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic linear (multi-armed) contextual bandit problem\nwith the possibility of hidden simple multi-armed bandit structure in which the\nrewards are independent of the contextual information. Algorithms that are\ndesigned solely for one of the regimes are known to be sub-optimal for the\nalternate regime. We design a single computationally efficient algorithm that\nsimultaneously obtains problem-dependent optimal regret rates in the simple\nmulti-armed bandit regime and minimax optimal regret rates in the linear\ncontextual bandit regime, without knowing a priori which of the two models\ngenerates the rewards. These results are proved under the condition of\nstochasticity of contextual information over multiple rounds. Our results\nshould be viewed as a step towards principled data-dependent policy class\nselection for contextual bandits.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:38:14 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 18:18:48 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 01:13:40 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 03:28:58 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Muthukumar", "Vidya", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1905.10041", "submitter": "Yueming Lyu", "authors": "Yueming Lyu, Yuan Yuan, Ivor W. Tsang", "title": "Efficient Batch Black-box Optimization with Deterministic Regret Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate black-box optimization from the perspective of\nfrequentist kernel methods. We propose a novel batch optimization algorithm,\nwhich jointly maximizes the acquisition function and select points from a whole\nbatch in a holistic way. Theoretically, we derive regret bounds for both the\nnoise-free and perturbation settings irrespective of the choice of kernel.\nMoreover, we analyze the property of the adversarial regret that is required by\na robust initialization for Bayesian Optimization (BO). We prove that the\nadversarial regret bounds decrease with the decrease of covering radius, which\nprovides a criterion for generating a point set to minimize the bound. We then\npropose fast searching algorithms to generate a point set with a small covering\nradius for the robust initialization. Experimental results on both synthetic\nbenchmark problems and real-world problems show the effectiveness of the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 05:40:05 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 07:32:04 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 04:37:48 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Lyu", "Yueming", ""], ["Yuan", "Yuan", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1905.10045", "submitter": "Yueming Lyu", "authors": "Yueming Lyu, Ivor W. Tsang", "title": "Curriculum Loss: Robust Learning and Generalization against Label\n  Corruption", "comments": "ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have great expressive power, which can even\nmemorize samples with wrong labels. It is vitally important to reiterate\nrobustness and generalization in DNNs against label corruption. To this end,\nthis paper studies the 0-1 loss, which has a monotonic relationship with an\nempirical adversary (reweighted) risk~\\citep{hu2016does}. Although the 0-1 loss\nhas some robust properties, it is difficult to optimize. To efficiently\noptimize the 0-1 loss while keeping its robust properties, we propose a very\nsimple and efficient loss, i.e. curriculum loss (CL). Our CL is a tighter upper\nbound of the 0-1 loss compared with conventional summation based surrogate\nlosses. Moreover, CL can adaptively select samples for model training. As a\nresult, our loss can be deemed as a novel perspective of curriculum sample\nselection strategy, which bridges a connection between curriculum learning and\nrobust learning. Experimental results on benchmark datasets validate the\nrobustness of the proposed loss.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:04:18 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 05:12:27 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:10:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Lyu", "Yueming", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1905.10053", "submitter": "Yang Liu", "authors": "Yang Liu, Yingting Liu, Zhijie Liu, Junbo Zhang, Chuishi Meng, Yu\n  Zheng", "title": "Federated Forest", "comments": null, "journal-ref": null, "doi": "10.1109/TBDATA.2020.2992755", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world data are scattered across different companies or government\norganizations, and cannot be easily integrated under data privacy and related\nregulations such as the European Union's General Data Protection Regulation\n(GDPR) and China' Cyber Security Law. Such data islands situation and data\nprivacy & security are two major challenges for applications of artificial\nintelligence. In this paper, we tackle these challenges and propose a\nprivacy-preserving machine learning model, called Federated Forest, which is a\nlossless learning model of the traditional random forest method, i.e.,\nachieving the same level of accuracy as the non-privacy-preserving approach.\nBased on it, we developed a secure cross-regional machine learning system that\nallows a learning process to be jointly trained over different regions' clients\nwith the same user samples but different attribute sets, processing the data\nstored in each of them without exchanging their raw data. A novel prediction\nalgorithm was also proposed which could largely reduce the communication\noverhead. Experiments on both real-world and UCI data sets demonstrate the\nperformance of the Federated Forest is as accurate as the non-federated\nversion. The efficiency and robustness of our proposed system had been\nverified. Overall, our model is practical, scalable and extensible for\nreal-life tasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:38:01 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Liu", "Yang", ""], ["Liu", "Yingting", ""], ["Liu", "Zhijie", ""], ["Zhang", "Junbo", ""], ["Meng", "Chuishi", ""], ["Zheng", "Yu", ""]]}, {"id": "1905.10069", "submitter": "Lei Bai", "authors": "Lei Bai and Lina Yao and Salil.S Kanhere and Xianzhi Wang and Quan.Z\n  Sheng", "title": "STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step\n  Passenger Demand Forecasting", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step passenger demand forecasting is a crucial task in on-demand\nvehicle sharing services. However, predicting passenger demand over multiple\ntime horizons is generally challenging due to the nonlinear and dynamic\nspatial-temporal dependencies. In this work, we propose to model multi-step\ncitywide passenger demand prediction based on a graph and use a hierarchical\ngraph convolutional structure to capture both spatial and temporal correlations\nsimultaneously. Our model consists of three parts: 1) a long-term encoder to\nencode historical passenger demands; 2) a short-term encoder to derive the\nnext-step prediction for generating multi-step prediction; 3) an\nattention-based output module to model the dynamic temporal and channel-wise\ninformation. Experiments on three real-world datasets show that our model\nconsistently outperforms many baseline methods and state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:24:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Bai", "Lei", ""], ["Yao", "Lina", ""], ["Kanhere", "Salil. S", ""], ["Wang", "Xianzhi", ""], ["Sheng", "Quan. Z", ""]]}, {"id": "1905.10070", "submitter": "Xin Huang", "authors": "Xin Huang, Boli Chen, Lin Xiao, and Liping Jing", "title": "Label-aware Document Representation via Hybrid Attention for Extreme\n  Multi-Label Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label text classification (XMTC) aims at tagging a document\nwith most relevant labels from an extremely large-scale label set. It is a\nchallenging problem especially for the tail labels because there are only few\ntraining documents to build classifier. This paper is motivated to better\nexplore the semantic relationship between each document and extreme labels by\ntaking advantage of both document content and label correlation. Our objective\nis to establish an explicit label-aware representation for each document with a\nhybrid attention deep neural network model(LAHA). LAHA consists of three parts.\nThe first part adopts a multi-label self-attention mechanism to detect the\ncontribution of each word to labels. The second part exploits the label\nstructure and document content to determine the semantic connection between\nwords and labels in a same latent space. An adaptive fusion strategy is\ndesigned in the third part to obtain the final label-aware document\nrepresentation so that the essence of previous two parts can be sufficiently\nintegrated. Extensive experiments have been conducted on six benchmark datasets\nby comparing with the state-of-the-art methods. The results show the\nsuperiority of our proposed LAHA method, especially on the tail labels.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:30:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 02:45:08 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Huang", "Xin", ""], ["Chen", "Boli", ""], ["Xiao", "Lin", ""], ["Jing", "Liping", ""]]}, {"id": "1905.10071", "submitter": "HsuanKung Yang", "authors": "Hsuan-Kung Yang, Po-Han Chiang, Min-Fong Hong, and Chun-Yi Lee", "title": "Flow-based Intrinsic Curiosity Module", "comments": "The SOLE copyright holder is IJCAI (International Joint Conferences\n  on Artificial Intelligence), all rights reserved. The link is provided as\n  follows: https://www.ijcai.org/Proceedings/2020/286", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence Main track. Pages 2065-2072", "doi": "10.24963/ijcai.2020/286", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on a prediction-based novelty estimation strategy\nupon the deep reinforcement learning (DRL) framework, and present a flow-based\nintrinsic curiosity module (FICM) to exploit the prediction errors from optical\nflow estimation as exploration bonuses. We propose the concept of leveraging\nmotion features captured between consecutive observations to evaluate the\nnovelty of observations in an environment. FICM encourages a DRL agent to\nexplore observations with unfamiliar motion features, and requires only two\nconsecutive frames to obtain sufficient information when estimating the\nnovelty. We evaluate our method and compare it with a number of existing\nmethods on multiple benchmark environments, including Atari games, Super Mario\nBros., and ViZDoom. We demonstrate that FICM is favorable to tasks or\nenvironments featuring moving objects, which allow FICM to utilize the motion\nfeatures between consecutive observations. We further ablatively analyze the\nencoding efficiency of FICM, and discuss its applicable domains\ncomprehensively.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:32:30 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:06:51 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 04:39:13 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yang", "Hsuan-Kung", ""], ["Chiang", "Po-Han", ""], ["Hong", "Min-Fong", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1905.10072", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Xu Yang, Feng He, Yuanyuan Chen, Jiancheng Lv", "title": "mu-Forcing: Training Variational Recurrent Autoencoders for Text\n  Generation", "comments": "To appear in the ACM Transactions on Asian and Low-Resource Language\n  Information Processing (TALLIP)", "journal-ref": null, "doi": "10.1145/3341110", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been previously observed that training Variational Recurrent\nAutoencoders (VRAE) for text generation suffers from serious uninformative\nlatent variables problem. The model would collapse into a plain language model\nthat totally ignore the latent variables and can only generate repeating and\ndull samples. In this paper, we explore the reason behind this issue and\npropose an effective regularizer based approach to address it. The proposed\nmethod directly injects extra constraints on the posteriors of latent variables\ninto the learning process of VRAE, which can flexibly and stably control the\ntrade-off between the KL term and the reconstruction term, making the model\nlearn dense and meaningful latent representations. The experimental results\nshow that the proposed method outperforms several strong baselines and can make\nthe model learn interpretable latent variables and generate diverse meaningful\nsentences. Furthermore, the proposed method can perform well without using\nother strategies, such as KL annealing.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:32:37 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Yang", "Xu", ""], ["He", "Feng", ""], ["Chen", "Yuanyuan", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1905.10073", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Gjergji Kasneci, Wolfgang Rosenstiel, Enkelejda Kasneci", "title": "Training Decision Trees as Replacement for Convolution Layers", "comments": "Will be published in the proceedings oft he AAAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative layer to convolution layers in convolutional neural\nnetworks (CNNs). Our approach reduces the complexity of convolutions by\nreplacing it with binary decisions. Those binary decisions are used as indexes\nto conditional distributions where each weight represents a leaf in a decision\ntree. This means that only the indices to the weights need to be determined\nonce, thus reducing the complexity of convolutions by the depth of the output\ntensor. Index computation is performed by simple binary decisions that require\nfewer cycles compared to conventionally used multiplications. In addition, we\nshow how convolutions can be replaced by binary decisions. These binary\ndecisions form indices in the conditional distributions and we show how they\nare used to replace 2D weight matrices as well as 3D weight tensors. These new\nlayers can be trained like convolution layers in CNNs based on the\nbackpropagation algorithm, for which we provide a formalization.\n  Our results on multiple publicly available data sets show that our approach\nperforms similar to conventional neuronal networks. Beyond the formalized\nreduction of complexity and the improved qualitative performance, we show the\nruntime improvement empirically compared to convolution layers.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:32:48 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 05:26:19 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 07:49:33 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 06:42:51 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Kasneci", "Gjergji", ""], ["Rosenstiel", "Wolfgang", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "1905.10079", "submitter": "Younghan Jeon", "authors": "Younghan Jeon, Minsik Lee, Jin Young Choi", "title": "Neuro-Optimization: Learning Objective Functions Using Neural Networks", "comments": "10 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical optimization is widely used in various research fields. With a\ncarefully-designed objective function, mathematical optimization can be quite\nhelpful in solving many problems. However, objective functions are usually\nhand-crafted and designing a good one can be quite challenging. In this paper,\nwe propose a novel framework to learn the objective function based on a neural\nnet-work. The basic idea is to consider the neural network as an objective\nfunction, and the input as an optimization variable. For the learning of\nobjective function from the training data, two processes are conducted: In the\ninner process, the optimization variable (the input of the network) are\noptimized to minimize the objective function (the network output), while fixing\nthe network weights. In the outer process, on the other hand, the weights are\noptimized based on how close the final solution of the inner process is to the\ndesired solution. After learning the objective function, the solution for the\ntest set is obtained in the same manner of the inner process. The potential and\napplicability of our approach are demonstrated by the experiments on toy\nexamples and a computer vision task, optical flow.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:00:22 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Jeon", "Younghan", ""], ["Lee", "Minsik", ""], ["Choi", "Jin Young", ""]]}, {"id": "1905.10086", "submitter": "Bo Kang", "authors": "Bo Kang, Dar\\'io Garc\\'ia Garc\\'ia, Jefrey Lijffijt, Ra\\'ul\n  Santos-Rodr\\'iguez, Tijl De Bie", "title": "Conditional t-SNE: Complementary t-SNE embeddings through factoring out\n  prior information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction and manifold learning methods such as t-Distributed\nStochastic Neighbor Embedding (t-SNE) are routinely used to map\nhigh-dimensional data into a 2-dimensional space to visualize and explore the\ndata. However, two dimensions are typically insufficient to capture all\nstructure in the data, the salient structure is often already known, and it is\nnot obvious how to extract the remaining information in a similarly effective\nmanner. To fill this gap, we introduce \\emph{conditional t-SNE} (ct-SNE), a\ngeneralization of t-SNE that discounts prior information from the embedding in\nthe form of labels. To achieve this, we propose a conditioned version of the\nt-SNE objective, obtaining a single, integrated, and elegant method. ct-SNE has\none extra parameter over t-SNE; we investigate its effects and show how to\nefficiently optimize the objective. Factoring out prior knowledge allows\ncomplementary structure to be captured in the embedding, providing new\ninsights. Qualitative and quantitative empirical results on synthetic and\n(large) real data show ct-SNE is effective and achieves its goal.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:25:52 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Kang", "Bo", ""], ["Garc\u00eda", "Dar\u00edo Garc\u00eda", ""], ["Lijffijt", "Jefrey", ""], ["Santos-Rodr\u00edguez", "Ra\u00fal", ""], ["De Bie", "Tijl", ""]]}, {"id": "1905.10091", "submitter": "Liwei Lin", "authors": "Liwei Lin, Xiangdong Wang, Hong Liu and Yueliang Qian", "title": "Specialized Decision Surface and Disentangled Feature for\n  Weakly-Supervised Polyphonic Sound Event Detection", "comments": "Accept by TASLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a special decision surface for the weakly-supervised sound\nevent detection (SED) and a disentangled feature (DF) for the multi-label\nproblem in polyphonic SED are proposed. We approach SED as a multiple instance\nlearning (MIL) problem and utilize a neural network framework with a pooling\nmodule to solve it. General MIL approaches include two kinds: the\ninstance-level approaches and embedding-level approaches. We present a method\nof generating instance-level probabilities for the embedding level approaches\nwhich tend to perform better than the instance-level approaches in terms of\nbag-level classification but can not provide instance-level probabilities in\ncurrent approaches. Moreover, we further propose a specialized decision surface\n(SDS) for the embedding-level attention pooling. We analyze and explained why\nan embedding-level attention module with SDS is better than other typical\npooling modules from the perspective of the high-level feature space. As for\nthe problem of the unbalanced dataset and the co-occurrence of multiple\ncategories in the polyphonic event detection task, we propose a DF to reduce\ninterference among categories, which optimizes the high-level feature space by\ndisentangling it based on class-wise identifiable information and obtaining\nmultiple different subspaces. Experiments on the dataset of DCASE 2018 Task 4\nshow that the proposed SDS and DF significantly improve the detection\nperformance of the embedding-level MIL approach with an attention pooling\nmodule and outperform the first place system in the challenge by 6.6 percentage\npoints.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:46:56 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 02:23:42 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 03:05:11 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 16:41:13 GMT"}, {"version": "v5", "created": "Thu, 19 Sep 2019 09:53:50 GMT"}, {"version": "v6", "created": "Fri, 10 Apr 2020 17:20:21 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Lin", "Liwei", ""], ["Wang", "Xiangdong", ""], ["Liu", "Hong", ""], ["Qian", "Yueliang", ""]]}, {"id": "1905.10094", "submitter": "Katharina Bieker", "authors": "Katharina Bieker, Sebastian Peitz, Steven L. Brunton, J. Nathan Kutz,\n  Michael Dellnitz", "title": "Deep Model Predictive Control with Online Learning for Complex Physical\n  Systems", "comments": null, "journal-ref": null, "doi": "10.1007/s00162-020-00520-4", "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of complex systems is of critical importance in many branches of\nscience, engineering, and industry. Controlling an unsteady fluid flow is\nparticularly important, as flow control is a key enabler for technologies in\nenergy (e.g., wind, tidal, and combustion), transportation (e.g., planes,\ntrains, and automobiles), security (e.g., tracking airborne contamination), and\nhealth (e.g., artificial hearts and artificial respiration). However, the\nhigh-dimensional, nonlinear, and multi-scale dynamics make real-time feedback\ncontrol infeasible. Fortunately, these high-dimensional systems exhibit\ndominant, low-dimensional patterns of activity that can be exploited for\neffective control in the sense that knowledge of the entire state of a system\nis not required. Advances in machine learning have the potential to\nrevolutionize flow control given its ability to extract principled, low-rank\nfeature spaces characterizing such complex systems. We present a novel deep\nlearning model predictive control (DeepMPC) framework that exploits low-rank\nfeatures of the flow in order to achieve considerable improvements to control\nperformance. Instead of predicting the entire fluid state, we use a recurrent\nneural network (RNN) to accurately predict the control relevant quantities of\nthe system. The RNN is then embedded into a MPC framework to construct a\nfeedback loop, and incoming sensor data is used to perform online updates to\nimprove prediction accuracy. The results are validated using varying fluid flow\nexamples of increasing complexity.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:54:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bieker", "Katharina", ""], ["Peitz", "Sebastian", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Dellnitz", "Michael", ""]]}, {"id": "1905.10095", "submitter": "Bin Guo", "authors": "Yi Ouyang, Bin Guo, Xing Tang, Xiuqiang He, Jian Xiong, Zhiwen Yu", "title": "Learning Cross-Domain Representation with Multi-Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective embedding has been proved to be useful in many real-world\nproblems, such as recommender systems, search ranking and online advertisement.\nHowever, one of the challenges is data sparsity in learning large-scale item\nembedding, as users' historical behavior data are usually lacking or\ninsufficient in an individual domain. In fact, user's behaviors from different\ndomains regarding the same items are usually relevant. Therefore, we can learn\ncomplete user behaviors to alleviate the sparsity using complementary\ninformation from correlated domains. It is intuitive to model users' behaviors\nusing graph, and graph neural networks (GNNs) have recently shown the great\npower for representation learning, which can be used to learn item embedding.\nHowever, it is challenging to transfer the information across domains and learn\ncross-domain representation using the existing GNNs. To address these\nchallenges, in this paper, we propose a novel model - Deep Multi-Graph\nEmbedding (DMGE) to learn cross-domain representation. Specifically, we first\nconstruct a multi-graph based on users' behaviors from different domains, and\nthen propose a multi-graph neural network to learn cross-domain representation\nin an unsupervised manner. Particularly, we present a multiple-gradient descent\noptimizer for efficiently training the model. We evaluate our approach on\nvarious large-scale real-world datasets, and the experimental results show that\nDMGE outperforms other state-of-art embedding methods in various tasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:58:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ouyang", "Yi", ""], ["Guo", "Bin", ""], ["Tang", "Xing", ""], ["He", "Xiuqiang", ""], ["Xiong", "Jian", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1905.10099", "submitter": "Boris Muzellec", "authors": "Boris Muzellec and Marco Cuturi", "title": "Subspace Detours: Building Transport Plans that are Optimal on Subspace\n  Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing optimal transport (OT) between measures in high dimensions is\ndoomed by the curse of dimensionality. A popular approach to avoid this curse\nis to project input measures on lower-dimensional subspaces (1D lines in the\ncase of sliced Wasserstein distances), solve the OT problem between these\nreduced measures, and settle for the Wasserstein distance between these\nreductions, rather than that between the original measures. This approach is\nhowever difficult to extend to the case in which one wants to compute an OT map\n(a Monge map) between the original measures. Since computations are carried out\non lower-dimensional projections, classical map estimation techniques can only\nproduce maps operating in these reduced dimensions. We propose in this work two\nmethods to extrapolate, from an transport map that is optimal on a subspace,\none that is nearly optimal in the entire space. We prove that the best optimal\ntransport plan that takes such \"subspace detours\" is a generalization of the\nKnothe-Rosenblatt transport. We show that these plans can be explicitly\nformulated when comparing Gaussian measures (between which the Wasserstein\ndistance is commonly referred to as the Bures or Fr\\'echet distance). We\nprovide an algorithm to select optimal subspaces given pairs of Gaussian\nmeasures, and study scenarios in which that mediating subspace can be selected\nusing prior information. We consider applications to semantic mediation between\nelliptic word embeddings and domain adaptation with Gaussian mixture models.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:07:43 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 12:43:35 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 09:16:59 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 02:14:14 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Muzellec", "Boris", ""], ["Cuturi", "Marco", ""]]}, {"id": "1905.10101", "submitter": "Lin Zhu", "authors": "Lin Zhu, Jiaxing Lu, Yihong Chen", "title": "HDI-Forest: Highest Density Interval Regression Forest", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By seeking the narrowest prediction intervals (PIs) that satisfy the\nspecified coverage probability requirements, the recently proposed\nquality-based PI learning principle can extract high-quality PIs that better\nsummarize the predictive certainty in regression tasks, and has been widely\napplied to solve many practical problems. Currently, the state-of-the-art\nquality-based PI estimation methods are based on deep neural networks or linear\nmodels. In this paper, we propose Highest Density Interval Regression Forest\n(HDI-Forest), a novel quality-based PI estimation method that is instead based\non Random Forest. HDI-Forest does not require additional model training, and\ndirectly reuses the trees learned in a standard Random Forest model. By\nutilizing the special properties of Random Forest, HDI-Forest could efficiently\nand more directly optimize the PI quality metrics. Extensive experiments on\nbenchmark datasets show that HDI-Forest significantly outperforms previous\napproaches, reducing the average PI width by over 20% while achieving the same\nor better coverage probability\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:19:09 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 16:03:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhu", "Lin", ""], ["Lu", "Jiaxing", ""], ["Chen", "Yihong", ""]]}, {"id": "1905.10107", "submitter": "Matteo Poggi", "authors": "Matteo Poggi, Davide Pallotti, Fabio Tosi, Stefano Mattoccia", "title": "Guided Stereo Matching", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stereo is a prominent technique to infer dense depth maps from images, and\ndeep learning further pushed forward the state-of-the-art, making end-to-end\narchitectures unrivaled when enough data is available for training. However,\ndeep networks suffer from significant drops in accuracy when dealing with new\nenvironments. Therefore, in this paper, we introduce Guided Stereo Matching, a\nnovel paradigm leveraging a small amount of sparse, yet reliable depth\nmeasurements retrieved from an external source enabling to ameliorate this\nweakness. The additional sparse cues required by our method can be obtained\nwith any strategy (e.g., a LiDAR) and used to enhance features linked to\ncorresponding disparity hypotheses. Our formulation is general and fully\ndifferentiable, thus enabling to exploit the additional sparse inputs in\npre-trained deep stereo networks as well as for training a new instance from\nscratch. Extensive experiments on three standard datasets and two\nstate-of-the-art deep architectures show that even with a small set of sparse\ninput cues, i) the proposed paradigm enables significant improvements to\npre-trained networks. Moreover, ii) training from scratch notably increases\naccuracy and robustness to domain shifts. Finally, iii) it is suited and\neffective even with traditional stereo algorithms such as SGM.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:32:34 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Poggi", "Matteo", ""], ["Pallotti", "Davide", ""], ["Tosi", "Fabio", ""], ["Mattoccia", "Stefano", ""]]}, {"id": "1905.10108", "submitter": "Josif Grabocka", "authors": "Josif Grabocka, Randolf Scholz, Lars Schmidt-Thieme", "title": "Learning Surrogate Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of loss functions is the heart and soul of Machine Learning.\nIn this paper, we propose an off-the-shelf optimization approach that can\nminimize virtually any non-differentiable and non-decomposable loss function\n(e.g. Miss-classification Rate, AUC, F1, Jaccard Index, Mathew Correlation\nCoefficient, etc.) seamlessly. Our strategy learns smooth relaxation versions\nof the true losses by approximating them through a surrogate neural network.\nThe proposed loss networks are set-wise models which are invariant to the order\nof mini-batch instances. Ultimately, the surrogate losses are learned jointly\nwith the prediction model via bilevel optimization. Empirical results on\nmultiple datasets with diverse real-life loss functions compared with\nstate-of-the-art baselines demonstrate the efficiency of learning surrogate\nlosses.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:33:04 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Grabocka", "Josif", ""], ["Scholz", "Randolf", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1905.10112", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Karan Desai, Eugenio Culurciello, Davide Maltoni", "title": "Continual Reinforcement Learning in 3D Non-stationary Environments", "comments": "Accepted in the CLVision Workshop at CVPR2020: 13 pages, 4 figures, 5\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional always-changing environments constitute a hard challenge for\ncurrent reinforcement learning techniques. Artificial agents, nowadays, are\noften trained off-line in very static and controlled conditions in simulation\nsuch that training observations can be thought as sampled i.i.d. from the\nentire observations space. However, in real world settings, the environment is\noften non-stationary and subject to unpredictable, frequent changes. In this\npaper we propose and openly release CRLMaze, a new benchmark for learning\ncontinually through reinforcement in a complex 3D non-stationary task based on\nViZDoom and subject to several environmental changes. Then, we introduce an\nend-to-end model-free continual reinforcement learning strategy showing\ncompetitive results with respect to four different baselines and not requiring\nany access to additional supervised signals, previously encountered\nenvironmental conditions or observations.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:38:42 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:57:48 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Desai", "Karan", ""], ["Culurciello", "Eugenio", ""], ["Maltoni", "Davide", ""]]}, {"id": "1905.10115", "submitter": "Badong Chen", "authors": "Badong Chen, Xin Wang, Zejian yuan, Pengju Ren and Jing Qin", "title": "Multi-Kernel Correntropy for Robust Learning", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a novel similarity measure that is defined as the expectation of a kernel\nfunction between two random variables, correntropy has been successfully\napplied in robust machine learning and signal processing to combat large\noutliers. The kernel function in correntropy is usually a zero-mean Gaussian\nkernel. In a recent work, the concept of mixture correntropy (MC) was proposed\nto improve the learning performance, where the kernel function is a mixture\nGaussian kernel, namely a linear combination of several zero-mean Gaussian\nkernels with different widths. In both correntropy and mixture correntropy, the\ncenter of the kernel function is, however, always located at zero. In the\npresent work, to further improve the learning performance, we propose the\nconcept of multi-kernel correntropy (MKC), in which each component of the\nmixture Gaussian kernel can be centered at a different location. The properties\nof the MKC are investigated and an efficient approach is proposed to determine\nthe free parameters in MKC. Experimental results show that the learning\nalgorithms under the maximum multi-kernel correntropy criterion (MMKCC) can\noutperform those under the original maximum correntropy criterion (MCC) and the\nmaximum mixture correntropy criterion (MMCC).\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:50:40 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Chen", "Badong", ""], ["Wang", "Xin", ""], ["yuan", "Zejian", ""], ["Ren", "Pengju", ""], ["Qin", "Jing", ""]]}, {"id": "1905.10116", "submitter": "Mert Demirer", "authors": "Mert Demirer, Vasilis Syrgkanis, Greg Lewis, Victor Chernozhukov", "title": "Semi-Parametric Efficient Policy Learning with Continuous Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy evaluation and optimization with continuous action\nspaces. We focus on observational data where the data collection policy is\nunknown and needs to be estimated. We take a semi-parametric approach where the\nvalue function takes a known parametric form in the treatment, but we are\nagnostic on how it depends on the observed contexts. We propose a doubly robust\noff-policy estimate for this setting and show that off-policy optimization\nbased on this estimate is robust to estimation errors of the policy function or\nthe regression model. Our results also apply if the model does not satisfy our\nsemi-parametric form, but rather we measure regret in terms of the best\nprojection of the true value function to this functional space. Our work\nextends prior approaches of policy optimization from observational data that\nonly considered discrete actions. We provide an experimental evaluation of our\nmethod in a synthetic data example motivated by optimal personalized pricing\nand costly resource allocation.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:51:21 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 23:36:34 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Demirer", "Mert", ""], ["Syrgkanis", "Vasilis", ""], ["Lewis", "Greg", ""], ["Chernozhukov", "Victor", ""]]}, {"id": "1905.10117", "submitter": "Andreas Pfeuffer", "authors": "Andreas Pfeuffer and Klaus Dietmayer", "title": "Robust Semantic Segmentation in Adverse Weather Conditions by means of\n  Sensor Data Fusion", "comments": null, "journal-ref": "22st International Conference on Information Fusion (FUSION)\n  (2019)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust and reliable semantic segmentation in adverse weather conditions is\nvery important for autonomous cars, but most state-of-the-art approaches only\nachieve high accuracy rates in optimal weather conditions. The reason is that\nthey are only optimized for good weather conditions and given noise models.\nHowever, most of them fail, if data with unknown disturbances occur, and their\nperformance decrease enormously. One possibility to still obtain reliable\nresults is to observe the environment with different sensor types, such as\ncamera and lidar, and to fuse the sensor data by means of neural networks,\nsince different sensors behave differently in diverse weather conditions.\nHence, the sensors can complement each other by means of an appropriate sensor\ndata fusion. Nevertheless, the fusion-based approaches are still susceptible to\ndisturbances and fail to classify disturbed image areas correctly. This problem\ncan be solved by means of a special training method, the so called Robust\nLearning Method (RLM), a method by which the neural network learns to handle\nunknown noise. In this work, two different sensor fusion architectures for\nsemantic segmentation are compared and evaluated on several datasets.\nFurthermore, it is shown that the RLM increases the robustness in adverse\nweather conditions enormously, and achieve good results although no disturbance\nmodel has been learned by the neural network.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 09:55:57 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Pfeuffer", "Andreas", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1905.10124", "submitter": "Vayer Titouan", "authors": "Titouan Vayer, R\\'emi Flamary, Romain Tavenard, Laetitia Chapel,\n  Nicolas Courty", "title": "Sliced Gromov-Wasserstein", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently used in various machine learning contexts, the Gromov-Wasserstein\ndistance (GW) allows for comparing distributions whose supports do not\nnecessarily lie in the same metric space. However, this Optimal Transport (OT)\ndistance requires solving a complex non convex quadratic program which is most\nof the time very costly both in time and memory. Contrary to GW, the\nWasserstein distance (W) enjoys several properties ({\\em e.g.} duality) that\npermit large scale optimization. Among those, the solution of W on the real\nline, that only requires sorting discrete samples in 1D, allows defining the\nSliced Wasserstein (SW) distance. This paper proposes a new divergence based on\nGW akin to SW. We first derive a closed form for GW when dealing with 1D\ndistributions, based on a new result for the related quadratic assignment\nproblem. We then define a novel OT discrepancy that can deal with large scale\ndistributions via a slicing approach and we show how it relates to the GW\ndistance while being $O(n\\log(n))$ to compute. We illustrate the behavior of\nthis so called Sliced Gromov-Wasserstein (SGW) discrepancy in experiments where\nwe demonstrate its ability to tackle similar problems as GW while being several\norder of magnitudes faster to compute.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:18:52 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 09:11:25 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 09:34:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Vayer", "Titouan", ""], ["Flamary", "R\u00e9mi", ""], ["Tavenard", "Romain", ""], ["Chapel", "Laetitia", ""], ["Courty", "Nicolas", ""]]}, {"id": "1905.10138", "submitter": "Se Jung Kwon", "authors": "Se Jung Kwon, Dongsoo Lee, Byeongwook Kim, Parichay Kapoor, Baeseong\n  Park and Gu-Yeon Wei", "title": "Structured Compression by Weight Encryption for Unstructured Pruning and\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression techniques, such as pruning and quantization, are becoming\nincreasingly important to reduce the memory footprints and the amount of\ncomputations. Despite model size reduction, achieving performance enhancement\non devices is, however, still challenging mainly due to the irregular\nrepresentations of sparse matrix formats. This paper proposes a new weight\nrepresentation scheme for Sparse Quantized Neural Networks, specifically\nachieved by fine-grained and unstructured pruning method. The representation is\nencrypted in a structured regular format, which can be efficiently decoded\nthrough XOR-gate network during inference in a parallel manner. We demonstrate\nvarious deep learning models that can be compressed and represented by our\nproposed format with fixed and high compression ratio. For example, for\nfully-connected layers of AlexNet on ImageNet dataset, we can represent the\nsparse weights by only 0.28 bits/weight for 1-bit quantization and 91% pruning\nrate with a fixed decoding rate and full memory bandwidth usage. Decoding\nthrough XOR-gate network can be performed without any model accuracy\ndegradation with additional patch data associated with small overhead.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:41:16 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 07:57:53 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Kwon", "Se Jung", ""], ["Lee", "Dongsoo", ""], ["Kim", "Byeongwook", ""], ["Kapoor", "Parichay", ""], ["Park", "Baeseong", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1905.10142", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Beatrice Bussolino, Alessio Colucci, Muhammad\n  Abdullah Hanif, Maurizio Martina, Guido Masera, Muhammad Shafique", "title": "FasTrCaps: An Integrated Framework for Fast yet Accurate Training of\n  Capsule Networks", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207533", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Capsule Networks (CapsNets) have shown improved performance\ncompared to the traditional Convolutional Neural Networks (CNNs), by encoding\nand preserving spatial relationships between the detected features in a better\nway. This is achieved through the so-called Capsules (i.e., groups of neurons)\nthat encode both the instantiation probability and the spatial information.\nHowever, one of the major hurdles in the wide adoption of CapsNets is their\ngigantic training time, which is primarily due to the relatively higher\ncomplexity of their new constituting elements that are different from CNNs. In\nthis paper, we implement different optimizations in the training loop of the\nCapsNets, and investigate how these optimizations affect their training speed\nand the accuracy. Towards this, we propose a novel framework FasTrCaps that\nintegrates multiple lightweight optimizations and a novel learning rate policy\ncalled WarmAdaBatch (that jointly performs warm restarts and adaptive batch\nsize), and steers them in an appropriate way to provide high training-loop\nspeedup at minimal accuracy loss. We also propose weight sharing for capsule\nlayers. The goal is to reduce the hardware requirements of CapsNets by removing\nunused/redundant connections and capsules, while keeping high accuracy through\ntests of different learning rate policies and batch sizes. We demonstrate that\none of the solutions generated by the FasTrCaps framework can achieve 58.6%\nreduction in the training time, while preserving the accuracy (even 0.12%\naccuracy improvement for the MNIST dataset), compared to the CapsNet by Google\nBrain. The Pareto-optimal solutions generated by FasTrCaps can be leveraged to\nrealize trade-offs between training time and achieved accuracy. We have\nopen-sourced our framework on https://github.com/Alexei95/FasTrCaps.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:51:02 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 21:42:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Bussolino", "Beatrice", ""], ["Colucci", "Alessio", ""], ["Hanif", "Muhammad Abdullah", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1905.10143", "submitter": "Hu Ding", "authors": "Hu Ding, Jiawei Huang and Haikuo Yu", "title": "The Effectiveness of Uniform Sampling for Center-Based Clustering with\n  Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering has many important applications in computer science, but\nreal-world datasets often contain outliers. Moreover, the presence of outliers\ncan make the clustering problems to be much more challenging. To reduce the\ncomplexities, various sampling methods have been proposed in past years.\nNamely, we take a small sample (uniformly or non-uniformly) from input and run\nan existing approximation algorithm on the sample. Comparing with existing\nnon-uniform sampling methods, the uniform sampling approach has several\nsignificant benefits. For example, it only needs to read the data in one-pass\nand is very easy to implement in practice. Thus, the effectiveness of uniform\nsampling for clustering with outliers is a natural and fundamental problem\ndeserving to study in both theory and practice. In this paper, we propose a new\nand unified framework for analyzing the effectiveness of uniform sampling for\nthree representative center-based clustering with outliers problems,\n$k$-center/median/means clustering with outliers. We introduce a \"significance\"\ncriterion and prove that the performance of uniform sampling depends on the\nsignificance degree of the given instance. In particular, we show that the\nsample size can be independent of the ratio $n/z$ and the dimensionality. More\nimportantly, to the best of our knowledge, our method is the first uniform\nsampling approach that allows to discard exactly $z$ outliers for these three\ncenter-based clustering with outliers problems. The results proposed in this\npaper also can be viewed as an extension of the previous sub-linear time\nalgorithms for the ordinary clustering problems (without outliers). The\nexperiments suggest that the uniform sampling method can achieve comparable\nclustering results with other existing methods, but greatly reduce the running\ntimes.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:51:46 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:43:12 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 01:49:08 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ding", "Hu", ""], ["Huang", "Jiawei", ""], ["Yu", "Haikuo", ""]]}, {"id": "1905.10144", "submitter": "Refael Vivanti", "authors": "Refael Vivanti, Talya D. Sohlberg-Baris, Shlomo Cohen, Orna Cohen", "title": "Adaptive Symmetric Reward Noising for Reinforcement Learning", "comments": "9 pages, 7 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning algorithms, though achieving impressive results\nin various fields, suffer from brittle training effects such as regression in\nresults and high sensitivity to initialization and parameters. We claim that\nsome of the brittleness stems from variance differences, i.e. when different\nenvironment areas - states and/or actions - have different rewards variance.\nThis causes two problems: First, the \"Boring Areas Trap\" in algorithms such as\nQ-learning, where moving between areas depends on the current area variance,\nand getting out of a boring area is hard due to its low variance. Second, the\n\"Manipulative Consultant\" problem, when value-estimation functions used in DQN\nand Actor-Critic algorithms influence the agent to prefer boring areas,\nregardless of the mean rewards return, as they maximize estimation precision\nrather than rewards. This sheds a new light on how exploration contribute to\ntraining, as it helps with both challenges. Cognitive experiments in humans\nshowed that noised reward signals may paradoxically improve performance. We\nexplain this using the two mentioned problems, claiming that both humans and\nalgorithms may share similar challenges. Inspired by this result, we propose\nthe Adaptive Symmetric Reward Noising (ASRN), by which we mean adding Gaussian\nnoise to rewards according to their states' estimated variance, thus avoiding\nthe two problems while not affecting the environment's mean rewards behavior.\nWe conduct our experiments in a Multi Armed Bandit problem with variance\ndifferences. We demonstrate that a Q-learning algorithm shows the brittleness\neffect in this problem, and that the ASRN scheme can dramatically improve the\nresults. We show that ASRN helps a DQN algorithm training process reach better\nresults in an end to end autonomous driving task using the AirSim driving\nsimulator.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:54:33 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Vivanti", "Refael", ""], ["Sohlberg-Baris", "Talya D.", ""], ["Cohen", "Shlomo", ""], ["Cohen", "Orna", ""]]}, {"id": "1905.10145", "submitter": "Se Jung Kwon", "authors": "Dongsoo Lee, Se Jung Kwon, Byeongwook Kim and Gu-Yeon Wei", "title": "Learning Low-Rank Approximation for CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximation is an effective model compression technique to not\nonly reduce parameter storage requirements, but to also reduce computations.\nFor convolutional neural networks (CNNs), however, well-known low-rank\napproximation methods, such as Tucker or CP decomposition, result in degraded\nmodel accuracy because decomposed layers hinder training convergence. In this\npaper, we propose a new training technique that finds a flat minimum in the\nview of low-rank approximation without a decomposed structure during training.\nBy preserving the original model structure, 2-dimensional low-rank\napproximation demanding lowering (such as im2col) is available in our proposed\nscheme. We show that CNN models can be compressed by low-rank approximation\nwith much higher compression ratio than conventional training methods while\nmaintaining or even enhancing model accuracy. We also discuss various\n2-dimensional low-rank approximation techniques for CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:56:02 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1905.10155", "submitter": "Remi Flamary", "authors": "R\\'emi Flamary, Karim Lounici, Andr\\'e Ferrari", "title": "Concentration bounds for linear Monge mapping estimation and optimal\n  transport domain adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the quality of the estimator of the linear Monge\nmapping between distributions. We provide the first concentration result on the\nlinear mapping operator and prove a sample complexity of $n^{-1/2}$ when using\nempirical estimates of first and second order moments. This result is then used\nto derive a generalization bound for domain adaptation with optimal transport.\nAs a consequence, this method approaches the performance of theoretical Bayes\npredictor under mild conditions on the covariance structure of the problem. We\nalso discuss the computational complexity of the linear mapping estimation and\nshow that when the source and target are stationary the mapping is a\nconvolution that can be estimated very efficiently using fast Fourier\ntransforms. Numerical experiments reproduce the behavior of the proven bounds\non simulated and real data for mapping estimation and domain adaptation on\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:31:34 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 10:27:58 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Flamary", "R\u00e9mi", ""], ["Lounici", "Karim", ""], ["Ferrari", "Andr\u00e9", ""]]}, {"id": "1905.10157", "submitter": "Bing Yu", "authors": "Bing Yu, Junzhao Zhang, Zhanxing Zhu", "title": "On the Learning Dynamics of Two-layer Nonlinear Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved remarkable performance in\nvarious fields, particularly in the domain of computer vision. However, why\nthis architecture works well remains to be a mystery. In this work we move a\nsmall step toward understanding the success of CNNs by investigating the\nlearning dynamics of a two-layer nonlinear convolutional neural network over\nsome specific data distributions. Rather than the typical Gaussian assumption\nfor input data distribution, we consider a more realistic setting that each\ndata point (e.g. image) contains a specific pattern determining its class\nlabel. Within this setting, we both theoretically and empirically show that\nsome convolutional filters will learn the key patterns in data and the norm of\nthese filters will dominate during the training process with stochastic\ngradient descent. And with any high probability, when the number of iterations\nis sufficiently large, the CNN model could obtain 100% accuracy over the\nconsidered data distributions. Our experiments demonstrate that for practical\nimage classification tasks our findings still hold to some extent.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:33:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Yu", "Bing", ""], ["Zhang", "Junzhao", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1905.10161", "submitter": "George Moustakides", "authors": "Kalliopi Basioti and George V. Moustakides", "title": "Optimizing Shallow Networks for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven classification that relies on neural networks is based on\noptimization criteria that involve some form of distance between the output of\nthe network and the desired label. Using the same mathematical analysis, for a\nmultitude of such measures, we can show that their optimum solution matches the\nideal likelihood ratio test classifier. In this work we introduce a different\nfamily of optimization problems which is not covered by the existing approaches\nand, therefore, opens possibilities for new training algorithms for neural\nnetwork based classification. We give examples that lead to algorithms that are\nsimple in implementation, exhibit stable convergence characteristics and are\nantagonistic to the most popular existing techniques.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:40:24 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 00:42:01 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""]]}, {"id": "1905.10163", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Takashi Matsubara, Nicolas Chauvet, Kazutaka Kanno,\n  Tianyu Yang, Atsushi Uchida", "title": "Generative adversarial network based on chaotic time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial network (GAN) is gaining increased importance in\nartificially constructing natural images and related functionalities wherein\ntwo networks called generator and discriminator are evolving through\nadversarial mechanisms. Using deep convolutional neural networks and related\ntechniques, high-resolution, highly realistic scenes, human faces, among others\nhave been generated. While GAN in general needs a large amount of genuine\ntraining data sets, it is noteworthy that vast amounts of pseudorandom numbers\nare required. Here we utilize chaotic time series generated experimentally by\nsemiconductor lasers for the latent variables of GAN whereby the inherent\nnature of chaos can be reflected or transformed into the generated output data.\nWe show that the similarity in proximity, which is a degree of robustness of\nthe generated images with respects to a minute change in the input latent\nvariables, is enhanced while the versatility as a whole is not severely\ndegraded. Furthermore, we demonstrate that the surrogate chaos time series\neliminates the signature of generated images that is originally observed\ncorresponding to the negative autocorrelation inherent in the chaos sequence.\nWe also discuss the impact of utilizing chaotic time series in retrieving\nimages from the trained generator.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:46:56 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Naruse", "Makoto", ""], ["Matsubara", "Takashi", ""], ["Chauvet", "Nicolas", ""], ["Kanno", "Kazutaka", ""], ["Yang", "Tianyu", ""], ["Uchida", "Atsushi", ""]]}, {"id": "1905.10176", "submitter": "Vasilis Syrgkanis", "authors": "Vasilis Syrgkanis, Victor Lei, Miruna Oprescu, Maggie Hei, Keith\n  Battocchi, Greg Lewis", "title": "Machine Learning Estimation of Heterogeneous Treatment Effects with\n  Instruments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of heterogeneous treatment effects with arbitrary\nmachine learning methods in the presence of unobserved confounders with the aid\nof a valid instrument. Such settings arise in A/B tests with an intent-to-treat\nstructure, where the experimenter randomizes over which user will receive a\nrecommendation to take an action, and we are interested in the effect of the\ndownstream action. We develop a statistical learning approach to the estimation\nof heterogeneous effects, reducing the problem to the minimization of an\nappropriate loss function that depends on a set of auxiliary models (each\ncorresponding to a separate prediction task). The reduction enables the use of\nall recent algorithmic advances (e.g. neural nets, forests). We show that the\nestimated effect model is robust to estimation errors in the auxiliary models,\nby showing that the loss satisfies a Neyman orthogonality criterion. Our\napproach can be used to estimate projections of the true effect model on\nsimpler hypothesis spaces. When these spaces are parametric, then the parameter\nestimates are asymptotically normal, which enables construction of confidence\nsets. We applied our method to estimate the effect of membership on downstream\nwebpage engagement on TripAdvisor, using as an instrument an intent-to-treat\nA/B test among 4 million TripAdvisor users, where some users received an easier\nmembership sign-up process. We also validate our method on synthetic data and\non public datasets for the effects of schooling on income.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 12:14:08 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 01:05:23 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 01:57:04 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Syrgkanis", "Vasilis", ""], ["Lei", "Victor", ""], ["Oprescu", "Miruna", ""], ["Hei", "Maggie", ""], ["Battocchi", "Keith", ""], ["Lewis", "Greg", ""]]}, {"id": "1905.10194", "submitter": "Zhiyuan Zhang", "authors": "Zhiyuan Zhang, Pengcheng Yang, Xuancheng Ren, Qi Su, Xu Sun", "title": "Memorized Sparse Backpropagation", "comments": "Accepted to Neurocomputing", "journal-ref": "Neurocomputing 415C (2020) pp. 397-407", "doi": "10.1016/j.neucom.2020.08.055", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network learning is usually time-consuming since backpropagation needs\nto compute full gradients and backpropagate them across multiple layers.\nDespite its success of existing works in accelerating propagation through\nsparseness, the relevant theoretical characteristics remain under-researched\nand empirical studies found that they suffer from the loss of information\ncontained in unpropagated gradients. To tackle these problems, this paper\npresents a unified sparse backpropagation framework and provides a detailed\nanalysis of its theoretical characteristics. Analysis reveals that when applied\nto a multilayer perceptron, our framework essentially performs gradient descent\nusing an estimated gradient similar enough to the true gradient, resulting in\nconvergence in probability under certain conditions. Furthermore, a simple yet\neffective algorithm named memorized sparse backpropagation (MSBP) is proposed\nto remedy the problem of information loss by storing unpropagated gradients in\nmemory for learning in the next steps. Experimental results demonstrate that\nthe proposed MSBP is effective to alleviate the information loss in traditional\nsparse backpropagation while achieving comparable acceleration.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 12:38:31 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 05:18:14 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 05:08:14 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Zhiyuan", ""], ["Yang", "Pengcheng", ""], ["Ren", "Xuancheng", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1905.10201", "submitter": "Benjamin Guedj", "authors": "Jie M. Zhang and Mark Harman and Benjamin Guedj and Earl T. Barr and\n  John Shawe-Taylor", "title": "Perturbation Validation: A New Heuristic to Validate Machine Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces Perturbation Validation (PV), a new heuristic to\nvalidate machine learning models. PV does not rely on test data. Instead, it\nperturbs training data labels, re-trains the model against the perturbed data,\nthen uses the consequent training accuracy decrease rate to assess model fit.\nPV also differs from traditional statistical approaches, which make judgements\nwithout considering label distribution. We evaluate PV on 10 real-world\ndatasets and 6 synthetic datasets. Our results demonstrate that PV is more\ndiscriminating about model fit than existing validation approaches and it\naccords well with widely-held intuitions concerning the properties of a good\nmodel fit measurement. We also show that PV complements existing validation\napproaches, allowing us to give explanations for some of the issues present in\nthe recently-debated \"apparent paradox\" that high capacity (potentially\n\"overfitted\") models may, nevertheless, exhibit good generalisation ability.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 12:45:43 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 14:47:55 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 15:12:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Zhang", "Jie M.", ""], ["Harman", "Mark", ""], ["Guedj", "Benjamin", ""], ["Barr", "Earl T.", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1905.10214", "submitter": "Th\\'eo Ryffel", "authors": "Theo Ryffel, Edouard Dufour-Sans, Romain Gay, Francis Bach, David\n  Pointcheval", "title": "Partially Encrypted Machine Learning using Functional Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on encrypted data has received a lot of attention thanks to\nrecent breakthroughs in homomorphic encryption and secure multi-party\ncomputation. It allows outsourcing computation to untrusted servers without\nsacrificing privacy of sensitive data. We propose a practical framework to\nperform partially encrypted and privacy-preserving predictions which combines\nadversarial training and functional encryption. We first present a new\nfunctional encryption scheme to efficiently compute quadratic functions so that\nthe data owner controls what can be computed but is not involved in the\ncalculation: it provides a decryption key which allows one to learn a specific\nfunction evaluation of some encrypted data. We then show how to use it in\nmachine learning to partially encrypt neural networks with quadratic activation\nfunctions at evaluation time, and we provide a thorough analysis of the\ninformation leaks based on indistinguishability of data items of the same\nlabel. Last, since most encryption schemes cannot deal with the last\nthresholding operation used for classification, we propose a training method to\nprevent selected sensitive features from leaking, which adversarially optimizes\nthe network against an adversary trying to identify these features. This is\ninteresting for several existing works using partially encrypted machine\nlearning as it comes with little reduction on the model's accuracy and\nsignificantly improves data privacy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:06:53 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 08:41:02 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 17:14:29 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 10:02:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ryffel", "Theo", ""], ["Dufour-Sans", "Edouard", ""], ["Gay", "Romain", ""], ["Bach", "Francis", ""], ["Pointcheval", "David", ""]]}, {"id": "1905.10221", "submitter": "Hedi Hadiji", "authors": "H\\'edi Hadiji (LMO)", "title": "Polynomial Cost of Adaptation for X -Armed Bandits", "comments": null, "journal-ref": "Thirty-third Conference on Neural Information Processing Systems,\n  Dec 2019, Vancouver, France", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of stochastic continuum-armed bandits, we present an algorithm\nthat adapts to the unknown smoothness of the objective function. We exhibit and\ncompute a polynomial cost of adaptation to the H{\\\"o}lder regularity for regret\nminimization. To do this, we first reconsider the recent lower bound of\nLocatelli and Carpentier [20], and define and characterize admissible rate\nfunctions. Our new algorithm matches any of these minimal rate functions. We\nprovide a finite-time analysis and a thorough discussion about asymptotic\noptimality.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:15:34 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:16:52 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hadiji", "H\u00e9di", "", "LMO"]]}, {"id": "1905.10224", "submitter": "Dominik Alfke", "authors": "Dominik Alfke and Martin Stoll", "title": "Semi-Supervised Classification on Non-Sparse Graphs Using Low-Rank Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have proven to be successful tools for\nsemi-supervised learning on graph-based datasets. For sparse graphs, linear and\npolynomial filter functions have yielded impressive results. For large\nnon-sparse graphs, however, network training and evaluation becomes\nprohibitively expensive. By introducing low-rank filters, we gain significant\nruntime acceleration and simultaneously improved accuracy. We further propose\nan architecture change mimicking techniques from Model Order Reduction in what\nwe call a reduced-order GCN. Moreover, we present how our method can also be\napplied to hypergraph datasets and how hypergraph convolution can be\nimplemented efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:32:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Alfke", "Dominik", ""], ["Stoll", "Martin", ""]]}, {"id": "1905.10227", "submitter": "Nino Antulov-Fantulin", "authors": "Thorben Funke, Tian Guo, Alen Lancic, Nino Antulov-Fantulin", "title": "Low-dimensional statistical manifold embedding of directed graphs", "comments": "camera ready version ICLR 2020", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel node embedding of directed graphs to statistical\nmanifolds, which is based on a global minimization of pairwise relative entropy\nand graph geodesics in a non-linear way. Each node is encoded with a\nprobability density function over a measurable space. Furthermore, we analyze\nthe connection between the geometrical properties of such embedding and their\nefficient learning procedure. Extensive experiments show that our proposed\nembedding is better in preserving the global geodesic information of graphs, as\nwell as outperforming existing embedding models on directed graphs in a variety\nof evaluation metrics, in an unsupervised setting.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:35:48 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:43:37 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 18:59:25 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Funke", "Thorben", ""], ["Guo", "Tian", ""], ["Lancic", "Alen", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1905.10240", "submitter": "Yunpeng Li", "authors": "Yunpeng Li, Dominik Roblek, Marco Tagliasacchi", "title": "From Here to There: Video Inbetweening Using Direct 3D Convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of generating plausible and diverse video sequences,\nwhen we are only given a start and an end frame. This task is also known as\ninbetweening, and it belongs to the broader area of stochastic video\ngeneration, which is generally approached by means of recurrent neural networks\n(RNN). In this paper, we propose instead a fully convolutional model to\ngenerate video sequences directly in the pixel domain. We first obtain a latent\nvideo representation using a stochastic fusion mechanism that learns how to\nincorporate information from the start and end frames. Our model learns to\nproduce such latent representation by progressively increasing the temporal\nresolution, and then decode in the spatiotemporal domain using 3D convolutions.\nThe model is trained end-to-end by minimizing an adversarial loss. Experiments\non several widely-used benchmark datasets show that it is able to generate\nmeaningful and diverse in-between video sequences, according to both\nquantitative and qualitative evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:01:08 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 07:55:23 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 07:54:06 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Yunpeng", ""], ["Roblek", "Dominik", ""], ["Tagliasacchi", "Marco", ""]]}, {"id": "1905.10259", "submitter": "Benjamin Guedj", "authors": "Ga\\\"el Letarte and Pascal Germain and Benjamin Guedj and Fran\\c{c}ois\n  Laviolette", "title": "Dichotomize and Generalize: PAC-Bayesian Binary Activated Deep Neural\n  Networks", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a comprehensive study of multilayer neural networks with binary\nactivation, relying on the PAC-Bayesian theory. Our contributions are twofold:\n(i) we develop an end-to-end framework to train a binary activated deep neural\nnetwork, (ii) we provide nonvacuous PAC-Bayesian generalization bounds for\nbinary activated deep neural networks. Our results are obtained by minimizing\nthe expected loss of an architecture-dependent aggregation of binary activated\ndeep neural networks. Our analysis inherently overcomes the fact that binary\nactivation function is non-differentiable. The performance of our approach is\nassessed on a thorough numerical experiment protocol on real-life datasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:37:38 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:52:11 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 14:22:07 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 20:18:17 GMT"}, {"version": "v5", "created": "Tue, 4 Feb 2020 13:48:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Letarte", "Ga\u00ebl", ""], ["Germain", "Pascal", ""], ["Guedj", "Benjamin", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "1905.10261", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Approximation Ratios of Graph Neural Networks for Combinatorial Problems", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, from a theoretical perspective, we study how powerful graph\nneural networks (GNNs) can be for learning approximation algorithms for\ncombinatorial problems. To this end, we first establish a new class of GNNs\nthat can solve a strictly wider variety of problems than existing GNNs. Then,\nwe bridge the gap between GNN theory and the theory of distributed local\nalgorithms. We theoretically demonstrate that the most powerful GNN can learn\napproximation algorithms for the minimum dominating set problem and the minimum\nvertex cover problem with some approximation ratios with the aid of the theory\nof distributed local algorithms. We also show that most of the existing GNNs\nsuch as GIN, GAT, GCN, and GraphSAGE cannot perform better than with these\nratios. This paper is the first to elucidate approximation ratios of GNNs for\ncombinatorial problems. Furthermore, we prove that adding coloring or\nweak-coloring to each node feature improves these approximation ratios. This\nindicates that preprocessing and feature engineering theoretically strengthen\nmodel capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:41:17 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 08:45:50 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1905.10264", "submitter": "Zhiqin Xu", "authors": "Yaoyu Zhang, Zhi-Qin John Xu, Tao Luo, Zheng Ma", "title": "Explicitizing an Implicit Bias of the Frequency Principle in Two-layer\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It remains a puzzle that why deep neural networks (DNNs), with more\nparameters than samples, often generalize well. An attempt of understanding\nthis puzzle is to discover implicit biases underlying the training process of\nDNNs, such as the Frequency Principle (F-Principle), i.e., DNNs often fit\ntarget functions from low to high frequencies. Inspired by the F-Principle, we\npropose an effective model of linear F-Principle (LFP) dynamics which\naccurately predicts the learning results of two-layer ReLU neural networks\n(NNs) of large widths. This LFP dynamics is rationalized by a linearized mean\nfield residual dynamics of NNs. Importantly, the long-time limit solution of\nthis LFP dynamics is equivalent to the solution of a constrained optimization\nproblem explicitly minimizing an FP-norm, in which higher frequencies of\nfeasible solutions are more heavily penalized. Using this optimization\nformulation, an a priori estimate of the generalization error bound is\nprovided, revealing that a higher FP-norm of the target function increases the\ngeneralization error. Overall, by explicitizing the implicit bias of the\nF-Principle as an explicit penalty for two-layer NNs, our work makes a step\ntowards a quantitative understanding of the learning and generalization of\ngeneral DNNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:45:37 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhang", "Yaoyu", ""], ["Xu", "Zhi-Qin John", ""], ["Luo", "Tao", ""], ["Ma", "Zheng", ""]]}, {"id": "1905.10268", "submitter": "Anna Bosman", "authors": "Anna Sergeevna Bosman, Andries Engelbrecht, Mard\\'e Helbig", "title": "Loss Surface Modality of Feed-Forward Neural Network Architectures", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued in the past that high-dimensional neural networks do not\nexhibit local minima capable of trapping an optimisation algorithm. However,\nthe relationship between loss surface modality and the neural architecture\nparameters, such as the number of hidden neurons per layer and the number of\nhidden layers, remains poorly understood. This study employs fitness landscape\nanalysis to study the modality of neural network loss surfaces under various\nfeed-forward architecture settings. An increase in the problem dimensionality\nis shown to yield a more searchable and more exploitable loss surface. An\nincrease in the hidden layer width is shown to effectively reduce the number of\nlocal minima, and simplify the shape of the global attractor. An increase in\nthe architecture depth is shown to sharpen the global attractor, thus making it\nmore exploitable.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:59:48 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 14:02:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Bosman", "Anna Sergeevna", ""], ["Engelbrecht", "Andries", ""], ["Helbig", "Mard\u00e9", ""]]}, {"id": "1905.10271", "submitter": "Motonobu Kanagawa", "authors": "Motonobu Kanagawa, Philipp Hennig", "title": "Convergence Guarantees for Adaptive Bayesian Quadrature Methods", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Bayesian quadrature (ABQ) is a powerful approach to numerical\nintegration that empirically compares favorably with Monte Carlo integration on\nproblems of medium dimensionality (where non-adaptive quadrature is not\ncompetitive). Its key ingredient is an acquisition function that changes as a\nfunction of previously collected values of the integrand. While this adaptivity\nappears to be empirically powerful, it complicates analysis. Consequently,\nthere are no theoretical guarantees so far for this class of methods. In this\nwork, for a broad class of adaptive Bayesian quadrature methods, we prove\nconsistency, deriving non-tight but informative convergence rates. To do so we\nintroduce a new concept we call weak adaptivity. Our results identify a large\nand flexible class of adaptive Bayesian quadrature rules as consistent, within\nwhich practitioners can develop empirically efficient methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:02:59 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 12:38:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kanagawa", "Motonobu", ""], ["Hennig", "Philipp", ""]]}, {"id": "1905.10291", "submitter": "Liwei Song", "authors": "Liwei Song, Reza Shokri, Prateek Mittal", "title": "Privacy Risks of Securing Machine Learning Models against Adversarial\n  Examples", "comments": "ACM CCS 2019, code is available at\n  https://github.com/inspire-group/privacy-vs-robustness", "journal-ref": null, "doi": "10.1145/3319535.3354211", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arms race between attacks and defenses for machine learning models has\ncome to a forefront in recent years, in both the security community and the\nprivacy community. However, one big limitation of previous research is that the\nsecurity domain and the privacy domain have typically been considered\nseparately. It is thus unclear whether the defense methods in one domain will\nhave any unexpected impact on the other domain.\n  In this paper, we take a step towards resolving this limitation by combining\nthe two domains. In particular, we measure the success of membership inference\nattacks against six state-of-the-art defense methods that mitigate the risk of\nadversarial examples (i.e., evasion attacks). Membership inference attacks\ndetermine whether or not an individual data record has been part of a model's\ntraining set. The accuracy of such attacks reflects the information leakage of\ntraining algorithms about individual members of the training set. Adversarial\ndefense methods against adversarial examples influence the model's decision\nboundaries such that model predictions remain unchanged for a small area around\neach input. However, this objective is optimized on training data. Thus,\nindividual data records in the training set have a significant influence on\nrobust models. This makes the models more vulnerable to inference attacks.\n  To perform the membership inference attacks, we leverage the existing\ninference methods that exploit model predictions. We also propose two new\ninference methods that exploit structural properties of robust models on\nadversarially perturbed data. Our experimental evaluation demonstrates that\ncompared with the natural training (undefended) approach, adversarial defense\nmethods can indeed increase the target model's risk against membership\ninference attacks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:37:22 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:34:47 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 19:05:32 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Liwei", ""], ["Shokri", "Reza", ""], ["Mittal", "Prateek", ""]]}, {"id": "1905.10295", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou and Amos Storkey", "title": "Learning to learn via Self-Critique", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot learning, a machine learning system learns from a small set of\nlabelled examples relating to a specific task, such that it can generalize to\nnew examples of the same task. Given the limited availability of labelled\nexamples in such tasks, we wish to make use of all the information we can.\nUsually a model learns task-specific information from a small training-set\n(support-set) to predict on an unlabelled validation set (target-set). The\ntarget-set contains additional task-specific information which is not utilized\nby existing few-shot learning methods. Making use of the target-set examples\nvia transductive learning requires approaches beyond the current methods; at\ninference time, the target-set contains only unlabelled input data-points, and\nso discriminative learning cannot be used. In this paper, we propose a\nframework called Self-Critique and Adapt or SCA, which learns to learn a\nlabel-free loss function, parameterized as a neural network. A base-model\nlearns on a support-set using existing methods (e.g. stochastic gradient\ndescent combined with the cross-entropy loss), and then is updated for the\nincoming target-task using the learnt loss function. This label-free loss\nfunction is itself optimized such that the learnt model achieves higher\ngeneralization performance. Experiments demonstrate that SCA offers\nsubstantially reduced error-rates compared to baselines which only adapt on the\nsupport-set, and results in state of the art benchmark performance on\nMini-ImageNet and Caltech-UCSD Birds 200.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:49:05 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 16:04:37 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 13:35:55 GMT"}, {"version": "v4", "created": "Sun, 16 Jun 2019 15:37:23 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 06:30:24 GMT"}, {"version": "v6", "created": "Thu, 30 Jan 2020 18:43:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Antoniou", "Antreas", ""], ["Storkey", "Amos", ""]]}, {"id": "1905.10296", "submitter": "Florian Kraus", "authors": "Florian Kraus and Klaus Dietmayer", "title": "Uncertainty Estimation in One-Stage Object Detection", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Conference (ITSC), 2019,\n  pp. 53-60", "doi": "10.1109/ITSC.2019.8917494", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environment perception is the task for intelligent vehicles on which all\nsubsequent steps rely. A key part of perception is to safely detect other road\nusers such as vehicles, pedestrians, and cyclists. With modern deep learning\ntechniques huge progress was made over the last years in this field. However\nsuch deep learning based object detection models cannot predict how certain\nthey are in their predictions, potentially hampering the performance of later\nsteps such as tracking or sensor fusion. We present a viable approaches to\nestimate uncertainty in an one-stage object detector, while improving the\ndetection performance of the baseline approach. The proposed model is evaluated\non a large scale automotive pedestrian dataset. Experimental results show that\nthe uncertainty outputted by our system is coupled with detection accuracy and\nthe occlusion level of pedestrians.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:51:59 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 11:13:58 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Kraus", "Florian", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "1905.10307", "submitter": "Murray Shanahan", "authors": "Murray Shanahan, Kyriacos Nikiforou, Antonia Creswell, Christos\n  Kaplanis, David Barrett, and Marta Garnelo", "title": "An Explicitly Relational Neural Network Architecture", "comments": "In Proceedings ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a view to bridging the gap between deep learning and symbolic AI, we\npresent a novel end-to-end neural network architecture that learns to form\npropositional representations with an explicitly relational structure from raw\npixel data. In order to evaluate and analyse the architecture, we introduce a\nfamily of simple visual relational reasoning tasks of varying complexity. We\nshow that the proposed architecture, when pre-trained on a curriculum of such\ntasks, learns to generate reusable representations that better facilitate\nsubsequent learning on previously unseen tasks when compared to a number of\nbaseline architectures. The workings of a successfully trained model are\nvisualised to shed some light on how the architecture functions.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:03:06 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:49:10 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 10:44:56 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 13:36:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Shanahan", "Murray", ""], ["Nikiforou", "Kyriacos", ""], ["Creswell", "Antonia", ""], ["Kaplanis", "Christos", ""], ["Barrett", "David", ""], ["Garnelo", "Marta", ""]]}, {"id": "1905.10308", "submitter": "Dell Zhang", "authors": "Dan A. Calian, Peter Roelants, Jacques Cali, Ben Carr, Krishna Dubba,\n  John E. Reid, Dell Zhang", "title": "SCRAM: Spatially Coherent Randomized Attention Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms and non-local mean operations in general are key\ningredients in many state-of-the-art deep learning techniques. In particular,\nthe Transformer model based on multi-head self-attention has recently achieved\ngreat success in natural language processing and computer vision. However, the\nvanilla algorithm computing the Transformer of an image with n pixels has\nO(n^2) complexity, which is often painfully slow and sometimes prohibitively\nexpensive for large-scale image data. In this paper, we propose a fast\nrandomized algorithm --- SCRAM --- that only requires O(n log(n)) time to\nproduce an image attention map. Such a dramatic acceleration is attributed to\nour insight that attention maps on real-world images usually exhibit (1)\nspatial coherence and (2) sparse structure. The central idea of SCRAM is to\nemploy PatchMatch, a randomized correspondence algorithm, to quickly pinpoint\nthe most compatible key (argmax) for each query first, and then exploit that\nknowledge to design a sparse approximation to non-local mean operations. Using\nthe argmax (mode) to dynamically construct the sparse approximation\ndistinguishes our algorithm from all of the existing sparse approximate methods\nand makes it very efficient. Moreover, SCRAM is a broadly applicable\napproximation to any non-local mean layer in contrast to some other sparse\napproximations that can only approximate self-attention. Our preliminary\nexperimental results suggest that SCRAM is indeed promising for speeding up or\nscaling up the computation of attention maps in the Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:03:44 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Calian", "Dan A.", ""], ["Roelants", "Peter", ""], ["Cali", "Jacques", ""], ["Carr", "Ben", ""], ["Dubba", "Krishna", ""], ["Reid", "John E.", ""], ["Zhang", "Dell", ""]]}, {"id": "1905.10310", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl, Christian Wachinger", "title": "Adversarial Learned Molecular Graph Inference and Generation", "comments": "Accepted at The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML PKDD); Code\n  at https://github.com/ai-med/almgig", "journal-ref": null, "doi": "10.1007/978-3-030-67661-2_11", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent methods for generating novel molecules use graph representations of\nmolecules and employ various forms of graph convolutional neural networks for\ninference. However, training requires solving an expensive graph isomorphism\nproblem, which previous approaches do not address or solve only approximately.\nIn this work, we propose ALMGIG, a likelihood-free adversarial learning\nframework for inference and de novo molecule generation that avoids explicitly\ncomputing a reconstruction loss. Our approach extends generative adversarial\nnetworks by including an adversarial cycle-consistency loss to implicitly\nenforce the reconstruction property. To capture properties unique to molecules,\nsuch as valence, we extend the Graph Isomorphism Network to multi-graphs. To\nquantify the performance of models, we propose to compute the distance between\ndistributions of physicochemical properties with the 1-Wasserstein distance. We\ndemonstrate that ALMGIG more accurately learns the distribution over the space\nof molecules than all baselines. Moreover, it can be utilized for drug\ndiscovery by efficiently searching the space of molecules using molecules'\ncontinuous latent representation. Our code is available at\nhttps://github.com/ai-med/almgig\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:09:14 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:29:55 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Wachinger", "Christian", ""]]}, {"id": "1905.10324", "submitter": "J. D. Curt\\'o", "authors": "J. D. Curt\\'o and I. C. Zarza and Kris Kitani and Irwin King and\n  Michael R. Lyu", "title": "Doctor of Crosswise: Reducing Over-parametrization in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dr. of Crosswise proposes a new architecture to reduce over-parametrization\nin Neural Networks. It introduces an operand for rapid computation in the\nframework of Deep Learning that leverages learned weights. The formalism is\ndescribed in detail providing both an accurate elucidation of the mechanics and\nthe theoretical implications.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:32:25 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 19:00:18 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 17:07:07 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Curt\u00f3", "J. D.", ""], ["Zarza", "I. C.", ""], ["Kitani", "Kris", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1905.10328", "submitter": "Gianluca Stringhini", "authors": "Yun Shen, Enrico Mariconti, Pierre-Antoine Vervier, Gianluca\n  Stringhini", "title": "Tiresias: Predicting Security Events Through Deep Learning", "comments": null, "journal-ref": "ACM SIGSAC Conference on Computer and Communications Security\n  (CCS), 2018", "doi": "10.1145/3243734.3243811", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased complexity of modern computer attacks, there is a need for\ndefenders not only to detect malicious activity as it happens, but also to\npredict the specific steps that will be taken by an adversary when performing\nan attack. However this is still an open research problem, and previous\nresearch in predicting malicious events only looked at binary outcomes (e.g.,\nwhether an attack would happen or not), but not at the specific steps that an\nattacker would undertake. To fill this gap we present Tiresias, a system that\nleverages Recurrent Neural Networks (RNNs) to predict future events on a\nmachine, based on previous observations. We test Tiresias on a dataset of 3.4\nbillion security events collected from a commercial intrusion prevention\nsystem, and show that our approach is effective in predicting the next event\nthat will occur on a machine with a precision of up to 0.93. We also show that\nthe models learned by Tiresias are reasonably stable over time, and provide a\nmechanism that can identify sudden drops in precision and trigger a retraining\nof the system. Finally, we show that the long-term memory typical of RNNs is\nkey in performing event prediction, rendering simpler methods not up to the\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:41:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Shen", "Yun", ""], ["Mariconti", "Enrico", ""], ["Vervier", "Pierre-Antoine", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1905.10330", "submitter": "Eric Strobl", "authors": "Eric V. Strobl, Shyam Visweswaran", "title": "Dirac Delta Regression: Conditional Density Estimation with Clinical\n  Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized medicine seeks to identify the causal effect of treatment for a\nparticular patient as opposed to a clinical population at large. Most\ninvestigators estimate such personalized treatment effects by regressing the\noutcome of a randomized clinical trial (RCT) on patient covariates. The\nrealized value of the outcome may however lie far from the conditional\nexpectation. We therefore introduce a method called Dirac Delta Regression\n(DDR) that estimates the entire conditional density from RCT data in order to\nvisualize the probabilities across all possible treatment outcomes. DDR\ntransforms the outcome into a set of asymptotically Dirac delta distributions\nand then estimates the density using non-linear regression. The algorithm can\nidentify significant patient-specific treatment effects even when no population\nlevel effect exists. Moreover, DDR outperforms state-of-the-art algorithms in\nconditional density estimation on average regardless of the need for causal\ninference.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:42:56 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Strobl", "Eric V.", ""], ["Visweswaran", "Shyam", ""]]}, {"id": "1905.10336", "submitter": "Rekha Singhal Dr.", "authors": "Rekha Singhal, Nathan Zhang, Luigi Nardi, Muhammad Shahbaz, Kunle\n  Olukotun", "title": "Polystore++: Accelerated Polystore System for Heterogeneous Workloads", "comments": "11 pages, Accepted in ICDCS 2019", "journal-ref": "ICDCS 2019", "doi": null, "report-no": null, "categories": "cs.AR cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern real-time business analytic consist of heterogeneous workloads (e.g,\ndatabase queries, graph processing, and machine learning). These analytic\napplications need programming environments that can capture all aspects of the\nconstituent workloads (including data models they work on and movement of data\nacross processing engines). Polystore systems suit such applications; however,\nthese systems currently execute on CPUs and the slowdown of Moore's Law means\nthey cannot meet the performance and efficiency requirements of modern\nworkloads. We envision Polystore++, an architecture to accelerate existing\npolystore systems using hardware accelerators (e.g, FPGAs, CGRAs, and GPUs).\nPolystore++ systems can achieve high performance at low power by identifying\nand offloading components of a polystore system that are amenable to\nacceleration using specialized hardware. Building a Polystore++ system is\nchallenging and introduces new research problems motivated by the use of\nhardware accelerators (e.g, optimizing and mapping query plans across\nheterogeneous computing units and exploiting hardware pipelining and\nparallelism to improve performance). In this paper, we discuss these challenges\nin detail and list possible approaches to address these problems.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:01:36 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Singhal", "Rekha", ""], ["Zhang", "Nathan", ""], ["Nardi", "Luigi", ""], ["Shahbaz", "Muhammad", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1905.10337", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li", "title": "What Can ResNet Learn Efficiently, Going Beyond Kernels?", "comments": "V2 slightly improves lower bound, V3 strengthens experiments and adds\n  citation to \"backward feature correction\" which is an even stronger form of\n  hierarchical learning [2]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can neural networks such as ResNet efficiently learn CIFAR-10 with test\naccuracy more than 96%, while other methods, especially kernel methods, fall\nrelatively behind? Can we more provide theoretical justifications for this gap?\n  Recently, there is an influential line of work relating neural networks to\nkernels in the over-parameterized regime, proving they can learn certain\nconcept class that is also learnable by kernels with similar test error. Yet,\ncan neural networks provably learn some concept class BETTER than kernels?\n  We answer this positively in the distribution-free setting. We prove neural\nnetworks can efficiently learn a notable class of functions, including those\ndefined by three-layer residual networks with smooth activations, without any\ndistributional assumption. At the same time, we prove there are simple\nfunctions in this class such that with the same number of training examples,\nthe test error obtained by neural networks can be MUCH SMALLER than ANY kernel\nmethod, including neural tangent kernels (NTK).\n  The main intuition is that multi-layer neural networks can implicitly perform\nhierarchical learning using different layers, which reduces the sample\ncomplexity comparing to \"one-shot\" learning algorithms such as kernel methods.\nIn a follow-up work [2], this theory of hierarchical learning is further\nstrengthened to incorporate the \"backward feature correction\" process when\ntraining deep networks.\n  In the end, we also prove a computation complexity advantage of ResNet with\nrespect to other learning methods including linear regression over arbitrary\nfeature mappings.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:02:51 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 07:25:18 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 17:25:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1905.10345", "submitter": "Iddo Drori", "authors": "Iddo Drori, Yamuna Krishnamurthy, Raoni Lourenco, Remi Rampin,\n  Kyunghyun Cho, Claudio Silva, Juliana Freire", "title": "Automatic Machine Learning by Pipeline Synthesis using Model-Based\n  Reinforcement Learning and a Grammar", "comments": "ICML Workshop on Automated Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning is an important problem in the forefront of\nmachine learning. The strongest AutoML systems are based on neural networks,\nevolutionary algorithms, and Bayesian optimization. Recently AlphaD3M reached\nstate-of-the-art results with an order of magnitude speedup using reinforcement\nlearning with self-play. In this work we extend AlphaD3M by using a pipeline\ngrammar and a pre-trained model which generalizes from many different datasets\nand similar tasks. Our results demonstrate improved performance compared with\nour earlier work and existing methods on AutoML benchmark datasets for\nclassification and regression tasks. In the spirit of reproducible research we\nmake our data, models, and code publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:27:10 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Drori", "Iddo", ""], ["Krishnamurthy", "Yamuna", ""], ["Lourenco", "Raoni", ""], ["Rampin", "Remi", ""], ["Cho", "Kyunghyun", ""], ["Silva", "Claudio", ""], ["Freire", "Juliana", ""]]}, {"id": "1905.10347", "submitter": "Dustin Tran", "authors": "Dustin Tran, Keyon Vafa, Kumar Krishna Agrawal, Laurent Dinh, Ben\n  Poole", "title": "Discrete Flows: Invertible Generative Models of Discrete Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While normalizing flows have led to significant advances in modeling\nhigh-dimensional continuous distributions, their applicability to discrete\ndistributions remains unknown. In this paper, we show that flows can in fact be\nextended to discrete events---and under a simple change-of-variables formula\nnot requiring log-determinant-Jacobian computations. Discrete flows have\nnumerous applications. We consider two flow architectures: discrete\nautoregressive flows that enable bidirectionality, allowing, for example,\ntokens in text to depend on both left-to-right and right-to-left contexts in an\nexact language model; and discrete bipartite flows that enable efficient\nnon-autoregressive generation as in RealNVP. Empirically, we find that discrete\nautoregressive flows outperform autoregressive baselines on synthetic discrete\ndistributions, an addition task, and Potts models; and bipartite flows can\nobtain competitive performance with autoregressive baselines on character-level\nlanguage modeling for Penn Tree Bank and text8.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:27:54 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Tran", "Dustin", ""], ["Vafa", "Keyon", ""], ["Agrawal", "Kumar Krishna", ""], ["Dinh", "Laurent", ""], ["Poole", "Ben", ""]]}, {"id": "1905.10350", "submitter": "Ivan Lobov", "authors": "Ivan Lobov, Sergey Ivanov", "title": "Unsupervised Community Detection with Modularity-Based Attention Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we take a problem of unsupervised nodes clustering on graphs\nand show how recent advances in attention models can be applied successfully in\na \"hard\" regime of the problem. We propose an unsupervised algorithm that\nencodes Bethe Hessian embeddings by optimizing soft modularity loss and argue\nthat our model is competitive to both classical and Graph Neural Network (GNN)\nmodels while it can be trained on a single graph.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:22:51 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lobov", "Ivan", ""], ["Ivanov", "Sergey", ""]]}, {"id": "1905.10360", "submitter": "Roy Frostig", "authors": "Vitaly Feldman, Roy Frostig, Moritz Hardt", "title": "The advantages of multiple classes for reducing overfitting from test\n  set reuse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessive reuse of holdout data can lead to overfitting. However, there is\nlittle concrete evidence of significant overfitting due to holdout reuse in\npopular multiclass benchmarks today. Known results show that, in the\nworst-case, revealing the accuracy of $k$ adaptively chosen classifiers on a\ndata set of size $n$ allows to create a classifier with bias of\n$\\Theta(\\sqrt{k/n})$ for any binary prediction problem. We show a new upper\nbound of $\\tilde O(\\max\\{\\sqrt{k\\log(n)/(mn)},k/n\\})$ on the worst-case bias\nthat any attack can achieve in a prediction problem with $m$ classes. Moreover,\nwe present an efficient attack that achieve a bias of $\\Omega(\\sqrt{k/(m^2\nn)})$ and improves on previous work for the binary setting ($m=2$). We also\npresent an inefficient attack that achieves a bias of $\\tilde\\Omega(k/n)$.\nComplementing our theoretical work, we give new practical attacks to\nstress-test multiclass benchmarks by aiming to create as large a bias as\npossible with a given number of queries. Our experiments show that the\nadditional uncertainty of prediction with a large number of classes indeed\nmitigates the effect of our best attacks.\n  Our work extends developments in understanding overfitting due to adaptive\ndata analysis to multiclass prediction problems. It also bears out the\nsurprising fact that multiclass prediction problems are significantly more\nrobust to overfitting when reusing a test (or holdout) dataset. This offers an\nexplanation as to why popular multiclass prediction benchmarks, such as\nImageNet, may enjoy a longer lifespan than what intuition from literature on\nbinary classification suggests.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:59:32 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Feldman", "Vitaly", ""], ["Frostig", "Roy", ""], ["Hardt", "Moritz", ""]]}, {"id": "1905.10363", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Eric Falk, Radu State, Jean Hilger", "title": "User-Device Authentication in Mobile Banking using APHEN for Paratuck2\n  Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new financial European regulations such as PSD2 are changing the retail\nbanking services. Noticeably, the monitoring of the personal expenses is now\nopened to other institutions than retail banks. Nonetheless, the retail banks\nare looking to leverage the user-device authentication on the mobile banking\napplications to enhance the personal financial advertisement. To address the\nprofiling of the authentication, we rely on tensor decomposition, a higher\ndimensional analogue of matrix decomposition. We use Paratuck2, which expresses\na tensor as a multiplication of matrices and diagonal tensors, because of the\nimbalance between the number of users and devices. We highlight why Paratuck2\nis more appropriate in this case than the popular CP tensor decomposition,\nwhich decomposes a tensor as a sum of rank-one tensors. However, the\ncomputation of Paratuck2 is computational intensive. We propose a new\nAPproximate HEssian-based Newton resolution algorithm, APHEN, capable of\nsolving Paratuck2 more accurately and faster than the other popular approaches\nbased on alternating least square or gradient descent. The results of Paratuck2\nare used for the predictions of users' authentication with neural networks. We\napply our method for the concrete case of targeting clients for financial\nadvertising campaigns based on the authentication events generated by mobile\nbanking applications.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:38:32 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Charlier", "Jeremy", ""], ["Falk", "Eric", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.10371", "submitter": "\\c{C}a\\u{g}lar Aytekin", "authors": "Caglar Aytekin, Francesco Cricri, Antti Hallapuro, Jani Lainema, Emre\n  Aksu and Miska Hannuksela", "title": "A Compression Objective and a Cycle Loss for Neural Image Compression", "comments": "Accepted in Challenge and Workshop on Learned Image Compression\n  (CLIC) as a part of CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we propose two objective terms for neural image\ncompression: a compression objective and a cycle loss. These terms are applied\non the encoder output of an autoencoder and are used in combination with\nreconstruction losses. The compression objective encourages sparsity and low\nentropy in the activations. The cycle loss term represents the distortion\nbetween encoder outputs computed from the original image and from the\nreconstructed image (code-domain distortion). We train different autoencoders\nby using the compression objective in combination with different losses: a)\nMSE, b) MSE and MSSSIM, c) MSE, MS-SSIM and cycle loss. We observe that images\nencoded by these differently-trained autoencoders fall into different points of\nthe perception-distortion curve (while having similar bit-rates). In\nparticular, MSE-only training favors low image-domain distortion, whereas cycle\nloss training favors high perceptual quality.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:33:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Aytekin", "Caglar", ""], ["Cricri", "Francesco", ""], ["Hallapuro", "Antti", ""], ["Lainema", "Jani", ""], ["Aksu", "Emre", ""], ["Hannuksela", "Miska", ""]]}, {"id": "1905.10389", "submitter": "Lin Yang", "authors": "Lin F. Yang, Mengdi Wang", "title": "Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and\n  Regret Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in reinforcement learning (RL) suffers from the curse of\ndimensionality when the state-action space is large. A common practice is to\nparameterize the high-dimensional value and policy functions using given\nfeatures. However existing methods either have no theoretical guarantee or\nsuffer a regret that is exponential in the planning horizon $H$. In this paper,\nwe propose an online RL algorithm, namely the MatrixRL, that leverages ideas\nfrom linear bandit to learn a low-dimensional representation of the probability\ntransition model while carefully balancing the exploitation-exploration\ntradeoff. We show that MatrixRL achieves a regret bound ${O}\\big(H^2d\\log\nT\\sqrt{T}\\big)$ where $d$ is the number of features. MatrixRL has an equivalent\nkernelized version, which is able to work with an arbitrary kernel Hilbert\nspace without using explicit features. In this case, the kernelized MatrixRL\nsatisfies a regret bound ${O}\\big(H^2\\widetilde{d}\\log T\\sqrt{T}\\big)$, where\n$\\widetilde{d}$ is the effective dimension of the kernel space. To our best\nknowledge, for RL using features or kernels, our results are the first regret\nbounds that are near-optimal in time $T$ and dimension $d$ (or $\\widetilde{d}$)\nand polynomial in the planning horizon $H$.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:02:39 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 07:28:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Yang", "Lin F.", ""], ["Wang", "Mengdi", ""]]}, {"id": "1905.10392", "submitter": "Aniket Anand Deshmukh", "authors": "Aniket Anand Deshmukh, Yunwen Lei, Srinagesh Sharma, Urun Dogan, James\n  W. Cutler, Clayton Scott", "title": "A Generalization Error Bound for Multi-class Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization is the problem of assigning labels to an unlabeled data\nset, given several similar data sets for which labels have been provided.\nDespite considerable interest in this problem over the last decade, there has\nbeen no theoretical analysis in the setting of multi-class classification. In\nthis work, we study a kernel-based learning algorithm and establish a\ngeneralization error bound that scales logarithmically in the number of\nclasses, matching state-of-the-art bounds for multi-class classification in the\nconventional learning setting. We also demonstrate empirically that the\nproposed algorithm achieves significant performance gains compared to a pooling\nstrategy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:03:27 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Deshmukh", "Aniket Anand", ""], ["Lei", "Yunwen", ""], ["Sharma", "Srinagesh", ""], ["Dogan", "Urun", ""], ["Cutler", "James W.", ""], ["Scott", "Clayton", ""]]}, {"id": "1905.10395", "submitter": "Wenbo Gao", "authors": "Yunfei Teng, Wenbo Gao, Francois Chalus, Anna Choromanska, Donald\n  Goldfarb, Adrian Weller", "title": "Leader Stochastic Gradient Descent for Distributed Training of Deep\n  Learning Models", "comments": "NeurIPS 2019. 25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed optimization under communication constraints for\ntraining deep learning models. We propose a new algorithm, whose parameter\nupdates rely on two forces: a regular gradient step, and a corrective direction\ndictated by the currently best-performing worker (leader). Our method differs\nfrom the parameter-averaging scheme EASGD in a number of ways: (i) our\nobjective formulation does not change the location of stationary points\ncompared to the original optimization problem; (ii) we avoid convergence\ndecelerations caused by pulling local workers descending to different local\nminima to each other (i.e. to the average of their parameters); (iii) our\nupdate by design breaks the curse of symmetry (the phenomenon of being trapped\nin poorly generalizing sub-optimal solutions in symmetric non-convex\nlandscapes); and (iv) our approach is more communication efficient since it\nbroadcasts only parameters of the leader rather than all workers. We provide\ntheoretical analysis of the batch version of the proposed algorithm, which we\ncall Leader Gradient Descent (LGD), and its stochastic variant (LSGD). Finally,\nwe implement an asynchronous version of our algorithm and extend it to the\nmulti-leader setting, where we form groups of workers, each represented by its\nown local leader (the best performer in a group), and update each worker with a\ncorrective direction comprised of two attractive forces: one to the local, and\none to the global leader (the best performer among all workers). The\nmulti-leader setting is well-aligned with current hardware architecture, where\nlocal workers forming a group lie within a single computational node and\ndifferent groups correspond to different nodes. For training convolutional\nneural networks, we empirically demonstrate that our approach compares\nfavorably to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:12:06 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 19:14:51 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Teng", "Yunfei", ""], ["Gao", "Wenbo", ""], ["Chalus", "Francois", ""], ["Choromanska", "Anna", ""], ["Goldfarb", "Donald", ""], ["Weller", "Adrian", ""]]}, {"id": "1905.10396", "submitter": "Kailiang Wu", "authors": "Kailiang Wu, Tong Qin, Dongbin Xiu", "title": "Structure-preserving Method for Reconstructing Unknown Hamiltonian\n  Systems from Trajectory Data", "comments": "27 pages, 19 figures", "journal-ref": "SIAM Journal on Scientific Computing 42 (6), A3704--A3729, 2020", "doi": "10.1137/19M1264011", "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical approach for approximating unknown Hamiltonian systems\nusing observation data. A distinct feature of the proposed method is that it is\nstructure-preserving, in the sense that it enforces conservation of the\nreconstructed Hamiltonian. This is achieved by directly approximating the\nunderlying unknown Hamiltonian, rather than the right-hand-side of the\ngoverning equations. We present the technical details of the proposed algorithm\nand its error estimate in a special case, along with a practical de-noising\nprocedure to cope with noisy data. A set of numerical examples are then\npresented to demonstrate the structure-preserving property and effectiveness of\nthe algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:12:19 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:59:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Kailiang", ""], ["Qin", "Tong", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1905.10399", "submitter": "Josef Schlittenlacher", "authors": "Josef Schlittenlacher, Richard E. Turner, Brian C. J. Moore", "title": "Fast computation of loudness using a deep neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper introduces a deep neural network (DNN) for predicting the\ninstantaneous loudness of a sound from its time waveform. The DNN was trained\nusing the output of a more complex model, called the Cambridge loudness model.\nWhile a modern PC can perform a few hundred loudness computations per second\nusing the Cambridge loudness model, it can perform more than 100,000 per second\nusing the DNN, allowing real-time calculation of loudness. The root-mean-square\ndeviation between the predictions of instantaneous loudness level using the two\nmodels was less than 0.5 phon for unseen types of sound. We think that the\ngeneral approach of simulating a complex perceptual model by a much faster DNN\ncan be applied to other perceptual models to make them run in real time.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:28:39 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Schlittenlacher", "Josef", ""], ["Turner", "Richard E.", ""], ["Moore", "Brian C. J.", ""]]}, {"id": "1905.10403", "submitter": "Junteng Jia", "authors": "Junteng Jia, Austin R. Benson", "title": "Neural Jump Stochastic Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many time series are effectively generated by a combination of deterministic\ncontinuous flows along with discrete jumps sparked by stochastic events.\nHowever, we usually do not have the equation of motion describing the flows, or\nhow they are affected by jumps. To this end, we introduce Neural Jump\nStochastic Differential Equations that provide a data-driven approach to learn\ncontinuous and discrete dynamic behavior, i.e., hybrid systems that both flow\nand jump. Our approach extends the framework of Neural Ordinary Differential\nEquations with a stochastic process term that models discrete events. We then\nmodel temporal point processes with a piecewise-continuous latent trajectory,\nwhere the discontinuities are caused by stochastic events whose conditional\nintensity depends on the latent state. We demonstrate the predictive\ncapabilities of our model on a range of synthetic and real-world marked point\nprocess datasets, including classical point processes (such as Hawkes\nprocesses), awards on Stack Overflow, medical records, and earthquake\nmonitoring.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:45:51 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 01:57:18 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 21:29:02 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Jia", "Junteng", ""], ["Benson", "Austin R.", ""]]}, {"id": "1905.10404", "submitter": "Aadil Hayat", "authors": "Aadil Hayat, Utsav Singh, Vinay P. Namboodiri", "title": "InfoRL: Interpretable Reinforcement Learning using Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have proved that given an\nenvironment we can learn to perform a task in that environment if we have\naccess to some form of a reward function (dense, sparse or derived from IRL).\nBut most of the algorithms focus on learning a single best policy to perform a\ngiven set of tasks. In this paper, we focus on an algorithm that learns to not\njust perform a task but different ways to perform the same task. As we know\nwhen the environment is complex enough there always exists multiple ways to\nperform a task. We show that using the concept of information maximization it\nis possible to learn latent codes for discovering multiple ways to perform any\ngiven task in an environment.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:47:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hayat", "Aadil", ""], ["Singh", "Utsav", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1905.10409", "submitter": "Anton Dereventsov", "authors": "Anton Dereventsov, Armenak Petrosyan, Clayton Webster", "title": "Greedy Shallow Networks: A New Approach for Constructing and Training\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a greedy-based approach to construct an efficient single hidden\nlayer neural network with the ReLU activation that approximates a target\nfunction. In our approach we obtain a shallow network by utilizing a greedy\nalgorithm with the prescribed dictionary provided by the available training\ndata and a set of possible inner weights. To facilitate the greedy selection\nprocess we employ an integral representation of the network, based on the\nridgelet transform, that significantly reduces the cardinality of the\ndictionary and hence promotes feasibility of the greedy selection. Our approach\nallows for the construction of efficient architectures which can be treated\neither as improved initializations to be used in place of random-based\nalternatives, or as fully-trained networks in certain cases, thus potentially\nnullifying the need for backpropagation training. Numerical experiments\ndemonstrate the tenability of the proposed concept and its advantages compared\nto the conventional techniques for selecting architectures and initializations\nfor neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:04:10 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 19:44:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dereventsov", "Anton", ""], ["Petrosyan", "Armenak", ""], ["Webster", "Clayton", ""]]}, {"id": "1905.10412", "submitter": "Numa Dhamani", "authors": "Numa Dhamani, Paul Azunre, Jeffrey L. Gleason, Craig Corcoran, Garrett\n  Honke, Steve Kramer, Jonathon Morgan", "title": "Using Deep Networks and Transfer Learning to Address Disinformation", "comments": "AI for Social Good Workshop at the International Conference on\n  Machine Learning, Long Beach, United States (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:10:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dhamani", "Numa", ""], ["Azunre", "Paul", ""], ["Gleason", "Jeffrey L.", ""], ["Corcoran", "Craig", ""], ["Honke", "Garrett", ""], ["Kramer", "Steve", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1905.10417", "submitter": "Haitian Sun", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Differentiable Representations For Multihop Inference Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient differentiable implementations of second-order multi-hop\nreasoning using a large symbolic knowledge base (KB). We introduce a new\noperation which can be used to compositionally construct second-order multi-hop\ntemplates in a neural model, and evaluate a number of alternative\nimplementations, with different time and memory trade offs. These techniques\nscale to KBs with millions of entities and tens of millions of triples, and\nlead to simple models with competitive performance on several learning tasks\nrequiring multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:20:03 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "1905.10418", "submitter": "Changjun Fan", "authors": "Changjun Fan, Li Zeng, Yuhui Ding, Muhao Chen, Yizhou Sun, Zhong Liu", "title": "Learning to Identify High Betweenness Centrality Nodes from Scratch: A\n  Novel Graph Neural Network Approach", "comments": "10 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness centrality (BC) is one of the most used centrality measures for\nnetwork analysis, which seeks to describe the importance of nodes in a network\nin terms of the fraction of shortest paths that pass through them. It is key to\nmany valuable applications, including community detection and network\ndismantling. Computing BC scores on large networks is computationally\nchallenging due to high time complexity. Many approximation algorithms have\nbeen proposed to speed up the estimation of BC, which are mainly\nsampling-based. However, these methods are still prone to considerable\nexecution time on large-scale networks, and their results are often exacerbated\nwhen small changes happen to the network structures. In this paper, we focus on\nidentifying nodes with high BC in a graph, since many application scenarios are\nbuilt upon retrieving nodes with top-k BC. Different from previous heuristic\nmethods, we turn this task into a learning problem and design an\nencoder-decoder based framework to resolve the problem. More specifcally, the\nencoder leverages the network structure to encode each node into an embedding\nvector, which captures the important structural information of the node. The\ndecoder transforms the embedding vector for each node into a scalar, which\ncaptures the relative rank of this node in terms of BC. We use the pairwise\nranking loss to train the model to identify the orders of nodes regarding their\nBC. By training on small-scale networks, the learned model is capable of\nassigning relative BC scores to nodes for any unseen networks, and thus\nidentifying the highly-ranked nodes. Comprehensive experiments on both\nsynthetic and real-world networks demonstrate that, compared to representative\nbaselines, our model drastically speeds up the prediction without noticeable\nsacrifce in accuracy, and outperforms the state-of-the-art by accuracy on\nseveral large real-world networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:23:49 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 07:08:49 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 22:10:03 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 17:18:55 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Fan", "Changjun", ""], ["Zeng", "Li", ""], ["Ding", "Yuhui", ""], ["Chen", "Muhao", ""], ["Sun", "Yizhou", ""], ["Liu", "Zhong", ""]]}, {"id": "1905.10423", "submitter": "Syed Anwar", "authors": "Aasim Raheel, Muhammad Majid, Syed Muhammad Anwar, Ulas Bagci", "title": "Emotion Classification in Response to Tactile Enhanced Multimedia using\n  Frequency Domain Features of Brain Signals", "comments": "Accepted in IEEE EMBC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile enhanced multimedia is generated by synchronizing traditional\nmultimedia clips, to generate hot and cold air effect, with an electric heater\nand a fan. This objective is to give viewers a more realistic and immersing\nfeel of the multimedia content. The response to this enhanced multimedia\ncontent (mulsemedia) is evaluated in terms of the appreciation/emotion by using\nhuman brain signals. We observe and record electroencephalography (EEG) data\nusing a commercially available four channel MUSE headband. A total of 21\nparticipants voluntarily participated in this study for EEG recordings. We\nextract frequency domain features from five different bands of each EEG\nchannel. Four emotions namely: happy, relaxed, sad, and angry are classified\nusing a support vector machine in response to the tactile enhanced multimedia.\nAn increased accuracy of 76:19% is achieved when compared to 63:41% by using\nthe time domain features. Our results show that the selected frequency domain\nfeatures could be better suited for emotion classification in mulsemedia\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 23:11:41 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Raheel", "Aasim", ""], ["Majid", "Muhammad", ""], ["Anwar", "Syed Muhammad", ""], ["Bagci", "Ulas", ""]]}, {"id": "1905.10424", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Weiwei Pan, Finale Doshi-Velez", "title": "A general method for regularizing tensor decomposition methods via\n  pseudo-data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition methods allow us to learn the parameters of latent\nvariable models through decomposition of low-order moments of data. A\nsignificant limitation of these algorithms is that there exists no general\nmethod to regularize them, and in the past regularization has mostly been\nperformed using bespoke modifications to the algorithms, tailored for the\nparticular form of the desired regularizer. We present a general method of\nregularizing tensor decomposition methods which can be used for any likelihood\nmodel that is learnable using tensor decomposition methods and any\ndifferentiable regularization function by supplementing the training data with\npseudo-data. The pseudo-data is optimized to balance two terms: being as close\nas possible to the true data and enforcing the desired regularization. On\nsynthetic, semi-synthetic and real data, we demonstrate that our method can\nimprove inference accuracy and regularize for a broad range of goals including\ntransfer learning, sparsity, interpretability, and orthogonality of the learned\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:50:37 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gottesman", "Omer", ""], ["Pan", "Weiwei", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1905.10427", "submitter": "Jakub Tomczak Ph.D.", "authors": "Maximilian Ilse and Jakub M. Tomczak and Christos Louizos and Max\n  Welling", "title": "DIVA: Domain Invariant Variational Autoencoders", "comments": "Code available at https://github.com/AMLab-Amsterdam/DIVA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of domain generalization, namely, how to learn\nrepresentations given data from a set of domains that generalize to data from a\npreviously unseen domain. We propose the Domain Invariant Variational\nAutoencoder (DIVA), a generative model that tackles this problem by learning\nthree independent latent subspaces, one for the domain, one for the class, and\none for any residual variations. We highlight that due to the generative nature\nof our model we can also incorporate unlabeled data from known or previously\nunseen domains. To the best of our knowledge this has not been done before in a\ndomain generalization setting. This property is highly desirable in fields like\nmedical imaging where labeled data is scarce. We experimentally evaluate our\nmodel on the rotated MNIST benchmark and a malaria cell images dataset where we\nshow that (i) the learned subspaces are indeed complementary to each other,\n(ii) we improve upon recent works on this task and (iii) incorporating\nunlabelled data can boost the performance even further.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 19:57:39 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:15:48 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ilse", "Maximilian", ""], ["Tomczak", "Jakub M.", ""], ["Louizos", "Christos", ""], ["Welling", "Max", ""]]}, {"id": "1905.10428", "submitter": "Maryam Majzoubi", "authors": "Maryam Majzoubi and Anna Choromanska", "title": "LdSM: Logarithm-depth Streaming Multi-label Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-label classification where the goal is to annotate each\ndata point with the most relevant $\\textit{subset}$ of labels from an extremely\nlarge label set. Efficient annotation can be achieved with balanced tree\npredictors, i.e. trees with logarithmic-depth in the label complexity, whose\nleaves correspond to labels. Designing prediction mechanism with such trees for\nreal data applications is non-trivial as it needs to accommodate sending\nexamples to multiple leaves while at the same time sustain high prediction\naccuracy. In this paper we develop the LdSM algorithm for the construction and\ntraining of multi-label decision trees, where in every node of the tree we\noptimize a novel objective function that favors balanced splits, maintains high\nclass purity of children nodes, and allows sending examples to multiple\ndirections but with a penalty that prevents tree over-growth. Each node of the\ntree is trained once the previous node is completed leading to a streaming\napproach for training. We analyze the proposed objective theoretically and show\nthat minimizing it leads to pure and balanced data splits. Furthermore, we show\na boosting theorem that captures its connection to the multi-label\nclassification error. Experimental results on benchmark data sets demonstrate\nthat our approach achieves high prediction accuracy and low prediction time and\nposition LdSM as a competitive tool among existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:01:27 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 01:30:57 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 00:48:25 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 19:07:23 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 16:06:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Majzoubi", "Maryam", ""], ["Choromanska", "Anna", ""]]}, {"id": "1905.10437", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados and Yoshua Bengio", "title": "N-BEATS: Neural basis expansion analysis for interpretable time series\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on solving the univariate times series point forecasting problem\nusing deep learning. We propose a deep neural architecture based on backward\nand forward residual links and a very deep stack of fully-connected layers. The\narchitecture has a number of desirable properties, being interpretable,\napplicable without modification to a wide array of target domains, and fast to\ntrain. We test the proposed architecture on several well-known datasets,\nincluding M3, M4 and TOURISM competition datasets containing time series from\ndiverse domains. We demonstrate state-of-the-art performance for two\nconfigurations of N-BEATS for all the datasets, improving forecast accuracy by\n11% over a statistical benchmark and by 3% over last year's winner of the M4\ncompetition, a domain-adjusted hand-crafted hybrid between neural network and\nstatistical time series models. The first configuration of our model does not\nemploy any time-series-specific components and its performance on heterogeneous\ndatasets strongly suggests that, contrarily to received wisdom, deep learning\nprimitives such as residual blocks are by themselves sufficient to solve a wide\nrange of forecasting problems. Finally, we demonstrate how the proposed\narchitecture can be augmented to provide outputs that are interpretable without\nconsiderable loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:28:57 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 15:03:49 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 13:51:38 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 21:08:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Carpov", "Dmitri", ""], ["Chapados", "Nicolas", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1905.10447", "submitter": "Yuanshun Yao", "authors": "Yuanshun Yao and Huiying Li and Haitao Zheng and Ben Y. Zhao", "title": "Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed the concept of backdoor attacks on deep neural\nnetworks (DNNs), where misbehaviors are hidden inside \"normal\" models, only to\nbe triggered by very specific inputs. In practice, however, these attacks are\ndifficult to perform and highly constrained by sharing of models through\ntransfer learning. Adversaries have a small window during which they must\ncompromise the student model before it is deployed. In this paper, we describe\na significantly more powerful variant of the backdoor attack, latent backdoors,\nwhere hidden rules can be embedded in a single \"Teacher\" model, and\nautomatically inherited by all \"Student\" models through the transfer learning\nprocess. We show that latent backdoors can be quite effective in a variety of\napplication contexts, and validate its practicality through real-world attacks\nagainst traffic sign recognition, iris identification of lab volunteers, and\nfacial recognition of public figures (politicians). Finally, we evaluate 4\npotential defenses, and find that only one is effective in disrupting latent\nbackdoors, but might incur a cost in classification accuracy as tradeoff.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:15:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yao", "Yuanshun", ""], ["Li", "Huiying", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1905.10448", "submitter": "Matthew Hirn", "authors": "Michael Perlmutter and Feng Gao and Guy Wolf and Matthew Hirn", "title": "Geometric Wavelet Scattering Networks on Compact Riemannian Manifolds", "comments": "35 pages; 3 figures; 2 tables; v3: Revisions based on reviewer\n  comments", "journal-ref": "Proceedings of The First Mathematical and Scientific Machine\n  Learning Conference, PMLR 107:570-604, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean scattering transform was introduced nearly a decade ago to\nimprove the mathematical understanding of convolutional neural networks.\nInspired by recent interest in geometric deep learning, which aims to\ngeneralize convolutional neural networks to manifold and graph-structured\ndomains, we define a geometric scattering transform on manifolds. Similar to\nthe Euclidean scattering transform, the geometric scattering transform is based\non a cascade of wavelet filters and pointwise nonlinearities. It is invariant\nto local isometries and stable to certain types of diffeomorphisms. Empirical\nresults demonstrate its utility on several geometric learning tasks. Our\nresults generalize the deformation stability and local translation invariance\nof Euclidean scattering, and demonstrate the importance of linking the used\nfilter structures to the underlying geometry of the data.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:19:04 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 21:44:23 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 01:30:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Perlmutter", "Michael", ""], ["Gao", "Feng", ""], ["Wolf", "Guy", ""], ["Hirn", "Matthew", ""]]}, {"id": "1905.10452", "submitter": "Matteo Spallanzani", "authors": "Matteo Spallanzani, Lukas Cavigelli, Gian Paolo Leonardi, Marko\n  Bertogna and Luca Benini", "title": "Additive Noise Annealing and Approximation Properties of Quantized\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical and experimental investigation of the quantization\nproblem for artificial neural networks. We provide a mathematical definition of\nquantized neural networks and analyze their approximation capabilities, showing\nin particular that any Lipschitz-continuous map defined on a hypercube can be\nuniformly approximated by a quantized neural network. We then focus on the\nregularization effect of additive noise on the arguments of multi-step\nfunctions inherent to the quantization of continuous variables. In particular,\nwhen the expectation operator is applied to a non-differentiable multi-step\nrandom function, and if the underlying probability density is differentiable\n(in either classical or weak sense), then a differentiable function is\nretrieved, with explicit bounds on its Lipschitz constant. Based on these\nresults, we propose a novel gradient-based training algorithm for quantized\nneural networks that generalizes the straight-through estimator, acting on\nnoise applied to the network's parameters. We evaluate our algorithm on the\nCIFAR-10 and ImageNet image classification benchmarks, showing state-of-the-art\nperformance on AlexNet and MobileNetV2 for ternary networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:30:54 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Spallanzani", "Matteo", ""], ["Cavigelli", "Lukas", ""], ["Leonardi", "Gian Paolo", ""], ["Bertogna", "Marko", ""], ["Benini", "Luca", ""]]}, {"id": "1905.10457", "submitter": "Joseph Daws Jr", "authors": "Joseph Daws Jr. and Clayton G. Webster", "title": "A Polynomial-Based Approach for Architectural Design and Learning with\n  Deep Neural Networks", "comments": "11 pages, 6 figures, submitted to NeurIPS 2019, corrected several\n  typos and included new examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this effort we propose a novel approach for reconstructing multivariate\nfunctions from training data, by identifying both a suitable network\narchitecture and an initialization using polynomial-based approximations.\nTraining deep neural networks using gradient descent can be interpreted as\nmoving the set of network parameters along the loss landscape in order to\nminimize the loss functional. The initialization of parameters is important for\niterative training methods based on descent. Our procedure produces a network\nwhose initial state is a polynomial representation of the training data. The\nmajor advantage of this technique is from this initialized state the network\nmay be improved using standard training procedures. Since the network already\napproximates the data, training is more likely to produce a set of parameters\nassociated with a desirable local minimum. We provide the details of the theory\nnecessary for constructing such networks and also consider several numerical\nexamples that reveal our approach ultimately produces networks which can be\neffectively trained from our initialized state to achieve an improved\napproximation for a large class of target functions.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:43:40 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 14:52:43 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Daws", "Joseph", "Jr."], ["Webster", "Clayton G.", ""]]}, {"id": "1905.10466", "submitter": "Anusha Lalitha", "authors": "Anusha Lalitha, Xinghan Wang, Osman Kilinc, Yongxi Lu, Tara Javidi,\n  Farinaz Koushanfar", "title": "Decentralized Bayesian Learning over Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized learning algorithm over a general social network.\nThe algorithm leaves the training data distributed on the mobile devices while\nutilizing a peer to peer model aggregation method. The proposed algorithm\nallows agents with local data to learn a shared model explaining the global\ntraining data in a decentralized fashion. The proposed algorithm can be viewed\nas a Bayesian and peer-to-peer variant of federated learning in which each\nagent keeps a \"posterior probability distribution\" over a global model\nparameters. The agent update its \"posterior\" based on 1) the local training\ndata and 2) the asynchronous communication and model aggregation with their\n1-hop neighbors. This Bayesian formulation allows for a systematic treatment of\nmodel aggregation over any arbitrary connected graph. Furthermore, it provides\nstrong analytic guarantees on converge in the realizable case as well as a\nclosed form characterization of the rate of convergence. We also show that our\nmethodology can be combined with efficient Bayesian inference techniques to\ntrain Bayesian neural networks in a decentralized manner. By empirical studies\nwe show that our theoretical analysis can guide the design of network/social\ninteractions and data partitioning to achieve convergence.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:29:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lalitha", "Anusha", ""], ["Wang", "Xinghan", ""], ["Kilinc", "Osman", ""], ["Lu", "Yongxi", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1905.10474", "submitter": "David Brookes", "authors": "David H. Brookes, Akosua Busia, Clara Fannjiang, Kevin Murphy,\n  Jennifer Listgarten", "title": "A view of Estimation of Distribution Algorithms through the lens of\n  Expectation-Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a large class of Estimation of Distribution Algorithms,\nincluding, but not limited to, Covariance Matrix Adaption, can be written as a\nMonte Carlo Expectation-Maximization algorithm, and as exact EM in the limit of\ninfinite samples. Because EM sits on a rigorous statistical foundation and has\nbeen thoroughly analyzed, this connection provides a new coherent framework\nwith which to reason about EDAs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:06:02 GMT"}, {"version": "v10", "created": "Thu, 11 Jun 2020 22:03:36 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 18:19:28 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 17:54:17 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 02:33:02 GMT"}, {"version": "v5", "created": "Wed, 5 Jun 2019 21:42:47 GMT"}, {"version": "v6", "created": "Wed, 9 Oct 2019 19:57:12 GMT"}, {"version": "v7", "created": "Thu, 12 Dec 2019 01:23:08 GMT"}, {"version": "v8", "created": "Mon, 10 Feb 2020 19:38:09 GMT"}, {"version": "v9", "created": "Tue, 9 Jun 2020 21:17:51 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Brookes", "David H.", ""], ["Busia", "Akosua", ""], ["Fannjiang", "Clara", ""], ["Murphy", "Kevin", ""], ["Listgarten", "Jennifer", ""]]}, {"id": "1905.10477", "submitter": "Jonathan Ullman", "authors": "Adam Sealfon and Jonathan Ullman", "title": "Efficiently Estimating Erdos-Renyi Graphs with Node Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple, computationally efficient, and node-differentially-private\nalgorithm for estimating the parameter of an Erdos-Renyi graph---that is,\nestimating p in a G(n,p)---with near-optimal accuracy. Our algorithm nearly\nmatches the information-theoretically optimal exponential-time algorithm for\nthe same problem due to Borgs et al. (FOCS 2018). More generally, we give an\noptimal, computationally efficient, private algorithm for estimating the\nedge-density of any graph whose degree distribution is concentrated on a small\ninterval.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:16:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sealfon", "Adam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1905.10478", "submitter": "Cole Hawkins", "authors": "Cole Hawkins and Zheng Zhang", "title": "Bayesian Tensorized Neural Networks with Automatic Rank Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition is an effective approach to compress over-parameterized\nneural networks and to enable their deployment on resource-constrained hardware\nplatforms. However, directly applying tensor compression in the training\nprocess is a challenging task due to the difficulty of choosing a proper tensor\nrank. In order to achieve this goal, this paper proposes a Bayesian tensorized\nneural network. Our Bayesian method performs automatic model compression via an\nadaptive tensor rank determination. We also present approaches for posterior\ndensity calculation and maximum a posteriori (MAP) estimation for the\nend-to-end training of our tensorized neural network. We provide experimental\nvalidation on a fully connected neural network, a CNN and a residual neural\nnetwork where our work produces $7.4\\times$ to $137\\times$ more compact neural\nnetworks directly from the training.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:18:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hawkins", "Cole", ""], ["Zhang", "Zheng", ""]]}, {"id": "1905.10479", "submitter": "Viktor Reshniak", "authors": "Viktor Reshniak, Clayton Webster", "title": "Robust learning with implicit residual networks", "comments": null, "journal-ref": "Knowl. Extr. 2021, 3, 34-55", "doi": "10.3390/make3010003", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this effort, we propose a new deep architecture utilizing residual blocks\ninspired by implicit discretization schemes. As opposed to the standard\nfeed-forward networks, the outputs of the proposed implicit residual blocks are\ndefined as the fixed points of the appropriately chosen nonlinear\ntransformations. We show that this choice leads to the improved stability of\nboth forward and backward propagations, has a favorable impact on the\ngeneralization power and allows to control the robustness of the network with\nonly a few hyperparameters. In addition, the proposed reformulation of ResNet\ndoes not introduce new parameters and can potentially lead to a reduction in\nthe number of required layers due to improved forward stability. Finally, we\nderive the memory-efficient training algorithm, propose a stochastic\nregularization technique and provide numerical results in support of our\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:27:30 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 22:57:35 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 23:44:18 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 15:28:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Reshniak", "Viktor", ""], ["Webster", "Clayton", ""]]}, {"id": "1905.10484", "submitter": "Keegan Lensink", "authors": "Keegan Lensink, Bas Peters, Eldad Haber", "title": "Fully Hyperbolic Convolutional Neural Networks", "comments": "21 pages, 9 figures, Updated work to include additional numerical\n  experiments, a section about VAEs and learnable wavelets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have recently seen tremendous success in\nvarious computer vision tasks. However, their application to problems with high\ndimensional input and output, such as high-resolution image and video\nsegmentation or 3D medical imaging, has been limited by various factors.\nPrimarily, in the training stage, it is necessary to store network activations\nfor back propagation. In these settings, the memory requirements associated\nwith storing activations can exceed what is feasible with current hardware,\nespecially for problems in 3D. Motivated by the propagation of signals over\nphysical networks, that are governed by the hyperbolic Telegraph equation, in\nthis work we introduce a fully conservative hyperbolic network for problems\nwith high dimensional input and output. We introduce a coarsening operation\nthat allows completely reversible CNNs by using a learnable Discrete Wavelet\nTransform and its inverse to both coarsen and interpolate the network state and\nchange the number of channels. We show that fully reversible networks are able\nto achieve results comparable to the state of the art in 4D time-lapse hyper\nspectral image segmentation and full 3D video segmentation, with a much lower\nmemory footprint that is a constant independent of the network depth. We also\nextend the use of such networks to Variational Auto Encoders with high\nresolution input and output.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:43:36 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 20:45:03 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 18:02:05 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Lensink", "Keegan", ""], ["Peters", "Bas", ""], ["Haber", "Eldad", ""]]}, {"id": "1905.10485", "submitter": "Qing Yan", "authors": "Zhisheng Xiao, Qing Yan, Yali Amit", "title": "Generative Latent Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose the Generative Latent Flow (GLF), an algorithm for\ngenerative modeling of the data distribution. GLF uses an Auto-encoder (AE) to\nlearn latent representations of the data, and a normalizing flow to map the\ndistribution of the latent variables to that of simple i.i.d noise. In contrast\nto some other Auto-encoder based generative models, which use various\nregularizers that encourage the encoded latent distribution to match the prior\ndistribution, our model explicitly constructs a mapping between these two\ndistributions, leading to better density matching while avoiding over\nregularizing the latent variables. We compare our model with several related\ntechniques, and show that it has many relative advantages including fast\nconvergence, single stage training and minimal reconstruction trade-off. We\nalso study the relationship between our model and its stochastic counterpart,\nand show that our model can be viewed as a vanishing noise limit of VAEs with\nflow prior. Quantitatively, under standardized evaluations, our method achieves\nstate-of-the-art sample quality among AE based models on commonly used\ndatasets, and is competitive with GANs' benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:44:50 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 22:57:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Xiao", "Zhisheng", ""], ["Yan", "Qing", ""], ["Amit", "Yali", ""]]}, {"id": "1905.10488", "submitter": "Sungmin Cha", "authors": "Sungmin Cha, Taeeon Park, Byeongjoon Kim, Jongduk Baek and Taesup Moon", "title": "GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy\n  Images", "comments": "ICLR 2021 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle a challenging blind image denoising problem, in which only single\ndistinct noisy images are available for training a denoiser, and no information\nabout noise is known, except for it being zero-mean, additive, and independent\nof the clean image. In such a setting, which often occurs in practice, it is\nnot possible to train a denoiser with the standard discriminative training or\nwith the recently developed Noise2Noise (N2N) training; the former requires the\nunderlying clean image for the given noisy image, and the latter requires two\nindependently realized noisy image pair for a clean image. To that end, we\npropose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise)\nmethod that first learns a generative model that can 1) simulate the noise in\nthe given noisy images and 2) generate a rough, noisy estimates of the clean\nimages, then 3) iteratively trains a denoiser with subsequently synthesized\nnoisy image pairs (as in N2N), obtained from the generative model. In results,\nwe show the denoiser trained with our GAN2GAN achieves an impressive denoising\nperformance on both synthetic and real-world datasets for the blind denoising\nsetting; it almost approaches the performance of the standard\ndiscriminatively-trained or N2N-trained models that have more information than\nours, and it significantly outperforms the recent baseline for the same\nsetting, \\textit{e.g.}, Noise2Void, and a more conventional yet strong one,\nBM3D. The official code of our method is available at\nhttps://github.com/csm9493/GAN2GAN.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 00:16:09 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 17:23:24 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 02:58:45 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 09:01:11 GMT"}, {"version": "v5", "created": "Sun, 4 Jul 2021 09:16:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cha", "Sungmin", ""], ["Park", "Taeeon", ""], ["Kim", "Byeongjoon", ""], ["Baek", "Jongduk", ""], ["Moon", "Taesup", ""]]}, {"id": "1905.10496", "submitter": "Rui Zhang", "authors": "Rui Zhang, Christian Walder, Marian-Andrei Rizoiu", "title": "Variational Inference for Sparse Gaussian Process Modulated Hawkes\n  Process", "comments": "AAAI-20", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence.\n  Vol. 34. No. 04. 2020", "doi": "10.1609/aaai.v34i04.6160", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hawkes process (HP) has been widely applied to modeling self-exciting\nevents including neuron spikes, earthquakes and tweets. To avoid designing\nparametric triggering kernel and to be able to quantify the prediction\nconfidence, the non-parametric Bayesian HP has been proposed. However, the\ninference of such models suffers from unscalability or slow convergence. In\nthis paper, we aim to solve both problems. Specifically, first, we propose a\nnew non-parametric Bayesian HP in which the triggering kernel is modeled as a\nsquared sparse Gaussian process. Then, we propose a novel variational inference\nschema for model optimization. We employ the branching structure of the HP so\nthat maximization of evidence lower bound (ELBO) is tractable by the\nexpectation-maximization algorithm. We propose a tighter ELBO which improves\nthe fitting performance. Further, we accelerate the novel variational inference\nschema to linear time complexity by leveraging the stationarity of the\ntriggering kernel. Different from prior acceleration methods, ours enjoys\nhigher efficiency. Finally, we exploit synthetic data and two large social\nmedia datasets to evaluate our method. We show that our approach outperforms\nstate-of-the-art non-parametric frequentist and Bayesian methods. We validate\nthe efficiency of our accelerated variational inference schema and practical\nutility of our tighter ELBO for model selection. We observe that the tighter\nELBO exceeds the common one in model selection.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 01:45:29 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 01:34:14 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Rui", ""], ["Walder", "Christian", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "1905.10497", "submitter": "Tian Li", "authors": "Tian Li, Maziar Sanjabi, Ahmad Beirami, Virginia Smith", "title": "Fair Resource Allocation in Federated Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves training statistical models in massive,\nheterogeneous networks. Naively minimizing an aggregate loss function in such a\nnetwork may disproportionately advantage or disadvantage some of the devices.\nIn this work, we propose q-Fair Federated Learning (q-FFL), a novel\noptimization objective inspired by fair resource allocation in wireless\nnetworks that encourages a more fair (specifically, a more uniform) accuracy\ndistribution across devices in federated networks. To solve q-FFL, we devise a\ncommunication-efficient method, q-FedAvg, that is suited to federated networks.\nWe validate both the effectiveness of q-FFL and the efficiency of q-FedAvg on a\nsuite of federated datasets with both convex and non-convex models, and show\nthat q-FFL (along with q-FedAvg) outperforms existing baselines in terms of the\nresulting fairness, flexibility, and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 01:47:41 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:48:28 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Li", "Tian", ""], ["Sanjabi", "Maziar", ""], ["Beirami", "Ahmad", ""], ["Smith", "Virginia", ""]]}, {"id": "1905.10498", "submitter": "L\\'eon Bottou", "authors": "Chhavi Yadav and L\\'eon Bottou", "title": "Cold Case: The Lost MNIST Digits", "comments": "Final NeurIPS version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the popular MNIST dataset [LeCun et al., 1994] is derived from the\nNIST database [Grother and Hanaoka, 1995], the precise processing steps for\nthis derivation have been lost to time. We propose a reconstruction that is\naccurate enough to serve as a replacement for the MNIST dataset, with\ninsignificant changes in accuracy. We trace each MNIST digit to its NIST source\nand its rich metadata such as writer identifier, partition identifier, etc. We\nalso reconstruct the complete MNIST test set with 60,000 samples instead of the\nusual 10,000. Since the balance 50,000 were never distributed, they enable us\nto investigate the impact of twenty-five years of MNIST experiments on the\nreported testing performances. Our results unambiguously confirm the trends\nobserved by Recht et al. [2018, 2019]: although the misclassification rates are\nslightly off, classifier ordering and model selection remain broadly reliable.\nWe attribute this phenomenon to the pairing benefits of comparing classifiers\non the same digits.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 01:50:51 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 21:05:26 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yadav", "Chhavi", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1905.10501", "submitter": "Kshitij Bansal", "authors": "Kshitij Bansal, Christian Szegedy, Markus N. Rabe, Sarah M. Loos,\n  Viktor Toman", "title": "Learning to Reason in Large Theories without Imitation", "comments": "Major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to do automated theorem proving in the\npresence of a large knowledge base of potential premises without learning from\nhuman proofs. We suggest an exploration mechanism that mixes in additional\npremises selected by a tf-idf (term frequency-inverse document frequency) based\nlookup in a deep reinforcement learning scenario. This helps with exploring and\nlearning which premises are relevant for proving a new theorem. Our experiments\nshow that the theorem prover trained with this exploration mechanism\noutperforms provers that are trained only on human proofs. It approaches the\nperformance of a prover trained by a combination of imitation and reinforcement\nlearning. We perform multiple experiments to understand the importance of the\nunderlying assumptions that make our exploration approach work, thus explaining\nour design choices.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 02:36:25 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 21:53:06 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:20:59 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""], ["Rabe", "Markus N.", ""], ["Loos", "Sarah M.", ""], ["Toman", "Viktor", ""]]}, {"id": "1905.10506", "submitter": "Yihao Feng", "authors": "Yihao Feng, Lihong Li, Qiang Liu", "title": "A Kernel Loss for Solving the Bellman Equation", "comments": "17 pages, 5 figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function learning plays a central role in many state-of-the-art\nreinforcement-learning algorithms. Many popular algorithms like Q-learning do\nnot optimize any objective function, but are fixed-point iterations of some\nvariant of Bellman operator that is not necessarily a contraction. As a result,\nthey may easily lose convergence guarantees, as can be observed in practice. In\nthis paper, we propose a novel loss function, which can be optimized using\nstandard gradient-based methods without risking divergence. The key advantage\nis that its gradient can be easily approximated using sampled transitions,\navoiding the need for double samples required by prior algorithms like residual\ngradient. Our approach may be combined with general function classes such as\nneural networks, on either on- or off-policy data, and is shown to work\nreliably and effectively in several benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:00:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 05:40:57 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 23:19:20 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Feng", "Yihao", ""], ["Li", "Lihong", ""], ["Liu", "Qiang", ""]]}, {"id": "1905.10510", "submitter": "Chang Xiao", "authors": "Chang Xiao, Peilin Zhong and Changxi Zheng", "title": "Enhancing Adversarial Defense by k-Winners-Take-All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple change to existing neural network structures for better\ndefending against gradient-based adversarial attacks. Instead of using popular\nactivation functions (such as ReLU), we advocate the use of k-Winners-Take-All\n(k-WTA) activation, a C0 discontinuous function that purposely invalidates the\nneural network model's gradient at densely distributed input data points. The\nproposed k-WTA activation can be readily used in nearly all existing networks\nand training methods with no significant overhead. Our proposal is\ntheoretically rationalized. We analyze why the discontinuities in k-WTA\nnetworks can largely prevent gradient-based search of adversarial examples and\nwhy they at the same time remain innocuous to the network training. This\nunderstanding is also empirically backed. We test k-WTA activation on various\nnetwork structures optimized by a training method, be it adversarial training\nor not. In all cases, the robustness of k-WTA networks outperforms that of\ntraditional networks under white-box attacks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:36:40 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 20:14:15 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 00:27:18 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Xiao", "Chang", ""], ["Zhong", "Peilin", ""], ["Zheng", "Changxi", ""]]}, {"id": "1905.10514", "submitter": "Jiaxing Wang", "authors": "Jiaxing Wang, Yin Zheng, Xiaoshuang Chen, Junzhou Huang, Jian Cheng", "title": "Semi-supervised Learning with Contrastive Predicative Coding", "comments": "6 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) provides a powerful framework for leveraging\nunlabeled data when labels are limited or expensive to obtain. SSL algorithms\nbased on deep neural networks have recently proven successful on standard\nbenchmark tasks. However, many of them have thus far been either inflexible,\ninefficient or non-scalable. This paper explores recently developed contrastive\npredictive coding technique to improve discriminative power of deep learning\nmodels when a large portion of labels are absent. Two models, cpc-SSL and a\nclass conditional variant~(ccpc-SSL) are presented. They effectively exploit\nthe unlabeled data by extracting shared information between different parts of\nthe (high-dimensional) data. The proposed approaches are inductive, and scale\nwell to very large datasets like ImageNet, making them good candidates in\nreal-world large scale applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:53:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Jiaxing", ""], ["Zheng", "Yin", ""], ["Chen", "Xiaoshuang", ""], ["Huang", "Junzhou", ""], ["Cheng", "Jian", ""]]}, {"id": "1905.10521", "submitter": "Kyungwoo Song", "authors": "Kyungwoo Song, JoonHo Jang, Seung jae Shin, Il-Chul Moon", "title": "Bivariate Beta-LSTM", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) infers the long term dependency through a cell\nstate maintained by the input and the forget gate structures, which models a\ngate output as a value in [0,1] through a sigmoid function. However, due to the\ngraduality of the sigmoid function, the sigmoid gate is not flexible in\nrepresenting multi-modality or skewness. Besides, the previous models lack\nmodeling on the correlation between the gates, which would be a new method to\nadopt inductive bias for a relationship between previous and current input.\nThis paper proposes a new gate structure with the bivariate Beta distribution.\nThe proposed gate structure enables probabilistic modeling on the gates within\nthe LSTM cell so that the modelers can customize the cell state flow with\npriors and distributions. Moreover, we theoretically show the higher upper\nbound of the gradient compared to the sigmoid function, and we empirically\nobserved that the bivariate Beta distribution gate structure provides higher\ngradient values in training. We demonstrate the effectiveness of bivariate Beta\ngate structure on the sentence classification, image classification, polyphonic\nmusic modeling, and image caption generation.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 05:10:01 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 12:12:26 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 10:35:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Song", "Kyungwoo", ""], ["Jang", "JoonHo", ""], ["Shin", "Seung jae", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1905.10536", "submitter": "Shuai Zhang", "authors": "Shuai Zhang and Yi Tay and Lina Yao and Bin Wu and Aixin Sun", "title": "DeepRec: An Open-source Toolkit for Deep Learning based Recommendation", "comments": "Accepted by IJCAI-2019 Demonstrations Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based recommender systems have been extensively explored in\nrecent years. However, the large number of models proposed each year poses a\nbig challenge for both researchers and practitioners in reproducing the results\nfor further comparisons. Although a portion of papers provides source code,\nthey adopted different programming languages or different deep learning\npackages, which also raises the bar in grasping the ideas. To alleviate this\nproblem, we released the open source project: \\textbf{DeepRec}. In this\ntoolkit, we have implemented a number of deep learning based recommendation\nalgorithms using Python and the widely used deep learning package - Tensorflow.\nThree major recommendation scenarios: rating prediction, top-N recommendation\n(item ranking) and sequential recommendation, were considered. Meanwhile,\nDeepRec maintains good modularity and extensibility to easily incorporate new\nmodels into the framework. It is distributed under the terms of the GNU General\nPublic License. The source code is available at github:\n\\url{https://github.com/cheungdaven/DeepRec}\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:00:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Shuai", ""], ["Tay", "Yi", ""], ["Yao", "Lina", ""], ["Wu", "Bin", ""], ["Sun", "Aixin", ""]]}, {"id": "1905.10540", "submitter": "Xin Qian", "authors": "Xin Qian, Matthew Kennedy, and Diego Klabjan", "title": "Dynamic Cell Structure via Recursive-Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recurrent setting, conventional approaches to neural architecture search\nfind and fix a general model for all data samples and time steps. We propose a\nnovel algorithm that can dynamically search for the structure of cells in a\nrecurrent neural network model. Based on a combination of recurrent and\nrecursive neural networks, our algorithm is able to construct customized cell\nstructures for each data sample and time step, allowing for a more efficient\narchitecture search than existing models. Experiments on three common datasets\nshow that the algorithm discovers high-performance cell architectures and\nachieves better prediction accuracy compared to the GRU structure for language\nmodelling and sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:14:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Qian", "Xin", ""], ["Kennedy", "Matthew", ""], ["Klabjan", "Diego", ""]]}, {"id": "1905.10546", "submitter": "Omer Ben-Porat", "authors": "Omer Ben-Porat, Fedor Sandomirskiy, Moshe Tennenholtz", "title": "Protecting the Protected Group: Circumventing Harmful Fairness", "comments": "Published in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms shape our lives. Banks use them to determine\nif we are good borrowers; IT companies delegate them recruitment decisions;\npolice apply ML for crime-prediction, and judges base their verdicts on ML.\nHowever, real-world examples show that such automated decisions tend to\ndiscriminate against protected groups. This potential discrimination generated\na huge hype both in media and in the research community. Quite a few formal\nnotions of fairness were proposed, which take a form of constraints a \"fair\"\nalgorithm must satisfy. We focus on scenarios where fairness is imposed on a\nself-interested party (e.g., a bank that maximizes its revenue). We find that\nthe disadvantaged protected group can be worse off after imposing a fairness\nconstraint. We introduce a family of \\textit{Welfare-Equalizing} fairness\nconstraints that equalize per-capita welfare of protected groups, and include\n\\textit{Demographic Parity} and \\textit{Equal Opportunity} as particular cases.\nIn this family, we characterize conditions under which the fairness constraint\nhelps the disadvantaged group. We also characterize the structure of the\noptimal \\textit{Welfare-Equalizing} classifier for the self-interested party,\nand provide an algorithm to compute it. Overall, our\n\\textit{Welfare-Equalizing} fairness approach provides a unified framework for\ndiscussing fairness in classification in the presence of a self-interested\nparty.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:37:21 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:29:02 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 12:15:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ben-Porat", "Omer", ""], ["Sandomirskiy", "Fedor", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "1905.10549", "submitter": "Vincenzo Crescimanna", "authors": "Vincenzo Crescimanna and Bruce Graham", "title": "The Variational InfoMax AutoEncoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational AutoEncoder (VAE) learns simultaneously an inference and a\ngenerative model, but only one of these models can be learned at optimum, this\nbehaviour is associated to the ELBO learning objective, that is optimised by a\nnon-informative generator. In order to solve such an issue, we provide a\nlearning objective, learning a maximal informative generator while maintaining\nbounded the network capacity: the Variational InfoMax (VIM). The contribution\nof the VIM derivation is twofold: an objective learning both an optimal\ninference and generative model and the explicit definition of the network\ncapacity, an estimation of the network robustness.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:42:09 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 16:40:20 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Crescimanna", "Vincenzo", ""], ["Graham", "Bruce", ""]]}, {"id": "1905.10550", "submitter": "Evgeny Burnaev", "authors": "Marina Pominova and Anna Kuzina and Ekaterina Kondrateva and Svetlana\n  Sushchinskaya and Maxim Sharaev and Evgeny Burnaev and and Vyacheslav Yarkin", "title": "Ensemble of 3D CNN regressors with data fusion for fluid intelligence\n  prediction", "comments": "10 pages, 1 figure, 2 tables", "journal-ref": "ABCD Neurocognitive Prediction Challenge, Springer LNCS, 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim at predicting children's fluid intelligence scores based\non structural T1-weighted MR images from the largest long-term study of brain\ndevelopment and child health. The target variable was regressed on a data\ncollection site, socio-demographic variables and brain volume, thus being\nindependent to the potentially informative factors, which are not directly\nrelated to the brain functioning. We investigate both feature extraction and\ndeep learning approaches as well as different deep CNN architectures and their\nensembles. We propose an advanced architecture of VoxCNNs ensemble, which yield\nMSE (92.838) on blind test.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:54:56 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Pominova", "Marina", ""], ["Kuzina", "Anna", ""], ["Kondrateva", "Ekaterina", ""], ["Sushchinskaya", "Svetlana", ""], ["Sharaev", "Maxim", ""], ["Burnaev", "Evgeny", ""], ["Yarkin", "and Vyacheslav", ""]]}, {"id": "1905.10564", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Yan Zhang, Sheng Li, Guangcan Liu, Meng Wang, Shuicheng\n  Yan", "title": "Robust Unsupervised Flexible Auto-weighted Local-Coordinate Concept\n  Factorization for Image Clustering", "comments": "Accepted at the 44th IEEE International Conference on Acoustics,\n  Speech, and Signal Processing(ICASSP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the high-dimensional data clustering problem by proposing a\nnovel and unsupervised representation learning model called Robust Flexible\nAuto-weighted Local-coordinate Concept Factorization (RFA-LCF). RFA-LCF\nintegrates the robust flexible CF, robust sparse local-coordinate coding and\nthe adaptive reconstruction weighting learning into a unified model. The\nadaptive weighting is driven by including the joint manifold preserving\nconstraints on the recovered clean data, basis concepts and new representation.\nSpecifically, our RFA-LCF uses a L2,1-norm based flexible residue to encode the\nmismatch between clean data and its reconstruction, and also applies the robust\nadaptive sparse local-coordinate coding to represent the data using a few\nnearby basis concepts, which can make the factorization more accurate and\nrobust to noise. The robust flexible factorization is also performed in the\nrecovered clean data space for enhancing representations. RFA-LCF also\nconsiders preserving the local manifold structures of clean data space, basis\nconcept space and the new coordinate space jointly in an adaptive manner way.\nExtensive comparisons show that RFA-LCF can deliver enhanced clustering\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 10:02:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Zhao", ""], ["Zhang", "Yan", ""], ["Li", "Sheng", ""], ["Liu", "Guangcan", ""], ["Wang", "Meng", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1905.10566", "submitter": "Giovanni Chierchia", "authors": "Giovanni Chierchia and Benjamin Perret", "title": "Ultrametric Fitting by Gradient Descent", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": "10.1088/1742-5468/abc62d", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fitting an ultrametric distance to a dissimilarity\ngraph in the context of hierarchical cluster analysis. Standard hierarchical\nclustering methods are specified procedurally, rather than in terms of the cost\nfunction to be optimized. We aim to overcome this limitation by presenting a\ngeneral optimization framework for ultrametric fitting. Our approach consists\nof modeling the latter as a constrained optimization problem over the\ncontinuous space of ultrametrics. So doing, we can leverage the simple, yet\neffective, idea of replacing the ultrametric constraint with a min-max\noperation injected directly into the cost function. The proposed reformulation\nleads to an unconstrained optimization problem that can be efficiently solved\nby gradient descent methods. The flexibility of our framework allows us to\ninvestigate several cost functions, following the classic paradigm of combining\na data fidelity term with a regularization. While we provide no theoretical\nguarantee to find the global optimum, the numerical results obtained over a\nnumber of synthetic and real datasets demonstrate the good performance of our\napproach with respect to state-of-the-art agglomerative algorithms. This makes\nus believe that the proposed framework sheds new light on the way to design a\nnew generation of hierarchical clustering methods. Our code is made publicly\navailable at \\url{https://github.com/PerretB/ultrametric-fitting}.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 10:33:07 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 20:12:31 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 15:19:49 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chierchia", "Giovanni", ""], ["Perret", "Benjamin", ""]]}, {"id": "1905.10575", "submitter": "Zhaohong Deng", "authors": "Xiang Ma, Zhaohong Deng, Peng Xu, Kup-Sze Choi, Dongrui Wu, Shitong\n  Wang", "title": "Deep Image Feature Learning with Fuzzy Rules", "comments": "Submitted to IEEE TETCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methods of extracting image features are the key to many image processing\ntasks. At present, the most popular method is the deep neural network which can\nautomatically extract robust features through end-to-end training instead of\nhand-crafted feature extraction. However, the deep neural network currently\nfaces many challenges: 1) its effectiveness is heavily dependent on large\ndatasets, so the computational complexity is very high; 2) it is usually\nregarded as a black box model with poor interpretability. To meet the above\nchallenges, a more interpretable and scalable feature learning method, i.e.,\ndeep image feature learning with fuzzy rules (DIFL-FR), is proposed in the\npaper, which combines the rule-based fuzzy modeling technique and the deep\nstacked learning strategy. The method progressively learns image features\nthrough a layer-by-layer manner based on fuzzy rules, so the feature learning\nprocess can be better explained by the generated rules. More importantly, the\nlearning process of the method is only based on forward propagation without\nback propagation and iterative learning, which results in the high learning\nefficiency. In addition, the method is under the settings of unsupervised\nlearning and can be easily extended to scenes of supervised and semi-supervised\nlearning. Extensive experiments are conducted on image datasets of different\nscales. The results obviously show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 11:33:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 00:03:26 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ma", "Xiang", ""], ["Deng", "Zhaohong", ""], ["Xu", "Peng", ""], ["Choi", "Kup-Sze", ""], ["Wu", "Dongrui", ""], ["Wang", "Shitong", ""]]}, {"id": "1905.10585", "submitter": "Jan Melchior", "authors": "Jan Melchior, Laurenz Wiskott", "title": "Hebbian-Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose Hebbian-descent as a biologically plausible learning\nrule for hetero-associative as well as auto-associative learning in single\nlayer artificial neural networks. It can be used as a replacement for gradient\ndescent as well as Hebbian learning, in particular in online learning, as it\ninherits their advantages while not suffering from their disadvantages. We\ndiscuss the drawbacks of Hebbian learning as having problems with correlated\ninput data and not profiting from seeing training patterns several times. For\ngradient descent we identify the derivative of the activation function as\nproblematic especially in online learning. Hebbian-descent addresses these\nproblems by getting rid of the activation function's derivative and by\ncentering, i.e. keeping the neural activities mean free, leading to a\nbiologically plausible update rule that is provably convergent, does not suffer\nfrom the vanishing error term problem, can deal with correlated data, profits\nfrom seeing patterns several times, and enables successful online learning when\ncentering is used. We discuss its relationship to Hebbian learning, contrastive\nlearning, and gradient decent and show that in case of a strictly positive\nderivative of the activation function Hebbian-descent leads to the same update\nrule as gradient descent but for a different loss function. In this case\nHebbian-descent inherits the convergence properties of gradient descent, but we\nalso show empirically that it converges when the derivative of the activation\nfunction is only non-negative, such as for the step function for example.\nFurthermore, in case of the mean squared error loss Hebbian-descent can be\nunderstood as the difference between two Hebb-learning steps, which in case of\nan invertible and integrable activation function actually optimizes a\ngeneralized linear model. ...\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 12:11:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Melchior", "Jan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1905.10587", "submitter": "Gil Shabat", "authors": "Gil Shabat, Era Choshen, Dvir Ben Or, Nadav Carmel", "title": "Fast and Accurate Gaussian Kernel Ridge Regression Using Matrix\n  Decompositions for Preconditioning", "comments": "accepted to SIAM Journal on Matrix Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for building a preconditioner for a kernel ridge\nregression problem, where the preconditioner is not only effective in its\nability to reduce the condition number substantially, but also efficient in its\napplication in terms of computational cost and memory consumption. The\nsuggested approach is based on randomized matrix decomposition methods,\ncombined with the fast multipole method to achieve an algorithm that can\nprocess large datasets in complexity linear to the number of data points. In\naddition, a detailed theoretical analysis is provided, including an upper bound\nto the condition number. Finally, for Gaussian kernels, the analysis shows that\nthe required rank for a desired condition number can be determined directly\nfrom the dataset itself without performing any analysis on the kernel matrix.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 12:28:42 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 13:32:15 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 09:25:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Shabat", "Gil", ""], ["Choshen", "Era", ""], ["Or", "Dvir Ben", ""], ["Carmel", "Nadav", ""]]}, {"id": "1905.10594", "submitter": "Peng Xu", "authors": "Peng Xu, Zhaohong Deng, Kup-Sze Choi, Longbing Cao, Shitong Wang", "title": "Multi-view Information-theoretic Co-clustering for Co-occurrence Data", "comments": null, "journal-ref": "AAAI 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering has received much attention recently. Most of the\nexisting multi-view clustering methods only focus on one-sided clustering. As\nthe co-occurring data elements involve the counts of sample-feature\nco-occurrences, it is more efficient to conduct two-sided clustering along the\nsamples and features simultaneously. To take advantage of two-sided clustering\nfor the co-occurrences in the scene of multi-view clustering, a two-sided\nmulti-view clustering method is proposed, i.e., multi-view\ninformation-theoretic co-clustering (MV-ITCC). The proposed method realizes\ntwo-sided clustering for co-occurring multi-view data under the formulation of\ninformation theory. More specifically, it exploits the agreement and\ndisagreement among views by sharing a common clustering results along the\nsample dimension and keeping the clustering results of each view specific along\nthe feature dimension. In addition, the mechanism of maximum entropy is also\nadopted to control the importance of different views, which can give a right\nbalance in leveraging the agreement and disagreement. Extensive experiments are\nconducted on text and image multi-view datasets. The results clearly\ndemonstrate the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 13:25:20 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Xu", "Peng", ""], ["Deng", "Zhaohong", ""], ["Choi", "Kup-Sze", ""], ["Cao", "Longbing", ""], ["Wang", "Shitong", ""]]}, {"id": "1905.10601", "submitter": "Chai Wah Wu", "authors": "Chai Wah Wu", "title": "TableNet: a multiplier-less implementation of neural networks for\n  inferencing", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of look-up tables (LUT) to simplify the hardware\nimplementation of a deep learning network for inferencing after weights have\nbeen successfully trained. The use of LUT replaces the matrix multiply and add\noperations with a small number of LUTs and addition operations resulting in a\ncompletely multiplier-less implementation. We compare the different tradeoffs\nof this approach in terms of accuracy versus LUT size and the number of\noperations and show that similar performance can be obtained with a comparable\nmemory footprint as a full precision deep neural network, but without the use\nof any multipliers. We illustrate this with several architectures such as MLP\nand CNN.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 14:17:44 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 00:43:23 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wu", "Chai Wah", ""]]}, {"id": "1905.10604", "submitter": "Rita Singh", "authors": "Yandong Wen and Rita Singh and Bhiksha Raj", "title": "Reconstructing faces from voices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice profiling aims at inferring various human parameters from their speech,\ne.g. gender, age, etc. In this paper, we address the challenge posed by a\nsubtask of voice profiling - reconstructing someone's face from their voice.\nThe task is designed to answer the question: given an audio clip spoken by an\nunseen person, can we picture a face that has as many common elements, or\nassociations as possible with the speaker, in terms of identity? To address\nthis problem, we propose a simple but effective computational framework based\non generative adversarial networks (GANs). The network learns to generate faces\nfrom voices by matching the identities of generated faces to those of the\nspeakers, on a training set. We evaluate the performance of the network by\nleveraging a closely related task - cross-modal matching. The results show that\nour model is able to generate faces that match several biometric\ncharacteristics of the speaker, and results in matching accuracies that are\nmuch better than chance.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 14:33:59 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 19:53:01 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wen", "Yandong", ""], ["Singh", "Rita", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1905.10607", "submitter": "Saeed Sharifi-Malvajerdi", "authors": "Michael Kearns, Aaron Roth, Saeed Sharifi-Malvajerdi", "title": "Average Individual Fairness: Algorithms, Generalization and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of fairness definitions for classification problems\nthat combine some of the best properties of both statistical and individual\nnotions of fairness. We posit not only a distribution over individuals, but\nalso a distribution over (or collection of) classification tasks. We then ask\nthat standard statistics (such as error or false positive/negative rates) be\n(approximately) equalized across individuals, where the rate is defined as an\nexpectation over the classification tasks. Because we are no longer averaging\nover coarse groups (such as race or gender), this is a semantically meaningful\nindividual-level constraint. Given a sample of individuals and classification\nproblems, we design an oracle-efficient algorithm (i.e. one that is given\naccess to any standard, fairness-free learning heuristic) for the fair\nempirical risk minimization task. We also show that given sufficiently many\nsamples, the ERM solution generalizes in two directions: both to new\nindividuals, and to new classification tasks, drawn from their corresponding\ndistributions. Finally we implement our algorithm and empirically verify its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 14:45:56 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 21:40:16 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Kearns", "Michael", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""]]}, {"id": "1905.10615", "submitter": "Adam Gleave", "authors": "Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine,\n  Stuart Russell", "title": "Adversarial Policies: Attacking Deep Reinforcement Learning", "comments": "Presented at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) policies are known to be vulnerable to\nadversarial perturbations to their observations, similar to adversarial\nexamples for classifiers. However, an attacker is not usually able to directly\nmodify another agent's observations. This might lead one to wonder: is it\npossible to attack an RL agent simply by choosing an adversarial policy acting\nin a multi-agent environment so as to create natural observations that are\nadversarial? We demonstrate the existence of adversarial policies in zero-sum\ngames between simulated humanoid robots with proprioceptive observations,\nagainst state-of-the-art victims trained via self-play to be robust to\nopponents. The adversarial policies reliably win against the victims but\ngenerate seemingly random and uncoordinated behavior. We find that these\npolicies are more successful in high-dimensional environments, and induce\nsubstantially different activations in the victim policy network than when the\nvictim plays against a normal opponent. Videos are available at\nhttps://adversarialpolicies.github.io/.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:23:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:54:47 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 19:25:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Gleave", "Adam", ""], ["Dennis", "Michael", ""], ["Wild", "Cody", ""], ["Kant", "Neel", ""], ["Levine", "Sergey", ""], ["Russell", "Stuart", ""]]}, {"id": "1905.10617", "submitter": "Tianxing He", "authors": "Tianxing He, Jingzhao Zhang, Zhiming Zhou, James Glass", "title": "Quantifying Exposure Bias for Open-ended Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exposure bias problem refers to the incrementally distorted generation\ninduced by the training-generation discrepancy, in teacher-forcing training for\nauto-regressive neural network language models (LM). It has been regarded as a\ncentral problem for LMs trained for open-ended language generation. Although a\nlot of algorithms have been proposed to avoid teacher forcing and therefore\nalleviate exposure bias, there is little work showing how serious the exposure\nbias problem actually is. In this work, we propose novel metrics to quantify\nthe impact of exposure bias in the generation of MLE-trained LMs. Our key\nintuition is that if we feed ground-truth data prefixes (instead of prefixes\ngenerated by the model itself) into the model and ask it to continue the\ngeneration, the performance should become much better because the\ntraining-generation discrepancy in the prefix is removed. We conduct both\nautomatic and human evaluation in our experiments, and our observations are\ntwo-fold: (1) We confirm that the prefix discrepancy indeed induces some level\nof performance loss. (2) However, the induced distortion seems to be limited,\nand is not incremental during the generation, which contradicts the claim of\nexposure bias.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:34:43 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:36:54 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 16:00:27 GMT"}, {"version": "v4", "created": "Sat, 8 Feb 2020 19:18:44 GMT"}, {"version": "v5", "created": "Fri, 17 Apr 2020 15:59:05 GMT"}, {"version": "v6", "created": "Thu, 24 Dec 2020 01:11:21 GMT"}, {"version": "v7", "created": "Thu, 31 Dec 2020 03:12:32 GMT"}, {"version": "v8", "created": "Wed, 31 Mar 2021 00:38:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["He", "Tianxing", ""], ["Zhang", "Jingzhao", ""], ["Zhou", "Zhiming", ""], ["Glass", "James", ""]]}, {"id": "1905.10626", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu", "title": "Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work shows that adversarially robust generalization requires larger\nsample complexity, and the same dataset, e.g., CIFAR-10, which enables good\nstandard accuracy may not suffice to train robust models. Since collecting new\ntraining data could be costly, we focus on better utilizing the given data by\ninducing the regions with high sample density in the feature space, which could\nlead to locally sufficient samples for robust learning. We first formally show\nthat the softmax cross-entropy (SCE) loss and its variants convey inappropriate\nsupervisory signals, which encourage the learned feature points to spread over\nthe space sparsely in training. This inspires us to propose the Max-Mahalanobis\ncenter (MMC) loss to explicitly induce dense feature regions in order to\nbenefit robustness. Namely, the MMC loss encourages the model to concentrate on\nlearning ordered and compact representations, which gather around the preset\noptimal centers for different classes. We empirically demonstrate that applying\nthe MMC loss can significantly improve robustness even under strong adaptive\nattacks, while keeping state-of-the-art accuracy on clean inputs with little\nextra computation compared to the SCE loss.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:11:14 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:35:29 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 08:50:47 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pang", "Tianyu", ""], ["Xu", "Kun", ""], ["Dong", "Yinpeng", ""], ["Du", "Chao", ""], ["Chen", "Ning", ""], ["Zhu", "Jun", ""]]}, {"id": "1905.10629", "submitter": "Jonathan Vacher", "authors": "Jonathan Vacher, Claire Launay and Ruben Coen-Cagli", "title": "Flexibly Regularized Mixture Models and Application to Image\n  Segmentation", "comments": "33 pages ( 30 + 3 for appendix). 11 figures + 1 in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic finite mixture models are widely used for unsupervised\nclustering. These models can often be improved by adapting them to the topology\nof the data. For instance, in order to classify spatially adjacent data points\nsimilarly, it is common to introduce a Laplacian constraint on the posterior\nprobability that each data point belongs to a class. Alternatively, the mixing\nprobabilities can be treated as free parameters, while assuming Gauss-Markov or\nmore complex priors to regularize those mixing probabilities. However, these\napproaches are constrained by the shape of the prior and often lead to\ncomplicated or intractable inference. Here, we propose a new parametrization of\nthe Dirichlet distribution to flexibly regularize the mixing probabilities of\nover-parametrized mixture distributions. Using the Expectation-Maximization\nalgorithm, we show that our approach allows us to define any linear update rule\nfor the mixing probabilities, including spatial smoothing regularization as a\nspecial case. We then show that this flexible design can be extended to share\nclass information between multiple mixture models. We apply our algorithm to\nartificial and natural image segmentation tasks, and we provide quantitative\nand qualitative comparison of the performance of Gaussian and Student-t\nmixtures on the Berkeley Segmentation Dataset. We also demonstrate how to\npropagate class information across the layers of deep convolutional neural\nnetworks in a probabilistically optimal way, suggesting a new interpretation\nfor feedback signals in biological visual systems. Our flexible approach can be\neasily generalized to adapt probabilistic mixture models to arbitrary data\ntopologies.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:55:19 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 08:48:58 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Vacher", "Jonathan", ""], ["Launay", "Claire", ""], ["Coen-Cagli", "Ruben", ""]]}, {"id": "1905.10630", "submitter": "Liwei Wu", "authors": "Liwei Wu, Shuqing Li, Cho-Jui Hsieh, James Sharpnack", "title": "Stochastic Shared Embeddings: Data-driven Regularization of Embedding\n  Layers", "comments": "Accepted to 2019 Conference on Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural nets, lower level embedding layers account for a large portion\nof the total number of parameters. Tikhonov regularization, graph-based\nregularization, and hard parameter sharing are approaches that introduce\nexplicit biases into training in a hope to reduce statistical complexity.\nAlternatively, we propose stochastically shared embeddings (SSE), a data-driven\napproach to regularizing embedding layers, which stochastically transitions\nbetween embeddings during stochastic gradient descent (SGD). Because SSE\nintegrates seamlessly with existing SGD algorithms, it can be used with only\nminor modifications when training large scale neural networks. We develop two\nversions of SSE: SSE-Graph using knowledge graphs of embeddings; SSE-SE using\nno prior information. We provide theoretical guarantees for our method and show\nits empirical effectiveness on 6 distinct tasks, from simple neural networks\nwith one hidden layer in recommender systems, to the transformer and BERT in\nnatural languages. We find that when used along with widely-used regularization\nmethods such as weight decay and dropout, our proposed SSE can further reduce\noverfitting, which often leads to more favorable generalization results.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:55:36 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:26:53 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 21:58:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wu", "Liwei", ""], ["Li", "Shuqing", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1905.10634", "submitter": "Danijel Kivaranovic", "authors": "Danijel Kivaranovic, Kory D. Johnson, Hannes Leeb", "title": "Adaptive, Distribution-Free Prediction Intervals for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning literature contains several constructions for prediction\nintervals that are intuitively reasonable but ultimately ad-hoc in that they do\nnot come with provable performance guarantees. We present methods from the\nstatistics literature that can be used efficiently with neural networks under\nminimal assumptions with guaranteed performance. We propose a neural network\nthat outputs three values instead of a single point estimate and optimizes a\nloss function motivated by the standard quantile regression loss. We provide\ntwo prediction interval methods with finite sample coverage guarantees solely\nunder the assumption that the observations are independent and identically\ndistributed. The first method leverages the conformal inference framework and\nprovides average coverage. The second method provides a new, stronger guarantee\nby conditioning on the observed data. Lastly, our loss function does not\ncompromise the predictive accuracy of the network like other prediction\ninterval methods. We demonstrate the ease of use of our procedures as well as\nits improvements over other methods on both simulated and real data. As most\ndeep networks can easily be modified by our method to output predictions with\nvalid prediction intervals, its use should become standard practice, much like\nreporting standard errors along with mean estimates.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 17:07:33 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 10:01:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kivaranovic", "Danijel", ""], ["Johnson", "Kory D.", ""], ["Leeb", "Hannes", ""]]}, {"id": "1905.10649", "submitter": "Adrian Rivera Cardoso", "authors": "Adrian Rivera Cardoso, He Wang, Huan Xu", "title": "Large Scale Markov Decision Processes with Changing Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov Decision Processes (MDPs) where the rewards are unknown\nand may change in an adversarial manner. We provide an algorithm that achieves\nstate-of-the-art regret bound of $O( \\sqrt{\\tau (\\ln|S|+\\ln|A|)T}\\ln(T))$,\nwhere $S$ is the state space, $A$ is the action space, $\\tau$ is the mixing\ntime of the MDP, and $T$ is the number of periods. The algorithm's\ncomputational complexity is polynomial in $|S|$ and $|A|$ per period. We then\nconsider a setting often encountered in practice, where the state space of the\nMDP is too large to allow for exact solutions. By approximating the\nstate-action occupancy measures with a linear architecture of dimension\n$d\\ll|S|$, we propose a modified algorithm with computational complexity\npolynomial in $d$. We also prove a regret bound for this modified algorithm,\nwhich to the best of our knowledge this is the first $\\tilde{O}(\\sqrt{T})$\nregret bound for large scale MDPs with changing rewards.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 18:26:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Wang", "He", ""], ["Xu", "Huan", ""]]}, {"id": "1905.10651", "submitter": "Wei Peng", "authors": "Wei Peng, Tim Coleman, Lucas Mentch", "title": "Asymptotic Distributions and Rates of Convergence for Random Forests via\n  Generalized U-statistics", "comments": "62 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests remain among the most popular off-the-shelf supervised\nlearning algorithms. Despite their well-documented empirical success, however,\nuntil recently, few theoretical results were available to describe their\nperformance and behavior. In this work we push beyond recent work on\nconsistency and asymptotic normality by establishing rates of convergence for\nrandom forests and other supervised learning ensembles. We develop the notion\nof generalized U-statistics and show that within this framework, random forest\npredictions can potentially remain asymptotically normal for larger subsample\nsizes than previously established. We also provide Berry-Esseen bounds in order\nto quantify the rate at which this convergence occurs, making explicit the\nroles of the subsample size and the number of trees in determining the\ndistribution of random forest predictions.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 18:31:23 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:33:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Peng", "Wei", ""], ["Coleman", "Tim", ""], ["Mentch", "Lucas", ""]]}, {"id": "1905.10659", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Michael D. Himes, Frank Soboczenski, Simone Zorzan,\n  Molly D. O'Beirne, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Yarin Gal, Shawn D.\n  Domagal-Goldman, Giada N. Arney, Daniel Angerhausen", "title": "An Ensemble of Bayesian Neural Networks for Exoplanetary Atmospheric\n  Retrieval", "comments": null, "journal-ref": null, "doi": "10.3847/1538-3881/ab2390", "report-no": null, "categories": "astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is now used in many areas of astrophysics, from detecting\nexoplanets in Kepler transit signals to removing telescope systematics. Recent\nwork demonstrated the potential of using machine learning algorithms for\natmospheric retrieval by implementing a random forest to perform retrievals in\nseconds that are consistent with the traditional, computationally-expensive\nnested-sampling retrieval method. We expand upon their approach by presenting a\nnew machine learning model, \\texttt{plan-net}, based on an ensemble of Bayesian\nneural networks that yields more accurate inferences than the random forest for\nthe same data set of synthetic transmission spectra. We demonstrate that an\nensemble provides greater accuracy and more robust uncertainties than a single\nmodel. In addition to being the first to use Bayesian neural networks for\natmospheric retrieval, we also introduce a new loss function for Bayesian\nneural networks that learns correlations between the model outputs.\nImportantly, we show that designing machine learning models to explicitly\nincorporate domain-specific knowledge both improves performance and provides\nadditional insight by inferring the covariance of the retrieved atmospheric\nparameters. We apply \\texttt{plan-net} to the Hubble Space Telescope Wide Field\nCamera 3 transmission spectrum for WASP-12b and retrieve an isothermal\ntemperature and water abundance consistent with the literature. We highlight\nthat our method is flexible and can be expanded to higher-resolution spectra\nand a larger number of atmospheric parameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 19:15:24 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Cobb", "Adam D.", ""], ["Himes", "Michael D.", ""], ["Soboczenski", "Frank", ""], ["Zorzan", "Simone", ""], ["O'Beirne", "Molly D.", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gal", "Yarin", ""], ["Domagal-Goldman", "Shawn D.", ""], ["Arney", "Giada N.", ""], ["Angerhausen", "Daniel", ""]]}, {"id": "1905.10660", "submitter": "Christopher Jung", "authors": "Christopher Jung, Michael Kearns, Seth Neel, Aaron Roth, Logan\n  Stapleton, Zhiwei Steven Wu", "title": "An Algorithmic Framework for Fairness Elicitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider settings in which the right notion of fairness is not captured by\nsimple mathematical definitions (such as equality of error rates across\ngroups), but might be more complex and nuanced and thus require elicitation\nfrom individual or collective stakeholders. We introduce a framework in which\npairs of individuals can be identified as requiring (approximately) equal\ntreatment under a learned model, or requiring ordered treatment such as\n\"applicant Alice should be at least as likely to receive a loan as applicant\nBob\". We provide a provably convergent and oracle efficient algorithm for\nlearning the most accurate model subject to the elicited fairness constraints,\nand prove generalization bounds for both accuracy and fairness. This algorithm\ncan also combine the elicited constraints with traditional statistical fairness\nnotions, thus \"correcting\" or modifying the latter by the former. We report\npreliminary findings of a behavioral study of our framework using human-subject\nfairness constraints elicited on the COMPAS criminal recidivism dataset.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 19:19:13 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 15:08:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Jung", "Christopher", ""], ["Kearns", "Michael", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Stapleton", "Logan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1905.10661", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Locality-Promoting Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates fundamental questions related to learning features in\nconvolutional neural networks (CNN). Empirical findings across multiple\narchitectures such as VGG, ResNet, Inception, DenseNet and MobileNet indicate\nthat weights near the center of a filter are larger than weights on the\noutside. Current regularization schemes violate this principle. Thus, we\nintroduce Locality-promoting Regularization (LOCO-Reg), which yields accuracy\ngains across multiple architectures and datasets. We also show theoretically\nthat the empirical finding is a consequence of maximizing feature cohesion\nunder the assumption of spatial locality.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 19:19:14 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 10:06:54 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 16:09:40 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "1905.10668", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Qiaoyu Tan, Yuening Li, Hongxia Yang, Jingren Zhou, Xia\n  Hu", "title": "Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330967", "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks have been widely used as the data structure for abstracting\nreal-world systems as well as organizing the relations among entities. Network\nembedding models are powerful tools in mapping nodes in a network into\ncontinuous vector-space representations in order to facilitate subsequent tasks\nsuch as classification and link prediction. Existing network embedding models\ncomprehensively integrate all information of each node, such as links and\nattributes, towards a single embedding vector to represent the node's general\nrole in the network. However, a real-world entity could be multifaceted, where\nit connects to different neighborhoods due to different motives or\nself-characteristics that are not necessarily correlated. For example, in a\nmovie recommender system, a user may love comedies or horror movies\nsimultaneously, but it is not likely that these two types of movies are\nmutually close in the embedding space, nor the user embedding vector could be\nsufficiently close to them at the same time. In this paper, we propose a\npolysemous embedding approach for modeling multiple facets of nodes, as\nmotivated by the phenomenon of word polysemy in language modeling. Each facet\nof a node is mapped as an embedding vector, while we also maintain association\ndegree between each pair of node and facet. The proposed method is adaptive to\nvarious existing embedding models, without significantly complicating the\noptimization process. We also discuss how to engage embedding vectors of\ndifferent facets for inference tasks including classification and link\nprediction. Experiments on real-world datasets help comprehensively evaluate\nthe performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 19:57:57 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Liu", "Ninghao", ""], ["Tan", "Qiaoyu", ""], ["Li", "Yuening", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Hu", "Xia", ""]]}, {"id": "1905.10671", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Senwei Liang, Mingfu Liang, Haizhao Yang", "title": "DIANet: Dense-and-Implicit Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks have successfully boosted the performance in various\nvision problems. Previous works lay emphasis on designing a new attention\nmodule and individually plug them into the networks. Our paper proposes a\nnovel-and-simple framework that shares an attention module throughout different\nnetwork layers to encourage the integration of layer-wise information and this\nparameter-sharing module is referred as Dense-and-Implicit-Attention (DIA)\nunit. Many choices of modules can be used in the DIA unit. Since Long Short\nTerm Memory (LSTM) has a capacity of capturing long-distance dependency, we\nfocus on the case when the DIA unit is the modified LSTM (refer as DIA-LSTM).\nExperiments on benchmark datasets show that the DIA-LSTM unit is capable of\nemphasizing layer-wise feature interrelation and leads to significant\nimprovement of image classification accuracy. We further empirically show that\nthe DIA-LSTM has a strong regularization ability on stabilizing the training of\ndeep networks by the experiments with the removal of skip connections or Batch\nNormalization in the whole residual network. The code is released at\nhttps://github.com/gbup-group/DIANet.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 20:51:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 08:23:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Liang", "Senwei", ""], ["Liang", "Mingfu", ""], ["Yang", "Haizhao", ""]]}, {"id": "1905.10674", "submitter": "William L Hamilton", "authors": "Avishek Joey Bose, William L. Hamilton", "title": "Compositional Fairness Constraints for Graph Embeddings", "comments": "Proceedings of the 36th International Conference on Machine Learning,\n  Long Beach, California, PMLR 97, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning high-quality node embeddings is a key building block for machine\nlearning models that operate on graph data, such as social networks and\nrecommender systems. However, existing graph embedding techniques are unable to\ncope with fairness constraints, e.g., ensuring that the learned representations\ndo not correlate with certain attributes, such as age or gender. Here, we\nintroduce an adversarial framework to enforce fairness constraints on graph\nembeddings. Our approach is compositional---meaning that it can flexibly\naccommodate different combinations of fairness constraints during inference.\nFor instance, in the context of social recommendations, our framework would\nallow one user to request that their recommendations are invariant to both\ntheir age and gender, while also allowing another user to request invariance to\njust their age. Experiments on standard knowledge graph and recommender system\nbenchmarks highlight the utility of our proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:13:27 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 22:20:27 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 16:42:35 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 22:11:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Hamilton", "William L.", ""]]}, {"id": "1905.10675", "submitter": "Artzai Picon", "authors": "Alfonso Medela and Artzai Picon", "title": "Constellation Loss: Improving the efficiency of deep metric learning\n  loss functions for optimal embedding", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning has become an attractive field for research on the latest\nyears. Loss functions like contrastive loss, triplet loss or multi-class N-pair\nloss have made possible generating models capable of tackling complex scenarios\nwith the presence of many classes and scarcity on the number of images per\nclass not only work to build classifiers, but to many other applications where\nmeasuring similarity is the key. Deep Neural Networks trained via metric\nlearning also offer the possibility to solve few-shot learning problems.\nCurrently used state of the art loss functions such as triplet and contrastive\nloss functions, still suffer from slow convergence due to the selection of\neffective training samples that has been partially solved by the multi-class\nN-pair loss by simultaneously adding additional samples from the different\nclasses. In this work, we extend triplet and multiclass-N-pair loss function by\nproposing the constellation loss metric where the distances among all class\ncombinations are simultaneously learned. We have compared our constellation\nloss for visual class embedding showing that our loss function over-performs\nthe other methods by obtaining more compact clusters while achieving better\nclassification results.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:16:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Medela", "Alfonso", ""], ["Picon", "Artzai", ""]]}, {"id": "1905.10680", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Ashok Cutkosky, Francesco Orabona", "title": "Kernel Truncated Randomized Ridge Regression: Optimal Rates and Low\n  Noise Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the nonparametric least square regression in a\nReproducing Kernel Hilbert Space (RKHS). We propose a new randomized algorithm\nthat has optimal generalization error bounds with respect to the square loss,\nclosing a long-standing gap between upper and lower bounds. Moreover, we show\nthat our algorithm has faster finite-time and asymptotic rates on problems\nwhere the Bayes risk with respect to the square loss is small. We state our\nresults using standard tools from the theory of least square regression in\nRKHSs, namely, the decay of the eigenvalues of the associated integral operator\nand the complexity of the optimal predictor measured through the integral\noperator.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:36:56 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Cutkosky", "Ashok", ""], ["Orabona", "Francesco", ""]]}, {"id": "1905.10681", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Jacob J. Johnson, Yuzhe Qin, Taylor Henderson, Byron\n  Boots, Michael C. Yip", "title": "Composing Task-Agnostic Policies with Deep Reinforcement Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The composition of elementary behaviors to solve challenging transfer\nlearning problems is one of the key elements in building intelligent machines.\nTo date, there has been plenty of work on learning task-specific policies or\nskills but almost no focus on composing necessary, task-agnostic skills to find\na solution to new problems. In this paper, we propose a novel deep\nreinforcement learning-based skill transfer and composition method that takes\nthe agent's primitive policies to solve unseen tasks. We evaluate our method in\ndifficult cases where training policy through standard reinforcement learning\n(RL) or even hierarchical RL is either not feasible or exhibits high sample\ncomplexity. We show that our method not only transfers skills to new problem\nsettings but also solves the challenging environments requiring both task\nplanning and motion control with high data efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:40:38 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 20:32:24 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Johnson", "Jacob J.", ""], ["Qin", "Yuzhe", ""], ["Henderson", "Taylor", ""], ["Boots", "Byron", ""], ["Yip", "Michael C.", ""]]}, {"id": "1905.10686", "submitter": "Nicole M\\\"ucke", "authors": "Nicole M\\\"ucke and Ingo Steinwart", "title": "Empirical Risk Minimization in the Interpolating Regime with Application\n  to Neural Network Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy to train deep neural networks (DNNs) is to use very large\narchitectures and to train them until they (almost) achieve zero training\nerror. Empirically observed good generalization performance on test data, even\nin the presence of lots of label noise, corroborate such a procedure. On the\nother hand, in statistical learning theory it is known that over-fitting models\nmay lead to poor generalization properties, occurring in e.g. empirical risk\nminimization (ERM) over too large hypotheses classes. Inspired by this\ncontradictory behavior, so-called interpolation methods have recently received\nmuch attention, leading to consistent and optimally learning methods for some\nlocal averaging schemes with zero training error. However, there is no\ntheoretical analysis of interpolating ERM-like methods so far. We take a step\nin this direction by showing that for certain, large hypotheses classes, some\ninterpolating ERMs enjoy very good statistical guarantees while others fail in\nthe worst sense. Moreover, we show that the same phenomenon occurs for DNNs\nwith zero training error and sufficiently large architectures.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 22:16:38 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 10:13:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["M\u00fccke", "Nicole", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1905.10687", "submitter": "Jakob Kruse", "authors": "Jakob Kruse, Gianluca Detommaso, Ullrich K\\\"othe and Robert Scheichl", "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation\n  and Bayesian Inference", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent invertible neural architectures are based on coupling block\ndesigns where variables are divided in two subsets which serve as inputs of an\neasily invertible (usually affine) triangular transformation. While such a\ntransformation is invertible, its Jacobian is very sparse and thus may lack\nexpressiveness. This work presents a simple remedy by noting that subdivision\nand (affine) coupling can be repeated recursively within the resulting subsets,\nleading to an efficiently invertible block with dense, triangular Jacobian. By\nformulating our recursive coupling scheme via a hierarchical architecture, HINT\nallows sampling from a joint distribution p(y,x) and the corresponding\nposterior p(x|y) using a single invertible network. We evaluate our method on\nsome standard data sets and benchmark its full power for density estimation and\nBayesian inference on a novel data set of 2D shapes in Fourier\nparameterization, which enables consistent visualization of samples for\ndifferent dimensionalities.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 22:29:21 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 15:50:48 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 12:25:36 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 10:09:45 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Kruse", "Jakob", ""], ["Detommaso", "Gianluca", ""], ["K\u00f6the", "Ullrich", ""], ["Scheichl", "Robert", ""]]}, {"id": "1905.10688", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Madelon Hulsebos and Kevin Hu and Michiel Bakker and Emanuel Zgraggen\n  and Arvind Satyanarayan and Tim Kraska and \\c{C}a\\u{g}atay Demiralp and\n  C\\'esar Hidalgo", "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection", "comments": "KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly detecting the semantic type of data columns is crucial for data\nscience tasks such as automated data cleaning, schema matching, and data\ndiscovery. Existing data preparation and analysis systems rely on dictionary\nlookups and regular expression matching to detect semantic types. However,\nthese matching-based approaches often are not robust to dirty data and only\ndetect a limited number of types. We introduce Sherlock, a multi-input deep\nneural network for detecting semantic types. We train Sherlock on $686,765$\ndata columns retrieved from the VizNet corpus by matching $78$ semantic types\nfrom DBpedia to column headers. We characterize each matched column with\n$1,588$ features describing the statistical properties, character\ndistributions, word embeddings, and paragraph vectors of column values.\nSherlock achieves a support-weighted F$_1$ score of $0.89$, exceeding that of\nmachine learning baselines, dictionary and regular expression benchmarks, and\nthe consensus of crowdsourced annotations.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 22:36:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hulsebos", "Madelon", ""], ["Hu", "Kevin", ""], ["Bakker", "Michiel", ""], ["Zgraggen", "Emanuel", ""], ["Satyanarayan", "Arvind", ""], ["Kraska", "Tim", ""], ["Demiralp", "\u00c7a\u011fatay", ""], ["Hidalgo", "C\u00e9sar", ""]]}, {"id": "1905.10691", "submitter": "Osbert Bastani", "authors": "Osbert Bastani", "title": "Safe Reinforcement Learning with Nonlinear Dynamics via Model Predictive\n  Shielding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to synthesizing policies for\nchallenging robotics tasks. A key problem is how to ensure safety of the\nlearned policy---e.g., that a walking robot does not fall over or that an\nautonomous car does not run into an obstacle. We focus on the setting where the\ndynamics are known, and the goal is to ensure that a policy trained in\nsimulation satisfies a given safety constraint. We propose an approach, called\nmodel predictive shielding (MPS), that switches on-the-fly between a learned\npolicy and a backup policy to ensure safety. We prove that our approach\nguarantees safety, and empirically evaluate it on the cart-pole.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:09:44 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 21:30:16 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 14:27:24 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Bastani", "Osbert", ""]]}, {"id": "1905.10695", "submitter": "Tianfu Wu", "authors": "Zekun Zhang and Tianfu Wu", "title": "Adversarial Distillation for Ordered Top-k Attacks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, especially\nwhite-box targeted attacks. One scheme of learning attacks is to design a\nproper adversarial objective function that leads to the imperceptible\nperturbation for any test image (e.g., the Carlini-Wagner (C&W) method). Most\nmethods address targeted attacks in the Top-1 manner. In this paper, we propose\nto learn ordered Top-k attacks (k>= 1) for image classification tasks, that is\nto enforce the Top-k predicted labels of an adversarial example to be the k\n(randomly) selected and ordered labels (the ground-truth label is exclusive).\nTo this end, we present an adversarial distillation framework: First, we\ncompute an adversarial probability distribution for any given ordered Top-k\ntargeted labels with respect to the ground-truth of a test image. Then, we\nlearn adversarial examples by minimizing the Kullback-Leibler (KL) divergence\ntogether with the perturbation energy penalty, similar in spirit to the network\ndistillation method. We explore how to leverage label semantic similarities in\ncomputing the targeted distributions, leading to knowledge-oriented attacks. In\nexperiments, we thoroughly test Top-1 and Top-5 attacks in the ImageNet-1000\nvalidation dataset using two popular DNNs trained with clean ImageNet-1000\ntrain dataset, ResNet-50 and DenseNet-121. For both models, our proposed\nadversarial distillation approach outperforms the C&W method in the Top-1\nsetting, as well as other baseline methods. Our approach shows significant\nimprovement in the Top-5 setting against a strong modified C&W method.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:24:15 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Zekun", ""], ["Wu", "Tianfu", ""]]}, {"id": "1905.10696", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali, Daniel Kifer, C. Lee Giles", "title": "Lifelong Neural Predictive Coding: Learning Cumulatively Online without\n  Forgetting", "comments": "Key updates including results on standard benchmarks, e.g., split\n  mnist/fmnist/not-mnist. Task selection/basal ganglia model has been\n  integrated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In lifelong learning systems, especially those based on artificial neural\nnetworks, one of the biggest obstacles is the severe inability to retain old\nknowledge as new information is encountered. This phenomenon is known as\ncatastrophic forgetting. In this article, we propose a new kind of\nconnectionist architecture, the Sequential Neural Coding Network, that is\nrobust to forgetting when learning from streams of data points and, unlike\nnetworks of today, does not learn via the immensely popular back-propagation of\nerrors. Grounded in the neurocognitive theory of predictive processing, our\nmodel adapts its synapses in a biologically-plausible fashion, while another,\ncomplementary neural system rapidly learns to direct and control this\ncortex-like structure by mimicking the task-executive control functionality of\nthe basal ganglia. In our experiments, we demonstrate that our self-organizing\nsystem experiences significantly less forgetting as compared to standard neural\nmodels and outperforms a wide swath of previously proposed methods even though\nit is trained across task datasets in a stream-like fashion. The promising\nperformance of our complementary system on benchmarks, e.g., SplitMNIST, Split\nFashion MNIST, and Split NotMNIST, offers evidence that by incorporating\nmechanisms prominent in real neuronal systems, such as competition, sparse\nactivation patterns, and iterative input processing, a new possibility for\ntackling the grand challenge of lifelong machine learning opens up.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:31:27 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 01:00:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "1905.10698", "submitter": "Farshid Varno", "authors": "Farshid Varno, Behrouz Haji Soleimani, Marzie Saghayi, Lisa Di Jorio\n  and Stan Matwin", "title": "Efficient Neural Task Adaptation by Maximum Entropy Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge from one neural network to another has been shown to\nbe helpful for learning tasks with few training examples. Prevailing\nfine-tuning methods could potentially contaminate pre-trained features by\ncomparably high energy random noise. This noise is mainly delivered from a\ncareless replacement of task-specific parameters. We analyze theoretically such\nknowledge contamination for classification tasks and propose a practical and\neasy to apply method to trap and minimize the contaminant. In our approach, the\nentropy of the output estimates gets maximized initially and the first\nback-propagated error is stalled at the output of the last layer. Our proposed\nmethod not only outperforms the traditional fine-tuning, but also significantly\nspeeds up the convergence of the learner. It is robust to randomness and\nindependent of the choice of architecture. Overall, our experiments show that\nthe power of transfer learning has been substantially underestimated so far.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:37:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 02:32:53 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Varno", "Farshid", ""], ["Soleimani", "Behrouz Haji", ""], ["Saghayi", "Marzie", ""], ["Di Jorio", "Lisa", ""], ["Matwin", "Stan", ""]]}, {"id": "1905.10701", "submitter": "Piyush Shrivastava Mr.", "authors": "Aditya Narayanaswamy, Yichuan Philip Ma, Piyush Shrivastava", "title": "Image Detection and Digit Recognition to solve Sudoku as a Constraint\n  Satisfaction Problem", "comments": "Pages: 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sudoku is a puzzle well-known to the scientific community with simple rules\nof completion, which may require a com-plex line of reasoning. This paper\naddresses the problem of partitioning the Sudoku image into a 1-D array,\nrecognizing digits from the array and representing it as a Constraint\nSat-isfaction Problem (CSP). In this paper, we introduce new fea-ture\nextraction techniques for recognizing digits, which are used with our benchmark\nclassifiers in conjunction with the CSP algorithms to provide performance\nassessment. Experi-mental results show that application of CSP techniques can\ndecrease the solution's search time by eliminating incon-sistent values from\nthe search space.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:47:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Narayanaswamy", "Aditya", ""], ["Ma", "Yichuan Philip", ""], ["Shrivastava", "Piyush", ""]]}, {"id": "1905.10702", "submitter": "Afshin Sadeghi", "authors": "Afshin Sadeghi, Damien Graux, Hamed Shariat Yazdi, Jens Lehmann", "title": "MDE: Multiple Distance Embeddings for Link Prediction in Knowledge\n  Graphs", "comments": "Accepted paper in ECAI 2020", "journal-ref": "24th European Conference on Artificial Intelligence (ECAI), 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, knowledge graphs became popular for capturing\nstructured domain knowledge. Relational learning models enable the prediction\nof missing links inside knowledge graphs. More specifically, latent distance\napproaches model the relationships among entities via a distance between latent\nrepresentations. Translating embedding models (e.g., TransE) are among the most\npopular latent distance approaches which use one distance function to learn\nmultiple relation patterns. However, they are mostly inefficient in capturing\nsymmetric relations since the representation vector norm for all the symmetric\nrelations becomes equal to zero. They also lose information when learning\nrelations with reflexive patterns since they become symmetric and transitive.\nWe propose the Multiple Distance Embedding model (MDE) that addresses these\nlimitations and a framework to collaboratively combine variant latent\ndistance-based terms. Our solution is based on two principles: 1) we use a\nlimit-based loss instead of a margin ranking loss and, 2) by learning\nindependent embedding vectors for each of the terms we can collectively train\nand predict using contradicting distance terms. We further demonstrate that MDE\nallows modeling relations with (anti)symmetry, inversion, and composition\npatterns. We propose MDE as a neural network model that allows us to map\nnon-linear relations between the embedding vectors and the expected output of\nthe score function. Our empirical results show that MDE performs competitively\nto state-of-the-art embedding models on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:48:00 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:36:32 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 17:19:34 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 20:57:08 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 18:38:58 GMT"}, {"version": "v6", "created": "Thu, 27 Jun 2019 12:40:11 GMT"}, {"version": "v7", "created": "Mon, 8 Jul 2019 11:54:43 GMT"}, {"version": "v8", "created": "Fri, 21 Feb 2020 13:09:08 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Graux", "Damien", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1905.10705", "submitter": "Guanyang Wang", "authors": "Guanyang Wang, Yumeng Zhang, Yong Deng, Xuxin Huang, {\\L}ukasz\n  Kidzi\\'nski", "title": "Modeling treatment events in disease progression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability to quantify and predict progression of a disease is fundamental for\nselecting an appropriate treatment. Many clinical metrics cannot be acquired\nfrequently either because of their cost (e.g. MRI, gait analysis) or because\nthey are inconvenient or harmful to a patient (e.g. biopsy, x-ray). In such\nscenarios, in order to estimate individual trajectories of disease progression,\nit is advantageous to leverage similarities between patients, i.e. the\ncovariance of trajectories, and find a latent representation of progression.\nMost of existing methods for estimating trajectories do not account for events\nin-between observations, what dramatically decreases their adequacy for\nclinical practice. In this study, we develop a machine learning framework named\nCoordinatewise-Soft-Impute (CSI) for analyzing disease progression from sparse\nobservations in the presence of confounding events. CSI is guaranteed to\nconverge to the global minimum of the corresponding optimization problem.\nExperimental results also demonstrates the effectiveness of CSI using both\nsimulated and real dataset.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:16:36 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Guanyang", ""], ["Zhang", "Yumeng", ""], ["Deng", "Yong", ""], ["Huang", "Xuxin", ""], ["Kidzi\u0144ski", "\u0141ukasz", ""]]}, {"id": "1905.10706", "submitter": "Eric Heiden", "authors": "Eric Heiden, David Millard, Hejia Zhang, Gaurav S. Sukhatme", "title": "Interactive Differentiable Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents need a physical understanding of the world to predict the\nimpact of their actions in the future. While learning-based models of the\nenvironment dynamics have contributed to significant improvements in sample\nefficiency compared to model-free reinforcement learning algorithms, they\ntypically fail to generalize to system states beyond the training data, while\noften grounding their predictions on non-interpretable latent variables.\n  We introduce Interactive Differentiable Simulation (IDS), a differentiable\nphysics engine, that allows for efficient, accurate inference of physical\nproperties of rigid-body systems. Integrated into deep learning architectures,\nour model is able to accomplish system identification using visual input,\nleading to an interpretable model of the world whose parameters have physical\nmeaning. We present experiments showing automatic task-based robot design and\nparameter estimation for nonlinear dynamical systems by automatically\ncalculating gradients in IDS. When integrated into an adaptive model-predictive\ncontrol algorithm, our approach exhibits orders of magnitude improvements in\nsample efficiency over model-free reinforcement learning algorithms on\nchallenging nonlinear control domains.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:40:44 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 19:21:25 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 23:41:58 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Heiden", "Eric", ""], ["Millard", "David", ""], ["Zhang", "Hejia", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1905.10708", "submitter": "Dmitry Konovalov", "authors": "Dmitry A. Konovalov, Alzayat Saleh, Michael Bradley, Mangalam\n  Sankupellay, Simone Marini, Marcus Sheaves", "title": "Underwater Fish Detection with Weak Multi-Domain Supervision", "comments": "Published in the 2019 International Joint Conference on Neural\n  Networks (IJCNN-2019), Budapest, Hungary, July 14-19, 2019,\n  https://www.ijcnn.org/ , https://ieeexplore.ieee.org/document/8851907", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN),\n  Budapest, Hungary, 2019, pp. 1-8", "doi": "10.1109/IJCNN.2019.8851907", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sufficiently large training dataset, it is relatively easy to train a\nmodern convolution neural network (CNN) as a required image classifier.\nHowever, for the task of fish classification and/or fish detection, if a CNN\nwas trained to detect or classify particular fish species in particular\nbackground habitats, the same CNN exhibits much lower accuracy when applied to\nnew/unseen fish species and/or fish habitats. Therefore, in practice, the CNN\nneeds to be continuously fine-tuned to improve its classification accuracy to\nhandle new project-specific fish species or habitats. In this work we present a\nlabelling-efficient method of training a CNN-based fish-detector (the Xception\nCNN was used as the base) on relatively small numbers (4,000) of project-domain\nunderwater fish/no-fish images from 20 different habitats. Additionally, 17,000\nof known negative (that is, missing fish) general-domain (VOC2012) above-water\nimages were used. Two publicly available fish-domain datasets supplied\nadditional 27,000 of above-water and underwater positive/fish images. By using\nthis multi-domain collection of images, the trained Xception-based binary\n(fish/not-fish) classifier achieved 0.17% false-positives and 0.61%\nfalse-negatives on the project's 20,000 negative and 16,000 positive holdout\ntest images, respectively. The area under the ROC curve (AUC) was 99.94%.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:43:58 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 02:29:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Konovalov", "Dmitry A.", ""], ["Saleh", "Alzayat", ""], ["Bradley", "Michael", ""], ["Sankupellay", "Mangalam", ""], ["Marini", "Simone", ""], ["Sheaves", "Marcus", ""]]}, {"id": "1905.10709", "submitter": "Doyup Lee", "authors": "Doyup Lee, Suehun Jung, Yeongjae Cheon, Dongil Kim, Seungil You", "title": "Demand Forecasting from Spatiotemporal Data with Graph Networks and\n  Temporal-Guided Embedding", "comments": "NeurIPS 2018 Workshop on Modeling and Decision-Making in the\n  Spatiotemporal Domain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term demand forecasting models commonly combine convolutional and\nrecurrent layers to extract complex spatiotemporal patterns in data. Long-term\nhistories are also used to consider periodicity and seasonality patterns as\ntime series data. In this study, we propose an efficient architecture,\nTemporal-Guided Network (TGNet), which utilizes graph networks and\ntemporal-guided embedding. Graph networks extract invariant features to\npermutations of adjacent regions instead of convolutional layers.\nTemporal-guided embedding explicitly learns temporal contexts from training\ndata and is substituted for the input of long-term histories from days/weeks\nago. TGNet learns an autoregressive model, conditioned on temporal contexts of\nforecasting targets from temporal-guided embedding. Finally, our model achieves\ncompetitive performances with other baselines on three spatiotemporal demand\ndataset from real-world, but the number of trainable parameters is about 20\ntimes smaller than a state-of-the-art baseline. We also show that\ntemporal-guided embedding learns temporal contexts as intended and TGNet has\nrobust forecasting performances even to atypical event situations.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:54:24 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 10:24:19 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Lee", "Doyup", ""], ["Jung", "Suehun", ""], ["Cheon", "Yeongjae", ""], ["Kim", "Dongil", ""], ["You", "Seungil", ""]]}, {"id": "1905.10710", "submitter": "Alexander Tong", "authors": "Alexander Tong, Guy Wolf, Smita Krishnaswamy", "title": "Fixing Bias in Reconstruction-based Anomaly Detection with Lipschitz\n  Discriminators", "comments": "6 pages, 4 figures, 2 tables, presented at IEEE MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is of great interest in fields where abnormalities need to\nbe identified and corrected (e.g., medicine and finance). Deep learning methods\nfor this task often rely on autoencoder reconstruction error, sometimes in\nconjunction with other errors. We show that this approach exhibits intrinsic\nbiases that lead to undesirable results. Reconstruction-based methods are\nsensitive to training-data outliers and simple-to-reconstruct points. Instead,\nwe introduce a new unsupervised Lipschitz anomaly discriminator that does not\nsuffer from these biases. Our anomaly discriminator is trained, similar to the\nones used in GANs, to detect the difference between the training data and\ncorruptions of the training data. We show that this procedure successfully\ndetects unseen anomalies with guarantees on those that have a certain\nWasserstein distance from the data or corrupted training set. These additions\nallow us to show improved performance on MNIST, CIFAR10, and health record\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 01:57:42 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 21:20:55 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 13:49:41 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tong", "Alexander", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1905.10713", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Xiang Ao, Pingzhong Tang, Min Lu, Dapeng Liu, Lei Xiao,\n  Qing He", "title": "Field-aware Calibration: A Simple and Empirically Strong Method for\n  Reliable Probabilistic Predictions", "comments": "WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380154", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often observed that the probabilistic predictions given by a machine\nlearning model can disagree with averaged actual outcomes on specific subsets\nof data, which is also known as the issue of miscalibration. It is responsible\nfor the unreliability of practical machine learning systems. For example, in\nonline advertising, an ad can receive a click-through rate prediction of 0.1\nover some population of users where its actual click rate is 0.15. In such\ncases, the probabilistic predictions have to be fixed before the system can be\ndeployed.\n  In this paper, we first introduce a new evaluation metric named field-level\ncalibration error that measures the bias in predictions over the sensitive\ninput field that the decision-maker concerns. We show that existing post-hoc\ncalibration methods have limited improvements in the new field-level metric and\nother non-calibration metrics such as the AUC score. To this end, we propose\nNeural Calibration, a simple yet powerful post-hoc calibration method that\nlearns to calibrate by making full use of the field-aware information over the\nvalidation set. We present extensive experiments on five large-scale datasets.\nThe results showed that Neural Calibration significantly improves against\nuncalibrated predictions in common metrics such as the negative log-likelihood,\nBrier score and AUC, as well as the proposed field-level calibration error.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 02:41:33 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:46:37 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 12:21:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pan", "Feiyang", ""], ["Ao", "Xiang", ""], ["Tang", "Pingzhong", ""], ["Lu", "Min", ""], ["Liu", "Dapeng", ""], ["Xiao", "Lei", ""], ["He", "Qing", ""]]}, {"id": "1905.10714", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Feng Chen, Yiming Ying", "title": "Dual Averaging Method for Online Graph-structured Sparsity", "comments": "11 pages, 14 figures", "journal-ref": "The 25th ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining (KDD '19), August 4--8, 2019", "doi": "10.1145/3292500.3330915", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning algorithms update models via one sample per iteration, thus\nefficient to process large-scale datasets and useful to detect malicious events\nfor social benefits, such as disease outbreak and traffic congestion on the\nfly. However, existing algorithms for graph-structured models focused on the\noffline setting and the least square loss, incapable for online setting, while\nmethods designed for online setting cannot be directly applied to the problem\nof complex (usually non-convex) graph-structured sparsity model. To address\nthese limitations, in this paper we propose a new algorithm for\ngraph-structured sparsity constraint problems under online setting, which we\ncall \\textsc{GraphDA}. The key part in \\textsc{GraphDA} is to project both\naveraging gradient (in dual space) and primal variables (in primal space) onto\nlower dimensional subspaces, thus capturing the graph-structured sparsity\neffectively. Furthermore, the objective functions assumed here are generally\nconvex so as to handle different losses for online learning settings. To the\nbest of our knowledge, \\textsc{GraphDA} is the first online learning algorithm\nfor graph-structure constrained optimization problems. To validate our method,\nwe conduct extensive experiments on both benchmark graph and real-world graph\ndatasets. Our experiment results show that, compared to other baseline methods,\n\\textsc{GraphDA} not only improves classification performance, but also\nsuccessfully captures graph-structured features more effectively, hence\nstronger interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 02:42:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhou", "Baojian", ""], ["Chen", "Feng", ""], ["Ying", "Yiming", ""]]}, {"id": "1905.10715", "submitter": "Amin Salehi", "authors": "Amin Salehi, Hasan Davulcu", "title": "Graph Attention Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Auto-encoders have emerged as a successful framework for unsupervised\nlearning. However, conventional auto-encoders are incapable of utilizing\nexplicit relations in structured data. To take advantage of relations in\ngraph-structured data, several graph auto-encoders have recently been proposed,\nbut they neglect to reconstruct either the graph structure or node attributes.\nIn this paper, we present the graph attention auto-encoder (GATE), a neural\nnetwork architecture for unsupervised representation learning on\ngraph-structured data. Our architecture is able to reconstruct graph-structured\ninputs, including both node attributes and the graph structure, through stacked\nencoder/decoder layers equipped with self-attention mechanisms. In the encoder,\nby considering node attributes as initial node representations, each layer\ngenerates new representations of nodes by attending over their neighbors'\nrepresentations. In the decoder, we attempt to reverse the encoding process to\nreconstruct node attributes. Moreover, node representations are regularized to\nreconstruct the graph structure. Our proposed architecture does not need to\nknow the graph structure upfront, and thus it can be applied to inductive\nlearning. Our experiments demonstrate competitive performance on several node\nclassification benchmark datasets for transductive and inductive tasks, even\nexceeding the performance of supervised learning baselines in most cases.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 02:47:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Salehi", "Amin", ""], ["Davulcu", "Hasan", ""]]}, {"id": "1905.10725", "submitter": "Yueqi Cao", "authors": "Yueqi Cao, Didong Li, Huafei Sun, Amir H Assadi, Shiqiang Zhang", "title": "Efficient Weingarten Map and Curvature Estimation on Manifolds", "comments": "23 pages, 8 figures", "journal-ref": "Machine Learning (2021)", "doi": "10.1007/s10994-021-05953-4", "report-no": null, "categories": "stat.ML cs.CV cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an efficient method to estimate the Weingarten map\nfor point cloud data sampled from manifold embedded in Euclidean space. A\nstatistical model is established to analyze the asymptotic property of the\nestimator. In particular, we show the convergence rate as the sample size tends\nto infinity. We verify the convergence rate through simulated data and apply\nthe estimated Weingarten map to curvature estimation and point cloud\nsimplification to multiple real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:48:32 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 03:51:21 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Cao", "Yueqi", ""], ["Li", "Didong", ""], ["Sun", "Huafei", ""], ["Assadi", "Amir H", ""], ["Zhang", "Shiqiang", ""]]}, {"id": "1905.10729", "submitter": "Hebi Li", "authors": "Hebi Li and Qi Xiao and Shixin Tian and Jin Tian", "title": "Purifying Adversarial Perturbation with Adversarially Trained\n  Auto-encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples. Iterative\nadversarial training has shown promising results against strong white-box\nattacks. However, adversarial training is very expensive, and every time a\nmodel needs to be protected, such expensive training scheme needs to be\nperformed. In this paper, we propose to apply iterative adversarial training\nscheme to an external auto-encoder, which once trained can be used to protect\nother models directly. We empirically show that our model outperforms other\npurifying-based methods against white-box attacks, and transfers well to\ndirectly protect other base models with different architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:57:55 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Hebi", ""], ["Xiao", "Qi", ""], ["Tian", "Shixin", ""], ["Tian", "Jin", ""]]}, {"id": "1905.10733", "submitter": "Juho Lee", "authors": "Juho Lee, Xenia Miscouridou, Fran\\c{c}ois Caron", "title": "A unified construction for series representations and finite\n  approximations of completely random measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite-activity completely random measures (CRMs) have become important\nbuilding blocks of complex Bayesian nonparametric models. They have been\nsuccessfully used in various applications such as clustering, density\nestimation, latent feature models, survival analysis or network science.\nPopular infinite-activity CRMs include the (generalized) gamma process and the\n(stable) beta process. However, except in some specific cases, exact simulation\nor scalable inference with these models is challenging and finite-dimensional\napproximations are often considered. In this work, we propose a general and\nunified framework to derive both series representations and finite-dimensional\napproximations of CRMs. Our framework can be seen as an extension of\nconstructions based on size-biased sampling of Poisson point process\n[Perman1992]. It includes as special cases several known series representations\nas well as novel ones. In particular, we show that one can get novel series\nrepresentations for the generalized gamma process and the stable beta process.\nWe also provide some analysis of the truncation error.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 05:50:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lee", "Juho", ""], ["Miscouridou", "Xenia", ""], ["Caron", "Fran\u00e7ois", ""]]}, {"id": "1905.10744", "submitter": "Manikanta Srikar Yellapragada", "authors": "Manikanta Srikar Yellapragada, Chandra Prakash Konkimalla", "title": "Variational Bayes: A report on approaches and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive results on a wide variety of\ntasks. However, quantifying uncertainty in the network's output is a\nchallenging task. Bayesian models offer a mathematical framework to reason\nabout model uncertainty. Variational methods have been used for approximating\nintractable integrals that arise in Bayesian inference for neural networks. In\nthis report, we review the major variational inference concepts pertinent to\nBayesian neural networks and compare various approximation methods used in\nliterature. We also talk about the applications of variational bayes in\nReinforcement learning and continual learning.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 06:20:31 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yellapragada", "Manikanta Srikar", ""], ["Konkimalla", "Chandra Prakash", ""]]}, {"id": "1905.10750", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, and Andrea J.\n  Goldsmith", "title": "ViterbiNet: A Deep Learning Based Viterbi Algorithm for Symbol Detection", "comments": "arXiv admin note: text overlap with arXiv:2002.07806", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbol detection plays an important role in the implementation of digital\nreceivers. In this work, we propose ViterbiNet, which is a data-driven symbol\ndetector that does not require channel state information (CSI). ViterbiNet is\nobtained by integrating deep neural networks (DNNs) into the Viterbi algorithm.\nWe identify the specific parts of the Viterbi algorithm that are\nchannel-model-based, and design a DNN to implement only those computations,\nleaving the rest of the algorithm structure intact. We then propose a\nmeta-learning based approach to train ViterbiNet online based on recent\ndecisions, allowing the receiver to track dynamic channel conditions without\nrequiring new training samples for every coherence block. Our numerical\nevaluations demonstrate that the performance of ViterbiNet, which is ignorant\nof the CSI, approaches that of the CSI-based Viterbi algorithm, and is capable\nof tracking time-varying channels without needing instantaneous CSI or\nadditional training data. Moreover, unlike conventional Viterbi detection,\nViterbiNet is robust to CSI uncertainty, and it can be reliably implemented in\ncomplex channel models with constrained computational burden. More broadly, our\nresults demonstrate the conceptual benefit of designing communication systems\nto that integrate DNNs into established algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:15:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 12:52:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Shlezinger", "Nir", ""], ["Farsad", "Nariman", ""], ["Eldar", "Yonina C.", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "1905.10751", "submitter": "Shariq Mobin", "authors": "Shariq Mobin, Bruno Olshausen", "title": "Auditory Separation of a Conversation from Background via Attentional\n  Gating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for separating a set of voices out of a sound mixture\ncontaining an unknown number of sources. Our Attentional Gating Network (AGN)\nuses a variable attentional context to specify which speakers in the mixture\nare of interest. The attentional context is specified by an embedding vector\nwhich modifies the processing of a neural network through an additive bias.\nIndividual speaker embeddings are learned to separate a single speaker while\nsuperpositions of the individual speaker embeddings are used to separate sets\nof speakers. We first evaluate AGN on a traditional single speaker separation\ntask and show an improvement of 9% with respect to comparable models. Then, we\nintroduce a new task to separate an arbitrary subset of voices from a mixture\nof an unknown-sized set of voices, inspired by the human ability to separate a\nconversation of interest from background chatter at a cafeteria. We show that\nAGN is the only model capable of solving this task, performing only 7% worse\nthan on the single speaker separation task.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:38:35 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Mobin", "Shariq", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1905.10756", "submitter": "Zhihong Chen", "authors": "Zhihong Chen, Chao Chen, Zhaowei Cheng, Boyuan Jiang, Ke Fang, Xinyu\n  Jin", "title": "Selective Transfer with Reinforced Transfer Network for Partial Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One crucial aspect of partial domain adaptation (PDA) is how to select the\nrelevant source samples in the shared classes for knowledge transfer. Previous\nPDA methods tackle this problem by re-weighting the source samples based on\ntheir high-level information (deep features). However, since the domain shift\nbetween source and target domains, only using the deep features for sample\nselection is defective. We argue that it is more reasonable to additionally\nexploit the pixel-level information for PDA problem, as the appearance\ndifference between outlier source classes and target classes is significantly\nlarge. In this paper, we propose a reinforced transfer network (RTNet), which\nutilizes both high-level and pixel-level information for PDA problem. Our RTNet\nis composed of a reinforced data selector (RDS) based on reinforcement learning\n(RL), which filters out the outlier source samples, and a domain adaptation\nmodel which minimizes the domain discrepancy in the shared label space.\nSpecifically, in the RDS, we design a novel reward based on the reconstruct\nerrors of selected source samples on the target generator, which introduces the\npixel-level information to guide the learning of RDS. Besides, we develope a\nstate containing high-level information, which used by the RDS for sample\nselection. The proposed RDS is a general module, which can be easily integrated\ninto existing DA models to make them fit the PDA situation. Extensive\nexperiments indicate that RTNet can achieve state-of-the-art performance for\nPDA tasks on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:59:36 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 07:38:52 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 04:14:54 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 01:59:52 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chen", "Zhihong", ""], ["Chen", "Chao", ""], ["Cheng", "Zhaowei", ""], ["Jiang", "Boyuan", ""], ["Fang", "Ke", ""], ["Jin", "Xinyu", ""]]}, {"id": "1905.10757", "submitter": "Jihun Yun", "authors": "Jihun Yun, Aurelie C. Lozano, Eunho Yang", "title": "Stochastic Gradient Methods with Block Diagonal Matrix Adaptation", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient approaches that automatically adjust the learning rate on a\nper-feature basis have been very popular for training deep networks. This rich\nclass of algorithms includes Adagrad, RMSprop, Adam, and recent extensions. All\nthese algorithms have adopted diagonal matrix adaptation, due to the\nprohibitive computational burden of manipulating full matrices in\nhigh-dimensions. In this paper, we show that block-diagonal matrix adaptation\ncan be a practical and powerful solution that can effectively utilize\nstructural characteristics of deep learning architectures, and significantly\nimprove convergence and out-of-sample generalization. We present a general\nframework with block-diagonal matrix updates via coordinate grouping, which\nincludes counterparts of the aforementioned algorithms, prove their convergence\nin non-convex optimization, highlighting benefits compared to diagonal\nversions. In addition, we propose an efficient spectrum-clipping scheme that\nbenefits from superior generalization performance of Sgd. Extensive experiments\nreveal that block-diagonal approaches achieve state-of-the-art results on\nseveral deep learning tasks, and can outperform adaptive diagonal methods,\nvanilla Sgd, as well as a modified version of full-matrix adaptation proposed\nvery recently.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:07:55 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yun", "Jihun", ""], ["Lozano", "Aurelie C.", ""], ["Yang", "Eunho", ""]]}, {"id": "1905.10759", "submitter": "Yash Akhauri", "authors": "Yash Akhauri", "title": "HadaNets: Flexible Quantization Strategies for Neural Networks", "comments": "Accepted in CVPR 2019, UAVision 2019", "journal-ref": null, "doi": "10.1109/CVPRW.2019.00078", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  On-board processing elements on UAVs are currently inadequate for training\nand inference of Deep Neural Networks. This is largely due to the energy\nconsumption of memory accesses in such a network. HadaNets introduce a flexible\ntrain-from-scratch tensor quantization scheme by pairing a full precision\ntensor to a binary tensor in the form of a Hadamard product. Unlike wider\nreduced precision neural network models, we preserve the train-time parameter\ncount, thus out-performing XNOR-Nets without a train-time memory penalty. Such\ntraining routines could see great utility in semi-supervised online learning\ntasks. Our method also offers advantages in model compression, as we reduce the\nmodel size of ResNet-18 by 7.43 times with respect to a full precision model\nwithout utilizing any other compression techniques. We also demonstrate a\n'Hadamard Binary Matrix Multiply' kernel, which delivers a 10-fold increase in\nperformance over full precision matrix multiplication with a similarly\noptimized kernel.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:17:54 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Akhauri", "Yash", ""]]}, {"id": "1905.10760", "submitter": "Feng Yuan", "authors": "Feng Yuan, Lina Yao, and Boualem Benatallah", "title": "DARec: Deep Domain Adaptation for Cross-Domain Recommendation via\n  Transferring Rating Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain recommendation has long been one of the major topics in\nrecommender systems. Recently, various deep models have been proposed to\ntransfer the learned knowledge across domains, but most of them focus on\nextracting abstract transferable features from auxilliary contents, e.g.,\nimages and review texts, and the patterns in the rating matrix itself is rarely\ntouched. In this work, inspired by the concept of domain adaptation, we\nproposed a deep domain adaptation model (DARec) that is capable of extracting\nand transferring patterns from rating matrices {\\em only} without relying on\nany auxillary information. We empirically demonstrate on public datasets that\nour method achieves the best performance among several state-of-the-art\nalternative cross-domain recommendation models.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:21:50 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yuan", "Feng", ""], ["Yao", "Lina", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1905.10761", "submitter": "Kumar Shridhar", "authors": "Kumar Shridhar, Joonho Lee, Hideaki Hayashi, Purvanshi Mehta, Brian\n  Kenji Iwana, Seokjun Kang, Seiichi Uchida, Sheraz Ahmed, Andreas Dengel", "title": "ProbAct: A Probabilistic Activation Function for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play an important role in training artificial neural\nnetworks. The majority of currently used activation functions are deterministic\nin nature, with their fixed input-output relationship. In this work, we propose\na novel probabilistic activation function, called ProbAct. ProbAct is\ndecomposed into a mean and variance and the output value is sampled from the\nformed distribution, making ProbAct a stochastic activation function. The\nvalues of mean and variances can be fixed using known functions or trained for\neach element. In the trainable ProbAct, the mean and the variance of the\nactivation distribution is trained within the back-propagation framework\nalongside other parameters. We show that the stochastic perturbation induced\nthrough ProbAct acts as a viable generalization technique for feature\naugmentation. In our experiments, we compare ProbAct with well-known activation\nfunctions on classification tasks on different modalities: Images(CIFAR-10,\nCIFAR-100, and STL-10) and Text (Large Movie Review). We show that ProbAct\nincreases the classification accuracy by +2-3% compared to ReLU or other\nconventional activation functions on both original datasets and when datasets\nare reduced to 50% and 25% of the original size. Finally, we show that ProbAct\nlearns an ensemble of models by itself that can be used to estimate the\nuncertainties associated with the prediction and provides robustness to noisy\ninputs.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:22:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 00:39:25 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Shridhar", "Kumar", ""], ["Lee", "Joonho", ""], ["Hayashi", "Hideaki", ""], ["Mehta", "Purvanshi", ""], ["Iwana", "Brian Kenji", ""], ["Kang", "Seokjun", ""], ["Uchida", "Seiichi", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "1905.10768", "submitter": "Mario Lucic", "authors": "Josip Djolonga and Mario Lucic and Marco Cuturi and Olivier Bachem and\n  Olivier Bousquet and Sylvain Gelly", "title": "Precision-Recall Curves Using Information Divergence Frontiers", "comments": "Updated to the AISTATS 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous progress in the estimation of generative models, the\ndevelopment of tools for diagnosing their failures and assessing their\nperformance has advanced at a much slower pace. Recent developments have\ninvestigated metrics that quantify which parts of the true distribution is\nmodeled well, and, on the contrary, what the model fails to capture, akin to\nprecision and recall in information retrieval. In this paper, we present a\ngeneral evaluation framework for generative models that measures the trade-off\nbetween precision and recall using R\\'enyi divergences. Our framework provides\na novel perspective on existing techniques and extends them to more general\ndomains. As a key advantage, this formulation encompasses both continuous and\ndiscrete models and allows for the design of efficient algorithms that do not\nhave to quantize the data. We further analyze the biases of the approximations\nused in practice.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 09:27:44 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 12:54:32 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Djolonga", "Josip", ""], ["Lucic", "Mario", ""], ["Cuturi", "Marco", ""], ["Bachem", "Olivier", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1905.10769", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Weijing Tang, Ji Zhu, Qiaozhu Mei", "title": "A Flexible Generative Framework for Graph-based Semi-supervised Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a family of problems that are concerned about making predictions\nfor the majority of unlabeled, graph-structured data samples based on a small\nproportion of labeled samples. Relational information among the data samples,\noften encoded in the graph/network structure, is shown to be helpful for these\nsemi-supervised learning tasks. However, conventional graph-based\nregularization methods and recent graph neural networks do not fully leverage\nthe interrelations between the features, the graph, and the labels. In this\nwork, we propose a flexible generative framework for graph-based\nsemi-supervised learning, which approaches the joint distribution of the node\nfeatures, labels, and the graph structure. Borrowing insights from random graph\nmodels in network science literature, this joint distribution can be\ninstantiated using various distribution families. For the inference of missing\nlabels, we exploit recent advances of scalable variational inference techniques\nto approximate the Bayesian posterior. We conduct thorough experiments on\nbenchmark datasets for graph-based semi-supervised learning. Results show that\nthe proposed methods outperform the state-of-the-art models in most settings.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 09:29:08 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 05:39:18 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ma", "Jiaqi", ""], ["Tang", "Weijing", ""], ["Zhu", "Ji", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1905.10796", "submitter": "Andriy Sarabakha", "authors": "Andriy Sarabakha, Erdal Kayacan", "title": "Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial\n  Vehicles Using Expert Knowledge", "comments": "corrected version accepted for ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an online learning-based control method for improved\ntrajectory tracking of unmanned aerial vehicles using both deep learning and\nexpert knowledge. The proposed method does not require the exact model of the\nsystem to be controlled, and it is robust against variations in system dynamics\nas well as operational uncertainties. The learning is divided into two phases:\noffline (pre-)training and online (post-)training. In the former, a\nconventional controller performs a set of trajectories and, based on the\ninput-output dataset, the deep neural network (DNN)-based controller is\ntrained. In the latter, the trained DNN, which mimics the conventional\ncontroller, controls the system. Unlike the existing papers in the literature,\nthe network is still being trained for different sets of trajectories which are\nnot used in the training phase of DNN. Thanks to the rule-base, which contains\nthe expert knowledge, the proposed framework learns the system dynamics and\noperational uncertainties in real-time. The experimental results show that the\nproposed online learning-based approach gives better trajectory tracking\nperformance when compared to the only offline trained network.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:36:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sarabakha", "Andriy", ""], ["Kayacan", "Erdal", ""]]}, {"id": "1905.10799", "submitter": "Weiyu Liu", "authors": "Weiyu Liu, Angel Daruna, Zsolt Kira and Sonia Chernova", "title": "Path Ranking with Attention to Type Hierarchies", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the knowledge base completion problem is to infer missing\ninformation from existing facts in a knowledge base. Prior work has\ndemonstrated the effectiveness of path-ranking based methods, which solve the\nproblem by discovering observable patterns in knowledge graphs, consisting of\nnodes representing entities and edges representing relations. However, these\npatterns either lack accuracy because they rely solely on relations or cannot\neasily generalize due to the direct use of specific entity information. We\nintroduce Attentive Path Ranking, a novel path pattern representation that\nleverages type hierarchies of entities to both avoid ambiguity and maintain\ngeneralization. Then, we present an end-to-end trained attention-based RNN\nmodel to discover the new path patterns from data. Experiments conducted on\nbenchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate\nthat the proposed model outperforms existing methods on the fact prediction\ntask by statistically significant margins of 26% and 10%, respectively.\nFurthermore, quantitative and qualitative analyses show that the path patterns\nbalance between generalization and discrimination.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 12:57:47 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 18:18:20 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 17:34:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Liu", "Weiyu", ""], ["Daruna", "Angel", ""], ["Kira", "Zsolt", ""], ["Chernova", "Sonia", ""]]}, {"id": "1905.10802", "submitter": "Boli Chen", "authors": "Boli Chen, Xin Huang, Lin Xiao, Zixin Cai, Liping Jing", "title": "Hyperbolic Interaction Model For Hierarchical Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the traditional classification tasks which assume mutual\nexclusion of labels, hierarchical multi-label classification (HMLC) aims to\nassign multiple labels to every instance with the labels organized under\nhierarchical relations. Besides the labels, since linguistic ontologies are\nintrinsic hierarchies, the conceptual relations between words can also form\nhierarchical structures. Thus it can be a challenge to learn mappings from word\nhierarchies to label hierarchies. We propose to model the word and label\nhierarchies by embedding them jointly in the hyperbolic space. The main reason\nis that the tree-likeness of the hyperbolic space matches the complexity of\nsymbolic data with hierarchical structures. A new Hyperbolic Interaction Model\n(HyperIM) is designed to learn the label-aware document representations and\nmake predictions for HMLC. Extensive experiments are conducted on three\nbenchmark datasets. The results have demonstrated that the new model can\nrealistically capture the complex data structures and further improve the\nperformance for HMLC comparing with the state-of-the-art methods. To facilitate\nfuture research, our code is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 13:20:11 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 15:36:22 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Chen", "Boli", ""], ["Huang", "Xin", ""], ["Xiao", "Lin", ""], ["Cai", "Zixin", ""], ["Jing", "Liping", ""]]}, {"id": "1905.10805", "submitter": "Evgeny Burnaev", "authors": "P. Proskura and A. Zaytsev and I. Braslavsky and E. Egorov and E.\n  Burnaev", "title": "Usage of multiple RTL features for Earthquake prediction", "comments": "13 pages, 3 figures, 3 tables", "journal-ref": "Proceedings of the International Conference on Computational\n  Science and Applications (ICCSA-2019), 2019", "doi": null, "report-no": null, "categories": "stat.AP cs.LG eess.SP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a classification model that predicts if an earthquake with the\nmagnitude above a threshold will take place at a given location in a time range\n30-180 days from a given moment of time. A common approach is to use expert\nforecasts based on features like Region-Time-Length (RTL) characteristics. The\nproposed approach uses machine learning on top of multiple RTL features to take\ninto account effects at various scales and to improve prediction accuracy. For\nhistorical data about Japan earthquakes 1992-2005 and predictions at locations\ngiven in this database the best model has precision up to ~ 0.95 and recall up\nto ~ 0.98.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 13:37:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Proskura", "P.", ""], ["Zaytsev", "A.", ""], ["Braslavsky", "I.", ""], ["Egorov", "E.", ""], ["Burnaev", "E.", ""]]}, {"id": "1905.10812", "submitter": "Fran\\c{c}ois-Pierre Paty", "authors": "Fran\\c{c}ois-Pierre Paty, Alexandre d'Aspremont, Marco Cuturi", "title": "Regularity as Regularization: Smooth and Strongly Convex Brenier\n  Potentials in Optimal Transport", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, PMLR 108:1222-1232, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating Wasserstein distances between two high-dimensional densities\nsuffers from the curse of dimensionality: one needs an exponential (wrt\ndimension) number of samples to ensure that the distance between two empirical\nmeasures is comparable to the distance between the original densities.\nTherefore, optimal transport (OT) can only be used in machine learning if it is\nsubstantially regularized. On the other hand, one of the greatest achievements\nof the OT literature in recent years lies in regularity theory: Caffarelli\nshowed that the OT map between two well behaved measures is Lipschitz, or\nequivalently when considering 2-Wasserstein distances, that Brenier convex\npotentials (whose gradient yields an optimal map) are smooth. We propose in\nthis work to draw inspiration from this theory and use regularity as a\nregularization tool. We give algorithms operating on two discrete measures that\ncan recover nearly optimal transport maps with small distortion, or\nequivalently, nearly optimal Brenier potentials that are strongly convex and\nsmooth. The problem boils down to solving alternatively a convex QCQP and a\ndiscrete OT problem, granting access to the values and gradients of the Brenier\npotential not only on sampled points, but also out of sample at the cost of\nsolving a simpler QCQP for each evaluation. We propose algorithms to estimate\nand evaluate transport maps with desired regularity properties, benchmark their\nstatistical performance, apply them to domain adaptation and visualize their\naction on a color transfer task.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:17:19 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 17:06:04 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 14:53:34 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 14:15:38 GMT"}, {"version": "v5", "created": "Fri, 10 Jul 2020 10:45:12 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Paty", "Fran\u00e7ois-Pierre", ""], ["d'Aspremont", "Alexandre", ""], ["Cuturi", "Marco", ""]]}, {"id": "1905.10817", "submitter": "Guy Uziel", "authors": "Guy Uziel", "title": "Deep Online Learning with Stochastic Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are considered to be state-of-the-art in many offline\nmachine learning tasks. However, many of the techniques developed are not\nsuitable for online learning tasks. The problem of using deep learning models\nwith sequential data becomes even harder when several loss functions need to be\nconsidered simultaneously, as in many real-world applications. In this paper,\nwe, therefore, propose a novel online deep learning training procedure which\ncan be used regardless of the neural network's architecture, aiming to deal\nwith the multiple objectives case. We demonstrate and show the effectiveness of\nour algorithm on the Neyman-Pearson classification problem on several benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:36:31 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Uziel", "Guy", ""]]}, {"id": "1905.10819", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik", "title": "Learning to Optimize Computational Resources: Frugal Training with\n  Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms typically come with tunable parameters that have a considerable\nimpact on the computational resources they consume. Too often, practitioners\nmust hand-tune the parameters, a tedious and error-prone task. A recent line of\nresearch provides algorithms that return nearly-optimal parameters from within\na finite set. These algorithms can be used when the parameter space is infinite\nby providing as input a random sample of parameters. This data-independent\ndiscretization, however, might miss pockets of nearly-optimal parameters: prior\nresearch has presented scenarios where the only viable parameters lie within an\narbitrarily small region. We provide an algorithm that learns a finite set of\npromising parameters from within an infinite set. Our algorithm can help\ncompile a configuration portfolio, or it can be used to select the input to a\nconfiguration algorithm for finite parameter spaces. Our approach applies to\nany configuration problem that satisfies a simple yet ubiquitous structure: the\nalgorithm's performance is a piecewise constant function of its parameters.\nPrior research has exhibited this structure in domains from integer programming\nto clustering.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:43:50 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:41:01 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 00:59:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1905.10821", "submitter": "Guy Uziel", "authors": "Guy Uziel", "title": "Nonparametric Online Learning Using Lipschitz Regularized Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are considered to be state of the art models in many\noffline machine learning tasks. However, their performance and generalization\nabilities in online learning tasks are much less understood. Therefore, we\nfocus on online learning and tackle the challenging problem where the\nunderlying process is stationary and ergodic and thus removing the i.i.d.\nassumption and allowing observations to depend on each other arbitrarily. We\nprove the generalization abilities of Lipschitz regularized deep neural\nnetworks and show that by using those networks, a convergence to the best\npossible prediction strategy is guaranteed.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:47:36 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Uziel", "Guy", ""]]}, {"id": "1905.10825", "submitter": "Yunzong Xu", "authors": "David Simchi-Levi, Yunzong Xu", "title": "Phase Transitions in Bandits with Switching Constraints", "comments": "An enhanced version. Many new results are obtained. The presentation\n  is improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical stochastic multi-armed bandit problem with a\nconstraint that limits the total cost incurred by switching between actions to\nbe no larger than a given switching budget. For this problem, we prove matching\nupper and lower bounds on the optimal (i.e., minimax) regret, and provide\nefficient rate-optimal algorithms. Surprisingly, the optimal regret of this\nproblem exhibits a non-conventional growth rate in terms of the time horizon\nand the number of arms. Consequently, we discover surprising \"phase\ntransitions\" regarding how the optimal regret rate changes with respect to the\nswitching budget: when the number of arms is fixed, there are equal-length\nphases, where the optimal regret rate remains (almost) the same within each\nphase and exhibits abrupt changes between phases; when the number of arms grows\nwith the time horizon, such abrupt changes become subtler and may disappear,\nbut a generalized notion of phase transitions involving certain new\nmeasurements still exists. The results enable us to fully characterize the\ntrade-off between the regret rate and the incurred switching cost in the\nstochastic multi-armed bandit problem, contributing new insights to this\nfundamental problem. Under the general switching cost structure, the results\nreveal interesting connections between bandit problems and graph traversal\nproblems, such as the shortest Hamiltonian path problem.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:07:12 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 03:13:54 GMT"}, {"version": "v3", "created": "Sat, 6 Jul 2019 16:06:47 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 22:20:40 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Simchi-Levi", "David", ""], ["Xu", "Yunzong", ""]]}, {"id": "1905.10826", "submitter": "Lili Su", "authors": "Lili Su and Pengkun Yang", "title": "On Learning Over-parameterized Neural Networks: A Functional\n  Approximation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training over-parameterized two-layer neural networks with\nRectified Linear Unit (ReLU) using gradient descent (GD) method. Inspired by a\nrecent line of work, we study the evolutions of network prediction errors\nacross GD iterations, which can be neatly described in a matrix form. When the\nnetwork is sufficiently over-parameterized, these matrices individually\napproximate {\\em an} integral operator which is determined by the feature\nvector distribution $\\rho$ only. Consequently, GD method can be viewed as {\\em\napproximately} applying the powers of this integral operator on the\nunderlying/target function $f^*$ that generates the responses/labels.\n  We show that if $f^*$ admits a low-rank approximation with respect to the\neigenspaces of this integral operator, then the empirical risk decreases to\nthis low-rank approximation error at a linear rate which is determined by $f^*$\nand $\\rho$ only, i.e., the rate is independent of the sample size $n$.\nFurthermore, if $f^*$ has zero low-rank approximation error, then, as long as\nthe width of the neural network is $\\Omega(n\\log n)$, the empirical risk\ndecreases to $\\Theta(1/\\sqrt{n})$. To the best of our knowledge, this is the\nfirst result showing the sufficiency of nearly-linear network\nover-parameterization. We provide an application of our general results to the\nsetting where $\\rho$ is the uniform distribution on the spheres and $f^*$ is a\npolynomial. Throughout this paper, we consider the scenario where the input\ndimension $d$ is fixed.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:09:06 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 15:35:33 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Su", "Lili", ""], ["Yang", "Pengkun", ""]]}, {"id": "1905.10830", "submitter": "Evgenii Zheltonozhskii", "authors": "Brian Chmiel, Chaim Baskin, Ron Banner, Evgenii Zheltonozhskii,\n  Yevgeny Yermolin, Alex Karbachevsky, Alex M. Bronstein and Avi Mendelson", "title": "Feature Map Transform Coding for Energy-Efficient CNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) achieve state-of-the-art accuracy in a\nvariety of tasks in computer vision and beyond. One of the major obstacles\nhindering the ubiquitous use of CNNs for inference on low-power edge devices is\ntheir high computational complexity and memory bandwidth requirements. The\nlatter often dominates the energy footprint on modern hardware. In this paper,\nwe introduce a lossy transform coding approach, inspired by image and video\ncompression, designed to reduce the memory bandwidth due to the storage of\nintermediate activation calculation results. Our method does not require\nfine-tuning the network weights and halves the data transfer volumes to the\nmain memory by compressing feature maps, which are highly correlated, with\nvariable length coding. Our method outperform previous approach in term of the\nnumber of bits per value with minor accuracy degradation on ResNet-34 and\nMobileNetV2. We analyze the performance of our approach on a variety of CNN\narchitectures and demonstrate that FPGA implementation of ResNet-18 with our\napproach results in a reduction of around 40% in the memory energy footprint,\ncompared to quantized network, with negligible impact on accuracy. When\nallowing accuracy degradation of up to 2%, the reduction of 60% is achieved. A\nreference implementation is available at\nhttps://github.com/CompressTeam/TransformCodingInference\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:29:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:02:16 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 14:43:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Chmiel", "Brian", ""], ["Baskin", "Chaim", ""], ["Banner", "Ron", ""], ["Zheltonozhskii", "Evgenii", ""], ["Yermolin", "Yevgeny", ""], ["Karbachevsky", "Alex", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1905.10837", "submitter": "Guy Davidson", "authors": "Guy Davidson, Michael C. Mozer", "title": "Sequential mastery of multiple visual tasks: Networks naturally learn to\n  learn and forget to forget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the behavior of a standard convolutional neural net in a\ncontinual-learning setting that introduces visual classification tasks\nsequentially and requires the net to master new tasks while preserving mastery\nof previously learned tasks. This setting corresponds to that which human\nlearners face as they acquire domain expertise serially, for example, as an\nindividual studies a textbook. Through simulations involving sequences of ten\nrelated visual tasks, we find reason for optimism that nets will scale well as\nthey advance from having a single skill to becoming multi-skill domain experts.\nWe observe two key phenomena. First, \\emph{forward facilitation}---the\naccelerated learning of task $n+1$ having learned $n$ previous tasks---grows\nwith $n$. Second, \\emph{backward interference}---the forgetting of the $n$\nprevious tasks when learning task $n+1$---diminishes with $n$. Amplifying\nforward facilitation is the goal of research on metalearning, and attenuating\nbackward interference is the goal of research on catastrophic forgetting. We\nfind that both of these goals are attained simply through broader exposure to a\ndomain.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:57:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 06:29:13 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 17:30:07 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 16:32:38 GMT"}, {"version": "v5", "created": "Tue, 31 Mar 2020 00:24:01 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Davidson", "Guy", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1905.10843", "submitter": "Stefano Spigler", "authors": "Stefano Spigler, Mario Geiger, Matthieu Wyart", "title": "Asymptotic learning curves of kernel methods: empirical data v.s.\n  Teacher-Student paradigm", "comments": "We added (i) the prediction of the exponent $\\beta$ for real data\n  using kernel PCA; (ii) the generalization of our results to non-Gaussian data\n  from reference [11] (Bordelon et al., \"Spectrum Dependent Learning Curves in\n  Kernel Regression and Wide Neural Networks\")", "journal-ref": null, "doi": "10.1088/1742-5468/abc61d", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many training data are needed to learn a supervised task? It is often\nobserved that the generalization error decreases as $n^{-\\beta}$ where $n$ is\nthe number of training examples and $\\beta$ an exponent that depends on both\ndata and algorithm. In this work we measure $\\beta$ when applying kernel\nmethods to real datasets. For MNIST we find $\\beta\\approx 0.4$ and for CIFAR10\n$\\beta\\approx 0.1$, for both regression and classification tasks, and for\nGaussian or Laplace kernels. To rationalize the existence of non-trivial\nexponents that can be independent of the specific kernel used, we study the\nTeacher-Student framework for kernels. In this scheme, a Teacher generates data\naccording to a Gaussian random field, and a Student learns them via kernel\nregression. With a simplifying assumption -- namely that the data are sampled\nfrom a regular lattice -- we derive analytically $\\beta$ for translation\ninvariant kernels, using previous results from the kriging literature. Provided\nthat the Student is not too sensitive to high frequencies, $\\beta$ depends only\non the smoothness and dimension of the training data. We confirm numerically\nthat these predictions hold when the training points are sampled at random on a\nhypersphere. Overall, the test error is found to be controlled by the magnitude\nof the projection of the true function on the kernel eigenvectors whose rank is\nlarger than $n$. Using this idea we predict relate the exponent $\\beta$ to an\nexponent $a$ describing how the coefficients of the true function in the\neigenbasis of the kernel decay with rank. We extract $a$ from real data by\nperforming kernel PCA, leading to $\\beta\\approx0.36$ for MNIST and\n$\\beta\\approx0.07$ for CIFAR10, in good agreement with observations. We argue\nthat these rather large exponents are possible due to the small effective\ndimension of the data.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 17:29:11 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 07:55:56 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 11:50:27 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 14:11:28 GMT"}, {"version": "v5", "created": "Wed, 24 Jul 2019 08:11:22 GMT"}, {"version": "v6", "created": "Thu, 6 Aug 2020 09:18:25 GMT"}, {"version": "v7", "created": "Thu, 13 Aug 2020 10:05:46 GMT"}, {"version": "v8", "created": "Tue, 18 Aug 2020 13:27:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Spigler", "Stefano", ""], ["Geiger", "Mario", ""], ["Wyart", "Matthieu", ""]]}, {"id": "1905.10845", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, Sungjin Im, Ben Moseley, Kirk Pruhs, Alireza Samadian", "title": "On Coresets for Regularized Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and mathematically analyze sampling-based algorithms for\nregularized loss minimization problems that are implementable in popular\ncomputational models for large data, in which the access to the data is\nrestricted in some way. Our main result is that if the regularizer's effect\ndoes not become negligible as the norm of the hypothesis scales, and as the\ndata scales, then a uniform sample of modest size is with high probability a\ncoreset. In the case that the loss function is either logistic regression or\nsoft-margin support vector machines, and the regularizer is one of the common\nrecommended choices, this result implies that a uniform sample of size $O(d\n\\sqrt{n})$ is with high probability a coreset of $n$ points in $\\Re^d$. We\ncontrast this upper bound with two lower bounds. The first lower bound shows\nthat our analysis of uniform sampling is tight; that is, a smaller uniform\nsample will likely not be a core set. The second lower bound shows that in some\nsense uniform sampling is close to optimal, as significantly smaller core sets\ndo not generally exist.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 17:43:48 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 21:12:37 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Im", "Sungjin", ""], ["Moseley", "Ben", ""], ["Pruhs", "Kirk", ""], ["Samadian", "Alireza", ""]]}, {"id": "1905.10848", "submitter": "Hangjian Li", "authors": "Hangjian Li, Oscar Hernan Madrid Padilla, Qing Zhou", "title": "Learning Gaussian DAGs from Network Data", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural learning of directed acyclic graphs (DAGs) or Bayesian networks\nhas been studied extensively under the assumption that data are independent. We\npropose a new Gaussian DAG model for dependent data which assumes the\nobservations are correlated according to an undirected network. Under this\nmodel, we develop a method to estimate the DAG structure given a topological\nordering of the nodes. The proposed method jointly estimates the Bayesian\nnetwork and the correlations among observations by optimizing a scoring\nfunction based on penalized likelihood. We show that under some mild\nconditions, the proposed method produces consistent estimators after one\niteration. Extensive numerical experiments also demonstrate that by jointly\nestimating the DAG structure and the sample correlation, our method achieves\nmuch higher accuracy in structure learning. When the node ordering is unknown,\nthrough experiments on synthetic and real data, we show that our algorithm can\nbe used to estimate the correlations between samples, with which we can\nde-correlate the dependent data to significantly improve the performance of\nclassical DAG learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 18:07:08 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 00:34:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Li", "Hangjian", ""], ["Padilla", "Oscar Hernan Madrid", ""], ["Zhou", "Qing", ""]]}, {"id": "1905.10854", "submitter": "Guy Hacohen", "authors": "Guy Hacohen, Leshem Choshen, Daphna Weinshall", "title": "Let's Agree to Agree: Neural Networks Share Classification Order on Real\n  Datasets", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a series of robust empirical observations, demonstrating that deep\nNeural Networks learn the examples in both the training and test sets in a\nsimilar order. This phenomenon is observed in all the commonly used benchmarks\nwe evaluated, including many image classification benchmarks, and one text\nclassification benchmark. While this phenomenon is strongest for models of the\nsame architecture, it also crosses architectural boundaries -- models of\ndifferent architectures start by learning the same examples, after which the\nmore powerful model may continue to learn additional examples. We further show\nthat this pattern of results reflects the interplay between the way neural\nnetworks learn benchmark datasets. Thus, when fixing the architecture, we show\nsynthetic datasets where this pattern ceases to exist. When fixing the dataset,\nwe show that other learning paradigms may learn the data in a different order.\nWe hypothesize that our results reflect how neural networks discover structure\nin natural datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 18:51:22 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 07:58:46 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 09:02:29 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 14:37:37 GMT"}, {"version": "v5", "created": "Tue, 2 Jun 2020 22:47:01 GMT"}, {"version": "v6", "created": "Mon, 13 Jul 2020 20:57:50 GMT"}, {"version": "v7", "created": "Mon, 20 Jul 2020 11:28:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hacohen", "Guy", ""], ["Choshen", "Leshem", ""], ["Weinshall", "Daphna", ""]]}, {"id": "1905.10857", "submitter": "Biwei Huang", "authors": "Biwei Huang, Kun Zhang, Mingming Gong, Clark Glymour", "title": "Causal Discovery and Forecasting in Nonstationary Environments with\n  State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific fields, such as economics and neuroscience, we are often\nfaced with nonstationary time series, and concerned with both finding causal\nrelations and forecasting the values of variables of interest, both of which\nare particularly challenging in such nonstationary environments. In this paper,\nwe study causal discovery and forecasting for nonstationary time series. By\nexploiting a particular type of state-space model to represent the processes,\nwe show that nonstationarity helps to identify causal structure and that\nforecasting naturally benefits from learned causal knowledge. Specifically, we\nallow changes in both causal strengths and noise variances in the nonlinear\nstate-space models, which, interestingly, renders both the causal structure and\nmodel parameters identifiable. Given the causal model, we treat forecasting as\na problem in Bayesian inference in the causal model, which exploits the\ntime-varying property of the data and adapts to new observations in a\nprincipled manner. Experimental results on synthetic and real-world data sets\ndemonstrate the efficacy of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 18:57:04 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 15:33:02 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Huang", "Biwei", ""], ["Zhang", "Kun", ""], ["Gong", "Mingming", ""], ["Glymour", "Clark", ""]]}, {"id": "1905.10859", "submitter": "Yixin Wang", "authors": "Yixin Wang, David M. Blei", "title": "Variational Bayes under Model Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) is a scalable alternative to Markov chain Monte Carlo\n(MCMC) for Bayesian posterior inference. Though popular, VB comes with few\ntheoretical guarantees, most of which focus on well-specified models. However,\nmodels are rarely well-specified in practice. In this work, we study VB under\nmodel misspecification. We prove the VB posterior is asymptotically normal and\ncenters at the value that minimizes the Kullback-Leibler (KL) divergence to the\ntrue data-generating distribution. Moreover, the VB posterior mean centers at\nthe same value and is also asymptotically normal. These results generalize the\nvariational Bernstein--von Mises theorem [29] to misspecified models. As a\nconsequence of these results, we find that the model misspecification error\ndominates the variational approximation error in VB posterior predictive\ndistributions. It explains the widely observed phenomenon that VB achieves\ncomparable predictive accuracy with MCMC even though VB uses an approximating\nfamily. As illustrations, we study VB under three forms of model\nmisspecification, ranging from model over-/under-dispersion to latent\ndimensionality misspecification. We conduct two simulation studies that\ndemonstrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:04:21 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 22:24:55 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1905.10861", "submitter": "Min-Hung Chen", "authors": "Min-Hung Chen, Zsolt Kira, Ghassan AlRegib", "title": "Temporal Attentive Alignment for Video Domain Adaptation", "comments": "CVPR2019 Workshop (Learning from Unlabeled Videos). Source code:\n  http://github.com/cmhungsteve/TA3N", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various image-based domain adaptation (DA) techniques have been\nproposed in recent years, domain shift in videos is still not well-explored.\nMost previous works only evaluate performance on small-scale datasets which are\nsaturated. Therefore, we first propose a larger-scale dataset with larger\ndomain discrepancy: UCF-HMDB_full. Second, we investigate different DA\nintegration methods for videos, and show that simultaneously aligning and\nlearning temporal dynamics achieves effective alignment even without\nsophisticated DA methods. Finally, we propose Temporal Attentive Adversarial\nAdaptation Network (TA3N), which explicitly attends to the temporal dynamics\nusing domain discrepancy for more effective domain alignment, achieving\nstate-of-the-art performance on three video DA datasets. The code and data are\nreleased at http://github.com/cmhungsteve/TA3N.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:15:23 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 01:24:44 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 17:17:38 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 05:24:54 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 03:45:29 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Chen", "Min-Hung", ""], ["Kira", "Zsolt", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "1905.10862", "submitter": "Brendan Avent", "authors": "Brendan Avent, Javier Gonzalez, Tom Diethe, Andrei Paleyes, Borja\n  Balle", "title": "Automatic Discovery of Privacy-Utility Pareto Fronts", "comments": "Proceedings on Privacy Enhancing Technologies 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a mathematical framework for privacy-preserving data\nanalysis. Changing the hyperparameters of a differentially private algorithm\nallows one to trade off privacy and utility in a principled way. Quantifying\nthis trade-off in advance is essential to decision-makers tasked with deciding\nhow much privacy can be provided in a particular application while maintaining\nacceptable utility. Analytical utility guarantees offer a rigorous tool to\nreason about this trade-off, but are generally only available for relatively\nsimple problems. For more complex tasks, such as training neural networks under\ndifferential privacy, the utility achieved by a given algorithm can only be\nmeasured empirically. This paper presents a Bayesian optimization methodology\nfor efficiently characterizing the privacy--utility trade-off of any\ndifferentially private algorithm using only empirical measurements of its\nutility. The versatility of our method is illustrated on a number of machine\nlearning tasks involving multiple models, optimizers, and datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:27:33 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 17:26:40 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 08:35:13 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 20:40:25 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Avent", "Brendan", ""], ["Gonzalez", "Javier", ""], ["Diethe", "Tom", ""], ["Paleyes", "Andrei", ""], ["Balle", "Borja", ""]]}, {"id": "1905.10864", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose, Andre Cianflone, William L. Hamilton", "title": "Generalizable Adversarial Attacks with Latent Variable Perturbation\n  Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial attacks on deep neural networks traditionally rely on a\nconstrained optimization paradigm, where an optimization procedure is used to\nobtain a single adversarial perturbation for a given input example. In this\nwork we frame the problem as learning a distribution of adversarial\nperturbations, enabling us to generate diverse adversarial distributions given\nan unperturbed input. We show that this framework is domain-agnostic in that\nthe same framework can be employed to attack different input domains with\nminimal modification. Across three diverse domains---images, text, and\ngraphs---our approach generates whitebox attacks with success rates that are\ncompetitive with or superior to existing approaches, with a new\nstate-of-the-art achieved in the graph domain. Finally, we demonstrate that our\nframework can efficiently generate a diverse set of attacks for a single given\ninput, and is even capable of attacking \\textit{unseen} test instances in a\nzero-shot manner, exhibiting attack generalization.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:38:15 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 23:30:40 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 23:22:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Cianflone", "Andre", ""], ["Hamilton", "William L.", ""]]}, {"id": "1905.10866", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson, Michael Muehlebach and Michael W. Mahoney", "title": "Physics-informed Autoencoders for Lyapunov-stable Fluid Flow Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to providing high-profile successes in computer vision and\nnatural language processing, neural networks also provide an emerging set of\ntechniques for scientific problems. Such data-driven models, however, typically\nignore physical insights from the scientific system under consideration. Among\nother things, a physics-informed model formulation should encode some degree of\nstability or robustness or well-conditioning (in that a small change of the\ninput will not lead to drastic changes in the output), characteristic of the\nunderlying scientific problem. We investigate whether it is possible to include\nphysics-informed prior knowledge for improving the model quality (e.g.,\ngeneralization performance, sensitivity to parameter tuning, or robustness in\nthe presence of noisy data). To that extent, we focus on the stability of an\nequilibrium, one of the most basic properties a dynamic system can have, via\nthe lens of Lyapunov analysis. For the prototypical problem of fluid flow\nprediction, we show that models preserving Lyapunov stability improve the\ngeneralization error and reduce the prediction uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 20:02:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Muehlebach", "Michael", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1905.10870", "submitter": "Yixin Wang", "authors": "Yixin Wang, Dhanya Sridhar, David M. Blei", "title": "Equal Opportunity and Affirmative Action via Counterfactual Predictions", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) can automate decision-making by learning to predict\ndecisions from historical data. However, these predictors may inherit\ndiscriminatory policies from past decisions and reproduce unfair decisions. In\nthis paper, we propose two algorithms that adjust fitted ML predictors to make\nthem fair. We focus on two legal notions of fairness: (a) providing equal\nopportunity (EO) to individuals regardless of sensitive attributes and (b)\nrepairing historical disadvantages through affirmative action (AA). More\ntechnically, we produce fair EO and AA predictors by positing a causal model\nand considering counterfactual decisions. We prove that the resulting\npredictors are theoretically optimal in predictive performance while satisfying\nfairness. We evaluate the algorithms, and the trade-offs between accuracy and\nfairness, on datasets about admissions, income, credit and recidivism.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 20:09:16 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 21:17:26 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Wang", "Yixin", ""], ["Sridhar", "Dhanya", ""], ["Blei", "David M.", ""]]}, {"id": "1905.10881", "submitter": "Pan Li", "authors": "Pan Li, Eli Chien, Olgica Milenkovic", "title": "Optimizing Generalized PageRank Methods for Seed-Expansion Community\n  Detection", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landing probabilities (LP) of random walks (RW) over graphs encode rich\ninformation regarding graph topology. Generalized PageRanks (GPR), which\nrepresent weighted sums of LPs of RWs, utilize the discriminative power of LP\nfeatures to enable many graph-based learning studies. Previous work in the area\nhas mostly focused on evaluating suitable weights for GPRs, and only a few\nstudies so far have attempted to derive the optimal weights of GRPs for a given\napplication. We take a fundamental step forward in this direction by using\nrandom graph models to better our understanding of the behavior of GPRs. In\nthis context, we provide a rigorous non-asymptotic analysis for the convergence\nof LPs and GPRs to their mean-field values on edge-independent random graphs.\nAlthough our theoretical results apply to many problem settings, we focus on\nthe task of seed-expansion community detection over stochastic block models.\nThere, we find that the predictive power of LPs decreases significantly slower\nthan previously reported based on asymptotic findings. Given this result, we\npropose a new GPR, termed Inverse PR (IPR), with LP weights that increase for\nthe initial few steps of the walks. Extensive experiments on both synthetic and\nreal, large-scale networks illustrate the superiority of IPR compared to other\nGPRs for seeded community detection.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:11:40 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 20:12:11 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 00:35:59 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Li", "Pan", ""], ["Chien", "Eli", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1905.10884", "submitter": "Martin Trapp", "authors": "Martin Trapp, Robert Peharz, Hong Ge, Franz Pernkopf, Zoubin\n  Ghahramani", "title": "Bayesian Learning of Sum-Product Networks", "comments": "NeurIPS 2019; See conference page for supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-product networks (SPNs) are flexible density estimators and have received\nsignificant attention due to their attractive inference properties. While\nparameter learning in SPNs is well developed, structure learning leaves\nsomething to be desired: Even though there is a plethora of SPN structure\nlearners, most of them are somewhat ad-hoc and based on intuition rather than a\nclear learning principle. In this paper, we introduce a well-principled\nBayesian framework for SPN structure learning. First, we decompose the problem\ninto i) laying out a computational graph, and ii) learning the so-called scope\nfunction over the graph. The first is rather unproblematic and akin to neural\nnetwork architecture validation. The second represents the effective structure\nof the SPN and needs to respect the usual structural constraints in SPN, i.e.\ncompleteness and decomposability. While representing and learning the scope\nfunction is somewhat involved in general, in this paper, we propose a natural\nparametrisation for an important and widely used special case of SPNs. These\nstructural parameters are incorporated into a Bayesian model, such that\nsimultaneous structure and parameter learning is cast into monolithic Bayesian\nposterior inference. In various experiments, our Bayesian SPNs often improve\ntest likelihoods over greedy SPN learners. Further, since the Bayesian\nframework protects against overfitting, we can evaluate hyper-parameters\ndirectly on the Bayesian model score, waiving the need for a separate\nvalidation set, which is especially beneficial in low data regimes. Bayesian\nSPNs can be applied to heterogeneous domains and can easily be extended to\nnonparametric formulations. Moreover, our Bayesian approach is the first, which\nconsistently and robustly learns SPN structures under missing data.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:22:52 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:24:31 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 13:26:50 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Trapp", "Martin", ""], ["Peharz", "Robert", ""], ["Ge", "Hong", ""], ["Pernkopf", "Franz", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1905.10885", "submitter": "Safa Cicek", "authors": "Safa Cicek, Stefano Soatto", "title": "Unsupervised Domain Adaptation via Regularized Conditional Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for unsupervised domain adaptation that trains a shared\nembedding to align the joint distributions of inputs (domain) and outputs\n(classes), making any classifier agnostic to the domain. Joint alignment\nensures that not only the marginal distributions of the domain are aligned, but\nthe labels as well. We propose a novel objective function that encourages the\nclass-conditional distributions to have disjoint support in feature space. We\nfurther exploit adversarial regularization to improve the performance of the\nclassifier on the domain for which no annotated data is available.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:25:45 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cicek", "Safa", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.10887", "submitter": "Suman Ravuri", "authors": "Suman Ravuri and Oriol Vinyals", "title": "Classification Accuracy Score for Conditional Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models (DGMs) of images are now sufficiently mature that they\nproduce nearly photorealistic samples and obtain scores similar to the data\ndistribution on heuristics such as Frechet Inception Distance (FID). These\nresults, especially on large-scale datasets such as ImageNet, suggest that DGMs\nare learning the data distribution in a perceptually meaningful space and can\nbe used in downstream tasks. To test this latter hypothesis, we use\nclass-conditional generative models from a number of model\nclasses---variational autoencoders, autoregressive models, and generative\nadversarial networks (GANs)---to infer the class labels of real data. We\nperform this inference by training an image classifier using only synthetic\ndata and using the classifier to predict labels on real data. The performance\non this task, which we call Classification Accuracy Score (CAS), reveals some\nsurprising results not identified by traditional metrics and constitute our\ncontributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1\nand Top-5 accuracy decrease by 27.9\\% and 41.6\\%, respectively, compared to the\noriginal data; and conditional generative models from other model classes, such\nas Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical\nAutoregressive Models (HAMs), substantially outperform GANs on this benchmark.\nSecond, CAS automatically surfaces particular classes for which generative\nmodels failed to capture the data distribution, and were previously unknown in\nthe literature. Third, we find traditional GAN metrics such as Inception Score\n(IS) and FID neither predictive of CAS nor useful when evaluating non-GAN\nmodels. Furthermore, in order to facilitate better diagnoses of generative\nmodels, we open-source the proposed metric.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:41:44 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 10:49:54 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ravuri", "Suman", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1905.10891", "submitter": "Bowei Chen", "authors": "Ji Ni and Bowei Chen and Nigel M. Allinson and Xujiong Ye", "title": "A hybrid model for predicting human physical activity status from\n  lifelogging data", "comments": null, "journal-ref": "European Journal of Operational Research, 281(3): 532-542, 2020", "doi": "10.1016/j.ejor.2019.05.035", "report-no": null, "categories": "cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One trend in the recent healthcare transformations is people are encouraged\nto monitor and manage their health based on their daily diets and physical\nactivity habits. However, much attention of the use of operational research and\nanalytical models in healthcare has been paid to the systematic level such as\ncountry or regional policy making or organisational issues. This paper proposes\na model concerned with healthcare analytics at the individual level, which can\npredict human physical activity status from sequential lifelogging data\ncollected from wearable sensors. The model has a two-stage hybrid structure (in\nshort, MOGP-HMM) -- a multi-objective genetic programming (MOGP) algorithm in\nthe first stage to reduce the dimensions of lifelogging data and a hidden\nMarkov model (HMM) in the second stage for activity status prediction over\ntime. It can be used as a decision support tool to provide real-time\nmonitoring, statistical analysis and personalized advice to individuals,\nencouraging positive attitudes towards healthy lifestyles. We validate the\nmodel with the real data collected from a group of participants in the UK, and\ncompare it with other popular two-stage hybrid models. Our experimental results\nshow that the MOGP-HMM can achieve comparable performance. To the best of our\nknowledge, this is the very first study that uses the MOGP in the hybrid\ntwo-stage structure for individuals' activity status prediction. It fits\nseamlessly with the current trend in the UK healthcare transformation of\npatient empowerment as well as contributing to a strategic development for more\nefficient and cost-effective provision of healthcare.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:49:40 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:08:24 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Ni", "Ji", ""], ["Chen", "Bowei", ""], ["Allinson", "Nigel M.", ""], ["Ye", "Xujiong", ""]]}, {"id": "1905.10899", "submitter": "Ernest Ryu", "authors": "Ernest K. Ryu and Kun Yuan and Wotao Yin", "title": "ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring\n  for Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable empirical success, the training dynamics of generative\nadversarial networks (GAN), which involves solving a minimax game using\nstochastic gradients, is still poorly understood. In this work, we analyze\nlast-iterate convergence of simultaneous gradient descent (simGD) and its\nvariants under the assumption of convex-concavity, guided by a continuous-time\nanalysis with differential equations. First, we show that simGD, as is,\nconverges with stochastic sub-gradients under strict convexity in the primal\nvariable. Second, we generalize optimistic simGD to accommodate an optimism\nrate separate from the learning rate and show its convergence with full\ngradients. Finally, we present anchored simGD, a new method, and show\nconvergence with stochastic subgradients.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:05:13 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 00:15:49 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 01:00:58 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ryu", "Ernest K.", ""], ["Yuan", "Kun", ""], ["Yin", "Wotao", ""]]}, {"id": "1905.10900", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Brian Tang, Nicolas Papernot, Kassem Fawaz,\n  Somesh Jha and Xi Wu", "title": "Rearchitecting Classification Frameworks For Increased Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generalizing well over natural inputs, neural networks are vulnerable\nto adversarial inputs. Existing defenses against adversarial inputs have\nlargely been detached from the real world. These defenses also come at a cost\nto accuracy. Fortunately, there are invariances of an object that are its\nsalient features; when we break them it will necessarily change the perception\nof the object. We find that applying invariants to the classification task\nmakes robustness and accuracy feasible together. Two questions follow: how to\nextract and model these invariances? and how to design a classification\nparadigm that leverages these invariances to improve the robustness accuracy\ntrade-off? The remainder of the paper discusses solutions to the aformenetioned\nquestions.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:10:38 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 17:00:15 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 23:16:11 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Tang", "Brian", ""], ["Papernot", "Nicolas", ""], ["Fawaz", "Kassem", ""], ["Jha", "Somesh", ""], ["Wu", "Xi", ""]]}, {"id": "1905.10901", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "Seeing Convolution Through the Eyes of Finite Transformation Semigroup\n  Theory: An Abstract Algebraic Interpretation of Convolutional Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers are actively trying to gain better insights into the\nrepresentational properties of convolutional neural networks for guiding better\nnetwork designs and for interpreting a network's computational nature. Gaining\nsuch insights can be an arduous task due to the number of parameters in a\nnetwork and the complexity of a network's architecture. Current approaches of\nneural network interpretation include Bayesian probabilistic interpretations\nand information theoretic interpretations. In this study, we take a different\napproach to studying convolutional neural networks by proposing an abstract\nalgebraic interpretation using finite transformation semigroup theory.\nSpecifically, convolutional layers are broken up and mapped to a finite space.\nThe state space of the proposed finite transformation semigroup is then defined\nas a single element within the convolutional layer, with the acting elements\ndefined by surrounding state elements combined with convolution kernel\nelements. Generators of the finite transformation semigroup are defined to\ncomplete the interpretation. We leverage this approach to analyze the basic\nproperties of the resulting finite transformation semigroup to gain insights on\nthe representational properties of convolutional neural networks, including\ninsights into quantized network representation. Such a finite transformation\nsemigroup interpretation can also enable better understanding outside of the\nconfines of fixed lattice data structures, thus useful for handling data that\nlie on irregular lattices. Furthermore, the proposed abstract algebraic\ninterpretation is shown to be viable for interpreting convolutional operations\nwithin a variety of convolutional neural network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:11:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.10904", "submitter": "Kevin Eykholt", "authors": "Kevin Eykholt, Swati Gupta, Atul Prakash, Amir Rahmati, Pratik\n  Vaishnavi, Haizhong Zheng", "title": "Robust Classification using Robust Feature Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep neural networks, say for image classification, have been shown\nto be vulnerable to adversarial images that can cause a DNN misclassification,\nwithout any perceptible change to an image. In this work, we propose shock\nabsorbing robust features such as binarization, e.g., rounding, and group\nextraction, e.g., color or shape, to augment the classification pipeline,\nresulting in more robust classifiers. Experimentally, we show that augmenting\nML models with these techniques leads to improved overall robustness on\nadversarial inputs as well as significant improvements in training time. On the\nMNIST dataset, we achieved 14x speedup in training time to obtain 90%\nadversarial accuracy com-pared to the state-of-the-art adversarial training\nmethod of Madry et al., as well as retained higher adversarial accuracy over a\nbroader range of attacks. We also find robustness improvements on traffic sign\nclassification using robust feature augmentation. Finally, we give theoretical\ninsights for why one can expect robust feature augmentation to reduce\nadversarial input space\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:18:32 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:25:16 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 00:09:26 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Eykholt", "Kevin", ""], ["Gupta", "Swati", ""], ["Prakash", "Atul", ""], ["Rahmati", "Amir", ""], ["Vaishnavi", "Pratik", ""], ["Zheng", "Haizhong", ""]]}, {"id": "1905.10906", "submitter": "Rita Singh", "authors": "Daanish Ali Khan, Linhong Li, Ninghao Sha, Zhuoran Liu, Abelino\n  Jimenez, Bhiksha Raj and Rita Singh", "title": "Non-Determinism in Neural Networks for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in the field of deep learning have led to advancements\nin a broad spectrum of tasks in computer vision, audio processing, natural\nlanguage processing and other areas. In most instances where these tasks are\ndeployed in real-world scenarios, the models used in them have been shown to be\nsusceptible to adversarial attacks, making it imperative for us to address the\nchallenge of their adversarial robustness. Existing techniques for adversarial\nrobustness fall into three broad categories: defensive distillation techniques,\nadversarial training techniques, and randomized or non-deterministic model\nbased techniques. In this paper, we propose a novel neural network paradigm\nthat falls under the category of randomized models for adversarial robustness,\nbut differs from all existing techniques under this category in that it models\neach parameter of the network as a statistical distribution with learnable\nparameters. We show experimentally that this framework is highly robust to a\nvariety of white-box and black-box adversarial attacks, while preserving the\ntask-specific performance of the traditional neural network model.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:55:35 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Khan", "Daanish Ali", ""], ["Li", "Linhong", ""], ["Sha", "Ninghao", ""], ["Liu", "Zhuoran", ""], ["Jimenez", "Abelino", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1905.10912", "submitter": "Aditya Dendukuri", "authors": "Aditya Dendukuri, Blake Keeling, Arash Fereidouni, Joshua Burbridge,\n  Khoa Luu, Hugh Churchill", "title": "Defining Quantum Neural Networks via Quantum Time Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel fundamental algorithm for for defining and\ntraining Neural Networks in Quantum Information based on time evolution and the\nHamiltonian. Classical Neural Network algorithms (ANN) are computationally\nexpensive. For example, in image classification, representing an image pixel by\npixel using classical information requires an enormous amount of computational\nmemory resources. Hence, exploring methods to represent images in a different\nparadigm of information is important. Quantum Neural Networks (QNNs) have been\nexplored for over 20 years. The current forefront work based on Variational\nQuantum Circuits is specifically defined for the Continuous Variable (CV) Model\nof quantum computers. In this work, a model is proposed which is defined at a\nmore fundamental level and hence can be inherited by any variants of quantum\ncomputing models. This work also presents a quantum backpropagation algorithm\nto train our QNN model and validate this algorithm on the MNIST dataset on a\nquantum computer simulation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:29:45 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 22:16:50 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Dendukuri", "Aditya", ""], ["Keeling", "Blake", ""], ["Fereidouni", "Arash", ""], ["Burbridge", "Joshua", ""], ["Luu", "Khoa", ""], ["Churchill", "Hugh", ""]]}, {"id": "1905.10913", "submitter": "Lorenzo Rosasco", "authors": "Ernesto De Vito, Nicole M\\\"ucke, Lorenzo Rosasco", "title": "Reproducing kernel Hilbert spaces on manifolds: Sobolev and Diffusion\n  spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reproducing kernel Hilbert spaces\n  (RKHS) on a Riemannian manifold. In particular, we discuss under which\ncondition Sobolev spaces are RKHS and characterize their reproducing kernels.\nFurther, we introduce and discuss a class of smoother RKHS that we call\ndiffusion spaces. We illustrate the general results with a number of detailed\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:41:28 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["De Vito", "Ernesto", ""], ["M\u00fccke", "Nicole", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1905.10915", "submitter": "Bochen Guan", "authors": "Bochen Guan, Jinnian Zhang, William A. Sethares, Richard Kijowski and\n  Fang Liu", "title": "SpecNet: Spectral Domain Convolutional Neural Network", "comments": "Accepted by ICASSP 21. Contact author: Bochen Guan\n  (bochen.guan@gmail.com)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The memory consumption of most Convolutional Neural Network (CNN)\narchitectures grows rapidly with increasing depth of the network, which is a\nmajor constraint for efficient network training on modern GPUs with limited\nmemory, embedded systems, and mobile devices. Several studies show that the\nfeature maps (as generated after the convolutional layers) are the main\nbottleneck in this memory problem. Often, these feature maps mimic natural\nphotographs in the sense that their energy is concentrated in the spectral\ndomain. Although embedding CNN architectures in the spectral domain is widely\nexploited to accelerate the training process, we demonstrate that it is also\npossible to use the spectral domain to reduce the memory footprint, a method we\ncall Spectral Domain Convolutional Neural Network (SpecNet) that performs both\nthe convolution and the activation operations in the spectral domain. The\nperformance of SpecNet is evaluated on three competitive object recognition\nbenchmark tasks (CIFAR-10, SVHN, and ImageNet), and compared with several\nstate-of-the-art implementations. Overall, SpecNet is able to reduce memory\nconsumption by about 60% without significant loss of performance for all tested\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:44:14 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 06:10:23 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 18:51:50 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 02:15:26 GMT"}, {"version": "v5", "created": "Tue, 20 Oct 2020 04:49:48 GMT"}, {"version": "v6", "created": "Mon, 8 Feb 2021 23:36:39 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Guan", "Bochen", ""], ["Zhang", "Jinnian", ""], ["Sethares", "William A.", ""], ["Kijowski", "Richard", ""], ["Liu", "Fang", ""]]}, {"id": "1905.10917", "submitter": "Andrea Agazzi", "authors": "Andrea Agazzi and Jianfeng Lu", "title": "Temporal-difference learning with nonlinear function approximation: lazy\n  training and mean field regimes", "comments": "added proof of mean-field dynamics optimality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the approximation of the value function for infinite-horizon\ndiscounted Markov Reward Processes (MRP) with nonlinear functions trained with\nthe Temporal-Difference (TD) learning algorithm. We first consider this problem\nunder a certain scaling of the approximating function, leading to a regime\ncalled lazy training. In this regime, the parameters of the model vary only\nslightly during the learning process, a feature that has recently been observed\nin the training of neural networks, where the scaling we study arises\nnaturally, implicit in the initialization of their parameters. Both in the\nunder- and over-parametrized frameworks, we prove exponential convergence to\nlocal, respectively global minimizers of the above algorithm in the lazy\ntraining regime. We then compare this scaling of the parameters to the\nmean-field regime, where the approximately linear behavior of the model is\nlost. Under this alternative scaling we prove that all fixed points of the\ndynamics in parameter space are global minimizers. We finally give examples of\nour convergence results in the case of models that diverge if trained with\nnon-lazy TD learning, and in the case of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 01:11:41 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 12:56:00 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 22:49:06 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 19:38:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Agazzi", "Andrea", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1905.10920", "submitter": "Hamideh Kerdegari", "authors": "Hamideh Kerdegari, Manzoor Razaak, Vasileios Argyriou, Paolo Remagnino", "title": "Semi-supervised GAN for Classification of Multispectral Imagery Acquired\n  by UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAV) are used in precision agriculture (PA) to\nenable aerial monitoring of farmlands. Intelligent methods are required to\npinpoint weed infestations and make optimal choice of pesticide. UAV can fly a\nmultispectral camera and collect data. However, the classification of\nmultispectral images using supervised machine learning algorithms such as\nconvolutional neural networks (CNN) requires large amount of training data.\nThis is a common drawback in deep learning we try to circumvent making use of a\nsemi-supervised generative adversarial networks (GAN), providing a pixel-wise\nclassification for all the acquired multispectral images. Our algorithm\nconsists of a generator network that provides photo-realistic images as extra\ntraining data to a multi-class classifier, acting as a discriminator and\ntrained on small amounts of labeled data. The performance of the proposed\nmethod is evaluated on the weedNet dataset consisting of multispectral crop and\nweed images collected by a micro aerial vehicle (MAV). The results by the\nproposed semi-supervised GAN achieves high classification accuracy and\ndemonstrates the potential of GAN-based methods for the challenging task of\nmultispectral image classification.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:43:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kerdegari", "Hamideh", ""], ["Razaak", "Manzoor", ""], ["Argyriou", "Vasileios", ""], ["Remagnino", "Paolo", ""]]}, {"id": "1905.10927", "submitter": "Michail Tzoufras", "authors": "Michail Tzoufras, Marcin Gajek, Andrew Walker", "title": "Magnetoresistive RAM for error resilient XNOR-Nets", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We trained three Binarized Convolutional Neural Network architectures\n(LeNet-4, Network-In-Network, AlexNet) on a variety of datasets (MNIST,\nCIFAR-10, CIFAR-100, extended SVHN, ImageNet) using error-prone activations and\ntested them without errors to study the resilience of the training process.\nWith the exception of the AlexNet when trained on the ImageNet dataset, we\nfound that Bit Error Rates of a few percent during training do not degrade the\ntest accuracy. Furthermore, by training the AlexNet on progressively smaller\nsubsets of ImageNet classes, we observed increasing tolerance to activation\nerrors. The ability to operate with high BERs is critical for reducing power\nconsumption in existing hardware and for facilitating emerging memory\ntechnologies. We discuss how operating at moderate BER can enable\nMagnetoresistive RAM with higher endurance, speed and density.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:10:48 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tzoufras", "Michail", ""], ["Gajek", "Marcin", ""], ["Walker", "Andrew", ""]]}, {"id": "1905.10930", "submitter": "Sean Welleck", "authors": "Sean Welleck, Kyunghyun Cho", "title": "Sequential Graph Dependency Parser", "comments": "RANLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for non-projective dependency parsing by incrementally\npredicting a set of edges. Since the edges do not have a pre-specified order,\nwe propose a set-based learning method. Our method blends graph, transition,\nand easy-first parsing, including a prior state of the parser as a special\ncase. The proposed transition-based method successfully parses near the state\nof the art on both projective and non-projective languages, without assuming a\ncertain parsing order.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 01:42:30 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 20:55:31 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Welleck", "Sean", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1905.10936", "submitter": "Shuai Zheng", "authors": "Shuai Zheng and Ziyue Huang and James T. Kwok", "title": "Communication-Efficient Distributed Blockwise Momentum SGD with\n  Error-Feedback", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication overhead is a major bottleneck hampering the scalability of\ndistributed machine learning systems. Recently, there has been a surge of\ninterest in using gradient compression to improve the communication efficiency\nof distributed neural network training. Using 1-bit quantization, signSGD with\nmajority vote achieves a 32x reduction on communication cost. However, its\nconvergence is based on unrealistic assumptions and can diverge in practice. In\nthis paper, we propose a general distributed compressed SGD with Nesterov's\nmomentum. We consider two-way compression, which compresses the gradients both\nto and from workers. Convergence analysis on nonconvex problems for general\ngradient compressors is provided. By partitioning the gradient into blocks, a\nblockwise compressor is introduced such that each gradient block is compressed\nand transmitted in 1-bit format with a scaling factor, leading to a nearly 32x\nreduction on communication. Experimental results show that the proposed method\nconverges as fast as full-precision distributed momentum SGD and achieves the\nsame testing accuracy. In particular, on distributed ResNet training with 7\nworkers on the ImageNet, the proposed algorithm achieves the same testing\naccuracy as momentum SGD using full-precision gradients, but with $46\\%$ less\nwall clock time.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:16:42 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 06:53:56 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zheng", "Shuai", ""], ["Huang", "Ziyue", ""], ["Kwok", "James T.", ""]]}, {"id": "1905.10943", "submitter": "Matthew Staib", "authors": "Matthew Staib and Stefanie Jegelka", "title": "Distributionally Robust Optimization and Generalization in Kernel\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally robust optimization (DRO) has attracted attention in machine\nlearning due to its connections to regularization, generalization, and\nrobustness. Existing work has considered uncertainty sets based on\nphi-divergences and Wasserstein distances, each of which have drawbacks. In\nthis paper, we study DRO with uncertainty sets measured via maximum mean\ndiscrepancy (MMD). We show that MMD DRO is roughly equivalent to regularization\nby the Hilbert norm and, as a byproduct, reveal deep connections to classic\nresults in statistical learning. In particular, we obtain an alternative proof\nof a generalization bound for Gaussian kernel ridge regression via a DRO lense.\nThe proof also suggests a new regularizer. Our results apply beyond kernel\nmethods: we derive a generically applicable approximation of MMD DRO, and show\nthat it generalizes recent work on variance-based regularization.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:50:15 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Staib", "Matthew", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.10944", "submitter": "Shuzhi Yu", "authors": "Shuzhi Yu and Carlo Tomasi", "title": "Identity Connections in Residual Nets Improve Noise Stability", "comments": "ICML 2019 Workshop on Understanding and Improving Generalization in\n  Deep Learning, additional analysis on a property called Dominant Gradient\n  Flow of Residual Nets in Appendix D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Neural Networks (ResNets) achieve state-of-the-art performance in\nmany computer vision problems. Compared to plain networks without residual\nconnections (PlnNets), ResNets train faster, generalize better, and suffer less\nfrom the so-called degradation problem. We introduce simplified (but still\nnonlinear) versions of ResNets and PlnNets for which these discrepancies still\nhold, although to a lesser degree. We establish a 1-1 mapping between\nsimplified ResNets and simplified PlnNets, and show that they are exactly\nequivalent to each other in expressive power for the same computational\ncomplexity. We conjecture that ResNets generalize better because they have\nbetter noise stability, and empirically support it for both simplified and\nfully-fledged networks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:52:46 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yu", "Shuzhi", ""], ["Tomasi", "Carlo", ""]]}, {"id": "1905.10945", "submitter": "Jongha Ryu", "authors": "J. Jon Ryu, Yoojin Choi, Young-Han Kim, Mostafa El-Khamy, Jungwon Lee", "title": "Wyner VAE: Joint and Conditional Generation with Succinct Common\n  Representation Learning", "comments": "24 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new variational autoencoder (VAE) model is proposed that learns a succinct\ncommon representation of two correlated data variables for conditional and\njoint generation tasks. The proposed Wyner VAE model is based on two\ninformation theoretic problems---distributed simulation and channel\nsynthesis---in which Wyner's common information arises as the fundamental limit\nof the succinctness of the common representation. The Wyner VAE decomposes a\npair of correlated data variables into their common representation (e.g., a\nshared concept) and local representations that capture the remaining randomness\n(e.g., texture and style) in respective data variables by imposing the mutual\ninformation between the data variables and the common representation as a\nregularization term. The utility of the proposed approach is demonstrated\nthrough experiments for joint and conditional generation with and without style\ncontrol using synthetic data and real images. Experimental results show that\nlearning a succinct common representation achieves better generative\nperformance and that the proposed model outperforms existing VAE variants and\nthe variational information bottleneck method.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:54:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ryu", "J. Jon", ""], ["Choi", "Yoojin", ""], ["Kim", "Young-Han", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1905.10947", "submitter": "Kenta Oono", "authors": "Kenta Oono, Taiji Suzuki", "title": "Graph Neural Networks Exponentially Lose Expressive Power for Node\n  Classification", "comments": "9 pages, Supplemental material 28 pages. Accepted in International\n  Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (graph NNs) are a promising deep learning approach for\nanalyzing graph-structured data. However, it is known that they do not improve\n(or sometimes worsen) their predictive performance as we pile up many layers\nand add non-lineality. To tackle this problem, we investigate the expressive\npower of graph NNs via their asymptotic behaviors as the layer size tends to\ninfinity. Our strategy is to generalize the forward propagation of a Graph\nConvolutional Network (GCN), which is a popular graph NN variant, as a specific\ndynamical system. In the case of a GCN, we show that when its weights satisfy\nthe conditions determined by the spectra of the (augmented) normalized\nLaplacian, its output exponentially approaches the set of signals that carry\ninformation of the connected components and node degrees only for\ndistinguishing nodes. Our theory enables us to relate the expressive power of\nGCNs with the topological information of the underlying graphs inherent in the\ngraph spectra. To demonstrate this, we characterize the asymptotic behavior of\nGCNs on the Erd\\H{o}s -- R\\'{e}nyi graph. We show that when the Erd\\H{o}s --\nR\\'{e}nyi graph is sufficiently dense and large, a broad range of GCNs on it\nsuffers from the \"information loss\" in the limit of infinite layers with high\nprobability. Based on the theory, we provide a principled guideline for weight\nnormalization of graph NNs. We experimentally confirm that the proposed weight\nscaling enhances the predictive performance of GCNs in real data. Code is\navailable at https://github.com/delta2323/gnn-asymptotics.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:59:06 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 04:45:55 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 14:51:10 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 09:21:18 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 13:32:14 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Oono", "Kenta", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1905.10948", "submitter": "Wen Sun", "authors": "Wen Sun, Anirudh Vemula, Byron Boots, J. Andrew Bagnell", "title": "Provably Efficient Imitation Learning from Observation Alone", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Imitation Learning (IL) from Observations alone (ILFO) in\nlarge-scale MDPs. While most IL algorithms rely on an expert to directly\nprovide actions to the learner, in this setting the expert only supplies\nsequences of observations. We design a new model-free algorithm for ILFO,\nForward Adversarial Imitation Learning (FAIL), which learns a sequence of\ntime-dependent policies by minimizing an Integral Probability Metric between\nthe observation distributions of the expert policy and the learner. FAIL is the\nfirst provably efficient algorithm in ILFO setting, which learns a near-optimal\npolicy with a number of samples that is polynomial in all relevant parameters\nbut independent of the number of unique observations. The resulting theory\nextends the domain of provably sample efficient learning algorithms beyond\nexisting results, which typically only consider tabular reinforcement learning\nsettings or settings that require access to a near-optimal reset distribution.\nWe also investigate the extension of FAIL in a model-based setting. Finally we\ndemonstrate the efficacy of FAIL on multiple OpenAI Gym control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:08:07 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 15:27:56 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sun", "Wen", ""], ["Vemula", "Anirudh", ""], ["Boots", "Byron", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1905.10949", "submitter": "Yu Yin", "authors": "Yu Yin, Qi Liu, Zhenya Huang, Enhong Chen, Wei Tong, Shijin Wang and\n  Yu Su", "title": "QuesNet: A Unified Representation for Heterogeneous Test Questions", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330900", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding learning materials (e.g. test questions) is a crucial issue in\nonline learning systems, which can promote many applications in education\ndomain. Unfortunately, many supervised approaches suffer from the problem of\nscarce human labeled data, whereas abundant unlabeled resources are highly\nunderutilized. To alleviate this problem, an effective solution is to use\npre-trained representations for question understanding. However, existing\npre-training methods in NLP area are infeasible to learn test question\nrepresentations due to several domain-specific characteristics in education.\nFirst, questions usually comprise of heterogeneous data including content text,\nimages and side information. Second, there exists both basic linguistic\ninformation as well as domain logic and knowledge. To this end, in this paper,\nwe propose a novel pre-training method, namely QuesNet, for comprehensively\nlearning question representations. Specifically, we first design a unified\nframework to aggregate question information with its heterogeneous inputs into\na comprehensive vector. Then we propose a two-level hierarchical pre-training\nalgorithm to learn better understanding of test questions in an unsupervised\nway. Here, a novel holed language model objective is developed to extract\nlow-level linguistic features, and a domain-oriented objective is proposed to\nlearn high-level logic and knowledge. Moreover, we show that QuesNet has good\ncapability of being fine-tuned in many question-based tasks. We conduct\nextensive experiments on large-scale real-world question data, where the\nexperimental results clearly demonstrate the effectiveness of QuesNet for\nquestion understanding as well as its superior applicability.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:08:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yin", "Yu", ""], ["Liu", "Qi", ""], ["Huang", "Zhenya", ""], ["Chen", "Enhong", ""], ["Tong", "Wei", ""], ["Wang", "Shijin", ""], ["Su", "Yu", ""]]}, {"id": "1905.10952", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Hongxu Yin, Niraj K. Jha", "title": "Incremental Learning Using a Grow-and-Prune Paradigm with Efficient\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become a widely deployed model for numerous\nmachine learning applications. However, their fixed architecture, substantial\ntraining cost, and significant model redundancy make it difficult to\nefficiently update them to accommodate previously unseen data. To solve these\nproblems, we propose an incremental learning framework based on a\ngrow-and-prune neural network synthesis paradigm. When new data arrive, the\nneural network first grows new connections based on the gradients to increase\nthe network capacity to accommodate new data. Then, the framework iteratively\nprunes away connections based on the magnitude of weights to enhance network\ncompactness, and hence recover efficiency. Finally, the model rests at a\nlightweight DNN that is both ready for inference and suitable for future\ngrow-and-prune updates. The proposed framework improves accuracy, shrinks\nnetwork size, and significantly reduces the additional training cost for\nincoming data compared to conventional approaches, such as training from\nscratch and network fine-tuning. For the LeNet-300-100 and LeNet-5 neural\nnetwork architectures derived for the MNIST dataset, the framework reduces\ntraining cost by up to 64% (63%) and 67% (63%) compared to training from\nscratch (network fine-tuning), respectively. For the ResNet-18 architecture\nderived for the ImageNet dataset and DeepSpeech2 for the AN4 dataset, the\ncorresponding training cost reductions against training from scratch (network\nfine-tunning) are 64% (60%) and 67% (62%), respectively. Our derived models\ncontain fewer network parameters but achieve higher accuracy relative to\nconventional baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:12:46 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1905.10953", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ilya Safro", "title": "FOBE and HOBE: First- and High-Order Bipartite Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical graph embeddings may not capture type-specific bipartite graph\nfeatures that arise in such areas as recommender systems, data visualization,\nand drug discovery. Machine learning methods utilized in these applications\nwould be better served with specialized embedding techniques. We propose two\nembeddings for bipartite graphs that decompose edges into sets of indirect\nrelationships between node neighborhoods. When sampling higher-order\nrelationships, we reinforce similarities through algebraic distance on graphs.\nWe also introduce ensemble embeddings to combine both into a \"best of both\nworlds\" embedding. The proposed methods are evaluated on link prediction and\nrecommendation tasks and compared with other state-of-the-art embeddings. While\nbeing all highly beneficial in applications, we demonstrate that none of the\nconsidered embeddings is clearly superior (in contrast to what is claimed in\nmany papers), and discuss the trade offs present among them. Reproducibility:\nOur code, data sets, and results are all publicly available online at:\nhttp://sybrandt.com/2020/fobe_hobe.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:12:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 03:53:45 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Sybrandt", "Justin", ""], ["Safro", "Ilya", ""]]}, {"id": "1905.10954", "submitter": "Yu Yin", "authors": "Yu Yin, Zhenya Huang, Enhong Chen, Qi Liu, Fuzheng Zhang, Xing Xie and\n  Guoping Hu", "title": "Transcribing Content from Structural Images with Spotlight Mechanism", "comments": "Accepted by KDD2018 Research Track. In proceedings of the 24th ACM\n  SIGKDD International Conference on Knowledge Discovery and Data Mining\n  (KDD'18)", "journal-ref": null, "doi": "10.1145/3219819.3219962", "report-no": null, "categories": "cs.LG cs.CV cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transcribing content from structural images, e.g., writing notes from music\nscores, is a challenging task as not only the content objects should be\nrecognized, but the internal structure should also be preserved. Existing image\nrecognition methods mainly work on images with simple content (e.g., text lines\nwith characters), but are not capable to identify ones with more complex\ncontent (e.g., structured symbols), which often follow a fine-grained grammar.\nTo this end, in this paper, we propose a hierarchical Spotlight Transcribing\nNetwork (STN) framework followed by a two-stage \"where-to-what\" solution.\nSpecifically, we first decide \"where-to-look\" through a novel spotlight\nmechanism to focus on different areas of the original image following its\nstructure. Then, we decide \"what-to-write\" by developing a GRU based network\nwith the spotlight areas for transcribing the content accordingly. Moreover, we\npropose two implementations on the basis of STN, i.e., STNM and STNR, where the\nspotlight movement follows the Markov property and Recurrent modeling,\nrespectively. We also design a reinforcement method to refine the framework by\nself-improving the spotlight mechanism. We conduct extensive experiments on\nmany structural image datasets, where the results clearly demonstrate the\neffectiveness of STN framework.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:25:29 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yin", "Yu", ""], ["Huang", "Zhenya", ""], ["Chen", "Enhong", ""], ["Liu", "Qi", ""], ["Zhang", "Fuzheng", ""], ["Xie", "Xing", ""], ["Hu", "Guoping", ""]]}, {"id": "1905.10955", "submitter": "Yazhou Yao", "authors": "Yazhou Yao, Zeren Sun, Fumin Shen, Li Liu, Limin Wang, Fan Zhu,\n  Lizhong Ding, Gangshan Wu, Ling Shao", "title": "Dynamically Visual Disambiguation of Keyword-based Image Search", "comments": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high cost of manual annotation, learning directly from the web has\nattracted broad attention. One issue that limits their performance is the\nproblem of visual polysemy. To address this issue, we present an adaptive\nmulti-model framework that resolves polysemy by visual disambiguation. Compared\nto existing methods, the primary advantage of our approach lies in that our\napproach can adapt to the dynamic changes in the search results. Our proposed\nframework consists of two major steps: we first discover and dynamically select\nthe text queries according to the image search results, then we employ the\nproposed saliency-guided deep multi-instance learning network to remove\noutliers and learn classification models for visual disambiguation. Extensive\nexperiments demonstrate the superiority of our proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:33:28 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yao", "Yazhou", ""], ["Sun", "Zeren", ""], ["Shen", "Fumin", ""], ["Liu", "Li", ""], ["Wang", "Limin", ""], ["Zhu", "Fan", ""], ["Ding", "Lizhong", ""], ["Wu", "Gangshan", ""], ["Shao", "Ling", ""]]}, {"id": "1905.10958", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "Explainable Reinforcement Learning Through a Causal Lens", "comments": "Accepted to AAAI 2020 - full paper (oral) - main track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prevalent theories in cognitive science propose that humans understand and\nrepresent the knowledge of the world through causal relationships. In making\nsense of the world, we build causal models in our mind to encode cause-effect\nrelations of events and use these to explain why new events happen. In this\npaper, we use causal models to derive causal explanations of behaviour of\nreinforcement learning agents. We present an approach that learns a structural\ncausal model during reinforcement learning and encodes causal relationships\nbetween variables of interest. This model is then used to generate explanations\nof behaviour based on counterfactual analysis of the causal model. We report on\na study with 120 participants who observe agents playing a real-time strategy\ngame (Starcraft II) and then receive explanations of the agents' behaviour. We\ninvestigated: 1) participants' understanding gained by explanations through\ntask prediction; 2) explanation satisfaction and 3) trust. Our results show\nthat causal model explanations perform better on these measures compared to two\nother baseline explanation models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:39:17 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 07:54:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "1905.10961", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, James Martens, Roger Grosse", "title": "Fast Convergence of Natural Gradient Descent for Overparameterized\n  Neural Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural gradient descent has proven effective at mitigating the effects of\npathological curvature in neural network optimization, but little is known\ntheoretically about its convergence properties, especially for \\emph{nonlinear}\nnetworks. In this work, we analyze for the first time the speed of convergence\nof natural gradient descent on nonlinear neural networks with squared-error\nloss. We identify two conditions which guarantee efficient convergence from\nrandom initializations: (1) the Jacobian matrix (of network's output for all\ntraining cases with respect to the parameters) has full row rank, and (2) the\nJacobian matrix is stable for small perturbations around the initialization.\nFor two-layer ReLU neural networks, we prove that these two conditions do in\nfact hold throughout the training, under the assumptions of nondegenerate\ninputs and overparameterization. We further extend our analysis to more general\nloss functions. Lastly, we show that K-FAC, an approximate natural gradient\ndescent method, also converges to global minima under the same assumptions, and\nwe give a bound on the rate of this convergence.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:53:50 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 14:40:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Guodong", ""], ["Martens", "James", ""], ["Grosse", "Roger", ""]]}, {"id": "1905.10963", "submitter": "Chi-Ken Lu", "authors": "Chi-Ken Lu, Scott Cheng-Hsin Yang, Xiaoran Hao, Patrick Shafto", "title": "Interpretable deep Gaussian processes with moments", "comments": "Preprint with 12 pages and 3 figures. The updated version (Oct 9\n  2019) consider the second and fourth moments, inspecting the heavy-tailed\n  nature of DGP distribution, justifying the validity of approximating DGP as\n  GP. A connection with the expressivity parameter in Poole et al NIPS paper is\n  also added. New reference and 4th moments of SC[]", "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian Processes (DGPs) combine the expressiveness of Deep Neural\nNetworks (DNNs) with quantified uncertainty of Gaussian Processes (GPs).\nExpressive power and intractable inference both result from the non-Gaussian\ndistribution over composition functions. We propose interpretable DGP based on\napproximating DGP as a GP by calculating the exact moments, which additionally\nidentify the heavy-tailed nature of some DGP distributions. Consequently, our\napproach admits interpretation as both NNs with specified activation functions\nand as a variational approximation to DGP. We identify the expressivity\nparameter of DGP and find non-local and non-stationary correlation from DGP\ncomposition. We provide general recipes for deriving the effective kernels for\nDGP of two, three, or infinitely many layers, composed of homogeneous or\nheterogeneous kernels. Results illustrate the expressiveness of our effective\nkernels through samples from the prior and inference on simulated and real data\nand demonstrate advantages of interpretability by analysis of analytic forms,\nand draw relations and equivalences across kernels.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:55:04 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 17:33:01 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 19:24:33 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Lu", "Chi-Ken", ""], ["Yang", "Scott Cheng-Hsin", ""], ["Hao", "Xiaoran", ""], ["Shafto", "Patrick", ""]]}, {"id": "1905.10964", "submitter": "Sunil Thulasidasan", "authors": "Sunil Thulasidasan, Tanmoy Bhattacharya, Jeff Bilmes, Gopinath\n  Chennupati, Jamal Mohd-Yusof", "title": "Combating Label Noise in Deep Learning Using Abstention", "comments": "ICML 2019. Added source code link", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method to combat label noise when training deep neural\nnetworks for classification. We propose a loss function that permits abstention\nduring training thereby allowing the DNN to abstain on confusing samples while\ncontinuing to learn and improve classification performance on the non-abstained\nsamples. We show how such a deep abstaining classifier (DAC) can be used for\nrobust learning in the presence of different types of label noise. In the case\nof structured or systematic label noise -- where noisy training labels or\nconfusing examples are correlated with underlying features of the data--\ntraining with abstention enables representation learning for features that are\nassociated with unreliable labels. In the case of unstructured (arbitrary)\nlabel noise, abstention during training enables the DAC to be used as an\neffective data cleaner by identifying samples that are likely to have label\nnoise. We provide analytical results on the loss function behavior that enable\ndynamic adaption of abstention rates based on learning progress during\ntraining. We demonstrate the utility of the deep abstaining classifier for\nvarious image classification tasks under different types of label noise; in the\ncase of arbitrary label noise, we show significant improvements over previously\npublished results on multiple image benchmarks. Source code is available at\nhttps://github.com/thulas/dac-label-noise\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 04:00:51 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 22:05:44 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Thulasidasan", "Sunil", ""], ["Bhattacharya", "Tanmoy", ""], ["Bilmes", "Jeff", ""], ["Chennupati", "Gopinath", ""], ["Mohd-Yusof", "Jamal", ""]]}, {"id": "1905.10969", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Mohammad Emtiyaz Khan, Jun Zhu", "title": "Scalable Training of Inference Networks for Gaussian-Process Models", "comments": "ICML 2019. Update results added in the camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in Gaussian process (GP) models is computationally challenging for\nlarge data, and often difficult to approximate with a small number of inducing\npoints. We explore an alternative approximation that employs stochastic\ninference networks for a flexible inference. Unfortunately, for such networks,\nminibatch training is difficult to be able to learn meaningful correlations\nover function outputs for a large dataset. We propose an algorithm that enables\nsuch training by tracking a stochastic, functional mirror-descent algorithm. At\neach iteration, this only requires considering a finite number of input\nlocations, resulting in a scalable and easy-to-implement algorithm. Empirical\nresults show comparable and, sometimes, superior performance to existing sparse\nvariational GP methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 04:33:37 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Shi", "Jiaxin", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Zhu", "Jun", ""]]}, {"id": "1905.10971", "submitter": "Shuai Tang", "authors": "Shuai Tang, Mahta Mousavi, Virginia R. de Sa", "title": "An Empirical Study on Post-processing Methods for Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings learnt from large corpora have been adopted in various\napplications in natural language processing and served as the general input\nrepresentations to learning systems. Recently, a series of post-processing\nmethods have been proposed to boost the performance of word embeddings on\nsimilarity comparison and analogy retrieval tasks, and some have been adapted\nto compose sentence representations. The general hypothesis behind these\nmethods is that by enforcing the embedding space to be more isotropic, the\nsimilarity between words can be better expressed. We view these methods as an\napproach to shrink the covariance/gram matrix, which is estimated by learning\nword vectors, towards a scaled identity matrix. By optimising an objective in\nthe semi-Riemannian manifold with Centralised Kernel Alignment (CKA), we are\nable to search for the optimal shrinkage parameter, and provide a\npost-processing method to smooth the spectrum of learnt word vectors which\nyields improved performance on downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 04:49:45 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 00:54:16 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 20:21:49 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Tang", "Shuai", ""], ["Mousavi", "Mahta", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1905.10974", "submitter": "Agnieszka Miko{\\l}ajczyk", "authors": "Agnieszka Miko{\\l}ajczyk, Micha{\\l} Grochowski", "title": "Style transfer-based image synthesis as an efficient regularization\n  technique in deep learning", "comments": "6 pages, 4 figures, accepted to the 24th International Conference on\n  Methods and Models in Automation and Robotics (MMAR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These days deep learning is the fastest-growing area in the field of Machine\nLearning. Convolutional Neural Networks are currently the main tool used for\nimage analysis and classification purposes. Although great achievements and\nperspectives, deep neural networks and accompanying learning algorithms have\nsome relevant challenges to tackle. In this paper, we have focused on the most\nfrequently mentioned problem in the field of machine learning, that is\nrelatively poor generalization abilities. Partial remedies for this are\nregularization techniques e.g. dropout, batch normalization, weight decay,\ntransfer learning, early stopping and data augmentation. In this paper, we have\nfocused on data augmentation. We propose to use a method based on a neural\nstyle transfer, which allows generating new unlabeled images of a high\nperceptual quality that combine the content of a base image with the appearance\nof another one. In a proposed approach, the newly created images are described\nwith pseudo-labels, and then used as a training dataset. Real, labeled images\nare divided into the validation and test set. We validated the proposed method\non a challenging skin lesion classification case study. Four representative\nneural architectures are examined. Obtained results show the strong potential\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 04:56:39 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Miko\u0142ajczyk", "Agnieszka", ""], ["Grochowski", "Micha\u0142", ""]]}, {"id": "1905.10975", "submitter": "Cole Freeman", "authors": "Cole Freeman, Mrinal Kanti Roy, Michele Fattoruso, Hamed Alhoori", "title": "Shared Feelings: Understanding Facebook Reactions to Scholarly Articles", "comments": "4 pages, 5 figures, JCDL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on social-media platforms has tended to rely on textual analysis to\nperform research tasks. While text-based approaches have significantly\nincreased our understanding of online behavior and social dynamics, they\noverlook features on these platforms that have grown in prominence in the past\nfew years: click-based responses to content. In this paper, we present a new\ndataset of Facebook Reactions to scholarly content. We give an overview of its\nstructure, analyze some of the statistical trends in the data, and use it to\ntrain and test two supervised learning algorithms. Our preliminary tests\nsuggest the presence of stratification in the number of users following pages,\ndivisions that seem to fall in line with distinctions in the subject matter of\nthose pages.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:00:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Freeman", "Cole", ""], ["Roy", "Mrinal Kanti", ""], ["Fattoruso", "Michele", ""], ["Alhoori", "Hamed", ""]]}, {"id": "1905.10979", "submitter": "Saurabh Agarwal", "authors": "Aravindakshan Babu, Saurabh Agarwal, Sudarshan Babu, Hariharan\n  Chandrasekaran", "title": "Scalable K-Medoids via True Error Bound and Familywise Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Medoids(KM) is a standard clustering method, used extensively on\nsemi-metric data.Error analyses of KM have traditionally used an in-sample\nnotion of error,which can be far from the true error and suffer from\ngeneralization gap. We formalize the true K-Medoid error based on the\nunderlying data distribution.We decompose the true error into fundamental\nstatistical problems of: minimum estimation (ME) and minimum mean estimation\n(MME). We provide a convergence result for MME. We show $\\errMME$ decreases no\nslower than $\\Theta(\\frac{1}{n^{\\frac{2}{3}}})$, where $n$ is a measure of\nsample size. Inspired by this bound, we propose a computationally efficient,\ndistributed KM algorithm namely MCPAM. MCPAM has expected runtime\n$\\mathcal{O}(km)$,where $k$ is the number of medoids and $m$ is number of\nsamples. MCPAM provides massive computational savings for a small tradeoff in\naccuracy. We verify the quality and scaling properties of MCPAM on various\ndatasets. And achieve the hitherto unachieved feat of calculating the KM of 1\nbillion points on semi-metric spaces.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:08:36 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:26:18 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Babu", "Aravindakshan", ""], ["Agarwal", "Saurabh", ""], ["Babu", "Sudarshan", ""], ["Chandrasekaran", "Hariharan", ""]]}, {"id": "1905.10982", "submitter": "Hazrat Ali", "authors": "Sulaiman Khan, Hazrat Ali, Zia Ullah, Mohammad Farhad Bulbul", "title": "An Intelligent Monitoring System of Vehicles on Highway Traffic", "comments": "5 pages", "journal-ref": "2018 12th International Conference on Open Source Systems and\n  Technologies (ICOSST), Lahore, Pakistan, 2018, pp. 71-75", "doi": "10.1109/ICOSST.2018.8632192", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vehicle speed monitoring and management of highways is the critical problem\nof the road in this modern age of growing technology and population. A poor\nmanagement results in frequent traffic jam, traffic rules violation and fatal\nroad accidents. Using traditional techniques of RADAR, LIDAR and LASAR to\naddress this problem is time-consuming, expensive and tedious. This paper\npresents an efficient framework to produce a simple, cost efficient and\nintelligent system for vehicle speed monitoring. The proposed method uses an HD\n(High Definition) camera mounted on the road side either on a pole or on a\ntraffic signal for recording video frames. On the basis of these frames, a\nvehicle can be tracked by using radius growing method, and its speed can be\ncalculated by calculating vehicle mask and its displacement in consecutive\nframes. The method uses pattern recognition, digital image processing and\nmathematical techniques for vehicle detection, tracking and speed calculation.\nThe validity of the proposed model is proved by testing it on different\nhighways.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:45:56 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Khan", "Sulaiman", ""], ["Ali", "Hazrat", ""], ["Ullah", "Zia", ""], ["Bulbul", "Mohammad Farhad", ""]]}, {"id": "1905.10983", "submitter": "Zikai Zhang", "authors": "Zikai Zhang, Yidong Li, Hairong Dong, Yizhe You and Fengping Zhao", "title": "Attention-based Supply-Demand Prediction for Autonomous Vehicles", "comments": "5 page, naive version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the important functions of the intelligent transportation system\n(ITS), supply-demand prediction for autonomous vehicles provides a decision\nbasis for its control. In this paper, we present two prediction models (i.e.\nARLP model and Advanced ARLP model) based on two system environments that only\nthe current day's historical data is available or several days' historical data\nare available. These two models jointly consider the spatial, temporal, and\nsemantic relations. Spatial dependency is captured with residual network and\ndimension reduction. Short term temporal dependency is captured with LSTM. Long\nterm temporal dependency and temporal shifting are captured with LSTM and\nattention mechanism. Semantic dependency is captured with multi-attention\nmechanism and autocorrelation coefficient method. Extensive experiments show\nthat our frameworks provide more accurate and stable prediction results than\nthe existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:51:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Zikai", ""], ["Li", "Yidong", ""], ["Dong", "Hairong", ""], ["You", "Yizhe", ""], ["Zhao", "Fengping", ""]]}, {"id": "1905.10987", "submitter": "Dmitry Baranchuk", "authors": "Dmitry Baranchuk, Dmitry Persiyanov, Anton Sinitsin, Artem Babenko", "title": "Learning to Route in Similarity Graphs", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently similarity graphs became the leading paradigm for efficient nearest\nneighbor search, outperforming traditional tree-based and LSH-based methods.\nSimilarity graphs perform the search via greedy routing: a query traverses the\ngraph and in each vertex moves to the adjacent vertex that is the closest to\nthis query. In practice, similarity graphs are often susceptible to local\nminima, when queries do not reach its nearest neighbors, getting stuck in\nsuboptimal vertices. In this paper we propose to learn the routing function\nthat overcomes local minima via incorporating information about the graph\nglobal structure. In particular, we augment the vertices of a given graph with\nadditional representations that are learned to provide the optimal routing from\nthe start vertex to the query nearest neighbor. By thorough experiments, we\ndemonstrate that the proposed learnable routing successfully diminishes the\nlocal minima problem and significantly improves the overall search performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:08:20 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Baranchuk", "Dmitry", ""], ["Persiyanov", "Dmitry", ""], ["Sinitsin", "Anton", ""], ["Babenko", "Artem", ""]]}, {"id": "1905.10988", "submitter": "Samuel Horv\\'ath", "authors": "Samuel Horvath, Chen-Yu Ho, Ludovit Horvath, Atal Narayan Sahu, Marco\n  Canini, Peter Richtarik", "title": "Natural Compression for Distributed Deep Learning", "comments": "8 pages, 20 pages of Appendix, 6 Tables, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models are often trained in parallel over a collection\nof distributed machines to reduce training time. In such settings,\ncommunication of model updates among machines becomes a significant performance\nbottleneck and various lossy update compression techniques have been proposed\nto alleviate this problem. In this work, we introduce a new, simple yet\ntheoretically and practically effective compression technique: {\\em natural\ncompression (NC)}. Our technique is applied individually to all entries of the\nto-be-compressed update vector and works by randomized rounding to the nearest\n(negative or positive) power of two, which can be computed in a \"natural\" way\nby ignoring the mantissa. We show that compared to no compression, NC increases\nthe second moment of the compressed vector by not more than the tiny factor\n$\\nicefrac{9}{8}$, which means that the effect of NC on the convergence speed\nof popular training algorithms, such as distributed SGD, is negligible.\nHowever, the communications savings enabled by NC are substantial, leading to\n{\\em $3$-$4\\times$ improvement in overall theoretical running time}. For\napplications requiring more aggressive compression, we generalize NC to {\\em\nnatural dithering}, which we prove is {\\em exponentially better} than the\ncommon random dithering technique. Our compression operators can be used on\ntheir own or in combination with existing operators for a more aggressive\ncombined effect, and offer new state-of-the-art both in theory and practice.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:10:59 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:58:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Horvath", "Samuel", ""], ["Ho", "Chen-Yu", ""], ["Horvath", "Ludovit", ""], ["Sahu", "Atal Narayan", ""], ["Canini", "Marco", ""], ["Richtarik", "Peter", ""]]}, {"id": "1905.10990", "submitter": "Frederik Diehl", "authors": "Frederik Diehl", "title": "Edge Contraction Pooling for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) research has concentrated on improving\nconvolutional layers, with little attention paid to developing graph pooling\nlayers. Yet pooling layers can enable GNNs to reason over abstracted groups of\nnodes instead of single nodes. To close this gap, we propose a graph pooling\nlayer relying on the notion of edge contraction: EdgePool learns a localized\nand sparse hard pooling transform. We show that EdgePool outperforms\nalternative pooling methods, can be easily integrated into most GNN models, and\nimproves performance on both node and graph classification.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:18:24 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Diehl", "Frederik", ""]]}, {"id": "1905.10994", "submitter": "Cagatay Yildiz", "authors": "\\c{C}a\\u{g}atay Y{\\i}ld{\\i}z, Markus Heinonen, Harri L\\\"ahdesm\\\"aki", "title": "ODE$^2$VAE: Deep generative second order ODEs with Bayesian neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Ordinary Differential Equation Variational Auto-Encoder\n(ODE$^2$VAE), a latent second order ODE model for high-dimensional sequential\ndata. Leveraging the advances in deep generative models, ODE$^2$VAE can\nsimultaneously learn the embedding of high dimensional trajectories and infer\narbitrarily complex continuous-time latent dynamics. Our model explicitly\ndecomposes the latent space into momentum and position components and solves a\nsecond order ODE system, which is in contrast to recurrent neural network (RNN)\nbased time series models and recently proposed black-box ODE techniques. In\norder to account for uncertainty, we propose probabilistic latent ODE dynamics\nparameterized by deep Bayesian neural networks. We demonstrate our approach on\nmotion capture, image rotation and bouncing balls datasets. We achieve\nstate-of-the-art performance in long term motion prediction and imputation\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:42:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 10:39:11 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Y\u0131ld\u0131z", "\u00c7a\u011fatay", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1905.10996", "submitter": "Christoph David Hofer PhD MSc", "authors": "Christoph D. Hofer, Florian Graf, Bastian Rieck, Marc Niethammer,\n  Roland Kwitt", "title": "Graph Filtration Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to learning with graph-structured data in the problem\ndomain of graph classification. In particular, we present a novel type of\nreadout operation to aggregate node features into a graph-level representation.\nTo this end, we leverage persistent homology computed via a real-valued,\nlearnable, filter function. We establish the theoretical foundation for\ndifferentiating through the persistent homology computation. Empirically, we\nshow that this type of readout operation compares favorably to previous\ntechniques, especially when the graph connectivity structure is informative for\nthe learning problem.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:46:30 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 07:54:26 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 04:39:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hofer", "Christoph D.", ""], ["Graf", "Florian", ""], ["Rieck", "Bastian", ""], ["Niethammer", "Marc", ""], ["Kwitt", "Roland", ""]]}, {"id": "1905.10998", "submitter": "Valerio Bonometti", "authors": "Valerio Bonometti, Charles Ringer, Mark Hall, Alex R. Wade, Anders\n  Drachen", "title": "Modelling Early User-Game Interactions for Joint Estimation of Survival\n  Time and Churn Probability", "comments": "Submitted to IEEE Conference on Games 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches which aim to identify and predict player engagement\nare becoming increasingly popular in games industry contexts. This is due to\nthe growing practice of tracking and storing large volumes of in-game\ntelemetries coupled with a desire to tailor the gaming experience to the\nend-user's needs. These approaches are particularly useful not just for\ncompanies adopting Game-as-a-Service (GaaS) models (e.g. for re-engagement\nstrategies) but also for those working under persistent content-delivery\nregimes (e.g. for better audience targeting). A major challenge for the latter\nis to build engagement models of the user which are data-efficient, holistic\nand can generalize across multiple game titles and genres with minimal\nadjustments. This work leverages a theoretical framework rooted in engagement\nand behavioural science research for building a model able to estimate\nengagement-related behaviours employing only a minimal set of game-agnostic\nmetrics. Through a series of experiments we show how, by modelling early\nuser-game interactions, this approach can make joint estimates of long-term\nsurvival time and churn probability across several single-player games in a\nrange of genres. The model proposed is very suitable for industry applications\nsince it relies on a minimal set of metrics and observations, scales well with\nthe number of users and is explicitly designed to work across a diverse range\nof titles.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 06:49:08 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 08:35:32 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 08:28:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Bonometti", "Valerio", ""], ["Ringer", "Charles", ""], ["Hall", "Mark", ""], ["Wade", "Alex R.", ""], ["Drachen", "Anders", ""]]}, {"id": "1905.11001", "submitter": "Sunil Thulasidasan", "authors": "Sunil Thulasidasan, Gopinath Chennupati, Jeff Bilmes, Tanmoy\n  Bhattacharya, Sarah Michalak", "title": "On Mixup Training: Improved Calibration and Predictive Uncertainty for\n  Deep Neural Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixup~\\cite{zhang2017mixup} is a recently proposed method for training deep\nneural networks where additional samples are generated during training by\nconvexly combining random pairs of images and their associated labels. While\nsimple to implement, it has been shown to be a surprisingly effective method of\ndata augmentation for image classification: DNNs trained with mixup show\nnoticeable gains in classification performance on a number of image\nclassification benchmarks. In this work, we discuss a hitherto untouched aspect\nof mixup training -- the calibration and predictive uncertainty of models\ntrained with mixup. We find that DNNs trained with mixup are significantly\nbetter calibrated -- i.e., the predicted softmax scores are much better\nindicators of the actual likelihood of a correct prediction -- than DNNs\ntrained in the regular fashion. We conduct experiments on a number of image\nclassification architectures and datasets -- including large-scale datasets\nlike ImageNet -- and find this to be the case. Additionally, we find that\nmerely mixing features does not result in the same calibration benefit and that\nthe label smoothing in mixup training plays a significant role in improving\ncalibration. Finally, we also observe that mixup-trained DNNs are less prone to\nover-confident predictions on out-of-distribution and random-noise data. We\nconclude that the typical overconfidence seen in neural networks, even on\nin-distribution data is likely a consequence of training with hard labels,\nsuggesting that mixup be employed for classification tasks where predictive\nuncertainty is a significant concern.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:00:33 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 03:16:37 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 04:45:51 GMT"}, {"version": "v4", "created": "Sun, 1 Dec 2019 00:37:50 GMT"}, {"version": "v5", "created": "Tue, 7 Jan 2020 01:26:21 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Thulasidasan", "Sunil", ""], ["Chennupati", "Gopinath", ""], ["Bilmes", "Jeff", ""], ["Bhattacharya", "Tanmoy", ""], ["Michalak", "Sarah", ""]]}, {"id": "1905.11006", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Changhan Wang and Jake Zhao", "title": "Levenshtein Transformer", "comments": "17 pages (6 pages appendix). Camera ready, accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural sequence generation models are built to either generate tokens\nstep-by-step from scratch or (iteratively) modify a sequence of tokens bounded\nby a fixed length. In this work, we develop Levenshtein Transformer, a new\npartially autoregressive model devised for more flexible and amenable sequence\ngeneration. Unlike previous approaches, the atomic operations of our model are\ninsertion and deletion. The combination of them facilitates not only generation\nbut also sequence refinement allowing dynamic length changes. We also propose a\nset of new training techniques dedicated at them, effectively exploiting one as\nthe other's learning signal thanks to their complementary nature. Experiments\napplying the proposed model achieve comparable performance but much-improved\nefficiency on both generation (e.g. machine translation, text summarization)\nand refinement tasks (e.g. automatic post-editing). We further confirm the\nflexibility of our model by showing a Levenshtein Transformer trained by\nmachine translation can straightforwardly be used for automatic post-editing.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:08:12 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 07:52:19 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gu", "Jiatao", ""], ["Wang", "Changhan", ""], ["Zhao", "Jake", ""]]}, {"id": "1905.11009", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Aritra Guha, Yuekai Sun and XuanLong Nguyen", "title": "Dirichlet Simplex Nest and Geometric Inference", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Dirichlet Simplex Nest, a class of probabilistic models suitable\nfor a variety of data types, and develop fast and provably accurate inference\nalgorithms by accounting for the model's convex geometry and low dimensional\nsimplicial structure. By exploiting the connection to Voronoi tessellation and\nproperties of Dirichlet distribution, the proposed inference algorithm is shown\nto achieve consistency and strong error bound guarantees on a range of model\nsettings and data distributions. The effectiveness of our model and the\nlearning algorithm is demonstrated by simulations and by analyses of text and\nfinancial data.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:12:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Guha", "Aritra", ""], ["Sun", "Yuekai", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1905.11010", "submitter": "Adam Farooq", "authors": "Adam Farooq, Yordan P. Raykov, Luc Evers, Max A. Little", "title": "Adaptive probabilistic principal component analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the linear Gaussian latent variable model as a starting point we relax\nsome of the constraints it imposes by deriving a nonparametric latent feature\nGaussian variable model. This model introduces additional discrete latent\nvariables to the original structure. The Bayesian nonparametric nature of this\nnew model allows it to adapt complexity as more data is observed and project\neach data point onto a varying number of subspaces. The linear relationship\nbetween the continuous latent and observed variables make the proposed model\nstraightforward to interpret, resembling a locally adaptive probabilistic PCA\n(A-PPCA). We propose two alternative Gibbs sampling procedures for inference in\nthe new model and demonstrate its applicability on sensor data for passive\nhealth monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:18:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Farooq", "Adam", ""], ["Raykov", "Yordan P.", ""], ["Evers", "Luc", ""], ["Little", "Max A.", ""]]}, {"id": "1905.11011", "submitter": "Mihailo Jovanovic", "authors": "Hesameddin Mohammadi, Meisam Razaviyayn, Mihailo R. Jovanovi\\'c", "title": "Robustness of accelerated first-order algorithms for strongly convex\n  optimization problems", "comments": "45 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness of accelerated first-order algorithms to stochastic\nuncertainties in gradient evaluation. Specifically, for unconstrained, smooth,\nstrongly convex optimization problems, we examine the mean-squared error in the\noptimization variable when the iterates are perturbed by additive white noise.\nThis type of uncertainty may arise in situations where an approximation of the\ngradient is sought through measurements of a real system or in a distributed\ncomputation over a network. Even though the underlying dynamics of first-order\nalgorithms for this class of problems are nonlinear, we establish upper bounds\non the mean-squared deviation from the optimal solution that are tight up to\nconstant factors. Our analysis quantifies fundamental trade-offs between noise\namplification and convergence rates obtained via any acceleration scheme\nsimilar to Nesterov's or heavy-ball methods. To gain additional analytical\ninsight, for strongly convex quadratic problems, we explicitly evaluate the\nsteady-state variance of the optimization variable in terms of the eigenvalues\nof the Hessian of the objective function. We demonstrate that the entire\nspectrum of the Hessian, rather than just the extreme eigenvalues, influence\nrobustness of noisy algorithms. We specialize this result to the problem of\ndistributed averaging over undirected networks and examine the role of network\nsize and topology on the robustness of noisy accelerated algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:19:13 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:04:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mohammadi", "Hesameddin", ""], ["Razaviyayn", "Meisam", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1905.11013", "submitter": "Hao Wang", "authors": "Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han\n  Wu, Wen Su", "title": "MCNE: An End-to-End Framework for Learning Multiple Conditional Network\n  Representations of Social Network", "comments": "Accepted by KDD 2019 Research Track. In Proceedings of the 25th ACM\n  SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'19)", "journal-ref": null, "doi": "10.1145/3292500.3330931", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Network Representation Learning (NRL) techniques, which\nrepresent graph structure via low-dimension vectors to support social-oriented\napplication, have attracted wide attention. Though large efforts have been\nmade, they may fail to describe the multiple aspects of similarity between\nsocial users, as only a single vector for one unique aspect has been\nrepresented for each node. To that end, in this paper, we propose a novel\nend-to-end framework named MCNE to learn multiple conditional network\nrepresentations, so that various preferences for multiple behaviors could be\nfully captured. Specifically, we first design a binary mask layer to divide the\nsingle vector as conditional embeddings for multiple behaviors. Then, we\nintroduce the attention network to model interaction relationship among\nmultiple preferences, and further utilize the adapted message sending and\nreceiving operation of graph neural network, so that multi-aspect preference\ninformation from high-order neighbors will be captured. Finally, we utilize\nBayesian Personalized Ranking loss function to learn the preference similarity\non each behavior, and jointly learn multiple conditional node embeddings via\nmulti-task learning framework. Extensive experiments on public datasets\nvalidate that our MCNE framework could significantly outperform several\nstate-of-the-art baselines, and further support the visualization and transfer\nlearning tasks with excellent interpretability and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:29:48 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Hao", ""], ["Xu", "Tong", ""], ["Liu", "Qi", ""], ["Lian", "Defu", ""], ["Chen", "Enhong", ""], ["Du", "Dongfang", ""], ["Wu", "Han", ""], ["Su", "Wen", ""]]}, {"id": "1905.11017", "submitter": "Chengjian Sun", "authors": "Chengjian Sun and Chenyang Yang", "title": "Learning to Optimize with Unsupervised Learning: Training Deep Neural\n  Networks for URLLC", "comments": "7 pages, 1 figure, submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the optimized solution as a function of environmental parameters is\neffective in solving numerical optimization in real time for time-sensitive\napplications. Existing works of learning to optimize train deep neural networks\n(DNN) with labels, and the learnt solution are inaccurate, which cannot be\nemployed to ensure the stringent quality of service. In this paper, we propose\na framework to learn the latent function with unsupervised deep learning, where\nthe property that the optimal solution should satisfy is used as the\n\"supervision signal\" implicitly. The framework is applicable to both functional\nand variable optimization problems with constraints. We take a variable\noptimization problem in ultra-reliable and low-latency communications as an\nexample, which demonstrates that the ultra-high reliability can be supported by\nthe DNN without supervision labels.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:42:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sun", "Chengjian", ""], ["Yang", "Chenyang", ""]]}, {"id": "1905.11027", "submitter": "Ke Sun", "authors": "Ke Sun and Frank Nielsen", "title": "Lightlike Neuromanifolds, Occam's Razor and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do deep neural networks benefit from a very high dimensional parameter\nspace? Their high complexity vs stunning generalization performance forms an\nintriguing paradox. We took an information-theoretic approach. We find that the\nlocally varying dimensionality of the parameter space can be studied by the\ndiscipline of singular semi-Riemannian geometry. We adapt Fisher information to\nthis singular neuromanifold. We use a new prior to interpolate between\nJeffreys' prior and the Gaussian prior. We derive a minimum description length\nof a deep learning model, where the spectrum of the Fisher information matrix\nplays a key role to reduce the model complexity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:57:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 05:53:28 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 03:45:04 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Sun", "Ke", ""], ["Nielsen", "Frank", ""]]}, {"id": "1905.11028", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Xiaoyu Liu, and Ingo Steinwart", "title": "Best-scored Random Forest Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm named best-scored random forest for binary\nclassification problems. The terminology \"best-scored\" means to select the one\nwith the best empirical performance out of a certain number of purely random\ntree candidates as each single tree in the forest. In this way, the resulting\nforest can be more accurate than the original purely random forest. From the\ntheoretical perspective, within the framework of regularized empirical risk\nminimization penalized on the number of splits, we establish almost optimal\nconvergence rates for the proposed best-scored random trees under certain\nconditions which can be extended to the best-scored random forest. In addition,\nwe present a counterexample to illustrate that in order to ensure the\nconsistency of the forest, every dimension must have the chance to be split. In\nthe numerical experiments, for the sake of efficiency, we employ an adaptive\nrandom splitting criterion. Comparative experiments with other state-of-art\nclassification methods demonstrate the accuracy of our best-scored random\nforest.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:58:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hang", "Hanyuan", ""], ["Liu", "Xiaoyu", ""], ["Steinwart", "Ingo", ""]]}, {"id": "1905.11041", "submitter": "Chuheng Zhang", "authors": "Chuheng Zhang, Yuanqi Li, Jian Li", "title": "Policy Search by Target Distribution Learning for Continuous Control", "comments": "AAAI-20 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that several existing policy gradient methods (such as vanilla\npolicy gradient, PPO, A2C) may suffer from overly large gradients when the\ncurrent policy is close to deterministic (even in some very simple\nenvironments), leading to an unstable training process. To address this issue,\nwe propose a new method, called \\emph{target distribution learning} (TDL), for\npolicy improvement in reinforcement learning. TDL alternates between proposing\na target distribution and training the policy network to approach the target\ndistribution. TDL is more effective in constraining the KL divergence between\nupdated policies, and hence leads to more stable policy improvements over\niterations. Our experiments show that TDL algorithms perform comparably to (or\nbetter than) state-of-the-art algorithms for most continuous control tasks in\nthe MuJoCo environment while being more stable in training.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:38:19 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 02:06:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhang", "Chuheng", ""], ["Li", "Yuanqi", ""], ["Li", "Jian", ""]]}, {"id": "1905.11045", "submitter": "Yuyang Xue", "authors": "Yuyang Xue, Jiannan Su", "title": "Attention Based Image Compression Post-Processing Convolutional Neural\n  Network", "comments": "4 pages, 2 figures, CVPR Compression Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional image compressors, e.g., BPG and H.266, have achieved great\nimage and video compression quality. Recently, Convolutional Neural Network has\nbeen used widely in image compression. We proposed an attention-based\nconvolutional neural network for low bit-rate compression to post-process the\noutput of traditional image compression decoder. Across the experimental\nresults on validation sets, the post-processing module trained by MAE and\nMS-SSIM losses yields the highest PSNR of 32.10 on average at the bit-rate of\n0.15.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:49:10 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Xue", "Yuyang", ""], ["Su", "Jiannan", ""]]}, {"id": "1905.11046", "submitter": "Yuan Zhou", "authors": "Chao Tao, Sa\\`ul Blanco, Jian Peng, Yuan Zhou", "title": "Thresholding Bandit with Optimal Aggregate Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the thresholding bandit problem, whose goal is to find arms of\nmean rewards above a given threshold $\\theta$, with a fixed budget of $T$\ntrials. We introduce LSA, a new, simple and anytime algorithm that aims to\nminimize the aggregate regret (or the expected number of mis-classified arms).\nWe prove that our algorithm is instance-wise asymptotically optimal. We also\nprovide comprehensive empirical results to demonstrate the algorithm's superior\nperformance over existing algorithms under a variety of different scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:51:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tao", "Chao", ""], ["Blanco", "Sa\u00f9l", ""], ["Peng", "Jian", ""], ["Zhou", "Yuan", ""]]}, {"id": "1905.11058", "submitter": "Yichao Wu", "authors": "Zhenmao Li, Yichao Wu, Ken Chen, Yudong Wu, Shunfeng Zhou, Jiaheng\n  Liu, Junjie Yan", "title": "Learning to Auto Weight: Entirely Data-driven and Highly Efficient\n  Weighting Framework", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Example weighting algorithm is an effective solution to the training bias\nproblem, however, most previous typical methods are usually limited to human\nknowledge and require laborious tuning of hyperparameters. In this paper, we\npropose a novel example weighting framework called Learning to Auto Weight\n(LAW). The proposed framework finds step-dependent weighting policies\nadaptively, and can be jointly trained with target networks without any\nassumptions or prior knowledge about the dataset. It consists of three key\ncomponents: Stage-based Searching Strategy (3SM) is adopted to shrink the huge\nsearching space in a complete training process; Duplicate Network Reward (DNR)\ngives more accurate supervision by removing randomness during the searching\nprocess; Full Data Update (FDU) further improves the updating efficiency.\nExperimental results demonstrate the superiority of weighting policy explored\nby LAW over standard training pipeline. Compared with baselines, LAW can find a\nbetter weighting schedule which achieves much more superior accuracy on both\nbiased CIFAR and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:05:28 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 06:43:14 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 05:39:17 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Li", "Zhenmao", ""], ["Wu", "Yichao", ""], ["Chen", "Ken", ""], ["Wu", "Yudong", ""], ["Zhou", "Shunfeng", ""], ["Liu", "Jiaheng", ""], ["Yan", "Junjie", ""]]}, {"id": "1905.11062", "submitter": "Hanwei Wu", "authors": "Hanwei Wu and Markus Flierl", "title": "Quantization-Based Regularization for Autoencoders", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders and their variations provide unsupervised models for learning\nlow-dimensional representations for downstream tasks. Without proper\nregularization, autoencoder models are susceptible to the overfitting problem\nand the so-called posterior collapse phenomenon. In this paper, we introduce a\nquantization-based regularizer in the bottleneck stage of autoencoder models to\nlearn meaningful latent representations. We combine both perspectives of Vector\nQuantized-Variational AutoEncoders (VQ-VAE) and classical denoising\nregularization methods of neural networks. We interpret quantizers as\nregularizers that constrain latent representations while fostering a\nsimilarity-preserving mapping at the encoder. Before quantization, we impose\nnoise on the latent codes and use a Bayesian estimator to optimize the\nquantizer-based representation. The introduced bottleneck Bayesian estimator\noutputs the posterior mean of the centroids to the decoder, and thus, is\nperforming soft quantization of the noisy latent codes. We show that our\nproposed regularization method results in improved latent representations for\nboth supervised learning and clustering downstream tasks when compared to\nautoencoders using other bottleneck structures.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:11:37 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 05:01:32 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wu", "Hanwei", ""], ["Flierl", "Markus", ""]]}, {"id": "1905.11063", "submitter": "Hadi Samer Jomaa", "authors": "Hadi S. Jomaa, Lars Schmidt-Thieme, Josif Grabocka", "title": "Dataset2Vec: Learning Dataset Meta-Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or learning to learn, is a machine learning approach that\nutilizes prior learning experiences to expedite the learning process on unseen\ntasks. As a data-driven approach, meta-learning requires meta-features that\nrepresent the primary learning tasks or datasets, and are estimated\ntraditonally as engineered dataset statistics that require expert domain\nknowledge tailored for every meta-task. In this paper, first, we propose a\nmeta-feature extractor called Dataset2Vec that combines the versatility of\nengineered dataset meta-features with the expressivity of meta-features learned\nby deep neural networks. Primary learning tasks or datasets are represented as\nhierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target\npairs, and then a DeepSet architecture is employed to regress meta-features on\nthem. Second, we propose a novel auxiliary meta-learning task with abundant\ndata called dataset similarity learning that aims to predict if two batches\nstem from the same dataset or different ones. In an experiment on a large-scale\nhyperparameter optimization task for 120 UCI datasets with varying schemas as a\nmeta-learning task, we show that the meta-features of Dataset2Vec outperform\nthe expert engineered meta-features and thus demonstrate the usefulness of\nlearned meta-features for datasets with varying schemas for the first time.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:11:57 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 15:47:31 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 20:23:55 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 07:43:56 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Jomaa", "Hadi S.", ""], ["Schmidt-Thieme", "Lars", ""], ["Grabocka", "Josif", ""]]}, {"id": "1905.11065", "submitter": "Stefano Peluchetti", "authors": "Stefano Peluchetti, Stefano Favaro", "title": "Infinitely deep neural networks as diffusion processes", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the parameters are independently and identically distributed\n(initialized) neural networks exhibit undesirable properties that emerge as the\nnumber of layers increases, e.g. a vanishing dependency on the input and a\nconcentration on restrictive families of functions including constant\nfunctions. We consider parameter distributions that shrink as the number of\nlayers increases in order to recover well-behaved stochastic processes in the\nlimit of infinite depth. This leads to set forth a link between infinitely deep\nresidual networks and solutions to stochastic differential equations, i.e.\ndiffusion processes. We show that these limiting processes do not suffer from\nthe aforementioned issues and investigate their properties.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:13:56 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 07:57:27 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 03:54:20 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Peluchetti", "Stefano", ""], ["Favaro", "Stefano", ""]]}, {"id": "1905.11067", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Chia-Mu Yu, Arashi Haishima, Jun Sakuma", "title": "Locally Differentially Private Minimum Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a problem of finding the minimum, in which each user has a\nreal value and we want to estimate the minimum of these values under the local\ndifferential privacy constraint. We reveal that this problem is fundamentally\ndifficult, and we cannot construct a mechanism that is consistent in the worst\ncase. Instead of considering the worst case, we aim to construct a private\nmechanism whose error rate is adaptive to the easiness of estimation of the\nminimum. As a measure of easiness, we introduce a parameter $\\alpha$ that\ncharacterizes the fatness of the minimum-side tail of the user data\ndistribution. As a result, we reveal that the mechanism can achieve\n$O((\\ln^6N/\\epsilon^2N)^{1/2\\alpha})$ error without knowledge of $\\alpha$ and\nthe error rate is near-optimal in the sense that any mechanism incurs\n$\\Omega((1/\\epsilon^2N)^{1/2\\alpha})$ error. Furthermore, we demonstrate that\nour mechanism outperforms a naive mechanism by empirical evaluations on\nsynthetic datasets. Also, we conducted experiments on the MovieLens dataset and\na purchase history dataset and demonstrate that our algorithm achieves\n$\\tilde{O}((1/N)^{1/2\\alpha})$ error adaptively to $\\alpha$.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:17:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Yu", "Chia-Mu", ""], ["Haishima", "Arashi", ""], ["Sakuma", "Jun", ""]]}, {"id": "1905.11068", "submitter": "Daniel Schleich", "authors": "Daniel Schleich, Tobias Klamt, Sven Behnke", "title": "Value Iteration Networks on Multiple Levels of Abstraction", "comments": null, "journal-ref": "Proceedings of Robotics: Science and Systems (RSS), Freiburg,\n  Germany, June 2019", "doi": "10.15607/RSS.2019.XV.014", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methods are promising to plan robot motion without performing\nextensive search, which is needed by many non-learning approaches. Recently,\nValue Iteration Networks (VINs) received much interest since---in contrast to\nstandard CNN-based architectures---they learn goal-directed behaviors which\ngeneralize well to unseen domains. However, VINs are restricted to small and\nlow-dimensional domains, limiting their applicability to real-world planning\nproblems.\n  To address this issue, we propose to extend VINs to representations with\nmultiple levels of abstraction. While the vicinity of the robot is represented\nin sufficient detail, the representation gets spatially coarser with increasing\ndistance from the robot. The information loss caused by the decreasing\nresolution is compensated by increasing the number of features representing a\ncell. We show that our approach is capable of solving significantly larger 2D\ngrid world planning tasks than the original VIN implementation. In contrast to\na multiresolution coarse-to-fine VIN implementation which does not employ\nadditional descriptive features, our approach is capable of solving challenging\nenvironments, which demonstrates that the proposed method learns to encode\nuseful information in the additional features. As an application for solving\nreal-world planning tasks, we successfully employ our method to plan\nomnidirectional driving for a search-and-rescue robot in cluttered terrain.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:17:33 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:11:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Schleich", "Daniel", ""], ["Klamt", "Tobias", ""], ["Behnke", "Sven", ""]]}, {"id": "1905.11071", "submitter": "Pierre Ablin", "authors": "Pierre Ablin, Thomas Moreau, Mathurin Massias and Alexandre Gramfort", "title": "Learning step sizes for unfolded sparse coding", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding is typically solved by iterative optimization techniques, such\nas the Iterative Shrinkage-Thresholding Algorithm (ISTA). Unfolding and\nlearning weights of ISTA using neural networks is a practical way to accelerate\nestimation. In this paper, we study the selection of adapted step sizes for\nISTA. We show that a simple step size strategy can improve the convergence rate\nof ISTA by leveraging the sparsity of the iterates. However, it is impractical\nin most large-scale applications. Therefore, we propose a network architecture\nwhere only the step sizes of ISTA are learned. We demonstrate that for a large\nclass of unfolded algorithms, if the algorithm converges to the solution of the\nLasso, its last layers correspond to ISTA with learned step sizes. Experiments\nshow that our method is competitive with state-of-the-art networks when the\nsolutions are sparse enough.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:19:02 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ablin", "Pierre", ""], ["Moreau", "Thomas", ""], ["Massias", "Mathurin", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1905.11075", "submitter": "Petros Koumoutsakos", "authors": "Steven Brunton and Bernd Noack and Petros Koumoutsakos", "title": "Machine Learning for Fluid Mechanics", "comments": "To appear in the Annual Reviews of Fluid Mechanics, 2020", "journal-ref": null, "doi": "10.1146/annurev-fluid-010719-060214", "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of fluid mechanics is rapidly advancing, driven by unprecedented\nvolumes of data from field measurements, experiments and large-scale\nsimulations at multiple spatiotemporal scales. Machine learning offers a wealth\nof techniques to extract information from data that could be translated into\nknowledge about the underlying fluid mechanics. Moreover, machine learning\nalgorithms can augment domain knowledge and automate tasks related to flow\ncontrol and optimization. This article presents an overview of past history,\ncurrent developments, and emerging opportunities of machine learning for fluid\nmechanics. It outlines fundamental machine learning methodologies and discusses\ntheir uses for understanding, modeling, optimizing, and controlling fluid\nflows. The strengths and limitations of these methods are addressed from the\nperspective of scientific inquiry that considers data as an inherent part of\nmodeling, experimentation, and simulation. Machine learning provides a powerful\ninformation processing framework that can enrich, and possibly even transform,\ncurrent lines of fluid mechanics research and industrial applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:26:17 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 07:59:26 GMT"}, {"version": "v3", "created": "Sat, 4 Jan 2020 11:27:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Brunton", "Steven", ""], ["Noack", "Bernd", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1905.11079", "submitter": "Yufei Wang", "authors": "Yufei Wang, Ziju Shen, Zichao Long, Bin Dong", "title": "Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conservation laws are considered to be fundamental laws of nature. It has\nbroad applications in many fields, including physics, chemistry, biology,\ngeology, and engineering. Solving the differential equations associated with\nconservation laws is a major branch in computational mathematics. The recent\nsuccess of machine learning, especially deep learning in areas such as computer\nvision and natural language processing, has attracted a lot of attention from\nthe community of computational mathematics and inspired many intriguing works\nin combining machine learning with traditional methods. In this paper, we are\nthe first to view numerical PDE solvers as an MDP and to use (deep) RL to learn\nnew solvers. As proof of concept, we focus on 1-dimensional scalar conservation\nlaws. We deploy the machinery of deep reinforcement learning to train a policy\nnetwork that can decide on how the numerical solutions should be approximated\nin a sequential and spatial-temporal adaptive manner. We will show that the\nproblem of solving conservation laws can be naturally viewed as a sequential\ndecision-making process, and the numerical schemes learned in such a way can\neasily enforce long-term accuracy. Furthermore, the learned policy network is\ncarefully designed to determine a good local discrete approximation based on\nthe current state of the solution, which essentially makes the proposed method\na meta-learning approach. In other words, the proposed method is capable of\nlearning how to discretize for a given situation mimicking human experts.\nFinally, we will provide details on how the policy network is trained, how well\nit performs compared with some state-of-the-art numerical solvers such as WENO\nschemes, and supervised learning based approach L3D and PINN, and how well it\ngeneralizes.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:31:12 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 15:06:32 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 03:45:42 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 03:27:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Yufei", ""], ["Shen", "Ziju", ""], ["Long", "Zichao", ""], ["Dong", "Bin", ""]]}, {"id": "1905.11088", "submitter": "Jee Seok Yoon", "authors": "Jee Seok Yoon, Myung-Cheol Roh, Heung-Il Suk", "title": "A Plug-in Method for Representation Factorization in Connectionist\n  Models", "comments": "in IEEE Transactions on Neural Networks and Learning Systems, 2021", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3054480", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we focus on decomposing latent representations in generative\nadversarial networks or learned feature representations in deep autoencoders\ninto semantically controllable factors in a semisupervised manner, without\nmodifying the original trained models. Particularly, we propose factors'\ndecomposer-entangler network (FDEN) that learns to decompose a latent\nrepresentation into mutually independent factors. Given a latent\nrepresentation, the proposed framework draws a set of interpretable factors,\neach aligned to independent factors of variations by minimizing their total\ncorrelation in an information-theoretic means. As a plug-in method, we have\napplied our proposed FDEN to the existing networks of adversarially learned\ninference and pioneer network and performed computer vision tasks of\nimage-to-image translation in semantic ways, e.g., changing styles, while\nkeeping the identity of a subject, and object classification in a few-shot\nlearning scheme. We have also validated the effectiveness of the proposed\nmethod with various ablation studies in the qualitative, quantitative, and\nstatistical examination.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:54:19 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 04:33:59 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 07:18:30 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 10:48:48 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Yoon", "Jee Seok", ""], ["Roh", "Myung-Cheol", ""], ["Suk", "Heung-Il", ""]]}, {"id": "1905.11092", "submitter": "Jan Macdonald", "authors": "Jan Macdonald, Stephan W\\\"aldchen, Sascha Hauch, Gitta Kutyniok", "title": "A Rate-Distortion Framework for Explaining Neural Network Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalise the widespread idea of interpreting neural network decisions as\nan explicit optimisation problem in a rate-distortion framework. A set of input\nfeatures is deemed relevant for a classification decision if the expected\nclassifier score remains nearly constant when randomising the remaining\nfeatures. We discuss the computational complexity of finding small sets of\nrelevant features and show that the problem is complete for\n$\\mathsf{NP}^\\mathsf{PP}$, an important class of computational problems\nfrequently arising in AI tasks. Furthermore, we show that it even remains\n$\\mathsf{NP}$-hard to only approximate the optimal solution to within any\nnon-trivial approximation factor. Finally, we consider a continuous problem\nrelaxation and develop a heuristic solution strategy based on assumed density\nfiltering for deep ReLU neural networks. We present numerical experiments for\ntwo image classification data sets where we outperform established methods in\nparticular for sparse explanations of neural network decisions.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:58:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Macdonald", "Jan", ""], ["W\u00e4ldchen", "Stephan", ""], ["Hauch", "Sascha", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1905.11096", "submitter": "Juli\\'an Urbano", "authors": "Juli\\'an Urbano, Harlley Lima, Alan Hanjalic", "title": "Statistical Significance Testing in Information Retrieval: An Empirical\n  Analysis of Type I, Type II and Type III Errors", "comments": "10 pages, 6 figures, SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331259", "report-no": null, "categories": "cs.IR cs.DL cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical significance testing is widely accepted as a means to assess how\nwell a difference in effectiveness reflects an actual difference between\nsystems, as opposed to random noise because of the selection of topics.\nAccording to recent surveys on SIGIR, CIKM, ECIR and TOIS papers, the t-test is\nthe most popular choice among IR researchers. However, previous work has\nsuggested computer intensive tests like the bootstrap or the permutation test,\nbased mainly on theoretical arguments. On empirical grounds, others have\nsuggested non-parametric alternatives such as the Wilcoxon test. Indeed, the\nquestion of which tests we should use has accompanied IR and related fields for\ndecades now. Previous theoretical studies on this matter were limited in that\nwe know that test assumptions are not met in IR experiments, and empirical\nstudies were limited in that we do not have the necessary control over the null\nhypotheses to compute actual Type I and Type II error rates under realistic\nconditions. Therefore, not only is it unclear which test to use, but also how\nmuch trust we should put in them. In contrast to past studies, in this paper we\nemploy a recent simulation methodology from TREC data to go around these\nlimitations. Our study comprises over 500 million p-values computed for a range\nof tests, systems, effectiveness measures, topic set sizes and effect sizes,\nand for both the 2-tail and 1-tail cases. Having such a large supply of IR\nevaluation data with full knowledge of the null hypotheses, we are finally in a\nposition to evaluate how well statistical significance tests really behave with\nIR data, and make sound recommendations for practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:02:29 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 22:18:34 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Urbano", "Juli\u00e1n", ""], ["Lima", "Harlley", ""], ["Hanjalic", "Alan", ""]]}, {"id": "1905.11100", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Jianye Hao, Guangyong Chen, Pengfei Chen, Zhaopeng Meng,\n  Yaodong Yang, Li Wang", "title": "Disentangling Dynamics and Returns: Value Function Decomposition with\n  Future Prediction", "comments": "10 pages for paper and 6 pages for the supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value functions are crucial for model-free Reinforcement Learning (RL) to\nobtain a policy implicitly or guide the policy updates. Value estimation\nheavily depends on the stochasticity of environmental dynamics and the quality\nof reward signals. In this paper, we propose a two-step understanding of value\nestimation from the perspective of future prediction, through decomposing the\nvalue function into a reward-independent future dynamics part and a\npolicy-independent trajectory return part. We then derive a practical deep RL\nalgorithm from the above decomposition, consisting of a convolutional\ntrajectory representation model, a conditional variational dynamics model to\npredict the expected representation of future trajectory and a convex\ntrajectory return model that maps a trajectory representation to its return.\nOur algorithm is evaluated in MuJoCo continuous control tasks and shows\nsuperior results under both common settings and delayed reward settings.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:15:42 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Chen", "Guangyong", ""], ["Chen", "Pengfei", ""], ["Meng", "Zhaopeng", ""], ["Yang", "Yaodong", ""], ["Wang", "Li", ""]]}, {"id": "1905.11108", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine", "title": "SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to imitate expert behavior from demonstrations can be challenging,\nespecially in environments with high-dimensional, continuous observations and\nunknown dynamics. Supervised learning methods based on behavioral cloning (BC)\nsuffer from distribution shift: because the agent greedily imitates\ndemonstrated actions, it can drift away from demonstrated states due to error\naccumulation. Recent methods based on reinforcement learning (RL), such as\ninverse RL and generative adversarial imitation learning (GAIL), overcome this\nissue by training an RL agent to match the demonstrations over a long horizon.\nSince the true reward function for the task is unknown, these methods learn a\nreward function from the demonstrations, often using complex and brittle\napproximation techniques that involve adversarial training. We propose a simple\nalternative that still uses RL, but does not require learning a reward\nfunction. The key idea is to provide the agent with an incentive to match the\ndemonstrations over a long horizon, by encouraging it to return to demonstrated\nstates upon encountering new, out-of-distribution states. We accomplish this by\ngiving the agent a constant reward of r=+1 for matching the demonstrated action\nin a demonstrated state, and a constant reward of r=0 for all other behavior.\nOur method, which we call soft Q imitation learning (SQIL), can be implemented\nwith a handful of minor modifications to any standard Q-learning or off-policy\nactor-critic algorithm. Theoretically, we show that SQIL can be interpreted as\na regularized variant of BC that uses a sparsity prior to encourage\nlong-horizon imitation. Empirically, we show that SQIL outperforms BC and\nachieves competitive results compared to GAIL, on a variety of image-based and\nlow-dimensional tasks in Box2D, Atari, and MuJoCo.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:29:31 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 08:39:46 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:44:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Reddy", "Siddharth", ""], ["Dragan", "Anca D.", ""], ["Levine", "Sergey", ""]]}, {"id": "1905.11112", "submitter": "Paul Rubenstein", "authors": "Paul K. Rubenstein, Olivier Bousquet, Josip Djolonga, Carlos Riquelme,\n  Ilya Tolstikhin", "title": "Practical and Consistent Estimation of f-Divergences", "comments": "Accepted to the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of an f-divergence between two probability distributions based\non samples is a fundamental problem in statistics and machine learning. Most\nworks study this problem under very weak assumptions, in which case it is\nprovably hard. We consider the case of stronger structural assumptions that are\ncommonly satisfied in modern machine learning, including representation\nlearning and generative modelling with autoencoder architectures. Under these\nassumptions we propose and study an estimator that can be easily implemented,\nworks well in high dimensions, and enjoys faster rates of convergence. We\nverify the behavior of our estimator empirically in both synthetic and\nreal-data experiments, and discuss its direct implications for total\ncorrelation, entropy, and mutual information estimation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:36:47 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:10:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Bousquet", "Olivier", ""], ["Djolonga", "Josip", ""], ["Riquelme", "Carlos", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "1905.11128", "submitter": "M. Sadegh Talebi", "authors": "Mohammad Sadegh Talebi and Odalric-Ambrym Maillard", "title": "Learning Multiple Markov Chains via Adaptive Allocation", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning the transition matrices of a set of Markov\nchains from a single stream of observations on each chain. We assume that the\nMarkov chains are ergodic but otherwise unknown. The learner can sample Markov\nchains sequentially to observe their states. The goal of the learner is to\nsequentially select various chains to learn transition matrices uniformly well\nwith respect to some loss function. We introduce a notion of loss that\nnaturally extends the squared loss for learning distributions to the case of\nMarkov chains, and further characterize the notion of being \\emph{uniformly\ngood} in all problem instances. We present a novel learning algorithm that\nefficiently balances \\emph{exploration} and \\emph{exploitation} intrinsic to\nthis problem, without any prior knowledge of the chains. We provide\nfinite-sample PAC-type guarantees on the performance of the algorithm. Further,\nwe show that our algorithm asymptotically attains an optimal loss.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:25:08 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:04:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Talebi", "Mohammad Sadegh", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1905.11133", "submitter": "Ge Fan", "authors": "Ge Fan, Wei Zeng, Shan Sun, Biao Geng, Weiyi Wang, Weibo Liu", "title": "A collaborative filtering model with heterogeneous neural networks for\n  recommender systems", "comments": "Some technical errors, such as the lack of computational complexity\n  analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural network is introduced in recommender systems to\nsolve the collaborative filtering problem, which has achieved immense success\non computer vision, speech recognition and natural language processing. On one\nhand, deep neural network can be used to model the auxiliary information in\nrecommender systems. On the other hand, it is also capable of modeling\nnonlinear relationships between users and items. One advantage of deep neural\nnetwork is that the performance of the algorithm can be easily enhanced by\naugmenting the depth of the neural network. However, two potential problems may\nemerge when the deep neural work is exploited to model relationships between\nusers and items. The fundamental problem is that the complexity of the\nalgorithm grows significantly with the increment in the depth of the neural\nnetwork. The second one is that a deeper neural network may undermine the\naccuracy of the algorithm. In order to alleviate these problems, we propose a\nhybrid neural network that combines heterogeneous neural networks with\ndifferent structures. The experimental results on real datasets reveal that our\nmethod is superior to the state-of-the-art methods in terms of the item\nranking.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:29:52 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 05:12:49 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 02:47:21 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Fan", "Ge", ""], ["Zeng", "Wei", ""], ["Sun", "Shan", ""], ["Geng", "Biao", ""], ["Wang", "Weiyi", ""], ["Liu", "Weibo", ""]]}, {"id": "1905.11136", "submitter": "Heli Ben-Hamu", "authors": "Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, Yaron Lipman", "title": "Provably Powerful Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Weisfeiler-Lehman (WL) graph isomorphism test was used to\nmeasure the expressive power of graph neural networks (GNN). It was shown that\nthe popular message passing GNN cannot distinguish between graphs that are\nindistinguishable by the 1-WL test (Morris et al. 2018; Xu et al. 2019).\nUnfortunately, many simple instances of graphs are indistinguishable by the\n1-WL test.\n  In search for more expressive graph learning models we build upon the recent\nk-order invariant and equivariant graph neural networks (Maron et al. 2019a,b)\nand present two results:\n  First, we show that such k-order networks can distinguish between\nnon-isomorphic graphs as good as the k-WL tests, which are provably stronger\nthan the 1-WL test for k>2. This makes these models strictly stronger than\nmessage passing models. Unfortunately, the higher expressiveness of these\nmodels comes with a computational cost of processing high order tensors.\n  Second, setting our goal at building a provably stronger, simple and scalable\nmodel we show that a reduced 2-order network containing just scaled identity\noperator, augmented with a single quadratic operation (matrix multiplication)\nhas a provable 3-WL expressive power. Differently put, we suggest a simple\nmodel that interleaves applications of standard Multilayer-Perceptron (MLP)\napplied to the feature dimension and matrix multiplication. We validate this\nmodel by presenting state of the art results on popular graph classification\nand regression tasks. To the best of our knowledge, this is the first practical\ninvariant/equivariant model with guaranteed 3-WL expressiveness, strictly\nstronger than message passing models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:33:19 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 05:57:55 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 07:28:10 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 11:28:26 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Maron", "Haggai", ""], ["Ben-Hamu", "Heli", ""], ["Serviansky", "Hadar", ""], ["Lipman", "Yaron", ""]]}, {"id": "1905.11141", "submitter": "Anton Tsitsulin", "authors": "Anton Tsitsulin, Marina Munkhoeva, Davide Mottin, Panagiotis Karras,\n  Alex Bronstein, Ivan Oseledets, Emmanuel M\\\"uller", "title": "The Shape of Data: Intrinsic Distance for Data Distributions", "comments": "Published in ICLR'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to represent and compare machine learning models is crucial in\norder to quantify subtle model changes, evaluate generative models, and gather\ninsights on neural network architectures. Existing techniques for comparing\ndata distributions focus on global data properties such as mean and covariance;\nin that sense, they are extrinsic and uni-scale. We develop a first-of-its-kind\nintrinsic and multi-scale method for characterizing and comparing data\nmanifolds, using a lower-bound of the spectral variant of the\nGromov-Wasserstein inter-manifold distance, which compares all data moments. In\na thorough experimental study, we demonstrate that our method effectively\ndiscerns the structure of data manifolds even on unaligned data of different\ndimensionalities; moreover, we showcase its efficacy in evaluating the quality\nof generative models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:39:56 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 09:30:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tsitsulin", "Anton", ""], ["Munkhoeva", "Marina", ""], ["Mottin", "Davide", ""], ["Karras", "Panagiotis", ""], ["Bronstein", "Alex", ""], ["Oseledets", "Ivan", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "1905.11142", "submitter": "Guanzhong Tian", "authors": "Guanzhong Tian, Yi Yuan, Yong liu", "title": "Audio2Face: Generating Speech/Face Animation from Single Audio with\n  Attention-Based Bidirectional LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end to end deep learning approach for generating real-time\nfacial animation from just audio. Specifically, our deep architecture employs\ndeep bidirectional long short-term memory network and attention mechanism to\ndiscover the latent representations of time-varying contextual information\nwithin the speech and recognize the significance of different information\ncontributed to certain face status. Therefore, our model is able to drive\ndifferent levels of facial movements at inference and automatically keep up\nwith the corresponding pitch and latent speaking style in the input audio, with\nno assumption or further human intervention. Evaluation results show that our\nmethod could not only generate accurate lip movements from audio, but also\nsuccessfully regress the speaker's time-varying facial movements.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:40:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tian", "Guanzhong", ""], ["Yuan", "Yi", ""], ["liu", "Yong", ""]]}, {"id": "1905.11148", "submitter": "Etienne Boursier", "authors": "Etienne Boursier and Vianney Perchet", "title": "Utility/Privacy Trade-off through the lens of Optimal Transport", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic information is valuable either by remaining private (for instance\nif it is sensitive) or, on the other hand, by being used publicly to increase\nsome utility. These two objectives are antagonistic and leaking this\ninformation might be more rewarding than concealing it. Unlike classical\nsolutions that focus on the first point, we consider instead agents that\noptimize a natural trade-off between both objectives. We formalize this as an\noptimization problem where the objective mapping is regularized by the amount\nof information revealed to the adversary (measured as a divergence between the\nprior and posterior on the private knowledge). Quite surprisingly, when\ncombined with the entropic regularization, the Sinkhorn loss naturally emerges\nin the optimization objective, making it efficiently solvable. We apply these\ntechniques to preserve some privacy in online repeated auctions.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:46:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:48:30 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 10:11:54 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "1905.11150", "submitter": "Christian Herta", "authors": "Christian Herta and Benjamin Voigt", "title": "Radial Prediction Layer", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a broad variety of critical applications, it is essential to know how\nconfident a classification prediction is. In this paper, we discuss the\ndrawbacks of softmax to calculate class probabilities and to handle uncertainty\nin Bayesian neural networks. We introduce a new kind of prediction layer called\nradial prediction layer (RPL) to overcome these issues. In contrast to the\nsoftmax classification, RPL is based on the open-world assumption. Therefore,\nthe class prediction probabilities are much more meaningful to assess the\nuncertainty concerning the novelty of the input. We show that neural networks\nwith RPLs can be learned in the same way as neural networks using softmax. On a\n2D toy data set (spiral data), we demonstrate the fundamental principles and\nadvantages. On the real-world ImageNet data set, we show that the open-world\nproperties are beneficially fulfilled. Additionally, we show that RPLs are less\nsensible to adversarial attacks on the MNIST data set. Due to its features, we\nexpect RPL to be beneficial in a broad variety of applications, especially in\ncritical environments, such as medicine or autonomous driving.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:50:25 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:27:46 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Herta", "Christian", ""], ["Voigt", "Benjamin", ""]]}, {"id": "1905.11151", "submitter": "Dong Quan Vu", "authors": "Dong Quan Vu, Patrick Loiseau, Alonso Silva, Long Tran-Thanh", "title": "Path Planning Problems with Side Observations-When Colonels Play\n  Hide-and-Seek", "comments": "Previously, this work appeared as arXiv:1911.09023 which was\n  mistakenly submitted as a new article (has been submitted to be withdrawn).\n  This is a preprint of the work published in Proceedings of the 34th AAAI\n  Conference on Artificial Intelligence (AAAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation games such as the famous Colonel Blotto (CB) and\nHide-and-Seek (HS) games are often used to model a large variety of practical\nproblems, but only in their one-shot versions. Indeed, due to their extremely\nlarge strategy space, it remains an open question how one can efficiently learn\nin these games. In this work, we show that the online CB and HS games can be\ncast as path planning problems with side-observations (SOPPP): at each stage, a\nlearner chooses a path on a directed acyclic graph and suffers the sum of\nlosses that are adversarially assigned to the corresponding edges; and she then\nreceives semi-bandit feedback with side-observations (i.e., she observes the\nlosses on the chosen edges plus some others). We propose a novel algorithm,\nEXP3-OE, the first-of-its-kind with guaranteed efficient running time for SOPPP\nwithout requiring any auxiliary oracle. We provide an expected-regret bound of\nEXP3-OE in SOPPP matching the order of the best benchmark in the literature.\nMoreover, we introduce additional assumptions on the observability model under\nwhich we can further improve the regret bounds of EXP3-OE. We illustrate the\nbenefit of using EXP3-OE in SOPPP by applying it to the online CB and HS games.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:51:23 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 12:29:31 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 21:40:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Vu", "Dong Quan", ""], ["Loiseau", "Patrick", ""], ["Silva", "Alonso", ""], ["Tran-Thanh", "Long", ""]]}, {"id": "1905.11169", "submitter": "Miguel Jaques", "authors": "Miguel Jaques, Michael Burke, Timothy Hospedales", "title": "Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation\n  from Video", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model that is able to perform unsupervised physical parameter\nestimation of systems from video, where the differential equations governing\nthe scene dynamics are known, but labeled states or objects are not available.\nExisting physical scene understanding methods require either object state\nsupervision, or do not integrate with differentiable physics to learn\ninterpretable system parameters and states. We address this problem through a\nphysics-as-inverse-graphics approach that brings together\nvision-as-inverse-graphics and differentiable physics engines, enabling objects\nand explicit state and velocity representations to be discovered. This\nframework allows us to perform long term extrapolative video prediction, as\nwell as vision-based model-predictive control. Our approach significantly\noutperforms related unsupervised methods in long-term future frame prediction\nof systems with interacting objects (such as ball-spring or 3-body\ngravitational systems), due to its ability to build dynamics into the model as\nan inductive bias. We further show the value of this tight vision-physics\nintegration by demonstrating data-efficient learning of vision-actuated\nmodel-based control for a pendulum system. We also show that the controller's\ninterpretability provides unique capabilities in goal-driven control and\nphysical reasoning for zero-data adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:37:14 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 12:14:26 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Jaques", "Miguel", ""], ["Burke", "Michael", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1905.11190", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Gilles Barthe, Borja Balle, Isabel Valera", "title": "Model-Agnostic Counterfactual Explanations for Consequential Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are being increasingly used to support consequential\ndecision making at the individual level in contexts such as pretrial bail and\nloan approval. As a result, there is increasing social and legal pressure to\nprovide explanations that help the affected individuals not only to understand\nwhy a prediction was output, but also how to act to obtain a desired outcome.\nTo this end, several works have proposed optimization-based methods to generate\nnearest counterfactual explanations. However, these methods are often\nrestricted to a particular subset of models (e.g., decision trees or linear\nmodels) and differentiable distance functions. In contrast, we build on\nstandard theory and tools from formal verification and propose a novel\nalgorithm that solves a sequence of satisfiability problems, where both the\ndistance function (objective) and predictive model (constraints) are\nrepresented as logic formulae. As shown by our experiments on real-world data,\nour algorithm is: i) model-agnostic ({non-}linear, {non-}differentiable,\n{non-}convex); ii) data-type-agnostic (heterogeneous features); iii)\ndistance-agnostic ($\\ell_0, \\ell_1, \\ell_\\infty$, and combinations thereof);\niv) able to generate plausible and diverse counterfactuals for any sample\n(i.e., 100% coverage); and v) at provably optimal distances.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:22:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 08:00:19 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 10:21:41 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 16:49:52 GMT"}, {"version": "v5", "created": "Fri, 28 Feb 2020 16:24:45 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Balle", "Borja", ""], ["Valera", "Isabel", ""]]}, {"id": "1905.11213", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Provable robustness against all adversarial $l_p$-perturbations for\n  $p\\geq 1$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years several adversarial attacks and defenses have been proposed.\nOften seemingly robust models turn out to be non-robust when more sophisticated\nattacks are used. One way out of this dilemma are provable robustness\nguarantees. While provably robust models for specific $l_p$-perturbation models\nhave been developed, we show that they do not come with any guarantee against\nother $l_q$-perturbations. We propose a new regularization scheme,\nMMR-Universal, for ReLU networks which enforces robustness wrt $l_1$- and\n$l_\\infty$-perturbations and show how that leads to the first provably robust\nmodels wrt any $l_p$-norm for $p\\geq 1$.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:49:08 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 13:32:07 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1905.11219", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Nils Appenrodt, J\\\"urgen Dickmann, Bernhard Sick", "title": "Automated Ground Truth Estimation of Vulnerable Road Users in Automotive\n  Radar Data Using GNSS", "comments": "5 pages, 5 figures", "journal-ref": "Published in Proceedings of IEEE MTT-S International Conference on\n  Microwaves for Intelligent Mobility (ICMIM), Detroit, MI, USA, April 2019,\n  pp. 5-9, ISBN: 978-1-7281-0775-2", "doi": "10.1109/ICMIM.2019.8726801", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating automotive radar data is a difficult task. This article presents\nan automated way of acquiring data labels which uses a highly accurate and\nportable global navigation satellite system (GNSS). The proposed system is\ndiscussed besides a revision of other label acquisitions techniques and a\nproblem description of manual data annotation. The article concludes with a\nsystematic comparison of conventional hand labeling and automatic data\nacquisition. The results show clear advantages of the proposed method without a\nrelevant loss in labeling accuracy. Minor changes can be observed in the\nmeasured radar data, but the so introduced bias of the GNSS reference is\nclearly outweighed by the indisputable time savings. Beside data annotation,\nthe proposed system can also provide a ground truth for validating object\ntracking or other automated driving system applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:52:16 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Appenrodt", "Nils", ""], ["Dickmann", "J\u00fcrgen", ""], ["Sick", "Bernhard", ""]]}, {"id": "1905.11222", "submitter": "Elita Lobo", "authors": "Elita Lobo, Scott Jordan", "title": "Soft Options Critic", "comments": "In the current version of the paper, there is an error in the\n  definition of the value function, unintended text overlap in the environment\n  description, and incomplete experimentation. These changes will take a\n  significant amount of time to address. Thus, we are withdrawing the paper\n  until these changes can be implemented", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The option-critic architecture (Bacon, Harb, and Precup 2017) and several\nvariants have successfully demonstrated the use of the options framework\nproposed by Sutton et al (Sutton, Precup, and Singh1999) to scale learning and\nplanning in hierarchical tasks. Although most of these frameworks use entropy\nas a regularizer to improve exploration, they do not maximize entropy along\nwith returns at every time step. (Haarnoja et al., 2018d) recently introduced\nan off-policy actor critic algorithm in theSoft Actor Critic paper that\nmaximize returns while maximizing entropy in a constrained manner thus enabling\nlearning of robust options in continuous and discrete action spaces In this\npaper we adopt the architecture of soft-actor critic to investigate the effect\nof maximizing entropy of each options and inter-option policy in options\nframework. We derive the soft options improvement theorem and propose a novel\nsoft-options framework to incorporate maximization of entropy of actions and\noptions in a constrained manner. Our experiments show that the modified\noptions-critic framework generates robust policies which allows fast recovery\nwhen environment is subjected to perturbations and outperforms vanilla\noptions-critic framework in most hierarchical tasks\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:27:11 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 21:48:19 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lobo", "Elita", ""], ["Jordan", "Scott", ""]]}, {"id": "1905.11226", "submitter": "Farhad Shakerin", "authors": "Farhad Shakerin, Gopal Gupta", "title": "Induction of Non-Monotonic Rules From Statistical Learning Models Using\n  High-Utility Itemset Mining", "comments": "arXiv admin note: text overlap with arXiv:1808.00629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast and scalable algorithm to induce non-monotonic logic\nprograms from statistical learning models. We reduce the problem of search for\nbest clauses to instances of the High-Utility Itemset Mining (HUIM) problem. In\nthe HUIM problem, feature values and their importance are treated as\ntransactions and utilities respectively. We make use of TreeExplainer, a fast\nand scalable implementation of the Explainable AI tool SHAP, to extract locally\nimportant features and their weights from ensemble tree models. Our experiments\nwith UCI standard benchmarks suggest a significant improvement in terms of\nclassification evaluation metrics and running time of the training algorithm\ncompared to ALEPH, a state-of-the-art Inductive Logic Programming (ILP) system.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:05:10 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:53:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "1905.11233", "submitter": "Xinshao Wang Dr", "authors": "Xinshao Wang, Elyor Kodirov, Yang Hua, Neil M. Robertson", "title": "Derivative Manipulation for General Example Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world large-scale datasets usually contain noisy labels and are\nimbalanced. Therefore, we propose derivative manipulation (DM), a novel and\ngeneral example weighting approach for training robust deep models under these\nadverse conditions.\n  DM has two main merits. First, loss function and example weighting are common\ntechniques in the literature. DM reveals their connection (a loss function does\nexample weighting) and is a replacement of both. Second, despite that a loss\ndefines an example weighting scheme by its derivative, in the loss design, we\nneed to consider whether it is differentiable. Instead, DM is more flexible by\ndirectly modifying the derivative so that a loss can be a non-elementary format\ntoo. Technically, DM defines an emphasis density function by a derivative\nmagnitude function. DM is generic in that diverse weighting schemes can be\nderived.\n  Extensive experiments on both vision and language tasks prove DM's\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:59:08 GMT"}, {"version": "v10", "created": "Sat, 3 Oct 2020 19:00:18 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 00:19:09 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 10:49:32 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 12:34:17 GMT"}, {"version": "v5", "created": "Fri, 24 Jan 2020 17:41:29 GMT"}, {"version": "v6", "created": "Sat, 8 Feb 2020 11:34:42 GMT"}, {"version": "v7", "created": "Sun, 7 Jun 2020 22:06:46 GMT"}, {"version": "v8", "created": "Mon, 29 Jun 2020 13:55:23 GMT"}, {"version": "v9", "created": "Sat, 4 Jul 2020 14:45:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Xinshao", ""], ["Kodirov", "Elyor", ""], ["Hua", "Yang", ""], ["Robertson", "Neil M.", ""]]}, {"id": "1905.11235", "submitter": "Linhao Dong", "authors": "Linhao Dong, Bo Xu", "title": "CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition", "comments": "To appear at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel soft and monotonic alignment mechanism used\nfor sequence transduction. It is inspired by the integrate-and-fire model in\nspiking neural networks and employed in the encoder-decoder framework consists\nof continuous functions, thus being named as: Continuous Integrate-and-Fire\n(CIF). Applied to the ASR task, CIF not only shows a concise calculation, but\nalso supports online recognition and acoustic boundary positioning, thus\nsuitable for various ASR scenarios. Several support strategies are also\nproposed to alleviate the unique problems of CIF-based model. With the joint\naction of these methods, the CIF-based model shows competitive performance.\nNotably, it achieves a word error rate (WER) of 2.86% on the test-clean of\nLibrispeech and creates new state-of-the-art result on Mandarin telephone ASR\nbenchmark.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:00:45 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 15:33:54 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 04:47:02 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 11:13:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Dong", "Linhao", ""], ["Xu", "Bo", ""]]}, {"id": "1905.11245", "submitter": "Pablo Strasser Mr", "authors": "Pablo Strasser, Stephane Armand, Stephane Marchand-Maillet, Alexandros\n  Kalousis", "title": "Learning by stochastic serializations", "comments": "Submission to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex structures are typical in machine learning. Tailoring learning\nalgorithms for every structure requires an effort that may be saved by defining\na generic learning procedure adaptive to any complex structure. In this paper,\nwe propose to map any complex structure onto a generic form, called\nserialization, over which we can apply any sequence-based density estimator. We\nthen show how to transfer the learned density back onto the space of original\nstructures. To expose the learning procedure to the structural particularities\nof the original structures, we take care that the serializations reflect\naccurately the structures' properties. Enumerating all serializations is\ninfeasible. We propose an effective way to sample representative serializations\nfrom the complete set of serializations which preserves the statistics of the\ncomplete set. Our method is competitive or better than state of the art\nlearning algorithms that have been specifically designed for given structures.\nIn addition, since the serialization involves sampling from a combinatorial\nprocess it provides considerable protection from overfitting, which we clearly\ndemonstrate on a number of experiments.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:09:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Strasser", "Pablo", ""], ["Armand", "Stephane", ""], ["Marchand-Maillet", "Stephane", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1905.11248", "submitter": "Simone Rossi", "authors": "Simone Rossi and Sebastien Marmin and Maurizio Filippone", "title": "Walsh-Hadamard Variational Inference for Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized models, such as DeepNets and ConvNets, form a class of\nmodels that are routinely adopted in a wide variety of applications, and for\nwhich Bayesian inference is desirable but extremely challenging. Variational\ninference offers the tools to tackle this challenge in a scalable way and with\nsome degree of flexibility on the approximation, but for over-parameterized\nmodels this is challenging due to the over-regularization property of the\nvariational objective. Inspired by the literature on kernel methods, and in\nparticular on structured approximations of distributions of random matrices,\nthis paper proposes Walsh-Hadamard Variational Inference (WHVI), which uses\nWalsh-Hadamard-based factorization strategies to reduce the parameterization\nand accelerate computations, thus avoiding over-regularization issues with the\nvariational objective. Extensive theoretical and empirical analyses demonstrate\nthat WHVI yields considerable speedups and model reductions compared to other\ntechniques to carry out approximate inference for over-parameterized models,\nand ultimately show how advances in kernel methods can be translated into\nadvances in approximate Bayesian inference.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:11:06 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 14:16:36 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rossi", "Simone", ""], ["Marmin", "Sebastien", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1905.11255", "submitter": "Ingmar Schuster", "authors": "Ingmar Schuster and Mattes Mollenhauer and Stefan Klus and Krikamol\n  Muandet", "title": "Kernel Conditional Density Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel conditional density estimation model termed the\nconditional density operator (CDO). It naturally captures multivariate,\nmultimodal output densities and shows performance that is competitive with\nrecent neural conditional density models and Gaussian processes. The proposed\nmodel is based on a novel approach to the reconstruction of probability\ndensities from their kernel mean embeddings by drawing connections to\nestimation of Radon-Nikodym derivatives in the reproducing kernel Hilbert space\n(RKHS). We prove finite sample bounds for the estimation error in a standard\ndensity reconstruction scenario, independent of problem dimensionality.\nInterestingly, when a kernel is used that is also a probability density, the\nCDO allows us to both evaluate and sample the output density efficiently. We\ndemonstrate the versatility and performance of the proposed model on both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:16:55 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:39:41 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Schuster", "Ingmar", ""], ["Mollenhauer", "Mattes", ""], ["Klus", "Stefan", ""], ["Muandet", "Krikamol", ""]]}, {"id": "1905.11256", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Nils Appenrodt, J\\\"urgen Dickmann, Bernhard Sick", "title": "Radar-based Feature Design and Multiclass Classification for Road User\n  Recognition", "comments": "8 pages, 6 figures", "journal-ref": "Published in Proceedings of IEEE Intelligent Vehicles Symposium\n  (IV), Changshu, China, June 2018, pp. 779-786, ISBN: 9781538644522", "doi": "10.1109/IVS.2018.8500607", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of individual traffic participants is a complex task,\nespecially for challenging scenarios with multiple road users or under bad\nweather conditions. Radar sensors provide an - with respect to well established\ncamera systems - orthogonal way of measuring such scenes. In order to gain\naccurate classification results, 50 different features are extracted from the\nmeasurement data and tested on their performance. From these features a\nsuitable subset is chosen and passed to random forest and long short-term\nmemory (LSTM) classifiers to obtain class predictions for the radar input.\nMoreover, it is shown why data imbalance is an inherent problem in automotive\nradar classification when the dataset is not sufficiently large. To overcome\nthis issue, classifier binarization is used among other techniques in order to\nbetter account for underrepresented classes. A new method to couple the\nresulting probabilities is proposed and compared to others with great success.\nFinal results show substantial improvements when compared to ordinary\nmulticlass classification\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:17:14 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Appenrodt", "Nils", ""], ["Dickmann", "J\u00fcrgen", ""], ["Sick", "Bernhard", ""]]}, {"id": "1905.11259", "submitter": "Lu Chen", "authors": "Lu Chen, Zhi Chen, Bowen Tan, Sishan Long, Milica Gasic, Kai Yu", "title": "AgentGraph: Towards Universal Dialogue Management with Structured Deep\n  Reinforcement Learning", "comments": "14 pages, 8 figures; Accepted by IEEE/ACM TRANSACTIONS ON AUDIO,\n  SPEECH, AND LANGUAGE PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy plays an important role in task-oriented spoken dialogue\nsystems. It determines how to respond to users. The recently proposed deep\nreinforcement learning (DRL) approaches have been used for policy optimization.\nHowever, these deep models are still challenging for two reasons: 1) Many\nDRL-based policies are not sample-efficient. 2) Most models don't have the\ncapability of policy transfer between different domains. In this paper, we\npropose a universal framework, AgentGraph, to tackle these two problems. The\nproposed AgentGraph is the combination of GNN-based architecture and DRL-based\nalgorithm. It can be regarded as one of the multi-agent reinforcement learning\napproaches. Each agent corresponds to a node in a graph, which is defined\naccording to the dialogue domain ontology. When making a decision, each agent\ncan communicate with its neighbors on the graph. Under AgentGraph framework, we\nfurther propose Dual GNN-based dialogue policy, which implicitly decomposes the\ndecision in each turn into a high-level global decision and a low-level local\ndecision. Experiments show that AgentGraph models significantly outperform\ntraditional reinforcement learning approaches on most of the 18 tasks of the\nPyDial benchmark. Moreover, when transferred from the source task to a target\ntask, these models not only have acceptable initial performance but also\nconverge much faster on the target task.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:27:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chen", "Lu", ""], ["Chen", "Zhi", ""], ["Tan", "Bowen", ""], ["Long", "Sishan", ""], ["Gasic", "Milica", ""], ["Yu", "Kai", ""]]}, {"id": "1905.11260", "submitter": "Ganesh Ghalme", "authors": "Vishakha Patil, Ganesh Ghalme, Vineet Nair, Y. Narahari", "title": "Achieving Fairness in Stochastic Multi-armed Bandit Problem", "comments": "Uploading the latest version with significant improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an interesting variant of the stochastic multi-armed bandit problem,\ncalled the Fair-SMAB problem, where each arm is required to be pulled for at\nleast a given fraction of the total available rounds. We investigate the\ninterplay between learning and fairness in terms of a pre-specified vector\ndenoting the fractions of guaranteed pulls. We define a fairness-aware regret,\ncalled r-Regret, that takes into account the above fairness constraints and\nnaturally extends the conventional notion of regret. Our primary contribution\nis characterizing a class of Fair-SMAB algorithms by two parameters: the\nunfairness tolerance and learning algorithm used as a black-box. We provide a\nfairness guarantee for this class that holds uniformly over time irrespective\nof the choice of the learning algorithm. In particular, when the learning\nalgorithm is UCB1, we show that our algorithm achieves O(log(T)) r-Regret.\nFinally, we evaluate the cost of fairness in terms of the conventional notion\nof regret.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:27:49 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 08:55:42 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 03:42:50 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Patil", "Vishakha", ""], ["Ghalme", "Ganesh", ""], ["Nair", "Vineet", ""], ["Narahari", "Y.", ""]]}, {"id": "1905.11261", "submitter": "Filip Hanzely", "authors": "Eduard Gorbunov, Filip Hanzely, Peter Richt\\'arik", "title": "A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and\n  Coordinate Descent", "comments": "38 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a unified analysis of a large family of variants\nof proximal stochastic gradient descent ({\\tt SGD}) which so far have required\ndifferent intuitions, convergence analyses, have different applications, and\nwhich have been developed separately in various communities. We show that our\nframework includes methods with and without the following tricks, and their\ncombinations: variance reduction, importance sampling, mini-batch sampling,\nquantization, and coordinate sub-sampling. As a by-product, we obtain the first\nunified theory of {\\tt SGD} and randomized coordinate descent ({\\tt RCD})\nmethods, the first unified theory of variance reduced and non-variance-reduced\n{\\tt SGD} methods, and the first unified theory of quantized and non-quantized\nmethods. A key to our approach is a parametric assumption on the iterates and\nstochastic gradients. In a single theorem we establish a linear convergence\nresult under this assumption and strong-quasi convexity of the loss function.\nWhenever we recover an existing method as a special case, our theorem gives the\nbest known complexity result. Our approach can be used to motivate the\ndevelopment of new useful methods, and offers pre-proved convergence\nguarantees. To illustrate the strength of our approach, we develop five new\nvariants of {\\tt SGD}, and through numerical experiments demonstrate some of\ntheir properties.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:28:13 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gorbunov", "Eduard", ""], ["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.11266", "submitter": "Filip Hanzely", "authors": "Filip Hanzely, Peter Richt\\'arik", "title": "One Method to Rule Them All: Variance Reduction for Data, Parameters and\n  Many New Methods", "comments": "61 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a remarkably general variance-reduced method suitable for solving\nregularized empirical risk minimization problems with either a large number of\ntraining examples, or a large model dimension, or both. In special cases, our\nmethod reduces to several known and previously thought to be unrelated methods,\nsuch as {\\tt SAGA}, {\\tt LSVRG}, {\\tt JacSketch}, {\\tt SEGA} and {\\tt ISEGA},\nand their arbitrary sampling and proximal generalizations. However, we also\nhighlight a large number of new specific algorithms with interesting\nproperties. We provide a single theorem establishing linear convergence of the\nmethod under smoothness and quasi strong convexity assumptions. With this\ntheorem we recover best-known and sometimes improved rates for known methods\narising in special cases. As a by-product, we provide the first unified method\nand theory for stochastic gradient and stochastic coordinate descent type\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:31:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 18:26:53 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.11268", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton", "title": "Combating Adversarial Misspellings with Robust Word Recognition", "comments": "ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat adversarial spelling mistakes, we propose placing a word\nrecognition model in front of the downstream classifier. Our word recognition\nmodels build upon the RNN semi-character architecture, introducing several new\nbackoff strategies for handling rare and unseen words. Trained to recognize\nwords corrupted by random adds, drops, swaps, and keyboard mistakes, our method\nachieves 32% relative (and 3.3% absolute) error reduction over the vanilla\nsemi-character model. Notably, our pipeline confers robustness on the\ndownstream classifier, outperforming both adversarial training and\noff-the-shelf spell checkers. Against a BERT model fine-tuned for sentiment\nanalysis, a single adversarially-chosen character attack lowers accuracy from\n90.3% to 45.8%. Our defense restores accuracy to 75%. Surprisingly, better word\nrecognition does not always entail greater robustness. Our analysis reveals\nthat robustness also depends upon a quantity that we denote the sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:35:35 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 15:20:17 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1905.11286", "submitter": "Boris Ginsburg", "authors": "Boris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii\n  Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, Yang Zhang,\n  Jonathan M. Cohen", "title": "Stochastic Gradient Methods with Layer-wise Adaptive Moments for\n  Training of Deep Networks", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NovoGrad, an adaptive stochastic gradient descent method with\nlayer-wise gradient normalization and decoupled weight decay. In our\nexperiments on neural networks for image classification, speech recognition,\nmachine translation, and language modeling, it performs on par or better than\nwell tuned SGD with momentum and Adam or AdamW. Additionally, NovoGrad (1) is\nrobust to the choice of learning rate and weight initialization, (2) works well\nin a large batch setting, and (3) has two times smaller memory footprint than\nAdam.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 15:12:50 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 22:19:35 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 21:40:02 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ginsburg", "Boris", ""], ["Castonguay", "Patrice", ""], ["Hrinchuk", "Oleksii", ""], ["Kuchaiev", "Oleksii", ""], ["Lavrukhin", "Vitaly", ""], ["Leary", "Ryan", ""], ["Li", "Jason", ""], ["Nguyen", "Huyen", ""], ["Zhang", "Yang", ""], ["Cohen", "Jonathan M.", ""]]}, {"id": "1905.11299", "submitter": "Yuzhe Yang", "authors": "Yuzhe Yang, Zhiwen Hu, Kaigui Bian, Lingyang Song", "title": "ImgSensingNet: UAV Vision Guided Aerial-Ground Air Quality Sensing\n  System", "comments": "Preliminary version published in INFOCOM 2019. Code available at\n  https://github.com/YyzHarry/ImgSensingNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasingly serious air pollution problem, the monitoring of air\nquality index (AQI) in urban areas has drawn considerable attention. This paper\npresents ImgSensingNet, a vision guided aerial-ground sensing system, for\nfine-grained air quality monitoring and forecasting using the fusion of haze\nimages taken by the unmanned-aerial-vehicle (UAV) and the AQI data collected by\nan on-ground three-dimensional (3D) wireless sensor network (WSN).\nSpecifically, ImgSensingNet first leverages the computer vision technique to\ntell the AQI scale in different regions from the taken haze images, where\nhaze-relevant features and a deep convolutional neural network (CNN) are\ndesigned for direct learning between haze images and corresponding AQI scale.\nBased on the learnt AQI scale, ImgSensingNet determines whether to wake up\non-ground wireless sensors for small-scale AQI monitoring and inference, which\ncan greatly reduce the energy consumption of the system. An entropy-based model\nis employed for accurate real-time AQI inference at unmeasured locations and\nfuture air quality distribution forecasting. We implement and evaluate\nImgSensingNet on two university campuses since Feb. 2018, and has collected\n17,630 photos and 2.6 millions of AQI data samples. Experimental results\nconfirm that ImgSensingNet can achieve higher inference accuracy while greatly\nreduce the energy consumption, compared to state-of-the-art AQI monitoring\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 15:32:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yang", "Yuzhe", ""], ["Hu", "Zhiwen", ""], ["Bian", "Kaigui", ""], ["Song", "Lingyang", ""]]}, {"id": "1905.11311", "submitter": "Alon Gonen", "authors": "Alon Gonen, Elad Hazan, Shay Moran", "title": "Private Learning Implies Online Learning: An Efficient Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between the notions of differentially private\nlearning and online learning in games. Several recent works have shown that\ndifferentially private learning implies online learning, but an open problem of\nNeel, Roth, and Wu \\cite{NeelAaronRoth2018} asks whether this implication is\n{\\it efficient}. Specifically, does an efficient differentially private learner\nimply an efficient online learner? In this paper we resolve this open question\nin the context of pure differential privacy. We derive an efficient black-box\nreduction from differentially private learning to online learning from expert\nadvice.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 15:53:01 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:53:37 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 11:05:37 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 09:51:38 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gonen", "Alon", ""], ["Hazan", "Elad", ""], ["Moran", "Shay", ""]]}, {"id": "1905.11313", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza, Daniel Krefl, Andrea Papaluca", "title": "Modelling conditional probabilities with Riemann-Theta Boltzmann\n  Machines", "comments": "7 pages, 3 figures, in proceedings of the 19th International Workshop\n  on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2019)", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012005", "report-no": "TIF-UNIMI-2019-6", "categories": "stat.ML cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability density function for the visible sector of a Riemann-Theta\nBoltzmann machine can be taken conditional on a subset of the visible units. We\nderive that the corresponding conditional density function is given by a\nreparameterization of the Riemann-Theta Boltzmann machine modelling the\noriginal probability density function. Therefore the conditional densities can\nbe directly inferred from the Riemann-Theta Boltzmann machine.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 15:58:44 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Carrazza", "Stefano", ""], ["Krefl", "Daniel", ""], ["Papaluca", "Andrea", ""]]}, {"id": "1905.11320", "submitter": "Natalie Schluter", "authors": "Natalie Schluter", "title": "On approximating dropout noise injection", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the assumptions of the derived equivalence between\ndropout noise injection and $L_2$ regularisation for logistic regression with\nnegative log loss. We show that the approximation method is based on a\ndivergent Taylor expansion, making, subsequent work using this approximation to\ncompare the dropout trained logistic regression model with standard\nregularisers unfortunately ill-founded to date. Moreover, the approximation\napproach is shown to be invalid using any robust constraints. We show how this\nfinding extends to general neural network topologies that use a cross-entropy\nprediction layer.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 16:11:42 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 21:04:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Schluter", "Natalie", ""]]}, {"id": "1905.11327", "submitter": "K S Sesh Kumar", "authors": "K S Sesh Kumar, Francis Bach and Thomas Pock", "title": "Fast Decomposable Submodular Function Minimization using Constrained\n  Total Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing the sum of submodular set functions\nassuming minimization oracles of each summand function. Most existing\napproaches reformulate the problem as the convex minimization of the sum of the\ncorresponding Lov\\'asz extensions and the squared Euclidean norm, leading to\nalgorithms requiring total variation oracles of the summand functions; without\nfurther assumptions, these more complex oracles require many calls to the\nsimpler minimization oracles often available in practice. In this paper, we\nconsider a modified convex problem requiring constrained version of the total\nvariation oracles that can be solved with significantly fewer calls to the\nsimple minimization oracles. We support our claims by showing results on graph\ncuts for 2D and 3D graphs\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 16:24:54 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kumar", "K S Sesh", ""], ["Bach", "Francis", ""], ["Pock", "Thomas", ""]]}, {"id": "1905.11333", "submitter": "Shenda Hong", "authors": "Shenda Hong, Cao Xiao, Tengfei Ma, Hongyan Li, Jimeng Sun", "title": "MINA: Multilevel Knowledge-Guided Attention for Modeling\n  Electrocardiography Signals", "comments": "Published in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Electrocardiography (ECG) signals are commonly used to diagnose various\ncardiac abnormalities. Recently, deep learning models showed initial success on\nmodeling ECG data, however they are mostly black-box, thus lack\ninterpretability needed for clinical usage. In this work, we propose MultIlevel\nkNowledge-guided Attention networks (MINA) that predict heart diseases from ECG\nsignals with intuitive explanation aligned with medical knowledge. By\nextracting multilevel (beat-, rhythm- and frequency-level) domain knowledge\nfeatures separately, MINA combines the medical knowledge and ECG data via a\nmultilevel attention model, making the learned models highly interpretable. Our\nexperiments showed MINA achieved PR-AUC 0.9436 (outperforming the best baseline\nby 5.51%) in real world ECG dataset. Finally, MINA also demonstrated robust\nperformance and strong interpretability against signal distortion and noise\ncontamination.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 16:39:17 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 02:57:50 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 14:48:01 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hong", "Shenda", ""], ["Xiao", "Cao", ""], ["Ma", "Tengfei", ""], ["Li", "Hongyan", ""], ["Sun", "Jimeng", ""]]}, {"id": "1905.11340", "submitter": "Kimon Fountoulakis", "authors": "S. Das, J. Demmel, K. Fountoulakis, L. Grigori, M. W. Mahoney, S. Yang", "title": "Parallel and Communication Avoiding Least Angle Regression", "comments": "21 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in parallelizing the Least Angle Regression (LARS)\nalgorithm for fitting linear regression models to high-dimensional data. We\nconsider two parallel and communication avoiding versions of the basic LARS\nalgorithm. The two algorithms have different asymptotic costs and practical\nperformance. One offers more speedup and the other produces more accurate\noutput. The first is bLARS, a block version of LARS algorithm, where we update\nb columns at each iteration. Assuming that the data are row-partitioned, bLARS\nreduces the number of arithmetic operations, latency, and bandwidth by a factor\nof b. The second is Tournament-bLARS (T-bLARS), a tournament version of LARS\nwhere processors compete by running several LARS computations in parallel to\nchoose b new columns to be added in the solution. Assuming that the data are\ncolumn-partitioned, T-bLARS reduces latency by a factor of b. Similarly to\nLARS, our proposed methods generate a sequence of linear models. We present\nextensive numerical experiments that illustrate speedups up to 4x compared to\nLARS without any compromise in solution quality.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:00:16 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 07:19:06 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 22:00:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Das", "S.", ""], ["Demmel", "J.", ""], ["Fountoulakis", "K.", ""], ["Grigori", "L.", ""], ["Mahoney", "M. W.", ""], ["Yang", "S.", ""]]}, {"id": "1905.11345", "submitter": "Barak Sober", "authors": "Nadav Dym, Barak Sober, Ingrid Daubechies", "title": "Expression of Fractals Through Neural Network Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help understand the underlying mechanisms of neural networks (NNs),\nseveral groups have, in recent years, studied the number of linear regions\n$\\ell$ of piecewise linear functions generated by deep neural networks (DNN).\nIn particular, they showed that $\\ell$ can grow exponentially with the number\nof network parameters $p$, a property often used to explain the advantages of\nDNNs over shallow NNs in approximating complicated functions. Nonetheless, a\nsimple dimension argument shows that DNNs cannot generate all piecewise linear\nfunctions with $\\ell$ linear regions as soon as $\\ell > p$. It is thus natural\nto seek to characterize specific families of functions with $\\ell$ linear\nregions that can be constructed by DNNs. Iterated Function Systems (IFS)\ngenerate sequences of piecewise linear functions $F_k$ with a number of linear\nregions exponential in $k$. We show that, under mild assumptions, $F_k$ can be\ngenerated by a NN using only $\\mathcal{O}(k)$ parameters. IFS are used\nextensively to generate, at low computational cost, natural-looking landscape\ntextures in artificial images. They have also been proposed for compression of\nnatural images, albeit with less commercial success. The surprisingly good\nperformance of this fractal-based compression suggests that our visual system\nmay lock in, to some extent, on self-similarities in images. The combination of\nthis phenomenon with the capacity, demonstrated here, of DNNs to efficiently\napproximate IFS may contribute to the success of DNNs, particularly striking\nfor image processing tasks, as well as suggest new algorithms for representing\nself similarities in images based on the DNN mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:06:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dym", "Nadav", ""], ["Sober", "Barak", ""], ["Daubechies", "Ingrid", ""]]}, {"id": "1905.11358", "submitter": "Saumya Jetley", "authors": "Laurynas Miksys, Saumya Jetley, Michael Sapienza, Stuart Golodetz,\n  Philip H.S. Torr", "title": "Straight to Shapes++: Real-time Instance Segmentation Made More Accurate", "comments": "Technical report, 27 pages (12 main, 15 supplementary), 17 figures,\n  14 tables", "journal-ref": null, "doi": null, "report-no": "STS-2018", "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance segmentation is an important problem in computer vision, with\napplications in autonomous driving, drone navigation and robotic manipulation.\nHowever, most existing methods are not real-time, complicating their deployment\nin time-sensitive contexts. In this work, we extend an existing approach to\nreal-time instance segmentation, called `Straight to Shapes' (STS), which makes\nuse of low-dimensional shape embedding spaces to directly regress to object\nshape masks. The STS model can run at 35 FPS on a high-end desktop, but its\naccuracy is significantly worse than that of offline state-of-the-art methods.\nWe leverage recent advances in the design and training of deep instance\nsegmentation models to improve the performance accuracy of the STS model whilst\nkeeping its real-time capabilities intact. In particular, we find that\nparameter sharing, more aggressive data augmentation and the use of structured\nloss for shape mask prediction all provide a useful boost to the network\nperformance. Our proposed approach, `Straight to Shapes++', achieves a\nremarkable 19.7 point improvement in mAP (at IOU of 0.5) over the original\nmethod as evaluated on the PASCAL VOC dataset, thus redefining the accuracy\nfrontier at real-time speeds. Since the accuracy of instance segmentation is\nclosely tied to that of object bounding box prediction, we also study the error\nprofile of the latter and examine the failure modes of our method for future\nimprovements.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:35:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 11:09:15 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Miksys", "Laurynas", ""], ["Jetley", "Saumya", ""], ["Sapienza", "Michael", ""], ["Golodetz", "Stuart", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1905.11359", "submitter": "Samantha Piatt", "authors": "Samantha Piatt", "title": "Large-Scale Statistical Survey of Magnetopause Reconnection", "comments": "21 pages with appendix. Stan code for model included with url for\n  additional data processing scripts in R", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Magnetospheric Multiscale Mission (MMS) seeks to study the micro-physics\nof reconnection, which occurs at the magnetopause boundary layer between the\nmagnetosphere of Earth and the interplanetary magnetic field originating from\nthe sun. Identifying this region of space automatically will allow for\nstatistical analysis of reconnection events. The magnetopause region is\ndifficult to identify automatically using simple models, and time consuming for\nscientists to classify by hand. We introduced a hierarchical Bayesian mixture\nmodel with linear and auto regressive components to identify the magnetopause.\nUsing data from the MMS mission with the programming languages R and Stan, we\nmodeled and predicted possible regions and evaluated our performance against a\nboosted regression tree model. Our model selects twice as many magnetopause\nregions as the comparison model, without significant over selection, achieving\na 31\\% true positive rate and 93\\% true negative rate. Our method will allow\nscientists to study the micro-physics of reconnection events in the\nmagnetopause using the large body of MMS data without manual classification.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:33:28 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Piatt", "Samantha", ""]]}, {"id": "1905.11361", "submitter": "Lee Cohen", "authors": "Lee Cohen, Zachary C. Lipton, Yishay Mansour", "title": "Efficient candidate screening under multiple tests and implications for\n  fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When recruiting job candidates, employers rarely observe their underlying\nskill level directly. Instead, they must administer a series of interviews\nand/or collate other noisy signals in order to estimate the worker's skill.\nTraditional economics papers address screening models where employers access\nworker skill via a single noisy signal. In this paper, we extend this\ntheoretical analysis to a multi-test setting, considering both Bernoulli and\nGaussian models. We analyze the optimal employer policy both when the employer\nsets a fixed number of tests per candidate and when the employer can set a\ndynamic policy, assigning further tests adaptively based on results from the\nprevious tests. To start, we characterize the optimal policy when employees\nconstitute a single group, demonstrating some interesting trade-offs.\nSubsequently, we address the multi-group setting, demonstrating that when the\nnoise levels vary across groups, a fundamental impossibility emerges whereby we\ncannot administer the same number of tests, subject candidates to the same\ndecision rule, and yet realize the same outcomes in both groups.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:45:50 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cohen", "Lee", ""], ["Lipton", "Zachary C.", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.11368", "submitter": "Wei Hu", "authors": "Wei Hu, Zhiyuan Li, Dingli Yu", "title": "Simple and Effective Regularization Methods for Training on Noisily\n  Labeled Data with Generalization Guarantee", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks trained by simple first-order methods\nare known to be able to fit any labeling of data. Such over-fitting ability\nhinders generalization when mislabeled training examples are present. On the\nother hand, simple regularization methods like early-stopping can often achieve\nhighly nontrivial performance on clean test data in these scenarios, a\nphenomenon not theoretically understood. This paper proposes and analyzes two\nsimple and intuitive regularization methods: (i) regularization by the distance\nbetween the network parameters to initialization, and (ii) adding a trainable\nauxiliary variable to the network output for each training example.\nTheoretically, we prove that gradient descent training with either of these two\nmethods leads to a generalization guarantee on the clean data distribution\ndespite being trained using noisy labels. Our generalization analysis relies on\nthe connection between wide neural network and neural tangent kernel (NTK). The\ngeneralization bound is independent of the network size, and is comparable to\nthe bound one can get when there is no label noise. Experimental results verify\nthe effectiveness of these methods on noisily labeled datasets.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:52:28 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:43:33 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 03:30:12 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 20:43:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hu", "Wei", ""], ["Li", "Zhiyuan", ""], ["Yu", "Dingli", ""]]}, {"id": "1905.11369", "submitter": "Relja Arandjelovi\\'c", "authors": "Relja Arandjelovi\\'c, Andrew Zisserman", "title": "Object Discovery with a Copy-Pasting GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of object discovery, where objects are segmented for a\ngiven input image, and the system is trained without using any direct\nsupervision whatsoever. A novel copy-pasting GAN framework is proposed, where\nthe generator learns to discover an object in one image by compositing it into\nanother image such that the discriminator cannot tell that the resulting image\nis fake. After carefully addressing subtle issues, such as preventing the\ngenerator from `cheating', this game results in the generator learning to\nselect objects, as copy-pasting objects is most likely to fool the\ndiscriminator. The system is shown to work well on four very different\ndatasets, including large object appearance variations in challenging cluttered\nbackgrounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:55:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Arandjelovi\u0107", "Relja", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1905.11373", "submitter": "Konstantin Mishchenko", "authors": "Konstantin Mishchenko, Dmitry Kovalev, Egor Shulgin, Peter\n  Richt\\'arik, Yura Malitsky", "title": "Revisiting Stochastic Extragradient", "comments": "Accepted to AISTATS 2020. 16 pages, 9 figures, 2 algorithms", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, PMLR 108:4573-4582, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We fix a fundamental issue in the stochastic extragradient method by\nproviding a new sampling strategy that is motivated by approximating implicit\nupdates. Since the existing stochastic extragradient algorithm, called\nMirror-Prox, of (Juditsky et al., 2011) diverges on a simple bilinear problem\nwhen the domain is not bounded, we prove guarantees for solving variational\ninequality that go beyond existing settings. Furthermore, we illustrate\nnumerically that the proposed variant converges faster than many other methods\non bilinear saddle-point problems. We also discuss how extragradient can be\napplied to training Generative Adversarial Networks (GANs) and how it compares\nto other methods. Our experiments on GANs demonstrate that the introduced\napproach may make the training faster in terms of data passes, while its higher\niteration complexity makes the advantage smaller.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:55:59 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 19:15:37 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Mishchenko", "Konstantin", ""], ["Kovalev", "Dmitry", ""], ["Shulgin", "Egor", ""], ["Richt\u00e1rik", "Peter", ""], ["Malitsky", "Yura", ""]]}, {"id": "1905.11374", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Bryant Chen, Suchi Saria", "title": "A Universal Hierarchy of Shift-Stable Distributions and the Tradeoff\n  Between Stability and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods which find invariant predictive distributions have been\ndeveloped to learn models that can generalize to new environments without using\nsamples from the target distribution. However, these methods consider differing\ntypes of shifts in environment and have been developed under disparate\nframeworks, making their comparison difficult. In this paper, we provide a\nunifying graphical representation of the data generating process that can\nrepresent all such shifts. We show there is a universal hierarchy of\nshift-stable distributions which correspond to operators on a graph that\ndisable edges. This provides the ability to compare current methods and derive\nnew algorithms that find optimal invariant distributions, all of which can be\nmapped to the hierarchy. We theoretically and empirically show that the degree\nto which stability is desirable depends on how concerned we are about large\nshifts: there is a tradeoff between stability and average performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:56:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 17:12:44 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 23:28:40 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Chen", "Bryant", ""], ["Saria", "Suchi", ""]]}, {"id": "1905.11381", "submitter": "Jirong Yi", "authors": "Jirong Yi, Hui Xie, Leixin Zhou, Xiaodong Wu, Weiyu Xu, Raghuraman\n  Mudumbai", "title": "Trust but Verify: An Information-Theoretic Explanation for the\n  Adversarial Fragility of Machine Learning Systems, and a General Defense\n  against Adversarial Attacks", "comments": "44 Pages, 2 Theorems, 35 Figures, 29 Tables. arXiv admin note:\n  substantial text overlap with arXiv:1901.09413", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning based classification algorithms have been shown to be\nsusceptible to adversarial attacks: minor changes to the input of classifiers\ncan dramatically change their outputs, while being imperceptible to humans. In\nthis paper, we present a simple hypothesis about a feature compression property\nof artificial intelligence (AI) classifiers and present theoretical arguments\nto show that this hypothesis successfully accounts for the observed fragility\nof AI classifiers to small adversarial perturbations. Drawing on ideas from\ninformation and coding theory, we propose a general class of defenses for\ndetecting classifier errors caused by abnormally small input perturbations. We\nfurther show theoretical guarantees for the performance of this detection\nmethod. We present experimental results with (a) a voice recognition system,\nand (b) a digit recognition system using the MNIST database, to demonstrate the\neffectiveness of the proposed defense methods. The ideas in this paper are\nmotivated by a simple analogy between AI classifiers and the standard Shannon\nmodel of a communication system.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:57:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yi", "Jirong", ""], ["Xie", "Hui", ""], ["Zhou", "Leixin", ""], ["Wu", "Xiaodong", ""], ["Xu", "Weiyu", ""], ["Mudumbai", "Raghuraman", ""]]}, {"id": "1905.11382", "submitter": "Alex Lamb", "authors": "Alex Lamb, Jonathan Binas, Anirudh Goyal, Sandeep Subramanian, Ioannis\n  Mitliagkas, Denis Kazakov, Yoshua Bengio, Michael C. Mozer", "title": "State-Reification Networks: Improving Generalization by Modeling the\n  Distribution of Hidden Representations", "comments": "ICML 2019 [full oral]. arXiv admin note: text overlap with\n  arXiv:1805.08394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning promises methods that generalize well from finite labeled\ndata. However, the brittleness of existing neural net approaches is revealed by\nnotable failures, such as the existence of adversarial examples that are\nmisclassified despite being nearly identical to a training example, or the\ninability of recurrent sequence-processing nets to stay on track without\nteacher forcing. We introduce a method, which we refer to as \\emph{state\nreification}, that involves modeling the distribution of hidden states over the\ntraining data and then projecting hidden states observed during testing toward\nthis distribution. Our intuition is that if the network can remain in a\nfamiliar manifold of hidden space, subsequent layers of the net should be well\ntrained to respond appropriately. We show that this state-reification method\nhelps neural nets to generalize better, especially when labeled data are\nsparse, and also helps overcome the challenge of achieving robust\ngeneralization with adversarial training.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 09:13:41 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Lamb", "Alex", ""], ["Binas", "Jonathan", ""], ["Goyal", "Anirudh", ""], ["Subramanian", "Sandeep", ""], ["Mitliagkas", "Ioannis", ""], ["Kazakov", "Denis", ""], ["Bengio", "Yoshua", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1905.11391", "submitter": "Diana Sousa", "authors": "Diana Sousa, Andre Lamurias, Francisco M. Couto", "title": "Using Neural Networks for Relation Extraction from Biomedical Literature", "comments": "Artificial Neural Networks book (Springer) - Chapter 14", "journal-ref": "Artificial Neural Networks. Methods in Molecular Biology, vol\n  2190. Humana, New York, NY. 2020. pp. 289-305", "doi": "10.1007/978-1-0716-0826-5_14", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using different sources of information to support automated extracting of\nrelations between biomedical concepts contributes to the development of our\nunderstanding of biological systems. The primary comprehensive source of these\nrelations is biomedical literature. Several relation extraction approaches have\nbeen proposed to identify relations between concepts in biomedical literature,\nnamely, using neural networks algorithms. The use of multichannel architectures\ncomposed of multiple data representations, as in deep neural networks, is\nleading to state-of-the-art results. The right combination of data\nrepresentations can eventually lead us to even higher evaluation scores in\nrelation extraction tasks. Thus, biomedical ontologies play a fundamental role\nby providing semantic and ancestry information about an entity. The\nincorporation of biomedical ontologies has already been proved to enhance\nprevious state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:33:29 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 13:40:39 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Sousa", "Diana", ""], ["Lamurias", "Andre", ""], ["Couto", "Francisco M.", ""]]}, {"id": "1905.11395", "submitter": "Xu Geng", "authors": "Xu Geng, Xiyu Wu, Lingyu Zhang, Qiang Yang, Yan Liu, Jieping Ye", "title": "Multi-Modal Graph Interaction for Multi-Graph Convolution Network in\n  Urban Spatiotemporal Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution network based approaches have been recently used to model\nregion-wise relationships in region-level prediction problems in urban\ncomputing. Each relationship represents a kind of spatial dependency, like\nregion-wise distance or functional similarity. To incorporate multiple\nrelationships into spatial feature extraction, we define the problem as a\nmulti-modal machine learning problem on multi-graph convolution networks.\nLeveraging the advantage of multi-modal machine learning, we propose to develop\nmodality interaction mechanisms for this problem, in order to reduce\ngeneralization error by reinforcing the learning of multimodal coordinated\nrepresentations. In this work, we propose two interaction techniques for\nhandling features in lower layers and higher layers respectively. In lower\nlayers, we propose grouped GCN to combine the graph connectivity from different\nmodalities for more complete spatial feature extraction. In higher layers, we\nadapt multi-linear relationship networks to GCN by exploring the dimension\ntransformation and freezing part of the covariance structure. The adapted\napproach, called multi-linear relationship GCN, learns more generalized\nfeatures to overcome the train-test divergence induced by time shifting. We\nevaluated our model on ridehailing demand forecasting problem using two\nreal-world datasets. The proposed technique outperforms state-of-the art\nbaselines in terms of prediction accuracy, training efficiency,\ninterpretability and model robustness.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:30:26 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Geng", "Xu", ""], ["Wu", "Xiyu", ""], ["Zhang", "Lingyu", ""], ["Yang", "Qiang", ""], ["Liu", "Yan", ""], ["Ye", "Jieping", ""]]}, {"id": "1905.11425", "submitter": "Zaiwei Chen", "authors": "Zaiwei Chen, Sheng Zhang, Thinh T. Doan, John-Paul Clarke, Siva Theja\n  Maguluri", "title": "Finite-Sample Analysis of Nonlinear Stochastic Approximation with\n  Applications in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by applications in reinforcement learning (RL), we study a\nnonlinear stochastic approximation (SA) algorithm under Markovian noise, and\nestablish its finite-sample convergence bounds under various stepsizes.\nSpecifically, we show that when using constant stepsize (i.e.,\n$\\epsilon_k\\equiv \\epsilon$), the algorithm achieves exponential fast\nconvergence with asymptotic accuracy $\\mathcal{O}(\\epsilon\\log(1/\\epsilon))$.\nWhen using diminishing stepsizes with appropriate decay rate, the algorithm\nconverges with rate $\\mathcal{O}(\\log(k)/k)$. Our proof is based on the\nLyapunov drift arguments, and to handle the Markovian noise, we exploit the\nfast mixing of the underlying Markov chain. To demonstrate the generality of\nour theoretical results on Markovian SA, we use it to derive the finite-sample\nbounds of the popular $Q$-learning with linear function approximation\nalgorithm, under a condition on the behavior policy. Importantly, we do not\nneed to make the unrealistic assumption that the samples are i.i.d., and do not\nrequire an additional projection step in the algorithm to maintain the\nboundedness of the iterates. Numerical simulations corroborate our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:01:59 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 16:19:34 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 21:57:09 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 03:22:59 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2020 00:56:28 GMT"}, {"version": "v6", "created": "Fri, 9 Jul 2021 01:36:18 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chen", "Zaiwei", ""], ["Zhang", "Sheng", ""], ["Doan", "Thinh T.", ""], ["Clarke", "John-Paul", ""], ["Maguluri", "Siva Theja", ""]]}, {"id": "1905.11427", "submitter": "Lu Lu", "authors": "Pengzhan Jin, Lu Lu, Yifa Tang, George Em Karniadakis", "title": "Quantifying the generalization error in deep learning in terms of data\n  distribution and neural network smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The accuracy of deep learning, i.e., deep neural networks, can be\ncharacterized by dividing the total error into three main types: approximation\nerror, optimization error, and generalization error. Whereas there are some\nsatisfactory answers to the problems of approximation and optimization, much\nless is known about the theory of generalization. Most existing theoretical\nworks for generalization fail to explain the performance of neural networks in\npractice. To derive a meaningful bound, we study the generalization error of\nneural networks for classification problems in terms of data distribution and\nneural network smoothness. We introduce the cover complexity (CC) to measure\nthe difficulty of learning a data set and the inverse of the modulus of\ncontinuity to quantify neural network smoothness. A quantitative bound for\nexpected accuracy/error is derived by considering both the CC and neural\nnetwork smoothness. Although most of the analysis is general and not specific\nto neural networks, we validate our theoretical assumptions and results\nnumerically for neural networks by several data sets of images. The numerical\nresults confirm that the expected error of trained networks scaled with the\nsquare root of the number of classes has a linear relationship with respect to\nthe CC. We also observe a clear consistency between test loss and neural\nnetwork smoothness during the training process. In addition, we demonstrate\nempirically that the neural network smoothness decreases when the network size\nincreases whereas the smoothness is insensitive to training dataset size.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:05:00 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 20:25:59 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 02:05:12 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Jin", "Pengzhan", ""], ["Lu", "Lu", ""], ["Tang", "Yifa", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1905.11428", "submitter": "Abhinav Kumar", "authors": "Abhinav Kumar, Thiago Serra and Srikumar Ramalingam", "title": "Equivalent and Approximate Transformations of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two networks are equivalent if they produce the same output for any given\ninput. In this paper, we study the possibility of transforming a deep neural\nnetwork to another network with a different number of units or layers, which\ncan be either equivalent, a local exact approximation, or a global linear\napproximation of the original network. On the practical side, we show that\ncertain rectified linear units (ReLUs) can be safely removed from a network if\nthey are always active or inactive for any valid input. If we only need an\nequivalent network for a smaller domain, then more units can be removed and\nsome layers collapsed. On the theoretical side, we constructively show that for\nany feed-forward ReLU network, there exists a global linear approximation to a\n2-hidden-layer shallow network with a fixed number of units. This result is a\nbalance between the increasing number of units for arbitrary approximation with\na single layer and the known upper bound of $\\lceil log(n_0+1)\\rceil +1$ layers\nfor exact representation, where $n_0$ is the input dimension. While the\ntransformed network may require an exponential number of units to capture the\nactivation patterns of the original network, we show that it can be made\nsubstantially smaller by only accounting for the patterns that define linear\nregions. Based on experiments with ReLU networks on the MNIST dataset, we found\nthat $l_1$-regularization and adversarial training reduces the number of linear\nregions significantly as the number of stable units increases due to weight\nsparsity. Therefore, we can also intentionally train ReLU networks to allow for\neffective loss-less compression and approximation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:05:28 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kumar", "Abhinav", ""], ["Serra", "Thiago", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "1905.11437", "submitter": "Leonardo Enzo Brito da Silva", "authors": "Leonardo Enzo Brito da Silva, Islam Elnabarawy, Donald C. Wunsch II", "title": "A Survey of Adaptive Resonance Theory Neural Network Models for\n  Engineering Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey samples from the ever-growing family of adaptive resonance theory\n(ART) neural network models used to perform the three primary machine learning\nmodalities, namely, unsupervised, supervised and reinforcement learning. It\ncomprises a representative list from classic to modern ART models, thereby\npainting a general picture of the architectures developed by researchers over\nthe past 30 years. The learning dynamics of these ART models are briefly\ndescribed, and their distinctive characteristics such as code representation,\nlong-term memory and corresponding geometric interpretation are discussed.\nUseful engineering properties of ART (speed, configurability, explainability,\nparallelization and hardware implementation) are examined along with current\nchallenges. Finally, a compilation of online software libraries is provided. It\nis expected that this overview will be helpful to new and seasoned ART\nresearchers.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 00:54:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Elnabarawy", "Islam", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "1905.11445", "submitter": "Ke Wang", "authors": "Ke Wang, Mihai Christodorescu", "title": "COSET: A Benchmark for Evaluating Neural Program Embeddings", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural program embedding can be helpful in analyzing large software, a task\nthat is challenging for traditional logic-based program analyses due to their\nlimited scalability. A key focus of recent machine-learning advances in this\narea is on modeling program semantics instead of just syntax. Unfortunately\nevaluating such advances is not obvious, as program semantics does not lend\nitself to straightforward metrics. In this paper, we introduce a benchmarking\nframework called COSET for standardizing the evaluation of neural program\nembeddings. COSET consists of a diverse dataset of programs in source-code\nformat, labeled by human experts according to a number of program properties of\ninterest. A point of novelty is a suite of program transformations included in\nCOSET. These transformations when applied to the base dataset can simulate\nnatural changes to program code due to optimization and refactoring and can\nserve as a \"debugging\" tool for classification mistakes. We conducted a pilot\nstudy on four prominent models: TreeLSTM, gated graph neural network (GGNN),\nAST-Path neural network (APNN), and DYPRO. We found that COSET is useful in\nidentifying the strengths and limitations of each model and in pinpointing\nspecific syntactic and semantic characteristics of programs that pose\nchallenges.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:44:54 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Wang", "Ke", ""], ["Christodorescu", "Mihai", ""]]}, {"id": "1905.11449", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Berrak Sisman, Mingyang Zhang, Sakriani Sakti, Haizhou\n  Li, Satoshi Nakamura", "title": "VQVAE Unsupervised Unit Discovery and Multi-scale Code2Spec Inverter for\n  Zerospeech Challenge 2019", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our submitted system for the ZeroSpeech Challenge 2019. The\ncurrent challenge theme addresses the difficulty of constructing a speech\nsynthesizer without any text or phonetic labels and requires a system that can\n(1) discover subword units in an unsupervised way, and (2) synthesize the\nspeech with a target speaker's voice. Moreover, the system should also balance\nthe discrimination score ABX, the bit-rate compression rate, and the\nnaturalness and the intelligibility of the constructed voice. To tackle these\nproblems and achieve the best trade-off, we utilize a vector quantized\nvariational autoencoder (VQ-VAE) and a multi-scale codebook-to-spectrogram\n(Code2Spec) inverter trained by mean square error and adversarial loss. The\nVQ-VAE extracts the speech to a latent space, forces itself to map it into the\nnearest codebook and produces compressed representation. Next, the inverter\ngenerates a magnitude spectrogram to the target voice, given the codebook\nvectors from VQ-VAE. In our experiments, we also investigated several other\nclustering algorithms, including K-Means and GMM, and compared them with the\nVQ-VAE result on ABX scores and bit rates. Our proposed approach significantly\nimproved the intelligibility (in CER), the MOS, and discrimination ABX scores\ncompared to the official ZeroSpeech 2019 baseline or even the topline.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 18:59:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 10:50:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tjandra", "Andros", ""], ["Sisman", "Berrak", ""], ["Zhang", "Mingyang", ""], ["Sakti", "Sakriani", ""], ["Li", "Haizhou", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1905.11452", "submitter": "Stefan Uhlich", "authors": "Stefan Uhlich, Lukas Mauch, Fabien Cardinaux, Kazuki Yoshiyama, Javier\n  Alonso Garcia, Stephen Tiedemann, Thomas Kemp, Akira Nakamura", "title": "Mixed Precision DNNs: All you need is a good parametrization", "comments": "International Conference on Learning Representations (ICLR) 2020;\n  Source code at https://github.com/sony/ai-research-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient deep neural network (DNN) inference on mobile or embedded devices\ntypically involves quantization of the network parameters and activations. In\nparticular, mixed precision networks achieve better performance than networks\nwith homogeneous bitwidth for the same size constraint. Since choosing the\noptimal bitwidths is not straight forward, training methods, which can learn\nthem, are desirable. Differentiable quantization with straight-through\ngradients allows to learn the quantizer's parameters using gradient methods. We\nshow that a suited parametrization of the quantizer is the key to achieve a\nstable training and a good final performance. Specifically, we propose to\nparametrize the quantizer with the step size and dynamic range. The bitwidth\ncan then be inferred from them. Other parametrizations, which explicitly use\nthe bitwidth, consistently perform worse. We confirm our findings with\nexperiments on CIFAR-10 and ImageNet and we obtain mixed precision DNNs with\nlearned quantization parameters, achieving state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:03:40 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 19:24:34 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 17:02:41 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Uhlich", "Stefan", ""], ["Mauch", "Lukas", ""], ["Cardinaux", "Fabien", ""], ["Yoshiyama", "Kazuki", ""], ["Garcia", "Javier Alonso", ""], ["Tiedemann", "Stephen", ""], ["Kemp", "Thomas", ""], ["Nakamura", "Akira", ""]]}, {"id": "1905.11455", "submitter": "Fabio De Sousa Ribeiro", "authors": "Fabio De Sousa Ribeiro, Georgios Leontidis, Stefanos Kollias", "title": "Capsule Routing via Variational Bayes", "comments": "AAAI 2020 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks are a recently proposed type of neural network shown to\noutperform alternatives in challenging shape recognition tasks. In capsule\nnetworks, scalar neurons are replaced with capsule vectors or matrices, whose\nentries represent different properties of objects. The relationships between\nobjects and their parts are learned via trainable viewpoint-invariant\ntransformation matrices, and the presence of a given object is decided by the\nlevel of agreement among votes from its parts. This interaction occurs between\ncapsule layers and is a process called routing-by-agreement. In this paper, we\npropose a new capsule routing algorithm derived from Variational Bayes for\nfitting a mixture of transforming gaussians, and show it is possible transform\nour capsule network into a Capsule-VAE. Our Bayesian approach addresses some of\nthe inherent weaknesses of MLE based models such as the variance-collapse by\nmodelling uncertainty over capsule pose parameters. We outperform the\nstate-of-the-art on smallNORB using 50% fewer capsules than previously\nreported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN,\nand demonstrate significant improvement in MNIST to affNIST generalisation over\nprevious works.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:08:42 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:21:06 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 16:49:01 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ribeiro", "Fabio De Sousa", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1905.11460", "submitter": "Marjan Albooyeh", "authors": "Marjan Albooyeh, Daniele Bertolini, Siamak Ravanbakhsh", "title": "Incidence Networks for Geometric Deep Learning", "comments": "Last revised August 10, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse incidence tensors can represent a variety of structured data. For\nexample, we may represent attributed graphs using their node-node, node-edge,\nor edge-edge incidence matrices. In higher dimensions, incidence tensors can\nrepresent simplicial complexes and polytopes. In this paper, we formalize\nincidence tensors, analyze their structure, and present the family of\nequivariant networks that operate on them. We show that any incidence tensor\ndecomposes into invariant subsets. This decomposition, in turn, leads to a\ndecomposition of the corresponding equivariant linear maps, for which we prove\nan efficient pooling-and-broadcasting implementation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:16:52 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 16:36:05 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 16:19:30 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 01:18:12 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Albooyeh", "Marjan", ""], ["Bertolini", "Daniele", ""], ["Ravanbakhsh", "Siamak", ""]]}, {"id": "1905.11462", "submitter": "Hamidreza Arian", "authors": "Mohammadreza Ghanbari and Hamidreza Arian", "title": "Forecasting Stock Market with Support Vector Regression and Butterfly\n  Optimization Algorithm", "comments": "Preprint submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Regression (SVR) has achieved high performance on forecasting\nfuture behavior of random systems. However, the performance of SVR models\nhighly depends upon the appropriate choice of SVR parameters. In this study, a\nnovel BOA-SVR model based on Butterfly Optimization Algorithm (BOA) is\npresented. The performance of the proposed model is compared with eleven other\nmeta-heuristic algorithms on a number of stocks from NASDAQ. The results\nindicate that the presented model here is capable to optimize the SVR\nparameters very well and indeed is one of the best models judged by both\nprediction performance accuracy and time consumption.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:20:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ghanbari", "Mohammadreza", ""], ["Arian", "Hamidreza", ""]]}, {"id": "1905.11468", "submitter": "Chris Finlay", "authors": "Chris Finlay and Adam M Oberman", "title": "Scaleable input gradient regularization for adversarial robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we revisit gradient regularization for adversarial robustness\nwith some new ingredients. First, we derive new per-image theoretical\nrobustness bounds based on local gradient information. These bounds strongly\nmotivate input gradient regularization. Second, we implement a scaleable\nversion of input gradient regularization which avoids double backpropagation:\nadversarially robust ImageNet models are trained in 33 hours on four consumer\ngrade GPUs. Finally, we show experimentally and through theoretical\ncertification that input gradient regularization is competitive with\nadversarial training. Moreover we demonstrate that gradient regularization does\nnot lead to gradient obfuscation or gradient masking.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:40:52 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 14:12:34 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "1905.11471", "submitter": "Jasdeep Singh", "authors": "Jasdeep Singh, Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,\n  Richard Socher", "title": "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural language processing systems often focus on a single language,\nmultilingual transfer learning has the potential to improve performance,\nespecially for low-resource languages. We introduce XLDA, cross-lingual data\naugmentation, a method that replaces a segment of the input text with its\ntranslation in another language. XLDA enhances performance of all 14 tested\nlanguages of the cross-lingual natural language inference (XNLI) benchmark.\nWith improvements of up to $4.8\\%$, training with XLDA achieves\nstate-of-the-art performance for Greek, Turkish, and Urdu. XLDA is in contrast\nto, and performs markedly better than, a more naive approach that aggregates\nexamples in various languages in a way that each example is solely in one\nlanguage. On the SQuAD question answering task, we see that XLDA provides a\n$1.0\\%$ performance increase on the English evaluation set. Comprehensive\nexperiments suggest that most languages are effective as cross-lingual\naugmentors, that XLDA is robust to a wide range of translation quality, and\nthat XLDA is even more effective for randomly initialized models than for\npretrained models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:44:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Singh", "Jasdeep", ""], ["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1905.11474", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sid Bundy, and Sheikh Khaled\n  Ghafoor", "title": "Infusing domain knowledge in AI-based \"black box\" models for better\n  explainability with application in bankruptcy prediction", "comments": "Under review in KDD, 2019 : 2nd KDD Workshop on Anomaly Detection in\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although \"black box\" models such as Artificial Neural Networks, Support\nVector Machines, and Ensemble Approaches continue to show superior performance\nin many disciplines, their adoption in the sensitive disciplines (e.g.,\nfinance, healthcare) is questionable due to the lack of interpretability and\nexplainability of the model. In fact, future adoption of \"black box\" models is\ndifficult because of the recent rule of \"right of explanation\" by the European\nUnion where a user can ask for an explanation behind an algorithmic decision,\nand the newly proposed bill by the US government, the \"Algorithmic\nAccountability Act\", which would require companies to assess their machine\nlearning systems for bias and discrimination and take corrective measures. Top\nBankruptcy Prediction Models are A.I.-based and are in need of better\nexplainability -the extent to which the internal working mechanisms of an AI\nsystem can be explained in human terms. Although explainable artificial\nintelligence is an emerging field of research, infusing domain knowledge for\nbetter explainability might be a possible solution. In this work, we\ndemonstrate a way to collect and infuse domain knowledge into a \"black box\"\nmodel for bankruptcy prediction. Our understanding from the experiments reveals\nthat infused domain knowledge makes the output from the black box model more\ninterpretable and explainable.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:49:11 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:19:22 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Bundy", "Sid", ""], ["Ghafoor", "Sheikh Khaled", ""]]}, {"id": "1905.11475", "submitter": "Xuwang Yin", "authors": "Xuwang Yin, Soheil Kolouri, Gustavo K. Rohde", "title": "Adversarial Example Detection and Classification With Asymmetrical\n  Adversarial Training", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerabilities of deep neural networks against adversarial examples have\nbecome a significant concern for deploying these models in sensitive domains.\nDevising a definitive defense against such attacks is proven to be challenging,\nand the methods relying on detecting adversarial samples are only valid when\nthe attacker is oblivious to the detection mechanism. In this paper we first\npresent an adversarial example detection method that provides performance\nguarantee to norm constrained adversaries. The method is based on the idea of\ntraining adversarial robust subspace detectors using asymmetrical adversarial\ntraining (AAT). The novel AAT objective presents a minimax problem similar to\nthat of GANs; it has the same convergence property, and consequently supports\nthe learning of class conditional distributions. We first demonstrate that the\nminimax problem could be reasonably solved by PGD attack, and then use the\nlearned class conditional generative models to define generative\ndetection/classification models that are both robust and more interpretable. We\nprovide comprehensive evaluations of the above methods, and demonstrate their\ncompetitive performances and compelling properties on adversarial detection and\nrobust classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:51:13 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 03:07:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yin", "Xuwang", ""], ["Kolouri", "Soheil", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1905.11478", "submitter": "Vivek Srikumar", "authors": "Annie Cherkaev, Waiming Tai, Jeff Phillips, Vivek Srikumar", "title": "Learning In Practice: Reasoning About Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a mismatch between the standard theoretical analyses of statistical\nmachine learning and how learning is used in practice. The foundational\nassumption supporting the theory is that we can represent features and models\nusing real-valued parameters. In practice, however, we do not use real numbers\nat any point during training or deployment. Instead, we rely on discrete and\nfinite quantizations of the reals, typically floating points. In this paper, we\npropose a framework for reasoning about learning under arbitrary quantizations.\nUsing this formalization, we prove the convergence of quantization-aware\nversions of the Perceptron and Frank-Wolfe algorithms. Finally, we report the\nresults of an extensive empirical study of the impact of quantization using a\nbroad spectrum of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:59:14 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Cherkaev", "Annie", ""], ["Tai", "Waiming", ""], ["Phillips", "Jeff", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1905.11481", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu (MIT), Max Tegmark (MIT)", "title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression", "comments": "15 pages, 2 figs. Our code is available at\n  https://github.com/SJ001/AI-Feynman and our Feynman Symbolic Regression\n  Database for benchmarking can be downloaded at\n  https://space.mit.edu/home/tegmark/aifeynman.html", "journal-ref": "Science Advances, 6:eaay2631, April 15, 2020", "doi": null, "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge for both physics and artificial intellicence (AI) is\nsymbolic regression: finding a symbolic expression that matches data from an\nunknown function. Although this problem is likely to be NP-hard in principle,\nfunctions of practical interest often exhibit symmetries, separability,\ncompositionality and other simplifying properties. In this spirit, we develop a\nrecursive multidimensional symbolic regression algorithm that combines neural\nnetwork fitting with a suite of physics-inspired techniques. We apply it to 100\nequations from the Feynman Lectures on Physics, and it discovers all of them,\nwhile previous publicly available software cracks only 71; for a more difficult\ntest set, we improve the state of the art success rate from 15% to 90%.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:03:57 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 16:39:27 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Udrescu", "Silviu-Marian", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "1905.11485", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, Ivan Kobyzev, Akshay\n  Sethi, Peter Forsyth, Pascal Poupart", "title": "Representation Learning for Dynamic Graphs: A Survey", "comments": "Accepted at JMLR, 73 pages, 2 figures", "journal-ref": "JMLR, Vol 21, Pages 1-73, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphs arise naturally in many real-world applications including social\nnetworks, recommender systems, ontologies, biology, and computational finance.\nTraditionally, machine learning models for graphs have been mostly designed for\nstatic graphs. However, many applications involve evolving graphs. This\nintroduces important challenges for learning and inference since nodes,\nattributes, and edges change over time. In this survey, we review the recent\nadvances in representation learning for dynamic graphs, including dynamic\nknowledge graphs. We describe existing models from an encoder-decoder\nperspective, categorize these encoders and decoders based on the techniques\nthey employ, and analyze the approaches in each category. We also review\nseveral prominent applications and widely used datasets and highlight\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:23:02 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 13:23:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Goel", "Rishab", ""], ["Jain", "Kshitij", ""], ["Kobyzev", "Ivan", ""], ["Sethi", "Akshay", ""], ["Forsyth", "Peter", ""], ["Poupart", "Pascal", ""]]}, {"id": "1905.11488", "submitter": "Adam Elmachtoub", "authors": "Othman El Balghiti, Adam N. Elmachtoub, Paul Grigas, Ambuj Tewari", "title": "Generalization Bounds in the Predict-then-Optimize Framework", "comments": "Preliminary version in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predict-then-optimize framework is fundamental in many practical\nsettings: predict the unknown parameters of an optimization problem, and then\nsolve the problem using the predicted values of the parameters. A natural loss\nfunction in this environment is to consider the cost of the decisions induced\nby the predicted parameters, in contrast to the prediction error of the\nparameters. This loss function was recently introduced in Elmachtoub and Grigas\n(2017) and referred to as the Smart Predict-then-Optimize (SPO) loss. In this\nwork, we seek to provide bounds on how well the performance of a prediction\nmodel fit on training data generalizes out-of-sample, in the context of the SPO\nloss. Since the SPO loss is non-convex and non-Lipschitz, standard results for\nderiving generalization bounds do not apply.\n  We first derive bounds based on the Natarajan dimension that, in the case of\na polyhedral feasible region, scale at most logarithmically in the number of\nextreme points, but, in the case of a general convex feasible region, have\nlinear dependence on the decision dimension. By exploiting the structure of the\nSPO loss function and a key property of the feasible region, which we denote as\nthe strength property, we can dramatically improve the dependence on the\ndecision and feature dimensions. Our approach and analysis rely on placing a\nmargin around problematic predictions that do not yield unique optimal\nsolutions, and then providing generalization bounds in the context of a\nmodified margin SPO loss function that is Lipschitz continuous. Finally, we\ncharacterize the strength property and show that the modified SPO loss can be\ncomputed efficiently for both strongly convex bodies and polytopes with an\nexplicit extreme point representation.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:29:20 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 21:16:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Balghiti", "Othman El", ""], ["Elmachtoub", "Adam N.", ""], ["Grigas", "Paul", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1905.11498", "submitter": "Chu Wang", "authors": "Chu Wang, Babak Samari, Vladimir Kim, Siddhartha Chaudhuri, Kaleem\n  Siddiqi", "title": "FAN: Focused Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks show promise for both vision and language tasks, by\nemphasizing relationships between constituent elements through weighting\nfunctions. Such elements could be regions in an image output by a region\nproposal network, or words in a sentence, represented by word embedding. Thus\nfar the learning of attention weights has been driven solely by the\nminimization of task specific loss functions. We introduce a method for\nlearning attention weights to better emphasize informative pair-wise relations\nbetween entities. The key component is a novel center-mass cross entropy loss,\nwhich can be applied in conjunction with the task specific ones. We further\nintroduce a focused attention backbone to learn these attention weights for\ngeneral tasks. We demonstrate that the focused supervision leads to improved\nattention distribution across meaningful entities, and that it enhances the\nrepresentation by aggregating features from them. Our focused attention module\nleads to state-of-the-art recovery of relations in a relationship proposal task\nand boosts performance for various vision and language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:41:53 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 16:31:24 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 19:55:42 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wang", "Chu", ""], ["Samari", "Babak", ""], ["Kim", "Vladimir", ""], ["Chaudhuri", "Siddhartha", ""], ["Siddiqi", "Kaleem", ""]]}, {"id": "1905.11503", "submitter": "Hosnieh Sattar", "authors": "Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz", "title": "Body Shape Privacy in Images: Understanding Privacy and Preventing\n  Automatic Shape Extraction", "comments": null, "journal-ref": "Proc. of the IEEE European Conference on Computer Vision Workshops\n  (ECCVW), CV-COPS@ECCV2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern approaches to pose and body shape estimation have recently achieved\nstrong performance even under challenging real-world conditions. Even from a\nsingle image of a clothed person, a realistic looking body shape can be\ninferred that captures a users' weight group and body shape type well. This\nopens up a whole spectrum of applications -- in particular in fashion -- where\nvirtual try-on and recommendation systems can make use of these new and\nautomatized cues. However, a realistic depiction of the undressed body is\nregarded highly private and therefore might not be consented by most people.\nHence, we ask if the automatic extraction of such information can be\neffectively evaded. While adversarial perturbations have been shown to be\neffective for manipulating the output of machine learning models -- in\nparticular, end-to-end deep learning approaches -- state of the art shape\nestimation methods are composed of multiple stages. We perform the first\ninvestigation of different strategies that can be used to effectively\nmanipulate the automatic shape estimation while preserving the overall\nappearance of the original image.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:57:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:11:55 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:15:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Sattar", "Hosnieh", ""], ["Krombholz", "Katharina", ""], ["Pons-Moll", "Gerard", ""], ["Fritz", "Mario", ""]]}, {"id": "1905.11506", "submitter": "Umberto No\\`e", "authors": "Umberto No\\`e, Bernd Taschler, Joachim T\\\"ager, Peter Heutink, Sach\n  Mukherjee", "title": "Ancestral causal learning in high dimensions with a human genome-wide\n  application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning ancestral causal relationships in high dimensions. Our\napproach is driven by a supervised learning perspective, with discrete\nindicators of causal relationships treated as labels to be learned from\navailable data. We focus on the setting in which some causal (ancestral)\nrelationships are known (via background knowledge or experimental data) and put\nforward a general approach that scales to large problems. This is motivated by\nproblems in human biology which are characterized by high dimensionality and\npotentially many latent variables. We present a case study involving\ninterventional data from human cells with total dimension $p \\! \\sim \\!\n19{,}000$. Performance is assessed empirically by testing model output against\npreviously unseen interventional data. The proposed approach is highly\neffective and demonstrably scalable to the human genome-wide setting. We\nconsider sensitivity to background knowledge and find that results are robust\nto nontrivial perturbations of the input information. We consider also the\ncase, relevant to some applications, where the only prior information available\nconcerns a small number of known ancestral relationships.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:08:35 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["No\u00e8", "Umberto", ""], ["Taschler", "Bernd", ""], ["T\u00e4ger", "Joachim", ""], ["Heutink", "Peter", ""], ["Mukherjee", "Sach", ""]]}, {"id": "1905.11515", "submitter": "Alex Gain", "authors": "Alex Gain, Hava Siegelmann", "title": "Abstraction Mechanisms Predict Generalization in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding problem for Deep Neural Networks (DNNs) is understanding their\npuzzling ability to generalize well. We approach this problem through the\nunconventional angle of \\textit{cognitive abstraction mechanisms}, drawing\ninspiration from recent neuroscience work, allowing us to define the Cognitive\nNeural Activation metric (CNA) for DNNs, which is the correlation between\ninformation complexity (entropy) of given input and the concentration of higher\nactivation values in deeper layers of the network. The CNA is highly predictive\nof generalization ability, outperforming norm-and-margin-based generalization\nmetrics on an extensive evaluation of over 100 dataset-and-network-architecture\ncombinations, especially in cases where additive noise is present and/or\ntraining labels are corrupted. These strong empirical results show the\nusefulness of CNA as a generalization metric, and encourage further research on\nthe connection between information complexity and representations in the deeper\nlayers of networks in order to better understand the generalization\ncapabilities of DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:34:34 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 02:59:25 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Gain", "Alex", ""], ["Siegelmann", "Hava", ""]]}, {"id": "1905.11518", "submitter": "Peng Yu", "authors": "Dora Jambor, Peng Yu", "title": "On a scalable problem transformation method for multi-label learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary relevance is a simple approach to solve multi-label learning problems\nwhere an independent binary classifier is built per each label. A common\nchallenge with this in real-world applications is that the label space can be\nvery large, making it difficult to use binary relevance to larger scale\nproblems. In this paper, we propose a scalable alternative to this, via\ntransforming the multi-label problem into a single binary classification. We\nexperiment with a few variations of our method and show that our method\nachieves higher precision than binary relevance and faster execution times on a\ntop-K recommender system task.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:40:37 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Jambor", "Dora", ""], ["Yu", "Peng", ""]]}, {"id": "1905.11520", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov, Ivan Oseledets", "title": "Universality Theorems for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that generative models are extremely successful in practice,\nthe theory underlying this phenomenon is only starting to catch up with\npractice. In this work we address the question of the universality of\ngenerative models: is it true that neural networks can approximate any data\nmanifold arbitrarily well? We provide a positive answer to this question and\nshow that under mild assumptions on the activation function one can always find\na feedforward neural network that maps the latent space onto a set located\nwithin the specified Hausdorff distance from the desired data manifold. We also\nprove similar theorems for the case of multiclass generative models and cycle\ngenerative models, trained to map samples from one manifold to another and vice\nversa.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:44:50 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 23:58:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1905.11527", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Nadav Merlis, Mohammad Ghavamzadeh, Shie Mannor", "title": "Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy\n  Policies", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art efficient model-based Reinforcement Learning (RL) algorithms\ntypically act by iteratively solving empirical models, i.e., by performing\n\\emph{full-planning} on Markov Decision Processes (MDPs) built by the gathered\nexperience. In this paper, we focus on model-based RL in the finite-state\nfinite-horizon MDP setting and establish that exploring with \\emph{greedy\npolicies} -- act by \\emph{1-step planning} -- can achieve tight minimax\nperformance in terms of regret, $\\tilde{\\mathcal{O}}(\\sqrt{HSAT})$. Thus,\nfull-planning in model-based RL can be avoided altogether without any\nperformance degradation, and, by doing so, the computational complexity\ndecreases by a factor of $S$. The results are based on a novel analysis of\nreal-time dynamic programming, then extended to model-based RL. Specifically,\nwe generalize existing algorithms that perform full-planning to such that act\nby 1-step planning. For these generalizations, we prove regret bounds with the\nsame rate as their full-planning counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:22:49 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:04:58 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Efroni", "Yonathan", ""], ["Merlis", "Nadav", ""], ["Ghavamzadeh", "Mohammad", ""], ["Mannor", "Shie", ""]]}, {"id": "1905.11528", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Risto Miikkulainen", "title": "Improved Training Speed, Accuracy, and Data Utilization Through Loss\n  Function Optimization", "comments": null, "journal-ref": "Proceedings of the 2020 IEEE Congress on Evolutionary Computation", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of neural network models has grown, it has become\nincreasingly important to optimize their design automatically through\nmetalearning. Methods for discovering hyperparameters, topologies, and learning\nrate schedules have lead to significant increases in performance. This paper\nshows that loss functions can be optimized with metalearning as well, and\nresult in similar improvements. The method, Genetic Loss-function Optimization\n(GLO), discovers loss functions de novo, and optimizes them for a target task.\nLeveraging techniques from genetic programming, GLO builds loss functions\nhierarchically from a set of operators and leaf nodes. These functions are\nrepeatedly recombined and mutated to find an optimal structure, and then a\ncovariance-matrix adaptation evolutionary strategy (CMA-ES) is used to find\noptimal coefficients. Networks trained with GLO loss functions are found to\noutperform the standard cross-entropy loss on standard image classification\ntasks. Training with these new loss functions requires fewer steps, results in\nlower test error, and allows for smaller datasets to be used. Loss-function\noptimization thus provides a new dimension of metalearning, and constitutes an\nimportant step towards AutoML.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:24:21 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:24:16 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 16:31:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1905.11530", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Zheng Li, Yufei Ma, Yu Cao", "title": "Efficient Network Construction through Structural Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) on hardware is facing excessive computation cost\ndue to the massive number of parameters. A typical training pipeline to\nmitigate over-parameterization is to pre-define a DNN structure first with\nredundant learning units (filters and neurons) under the goal of high accuracy,\nthen to prune redundant learning units after training with the purpose of\nefficient inference. We argue that it is sub-optimal to introduce redundancy\ninto training for the purpose of reducing redundancy later in inference.\nMoreover, the fixed network structure further results in poor adaption to\ndynamic tasks, such as lifelong learning. In contrast, structural plasticity\nplays an indispensable role in mammalian brains to achieve compact and accurate\nlearning. Throughout the lifetime, active connections are continuously created\nwhile those no longer important are degenerated. Inspired by such observation,\nwe propose a training scheme, namely Continuous Growth and Pruning (CGaP),\nwhere we start the training from a small network seed, then literally execute\ncontinuous growth by adding important learning units and finally prune\nsecondary ones for efficient inference. The inference model generated from CGaP\nis sparse in the structure, largely decreasing the inference power and latency\nwhen deployed on hardware platforms. With popular DNN structures on\nrepresentative datasets, the efficacy of CGaP is benchmarked by both algorithm\nsimulation and architectural modeling on Field-programmable Gate Arrays (FPGA).\nFor example, CGaP decreases the FLOPs, model size, DRAM access energy and\ninference latency by 63.3%, 64.0%, 11.8% and 40.2%, respectively, for\nResNet-110 on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:39:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:07:05 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 19:03:37 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Du", "Xiaocong", ""], ["Li", "Zheng", ""], ["Ma", "Yufei", ""], ["Cao", "Yu", ""]]}, {"id": "1905.11531", "submitter": "Amir Ziai", "authors": "Amir Ziai", "title": "Compositional pre-training for neural semantic parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the process of translating natural language utterances\ninto logical forms, which has many important applications such as question\nanswering and instruction following. Sequence-to-sequence models have been very\nsuccessful across many NLP tasks. However, a lack of task-specific prior\nknowledge can be detrimental to the performance of these models. Prior work has\nused frameworks for inducing grammars over the training examples, which capture\nconditional independence properties that the model can leverage. Inspired by\nthe recent success stories such as BERT we set out to extend this augmentation\nframework into two stages. The first stage is to pre-train using a corpus of\naugmented examples in an unsupervised manner. The second stage is to fine-tune\nto a domain-specific task. In addition, since the pre-training stage is\nseparate from the training on the main task we also expand the universe of\npossible augmentations without causing catastrophic inference. We also propose\na novel data augmentation strategy that interchanges tokens that co-occur in\nsimilar contexts to produce new training pairs. We demonstrate that the\nproposed two-stage framework is beneficial for improving the parsing accuracy\nin a standard dataset called GeoQuery for the task of generating logical forms\nfrom a set of questions about the US geography.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:51:39 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ziai", "Amir", ""]]}, {"id": "1905.11532", "submitter": "Vardaan Pahuja", "authors": "Vardaan Pahuja, Jie Fu, Sarath Chandar, Christopher J. Pal", "title": "Structure Learning for Neural Module Networks", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-6401", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Module Networks, originally proposed for the task of visual question\nanswering, are a class of neural network architectures that involve\nhuman-specified neural modules, each designed for a specific form of reasoning.\nIn current formulations of such networks only the parameters of the neural\nmodules and/or the order of their execution is learned. In this work, we\nfurther expand this approach and also learn the underlying internal structure\nof modules in terms of the ordering and combination of simple and elementary\narithmetic operators. Our results show that one is indeed able to\nsimultaneously learn both internal module structure and module sequencing\nwithout extra supervisory signals for module execution sequencing. With this\napproach, we report performance comparable to models using hand-designed\nmodules.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:53:29 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Pahuja", "Vardaan", ""], ["Fu", "Jie", ""], ["Chandar", "Sarath", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1905.11533", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Zheng Li, Yu Cao", "title": "CGaP: Continuous Growth and Pruning for Efficient Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today a canonical approach to reduce the computation cost of Deep Neural\nNetworks (DNNs) is to pre-define an over-parameterized model before training to\nguarantee the learning capacity, and then prune unimportant learning units\n(filters and neurons) during training to improve model compactness. We argue it\nis unnecessary to introduce redundancy at the beginning of the training but\nthen reduce redundancy for the ultimate inference model. In this paper, we\npropose a Continuous Growth and Pruning (CGaP) scheme to minimize the\nredundancy from the beginning. CGaP starts the training from a small network\nseed, then expands the model continuously by reinforcing important learning\nunits, and finally prunes the network to obtain a compact and accurate model.\nAs the growth phase favors important learning units, CGaP provides a clear\nlearning purpose to the pruning phase. Experimental results on representative\ndatasets and DNN architectures demonstrate that CGaP outperforms previous\npruning-only approaches that deal with pre-defined structures. For VGG-19 on\nCIFAR-100 and SVHN datasets, CGaP reduces the number of parameters by 78.9% and\n85.8%, FLOPs by 53.2% and 74.2%, respectively; For ResNet-110 On CIFAR-10, CGaP\nreduces 64.0% number of parameters and 63.3% FLOPs.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:54:59 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:07:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Du", "Xiaocong", ""], ["Li", "Zheng", ""], ["Cao", "Yu", ""]]}, {"id": "1905.11536", "submitter": "Robert Porter", "authors": "Robert Porter", "title": "OrderNet: Ordering by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new neural architecture for sorting unordered\nsequences where the correct sequence order is not easily defined but must\nrather be inferred from training data. We refer to this architecture as\nOrderNet and describe how it was constructed to be naturally permutation\nequivariant while still allowing for rich interactions of elements of the input\nset. We evaluate the capabilities of our architecture by training it to\napproximate solutions for the Traveling Salesman Problem and find that it\noutperforms previously studied supervised techniques in its ability to\ngeneralize to longer sequences than it was trained with. We further demonstrate\nthe capability by reconstructing the order of sentences with scrambled word\norder.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:09:35 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Porter", "Robert", ""]]}, {"id": "1905.11544", "submitter": "Naveed Akhtar Dr.", "authors": "Naveed Akhtar, Mohammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal\n  Mian", "title": "Label Universal Targeted Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Label Universal Targeted Attack (LUTA) that makes a deep model\npredict a label of attacker's choice for `any' sample of a given source class\nwith high probability. Our attack stochastically maximizes the log-probability\nof the target label for the source class with first order gradient\noptimization, while accounting for the gradient moments. It also suppresses the\nleakage of attack information to the non-source classes for avoiding the attack\nsuspicions. The perturbations resulting from our attack achieve high fooling\nratios on the large-scale ImageNet and VGGFace models, and transfer well to the\nPhysical World. Given full control over the perturbation scope in LUTA, we also\ndemonstrate it as a tool for deep model autopsy. The proposed attack reveals\ninteresting perturbation patterns and observations regarding the deep models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:53:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 05:11:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Akhtar", "Naveed", ""], ["Jalwana", "Mohammad A. A. K.", ""], ["Bennamoun", "Mohammed", ""], ["Mian", "Ajmal", ""]]}, {"id": "1905.11545", "submitter": "Ali Siahkamari", "authors": "Ali Siahkamari, Xide Xia, Venkatesh Saligrama, David Castanon, Brian\n  Kulis", "title": "Learning to Approximate a Bregman Divergence", "comments": "19 pages, 4 figures", "journal-ref": "Proceedings of the 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bregman divergences generalize measures such as the squared Euclidean\ndistance and the KL divergence, and arise throughout many areas of machine\nlearning. In this paper, we focus on the problem of approximating an arbitrary\nBregman divergence from supervision, and we provide a well-principled approach\nto analyzing such approximations. We develop a formulation and algorithm for\nlearning arbitrary Bregman divergences based on approximating their underlying\nconvex generating function via a piecewise linear function. We provide\ntheoretical approximation bounds using our parameterization and show that the\ngeneralization error $O_p(m^{-1/2})$ for metric learning using our framework\nmatches the known generalization error in the strictly less general Mahalanobis\nmetric learning setting. We further demonstrate empirically that our method\nperforms well in comparison to existing metric learning methods, particularly\nfor clustering and ranking problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:01:00 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:10:50 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 16:26:13 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 02:24:12 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Siahkamari", "Ali", ""], ["Xia", "Xide", ""], ["Saligrama", "Venkatesh", ""], ["Castanon", "David", ""], ["Kulis", "Brian", ""]]}, {"id": "1905.11546", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski and Michael W. Mahoney", "title": "Distributed estimation of the inverse Hessian by determinantal averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed optimization and distributed numerical linear algebra, we\noften encounter an inversion bias: if we want to compute a quantity that\ndepends on the inverse of a sum of distributed matrices, then the sum of the\ninverses does not equal the inverse of the sum. An example of this occurs in\ndistributed Newton's method, where we wish to compute (or implicitly work with)\nthe inverse Hessian multiplied by the gradient. In this case, locally computed\nestimates are biased, and so taking a uniform average will not recover the\ncorrect solution. To address this, we propose determinantal averaging, a new\napproach for correcting the inversion bias. This approach involves reweighting\nthe local estimates of the Newton's step proportionally to the determinant of\nthe local Hessian estimate, and then averaging them together to obtain an\nimproved global estimate. This method provides the first known distributed\nNewton step that is asymptotically consistent, i.e., it recovers the exact step\nin the limit as the number of distributed partitions grows to infinity. To show\nthis, we develop new expectation identities and moment bounds for the\ndeterminant and adjugate of a random matrix. Determinantal averaging can be\napplied not only to Newton's method, but to computing any quantity that is a\nlinear tranformation of a matrix inverse, e.g., taking a trace of the inverse\ncovariance matrix, which is used in data uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:08:57 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1905.11549", "submitter": "Xin Zhang", "authors": "Xin Zhang, Jia Liu, Zhengyuan Zhu", "title": "Distributed Linear Model Clustering over Networks: A Tree-Based\n  Fused-Lasso ADMM Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider to improve the model estimation efficiency by\naggregating the neighbors' information as well as identify the subgroup\nmembership for each node in the network. A tree-based $l_1$ penalty is proposed\nto save the computation and communication cost. We design a decentralized\ngeneralized alternating direction method of multiplier algorithm for solving\nthe objective function in parallel. The theoretical properties are derived to\nguarantee both the model consistency and the algorithm convergence. Thorough\nnumerical experiments are also conducted to back up our theory, which also show\nthat our approach outperforms in the aspects of the estimation accuracy,\ncomputation speed and communication cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:40:01 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhang", "Xin", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1905.11550", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Gouranga Charan, Frank Liu, Yu Cao", "title": "Single-Net Continual Learning with Progressive Segmented Training (PST)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing need of continual learning in dynamic systems, such as\nthe self-driving vehicle, the surveillance drone, and the robotic system. Such\na system requires learning from the data stream, training the model to preserve\nprevious information and adapt to a new task, and generating a single-headed\nvector for future inference. Different from previous approaches with dynamic\nstructures, this work focuses on a single network and model segmentation to\nprevent catastrophic forgetting. Leveraging the redundant capacity of a single\nnetwork, model parameters for each task are separated into two groups: one\nimportant group which is frozen to preserve current knowledge, and secondary\ngroup to be saved (not pruned) for a future learning. A fixed-size memory\ncontaining a small amount of previously seen data is further adopted to assist\nthe training. Without additional regularization, the simple yet effective\napproach of PST successfully incorporates multiple tasks and achieves the\nstate-of-the-art accuracy in the single-head evaluation on CIFAR-10 and\nCIFAR-100 datasets. Moreover, the segmented training significantly improves\ncomputation efficiency in continual learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:43:26 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:56:31 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 17:56:57 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 20:06:53 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Du", "Xiaocong", ""], ["Charan", "Gouranga", ""], ["Liu", "Frank", ""], ["Cao", "Yu", ""]]}, {"id": "1905.11553", "submitter": "Zhiting Hu", "authors": "Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric P.\n  Xing, Zhiting Hu", "title": "Target-Guided Open-Domain Conversation", "comments": "ACL 2019. Data and code available at\n  https://github.com/squareRoot3/Target-Guided-Conversation. fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world open-domain conversation applications have specific goals to\nachieve during open-ended chats, such as recommendation, psychotherapy,\neducation, etc. We study the problem of imposing conversational goals on\nopen-domain chat agents. In particular, we want a conversational system to chat\nnaturally with human and proactively guide the conversation to a designated\ntarget subject. The problem is challenging as no public data is available for\nlearning such a target-guided strategy. We propose a structured approach that\nintroduces coarse-grained keywords to control the intended content of system\nresponses. We then attain smooth conversation transition through turn-level\nsupervised learning, and drive the conversation towards the target with\ndiscourse-level constraints. We further derive a keyword-augmented conversation\ndataset for the study. Quantitative and human evaluations show our system can\nproduce meaningful and effective conversations, significantly improving over\nother approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:55:25 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:36:13 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tang", "Jianheng", ""], ["Zhao", "Tiancheng", ""], ["Xiong", "Chenyan", ""], ["Liang", "Xiaodan", ""], ["Xing", "Eric P.", ""], ["Hu", "Zhiting", ""]]}, {"id": "1905.11563", "submitter": "Andy T. Liu", "authors": "Andy T. Liu, Po-chun Hsu, Hung-yi Lee", "title": "Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice\n  Conversion", "comments": "Accepted by Interspeech 2019, Graz, Austria", "journal-ref": "Interspeech 2019", "doi": "10.21437/Interspeech.2019-2048", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised end-to-end training scheme where we discover\ndiscrete subword units from speech without using any labels. The discrete\nsubword units are learned under an ASR-TTS autoencoder reconstruction setting,\nwhere an ASR-Encoder is trained to discover a set of common linguistic units\ngiven a variety of speakers, and a TTS-Decoder trained to project the\ndiscovered units back to the designated speech. We propose a discrete encoding\nmethod, Multilabel-Binary Vectors (MBV), to make the ASR-TTS autoencoder\ndifferentiable. We found that the proposed encoding method offers automatic\nextraction of speech content from speaker style, and is sufficient to cover\nfull linguistic content in a given language. Therefore, the TTS-Decoder can\nsynthesize speech with the same content as the input of ASR-Encoder but with\ndifferent speaker characteristics, which achieves voice conversion (VC). We\nfurther improve the quality of VC using adversarial training, where we train a\nTTS-Patcher that augments the output of TTS-Decoder. Objective and subjective\nevaluations show that the proposed approach offers strong VC results as it\neliminates speaker identity while preserving content within speech. In the\nZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low\nbitrate.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:36:31 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 09:32:39 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 16:05:26 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Liu", "Andy T.", ""], ["Hsu", "Po-chun", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1905.11564", "submitter": "Mohammad Mahmoody", "authors": "Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarially Robust Learning Could Leverage Computational Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years, devising classification algorithms that are robust to\nadversarial perturbations has emerged as a challenging problem. In particular,\ndeep neural nets (DNNs) seem to be susceptible to small imperceptible changes\nover test instances. However, the line of work in provable robustness, so far,\nhas been focused on information-theoretic robustness, ruling out even the\nexistence of any adversarial examples. In this work, we study whether there is\na hope to benefit from algorithmic nature of an attacker that searches for\nadversarial examples, and ask whether there is any learning task for which it\nis possible to design classifiers that are only robust against polynomial-time\nadversaries. Indeed, numerous cryptographic tasks can only be secure against\ncomputationally bounded adversaries, and are indeed impossible for\ncomputationally unbounded attackers. Thus, it is natural to ask if the same\nstrategy could help robust learning.\n  We show that computational limitation of attackers can indeed be useful in\nrobust learning by demonstrating the possibility of a classifier for some\nlearning task for which computational and information theoretic adversaries of\nbounded perturbations have very different power. Namely, while computationally\nunbounded adversaries can attack successfully and find adversarial examples\nwith small perturbation, polynomial time adversaries are unable to do so unless\nthey can break standard cryptographic hardness assumptions. Our results,\ntherefore, indicate that perhaps a similar approach to cryptography (relying on\ncomputational hardness) holds promise for achieving computationally robust\nmachine learning. On the reverse directions, we also show that the existence of\nsuch learning task in which computational robustness beats information\ntheoretic robustness requires computational hardness by implying (average-case)\nhardness of NP.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:44:22 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:55:20 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1905.11566", "submitter": "Qiong Wu", "authors": "Qiong Wu, Felix Ming Fai Wong, Zhenming Liu, Yanhua Li, Varun Kanade", "title": "Adaptive Reduced Rank Regression", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the low rank regression problem $\\my = M\\mx + \\epsilon$, where $\\mx$\nand $\\my$ are $d_1$ and $d_2$ dimensional vectors respectively. We consider the\nextreme high-dimensional setting where the number of observations $n$ is less\nthan $d_1 + d_2$. Existing algorithms are designed for settings where $n$ is\ntypically as large as $\\Rank(M)(d_1+d_2)$. This work provides an efficient\nalgorithm which only involves two SVD, and establishes statistical guarantees\non its performance. The algorithm decouples the problem by first estimating the\nprecision matrix of the features, and then solving the matrix denoising\nproblem. To complement the upper bound, we introduce new techniques for\nestablishing lower bounds on the performance of any algorithm for this problem.\nOur preliminary experiments confirm that our algorithm often out-performs\nexisting baselines, and is always at least competitive.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:47:31 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:51:44 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 21:30:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Qiong", ""], ["Wong", "Felix Ming Fai", ""], ["Liu", "Zhenming", ""], ["Li", "Yanhua", ""], ["Kanade", "Varun", ""]]}, {"id": "1905.11569", "submitter": "Jingwen Ye", "authors": "Jingwen Ye, Xinchao Wang, Yixin Ji, Kairi Ou and Mingli Song", "title": "Amalgamating Filtered Knowledge: Learning Task-customized Student from\n  Multi-task Teachers", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many well-trained Convolutional Neural Network(CNN) models have now been\nreleased online by developers for the sake of effortless reproducing. In this\npaper, we treat such pre-trained networks as teachers and explore how to learn\na target student network for customized tasks, using multiple teachers that\nhandle different tasks. We assume no human-labelled annotations are available,\nand each teacher model can be either single- or multi-task network, where the\nformer is a degenerated case of the latter. The student model, depending on the\ncustomized tasks, learns the related knowledge filtered from the multiple\nteachers, and eventually masters the complete or a subset of expertise from all\nteachers. To this end, we adopt a layer-wise training strategy, which entangles\nthe student's network block to be learned with the corresponding teachers. As\ndemonstrated on several benchmarks, the learned student network achieves very\npromising results, even outperforming the teachers on the customized tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:00:18 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ye", "Jingwen", ""], ["Wang", "Xinchao", ""], ["Ji", "Yixin", ""], ["Ou", "Kairi", ""], ["Song", "Mingli", ""]]}, {"id": "1905.11574", "submitter": "Minje Park", "authors": "Minje Park", "title": "JGAN: A Joint Formulation of GAN for Synthesizing Images and Labels", "comments": "To be published in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3031292", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image generation with explicit condition or label generally works better than\nunconditional methods. In modern GAN frameworks, both generator and\ndiscriminator are formulated to model the conditional distribution of images\ngiven with labels. In this paper, we provide an alternative formulation of GAN\nwhich models the joint distribution of images and labels. There are two\nadvantages in this joint formulation over conditional approaches. The first\nadvantage is that the joint formulation is more robust to label noises if it's\nproperly modeled. This alleviates the burden of making noise-free labels and\nallows the use of weakly-supervised labels in image generation. The second is\nthat we can use any kinds of weak labels or image features that have\ncorrelations with the original image data to enhance unconditional image\ngeneration. We will show the effectiveness of our joint formulation on CIFAR10,\nCIFAR100, and STL dataset with the state-of-the-art GAN architecture.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:19:42 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 05:39:16 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 05:44:25 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 00:59:40 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 01:17:36 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Park", "Minje", ""]]}, {"id": "1905.11577", "submitter": "Dominique Beaini", "authors": "Emmanuel Noutahi, Dominique Beaini, Julien Horwood, S\\'ebastien\n  Gigu\\`ere and Prudencio Tossou", "title": "Towards Interpretable Sparse Graph Representation Learning with\n  Laplacian Pooling", "comments": "11 pages, with Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in graph neural networks (GNNs) has led to improvements in\nmolecular activity and property prediction tasks. Unfortunately, GNNs often\nfail to capture the relative importance of interactions between molecular\nsubstructures, in part due to the absence of efficient intermediate pooling\nsteps. To address these issues, we propose LaPool (Laplacian Pooling), a novel,\ndata-driven, and interpretable hierarchical graph pooling method that takes\ninto account both node features and graph structure to improve molecular\nrepresentation. We benchmark LaPool on molecular graph prediction and\nunderstanding tasks and show that it outperforms recent GNNs. Interestingly,\nLaPool also remains competitive on non-molecular tasks. Both quantitative and\nqualitative assessments are done to demonstrate LaPool's improved\ninterpretability and highlight its potential benefits in drug design. Finally,\nwe demonstrate LaPool's utility for the generation of valid and novel molecules\nby incorporating it into an adversarial autoencoder.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:38:16 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:41:13 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 13:10:47 GMT"}, {"version": "v4", "created": "Thu, 2 Apr 2020 14:01:17 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Noutahi", "Emmanuel", ""], ["Beaini", "Dominique", ""], ["Horwood", "Julien", ""], ["Gigu\u00e8re", "S\u00e9bastien", ""], ["Tossou", "Prudencio", ""]]}, {"id": "1905.11581", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Xuehao Ding, Divyanshu Murli, Daniel Yamins", "title": "Local Label Propagation for Large-Scale Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant issue in training deep neural networks to solve supervised\nlearning tasks is the need for large numbers of labelled datapoints. The goal\nof semi-supervised learning is to leverage ubiquitous unlabelled data, together\nwith small quantities of labelled data, to achieve high task performance.\nThough substantial recent progress has been made in developing semi-supervised\nalgorithms that are effective for comparatively small datasets, many of these\ntechniques do not scale readily to the large (unlaballed) datasets\ncharacteristic of real-world applications. In this paper we introduce a novel\napproach to scalable semi-supervised learning, called Local Label Propagation\n(LLP). Extending ideas from recent work on unsupervised embedding learning, LLP\nfirst embeds datapoints, labelled and otherwise, in a common latent space using\na deep neural network. It then propagates pseudolabels from known to unknown\ndatapoints in a manner that depends on the local geometry of the embedding,\ntaking into account both inter-point distance and local data density as a\nweighting on propagation likelihood. The parameters of the deep embedding are\nthen trained to simultaneously maximize pseudolabel categorization performance\nas well as a metric of the clustering of datapoints within each psuedo-label\ngroup, iteratively alternating stages of network training and label\npropagation. We illustrate the utility of the LLP method on the ImageNet\ndataset, achieving results that outperform previous state-of-the-art scalable\nsemi-supervised learning algorithms by large margins, consistently across a\nwide variety of training regimes. We also show that the feature representation\nlearned with LLP transfers well to scene recognition in the Places 205 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:57:42 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhuang", "Chengxu", ""], ["Ding", "Xuehao", ""], ["Murli", "Divyanshu", ""], ["Yamins", "Daniel", ""]]}, {"id": "1905.11583", "submitter": "Qiwei Ye", "authors": "Ruihan Yang, Qiwei Ye, Tie-Yan Liu", "title": "Learning Efficient and Effective Exploration Policies with\n  Counterfactual Meta Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental issue in reinforcement learning algorithms is the balance\nbetween exploration of the environment and exploitation of information already\nobtained by the agent. Especially, exploration has played a critical role for\nboth efficiency and efficacy of the learning process. However, Existing works\nfor exploration involve task-agnostic design, that is performing well in one\nenvironment, but be ill-suited to another. To the purpose of learning an\neffective and efficient exploration policy in an automated manner. We\nformalized a feasible metric for measuring the utility of exploration based on\ncounterfactual ideology. Based on that, We proposed an end-to-end algorithm to\nlearn exploration policy by meta-learning. We demonstrate that our method\nachieves good results compared to previous works in the high-dimensional\ncontrol tasks in MuJoCo simulator.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:58:28 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yang", "Ruihan", ""], ["Ye", "Qiwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.11586", "submitter": "Evgeny Burnaev", "authors": "Evgeny Burnaev", "title": "Rare Failure Prediction via Event Matching for Aerospace Applications", "comments": "7 pages, 8 figures, 1 table", "journal-ref": "3rd International Conference on Circuits, System and Simulation\n  (ICCSS 2019), 2019", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a problem of failure prediction in the context of\npredictive maintenance applications. We present a new approach for rare\nfailures prediction, based on a general methodology, which takes into account\npeculiar properties of technical systems. We illustrate the applicability of\nthe method on the real-world test cases from aircraft operations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:03:18 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Burnaev", "Evgeny", ""]]}, {"id": "1905.11589", "submitter": "David Rawlinson", "authors": "David Rawlinson, Abdelrahman Ahmed, Gideon Kowadlo", "title": "Learning distant cause and effect using only local and immediate credit\n  assignment", "comments": "11 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recurrent neural network memory that uses sparse coding to\ncreate a combinatoric encoding of sequential inputs. Using several examples, we\nshow that the network can associate distant causes and effects in a discrete\nstochastic process, predict partially-observable higher-order sequences, and\nenable a DQN agent to navigate a maze by giving it memory. The network uses\nonly biologically-plausible, local and immediate credit assignment. Memory\nrequirements are typically one order of magnitude less than existing LSTM, GRU\nand autoregressive feed-forward sequence learning models. The most significant\nlimitation of the memory is generalization to unseen input sequences. We\nexplore this limitation by measuring next-word prediction perplexity on the\nPenn Treebank dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:20:07 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 11:19:17 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Rawlinson", "David", ""], ["Ahmed", "Abdelrahman", ""], ["Kowadlo", "Gideon", ""]]}, {"id": "1905.11590", "submitter": "Enmei Tu", "authors": "Enmei Tu, Jie Yang", "title": "A Review of Semi Supervised Learning Theories and Recent Advances", "comments": "Chinese language, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning, which has emerged from the beginning of this\ncentury, is a new type of learning method between traditional supervised\nlearning and unsupervised learning. The main idea of semi-supervised learning\nis to introduce unlabeled samples into the model training process to avoid\nperformance (or model) degeneration due to insufficiency of labeled samples.\nSemi-supervised learning has been applied successfully in many fields. This\npaper reviews the development process and main theories of semi-supervised\nlearning, as well as its recent advances and importance in solving real-world\nproblems demonstrated by typical application examples.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:25:45 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Tu", "Enmei", ""], ["Yang", "Jie", ""]]}, {"id": "1905.11591", "submitter": "Qiwei Ye", "authors": "Yufei Wang, Qiwei Ye, Tie-Yan Liu", "title": "Beyond Exponentially Discounted Sum: Automatic Learning of Return\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, Return, which is the weighted accumulated future\nrewards, and Value, which is the expected return, serve as the objective that\nguides the learning of the policy. In classic RL, return is defined as the\nexponentially discounted sum of future rewards. One key insight is that there\ncould be many feasible ways to define the form of the return function (and thus\nthe value), from which the same optimal policy can be derived, yet these\ndifferent forms might render dramatically different speeds of learning this\npolicy. In this paper, we research how to modify the form of the return\nfunction to enhance the learning towards the optimal policy. We propose to use\na general mathematical form for return function, and employ meta-learning to\nlearn the optimal return function in an end-to-end manner. We test our methods\non a specially designed maze environment and several Atari games, and our\nexperimental results clearly indicate the advantages of automatically learning\noptimal return functions in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:26:08 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 06:34:38 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Yufei", ""], ["Ye", "Qiwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.11592", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee and Aly El Gamal", "title": "Efficient Wrapper Feature Selection using Autoencoder and Model Based\n  Elimination", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computationally efficient wrapper feature selection method -\ncalled Autoencoder and Model Based Elimination of features using Relevance and\nRedundancy scores (AMBER) - that uses a single ranker model along with\nautoencoders to perform greedy backward elimination of features. The ranker\nmodel is used to prioritize the removal of features that are not critical to\nthe classification task, while the autoencoders are used to prioritize the\nelimination of correlated features. We demonstrate the superior feature\nselection ability of AMBER on 4 well known datasets corresponding to different\ndomain applications via comparing the classification accuracies with other\ncomputationally efficient state-of-the-art feature selection techniques.\nInterestingly, we find that the ranker model that is used for feature selection\ndoes not necessarily have to be the same as the final classifier that is\ntrained on the selected features. Finally, we note how a smaller number of\nfeatures can lead to higher accuracies on some datasets, and hypothesize that\noverfitting the ranker model on the training set facilitates the selection of\nmore salient features.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:31:40 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 02:30:07 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ramjee", "Sharan", ""], ["Gamal", "Aly El", ""]]}, {"id": "1905.11594", "submitter": "Yuan Zeng", "authors": "Yuan Zeng and Zubayer Ibne Ferdous and Weixiang Zhang and Mufan Xu and\n  Anlan Yu and Drew Patel and Xiaochen Guo and Yevgeny Berdichevsky and Zhiyuan\n  Yan", "title": "Inference with Hybrid Bio-hardware Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the learning process in brains, biologically plausible\nalgorithms have been explored by modeling the detailed neuron properties and\ndynamics. On the other hand, simplified multi-layer models of neural networks\nhave shown great success on computational tasks such as image classification\nand speech recognition. However, the computational models that can achieve good\naccuracy for these learning applications are very different from the\nbio-plausible models. This paper studies whether a bio-plausible model of a in\nvitro living neural network can be used to perform machine learning tasks and\nachieve good inference accuracy. A novel two-layer bio-hardware hybrid neural\nnetwork is proposed. The biological layer faithfully models variations of\nsynapses, neurons, and network sparsity in in vitro living neural networks. The\nhardware layer is a computational fully-connected layer that tunes parameters\nto optimize for accuracy. Several techniques are proposed to improve the\ninference accuracy of the proposed hybrid neural network. For instance, an\nadaptive pre-processing technique helps the proposed neural network to achieve\ngood learning accuracy for different living neural network sparsity. The\nproposed hybrid neural network with realistic neuron parameters and variations\nachieves a 98.3% testing accuracy for the handwritten digit recognition task on\nthe full MNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:38:27 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 16:06:44 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zeng", "Yuan", ""], ["Ferdous", "Zubayer Ibne", ""], ["Zhang", "Weixiang", ""], ["Xu", "Mufan", ""], ["Yu", "Anlan", ""], ["Patel", "Drew", ""], ["Guo", "Xiaochen", ""], ["Berdichevsky", "Yevgeny", ""], ["Yan", "Zhiyuan", ""]]}, {"id": "1905.11596", "submitter": "Bei Chen", "authors": "Yihong Chen, Bei Chen, Xiangnan He, Chen Gao, Yong Li, Jian-Guang Lou,\n  Yue Wang", "title": "LambdaOpt: Learn to Regularize Recommender Models in Finer Levels", "comments": "Accepted by KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330880", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation models mainly deal with categorical variables, such as\nuser/item ID and attributes. Besides the high-cardinality issue, the\ninteractions among such categorical variables are usually long-tailed, with the\nhead made up of highly frequent values and a long tail of rare ones. This\nphenomenon results in the data sparsity issue, making it essential to\nregularize the models to ensure generalization. The common practice is to\nemploy grid search to manually tune regularization hyperparameters based on the\nvalidation data. However, it requires non-trivial efforts and large computation\nresources to search the whole candidate space; even so, it may not lead to the\noptimal choice, for which different parameters should have different\nregularization strengths. In this paper, we propose a hyperparameter\noptimization method, LambdaOpt, which automatically and adaptively enforces\nregularization during training. Specifically, it updates the regularization\ncoefficients based on the performance of validation data. With LambdaOpt, the\nnotorious tuning of regularization hyperparameters can be avoided; more\nimportantly, it allows fine-grained regularization (i.e. each parameter can\nhave an individualized regularization coefficient), leading to better\ngeneralized models. We show how to employ LambdaOpt on matrix factorization, a\nclassical model that is representative of a large family of recommender models.\nExtensive experiments on two public benchmarks demonstrate the superiority of\nour method in boosting the performance of top-K recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:54:38 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Chen", "Yihong", ""], ["Chen", "Bei", ""], ["He", "Xiangnan", ""], ["Gao", "Chen", ""], ["Li", "Yong", ""], ["Lou", "Jian-Guang", ""], ["Wang", "Yue", ""]]}, {"id": "1905.11600", "submitter": "Kaushalya Madhawa Mr", "authors": "Kaushalya Madhawa, Katushiko Ishiguro, Kosuke Nakago, Motoki Abe", "title": "GraphNVP: An Invertible Flow Model for Generating Molecular Graphs", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GraphNVP, the first invertible, normalizing flow-based molecular\ngraph generation model. We decompose the generation of a graph into two steps:\ngeneration of (i) an adjacency tensor and (ii) node attributes. This\ndecomposition yields the exact likelihood maximization on graph-structured\ndata, combined with two novel reversible flows. We empirically demonstrate that\nour model efficiently generates valid molecular graphs with almost no\nduplicated molecules. In addition, we observe that the learned latent space can\nbe used to generate molecules with desired chemical properties.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:13:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Madhawa", "Kaushalya", ""], ["Ishiguro", "Katushiko", ""], ["Nakago", "Kosuke", ""], ["Abe", "Motoki", ""]]}, {"id": "1905.11602", "submitter": "Peter Karkus", "authors": "Peter Karkus, Xiao Ma, David Hsu, Leslie Pack Kaelbling, Wee Sun Lee\n  and Tomas Lozano-Perez", "title": "Differentiable Algorithm Networks for Composable Robot Learning", "comments": "RSS 2019 camera ready. Video is available at\n  https://youtu.be/4jcYlTSJF4Y", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Differentiable Algorithm Network (DAN), a\ncomposable architecture for robot learning systems. A DAN is composed of neural\nnetwork modules, each encoding a differentiable robot algorithm and an\nassociated model; and it is trained end-to-end from data. DAN combines the\nstrengths of model-driven modular system design and data-driven end-to-end\nlearning. The algorithms and models act as structural assumptions to reduce the\ndata requirements for learning; end-to-end learning allows the modules to adapt\nto one another and compensate for imperfect models and algorithms, in order to\nachieve the best overall system performance. We illustrate the DAN methodology\nthrough a case study on a simulated robot system, which learns to navigate in\ncomplex 3-D environments with only local visual observations and an image of a\npartially correct 2-D floor map.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:18:05 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Karkus", "Peter", ""], ["Ma", "Xiao", ""], ["Hsu", "David", ""], ["Kaelbling", "Leslie Pack", ""], ["Lee", "Wee Sun", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1905.11604", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Gal Kaplun, Dimitris Kalimeris, Tristan Yang,\n  Benjamin L. Edelman, Fred Zhang, Boaz Barak", "title": "SGD on Neural Networks Learns Functions of Increasing Complexity", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an experimental study of the dynamics of Stochastic Gradient\nDescent (SGD) in learning deep neural networks for several real and synthetic\nclassification tasks. We show that in the initial epochs, almost all of the\nperformance improvement of the classifier obtained by SGD can be explained by a\nlinear classifier. More generally, we give evidence for the hypothesis that, as\niterations progress, SGD learns functions of increasing complexity. This\nhypothesis can be helpful in explaining why SGD-learned classifiers tend to\ngeneralize well even in the over-parameterized regime. We also show that the\nlinear classifier learned in the initial stages is \"retained\" throughout the\nexecution even if training is continued to the point of zero training error,\nand complement this with a theoretical result in a simplified model. Key to our\nwork is a new measure of how well one classifier explains the performance of\nanother, based on conditional mutual information.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:34:08 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Kaplun", "Gal", ""], ["Kalimeris", "Dimitris", ""], ["Yang", "Tristan", ""], ["Edelman", "Benjamin L.", ""], ["Zhang", "Fred", ""], ["Barak", "Boaz", ""]]}, {"id": "1905.11605", "submitter": "Kun Xu", "authors": "Kun Xu, Liwei Wang, Mo Yu, Yansong Feng, Yan Song, Zhiguo Wang and\n  Dong Yu", "title": "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural\n  Network", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous cross-lingual knowledge graph (KG) alignment studies rely on entity\nembeddings derived only from monolingual KG structural information, which may\nfail at matching entities that have different facts in two KGs. In this paper,\nwe introduce the topic entity graph, a local sub-graph of an entity, to\nrepresent entities with their contextual information in KG. From this view, the\nKB-alignment task can be formulated as a graph matching problem; and we further\npropose a graph-attention based solution, which first matches all entities in\ntwo topic entity graphs, and then jointly model the local matching information\nto derive a graph-level matching vector. Experiments show that our model\noutperforms previous state-of-the-art methods by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:37:49 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 08:04:55 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 20:55:42 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Xu", "Kun", ""], ["Wang", "Liwei", ""], ["Yu", "Mo", ""], ["Feng", "Yansong", ""], ["Song", "Yan", ""], ["Wang", "Zhiguo", ""], ["Yu", "Dong", ""]]}, {"id": "1905.11614", "submitter": "Sungmin Cha", "authors": "Hongjoon Ahn, Sungmin Cha, Donggyu Lee, and Taesup Moon", "title": "Uncertainty-based Continual Learning with Adaptive Regularization", "comments": "10 pages (including Supplementary Materials), Neurips 2019 camera\n  ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new neural network-based continual learning algorithm, dubbed\nas Uncertainty-regularized Continual Learning (UCL), which builds on\ntraditional Bayesian online learning framework with variational inference. We\nfocus on two significant drawbacks of the recently proposed\nregularization-based methods: a) considerable additional memory cost for\ndetermining the per-weight regularization strengths and b) the absence of\ngracefully forgetting scheme, which can prevent performance degradation in\nlearning new tasks. In this paper, we show UCL can solve these two problems by\nintroducing a fresh interpretation on the Kullback-Leibler (KL) divergence term\nof the variational lower bound for Gaussian mean-field approximation. Based on\nthe interpretation, we propose the notion of node-wise uncertainty, which\ndrastically reduces the number of additional parameters for implementing\nper-weight regularization. Moreover, we devise two additional regularization\nterms that enforce stability by freezing important parameters for past tasks\nand allow plasticity by controlling the actively learning parameters for a new\ntask. Through extensive experiments, we show UCL convincingly outperforms most\nof recent state-of-the-art baselines not only on popular supervised learning\nbenchmarks, but also on challenging lifelong reinforcement learning tasks. The\nsource code of our algorithm is available at https://github.com/csm9493/UCL.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 05:21:07 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 20:19:47 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 05:25:59 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ahn", "Hongjoon", ""], ["Cha", "Sungmin", ""], ["Lee", "Donggyu", ""], ["Moon", "Taesup", ""]]}, {"id": "1905.11616", "submitter": "Insu Han", "authors": "Insu Han, Haim Avron, Jinwoo Shin", "title": "Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to sketch element-wise functions of low-rank matrices.\nFormally, given low-rank matrix A = [Aij] and scalar non-linear function f, we\naim for finding an approximated low-rank representation of the (possibly\nhigh-rank) matrix [f(Aij)]. To this end, we propose an efficient\nsketching-based algorithm whose complexity is significantly lower than the\nnumber of entries of A, i.e., it runs without accessing all entries of [f(Aij)]\nexplicitly. The main idea underlying our method is to combine a polynomial\napproximation of f with the existing tensor sketch scheme for approximating\nmonomials of entries of A. To balance the errors of the two approximation\ncomponents in an optimal manner, we propose a novel regression formula to find\npolynomial coefficients given A and f. In particular, we utilize a\ncoreset-based regression with a rigorous approximation guarantee. Finally, we\ndemonstrate the applicability and superiority of the proposed scheme under\nvarious machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 05:34:25 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 10:40:37 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 07:55:01 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Han", "Insu", ""], ["Avron", "Haim", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1905.11620", "submitter": "Thulasi Tholeti", "authors": "Thulasi Tholeti and Sheetal Kalyani", "title": "Concavifiability and convergence: necessary and sufficient conditions\n  for gradient descent analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence of the gradient descent algorithm has been attracting renewed\ninterest due to its utility in deep learning applications. Even as multiple\nvariants of gradient descent were proposed, the assumption that the gradient of\nthe objective is Lipschitz continuous remained an integral part of the analysis\nuntil recently. In this work, we look at convergence analysis by focusing on a\nproperty that we term as concavifiability, instead of Lipschitz continuity of\ngradients. We show that concavifiability is a necessary and sufficient\ncondition to satisfy the upper quadratic approximation which is key in proving\nthat the objective function decreases after every gradient descent update. We\nalso show that any gradient Lipschitz function satisfies concavifiability. A\nconstant known as the concavifier analogous to the gradient Lipschitz constant\nis derived which is indicative of the optimal step size. As an application, we\ndemonstrate the utility of finding the concavifier the in convergence of\ngradient descent through an example inspired by neural networks. We derive\nbounds on the concavifier to obtain a fixed step size for a single hidden layer\nReLU network.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 05:50:00 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Tholeti", "Thulasi", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1905.11623", "submitter": "Kenshin Abe", "authors": "Kenshin Abe, Zijian Xu, Issei Sato, Masashi Sugiyama", "title": "Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been increasing challenges to solve combinatorial optimization\nproblems by machine learning. Khalil et al. proposed an end-to-end\nreinforcement learning framework, S2V-DQN, which automatically learns graph\nembeddings to construct solutions to a wide range of problems. To improve the\ngeneralization ability of their Q-learning method, we propose a novel learning\nstrategy based on AlphaGo Zero which is a Go engine that achieved a superhuman\nlevel without the domain knowledge of the game. Our framework is redesigned for\ncombinatorial problems, where the final reward might take any real number\ninstead of a binary response, win/lose. In experiments conducted for five kinds\nof NP-hard problems including {\\sc MinimumVertexCover} and {\\sc MaxCut}, our\nmethod is shown to generalize better to various graphs than S2V-DQN.\nFurthermore, our method can be combined with recently-developed graph neural\nnetwork (GNN) models such as the \\emph{Graph Isomorphism Network}, resulting in\neven better performance. This experiment also gives an interesting insight into\na suitable choice of GNN models for each task.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:04:25 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 14:01:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Abe", "Kenshin", ""], ["Xu", "Zijian", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1905.11625", "submitter": "Mingshuai Chen", "authors": "Mingshuai Chen, Jian Wang, Jie An, Bohua Zhan, Deepak Kapur, and\n  Naijun Zhan", "title": "NIL: Learning Nonlinear Interpolants", "comments": "Full version of the paper in Proc. of CADE-27, with typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear interpolants have been shown useful for the verification of\nprograms and hybrid systems in contexts of theorem proving, model checking,\nabstract interpretation, etc. The underlying synthesis problem, however, is\nchallenging and existing methods have limitations on the form of formulae to be\ninterpolated. We leverage classification techniques with space transformations\nand kernel tricks as established in the realm of machine learning, and present\na counterexample-guided method named NIL for synthesizing polynomial\ninterpolants, thereby yielding a unified framework tackling the interpolation\nproblem for the general quantifier-free theory of nonlinear arithmetic,\npossibly involving transcendental functions. We prove the soundness of NIL and\npropose sufficient conditions under which NIL is guaranteed to converge, i.e.,\nthe derived sequence of candidate interpolants converges to an actual\ninterpolant, and is complete, namely the algorithm terminates by producing an\ninterpolant if there exists one. The applicability and effectiveness of our\ntechnique are demonstrated experimentally on a collection of representative\nbenchmarks from the literature, where in particular, our method suffices to\naddress more interpolation tasks, including those with perturbations in\nparameters, and in many cases synthesizes simpler interpolants compared with\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:19:44 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:39:26 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 08:20:57 GMT"}, {"version": "v4", "created": "Mon, 26 Aug 2019 03:47:27 GMT"}, {"version": "v5", "created": "Wed, 28 Aug 2019 12:41:54 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Chen", "Mingshuai", ""], ["Wang", "Jian", ""], ["An", "Jie", ""], ["Zhan", "Bohua", ""], ["Kapur", "Deepak", ""], ["Zhan", "Naijun", ""]]}, {"id": "1905.11633", "submitter": "Davide Brunelli PhD", "authors": "M. Guermandi, S. Benatti, D. Brunelli, V. Kartsch, L. Benini", "title": "Towards a Wearable Interface for Food Quality Grading through ERP\n  Analysis", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": "10.1109/ISCAS.2019.8702725", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory evaluation is used to assess the consumer acceptance of foods or\nother consumer products, so as to improve industrial processes and marketing\nstrategies. The procedures currently involved are time-consuming because they\nrequire a statistical approach from measurements and feedback reports from a\nwide set of evaluators under a well-established measurement setup. In this\npaper, we propose to collect directly the signal of the perceived quality of\nthe food from Event-related potentials (ERPs) that are the outcome of the\nprocessing of visual stimuli. This permits to narrow the number of evaluators\nsince errors related to psychological factors are by-passed. We present the\ndesign of a wearable system for ERP measurement and we present preliminary\nresults on the use of ERP to give a quantitative measure to the appearance of a\nfood product. The system is developed to be wearable and our experiments\ndemonstrate that is possible to use it to identify and classify the grade of\nacceptance of the food.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:41:37 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Guermandi", "M.", ""], ["Benatti", "S.", ""], ["Brunelli", "D.", ""], ["Kartsch", "V.", ""], ["Benini", "L.", ""]]}, {"id": "1905.11634", "submitter": "Songyang Zhang", "authors": "Songyang Zhang, Shipeng Yan, Xuming He", "title": "LatentGNN: Learning Efficient Non-local Relations for Visual Recognition", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing long-range dependencies in feature representations is crucial for\nmany visual recognition tasks. Despite recent successes of deep convolutional\nnetworks, it remains challenging to model non-local context relations between\nvisual features. A promising strategy is to model the feature context by a\nfully-connected graph neural network (GNN), which augments traditional\nconvolutional features with an estimated non-local context representation.\nHowever, most GNN-based approaches require computing a dense graph affinity\nmatrix and hence have difficulty in scaling up to tackle complex real-world\nvisual problems. In this work, we propose an efficient and yet flexible\nnon-local relation representation based on a novel class of graph neural\nnetworks. Our key idea is to introduce a latent space to reduce the complexity\nof graph, which allows us to use a low-rank representation for the graph\naffinity matrix and to achieve a linear complexity in computation. Extensive\nexperimental evaluations on three major visual recognition tasks show that our\nmethod outperforms the prior works with a large margin while maintaining a low\ncomputation cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:42:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhang", "Songyang", ""], ["Yan", "Shipeng", ""], ["He", "Xuming", ""]]}, {"id": "1905.11639", "submitter": "Hamid Javadi", "authors": "Daniel LeJeune, Randall Balestriero, Hamid Javadi, Richard G. Baraniuk", "title": "Implicit Rugosity Regularization via Data Augmentation", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep (neural) networks have been applied productively in a wide range of\nsupervised and unsupervised learning tasks. Unlike classical machine learning\nalgorithms, deep networks typically operate in the \\emph{overparameterized}\nregime, where the number of parameters is larger than the number of training\ndata points. Consequently, understanding the generalization properties and the\nrole of (explicit or implicit) regularization in these networks is of great\nimportance. In this work, we explore how the oft-used heuristic of \\emph{data\naugmentation} imposes an {\\em implicit regularization} penalty of a novel\nmeasure of the \\emph{rugosity} or \"roughness\" based on the tangent Hessian of\nthe function fit to the training data.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:53:04 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 05:28:11 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 20:31:18 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["LeJeune", "Daniel", ""], ["Balestriero", "Randall", ""], ["Javadi", "Hamid", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1905.11656", "submitter": "Yoonho Lee", "authors": "Yoonho Lee, Wonjae Kim, Wonpyo Park, Seungjin Choi", "title": "Discrete Infomax Codes for Supervised Representation Learning", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning compact discrete representations of data is a key task on its own or\nfor facilitating subsequent processing of data. In this paper we present a\nmodel that produces Discrete InfoMax Codes (DIMCO); we learn a probabilistic\nencoder that yields k-way d-dimensional codes associated with input data. Our\nmodel's learning objective is to maximize the mutual information between codes\nand labels with a regularization, which enforces entries of a codeword to be as\nindependent as possible. We show that the infomax principle also justifies\nprevious loss functions (e.g., cross-entropy) as its special cases. Our\nanalysis also shows that using shorter codes, as DIMCO does, reduces\noverfitting in the context of few-shot classification. Through experiments in\nvarious domains, we observe this implicit meta-regularization effect of DIMCO.\nFurthermore, we show that the codes learned by DIMCO are efficient in terms of\nboth memory and retrieval time compared to previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 07:38:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:21:53 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lee", "Yoonho", ""], ["Kim", "Wonjae", ""], ["Park", "Wonpyo", ""], ["Choi", "Seungjin", ""]]}, {"id": "1905.11659", "submitter": "Dan Levi", "authors": "Dan Levi, Liran Gispan, Niv Giladi, Ethan Fetaya", "title": "Evaluating and Calibrating Uncertainty Prediction in Regression Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting not only the target but also an accurate measure of uncertainty is\nimportant for many machine learning applications and in particular\nsafety-critical ones. In this work we study the calibration of uncertainty\nprediction for regression tasks which often arise in real-world systems. We\nshow that the existing definition for calibration of a regression uncertainty\n[Kuleshov et al. 2018] has severe limitations in distinguishing informative\nfrom non-informative uncertainty predictions. We propose a new definition that\nescapes this caveat and an evaluation method using a simple histogram-based\napproach. Our method clusters examples with similar uncertainty prediction and\ncompares the prediction with the empirical uncertainty on these examples. We\nalso propose a simple, scaling-based calibration method that preforms as well\nas much more complex ones. We show results on both a synthetic, controlled\nproblem and on the object detection bounding-box regression task using the COCO\nand KITTI datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 07:52:01 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 13:38:13 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 14:42:54 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Levi", "Dan", ""], ["Gispan", "Liran", ""], ["Giladi", "Niv", ""], ["Fetaya", "Ethan", ""]]}, {"id": "1905.11666", "submitter": "Wonjae Kim", "authors": "Wonjae Kim and Yoonho Lee", "title": "Learning Dynamics of Attention: Human Prior for Interpretable Machine\n  Reasoning", "comments": "20 pages, 18 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without relevant human priors, neural networks may learn uninterpretable\nfeatures. We propose Dynamics of Attention for Focus Transition (DAFT) as a\nhuman prior for machine reasoning. DAFT is a novel method that regularizes\nattention-based reasoning by modelling it as a continuous dynamical system\nusing neural ordinary differential equations. As a proof of concept, we augment\na state-of-the-art visual reasoning model with DAFT. Our experiments reveal\nthat applying DAFT yields similar performance to the original model while using\nfewer reasoning steps, showing that it implicitly learns to skip unnecessary\nsteps. We also propose a new metric, Total Length of Transition (TLT), which\nrepresents the effective reasoning step size by quantifying how much a given\nmodel's focus drifts while reasoning about a question. We show that adding DAFT\nresults in lower TLT, demonstrating that our method indeed obeys the human\nprior towards shorter reasoning paths in addition to producing more\ninterpretable attention maps. Our code is available at\nhttps://github.com/kakao/DAFT.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:13:37 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 05:50:25 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 05:37:28 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kim", "Wonjae", ""], ["Lee", "Yoonho", ""]]}, {"id": "1905.11669", "submitter": "Weicheng Li Mr", "authors": "Weicheng Li, Rui Wang, Zhongzhi Luan, Di Huang, Zidong Du, Yunji Chen\n  and Depei Qian", "title": "CompactNet: Platform-Aware Automatic Optimization for Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) based Deep Learning (DL) has achieved\ngreat progress in many real-life applications. Meanwhile, due to the complex\nmodel structures against strict latency and memory restriction, the\nimplementation of CNN models on the resource-limited platforms is becoming more\nchallenging. This work proposes a solution, called CompactNet\\footnote{Project\nURL: \\url{https://github.com/CompactNet/CompactNet}}, which automatically\noptimizes a pre-trained CNN model on a specific resource-limited platform given\na specific target of inference speedup. Guided by a simulator of the target\nplatform, CompactNet progressively trims a pre-trained network by removing\ncertain redundant filters until the target speedup is reached and generates an\noptimal platform-specific model while maintaining the accuracy. We evaluate our\nwork on two platforms of a mobile ARM CPU and a machine learning accelerator\nNPU (Cambricon-1A ISA) on a Huawei Mate10 smartphone. For the state-of-the-art\nslim CNN model made for the embedded platform, MobileNetV2, CompactNet achieves\nup to a 1.8x kernel computation speedup with equal or even higher accuracy for\nimage classification tasks on the Cifar-10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:24:58 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Li", "Weicheng", ""], ["Wang", "Rui", ""], ["Luan", "Zhongzhi", ""], ["Huang", "Di", ""], ["Du", "Zidong", ""], ["Chen", "Yunji", ""], ["Qian", "Depei", ""]]}, {"id": "1905.11675", "submitter": "Tianle Cai", "authors": "Tianle Cai, Ruiqi Gao, Jikai Hou, Siyu Chen, Dong Wang, Di He, Zhihua\n  Zhang, Liwei Wang", "title": "Gram-Gauss-Newton Method: Learning Overparameterized Neural Networks for\n  Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order methods such as stochastic gradient descent (SGD) are currently\nthe standard algorithm for training deep neural networks. Second-order methods,\ndespite their better convergence rate, are rarely used in practice due to the\nprohibitive computational cost in calculating the second-order information. In\nthis paper, we propose a novel Gram-Gauss-Newton (GGN) algorithm to train deep\nneural networks for regression problems with square loss. Our method draws\ninspiration from the connection between neural network optimization and kernel\nregression of neural tangent kernel (NTK). Different from typical second-order\nmethods that have heavy computational cost in each iteration, GGN only has\nminor overhead compared to first-order methods such as SGD. We also give\ntheoretical results to show that for sufficiently wide neural networks, the\nconvergence rate of GGN is \\emph{quadratic}. Furthermore, we provide\nconvergence guarantee for mini-batch GGN algorithm, which is, to our knowledge,\nthe first convergence result for the mini-batch version of a second-order\nmethod on overparameterized neural networks. Preliminary experiments on\nregression tasks demonstrate that for training standard networks, our GGN\nalgorithm converges much faster and achieves better performance than SGD.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:30:24 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:28:33 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Cai", "Tianle", ""], ["Gao", "Ruiqi", ""], ["Hou", "Jikai", ""], ["Chen", "Siyu", ""], ["Wang", "Dong", ""], ["He", "Di", ""], ["Zhang", "Zhihua", ""], ["Wang", "Liwei", ""]]}, {"id": "1905.11678", "submitter": "Soobeom Jang", "authors": "Soobeom Jang, Seong-Eun Moon, Jong-Seok Lee", "title": "Brain Signal Classification via Learning Connectivity Structure", "comments": "14 pages (11 for article + 3 for supplementary), 5 figures (3 for\n  article + 2 for supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity between different brain regions is one of the most important\nproperties for classification of brain signals including electroencephalography\n(EEG). However, how to define the connectivity structure for a given task is\nstill an open problem, because there is no ground truth about how the\nconnectivity structure should be in order to maximize the performance. In this\npaper, we propose an end-to-end neural network model for EEG classification,\nwhich can extract an appropriate multi-layer graph structure and signal\nfeatures directly from a set of raw EEG signals and perform classification.\nExperimental results demonstrate that our method yields improved performance in\ncomparison to the existing approaches where manually defined connectivity\nstructures and signal features are used. Furthermore, we show that the graph\nstructure extraction process is reliable in terms of consistency, and the\nlearned graph structures make much sense in the neuroscientific viewpoint.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:35:19 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:13:43 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jang", "Soobeom", ""], ["Moon", "Seong-Eun", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "1905.11681", "submitter": "Alpha Albert Lee", "authors": "Matthew C. Robinson and Robert C. Glen and Alpha A. Lee", "title": "Validating the Validation: Reanalyzing a large-scale comparison of Deep\n  Learning and Machine Learning models for bioactivity prediction", "comments": "Code available on GitHub:\n  https://github.com/mc-robinson/validating_validation_supp_info", "journal-ref": null, "doi": "10.1007/s10822-019-00274-0", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods may have the potential to significantly accelerate\ndrug discovery. However, the increasing rate of new methodological approaches\nbeing published in the literature raises the fundamental question of how models\nshould be benchmarked and validated. We reanalyze the data generated by a\nrecently published large-scale comparison of machine learning models for\nbioactivity prediction and arrive at a somewhat different conclusion. We show\nthat the performance of support vector machines is competitive with that of\ndeep learning methods. Additionally, using a series of numerical experiments,\nwe question the relevance of area under the receiver operating characteristic\ncurve as a metric in virtual screening, and instead suggest that area under the\nprecision-recall curve should be used in conjunction with the receiver\noperating characteristic. Our numerical experiments also highlight challenges\nin estimating the uncertainty in model performance via scaffold-split nested\ncross validation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:43:06 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 17:04:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Robinson", "Matthew C.", ""], ["Glen", "Robert C.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1905.11691", "submitter": "Valeria Fionda", "authors": "Valeria Fionda and Giuseppe Pirr\\'o", "title": "Triple2Vec: Learning Triple Embeddings from Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding techniques allow to learn high-quality feature vectors from\ngraph structures and are useful in a variety of tasks, from node classification\nto clustering. Existing approaches have only focused on learning feature\nvectors for the nodes in a (knowledge) graph. To the best of our knowledge,\nnone of them has tackled the problem of embedding of graph edges, that is,\nknowledge graph triples. The approaches that are closer to this task have\nfocused on homogeneous graphs involving only one type of edge and obtain edge\nembeddings by applying some operation (e.g., average) on the embeddings of the\nendpoint nodes. The goal of this paper is to introduce Triple2Vec, a new\ntechnique to directly embed edges in (knowledge) graphs. Trple2Vec builds upon\nthree main ingredients. The first is the notion of line graph. The line graph\nof a graph is another graph representing the adjacency between edges of the\noriginal graph. In particular, the nodes of the line graph are the edges of the\noriginal graph. We show that directly applying existing embedding techniques on\nthe nodes of the line graph to learn edge embeddings is not enough in the\ncontext of knowledge graphs. Thus, we introduce the notion of triple line\ngraph. The second is an edge weighting mechanism both for line graphs derived\nfrom knowledge graphs and homogeneous graphs. The third is a strategy based on\ngraph walks on the weighted triple line graph that can preserve proximity\nbetween nodes. Embeddings are finally generated by adopting the SkipGram model,\nwhere sentences are replaced with graph walks. We evaluate our approach on\ndifferent real world (knowledge) graphs and compared it with related work.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:11:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Fionda", "Valeria", ""], ["Pirr\u00f3", "Giuseppe", ""]]}, {"id": "1905.11692", "submitter": "Aritra Dutta", "authors": "Aritra Dutta, El Houcine Bergou, Yunming Xiao, Marco Canini, Peter\n  Richt\\'arik", "title": "Direct Nonlinear Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization acceleration techniques such as momentum play a key role in\nstate-of-the-art machine learning algorithms. Recently, generic vector sequence\nextrapolation techniques, such as regularized nonlinear acceleration (RNA) of\nScieur et al., were proposed and shown to accelerate fixed point iterations. In\ncontrast to RNA which computes extrapolation coefficients by (approximately)\nsetting the gradient of the objective function to zero at the extrapolated\npoint, we propose a more direct approach, which we call direct nonlinear\nacceleration (DNA). In DNA, we aim to minimize (an approximation of) the\nfunction value at the extrapolated point instead. We adopt a regularized\napproach with regularizers designed to prevent the model from entering a region\nin which the functional approximation is less precise. While the computational\ncost of DNA is comparable to that of RNA, our direct approach significantly\noutperforms RNA on both synthetic and real-world datasets. While the focus of\nthis paper is on convex problems, we obtain very encouraging results in\naccelerating the training of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:12:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dutta", "Aritra", ""], ["Bergou", "El Houcine", ""], ["Xiao", "Yunming", ""], ["Canini", "Marco", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.11697", "submitter": "Daniel Worrall", "authors": "Daniel E. Worrall, Max Welling", "title": "Deep Scale-spaces: Equivariance Over Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep scale-spaces (DSS), a generalization of convolutional\nneural networks, exploiting the scale symmetry structure of conventional image\nrecognition tasks. Put plainly, the class of an image is invariant to the scale\nat which it is viewed. We construct scale equivariant cross-correlations based\non a principled extension of convolutions, grounded in the theory of\nscale-spaces and semigroups. As a very basic operation, these\ncross-correlations can be used in almost any modern deep learning architecture\nin a plug-and-play manner. We demonstrate our networks on the Patch Camelyon\nand Cityscapes datasets, to prove their utility and perform introspective\nstudies to further understand their properties.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:16:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Worrall", "Daniel E.", ""], ["Welling", "Max", ""]]}, {"id": "1905.11702", "submitter": "Samuel Yang-Zhao Mr", "authors": "Marcus Hutter, Samuel Yang-Zhao, Sultan J. Majeed", "title": "Conditions on Features for Temporal Difference-Like Methods to Converge", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence of many reinforcement learning (RL) algorithms with linear\nfunction approximation has been investigated extensively but most proofs assume\nthat these methods converge to a unique solution. In this paper, we provide a\ncomplete characterization of non-uniqueness issues for a large class of\nreinforcement learning algorithms, simultaneously unifying many\ncounter-examples to convergence in a theoretical framework. We achieve this by\nproving a new condition on features that can determine whether the convergence\nassumptions are valid or non-uniqueness holds. We consider a general class of\nRL methods, which we call natural algorithms, whose solutions are characterized\nas the fixed point of a projected Bellman equation (when it exists); notably,\nbootstrapped temporal difference-based methods such as $TD(\\lambda)$ and\n$GTD(\\lambda)$ are natural algorithms. Our main result proves that natural\nalgorithms converge to the correct solution if and only if all the value\nfunctions in the approximation space satisfy a certain shape. This implies that\nnatural algorithms are, in general, inherently prone to converge to the wrong\nsolution for most feature choices even if the value function can be represented\nexactly. Given our results, we show that state aggregation based features are a\nsafe choice for natural algorithms and we also provide a condition for finding\nconvergent algorithms under other feature constructions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:31:28 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Hutter", "Marcus", ""], ["Yang-Zhao", "Samuel", ""], ["Majeed", "Sultan J.", ""]]}, {"id": "1905.11703", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Nils Appenrodt, J\\\"urgen Dickmann, and Bernhard Sick", "title": "Radar-based Road User Classification and Novelty Detection with\n  Recurrent Neural Network Ensembles", "comments": "8 pages, 9 figures, accepted paper for 2019 IEEE Intelligent Vehicles\n  Symposium (IV), Paris, France, June 2019", "journal-ref": "Published in Proceedings of IEEE Intelligent Vehicles Symposium\n  (IV), Paris, France, June 2019", "doi": "10.1109/IVS.2019.8813773", "report-no": null, "categories": "cs.LG cs.RO eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar-based road user classification is an important yet still challenging\ntask towards autonomous driving applications. The resolution of conventional\nautomotive radar sensors results in a sparse data representation which is tough\nto recover by subsequent signal processing. In this article, classifier\nensembles originating from a one-vs-one binarization paradigm are enriched by\none-vs-all correction classifiers. They are utilized to efficiently classify\nindividual traffic participants and also identify hidden object classes which\nhave not been presented to the classifiers during training. For each classifier\nof the ensemble an individual feature set is determined from a total set of 98\nfeatures. Thereby, the overall classification performance can be improved when\ncompared to previous methods and, additionally, novel classes can be identified\nmuch more accurately. Furthermore, the proposed structure allows to give new\ninsights in the importance of features for the recognition of individual\nclasses which is crucial for the development of new algorithms and sensor\nrequirements.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:37:07 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Appenrodt", "Nils", ""], ["Dickmann", "J\u00fcrgen", ""], ["Sick", "Bernhard", ""]]}, {"id": "1905.11711", "submitter": "Manuel Sch\\\"urch", "authors": "Manuel Sch\\\"urch, Dario Azzimonti, Alessio Benavoli, Marco Zaffalon", "title": "Recursive Estimation for Sparse Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are powerful kernelized methods for non-parameteric\nregression used in many applications. However, their use is limited to a few\nthousand of training samples due to their cubic time complexity. In order to\nscale GPs to larger datasets, several sparse approximations based on so-called\ninducing points have been proposed in the literature. In this work we\ninvestigate the connection between a general class of sparse inducing point GP\nregression methods and Bayesian recursive estimation which enables Kalman\nFilter like updating for online learning. The majority of previous work has\nfocused on the batch setting, in particular for learning the model parameters\nand the position of the inducing points, here instead we focus on training with\nmini-batches. By exploiting the Kalman filter formulation, we propose a novel\napproach that estimates such parameters by recursively propagating the\nanalytical gradients of the posterior over mini-batches of the data. Compared\nto state of the art methods, our method keeps analytic updates for the mean and\ncovariance of the posterior, thus reducing drastically the size of the\noptimization problem. We show that our method achieves faster convergence and\nsuperior performance compared to state of the art sequential Gaussian Process\nregression on synthetic GP as well as real-world data with up to a million of\ndata samples.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:53:55 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 16:19:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sch\u00fcrch", "Manuel", ""], ["Azzimonti", "Dario", ""], ["Benavoli", "Alessio", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1905.11713", "submitter": "Pengcheng Li", "authors": "Pengcheng Li, Jinfeng Yi, Bowen Zhou, Lijun Zhang", "title": "Improving the Robustness of Deep Neural Networks via Adversarial\n  Training with Triplet Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have highlighted that deep neural networks (DNNs) are\nvulnerable to adversarial examples. In this paper, we improve the robustness of\nDNNs by utilizing techniques of Distance Metric Learning. Specifically, we\nincorporate Triplet Loss, one of the most popular Distance Metric Learning\nmethods, into the framework of adversarial training. Our proposed algorithm,\nAdversarial Training with Triplet Loss (AT$^2$L), substitutes the adversarial\nexample against the current model for the anchor of triplet loss to effectively\nsmooth the classification boundary. Furthermore, we propose an ensemble version\nof AT$^2$L, which aggregates different attack methods and model structures for\nbetter defense effects. Our empirical studies verify that the proposed approach\ncan significantly improve the robustness of DNNs without sacrificing accuracy.\nFinally, we demonstrate that our specially designed triplet loss can also be\nused as a regularization term to enhance other defense methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:01:24 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Li", "Pengcheng", ""], ["Yi", "Jinfeng", ""], ["Zhou", "Bowen", ""], ["Zhang", "Lijun", ""]]}, {"id": "1905.11716", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Maksim Belousov, Nikola Milosevic, William Dixon, and Goran Nenadic", "title": "Extracting adverse drug reactions and their context using sequence\n  labelling ensembles in TAC2017", "comments": "Paper describing submission for TAC ADR shared task", "journal-ref": "Text Analytics Conference 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Adverse drug reactions (ADRs) are unwanted or harmful effects experienced\nafter the administration of a certain drug or a combination of drugs,\npresenting a challenge for drug development and drug administration. In this\npaper, we present a set of taggers for extracting adverse drug reactions and\nrelated entities, including factors, severity, negations, drug class and\nanimal. The systems used a mix of rule-based, machine learning (CRF) and deep\nlearning (BLSTM with word2vec embeddings) methodologies in order to annotate\nthe data. The systems were submitted to adverse drug reaction shared task,\norganised during Text Analytics Conference in 2017 by National Institute for\nStandards and Technology, archiving F1-scores of 76.00 and 75.61 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:07:01 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Belousov", "Maksim", ""], ["Milosevic", "Nikola", ""], ["Dixon", "William", ""], ["Nenadic", "Goran", ""]]}, {"id": "1905.11719", "submitter": "Nikita Kazeev", "authors": "Maxim Borisyak, Nikita Kazeev", "title": "Machine Learning on data with sPlot background subtraction", "comments": null, "journal-ref": "JINST 14 P08020 (2019)", "doi": "10.1088/1748-0221/14/08/P08020", "report-no": null, "categories": "cs.LG hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analysis in high energy physics often deals with data samples consisting\nof a mixture of signal and background events. The sPlot technique is a common\nmethod to subtract the contribution of the background by assigning weights to\nevents. Part of the weights are by design negative. Negative weights lead to\nthe divergence of some machine learning algorithms training due to absence of\nthe lower bound in the loss function. In this paper we propose a mathematically\nrigorous way to train machine learning algorithms on data samples with\nbackground described by sPlot to obtain signal probabilities conditioned on\nobservables, without encountering negative event weight at all. This allows\nusage of any out-of-the-box machine learning methods on such data.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:09:52 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:36:45 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 03:22:02 GMT"}, {"version": "v4", "created": "Fri, 9 Aug 2019 08:26:26 GMT"}, {"version": "v5", "created": "Mon, 2 Dec 2019 16:36:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Borisyak", "Maxim", ""], ["Kazeev", "Nikita", ""]]}, {"id": "1905.11722", "submitter": "Mitsuru Kusumoto", "authors": "Mitsuru Kusumoto, Takuya Inoue, Gentaro Watanabe, Takuya Akiba and\n  Masanori Koyama", "title": "A Graph Theoretic Framework of Recomputation Algorithms for\n  Memory-Efficient Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recomputation algorithms collectively refer to a family of methods that aims\nto reduce the memory consumption of the backpropagation by selectively\ndiscarding the intermediate results of the forward propagation and recomputing\nthe discarded results as needed. In this paper, we will propose a novel and\nefficient recomputation method that can be applied to a wider range of neural\nnets than previous methods. We use the language of graph theory to formalize\nthe general recomputation problem of minimizing the computational overhead\nunder a fixed memory budget constraint, and provide a dynamic programming\nsolution to the problem. Our method can reduce the peak memory consumption on\nvarious benchmark networks by 36%~81%, which outperforms the reduction achieved\nby other methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:15:35 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kusumoto", "Mitsuru", ""], ["Inoue", "Takuya", ""], ["Watanabe", "Gentaro", ""], ["Akiba", "Takuya", ""], ["Koyama", "Masanori", ""]]}, {"id": "1905.11724", "submitter": "Elahe Ghalebi", "authors": "Elahe Ghalebi, Hamidreza Mahyar, Radu Grosu, Graham W. Taylor, Sinead\n  A. Williamson", "title": "Sequential Edge Clustering in Temporal Multigraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction graphs, such as those recording emails between individuals or\ntransactions between institutions, tend to be sparse yet structured, and often\ngrow in an unbounded manner. Such behavior can be well-captured by structured,\nnonparametric edge-exchangeable graphs. However, such exchangeable models\nnecessarily ignore temporal dynamics in the network. We propose a dynamic\nnonparametric model for interaction graphs that combine the sparsity of the\nexchangeable models with dynamic clustering patterns that tend to reinforce\nrecent behavioral patterns. We show that our method yields improved held-out\nlikelihood over stationary variants, and impressive predictive performance\nagainst a range of state-of-the-art dynamic interaction graph models.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:20:02 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 14:50:13 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 10:56:14 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ghalebi", "Elahe", ""], ["Mahyar", "Hamidreza", ""], ["Grosu", "Radu", ""], ["Taylor", "Graham W.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "1905.11741", "submitter": "Yigit Ugur", "authors": "Yigit Ugur, George Arvanitakis, Abdellatif Zaidi", "title": "Variational Information Bottleneck for Unsupervised Clustering: Deep\n  Gaussian Mixture Embedding", "comments": "accepted for publication in Entropy, Special Issue on Information\n  Theory for Data Communications and Processing", "journal-ref": null, "doi": "10.3390/e22020213", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an unsupervised generative clustering framework\nthat combines the Variational Information Bottleneck and the Gaussian Mixture\nModel. Specifically, in our approach, we use the Variational Information\nBottleneck method and model the latent space as a mixture of Gaussians. We\nderive a bound on the cost function of our model that generalizes the Evidence\nLower Bound (ELBO) and provide a variational inference type algorithm that\nallows computing it. In the algorithm, the coders' mappings are parametrized\nusing neural networks, and the bound is approximated by Monte Carlo sampling\nand optimized with stochastic gradient descent. Numerical results on real\ndatasets are provided to support the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:15:59 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 11:41:24 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 05:49:25 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ugur", "Yigit", ""], ["Arvanitakis", "George", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "1905.11742", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Overlearning Reveals Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Overlearning\" means that a model trained for a seemingly simple objective\nimplicitly learns to recognize attributes and concepts that are (1) not part of\nthe learning objective, and (2) sensitive from a privacy or bias perspective.\nFor example, a binary gender classifier of facial images also learns to\nrecognize races\\textemdash even races that are not represented in the training\ndata\\textemdash and identities.\n  We demonstrate overlearning in several vision and NLP models and analyze its\nharmful consequences. First, inference-time representations of an overlearned\nmodel reveal sensitive attributes of the input, breaking privacy protections\nsuch as model partitioning. Second, an overlearned model can be \"re-purposed\"\nfor a different, privacy-violating task even in the absence of the original\ntraining data.\n  We show that overlearning is intrinsic for some tasks and cannot be prevented\nby censoring unwanted attributes. Finally, we investigate where, when, and why\noverlearning happens during model training.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:16:02 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 20:01:43 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 23:45:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1905.11744", "submitter": "Luis Torgo", "authors": "Vitor Cerqueira and Luis Torgo and Igor Mozetic", "title": "Evaluating time series forecasting models: An empirical study on\n  performance estimation methods", "comments": null, "journal-ref": "Machine Learning 109:1997-2028", "doi": "10.1007/s10994-020-05910-7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance estimation aims at estimating the loss that a predictive model\nwill incur on unseen data. These procedures are part of the pipeline in every\nmachine learning project and are used for assessing the overall generalisation\nability of predictive models. In this paper we address the application of these\nmethods to time series forecasting tasks. For independent and identically\ndistributed data the most common approach is cross-validation. However, the\ndependency among observations in time series raises some caveats about the most\nappropriate way to estimate performance in this type of data and currently\nthere is no settled way to do so. We compare different variants of\ncross-validation and of out-of-sample approaches using two case studies: One\nwith 62 real-world time series and another with three synthetic time series.\nResults show noticeable differences in the performance estimation methods in\nthe two scenarios. In particular, empirical experiments suggest that\ncross-validation approaches can be applied to stationary time series. However,\nin real-world scenarios, when different sources of non-stationary variation are\nat play, the most accurate estimates are produced by out-of-sample methods that\npreserve the temporal order of observations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:16:20 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Mozetic", "Igor", ""]]}, {"id": "1905.11757", "submitter": "Simon D. Duque Anton", "authors": "Simon Duque Anton, Suneetha Kanoor, Daniel Fraunholz, and Hans Dieter\n  Schotten", "title": "Evaluation of Machine Learning-based Anomaly Detection Algorithms on an\n  Industrial Modbus/TCP Data Set", "comments": "This is a preprint of a work published in the Proceedings of the 13th\n  International Conference on Availability, Reliability and Security (ARES\n  2018)", "journal-ref": null, "doi": "10.1145/3230833.3232818", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Industrial Internet of Things, communication\ntechnology, originally used in home and office environments, is introduced into\nindustrial applications. Commercial off-the-shelf products, as well as unified\nand well-established communication protocols make this technology easy to\nintegrate and use. Furthermore, productivity is increased in comparison to\nclassic industrial control by making systems easier to manage, set up and\nconfigure. Unfortunately, most attack surfaces of home and office environments\nare introduced into industrial applications as well, which usually have very\nfew security mechanisms in place. Over the last years, several technologies\ntackling that issue have been researched. In this work, machine learning-based\nanomaly detection algorithms are employed to find malicious traffic in a\nsynthetically generated data set of Modbus/TCP communication of a fictitious\nindustrial scenario. The applied algorithms are Support Vector Machine (SVM),\nRandom Forest, k-nearest neighbour and k-means clustering. Due to the synthetic\ndata set, supervised learning is possible. Support Vector Machine and k-nearest\nneighbour perform well with different data sets, while k-nearest neighbour and\nk-means clustering do not perform satisfactorily.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:52:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Anton", "Simon Duque", ""], ["Kanoor", "Suneetha", ""], ["Fraunholz", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.11759", "submitter": "Jiarui Gan", "authors": "Jiarui Gan, Qingyu Guo, Long Tran-Thanh, Bo An, Michael Wooldridge", "title": "Manipulating a Learning Defender and Ways to Counteract", "comments": "The paper appears in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Stackelberg security games when information about the attacker's payoffs\nis uncertain, algorithms have been proposed to learn the optimal defender\ncommitment by interacting with the attacker and observing their best responses.\nIn this paper, we show that, however, these algorithms can be easily\nmanipulated if the attacker responds untruthfully. As a key finding, attacker\nmanipulation normally leads to the defender learning a maximin strategy, which\neffectively renders the learning attempt meaningless as to compute a maximin\nstrategy requires no additional information about the other player at all. We\nthen apply a game-theoretic framework at a higher level to counteract such\nmanipulation, in which the defender commits to a policy that specifies her\nstrategy commitment according to the learned information. We provide a\npolynomial-time algorithm to compute the optimal such policy, and in addition,\na heuristic approach that applies even when the attacker's payoff space is\ninfinite or completely unknown. Empirical evaluation shows that our approaches\ncan improve the defender's utility significantly as compared to the situation\nwhen attacker manipulation is ignored.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:06:56 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 01:30:26 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Gan", "Jiarui", ""], ["Guo", "Qingyu", ""], ["Tran-Thanh", "Long", ""], ["An", "Bo", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1905.11760", "submitter": "Verena Haunschmid", "authors": "Verena Haunschmid, Shreyan Chowdhury, Gerhard Widmer", "title": "Two-level Explanations in Music Emotion Recognition", "comments": "ML4MD Workshop of the 36th International Conference on Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current ML models for music emotion recognition, while generally working\nquite well, do not give meaningful or intuitive explanations for their\npredictions. In this work, we propose a 2-step procedure to arrive at\nspectrogram-level explanations that connect certain aspects of the audio to\ninterpretable mid-level perceptual features, and these to the actual emotion\nprediction. That makes it possible to focus on specific musical reasons for a\nprediction (in terms of perceptual features), and to trace these back to\npatterns in the audio that can be interpreted visually and acoustically.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:08:54 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Haunschmid", "Verena", ""], ["Chowdhury", "Shreyan", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1905.11765", "submitter": "Brian Reich", "authors": "Neal S. Grantham, Brian J. Reich, Eric B. Laber, Krishna Pacifici,\n  Robert R. Dunn, Noah Fierer, Matthew Gebert, Julia S. Allwood, Seth A. Faith", "title": "Global forensic geolocation with deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in forensic analyses is identifying the provenance of\nmaterials at a crime scene, such as biological material on a piece of clothing.\nThis procedure, known as geolocation, is conventionally guided by expert\nknowledge of the biological evidence and therefore tends to be\napplication-specific, labor-intensive, and subjective. Purely data-driven\nmethods have yet to be fully realized due in part to the lack of a sufficiently\nrich data source. However, high-throughput sequencing technologies are able to\nidentify tens of thousands of microbial taxa using DNA recovered from a single\nswab collected from nearly any object or surface. We present a new algorithm\nfor geolocation that aggregates over an ensemble of deep neural network\nclassifiers trained on randomly-generated Voronoi partitions of a spatial\ndomain. We apply the algorithm to fungi present in each of 1300 dust samples\ncollected across the continental United States and then to a global dataset of\ndust samples from 28 countries. Our algorithm makes remarkably good point\npredictions with more than half of the geolocation errors under 100 kilometers\nfor the continental analysis and nearly 90% classification accuracy of a\nsample's country of origin for the global analysis. We suggest that the\neffectiveness of this model sets the stage for a new, quantitative approach to\nforensic geolocation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:24:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Grantham", "Neal S.", ""], ["Reich", "Brian J.", ""], ["Laber", "Eric B.", ""], ["Pacifici", "Krishna", ""], ["Dunn", "Robert R.", ""], ["Fierer", "Noah", ""], ["Gebert", "Matthew", ""], ["Allwood", "Julia S.", ""], ["Faith", "Seth A.", ""]]}, {"id": "1905.11768", "submitter": "Adil Salim", "authors": "Adil Salim, Dmitry Kovalev, Peter Richt\\'arik", "title": "Stochastic Proximal Langevin Algorithm: Potential Splitting and\n  Nonasymptotic Rates", "comments": null, "journal-ref": "Neurips 2019 (Spotlight)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm---Stochastic Proximal Langevin Algorithm\n(SPLA)---for sampling from a log concave distribution. Our method is a\ngeneralization of the Langevin algorithm to potentials expressed as the sum of\none stochastic smooth term and multiple stochastic nonsmooth terms. In each\niteration, our splitting technique only requires access to a stochastic\ngradient of the smooth term and a stochastic proximal operator for each of the\nnonsmooth terms. We establish nonasymptotic sublinear and linear convergence\nrates under convexity and strong convexity of the smooth term, respectively,\nexpressed in terms of the KL divergence and Wasserstein distance. We illustrate\nthe efficiency of our sampling technique through numerical simulations on a\nBayesian learning task.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:28:31 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:09:42 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Salim", "Adil", ""], ["Kovalev", "Dmitry", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.11769", "submitter": "Purushottam Kar", "authors": "Ankit Jalan and Purushottam Kar", "title": "Accelerating Extreme Classification via Adaptive Feature Agglomeration", "comments": "A version of this paper without the appendices will appear at the\n  28th International Joint Conference on Artificial Intelligence (IJCAI 2019).\n  Code for this paper is available at https://github.com/purushottamkar/defrag/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme classification seeks to assign each data point, the most relevant\nlabels from a universe of a million or more labels. This task is faced with the\ndual challenge of high precision and scalability, with millisecond level\nprediction times being a benchmark. We propose DEFRAG, an adaptive feature\nagglomeration technique to accelerate extreme classification algorithms.\nDespite past works on feature clustering and selection, DEFRAG distinguishes\nitself in being able to scale to millions of features, and is especially\nbeneficial when feature sets are sparse, which is typical of recommendation and\nmulti-label datasets. The method comes with provable performance guarantees and\nperforms efficient task-driven agglomeration to reduce feature dimensionalities\nby an order of magnitude or more. Experiments show that DEFRAG can not only\nreduce training and prediction times of several leading extreme classification\nalgorithms by as much as 40%, but also be used for feature reconstruction to\naddress the problem of missing features, as well as offer superior coverage on\nrare labels.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:30:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Jalan", "Ankit", ""], ["Kar", "Purushottam", ""]]}, {"id": "1905.11775", "submitter": "Pekka Siirtola", "authors": "Pekka Siirtola, Heli Koskim\\\"aki, Juha R\\\"oning", "title": "Importance of user inputs while using incremental learning to\n  personalize human activity recognition models", "comments": "European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN) 2019, pages 449-454", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, importance of user inputs is studied in the context of\npersonalizing human activity recognition models using incremental learning.\nInertial sensor data from three body positions are used, and the classification\nis based on Learn++ ensemble method. Three different approaches to update\nmodels are compared: non-supervised, semi-supervised and supervised.\nNon-supervised approach relies fully on predicted labels, supervised fully on\nuser labeled data, and the proposed method for semi-supervised learning, is a\ncombination of these two. In fact, our experiments show that by relying on\npredicted labels with high confidence, and asking the user to label only\nuncertain observations (from 12% to 26% of the observations depending on the\nused base classifier), almost as low error rates can be achieved as by using\nsupervised approach. In fact, the difference was less than 2%-units. Moreover,\nunlike non-supervised approach, semi-supervised approach does not suffer from\ndrastic concept drift, and thus, the error rate of the non-supervised approach\nis over 5%-units higher than using semi-supervised approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:41:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Siirtola", "Pekka", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "1905.11780", "submitter": "Pekka Siirtola", "authors": "Pekka Siirtola, Jukka Komulainen, Vili Kellokumpu", "title": "Effect of context in swipe gesture-based continuous authentication on\n  smartphones", "comments": "European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN) 2018, pages 639-644", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates how context should be taken into account when\nperforming continuous authentication of a smartphone user based on touchscreen\nand accelerometer readings extracted from swipe gestures. The study is\nconducted on the publicly available HMOG dataset consisting of 100 study\nsubjects performing pre-defined reading and navigation tasks while sitting and\nwalking. It is shown that context-specific models are needed for different\nsmartphone usage and human activity scenarios to minimize authentication error.\nAlso, the experimental results suggests that utilization of phone movement\nimproves swipe gesture-based verification performance only when the user is\nmoving.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:49:55 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Siirtola", "Pekka", ""], ["Komulainen", "Jukka", ""], ["Kellokumpu", "Vili", ""]]}, {"id": "1905.11786", "submitter": "Sindy L\\\"owe", "authors": "Sindy L\\\"owe, Peter O'Connor, Bastiaan S. Veeling", "title": "Putting An End to End-to-End: Gradient-Isolated Learning of\n  Representations", "comments": "Honorable Mention for Outstanding New Directions Paper Award at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning method for local self-supervised\nrepresentation learning that does not require labels nor end-to-end\nbackpropagation but exploits the natural order in data instead. Inspired by the\nobservation that biological neural networks appear to learn without\nbackpropagating a global error signal, we split a deep neural network into a\nstack of gradient-isolated modules. Each module is trained to maximally\npreserve the information of its inputs using the InfoNCE bound from Oord et al.\n[2018]. Despite this greedy training, we demonstrate that each module improves\nupon the output of its predecessor, and that the representations created by the\ntop module yield highly competitive results on downstream classification tasks\nin the audio and visual domain. The proposal enables optimizing modules\nasynchronously, allowing large-scale distributed training of very deep neural\nnetworks on unlabelled datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:00:46 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 15:33:41 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 12:34:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["L\u00f6we", "Sindy", ""], ["O'Connor", "Peter", ""], ["Veeling", "Bastiaan S.", ""]]}, {"id": "1905.11796", "submitter": "Marco Tagliasacchi", "authors": "Marco Tagliasacchi, Beat Gfeller, F\\'elix de Chaumont Quitry, Dominik\n  Roblek", "title": "Self-supervised audio representation learning for mobile devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore self-supervised models that can be potentially deployed on mobile\ndevices to learn general purpose audio representations. Specifically, we\npropose methods that exploit the temporal context in the spectrogram domain.\nOne method estimates the temporal gap between two short audio segments\nextracted at random from the same audio clip. The other methods are inspired by\nWord2Vec, a popular technique used to learn word embeddings, and aim at\nreconstructing a temporal spectrogram slice from past and future slices or,\nalternatively, at reconstructing the context of surrounding slices from the\ncurrent slice. We focus our evaluation on small encoder architectures, which\ncan be potentially run on mobile devices during both inference (re-using a\ncommon learned representation across multiple downstream tasks) and training\n(capturing the true data distribution without compromising users' privacy when\ncombined with federated learning). We evaluate the quality of the embeddings\nproduced by the self-supervised learning models, and show that they can be\nre-used for a variety of downstream tasks, and for some tasks even approach the\nperformance of fully supervised models of similar size.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:57:40 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Tagliasacchi", "Marco", ""], ["Gfeller", "Beat", ""], ["Quitry", "F\u00e9lix de Chaumont", ""], ["Roblek", "Dominik", ""]]}, {"id": "1905.11797", "submitter": "Tommaso Cesari", "authors": "Nicol\\`o Cesa-Bianchi, Tommaso R. Cesari, Yishay Mansour, Vianney\n  Perchet", "title": "A New Theoretical Framework for Fast and Accurate Online Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel theoretical framework for Return On Investment (ROI)\nmaximization in repeated decision-making. Our setting is motivated by the use\ncase of companies that regularly receive proposals for technological\ninnovations and want to quickly decide whether they are worth implementing. We\ndesign an algorithm for learning ROI-maximizing decision-making policies over a\nsequence of innovation proposals. Our algorithm provably converges to an\noptimal policy in class $\\Pi$ at a rate of order\n$\\min\\big\\{1/(N\\Delta^2),N^{-1/3}\\}$, where $N$ is the number of innovations\nand $\\Delta$ is the suboptimality gap in $\\Pi$. A significant hurdle of our\nformulation, which sets it aside from other online learning problems such as\nbandits, is that running a policy does not provide an unbiased estimate of its\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:24:47 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 10:18:59 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 16:11:02 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 18:12:51 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 19:52:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", ""], ["Cesari", "Tommaso R.", ""], ["Mansour", "Yishay", ""], ["Perchet", "Vianney", ""]]}, {"id": "1905.11804", "submitter": "Haytham Elmousalami", "authors": "Haytham H. Elmousalami", "title": "Prediction of Construction Cost for Field Canals Improvement Projects in\n  Egypt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field canals improvement projects (FCIPs) are one of the ambitious projects\nconstructed to save fresh water. To finance this project, Conceptual cost\nmodels are important to accurately predict preliminary costs at the early\nstages of the project. The first step is to develop a conceptual cost model to\nidentify key cost drivers affecting the project. Therefore, input variables\nselection remains an important part of model development, as the poor variables\nselection can decrease model precision. The study discovered the most important\ndrivers of FCIPs based on a qualitative approach and a quantitative approach.\nSubsequently, the study has developed a parametric cost model based on machine\nlearning methods such as regression methods, artificial neural networks, fuzzy\nmodel and case-based reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 00:33:54 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Elmousalami", "Haytham H.", ""]]}, {"id": "1905.11814", "submitter": "FatemehSadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Prakash Ramrakhyani,\n  Dean Tullsen, Hadi Esmaeilzadeh", "title": "Shredder: Learning Noise Distributions to Protect Inference Privacy", "comments": "Presented in ASPLOS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep neural applications increasingly rely on the cloud to\nperform their compute-heavy inference. This common practice requires sending\nprivate and privileged data over the network to remote servers, exposing it to\nthe service provider and potentially compromising its privacy. Even if the\nprovider is trusted, the data can still be vulnerable over communication\nchannels or via side-channel attacks in the cloud. To that end, this paper aims\nto reduce the information content of the communicated data with as little as\npossible compromise on the inference accuracy by making the sent data noisy. An\nundisciplined addition of noise can significantly reduce the accuracy of\ninference, rendering the service unusable. To address this challenge, this\npaper devises Shredder, an end-to-end framework, that, without altering the\ntopology or the weights of a pre-trained network, learns additive noise\ndistributions that significantly reduce the information content of communicated\ndata while maintaining the inference accuracy. The key idea is finding the\nadditive noise distributions by casting it as a disjoint offline learning\nprocess with a loss function that strikes a balance between accuracy and\ninformation degradation. The loss function also exposes a knob for a\ndisciplined and controlled asymmetric trade-off between privacy and accuracy.\nExperimentation with six real-world DNNs from text processing and image\nclassification shows that Shredder reduces the mutual information between the\ninput and the communicated data to the cloud by 74.70% compared to the original\nexecution while only sacrificing 1.58% loss in accuracy. On average, Shredder\nalso offers a speedup of 1.79x over Wi-Fi and 2.17x over LTE compared to\ncloud-only execution when using an off-the-shelf mobile GPU (Tegra X2) on the\nedge.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:59:34 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 16:20:44 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 23:12:58 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Ramrakhyani", "Prakash", ""], ["Tullsen", "Dean", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1905.11817", "submitter": "Julian Zimmert", "authors": "Julian Zimmert and Tor Lattimore", "title": "Connections Between Mirror Descent, Thompson Sampling and the\n  Information Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information-theoretic analysis by Russo and Van Roy (2014) in combination\nwith minimax duality has proved a powerful tool for the analysis of online\nlearning algorithms in full and partial information settings. In most\napplications there is a tantalising similarity to the classical analysis based\non mirror descent. We make a formal connection, showing that the\ninformation-theoretic bounds in most applications can be derived from existing\ntechniques for online convex optimisation. Besides this, for $k$-armed\nadversarial bandits we provide an efficient algorithm with regret that matches\nthe best information-theoretic upper bound and improve best known regret\nguarantees for online linear optimisation on $\\ell_p$-balls and bandits with\ngraph feedback.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:53:30 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zimmert", "Julian", ""], ["Lattimore", "Tor", ""]]}, {"id": "1905.11824", "submitter": "Soham Deshmukh", "authors": "Soham Deshmukh, Rahul Rade, Dr. Faruk Kazi", "title": "Attacker Behaviour Profiling using Stochastic Ensemble of Hidden Markov\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber threat intelligence is one of the emerging areas of focus in\ninformation security. Much of the recent work has focused on rule-based methods\nand detection of network attacks using Intrusion Detection algorithms. In this\npaper we propose a framework for inspecting and modelling the behavioural\naspect of an attacker to obtain better insight predictive power on his future\nactions. For modelling we propose a novel semi-supervised algorithm called\nFusion Hidden Markov Model (FHMM) which is more robust to noise, requires\ncomparatively less training time, and utilizes the benefits of ensemble\nlearning to better model temporal relationships in data. This paper evaluates\nthe performances of FHMM and compares it with both traditional algorithms like\nMarkov Chain, Hidden Markov Model (HMM) and recently developed Deep Recurrent\nNeural Network (Deep RNN) architectures. We conduct the experiments on dataset\nconsisting of real data attacks on a Cowrie honeypot system. FHMM provides\naccuracy comparable to deep RNN architectures at significant lower training\ntime. Given these experimental results, we recommend using FHMM for modelling\ndiscrete temporal data for significantly faster training and better performance\nthan existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:56:44 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 19:56:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Deshmukh", "Soham", ""], ["Rade", "Rahul", ""], ["Kazi", "Dr. Faruk", ""]]}, {"id": "1905.11825", "submitter": "Artem Maevskiy", "authors": "Artem Maevskiy, Denis Derkach, Nikita Kazeev, Andrey Ustyuzhanin,\n  Maksim Artemev, Lucio Anderlini", "title": "Fast Data-Driven Simulation of Cherenkov Detectors Using Generative\n  Adversarial Networks", "comments": "Proceedings for 19th International Workshop on Advanced Computing and\n  Analysis Techniques in Physics Research. (Fixed typos and added one missing\n  reference in the revised version.)", "journal-ref": "J. Phys.: Conf. Ser. 1525 012097 (2020)", "doi": "10.1088/1742-6596/1525/1/012097", "report-no": null, "categories": "physics.ins-det cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing luminosities of future Large Hadron Collider runs and next\ngeneration of collider experiments will require an unprecedented amount of\nsimulated events to be produced. Such large scale productions are extremely\ndemanding in terms of computing resources. Thus new approaches to event\ngeneration and simulation of detector responses are needed. In LHCb, the\naccurate simulation of Cherenkov detectors takes a sizeable fraction of CPU\ntime. An alternative approach is described here, when one generates high-level\nreconstructed observables using a generative neural network to bypass low level\ndetails. This network is trained to reproduce the particle species likelihood\nfunction values based on the track kinematic parameters and detector occupancy.\nThe fast simulation is trained using real data samples collected by LHCb during\nrun 2. We demonstrate that this approach provides high-fidelity results.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:03:24 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 11:06:55 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Maevskiy", "Artem", ""], ["Derkach", "Denis", ""], ["Kazeev", "Nikita", ""], ["Ustyuzhanin", "Andrey", ""], ["Artemev", "Maksim", ""], ["Anderlini", "Lucio", ""]]}, {"id": "1905.11830", "submitter": "Nathaniel Lahn", "authors": "Nathaniel Lahn, Deepika Mulchandani, Sharath Raghvendra", "title": "A Graph Theoretic Additive Approximation of Optimal Transport", "comments": "Final version to appear in NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation cost is an attractive similarity measure between probability\ndistributions due to its many useful theoretical properties. However, solving\noptimal transport exactly can be prohibitively expensive. Therefore, there has\nbeen significant effort towards the design of scalable approximation\nalgorithms. Previous combinatorial results [Sharathkumar, Agarwal STOC '12,\nAgarwal, Sharathkumar STOC '14] have focused primarily on the design of\nnear-linear time multiplicative approximation algorithms. There has also been\nan effort to design approximate solutions with additive errors [Cuturi NIPS\n'13, Altschuler \\etal\\ NIPS '17, Dvurechensky \\etal\\, ICML '18, Quanrud, SOSA\n'19] within a time bound that is linear in the size of the cost matrix and\npolynomial in $C/\\delta$; here $C$ is the largest value in the cost matrix and\n$\\delta$ is the additive error. We present an adaptation of the classical graph\nalgorithm of Gabow and Tarjan and provide a novel analysis of this algorithm\nthat bounds its execution time by $O(\\frac{n^2 C}{\\delta}+\n\\frac{nC^2}{\\delta^2})$. Our algorithm is extremely simple and executes, for an\narbitrarily small constant $\\varepsilon$, only $\\lfloor\n\\frac{2C}{(1-\\varepsilon)\\delta}\\rfloor + 1$ iterations, where each iteration\nconsists only of a Dijkstra-type search followed by a depth-first search. We\nalso provide empirical results that suggest our algorithm is competitive with\nrespect to a sequential implementation of the Sinkhorn algorithm in execution\ntime. Moreover, our algorithm quickly computes a solution for very small values\nof $\\delta$ whereas Sinkhorn algorithm slows down due to numerical instability.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:08:27 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 16:04:16 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 18:06:04 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lahn", "Nathaniel", ""], ["Mulchandani", "Deepika", ""], ["Raghvendra", "Sharath", ""]]}, {"id": "1905.11831", "submitter": "Yi Xiang Marcus Tan", "authors": "Yi Xiang Marcus Tan, Alfonso Iacovazzi, Ivan Homoliak, Yuval Elovici,\n  Alexander Binder", "title": "Adversarial Attacks on Remote User Authentication Using Behavioural\n  Mouse Dynamics", "comments": "Accepted in 2019 International Joint Conference on Neural Networks\n  (IJCNN). Update of DOI", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852414", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mouse dynamics is a potential means of authenticating users. Typically, the\nauthentication process is based on classical machine learning techniques, but\nrecently, deep learning techniques have been introduced for this purpose.\nAlthough prior research has demonstrated how machine learning and deep learning\nalgorithms can be bypassed by carefully crafted adversarial samples, there has\nbeen very little research performed on the topic of behavioural biometrics in\nthe adversarial domain. In an attempt to address this gap, we built a set of\nattacks, which are applications of several generative approaches, to construct\nadversarial mouse trajectories that bypass authentication models. These\ngenerated mouse sequences will serve as the adversarial samples in the context\nof our experiments. We also present an analysis of the attack approaches we\nexplored, explaining their limitations. In contrast to previous work, we\nconsider the attacks in a more realistic and challenging setting in which an\nattacker has access to recorded user data but does not have access to the\nauthentication model or its outputs. We explore three different attack\nstrategies: 1) statistics-based, 2) imitation-based, and 3) surrogate-based; we\nshow that they are able to evade the functionality of the authentication\nmodels, thereby impacting their robustness adversely. We show that\nimitation-based attacks often perform better than surrogate-based attacks,\nunless, however, the attacker can guess the architecture of the authentication\nmodel. In such cases, we propose a potential detection mechanism against\nsurrogate-based attacks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:09:15 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:30:01 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tan", "Yi Xiang Marcus", ""], ["Iacovazzi", "Alfonso", ""], ["Homoliak", "Ivan", ""], ["Elovici", "Yuval", ""], ["Binder", "Alexander", ""]]}, {"id": "1905.11832", "submitter": "Matthew Inkawhich", "authors": "Matthew Inkawhich, Yiran Chen, Hai Li", "title": "Snooping Attacks on Deep Reinforcement Learning", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have exposed a significant security vulnerability in\nstate-of-the-art machine learning models. Among these models include deep\nreinforcement learning agents. The existing methods for attacking reinforcement\nlearning agents assume the adversary either has access to the target agent's\nlearned parameters or the environment that the agent interacts with. In this\nwork, we propose a new class of threat models, called snooping threat models,\nthat are unique to reinforcement learning. In these snooping threat models, the\nadversary does not have the ability to interact with the target agent's\nenvironment, and can only eavesdrop on the action and reward signals being\nexchanged between agent and environment. We show that adversaries operating in\nthese highly constrained threat models can still launch devastating attacks\nagainst the target agent by training proxy models on related tasks and\nleveraging the transferability of adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:11:16 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 23:59:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Inkawhich", "Matthew", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1905.11833", "submitter": "Mariya Toneva", "authors": "Mariya Toneva and Leila Wehbe", "title": "Interpreting and improving natural-language processing (in machines)\n  with natural language-processing (in the brain)", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks models for NLP are typically implemented without the explicit\nencoding of language rules and yet they are able to break one performance\nrecord after another. This has generated a lot of research interest in\ninterpreting the representations learned by these networks. We propose here a\nnovel interpretation approach that relies on the only processing system we have\nthat does understand language: the human brain. We use brain imaging recordings\nof subjects reading complex natural text to interpret word and sequence\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\nstudy how their representations differ across layer depth, context length, and\nattention type. Our results reveal differences in the context-related\nrepresentations across these models. Further, in the transformer models, we\nfind an interaction between layer depth and context length, and between layer\ndepth and attention type. We finally hypothesize that altering BERT to better\nalign with brain recordings would enable it to also better understand language.\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\nincreased brain-alignment outperforms the original model. Cognitive\nneuroscientists have already begun using NLP networks to study the brain, and\nthis work closes the loop to allow the interaction between NLP and cognitive\nneuroscience to be a true cross-pollination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:13:09 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 14:52:22 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 17:40:56 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 16:25:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Toneva", "Mariya", ""], ["Wehbe", "Leila", ""]]}, {"id": "1905.11837", "submitter": "Chunmei Feng", "authors": "Chun-Mei Feng, Yong Xu, Jin-Xing Liu, Ying-Lian Gao, Chun-Hou Zheng", "title": "Supervised Discriminative Sparse PCA for Com-Characteristic Gene\n  Selection and Tumor Classification on Multiview Biological Data", "comments": "This paper has been published on TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) has been used to study the pathogenesis of\ndiseases. To enhance the interpretability of classical PCA, various improved\nPCA methods have been proposed to date. Among these, a typical method is the\nso-called sparse PCA, which focuses on seeking sparse loadings. However, the\nperformance of these methods is still far from satisfactory due to their\nlimitation of using unsupervised learning methods; moreover, the class\nambiguity within the sample is high. To overcome this problem, this study\ndeveloped a new PCA method, which is named the Supervised Discriminative Sparse\nPCA (SDSPCA). The main innovation of this method is the incorporation of\ndiscriminative information and sparsity into the PCA model. Specifically, in\ncontrast to the traditional sparse PCA, which imposes sparsity on the loadings,\nhere, sparse components are obtained to represent the data. Furthermore, via\nlinear transformation, the sparse components approximate the given label\ninformation. On the one hand, sparse components improve interpretability over\ntraditional PCA, while on the other hand, they are have discriminative\nabilities suitable for classification purposes. A simple algorithm is developed\nand its convergence proof is provided. The SDSPCA has been applied to common\ncharacteristic gene selection (com-characteristic gene) and tumor\nclassification on multi-view biological data. The sparsity and classification\nperformance of the SDSPCA are empirically verified via abundant, reasonable,\nand effective experiments, and the obtained results demonstrate that SDSPCA\noutperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:18:15 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Feng", "Chun-Mei", ""], ["Xu", "Yong", ""], ["Liu", "Jin-Xing", ""], ["Gao", "Ying-Lian", ""], ["Zheng", "Chun-Hou", ""]]}, {"id": "1905.11852", "submitter": "Diane Bouchacourt", "authors": "Diane Bouchacourt and Ludovic Denoyer", "title": "EDUCE: Explaining model Decisions through Unsupervised Concepts\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing explanations along with predictions is crucial in some text\nprocessing tasks. Therefore, we propose a new self-interpretable model that\nperforms output prediction and simultaneously provides an explanation in terms\nof the presence of particular concepts in the input. To do so, our model's\nprediction relies solely on a low-dimensional binary representation of the\ninput, where each feature denotes the presence or absence of concepts. The\npresence of a concept is decided from an excerpt i.e. a small sequence of\nconsecutive words in the text. Relevant concepts for the prediction task at\nhand are automatically defined by our model, avoiding the need for\nconcept-level annotations. To ease interpretability, we enforce that for each\nconcept, the corresponding excerpts share similar semantics and are\ndifferentiable from each others. We experimentally demonstrate the relevance of\nour approach on text classification and multi-sentiment analysis tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:33:19 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 14:16:30 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1905.11858", "submitter": "Maximilian Arnold", "authors": "Mark Widmaier, Maximilian Arnold, Sebastian D\\\"orner, Sebastian\n  Cammerer, and Stephan ten Brink", "title": "Towards Practical Indoor Positioning Based on Massive MIMO Systems", "comments": "Submitted to VTC2019 Fall", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showcase the practicability of an indoor positioning system (IPS) solely\nbased on Neural Networks (NNs) and the channel state information (CSI) of a\n(Massive) multiple-input multiple-output (MIMO) communication system, i.e.,\nonly build on the basis of data that is already existent in today's systems. As\nsuch our IPS system promises both, a good accuracy without the need of any\nadditional protocol/signaling overhead for the user localization task. In\nparticular, we propose a tailored NN structure with an additional phase branch\nas feature extractor and (compared to previous results) a significantly reduced\namount of trainable parameters, leading to a minimization of the amount of\nrequired training data. We provide actual measurements for indoor scenarios\nwith up to 64 antennas covering a large area of 80m2. In the second part,\nseveral robustness investigations for real-measurements are conducted, i.e.,\nonce trained, we analyze the recall accuracy over a time-period of several\ndays. Further, we analyze the impact of pedestrians walking in-between the\nmeasurements and show that finetuning and pre-training of the NN helps to\nmitigate effects of hardware drifts and alterations in the propagation\nenvironment over time. This reduces the amount of required training samples at\nequal precision and, thereby, decreases the effort of the costly training data\nacquisition\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:42:53 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Widmaier", "Mark", ""], ["Arnold", "Maximilian", ""], ["D\u00f6rner", "Sebastian", ""], ["Cammerer", "Sebastian", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1905.11862", "submitter": "Peixian Chen", "authors": "Peixian Chen, Pingyang Dai, Qiong Wu, Yuyu Huang", "title": "Video-based Person Re-identification with Two-stream Convolutional\n  Network and Co-attentive Snippet Embedding", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the applications of person re-identification in visual surveillance\nand human-computer interaction are sharply increasing, which signifies the\ncritical role of such a problem. In this paper, we propose a two-stream\nconvolutional network (ConvNet) based on the competitive similarity aggregation\nscheme and co-attentive embedding strategy for video-based person\nre-identification. By dividing the long video sequence into multiple short\nvideo snippets, we manage to utilize every snippet's RGB frames, optical flow\nmaps and pose maps to facilitate residual networks, e.g., ResNet, for feature\nextraction in the two-stream ConvNet. The extracted features are embedded by\nthe co-attentive embedding method, which allows for the reduction of the\neffects of noisy frames. Finally, we fuse the outputs of both streams as the\nembedding of a snippet, and apply competitive snippet-similarity aggregation to\nmeasure the similarity between two sequences. Our experiments show that the\nproposed method significantly outperforms current state-of-the-art approaches\non multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:47:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Chen", "Peixian", ""], ["Dai", "Pingyang", ""], ["Wu", "Qiong", ""], ["Huang", "Yuyu", ""]]}, {"id": "1905.11866", "submitter": "Christina G\\\"opfert", "authors": "Christina G\\\"opfert, Shai Ben-David, Olivier Bousquet, Sylvain Gelly,\n  Ilya Tolstikhin and Ruth Urner", "title": "When can unlabeled data improve the learning rate?", "comments": null, "journal-ref": "Proceedings of the Thirty-Second Conference on Learning Theory,\n  PMLR 99:1500-1518, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised classification, one is given access both to labeled and\nunlabeled data. As unlabeled data is typically cheaper to acquire than labeled\ndata, this setup becomes advantageous as soon as one can exploit the unlabeled\ndata in order to produce a better classifier than with labeled data alone.\nHowever, the conditions under which such an improvement is possible are not\nfully understood yet. Our analysis focuses on improvements in the minimax\nlearning rate in terms of the number of labeled examples (with the number of\nunlabeled examples being allowed to depend on the number of labeled ones). We\nargue that for such improvements to be realistic and indisputable, certain\nspecific conditions should be satisfied and previous analyses have failed to\nmeet those conditions. We then demonstrate examples where these conditions can\nbe met, in particular showing rate changes from $1/\\sqrt{\\ell}$ to $e^{-c\\ell}$\nand from $1/\\sqrt{\\ell}$ to $1/\\ell$. These results improve our understanding\nof what is and isn't possible in semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:58:00 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["G\u00f6pfert", "Christina", ""], ["Ben-David", "Shai", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Tolstikhin", "Ilya", ""], ["Urner", "Ruth", ""]]}, {"id": "1905.11867", "submitter": "Adish Singla", "authors": "Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, Adish Singla", "title": "Interactive Teaching Algorithms for Inverse Reinforcement Learning", "comments": "IJCAI'19 paper (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inverse reinforcement learning (IRL) with the added\ntwist that the learner is assisted by a helpful teacher. More formally, we\ntackle the following algorithmic question: How could a teacher provide an\ninformative sequence of demonstrations to an IRL learner to speed up the\nlearning process? We present an interactive teaching framework where a teacher\nadaptively chooses the next demonstration based on learner's current policy. In\nparticular, we design teaching algorithms for two concrete settings: an\nomniscient setting where a teacher has full knowledge about the learner's\ndynamics and a blackbox setting where the teacher has minimal knowledge. Then,\nwe study a sequential variant of the popular MCE-IRL learner and prove\nconvergence guarantees of our teaching algorithm in the omniscient setting.\nExtensive experiments with a car driving simulator environment show that the\nlearning progress can be speeded up drastically as compared to an uninformative\nteacher.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:03:14 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 16:26:55 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 21:51:13 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Devidze", "Rati", ""], ["Cevher", "Volkan", ""], ["Singla", "Adish", ""]]}, {"id": "1905.11876", "submitter": "Arno Blaas", "authors": "Arno Blaas, Andrea Patane, Luca Laurenti, Luca Cardelli, Marta\n  Kwiatkowska, Stephen Roberts", "title": "Adversarial Robustness Guarantees for Classification with Gaussian\n  Processes", "comments": "10 pages, 6 figures + Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adversarial robustness of Gaussian Process Classification\n(GPC) models. Given a compact subset of the input space $T\\subseteq\n\\mathbb{R}^d$ enclosing a test point $x^*$ and a GPC trained on a dataset\n$\\mathcal{D}$, we aim to compute the minimum and the maximum classification\nprobability for the GPC over all the points in $T$. In order to do so, we show\nhow functions lower- and upper-bounding the GPC output in $T$ can be derived,\nand implement those in a branch and bound optimisation algorithm. For any error\nthreshold $\\epsilon > 0$ selected a priori, we show that our algorithm is\nguaranteed to reach values $\\epsilon$-close to the actual values in finitely\nmany iterations. We apply our method to investigate the robustness of GPC\nmodels on a 2D synthetic dataset, the SPAM dataset and a subset of the MNIST\ndataset, providing comparisons of different GPC training techniques, and show\nhow our method can be used for interpretability analysis. Our empirical\nanalysis suggests that GPC robustness increases with more accurate posterior\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:18:13 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 23:12:53 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 12:21:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Blaas", "Arno", ""], ["Patane", "Andrea", ""], ["Laurenti", "Luca", ""], ["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Roberts", "Stephen", ""]]}, {"id": "1905.11881", "submitter": "Jingzhao Zhang", "authors": "Jingzhao Zhang, Tianxing He, Suvrit Sra, Ali Jadbabaie", "title": "Why gradient clipping accelerates training: A theoretical justification\n  for adaptivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a theoretical explanation for the effectiveness of gradient\nclipping in training deep neural networks. The key ingredient is a new\nsmoothness condition derived from practical neural network training examples.\nWe observe that gradient smoothness, a concept central to the analysis of\nfirst-order optimization algorithms that is often assumed to be a constant,\ndemonstrates significant variability along the training trajectory of deep\nneural networks. Further, this smoothness positively correlates with the\ngradient norm, and contrary to standard assumptions in the literature, it can\ngrow with the norm of the gradient. These empirical observations limit the\napplicability of existing theoretical analyses of algorithms that rely on a\nfixed bound on smoothness. These observations motivate us to introduce a novel\nrelaxation of gradient smoothness that is weaker than the commonly used\nLipschitz smoothness assumption. Under the new condition, we prove that two\npopular methods, namely, \\emph{gradient clipping} and \\emph{normalized\ngradient}, converge arbitrarily faster than gradient descent with fixed\nstepsize. We further explain why such adaptively scaled gradient methods can\naccelerate empirical convergence and verify our results empirically in popular\nneural network training settings.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:23:12 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 22:58:53 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Jingzhao", ""], ["He", "Tianxing", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1905.11882", "submitter": "Gonzalo Mena E", "authors": "Gonzalo Mena, Jonathan Weed", "title": "Statistical bounds for entropic optimal transport: sample complexity and\n  the central limit theorem", "comments": "Under review. 23 pages, 2 figures. Version 2 fixes minor typos and\n  errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several fundamental statistical bounds for entropic OT with the\nsquared Euclidean cost between subgaussian probability measures in arbitrary\ndimension. First, through a new sample complexity result we establish the rate\nof convergence of entropic OT for empirical measures. Our analysis improves\nexponentially on the bound of Genevay et al. (2019) and extends their work to\nunbounded measures. Second, we establish a central limit theorem for entropic\nOT, based on techniques developed by Del Barrio and Loubes (2019). Previously,\nsuch a result was only known for finite metric spaces. As an application of our\nresults, we develop and analyze a new technique for estimating the entropy of a\nrandom variable corrupted by gaussian noise.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:23:37 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:42:36 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mena", "Gonzalo", ""], ["Weed", "Jonathan", ""]]}, {"id": "1905.11885", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, Olivier Teboul, Jean-Philippe Vert", "title": "Differentiable Ranks and Sorting using Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting an array is a fundamental routine in machine learning, one that is\nused to compute rank-based statistics, cumulative distribution functions\n(CDFs), quantiles, or to select closest neighbors and labels. The sorting\nfunction is however piece-wise constant (the sorting permutation of a vector\ndoes not change if the entries of that vector are infinitesimally perturbed)\nand therefore has no gradient information to back-propagate. We propose a\nframework to sort elements that is algorithmically differentiable. We leverage\nthe fact that sorting can be seen as a particular instance of the optimal\ntransport (OT) problem on $\\mathbb{R}$, from input values to a predefined array\nof sorted values (e.g. $1,2,\\dots,n$ if the input array has $n$ elements).\nBuilding upon this link , we propose generalized CDFs and quantile operators by\nvarying the size and weights of the target presorted array. Because this\namounts to using the so-called Kantorovich formulation of OT, we call these\nquantities K-sorts, K-CDFs and K-quantiles. We recover differentiable\nalgorithms by adding to the OT problem an entropic regularization, and\napproximate it using a few Sinkhorn iterations. We call these operators\nS-sorts, S-CDFs and S-quantiles, and use them in various learning settings: we\nbenchmark them against the recently proposed neuralsort [Grover et al. 2019],\npropose applications to quantile regression and introduce differentiable\nformulations of the top-k accuracy that deliver state-of-the art performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:28:07 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 15:18:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cuturi", "Marco", ""], ["Teboul", "Olivier", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1905.11887", "submitter": "Poorya Mianjy", "authors": "Poorya Mianjy and Raman Arora", "title": "On Dropout and Nuclear Norm Regularization", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:4575-4584, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formal and complete characterization of the explicit regularizer\ninduced by dropout in deep linear networks with squared loss. We show that (a)\nthe explicit regularizer is composed of an $\\ell_2$-path regularizer and other\nterms that are also re-scaling invariant, (b) the convex envelope of the\ninduced regularizer is the squared nuclear norm of the network map, and (c) for\na sufficiently large dropout rate, we characterize the global optima of the\ndropout objective. We validate our theoretical findings with empirical results.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:31:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Mianjy", "Poorya", ""], ["Arora", "Raman", ""]]}, {"id": "1905.11888", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Ziteng Sun", "title": "Communication Complexity in Locally Private Distribution Estimation and\n  Heavy Hitters", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of distribution estimation and heavy hitter\n(frequency) estimation under privacy and communication constraints. While these\nconstraints have been studied separately, optimal schemes for one are\nsub-optimal for the other. We propose a sample-optimal $\\varepsilon$-locally\ndifferentially private (LDP) scheme for distribution estimation, where each\nuser communicates only one bit, and requires no public randomness. We show that\nHadamard Response, a recently proposed scheme for $\\varepsilon$-LDP\ndistribution estimation is also utility-optimal for heavy hitter estimation.\nFinally, we show that unlike distribution estimation, without public randomness\nwhere only one bit suffices, any heavy hitter estimation algorithm that\ncommunicates $o(\\min \\{\\log n, \\log k\\})$ bits from each user cannot be\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:33:10 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""]]}, {"id": "1905.11890", "submitter": "Jan B\\'im", "authors": "V\\'aclav \\v{S}m\\'idl, Jan B\\'im, Tom\\'a\\v{s} Pevn\\'y", "title": "Anomaly scores for generative models", "comments": "9 pages, 3 figures, submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction error is a prevalent score used to identify anomalous samples\nwhen data are modeled by generative models, such as (variational) auto-encoders\nor generative adversarial networks. This score relies on the assumption that\nnormal samples are located on a manifold and all anomalous samples are located\noutside. Since the manifold can be learned only where the training data lie,\nthere are no guarantees how the reconstruction error behaves elsewhere and the\nscore, therefore, seems to be ill-defined. This work defines an anomaly score\nthat is theoretically compatible with generative models, and very natural for\n(variational) auto-encoders as they seem to be prevalent. The new score can be\nalso used to select hyper-parameters and models. Finally, we explain why\nreconstruction error delivers good experimental results despite weak\ntheoretical justification.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:35:39 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["\u0160m\u00eddl", "V\u00e1clav", ""], ["B\u00edm", "Jan", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "1905.11893", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Charlotte Pelletier, Maximilian Zollner, S\\'ebastien\n  Lef\\`evre, Marco K\\\"orner", "title": "BreizhCrops: A Time Series Dataset for Crop Type Mapping", "comments": "accepted to ISPRS Archives 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Breizhcrops, a novel benchmark dataset for the supervised\nclassification of field crops from satellite time series. We aggregated label\ndata and Sentinel-2 top-of-atmosphere as well as bottom-of-atmosphere time\nseries in the region of Brittany (Breizh in local language), north-east France.\nWe compare seven recently proposed deep neural networks along with a Random\nForest baseline. The dataset, model (re-)implementations and pre-trained model\nweights are available at the associated GitHub repository\n(https://github.com/dl4sits/BreizhCrops) that has been designed with\napplicability for practitioners in mind. We plan to maintain the repository\nwith additional data and welcome contributions of novel methods to build a\nstate-of-the-art benchmark on methods for crop type mapping.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:40:18 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 19:01:27 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Pelletier", "Charlotte", ""], ["Zollner", "Maximilian", ""], ["Lef\u00e8vre", "S\u00e9bastien", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1905.11902", "submitter": "Andrea Paudice", "authors": "Marco Bressan, Nicol\\`o Cesa-Bianchi, Andrea Paudice, Fabio Vitale", "title": "Correlation Clustering with Adaptive Similarity Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In correlation clustering, we are given $n$ objects together with a binary\nsimilarity score between each pair of them. The goal is to partition the\nobjects into clusters so to minimise the disagreements with the scores. In this\nwork we investigate correlation clustering as an active learning problem: each\nsimilarity score can be learned by making a query, and the goal is to minimise\nboth the disagreements and the total number of queries. On the one hand, we\ndescribe simple active learning algorithms, which provably achieve an almost\noptimal trade-off while giving cluster recovery guarantees, and we test them on\ndifferent datasets. On the other hand, we prove information-theoretical bounds\non the number of queries necessary to guarantee a prescribed disagreement\nbound. These results give a rich characterization of the trade-off between\nqueries and clustering error.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:00:09 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 09:38:52 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 15:44:31 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Bressan", "Marco", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Paudice", "Andrea", ""], ["Vitale", "Fabio", ""]]}, {"id": "1905.11910", "submitter": "Athena Elafrou", "authors": "George Retsinas, Athena Elafrou, Georgios Goumas, Petros Maragos", "title": "RecNets: Channel-wise Recurrent Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Channel-wise recurrent convolutional neural\nnetworks (RecNets), a family of novel, compact neural network architectures for\ncomputer vision tasks inspired by recurrent neural networks (RNNs). RecNets\nbuild upon Channel-wise recurrent convolutional (CRC) layers, a novel type of\nconvolutional layer that splits the input channels into disjoint segments and\nprocesses them in a recurrent fashion. In this way, we simulate wide, yet\ncompact models, since the number of parameters is vastly reduced via the\nparameter sharing of the RNN formulation. Experimental results on the CIFAR-10\nand CIFAR-100 image classification tasks demonstrate the superior size-accuracy\ntrade-off of RecNets compared to other compact state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:13:44 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 21:44:38 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Retsinas", "George", ""], ["Elafrou", "Athena", ""], ["Goumas", "Georgios", ""], ["Maragos", "Petros", ""]]}, {"id": "1905.11911", "submitter": "Niv Haim", "authors": "Matan Atzmon, Niv Haim, Lior Yariv, Ofer Israelov, Haggai Maron, Yaron\n  Lipman", "title": "Controlling Neural Level Sets", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The level sets of neural networks represent fundamental properties such as\ndecision boundaries of classifiers and are used to model non-linear manifold\ndata such as curves and surfaces. Thus, methods for controlling the neural\nlevel sets could find many applications in machine learning.\n  In this paper we present a simple and scalable approach to directly control\nlevel sets of a deep neural network. Our method consists of two parts: (i)\nsampling of the neural level sets, and (ii) relating the samples' positions to\nthe network parameters. The latter is achieved by a sample network that is\nconstructed by adding a single fixed linear layer to the original network. In\nturn, the sample network can be used to incorporate the level set samples into\na loss function of interest.\n  We have tested our method on three different learning tasks: improving\ngeneralization to unseen data, training networks robust to adversarial attacks,\nand curve and surface reconstruction from point clouds. For surface\nreconstruction, we produce high fidelity surfaces directly from raw 3D point\nclouds. When training small to medium networks to be robust to adversarial\nattacks we obtain robust accuracy comparable to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:15:19 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 19:13:59 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Atzmon", "Matan", ""], ["Haim", "Niv", ""], ["Yariv", "Lior", ""], ["Israelov", "Ofer", ""], ["Maron", "Haggai", ""], ["Lipman", "Yaron", ""]]}, {"id": "1905.11926", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Matthew Evanusa, Hua He, Anton Mitrokhin, Tom Goldstein,\n  James A. Yorke, Cornelia Ferm\\\"uller, Yiannis Aloimonos", "title": "Network Deconvolution", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution is a central operation in Convolutional Neural Networks (CNNs),\nwhich applies a kernel to overlapping regions shifted across the image.\nHowever, because of the strong correlations in real-world image data,\nconvolutional kernels are in effect re-learning redundant data. In this work,\nwe show that this redundancy has made neural network training challenging, and\npropose network deconvolution, a procedure which optimally removes pixel-wise\nand channel-wise correlations before the data is fed into each layer. Network\ndeconvolution can be efficiently calculated at a fraction of the computational\ncost of a convolution layer. We also show that the deconvolution filters in the\nfirst layer of the network resemble the center-surround structure found in\nbiological neurons in the visual regions of the brain. Filtering with such\nkernels results in a sparse representation, a desired property that has been\nmissing in the training of neural networks. Learning from the sparse\nrepresentation promotes faster convergence and superior results without the use\nof batch normalization. We apply our network deconvolution operation to 10\nmodern neural network models by replacing batch normalization within each.\nExtensive experiments show that the network deconvolution operation is able to\ndeliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST,\nFashion-MNIST, Cityscapes, and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:38:34 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 17:44:36 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 19:24:00 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 20:48:22 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ye", "Chengxi", ""], ["Evanusa", "Matthew", ""], ["He", "Hua", ""], ["Mitrokhin", "Anton", ""], ["Goldstein", "Tom", ""], ["Yorke", "James A.", ""], ["Ferm\u00fcller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1905.11928", "submitter": "Scott H. Hawley", "authors": "Scott H. Hawley, Benjamin Colburn, Stylianos I. Mimilakis", "title": "SignalTrain: Profiling Audio Compressors with Deep Neural Networks", "comments": "9 pages, 10 figures. v2: typos & references fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a data-driven approach for predicting the behavior of\n(i.e., profiling) a given non-linear audio signal processing effect (henceforth\n\"audio effect\"). Our objective is to learn a mapping function that maps the\nunprocessed audio to the processed by the audio effect to be profiled, using\ntime-domain samples. To that aim, we employ a deep auto-encoder model that is\nconditioned on both time-domain samples and the control parameters of the\ntarget audio effect. As a test-case study, we focus on the offline profiling of\ntwo dynamic range compression audio effects, one software-based and the other\nanalog. Compressors were chosen because they are a widely used and important\nset of effects and because their parameterized nonlinear time-dependent nature\nmakes them a challenging problem for a system aiming to profile \"general\" audio\neffects. Results from our experimental procedure show that the primary\nfunctional and auditory characteristics of the compressors can be captured,\nhowever there is still sufficient audible noise to merit further investigation\nbefore such methods are applied to real-world audio processing workflows.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:42:06 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 01:59:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Hawley", "Scott H.", ""], ["Colburn", "Benjamin", ""], ["Mimilakis", "Stylianos I.", ""]]}, {"id": "1905.11930", "submitter": "Aryeh Kontorovich", "authors": "Armin Biess, Aryeh Kontorovich, Yury Makarychev, Hanan Zaichyk", "title": "Regression via Kirszbraun Extension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for performing regression between two Hilbert spaces.\nWe accomplish this via Kirszbraun's extension theorem -- apparently the first\napplication of this technique to supervised learning -- and analyze its\nstatistical and computational aspects. We begin by formulating the\ncorrespondence problem in terms of quadratically constrained quadratic program\n(QCQP) regression. Then we describe a procedure for smoothing the training\ndata, which amounts to regularizing hypothesis complexity via its Lipschitz\nconstant. The Lipschitz constant is tuned via a Structural Risk Minimization\n(SRM) procedure, based on the covering-number risk bounds we derive. We apply\nour technique to learn a transformation between two robotic manipulators with\ndifferent embodiments, and report promising results.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:48:01 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:22:28 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Biess", "Armin", ""], ["Kontorovich", "Aryeh", ""], ["Makarychev", "Yury", ""], ["Zaichyk", "Hanan", ""]]}, {"id": "1905.11931", "submitter": "Zeya Wang", "authors": "Zeya Wang, Baoyu Jing, Yang Ni, Nanqing Dong, Pengtao Xie, Eric P.\n  Xing", "title": "Adversarial Domain Adaptation Being Aware of Class Relationships", "comments": null, "journal-ref": "24th European Conference on Artificial Intelligence (ECAI), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a useful approach to promote the learning of\ntransferable representations across the source and target domains, which has\nbeen widely applied for domain adaptation (DA) tasks based on deep neural\nnetworks. Until very recently, existing adversarial domain adaptation (ADA)\nmethods ignore the useful information from the label space, which is an\nimportant factor accountable for the complicated data distributions associated\nwith different semantic classes. Especially, the inter-class semantic\nrelationships have been rarely considered and discussed in the current work of\ntransfer learning. In this paper, we propose a novel relationship-aware\nadversarial domain adaptation (RADA) algorithm, which first utilizes a single\nmulti-class domain discriminator to enforce the learning of inter-class\ndependency structure during domain-adversarial training and then aligns this\nstructure with the inter-class dependencies that are characterized from\ntraining the label predictor on source domain. Specifically, we impose a\nregularization term to penalize the structure discrepancy between the\ninter-class dependencies respectively estimated from domain discriminator and\nlabel predictor. Through this alignment, our proposed method makes the\nadversarial domain adaptation aware of the class relationships. Empirical\nstudies show that the incorporation of class relationships significantly\nimproves the performance on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:52:08 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 00:52:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wang", "Zeya", ""], ["Jing", "Baoyu", ""], ["Ni", "Yang", ""], ["Dong", "Nanqing", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1905.11940", "submitter": "Boyang Deng", "authors": "Boyang Deng, Simon Kornblith, Geoffrey Hinton", "title": "Cerberus: A Multi-headed Derenderer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To generalize to novel visual scenes with new viewpoints and new object\nposes, a visual system needs representations of the shapes of the parts of an\nobject that are invariant to changes in viewpoint or pose. 3D graphics\nrepresentations disentangle visual factors such as viewpoints and lighting from\nobject structure in a natural way. It is possible to learn to invert the\nprocess that converts 3D graphics representations into 2D images, provided the\n3D graphics representations are available as labels. When only the unlabeled\nimages are available, however, learning to derender is much harder. We consider\na simple model which is just a set of free floating parts. Each part has its\nown relation to the camera and its own triangular mesh which can be deformed to\nmodel the shape of the part. At test time, a neural network looks at a single\nimage and extracts the shapes of the parts and their relations to the camera.\nEach part can be viewed as one head of a multi-headed derenderer. During\ntraining, the extracted parts are used as input to a differentiable 3D renderer\nand the reconstruction error is backpropagated to train the neural net. We make\nthe learning task easier by encouraging the deformations of the part meshes to\nbe invariant to changes in viewpoint and invariant to the changes in the\nrelative positions of the parts that occur when the pose of an articulated body\nchanges. Cerberus, our multi-headed derenderer, outperforms previous methods\nfor extracting 3D parts from single images without part annotations, and it\ndoes quite well at extracting natural parts of human figures.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:00:03 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Deng", "Boyang", ""], ["Kornblith", "Simon", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1905.11946", "submitter": "Mingxing Tan", "authors": "Mingxing Tan and Quoc V. Le", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "comments": "ICML 2019", "journal-ref": "International Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (ConvNets) are commonly developed at a fixed\nresource budget, and then scaled up for better accuracy if more resources are\navailable. In this paper, we systematically study model scaling and identify\nthat carefully balancing network depth, width, and resolution can lead to\nbetter performance. Based on this observation, we propose a new scaling method\nthat uniformly scales all dimensions of depth/width/resolution using a simple\nyet highly effective compound coefficient. We demonstrate the effectiveness of\nthis method on scaling up MobileNets and ResNet.\n  To go even further, we use neural architecture search to design a new\nbaseline network and scale it up to obtain a family of models, called\nEfficientNets, which achieve much better accuracy and efficiency than previous\nConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3%\ntop-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on\ninference than the best existing ConvNet. Our EfficientNets also transfer well\nand achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%),\nand 3 other transfer learning datasets, with an order of magnitude fewer\nparameters. Source code is at\nhttps://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:05:32 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 04:48:48 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 03:13:25 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 05:43:46 GMT"}, {"version": "v5", "created": "Fri, 11 Sep 2020 05:08:01 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Tan", "Mingxing", ""], ["Le", "Quoc V.", ""]]}, {"id": "1905.11947", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman,\n  Lydia Zakynthinou", "title": "Private Identity Testing for High-Dimensional Distributions", "comments": "Improved the bounds and the writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present novel differentially private identity\n(goodness-of-fit) testers for natural and widely studied classes of\nmultivariate product distributions: Gaussians in $\\mathbb{R}^d$ with known\ncovariance and product distributions over $\\{\\pm 1\\}^{d}$. Our testers have\nimproved sample complexity compared to those derived from previous techniques,\nand are the first testers whose sample complexity matches the order-optimal\nminimax sample complexity of $O(d^{1/2}/\\alpha^2)$ in many parameter regimes.\nWe construct two types of testers, exhibiting tradeoffs between sample\ncomplexity and computational complexity. Finally, we provide a two-way\nreduction between testing a subclass of multivariate product distributions and\ntesting univariate distributions, and thereby obtain upper and lower bounds for\ntesting this subclass of product distributions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:07:38 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:33:34 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""], ["McMillan", "Audra", ""], ["Ullman", "Jonathan", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "1905.11954", "submitter": "Chengxu Zhuang", "authors": "Chengxu Zhuang, Tianwei She, Alex Andonian, Max Sobol Mark, Daniel\n  Yamins", "title": "Unsupervised Learning from Video with Deep Neural Embeddings", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the rich dynamical structure of videos and their ubiquity in\neveryday life, it is a natural idea that video data could serve as a powerful\nunsupervised learning signal for training visual representations in deep neural\nnetworks. However, instantiating this idea, especially at large scale, has\nremained a significant artificial intelligence challenge. Here we present the\nVideo Instance Embedding (VIE) framework, which extends powerful recent\nunsupervised loss functions for learning deep nonlinear embeddings to\nmulti-stream temporal processing architectures on large-scale video datasets.\nWe show that VIE-trained networks substantially advance the state of the art in\nunsupervised learning from video datastreams, both for action recognition in\nthe Kinetics dataset, and object recognition in the ImageNet dataset. We show\nthat a hybrid model with both static and dynamic processing pathways is optimal\nfor both transfer tasks, and provide analyses indicating how the pathways\ndiffer. Taken in context, our results suggest that deep neural embeddings are a\npromising approach to unsupervised visual learning across a wide variety of\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:24:48 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 21:57:55 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhuang", "Chengxu", ""], ["She", "Tianwei", ""], ["Andonian", "Alex", ""], ["Mark", "Max Sobol", ""], ["Yamins", "Daniel", ""]]}, {"id": "1905.11959", "submitter": "Juliano Henrique Foleiss", "authors": "Juliano H. Foleiss and Tiago F. Tavares", "title": "Texture Selection for Automatic Music Genre Classification", "comments": "Submitted to Pattern Recognition (may, 2019)", "journal-ref": null, "doi": "10.1016/j.asoc.2020.106127", "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music Genre Classification is the problem of associating genre-related labels\nto digitized music tracks. It has applications in the organization of\ncommercial and personal music collections. Often, music tracks are described as\na set of timbre-inspired sound textures. In shallow-learning systems, the total\nnumber of sound textures per track is usually too high, and texture\ndownsampling is necessary to make training tractable. Although previous work\nhas solved this by linear downsampling, no extensive work has been done to\nevaluate how texture selection benefits genre classification in the context of\nthe bag of frames track descriptions. In this paper, we evaluate the impact of\nframe selection on automatic music genre classification in a bag of frames\nscenario. We also present a novel texture selector based on K-Means aimed to\nidentify diverse sound textures within each track. We evaluated texture\nselection in diverse datasets, four different feature sets, as well as its\nrelationship to a univariate feature selection strategy. The results show that\nframe selection leads to significant improvement over the single vector\nbaseline on datasets consisting of full-length tracks, regardless of the\nfeature set. Results also indicate that the K-Means texture selector achieves\nsignificant improvements over the baseline, using fewer textures per track than\nthe commonly used linear downsampling. The results also suggest that texture\nselection is complementary to the feature selection strategy evaluated. Our\nqualitative analysis indicates that texture variety within classes benefits\nmodel generalization. Our analysis shows that selecting specific audio excerpts\ncan improve classification performance, and it can be done automatically.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:30:31 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Foleiss", "Juliano H.", ""], ["Tavares", "Tiago F.", ""]]}, {"id": "1905.11963", "submitter": "Mostafa Haghir Chehreghani", "authors": "Mostafa Haghir Chehreghani", "title": "Sketch-based Randomized Algorithms for Dynamic Graph Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known problem in data science and machine learning is {\\em linear\nregression}, which is recently extended to dynamic graphs. Existing exact\nalgorithms for updating the solution of dynamic graph regression problem\nrequire at least a linear time (in terms of $n$: the size of the graph).\nHowever, this time complexity might be intractable in practice. In the current\npaper, we utilize {\\em subsampled randomized Hadamard transform} and\n\\textsf{CountSketch} to propose the first randomized algorithms. Suppose that\nwe are given an $n\\times m$ matrix embedding $M$ of the graph, where $m \\ll n$.\nLet $r$ be the number of samples required for a guaranteed approximation error,\nwhich is a sublinear function of $n$. Our first algorithm reduces time\ncomplexity of pre-processing to $O(n(m + 1) + 2n(m + 1) \\log_2(r + 1) + rm^2)$.\nThen after an edge insertion or an edge deletion, it updates the approximate\nsolution in $O(rm)$ time. Our second algorithm reduces time complexity of\npre-processing to $O \\left( nnz(M) + m^3 \\epsilon^{-2} \\log^7(m/\\epsilon)\n\\right)$, where $nnz(M)$ is the number of nonzero elements of $M$. Then after\nan edge insertion or an edge deletion or a node insertion or a node deletion,\nit updates the approximate solution in $O(qm)$ time, with\n$q=O\\left(\\frac{m^2}{\\epsilon^2} \\log^6(m/\\epsilon) \\right)$. Finally, we show\nthat under some assumptions, if $\\ln n < \\epsilon^{-1}$ our first algorithm\noutperforms our second algorithm and if $\\ln n \\geq \\epsilon^{-1}$ our second\nalgorithm outperforms our first algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:36:22 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 19:19:19 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chehreghani", "Mostafa Haghir", ""]]}, {"id": "1905.11971", "submitter": "Yuzhe Yang", "authors": "Yuzhe Yang, Guo Zhang, Dina Katabi, Zhi Xu", "title": "ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks. The literature is\nrich with algorithms that can easily craft successful adversarial examples. In\ncontrast, the performance of defense techniques still lags behind. This paper\nproposes ME-Net, a defense method that leverages matrix estimation (ME). In\nME-Net, images are preprocessed using two steps: first pixels are randomly\ndropped from the image; then, the image is reconstructed using ME. We show that\nthis process destroys the adversarial structure of the noise, while\nre-enforcing the global structure in the original image. Since humans typically\nrely on such global structures in classifying images, the process makes the\nnetwork mode compatible with human perception. We conduct comprehensive\nexperiments on prevailing benchmarks such as MNIST, CIFAR-10, SVHN, and\nTiny-ImageNet. Comparing ME-Net with state-of-the-art defense mechanisms shows\nthat ME-Net consistently outperforms prior techniques, improving robustness\nagainst both black-box and white-box attacks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:47:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yang", "Yuzhe", ""], ["Zhang", "Guo", ""], ["Katabi", "Dina", ""], ["Xu", "Zhi", ""]]}, {"id": "1905.11972", "submitter": "Matias Vera", "authors": "Matias Vera, Pablo Piantanida and Leonardo Rey Vega", "title": "Understanding the Behaviour of the Empirical Cross-Entropy Beyond the\n  Training Distribution", "comments": "18 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning theory has mostly focused on generalization to samples from\nthe same distribution as the training data. Whereas a better understanding of\ngeneralization beyond the training distribution where the observed distribution\nchanges is also fundamentally important to achieve a more powerful form of\ngeneralization. In this paper, we attempt to study through the lens of\ninformation measures how a particular architecture behaves when the true\nprobability law of the samples is potentially different at training and testing\ntimes. Our main result is that the testing gap between the empirical\ncross-entropy and its statistical expectation (measured with respect to the\ntesting probability law) can be bounded with high probability by the mutual\ninformation between the input testing samples and the corresponding\nrepresentations, generated by the encoder obtained at training time. These\nresults of theoretical nature are supported by numerical simulations showing\nthat the mentioned mutual information is representative of the testing gap,\ncapturing qualitatively the dynamic in terms of the hyperparameters of the\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:48:48 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Vera", "Matias", ""], ["Piantanida", "Pablo", ""], ["Vega", "Leonardo Rey", ""]]}, {"id": "1905.11975", "submitter": "Peng Xu", "authors": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao", "title": "On Variational Learning of Controllable Representations for Text without\n  Supervision", "comments": "ICML 2020 Camera Ready. Previous title: Unsupervised Controllable\n  Text Generation with Global Variation Discovery and Disentanglement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) can learn the manifold of natural images on\ncertain datasets, as evidenced by meaningful interpolating or extrapolating in\nthe continuous latent space. However, on discrete data such as text, it is\nunclear if unsupervised learning can discover similar latent space that allows\ncontrollable manipulation. In this work, we find that sequence VAEs trained on\ntext fail to properly decode when the latent codes are manipulated, because the\nmodified codes often land in holes or vacant regions in the aggregated\nposterior latent space, where the decoding network fails to generalize. Both as\na validation of the explanation and as a fix to the problem, we propose to\nconstrain the posterior mean to a learned probability simplex, and performs\nmanipulation within this simplex. Our proposed method mitigates the latent\nvacancy problem and achieves the first success in unsupervised learning of\ncontrollable representations for text. Empirically, our method outperforms\nunsupervised baselines and strong supervised approaches on text style transfer,\nand is capable of performing more flexible fine-grained control over text\ngeneration than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:49:47 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:47:53 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 21:42:52 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 17:44:10 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Xu", "Peng", ""], ["Cheung", "Jackie Chi Kit", ""], ["Cao", "Yanshuai", ""]]}, {"id": "1905.11978", "submitter": "Peng Xu", "authors": "Yanshuai Cao and Peng Xu", "title": "Better Long-Range Dependency By Bootstrapping A Mutual Information\n  Regularizer", "comments": "Camera-ready for AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel regularizer to improve the learning of\nlong-range dependency of sequence data. Applied on language modelling, our\nregularizer expresses the inductive bias that sequence variables should have\nhigh mutual information even though the model might not see abundant\nobservations for complex long-range dependency. We show how the `next sentence\nprediction (classification)' heuristic can be derived in a principled way from\nour mutual information estimation framework, and be further extended to\nmaximize the mutual information of sequence variables. The proposed approach\nnot only is effective at increasing the mutual information of segments under\nthe learned model but more importantly, leads to a higher likelihood on holdout\ndata, and improved generation quality. Code is released at\nhttps://github.com/BorealisAI/BMI.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:55:32 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 01:07:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cao", "Yanshuai", ""], ["Xu", "Peng", ""]]}, {"id": "1905.11979", "submitter": "Pim de Haan", "authors": "Pim de Haan, Dinesh Jayaraman, and Sergey Levine", "title": "Causal Confusion in Imitation Learning", "comments": "Published at NeurIPS 2019 9 pages, plus references and appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral cloning reduces policy learning to supervised learning by training\na discriminative model to predict expert actions given observations. Such\ndiscriminative models are non-causal: the training procedure is unaware of the\ncausal structure of the interaction between the expert and the environment. We\npoint out that ignoring causality is particularly damaging because of the\ndistributional shift in imitation learning. In particular, it leads to a\ncounter-intuitive \"causal misidentification\" phenomenon: access to more\ninformation can yield worse performance. We investigate how this problem\narises, and propose a solution to combat it through targeted\ninterventions---either environment interaction or expert queries---to determine\nthe correct causal model. We show that causal misidentification occurs in\nseveral benchmark control domains as well as realistic driving settings, and\nvalidate our solution against DAgger and other baselines and ablations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:56:19 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 12:59:24 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["de Haan", "Pim", ""], ["Jayaraman", "Dinesh", ""], ["Levine", "Sergey", ""]]}, {"id": "1905.11984", "submitter": "Rohit Vaish", "authors": "Haoming Li, Sujoy Sikdar, Rohit Vaish, Junming Wang, Lirong Xia,\n  Chaonan Ye", "title": "Minimizing Time-to-Rank: A Learning and Recommendation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following problem faced by an online voting platform: A user is\nprovided with a list of alternatives, and is asked to rank them in order of\npreference using only drag-and-drop operations. The platform's goal is to\nrecommend an initial ranking that minimizes the time spent by the user in\narriving at her desired ranking. We develop the first optimization framework to\naddress this problem, and make theoretical as well as practical contributions.\nOn the practical side, our experiments on Amazon Mechanical Turk provide two\ninteresting insights about user behavior: First, that users' ranking strategies\nclosely resemble selection or insertion sort, and second, that the time taken\nfor a drag-and-drop operation depends linearly on the number of positions\nmoved. These insights directly motivate our theoretical model of the\noptimization problem. We show that computing an optimal recommendation is\nNP-hard, and provide exact and approximation algorithms for a variety of\nspecial cases of the problem. Experimental evaluation on MTurk shows that,\ncompared to a random recommendation strategy, the proposed approach reduces the\n(average) time-to-rank by up to 50%.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:50:06 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Li", "Haoming", ""], ["Sikdar", "Sujoy", ""], ["Vaish", "Rohit", ""], ["Wang", "Junming", ""], ["Xia", "Lirong", ""], ["Ye", "Chaonan", ""]]}, {"id": "1905.11987", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Stefan Haag, Nils Appenrodt, Bharanidhar Duraisamy,\n  J\\\"urgen Dickmann, Martin Fritzsche, Bernhard Sick", "title": "Automated Ground Truth Estimation For Automotive Radar Tracking\n  Applications With Portable GNSS And IMU Devices", "comments": "10 pages, 9 figures, accepted paper for 2019 20th International Radar\n  Symposium (IRS), Ulm, Germany, June 2019. arXiv admin note: text overlap with\n  arXiv:1905.11219", "journal-ref": "Published in Proceedings of 20th International Radar Symposium\n  (IRS), Ulm, Germany, June 2019", "doi": "10.23919/IRS.2019.8768169", "report-no": null, "categories": "eess.SP cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Baseline generation for tracking applications is a difficult task when\nworking with real world radar data. Data sparsity usually only allows an\nindirect way of estimating the original tracks as most objects' centers are not\nrepresented in the data. This article proposes an automated way of acquiring\nreference trajectories by using a highly accurate hand-held global navigation\nsatellite system (GNSS). An embedded inertial measurement unit (IMU) is used\nfor estimating orientation and motion behavior. This article contains two major\ncontributions. A method for associating radar data to vulnerable road user\n(VRU) tracks is described. It is evaluated how accurate the system performs\nunder different GNSS reception conditions and how carrying a reference system\nalters radar measurements. Second, the system is used to track pedestrians and\ncyclists over many measurement cycles in order to generate object centered\noccupancy grid maps. The reference system allows to much more precisely\ngenerate real world radar data distributions of VRUs than compared to\nconventional methods. Hereby, an important step towards radar-based VRU\ntracking is accomplished.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:21:17 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 09:57:24 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Haag", "Stefan", ""], ["Appenrodt", "Nils", ""], ["Duraisamy", "Bharanidhar", ""], ["Dickmann", "J\u00fcrgen", ""], ["Fritzsche", "Martin", ""], ["Sick", "Bernhard", ""]]}, {"id": "1905.12006", "submitter": "Steven James", "authors": "Steven James, Benjamin Rosman, George Konidaris", "title": "Learning Portable Representations for High-Level Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for autonomously learning a portable representation\nthat describes a collection of low-level continuous environments. We show that\nthese abstract representations can be learned in a task-independent egocentric\nspace specific to the agent that, when grounded with problem-specific\ninformation, are provably sufficient for planning. We demonstrate transfer in\ntwo different domains, where an agent learns a portable, task-independent\nsymbolic vocabulary, as well as rules expressed in that vocabulary, and then\nlearns to instantiate those rules on a per-task basis. This reduces the number\nof samples required to learn a representation of a new task.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:13:42 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["James", "Steven", ""], ["Rosman", "Benjamin", ""], ["Konidaris", "George", ""]]}, {"id": "1905.12008", "submitter": "Tomasz Kornuta", "authors": "Tomasz Kornuta and Deepta Rajan and Chaitanya Shivade and Alexis\n  Asseman and Ahmet S. Ozcan", "title": "Leveraging Medical Visual Question Answering with Supporting Facts", "comments": "Working notes from the ImageCLEF 2019 VQA-Med competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this working notes paper, we describe IBM Research AI (Almaden) team's\nparticipation in the ImageCLEF 2019 VQA-Med competition. The challenge consists\nof four question-answering tasks based on radiology images. The diversity of\nimaging modalities, organs and disease types combined with a small imbalanced\ntraining set made this a highly complex problem. To overcome these\ndifficulties, we implemented a modular pipeline architecture that utilized\ntransfer learning and multi-task learning. Our findings led to the development\nof a novel model called Supporting Facts Network (SFN). The main idea behind\nSFN is to cross-utilize information from upstream tasks to improve the accuracy\non harder downstream ones. This approach significantly improved the scores\nachieved in the validation set (18 point improvement in F-1 score). Finally, we\nsubmitted four runs to the competition and were ranked seventh.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:15:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kornuta", "Tomasz", ""], ["Rajan", "Deepta", ""], ["Shivade", "Chaitanya", ""], ["Asseman", "Alexis", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1905.12009", "submitter": "Yingdong Lu", "authors": "Yingdong Lu and Mark S. Squillante and Chai Wah Wu", "title": "A General Markov Decision Process Framework for Directly Learning\n  Optimal Control Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new form of reinforcement learning (RL) that is based on\nopportunities to directly learn the optimal control policy and a general Markov\ndecision process (MDP) framework devised to support these opportunities.\nDerivations of general classes of our control-based RL methods are presented,\ntogether with forms of exploration and exploitation in learning and applying\nthe optimal control policy over time. Our general MDP framework extends the\nclassical Bellman operator and optimality criteria by generalizing the\ndefinition and scope of a policy for any given state. We establish the\nconvergence and optimality-both in general and within various control paradigms\n(e.g., piecewise linear control policies)-of our control-based methods through\nthis general MDP framework, including convergence of $Q$-learning within the\ncontext of our MDP framework. Our empirical results demonstrate and quantify\nthe significant benefits of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:16:03 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 02:10:55 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Lu", "Yingdong", ""], ["Squillante", "Mark S.", ""], ["Wu", "Chai Wah", ""]]}, {"id": "1905.12019", "submitter": "Martin Mundt", "authors": "Martin Mundt, Sagnik Majumder, Iuliia Pliushch, Yong Won Hong,\n  Visvanathan Ramesh", "title": "Unified Probabilistic Deep Continual Learning through Generative Replay\n  and Open Set Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic approach to unify open set recognition with the\nprevention of catastrophic forgetting in deep continual learning, based on\nvariational Bayesian inference. Our single model combines a joint probabilistic\nencoder with a generative model and a linear classifier that get shared across\nsequentially arriving tasks. In order to successfully distinguish unseen\nunknown data from trained known tasks, we propose to bound the class specific\napproximate posterior by fitting regions of high density on the basis of\ncorrectly classified data points. These bounds are further used to\nsignificantly alleviate catastrophic forgetting by avoiding samples from low\ndensity areas in generative replay. Our approach requires neither storing of\nold, nor upfront knowledge of future data, and is empirically validated on\nvisual and audio tasks in class incremental, as well as cross-dataset scenarios\nacross modalities.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:26:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:24:33 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 15:14:34 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 10:54:47 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mundt", "Martin", ""], ["Majumder", "Sagnik", ""], ["Pliushch", "Iuliia", ""], ["Hong", "Yong Won", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1905.12020", "submitter": "Gentry Johnson", "authors": "Gentry Johnson, Brian Quistorff, Matt Goldman", "title": "Matching on What Matters: A Pseudo-Metric Learning Approach to Matching\n  Estimation in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When pre-processing observational data via matching, we seek to approximate\neach unit with maximally similar peers that had an alternative treatment\nstatus--essentially replicating a randomized block design. However, as one\nconsiders a growing number of continuous features, a curse of dimensionality\napplies making asymptotically valid inference impossible (Abadie and Imbens,\n2006). The alternative of ignoring plausibly relevant features is certainly no\nbetter, and the resulting trade-off substantially limits the application of\nmatching methods to \"wide\" datasets. Instead, Li and Fu (2017) recasts the\nproblem of matching in a metric learning framework that maps features to a\nlow-dimensional space that facilitates \"closer matches\" while still capturing\nimportant aspects of unit-level heterogeneity. However, that method lacks key\ntheoretical guarantees and can produce inconsistent estimates in cases of\nheterogeneous treatment effects. Motivated by straightforward extension of\nexisting results in the matching literature, we present alternative techniques\nthat learn latent matching features through either MLPs or through siamese\nneural networks trained on a carefully selected loss function. We benchmark the\nresulting alternative methods in simulations as well as against two\nexperimental data sets--including the canonical NSW worker training program\ndata set--and find superior performance of the neural-net-based methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:26:46 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Johnson", "Gentry", ""], ["Quistorff", "Brian", ""], ["Goldman", "Matt", ""]]}, {"id": "1905.12022", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald,\n  Trong Nghia Hoang and Yasaman Khazaeni", "title": "Bayesian Nonparametric Federated Learning of Neural Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning problems, data is scattered across different servers\nand exchanging or pooling it is often impractical or prohibited. We develop a\nBayesian nonparametric framework for federated learning with neural networks.\nEach data server is assumed to provide local neural network weights, which are\nmodeled through our framework. We then develop an inference approach that\nallows us to synthesize a more expressive global network without additional\nsupervision, data pooling and with as few as a single communication round. We\nthen demonstrate the efficacy of our approach on federated learning problems\nsimulated from two popular image classification datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:33:27 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Agarwal", "Mayank", ""], ["Ghosh", "Soumya", ""], ["Greenewald", "Kristjan", ""], ["Hoang", "Trong Nghia", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "1905.12032", "submitter": "Pu Zhao", "authors": "Pu Zhao, Siyue Wang, Cheng Gongye, Yanzhi Wang, Yunsi Fei, Xue Lin", "title": "Fault Sneaking Attack: a Stealthy Framework for Misleading Deep Neural\n  Networks", "comments": "Accepted by the 56th Design Automation Conference (DAC 2019)", "journal-ref": null, "doi": "10.1145/3316781.3317825", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements of deep neural networks (DNNs), the\nvulnerability of state-of-the-art DNNs raises security concerns of DNNs in many\napplication domains requiring high reliability.We propose the fault sneaking\nattack on DNNs, where the adversary aims to misclassify certain input images\ninto any target labels by modifying the DNN parameters. We apply ADMM\n(alternating direction method of multipliers) for solving the optimization\nproblem of the fault sneaking attack with two constraints: 1) the\nclassification of the other images should be unchanged and 2) the parameter\nmodifications should be minimized. Specifically, the first constraint requires\nus not only to inject designated faults (misclassifications), but also to hide\nthe faults for stealthy or sneaking considerations by maintaining model\naccuracy. The second constraint requires us to minimize the parameter\nmodifications (using L0 norm to measure the number of modifications and L2 norm\nto measure the magnitude of modifications). Comprehensive experimental\nevaluation demonstrates that the proposed framework can inject multiple\nsneaking faults without losing the overall test accuracy performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:56:44 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zhao", "Pu", ""], ["Wang", "Siyue", ""], ["Gongye", "Cheng", ""], ["Wang", "Yanzhi", ""], ["Fei", "Yunsi", ""], ["Lin", "Xue", ""]]}, {"id": "1905.12033", "submitter": "Vincent Mallet", "authors": "Vincent Mallet, Carlos G. Oliver, Nicolas Moitessier, Jerome\n  Waldispuhl", "title": "Leveraging binding-site structure for drug discovery with point-cloud\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational drug discovery strategies can be broadly placed in two\ncategories: ligand-based methods which identify novel molecules by similarity\nwith known ligands, and structure-based methods which predict molecules with\nhigh-affinity to a given 3D structure (e.g. a protein). However, ligand-based\nmethods do not leverage information about the binding site, and structure-based\napproaches rely on the knowledge of a finite set of ligands binding the target.\nIn this work, we introduce TarLig, a novel approach that aims to bridge the gap\nbetween ligand and structure-based approaches. We use the 3D structure of the\nbinding site as input to a model which predicts the ligand preferences of the\nbinding site. The resulting predictions could then offer promising seeds and\nconstraints in the chemical space search, based on the binding site structure.\nTarLig outperforms standard models by introducing a data-alignment and\naugmentation technique. The recent popularity of Volumetric 3DCNN pipelines in\nstructural bioinformatics suggests that this extra step could help a wide range\nof methods to improve their results with minimal modifications.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:03:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Mallet", "Vincent", ""], ["Oliver", "Carlos G.", ""], ["Moitessier", "Nicolas", ""], ["Waldispuhl", "Jerome", ""]]}, {"id": "1905.12034", "submitter": "Tian Guo", "authors": "Tian Guo, Tao Lin, Nino Antulov-Fantulin", "title": "Exploring Interpretable LSTM Neural Networks over Multi-Variable Data", "comments": "Accepted to International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For recurrent neural networks trained on time series with target and\nexogenous variables, in addition to accurate prediction, it is also desired to\nprovide interpretable insights into the data. In this paper, we explore the\nstructure of LSTM recurrent neural networks to learn variable-wise hidden\nstates, with the aim to capture different dynamics in multi-variable time\nseries and distinguish the contribution of variables to the prediction. With\nthese variable-wise hidden states, a mixture attention mechanism is proposed to\nmodel the generative process of the target. Then we develop associated training\nmethods to jointly learn network parameters, variable and temporal importance\nw.r.t the prediction of the target variable. Extensive experiments on real\ndatasets demonstrate enhanced prediction performance by capturing the dynamics\nof different variables. Meanwhile, we evaluate the interpretation results both\nqualitatively and quantitatively. It exhibits the prospect as an end-to-end\nframework for both forecasting and knowledge extraction over multi-variable\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:03:12 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Guo", "Tian", ""], ["Lin", "Tao", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1905.12044", "submitter": "Nicholay Topin", "authors": "Nicholay Topin and Manuela Veloso", "title": "Generation of Policy-Level Explanations for Reinforcement Learning", "comments": "Accepted to Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though reinforcement learning has greatly benefited from the incorporation of\nneural networks, the inability to verify the correctness of such systems limits\ntheir use. Current work in explainable deep learning focuses on explaining only\na single decision in terms of input features, making it unsuitable for\nexplaining a sequence of decisions. To address this need, we introduce\nAbstracted Policy Graphs, which are Markov chains of abstract states. This\nrepresentation concisely summarizes a policy so that individual decisions can\nbe explained in the context of expected future transitions. Additionally, we\npropose a method to generate these Abstracted Policy Graphs for deterministic\npolicies given a learned value function and a set of observed transitions,\npotentially off-policy transitions used during training. Since no restrictions\nare placed on how the value function is generated, our method is compatible\nwith many existing reinforcement learning methods. We prove that the worst-case\ntime complexity of our method is quadratic in the number of features and linear\nin the number of provided transitions, $O(|F|^2 |tr\\_samples|)$. By applying\nour method to a family of domains, we show that our method scales well in\npractice and produces Abstracted Policy Graphs which reliably capture\nrelationships within these domains.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:33:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Topin", "Nicholay", ""], ["Veloso", "Manuela", ""]]}, {"id": "1905.12052", "submitter": "Andrew Stirn", "authors": "Andrew Stirn, Tony Jebara, David A Knowles", "title": "A New Distribution on the Simplex with Auto-Encoding Applications", "comments": "15 pages, 6 figures, 1 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a new distribution for the simplex using the Kumaraswamy\ndistribution and an ordered stick-breaking process. We explore and develop the\ntheoretical properties of this new distribution and prove that it exhibits\nsymmetry under the same conditions as the well-known Dirichlet. Like the\nDirichlet, the new distribution is adept at capturing sparsity but, unlike the\nDirichlet, has an exact and closed form reparameterization--making it well\nsuited for deep variational Bayesian modeling. We demonstrate the\ndistribution's utility in a variety of semi-supervised auto-encoding tasks. In\nall cases, the resulting models achieve competitive performance commensurate\nwith their simplicity, use of explicit probability models, and abstinence from\nadversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:56:55 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 20:16:38 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 18:19:11 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Stirn", "Andrew", ""], ["Jebara", "Tony", ""], ["Knowles", "David A", ""]]}, {"id": "1905.12080", "submitter": "Giancarlo Kerg", "authors": "Giancarlo Kerg, Kyle Goyette, Maximilian Puelma Touzel, Gauthier\n  Gidel, Eugene Vorontsov, Yoshua Bengio, Guillaume Lajoie", "title": "Non-normal Recurrent Neural Network (nnRNN): learning long time\n  dependencies while improving expressivity with transient dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent strategy to circumvent the exploding and vanishing gradient problem\nin RNNs, and to allow the stable propagation of signals over long time scales,\nis to constrain recurrent connectivity matrices to be orthogonal or unitary.\nThis ensures eigenvalues with unit norm and thus stable dynamics and training.\nHowever this comes at the cost of reduced expressivity due to the limited\nvariety of orthogonal transformations. We propose a novel connectivity\nstructure based on the Schur decomposition and a splitting of the Schur form\ninto normal and non-normal parts. This allows to parametrize matrices with\nunit-norm eigenspectra without orthogonality constraints on eigenbases. The\nresulting architecture ensures access to a larger space of spectrally\nconstrained matrices, of which orthogonal matrices are a subset. This crucial\ndifference retains the stability advantages and training speed of orthogonal\nRNNs while enhancing expressivity, especially on tasks that require\ncomputations over ongoing input sequences.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:41:27 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 13:13:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kerg", "Giancarlo", ""], ["Goyette", "Kyle", ""], ["Touzel", "Maximilian Puelma", ""], ["Gidel", "Gauthier", ""], ["Vorontsov", "Eugene", ""], ["Bengio", "Yoshua", ""], ["Lajoie", "Guillaume", ""]]}, {"id": "1905.12081", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Alexander Mey, Marco Loog, Bernhard Sch\\\"olkopf", "title": "Semi-Supervised Learning, Causality and the Conditional Cluster\n  Assumption", "comments": "36th Conference on Uncertainty in Artificial Intelligence (2020)\n  (Previously presented at the NeurIPS 2019 workshop \"Do the right thing\":\n  machine learning and causal inference for improved decision making,\n  Vancouver, Canada.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the success of semi-supervised learning (SSL) is still not fully\nunderstood, Sch\\\"olkopf et al. (2012) have established a link to the principle\nof independent causal mechanisms. They conclude that SSL should be impossible\nwhen predicting a target variable from its causes, but possible when predicting\nit from its effects. Since both these cases are somewhat restrictive, we extend\ntheir work by considering classification using cause and effect features at the\nsame time, such as predicting disease from both risk factors and symptoms.\nWhile standard SSL exploits information contained in the marginal distribution\nof all inputs (to improve the estimate of the conditional distribution of the\ntarget given inputs), we argue that in our more general setting we should use\ninformation in the conditional distribution of effect features given causal\nfeatures. We explore how this insight generalises the previous understanding,\nand how it relates to and can be exploited algorithmically for SSL.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:53:56 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 13:35:22 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 09:32:52 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 10:40:15 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Mey", "Alexander", ""], ["Loog", "Marco", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1905.12090", "submitter": "Geoffrey Roeder", "authors": "Geoffrey Roeder, Paul K. Grant, Andrew Phillips, Neil Dalchau, and\n  Edward Meeds", "title": "Efficient Amortised Bayesian Inference for Hierarchical and Nonlinear\n  Dynamical Systems", "comments": "Published in \"Proceedings of Machine Learning Research, Volume 97:\n  International Conference on Machine Learning, 9-15 June 2019, Long Beach,\n  California, USA\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a flexible, scalable Bayesian inference framework for nonlinear\ndynamical systems characterised by distinct and hierarchical variability at the\nindividual, group, and population levels. Our model class is a generalisation\nof nonlinear mixed-effects (NLME) dynamical systems, the statistical workhorse\nfor many experimental sciences. We cast parameter inference as stochastic\noptimisation of an end-to-end differentiable, block-conditional variational\nautoencoder. We specify the dynamics of the data-generating process as an\nordinary differential equation (ODE) such that both the ODE and its solver are\nfully differentiable. This model class is highly flexible: the ODE right-hand\nsides can be a mixture of user-prescribed or \"white-box\" sub-components and\nneural network or \"black-box\" sub-components. Using stochastic optimisation,\nour amortised inference algorithm could seamlessly scale up to massive data\ncollection pipelines (common in labs with robotic automation). Finally, our\nframework supports interpretability with respect to the underlying dynamics, as\nwell as predictive generalization to unseen combinations of group components\n(also called \"zero-shot\" learning). We empirically validate our method by\npredicting the dynamic behaviour of bacteria that were genetically engineered\nto function as biosensors. Our implementation of the framework, the dataset,\nand all code to reproduce the experimental results is available at\nhttps://www.github.com/Microsoft/vi-hds .\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:06:50 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:51:00 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Roeder", "Geoffrey", ""], ["Grant", "Paul K.", ""], ["Phillips", "Andrew", ""], ["Dalchau", "Neil", ""], ["Meeds", "Edward", ""]]}, {"id": "1905.12091", "submitter": "Wai Ming Tai", "authors": "Aditya Bhaskara, Wai Ming Tai", "title": "Approximate Guarantees for Dictionary Learning", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the dictionary learning (or sparse coding) problem, we are given a\ncollection of signals (vectors in $\\mathbb{R}^d$), and the goal is to find a\n\"basis\" in which the signals have a sparse (approximate) representation. The\nproblem has received a lot of attention in signal processing, learning, and\ntheoretical computer science. The problem is formalized as factorizing a matrix\n$X (d \\times n)$ (whose columns are the signals) as $X = AY$, where $A$ has a\nprescribed number $m$ of columns (typically $m \\ll n$), and $Y$ has columns\nthat are $k$-sparse (typically $k \\ll d$). Most of the known theoretical\nresults involve assuming that the columns of the unknown $A$ have certain\nincoherence properties, and that the coefficient matrix $Y$ has random (or\npartly random) structure.\n  The goal of our work is to understand what can be said in the absence of such\nassumptions. Can we still find $A$ and $Y$ such that $X \\approx AY$? We show\nthat this is possible, if we allow violating the bounds on $m$ and $k$ by\nappropriate factors that depend on $k$ and the desired approximation. Our\nresults rely on an algorithm for what we call the threshold correlation\nproblem, which turns out to be related to hypercontractive norms of matrices.\nWe also show that our algorithmic ideas apply to a setting in which some of the\ncolumns of $X$ are outliers, thus giving similar guarantees even in this\nchallenging setting.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:11:27 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1905.12099", "submitter": "Piero Molino", "authors": "Piero Molino, Yang Wang, Jiawei Zhang", "title": "Parallax: Visualizing and Understanding the Semantics of Embedding\n  Spaces via Algebraic Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings are a fundamental component of many modern machine learning and\nnatural language processing models. Understanding them and visualizing them is\nessential for gathering insights about the information they capture and the\nbehavior of the models. State of the art in analyzing embeddings consists in\nprojecting them in two-dimensional planes without any interpretable semantics\nassociated to the axes of the projection, which makes detailed analyses and\ncomparison among multiple sets of embeddings challenging. In this work, we\npropose to use explicit axes defined as algebraic formulae over embeddings to\nproject them into a lower dimensional, but semantically meaningful subspace, as\na simple yet effective analysis and visualization methodology. This methodology\nassigns an interpretable semantics to the measures of variability and the axes\nof visualizations, allowing for both comparisons among different sets of\nembeddings and fine-grained inspection of the embedding spaces. We demonstrate\nthe power of the proposed methodology through a series of case studies that\nmake use of visualizations constructed around the underlying methodology and\nthrough a user study. The results show how the methodology is effective at\nproviding more profound insights than classical projection methods and how it\nis widely applicable to many other use cases.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:32:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Molino", "Piero", ""], ["Wang", "Yang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1905.12101", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan, Vitaly Shmatikov", "title": "Differential Privacy Has Disparate Impact on Model Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a popular mechanism for training machine\nlearning models with bounded leakage about the presence of specific points in\nthe training data. The cost of differential privacy is a reduction in the\nmodel's accuracy. We demonstrate that in the neural networks trained using\ndifferentially private stochastic gradient descent (DP-SGD), this cost is not\nborne equally: accuracy of DP models drops much more for the underrepresented\nclasses and subgroups.\n  For example, a gender classification model trained using DP-SGD exhibits much\nlower accuracy for black faces than for white faces. Critically, this gap is\nbigger in the DP model than in the non-DP model, i.e., if the original model is\nunfair, the unfairness becomes worse once DP is applied. We demonstrate this\neffect for a variety of tasks and models, including sentiment analysis of text\nand image classification. We then explain why DP training mechanisms such as\ngradient clipping and noise addition have disproportionate effect on the\nunderrepresented and more complex subgroups, resulting in a disparate reduction\nof model accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:39:44 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 02:46:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1905.12103", "submitter": "Florian Sch\\\"afer", "authors": "Florian Sch\\\"afer and Anima Anandkumar", "title": "Competitive Gradient Descent", "comments": "Appeared in NeurIPS 2019. This version corrects an error in theorem\n  2.2. Source code used for the numerical experiments can be found under\n  http://github.com/f-t-s/CGD. A high-level overview of this work can be found\n  under http://f-t-s.github.io/projects/cgd/", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm for the numerical computation of Nash equilibria\nof competitive two-player games. Our method is a natural generalization of\ngradient descent to the two-player setting where the update is given by the\nNash equilibrium of a regularized bilinear local approximation of the\nunderlying game. It avoids oscillatory and divergent behaviors seen in\nalternating gradient descent. Using numerical experiments and rigorous\nanalysis, we provide a detailed comparison to methods based on \\emph{optimism}\nand \\emph{consensus} and show that our method avoids making any unnecessary\nchanges to the gradient dynamics while achieving exponential (local)\nconvergence for (locally) convex-concave zero sum games. Convergence and\nstability properties of our method are robust to strong interactions between\nthe players, without adapting the stepsize, which is not the case with previous\nmethods. In our numerical experiments on non-convex-concave problems, existing\nmethods are prone to divergence and instability due to their sensitivity to\ninteractions among the players, whereas we never observe divergence of our\nalgorithm. The ability to choose larger stepsizes furthermore allows our\nalgorithm to achieve faster convergence, as measured by the number of model\nevaluations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:42:33 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 15:54:35 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 01:48:46 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sch\u00e4fer", "Florian", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1905.12105", "submitter": "Alexander Levine", "authors": "Alexander Levine, Sahil Singla, Soheil Feizi", "title": "Certifiably Robust Interpretation in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning interpretation is essential to explain the reasoning behind\nmodel predictions. Understanding the robustness of interpretation methods is\nimportant especially in sensitive domains such as medical applications since\ninterpretation results are often used in downstream tasks. Although\ngradient-based saliency maps are popular methods for deep learning\ninterpretation, recent works show that they can be vulnerable to adversarial\nattacks. In this paper, we address this problem and provide a certifiable\ndefense method for deep learning interpretation. We show that a sparsified\nversion of the popular SmoothGrad method, which computes the average saliency\nmaps over random perturbations of the input, is certifiably robust against\nadversarial perturbations. We obtain this result by extending recent bounds for\ncertifiably robust smooth classifiers to the interpretation setting.\nExperiments on ImageNet samples validate our theory.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:49:40 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 02:25:03 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:09:36 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Levine", "Alexander", ""], ["Singla", "Sahil", ""], ["Feizi", "Soheil", ""]]}, {"id": "1905.12106", "submitter": "Jeongyeol Kwon", "authors": "Jeongyeol Kwon, Constantine Caramanis", "title": "EM Converges for a Mixture of Many Linear Regressions", "comments": "SNR, initialization conditions improved from previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of the Expectation-Maximization (EM) algorithm for\nmixtures of linear regressions with an arbitrary number $k$ of components. We\nshow that as long as signal-to-noise ratio (SNR) is $\\tilde{\\Omega}(k)$,\nwell-initialized EM converges to the true regression parameters. Previous\nresults for $k \\geq 3$ have only established local convergence for the\nnoiseless setting, i.e., where SNR is infinitely large. Our results enlarge the\nscope to the environment with noises, and notably, we establish a statistical\nerror rate that is independent of the norm (or pairwise distance) of the\nregression parameters. In particular, our results imply exact recovery as\n$\\sigma \\rightarrow 0$, in contrast to most previous local convergence results\nfor EM, where the statistical error scaled with the norm of parameters.\nStandard moment-method approaches may be applied to guarantee we are in the\nregion where our local convergence guarantees apply.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:51:48 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:28:44 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Kwon", "Jeongyeol", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1905.12107", "submitter": "Igor Fedorov", "authors": "Igor Fedorov, Ryan P. Adams, Matthew Mattina, Paul N. Whatmough", "title": "SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained\n  Microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of processors in the world are actually microcontroller\nunits (MCUs), which find widespread use performing simple control tasks in\napplications ranging from automobiles to medical devices and office equipment.\nThe Internet of Things (IoT) promises to inject machine learning into many of\nthese every-day objects via tiny, cheap MCUs. However, these\nresource-impoverished hardware platforms severely limit the complexity of\nmachine learning models that can be deployed. For example, although\nconvolutional neural networks (CNNs) achieve state-of-the-art results on many\nvisual recognition tasks, CNN inference on MCUs is challenging due to severe\nfinite memory limitations. To circumvent the memory challenge associated with\nCNNs, various alternatives have been proposed that do fit within the memory\nbudget of an MCU, albeit at the cost of prediction accuracy. This paper\nchallenges the idea that CNNs are not suitable for deployment on MCUs. We\ndemonstrate that it is possible to automatically design CNNs which generalize\nwell, while also being small enough to fit onto memory-limited MCUs. Our Sparse\nArchitecture Search method combines neural architecture search with pruning in\na single, unified approach, which learns superior models on four popular IoT\ndatasets. The CNNs we find are more accurate and up to $4.35\\times$ smaller\nthan previous approaches, while meeting the strict MCU working memory\nconstraint.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:52:08 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Fedorov", "Igor", ""], ["Adams", "Ryan P.", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "1905.12115", "submitter": "Amelia Henriksen", "authors": "Amelia Henriksen and Rachel Ward", "title": "AdaOja: Adaptive Learning Rates for Streaming PCA", "comments": "15 pages, 8 figures, typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oja's algorithm has been the cornerstone of streaming methods in Principal\nComponent Analysis (PCA) since it was first proposed in 1982. However, Oja's\nalgorithm does not have a standardized choice of learning rate (step size) that\nboth performs well in practice and truly conforms to the online streaming\nsetting. In this paper, we propose a new learning rate scheme for Oja's method\ncalled AdaOja. This new algorithm requires only a single pass over the data and\ndoes not depend on knowing properties of the data set a priori. AdaOja is a\nnovel variation of the Adagrad algorithm to Oja's algorithm in the single\neigenvector case and extended to the multiple eigenvector case. We demonstrate\nfor dense synthetic data, sparse real-world data and dense real-world data that\nAdaOja outperforms common learning rate choices for Oja's method. We also show\nthat AdaOja performs comparably to state-of-the-art algorithms (History PCA and\nStreaming Power Method) in the same streaming PCA setting.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:02:24 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 20:46:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Henriksen", "Amelia", ""], ["Ward", "Rachel", ""]]}, {"id": "1905.12116", "submitter": "Tianlin Liu", "authors": "Tianlin Liu", "title": "Harnessing Slow Dynamics in Neuromorphic Computation", "comments": "Master thesis of Tianlin Liu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic Computing is a nascent research field in which models and\ndevices are designed to process information by emulating biological neural\nsystems. Thanks to their superior energy efficiency, analog neuromorphic\nsystems are highly promising for embedded, wearable, and implantable systems.\nHowever, optimizing neural networks deployed on these systems is challenging.\nOne main challenge is the so-called timescale mismatch: Dynamics of analog\ncircuits tend to be too fast to process real-time sensory inputs. In this\nthesis, we propose a few working solutions to slow down dynamics of on-chip\nspiking neural networks. We empirically show that, by harnessing slow dynamics,\nspiking neural networks on analog neuromorphic systems can gain non-trivial\nperformance boosts on a battery of real-time signal processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:20:38 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Liu", "Tianlin", ""]]}, {"id": "1905.12121", "submitter": "Yizhen Wang", "authors": "Yizhen Wang, Somesh Jha, Kamalika Chaudhuri", "title": "An Investigation of Data Poisoning Defenses for Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning attacks -- where an adversary can modify a small fraction of\ntraining data, with the goal of forcing the trained classifier to high loss --\nare an important threat for machine learning in many applications. While a body\nof prior work has developed attacks and defenses, there is not much general\nunderstanding on when various attacks and defenses are effective. In this work,\nwe undertake a rigorous study of defenses against data poisoning for online\nlearning. First, we study four standard defenses in a powerful threat model,\nand provide conditions under which they can allow or resist rapid poisoning. We\nthen consider a weaker and more realistic threat model, and show that the\nsuccess of the adversary in the presence of data poisoning defenses there\ndepends on the \"ease\" of the learning problem.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:42:29 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 17:43:59 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 23:44:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Yizhen", ""], ["Jha", "Somesh", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1905.12122", "submitter": "Oliver Ernst", "authors": "Oliver K. Ernst, Tom Bartol, Terrence Sejnowski, and Eric Mjolsness", "title": "Deep Learning Moment Closure Approximations using Dynamic Boltzmann\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moments of spatial probabilistic systems are often given by an infinite\nhierarchy of coupled differential equations. Moment closure methods are used to\napproximate a subset of low order moments by terminating the hierarchy at some\norder and replacing higher order terms with functions of lower order ones. For\na given system, it is not known beforehand which closure approximation is\noptimal, i.e. which higher order terms are relevant in the current regime.\nFurther, the generalization of such approximations is typically poor, as higher\norder corrections may become relevant over long timescales. We have developed a\nmethod to learn moment closure approximations directly from data using dynamic\nBoltzmann distributions (DBDs). The dynamics of the distribution are\nparameterized using basis functions from finite element methods, such that the\napproach can be applied without knowing the true dynamics of the system under\nconsideration. We use the hierarchical architecture of deep Boltzmann machines\n(DBMs) with multinomial latent variables to learn closure approximations for\nprogressively higher order spatial correlations. The learning algorithm uses a\ncentering transformation, allowing the dynamic DBM to be trained without the\nneed for pre-training. We demonstrate the method for a Lotka-Volterra system on\na lattice, a typical example in spatial chemical reaction networks. The\napproach can be applied broadly to learn deep generative models in applications\nwhere infinite systems of differential equations arise.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:43:54 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ernst", "Oliver K.", ""], ["Bartol", "Tom", ""], ["Sejnowski", "Terrence", ""], ["Mjolsness", "Eric", ""]]}, {"id": "1905.12126", "submitter": "Ethan Steinberg", "authors": "Ethan Steinberg, Peter J. Liu", "title": "Using Ontologies To Improve Performance In Massively Multi-label\n  Prediction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively multi-label prediction/classification problems arise in\nenvironments like health-care or biology where very precise predictions are\nuseful. One challenge with massively multi-label problems is that there is\noften a long-tailed frequency distribution for the labels, which results in few\npositive examples for the rare labels. We propose a solution to this problem by\nmodifying the output layer of a neural network to create a Bayesian network of\nsigmoids which takes advantage of ontology relationships between the labels to\nhelp share information between the rare and the more common labels. We apply\nthis method to the two massively multi-label tasks of disease prediction (ICD-9\ncodes) and protein function prediction (Gene Ontology terms) and obtain\nsignificant improvements in per-label AUROC and average precision for less\ncommon labels.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:55:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Steinberg", "Ethan", ""], ["Liu", "Peter J.", ""]]}, {"id": "1905.12127", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal and Fei Sha", "title": "Coordinated Exploration via Intrinsic Rewards for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks with sparse rewards is one of the most important challenges in\nreinforcement learning. In the single-agent setting, this challenge is\naddressed by introducing intrinsic rewards that motivate agents to explore\nunseen regions of their state spaces; however, applying these techniques\nnaively to the multi-agent setting results in agents exploring independently,\nwithout any coordination among themselves. Exploration in cooperative\nmulti-agent settings can be accelerated and improved if agents coordinate their\nexploration. In this paper we introduce a framework for designing intrinsic\nrewards which consider what other agents have explored such that the agents can\ncoordinate. Then, we develop an approach for learning how to dynamically select\nbetween several exploration modalities to maximize extrinsic rewards.\nConcretely, we formulate the approach as a hierarchical policy where a\nhigh-level controller selects among sets of policies trained on diverse\nintrinsic rewards and the low-level controllers learn the action policies of\nall agents under these specific rewards. We demonstrate the effectiveness of\nthe proposed approach in cooperative domains with sparse rewards where\nstate-of-the-art methods fail and challenging multi-stage tasks that\nnecessitate changing modes of coordination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:01:02 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 02:08:26 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 20:19:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1905.12131", "submitter": "Prudencio Tossou", "authors": "Prudencio Tossou, Basile Dura, Francois Laviolette, Mario Marchand,\n  Alexandre Lacoste", "title": "Adaptive Deep Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning provides an elegant and principled framework for\ncombining the structural properties of deep learning algorithms with the\nflexibility of kernel methods. By means of a deep neural network, we learn a\nparametrized kernel operator that can be combined with a differentiable kernel\nalgorithm during inference. While previous work within this framework has\nfocused on learning a single kernel for large datasets, we learn a kernel\nfamily for a variety of few-shot regression tasks. Compared to single deep\nkernel learning, our algorithm enables the identification of the appropriate\nkernel for each task during inference. As such, it is well adapted for complex\ntask distributions in a few-shot learning setting, which we demonstrate by\ncomparing against existing state-of-the-art algorithms using real-world,\nfew-shot regression tasks related to the field of drug discovery.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:20:05 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 12:18:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tossou", "Prudencio", ""], ["Dura", "Basile", ""], ["Laviolette", "Francois", ""], ["Marchand", "Mario", ""], ["Lacoste", "Alexandre", ""]]}, {"id": "1905.12135", "submitter": "Ervin Sejdic", "authors": "Yassin Khalifa, Justin Hawks, and Ervin Sejdic", "title": "Single neuron-based neural networks are as efficient as dense deep\n  neural networks in binary and multi-class recognition problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neuroscience have revealed many principles about neural\nprocessing. In particular, many biological systems were found to\nreconfigure/recruit single neurons to generate multiple kinds of decisions.\nSuch findings have the potential to advance our understanding of the design and\noptimization process of artificial neural networks. Previous work demonstrated\nthat dense neural networks are needed to shape complex decision surfaces\nrequired for AI-level recognition tasks. We investigate the ability to model\nhigh dimensional recognition problems using single or several neurons networks\nthat are relatively easier to train. By employing three datasets, we test the\nuse of a population of single neuron networks in performing multi-class\nrecognition tasks. Surprisingly, we find that sparse networks can be as\nefficient as dense networks in both binary and multi-class tasks. Moreover,\nsingle neuron networks demonstrate superior performance in binary\nclassification scheme and competing results when combined for multi-class\nrecognition.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:35:38 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Khalifa", "Yassin", ""], ["Hawks", "Justin", ""], ["Sejdic", "Ervin", ""]]}, {"id": "1905.12145", "submitter": "Marwa El Halabi", "authors": "Marwa El Halabi and Stefanie Jegelka", "title": "Optimal approximation for unconstrained non-submodular minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function minimization is a well studied problem; existing\nalgorithms solve it exactly or up to arbitrary accuracy. However, in many\napplications, the objective function is not exactly submodular. No theoretical\nguarantees exist in this case. While submodular minimization algorithms rely on\nintricate connections between submodularity and convexity, we show that these\nrelations can be extended sufficiently to obtain approximation guarantees for\nnon-submodular minimization. In particular, we prove how a projected\nsubgradient method can perform well even for certain non-submodular functions.\n  This includes important examples, such as objectives for structured sparse\nlearning and variance reduction in Bayesian optimization. We also extend this\nresult to noisy function evaluations. Our algorithm works in the value oracle\nmodel. We prove that in this model, the approximation result we obtain is the\nbest possible with a subexponential number of queries.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 00:33:42 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 19:15:43 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 14:51:41 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Halabi", "Marwa El", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.12149", "submitter": "Po-Wei Wang", "authors": "Po-Wei Wang, Priya L. Donti, Bryan Wilder, Zico Kolter", "title": "SATNet: Bridging deep learning and logical reasoning using a\n  differentiable satisfiability solver", "comments": "Accepted at ICML'19. The code can be found at\n  https://github.com/locuslab/satnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating logical reasoning within deep learning architectures has been a\nmajor goal of modern AI systems. In this paper, we propose a new direction\ntoward this goal by introducing a differentiable (smoothed) maximum\nsatisfiability (MAXSAT) solver that can be integrated into the loop of larger\ndeep learning systems. Our (approximate) solver is based upon a fast coordinate\ndescent approach to solving the semidefinite program (SDP) associated with the\nMAXSAT problem. We show how to analytically differentiate through the solution\nto this SDP and efficiently solve the associated backward pass. We demonstrate\nthat by integrating this solver into end-to-end learning systems, we can learn\nthe logical structure of challenging problems in a minimally supervised\nfashion. In particular, we show that we can learn the parity function using\nsingle-bit supervision (a traditionally hard task for deep networks) and learn\nhow to play 9x9 Sudoku solely from examples. We also solve a \"visual Sudok\"\nproblem that maps images of Sudoku puzzles to their associated logical\nsolutions by combining our MAXSAT solver with a traditional convolutional\narchitecture. Our approach thus shows promise in integrating logical structures\nwithin deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 00:47:35 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wang", "Po-Wei", ""], ["Donti", "Priya L.", ""], ["Wilder", "Bryan", ""], ["Kolter", "Zico", ""]]}, {"id": "1905.12150", "submitter": "Sreelekha Guggilam", "authors": "Sreelekha Guggilam and S. M. Arshad Zaidi and Varun Chandola and Abani\n  Patra", "title": "Bayesian Anomaly Detection Using Extreme Value Theory", "comments": "7 pages, 7 figures, The paper has been withdrawn due to major\n  modification in the automation model", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven anomaly detection methods typically build a model for the normal\nbehavior of the target system, and score each data instance with respect to\nthis model. A threshold is invariably needed to identify data instances with\nhigh (or low) scores as anomalies. This presents a practical limitation on the\napplicability of such methods, since most methods are sensitive to the choice\nof the threshold, and it is challenging to set optimal thresholds. We present a\nprobabilistic framework to explicitly model the normal and anomalous behaviors\nand probabilistically reason about the data. An extreme value theory based\nformulation is proposed to model the anomalous behavior as the extremes of the\nnormal behavior. As a specific instantiation, a joint non-parametric clustering\nand anomaly detection algorithm is proposed that models the normal behavior as\na Dirichlet Process Mixture Model.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 00:51:03 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:21:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Guggilam", "Sreelekha", ""], ["Zaidi", "S. M. Arshad", ""], ["Chandola", "Varun", ""], ["Patra", "Abani", ""]]}, {"id": "1905.12152", "submitter": "Arushi Gupta", "authors": "Arushi Gupta, Sanjeev Arora", "title": "A Simple Saliency Method That Passes the Sanity Checks", "comments": "Small typo on paragraph 3 of section 3 fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is great interest in \"saliency methods\" (also called \"attribution\nmethods\"), which give \"explanations\" for a deep net's decision, by assigning a\n\"score\" to each feature/pixel in the input. Their design usually involves\ncredit-assignment via the gradient of the output with respect to input.\nRecently Adebayo et al. [arXiv:1810.03292] questioned the validity of many of\nthese methods since they do not pass simple *sanity checks* which test whether\nthe scores shift/vanish when layers of the trained net are randomized, or when\nthe net is retrained using random labels for inputs.\n  We propose a simple fix to existing saliency methods that helps them pass\nsanity checks, which we call \"competition for pixels\". This involves computing\nsaliency maps for all possible labels in the classification task, and using a\nsimple competition among them to identify and remove less relevant pixels from\nthe map. The simplest variant of this is \"Competitive Gradient $\\odot$ Input\n(CGI)\": it is efficient, requires no additional training, and uses only the\ninput and gradient. Some theoretical justification is provided for it\n(especially for ReLU networks) and its performance is empirically demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:15:11 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 00:55:44 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gupta", "Arushi", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1905.12155", "submitter": "Michael Mitzenmacher", "authors": "Michael Mitzenmacher and Matteo Dell'Amico", "title": "The Supermarket Model with Known and Predicted Service Times", "comments": "Revision, draft version, 16 pages, future updates and corrections\n  possible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supermarket model refers to a system with a large number of queues, where\narriving customers choose $d$ queues at random and join the queue with the\nfewest customers. The supermarket model demonstrates the power of even small\namounts of choice, as compared to simply joining a queue chosen uniformly at\nrandom, for load balancing systems. In this work we perform simulation-based\nstudies to consider variations where service times for a customer are\npredicted, as might be done in modern settings using machine learning\ntechniques or related mechanisms. Our primary takeaway is that using even\nseemingly weak predictions of service times can yield significant benefits over\nblind First In First Out queueing in this context. However, some care must be\ntaken when using predicted service time information to both choose a queue and\norder elements for service within a queue; while in many cases using the\ninformation for both choosing and ordering is beneficial, in many of our\nsimulation settings we find that simply using the number of jobs to choose a\nqueue is better when using predicted service times to order jobs in a queue.\nAlthough this study is simulation based, our study leaves many natural\ntheoretical open questions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:33:45 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 14:44:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Dell'Amico", "Matteo", ""]]}, {"id": "1905.12158", "submitter": "Vikas Garg", "authors": "Vikas K. Garg and Tommi Jaakkola", "title": "Solving graph compression via optimal transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to graph compression by appeal to optimal\ntransport. The transport problem is seeded with prior information about node\nimportance, attributes, and edges in the graph. The transport formulation can\nbe setup for either directed or undirected graphs, and its dual\ncharacterization is cast in terms of distributions over the nodes. The\ncompression pertains to the support of node distributions and makes the problem\nchallenging to solve directly. To this end, we introduce Boolean relaxations\nand specify conditions under which these relaxations are exact. The relaxations\nadmit algorithms with provably fast convergence. Moreover, we provide an exact\n$O(d \\log d)$ algorithm for the subproblem of projecting a $d$-dimensional\nvector to transformed simplex constraints. Our method outperforms\nstate-of-the-art compression methods on graph classification.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:22:18 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Garg", "Vikas K.", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1905.12164", "submitter": "Tianye Zhang", "authors": "Tianye Zhang, Haozhe Feng, Zexian Chen, Can Wang, Yanhao Huang, Yong\n  Tang, Wei Chen", "title": "An Interactive Insight Identification and Annotation Framework for Power\n  Grid Pixel Maps using DenseU-Hierarchical VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insights in power grid pixel maps (PGPMs) refer to important facility\noperating states and unexpected changes in the power grid. Identifying insights\nhelps analysts understand the collaboration of various parts of the grid so\nthat preventive and correct operations can be taken to avoid potential\naccidents. Existing solutions for identifying insights in PGPMs are performed\nmanually, which may be laborious and expertise-dependent. In this paper, we\npropose an interactive insight identification and annotation framework by\nleveraging an enhanced variational autoencoder (VAE). In particular, a new\narchitecture, DenseU-Hierarchical VAE (DUHiV), is designed to learn\nrepresentations from large-sized PGPMs, which achieves a significantly tighter\nevidence lower bound (ELBO) than existing Hierarchical VAEs with a Multilayer\nPerceptron architecture. Our approach supports modulating the derived\nrepresentations in an interactive visual interface, discover potential insights\nand create multi-label annotations. Evaluations using real-world PGPMs datasets\nshow that our framework outperforms the baseline models in identifying and\nannotating insights.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 05:55:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zhang", "Tianye", ""], ["Feng", "Haozhe", ""], ["Chen", "Zexian", ""], ["Wang", "Can", ""], ["Huang", "Yanhao", ""], ["Tang", "Yong", ""], ["Chen", "Wei", ""]]}, {"id": "1905.12169", "submitter": "Vikas Garg", "authors": "Vikas K. Garg and Tommi Jaakkola", "title": "Strategic Prediction with Latent Aggregative Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of context dependent, incomplete information games\nto serve as structured prediction models for settings with significant\nstrategic interactions. Our games map the input context to outcomes by first\ncondensing the input into private player types that specify the utilities,\nweighted interactions, as well as the initial strategies for the players. The\ngame is played over multiple rounds where players respond to weighted\naggregates of their neighbors' strategies. The predicted output from the model\nis a mixed strategy profile (a near-Nash equilibrium) and each observation is\nthought of as a sample from this strategy profile. We introduce two new\naggregator paradigms with provably convergent game dynamics, and characterize\nthe conditions under which our games are identifiable from data. Our games can\nbe parameterized in a transferable manner so that the sets of players can\nchange from one game to another. We demonstrate empirically that our games as\nmodels can recover meaningful strategic interactions from real voting data.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:40:53 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Garg", "Vikas K.", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1905.12170", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Fang Chen, and Bogdan Gabrys", "title": "An Effective Multi-Resolution Hierarchical Granular Representation based\n  Classifier using General Fuzzy Min-Max Neural Network", "comments": "@20xx IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE Transactions on Fuzzy Systems, pp. 1-1, 2019", "doi": "10.1109/TFUZZ.2019.2956917", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by the practical demands for simplification of data towards being\nconsistent with human thinking and problem solving as well as tolerance of\nuncertainty, information granules are becoming important entities in data\nprocessing at different levels of data abstraction. This paper proposes a\nmethod to construct classifiers from multi-resolution hierarchical granular\nrepresentations (MRHGRC) using hyperbox fuzzy sets. The proposed approach forms\na series of granular inferences hierarchically through many levels of\nabstraction. An attractive characteristic of our classifier is that it can\nmaintain relatively high accuracy at a low degree of granularity based on\nreusing the knowledge learned from lower levels of abstraction. In addition,\nour approach can reduce the data size significantly as well as handling the\nuncertainty and incompleteness associated with data in real-world applications.\nThe construction process of the classifier consists of two phases. The first\nphase is to formulate the model at the greatest level of granularity, while the\nlater stage aims to reduce the complexity of the constructed model and deduce\nit from data at higher abstraction levels. Experimental outcomes conducted\ncomprehensively on both synthetic and real datasets indicated the efficiency of\nour method in terms of training time and predictive performance in comparison\nto other types of fuzzy min-max neural networks and common machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:44:07 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 06:35:50 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 22:42:27 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Chen", "Fang", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "1905.12171", "submitter": "Shaokai Ye", "authors": "Shaokai Ye, Sia Huat Tan, Kaidi Xu, Yanzhi Wang, Chenglong Bao,\n  Kaisheng Ma", "title": "Brain-inspired reverse adversarial examples", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A human does not have to see all elephants to recognize an animal as an\nelephant. On contrast, current state-of-the-art deep learning approaches\nheavily depend on the variety of training samples and the capacity of the\nnetwork. In practice, the size of network is always limited and it is\nimpossible to access all the data samples. Under this circumstance, deep\nlearning models are extremely fragile to human-imperceivable adversarial\nexamples, which impose threats to all safety critical systems. Inspired by the\nassociation and attention mechanisms of the human brain, we propose reverse\nadversarial examples method that can greatly improve models' robustness on\nunseen data. Experiments show that our reverse adversarial method can improve\naccuracy on average 19.02% on ResNet18, MobileNet, and VGG16 on unseen data\ntransformation. Besides, the proposed method is also applicable to compressed\nmodels and shows potential to compensate the robustness drop brought by model\nquantization - an absolute 30.78% accuracy improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:58:55 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ye", "Shaokai", ""], ["Tan", "Sia Huat", ""], ["Xu", "Kaidi", ""], ["Wang", "Yanzhi", ""], ["Bao", "Chenglong", ""], ["Ma", "Kaisheng", ""]]}, {"id": "1905.12173", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Julien Mairal", "title": "On the Inductive Bias of Neural Tangent Kernels", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural networks are heavily over-parameterized, making the\noptimization algorithm a crucial ingredient for learning predictive models with\ngood generalization properties. A recent line of work has shown that in a\ncertain over-parameterized regime, the learning dynamics of gradient descent\nare governed by a certain kernel obtained at initialization, called the neural\ntangent kernel. We study the inductive bias of learning in such a regime by\nanalyzing this kernel and the corresponding function space (RKHS). In\nparticular, we study smoothness, approximation, and stability properties of\nfunctions with finite norm, including stability to image deformations in the\ncase of convolutional networks, and compare to other known kernels for similar\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:49:32 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:38:51 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bietti", "Alberto", ""], ["Mairal", "Julien", ""]]}, {"id": "1905.12176", "submitter": "Eli Shlizerman", "authors": "Kun Su, Eli Shlizerman", "title": "Clustering and Recognition of Spatiotemporal Features through\n  Interpretable Embedding of Sequence to Sequence Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder recurrent neural network models (RNN Seq2Seq) have achieved\ngreat success in ubiquitous areas of computation and applications. It was shown\nto be successful in modeling data with both temporal and spatial dependencies\nfor translation or prediction tasks. In this study, we propose an embedding\napproach to visualize and interpret the representation of data by these models.\nFurthermore, we show that the embedding is an effective method for unsupervised\nlearning and can be utilized to estimate the optimality of model training. In\nparticular, we demonstrate that embedding space projections of the decoder\nstates of RNN Seq2Seq model trained on sequences prediction are organized in\nclusters capturing similarities and differences in the dynamics of these\nsequences. Such performance corresponds to an unsupervised clustering of any\nspatio-temporal features and can be employed for time-dependent problems such\nas temporal segmentation, clustering of dynamic activity, self-supervised\nclassification, action recognition, failure prediction, etc. We test and\ndemonstrate the application of the embedding methodology to time-sequences of\n3D human body poses. We show that the methodology provides a high-quality\nunsupervised categorization of movements.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:56:06 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 16:44:40 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Su", "Kun", ""], ["Shlizerman", "Eli", ""]]}, {"id": "1905.12177", "submitter": "Jaime Roquero Gimenez", "authors": "Jaime Roquero Gimenez, James Zou", "title": "Discovering Conditionally Salient Features with Statistical Guarantees", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of feature selection is to identify important features that are\nrelevant to explain an outcome variable. Most of the work in this domain has\nfocused on identifying globally relevant features, which are features that are\nrelated to the outcome using evidence across the entire dataset. We study a\nmore fine-grained statistical problem: conditional feature selection, where a\nfeature may be relevant depending on the values of the other features. For\nexample in genetic association studies, variant $A$ could be associated with\nthe phenotype in the entire dataset, but conditioned on variant $B$ being\npresent it might be independent of the phenotype. In this sense, variant $A$ is\nglobally relevant, but conditioned on $B$ it is no longer locally relevant in\nthat region of the feature space. We present a generalization of the knockoff\nprocedure that performs conditional feature selection while controlling a\ngeneralization of the false discovery rate (FDR) to the conditional setting. By\nexploiting the feature/response model-free framework of the knockoffs, the\nquality of the statistical FDR guarantee is not degraded even when we perform\nconditional feature selections. We implement this method and present an\nalgorithm that automatically partitions the feature space such that it enhances\nthe differences between selected sets in different regions, and validate the\nstatistical theoretical results with experiments.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 01:56:18 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gimenez", "Jaime Roquero", ""], ["Zou", "James", ""]]}, {"id": "1905.12181", "submitter": "Angel Daruna", "authors": "Angel Daruna, Weiyu Liu, Zsolt Kira, Sonia Chernova", "title": "Leveraging Semantics for Incremental Learning in Multi-Relational\n  Embeddings", "comments": "10 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service robots benefit from encoding information in semantically meaningful\nways to enable more robust task execution. Prior work has shown\nmulti-relational embeddings can encode semantic knowledge graphs to promote\ngeneralizability and scalability, but only within a batched learning paradigm.\nWe present Incremental Semantic Initialization (ISI), an incremental learning\napproach that enables novel semantic concepts to be initialized in the\nembedding in relation to previously learned embeddings of semantically similar\nconcepts. We evaluate ISI on mined AI2Thor and MatterPort3D datasets; our\nexperiments show that on average ISI improves immediate query performance by\n41.4%. Additionally, ISI methods on average reduced the number of epochs\nrequired to approach model convergence by 78.2%.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 02:38:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 19:03:09 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Daruna", "Angel", ""], ["Liu", "Weiyu", ""], ["Kira", "Zsolt", ""], ["Chernova", "Sonia", ""]]}, {"id": "1905.12185", "submitter": "David Brandfonbrener", "authors": "David Brandfonbrener and Joan Bruna", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there are convergence guarantees for temporal difference (TD) learning\nwhen using linear function approximators, the situation for nonlinear models is\nfar less understood, and divergent examples are known. Here we take a first\nstep towards extending theoretical convergence guarantees to TD learning with\nnonlinear function approximation. More precisely, we consider the expected\nlearning dynamics of the TD(0) algorithm for value estimation. As the step-size\nconverges to zero, these dynamics are defined by a nonlinear ODE which depends\non the geometry of the space of function approximators, the structure of the\nunderlying Markov chain, and their interaction. We find a set of function\napproximators that includes ReLU networks and has geometry amenable to TD\nlearning regardless of environment, so that the solution performs about as well\nas linear TD in the worst case. Then, we show how environments that are more\nreversible induce dynamics that are better for TD learning and prove global\nconvergence to the true value function for well-conditioned function\napproximators. Finally, we generalize a divergent counterexample to a family of\ndivergent problems to demonstrate how the interaction between approximator and\nenvironment can go wrong and to motivate the assumptions needed to prove\nconvergence.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 02:47:43 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 18:44:56 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 13:42:01 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 16:15:04 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Brandfonbrener", "David", ""], ["Bruna", "Joan", ""]]}, {"id": "1905.12194", "submitter": "Yufei Cui", "authors": "Yufei Cui, Wuguannan Yao, Qiao Li, Antoni B. Chan, Chun Jason Xue", "title": "Accelerating Monte Carlo Bayesian Inference via Approximating Predictive\n  Uncertainty over Simplex", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3042525", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the predictive uncertainty of a Bayesian learning model is\ncritical in various decision-making problems, e.g., reinforcement learning,\ndetecting adversarial attack, self-driving car. As the model posterior is\nalmost always intractable, most efforts were made on finding an accurate\napproximation the true posterior. Even though a decent estimation of the model\nposterior is obtained, another approximation is required to compute the\npredictive distribution over the desired output. A common accurate solution is\nto use Monte Carlo (MC) integration. However, it needs to maintain a large\nnumber of samples, evaluate the model repeatedly and average multiple model\noutputs. In many real-world cases, this is computationally prohibitive. In this\nwork, assuming that the exact posterior or a decent approximation is obtained,\nwe propose a generic framework to approximate the output probability\ndistribution induced by model posterior with a parameterized model and in an\namortized fashion. The aim is to approximate the true uncertainty of a specific\nBayesian model, meanwhile alleviating the heavy workload of MC integration at\ntesting time. The proposed method is universally applicable to Bayesian\nclassification models that allow for posterior sampling. Theoretically, we show\nthat the idea of amortization incurs no additional costs on approximation\nperformance. Empirical results validate the strong practical performance of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:18:21 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 03:46:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cui", "Yufei", ""], ["Yao", "Wuguannan", ""], ["Li", "Qiao", ""], ["Chan", "Antoni B.", ""], ["Xue", "Chun Jason", ""]]}, {"id": "1905.12197", "submitter": "Panpan Cai", "authors": "Panpan Cai, Yuanfu Luo, Aseem Saxena, David Hsu, Wee Sun Lee", "title": "LeTS-Drive: Driving in a Crowd by Learning from Tree Search", "comments": null, "journal-ref": "Proc. Robotics: Science & Systems (RSS), 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving in a crowded environment, e.g., a busy traffic\nintersection, is an unsolved challenge for robotics. The robot vehicle must\ncontend with a dynamic and partially observable environment, noisy sensors, and\nmany agents. A principled approach is to formalize it as a Partially Observable\nMarkov Decision Process (POMDP) and solve it through online belief-tree search.\nTo handle a large crowd and achieve real-time performance in this very\nchallenging setting, we propose LeTS-Drive, which integrates online POMDP\nplanning and deep learning. It consists of two phases. In the offline phase, we\nlearn a policy and the corresponding value function by imitating the belief\ntree search. In the online phase, the learned policy and value function guide\nthe belief tree search. LeTS-Drive leverages the robustness of planning and the\nruntime efficiency of learning to enhance the performance of both. Experimental\nresults in simulation show that LeTS-Drive outperforms either planning or\nimitation learning alone and develops sophisticated driving skills.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:27:01 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Cai", "Panpan", ""], ["Luo", "Yuanfu", ""], ["Saxena", "Aseem", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1905.12200", "submitter": "Rickard Br\\\"uel Gabrielsson", "authors": "Rickard Br\\\"uel-Gabrielsson, Bradley J. Nelson, Anjan Dwaraknath,\n  Primoz Skraba, Leonidas J. Guibas, Gunnar Carlsson", "title": "A Topology Layer for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology applied to real world data using persistent homology has started to\nfind applications within machine learning, including deep learning. We present\na differentiable topology layer that computes persistent homology based on\nlevel set filtrations and edge-based filtrations. We present three novel\napplications: the topological layer can (i) regularize data reconstruction or\nthe weights of machine learning models, (ii) construct a loss on the output of\na deep generative network to incorporate topological priors, and (iii) perform\ntopological adversarial attacks on deep networks trained with persistence\nfeatures. The code (www.github.com/bruel-gabrielsson/TopologyLayer) is publicly\navailable and we hope its availability will facilitate the use of persistent\nhomology in deep learning and other gradient based applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:46:32 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 08:25:16 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Br\u00fcel-Gabrielsson", "Rickard", ""], ["Nelson", "Bradley J.", ""], ["Dwaraknath", "Anjan", ""], ["Skraba", "Primoz", ""], ["Guibas", "Leonidas J.", ""], ["Carlsson", "Gunnar", ""]]}, {"id": "1905.12202", "submitter": "Xiao Zhang", "authors": "Saeed Mahloujifar, Xiao Zhang, Mohammad Mahmoody, David Evans", "title": "Empirically Measuring Concentration: Fundamental Limits on Intrinsic\n  Robustness", "comments": "17 pages, 3 figures, 5 tables; NeurIPS final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have shown that adversarial examples that fool classifiers\ncan be found by minimally perturbing a normal input. Recent theoretical\nresults, starting with Gilmer et al. (2018b), show that if the inputs are drawn\nfrom a concentrated metric probability space, then adversarial examples with\nsmall perturbation are inevitable. A concentrated space has the property that\nany subset with $\\Omega(1)$ (e.g., 1/100) measure, according to the imposed\ndistribution, has small distance to almost all (e.g., 99/100) of the points in\nthe space. It is not clear, however, whether these theoretical results apply to\nactual distributions such as images. This paper presents a method for\nempirically measuring and bounding the concentration of a concrete dataset\nwhich is proven to converge to the actual concentration. We use it to\nempirically estimate the intrinsic robustness to $\\ell_\\infty$ and $\\ell_2$\nperturbations of several image classification benchmarks. Code for our\nexperiments is available at\nhttps://github.com/xiaozhanguva/Measure-Concentration.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:51:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:36:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Zhang", "Xiao", ""], ["Mahmoody", "Mohammad", ""], ["Evans", "David", ""]]}, {"id": "1905.12203", "submitter": "Guoxian Yu", "authors": "Xuanwu Liu, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang\n  Zhang", "title": "Weakly-paired Cross-Modal Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing has been widely adopted for large-scale data retrieval in many\ndomains, due to its low storage cost and high retrieval speed. Existing\ncross-modal hashing methods optimistically assume that the correspondence\nbetween training samples across modalities are readily available. This\nassumption is unrealistic in practical applications. In addition, these methods\ngenerally require the same number of samples across different modalities, which\nrestricts their flexibility. We propose a flexible cross-modal hashing approach\n(Flex-CMH) to learn effective hashing codes from weakly-paired data, whose\ncorrespondence across modalities are partially (or even totally) unknown.\nFlexCMH first introduces a clustering-based matching strategy to explore the\nlocal structure of each cluster, and thus to find the potential correspondence\nbetween clusters (and samples therein) across modalities. To reduce the impact\nof an incomplete correspondence, it jointly optimizes in a unified objective\nfunction the potential correspondence, the cross-modal hashing functions\nderived from the correspondence, and a hashing quantitative loss. An\nalternative optimization technique is also proposed to coordinate the\ncorrespondence and hash functions, and to reinforce the reciprocal effects of\nthe two objectives. Experiments on publicly multi-modal datasets show that\nFlexCMH achieves significantly better results than state-of-the-art methods,\nand it indeed offers a high degree of flexibility for practical cross-modal\nhashing tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:59:08 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Liu", "Xuanwu", ""], ["Wang", "Jun", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1905.12204", "submitter": "Hyunwook Kang", "authors": "Hyunwook Kang, Aydar Mynbay, James R. Morrison, Jinkyoo Park", "title": "Learning scalable and transferable multi-robot/machine sequential\n  assignment planning via graph embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can the success of reinforcement learning methods for simple combinatorial\noptimization problems be extended to multi-robot sequential assignment\nplanning? In addition to the challenge of achieving near-optimal performance in\nlarge problems, transferability to an unseen number of robots and tasks is\nanother key challenge for real-world applications. In this paper, we suggest a\nmethod that achieves the first success in both challenges for robot/machine\nscheduling problems.\n  Our method comprises of three components. First, we show a robot scheduling\nproblem can be expressed as a random probabilistic graphical model (PGM). We\ndevelop a mean-field inference method for random PGM and use it for Q-function\ninference. Second, we show that transferability can be achieved by carefully\ndesigning two-step sequential encoding of problem state. Third, we resolve the\ncomputational scalability issue of fitted Q-iteration by suggesting a heuristic\nauction-based Q-iteration fitting method enabled by transferability we\nachieved.\n  We apply our method to discrete-time, discrete space problems (Multi-Robot\nReward Collection (MRRC)) and scalably achieve 97% optimality with\ntransferability. This optimality is maintained under stochastic contexts. By\nextending our method to continuous time, continuous space formulation, we claim\nto be the first learning-based method with scalable performance among\nmulti-machine scheduling problems; our method scalability achieves comparable\nperformance to popular metaheuristics in Identical parallel machine scheduling\n(IPMS) problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:02:41 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 16:51:06 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:44:13 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kang", "Hyunwook", ""], ["Mynbay", "Aydar", ""], ["Morrison", "James R.", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1905.12207", "submitter": "Joe Kileel", "authors": "Joe Kileel, Matthew Trager, Joan Bruna", "title": "On the Expressive Power of Deep Polynomial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep neural networks with polynomial activations, particularly their\nexpressive power. For a fixed architecture and activation degree, a polynomial\nneural network defines an algebraic map from weights to polynomials. The image\nof this map is the functional space associated to the network, and it is an\nirreducible algebraic variety upon taking closure. This paper proposes the\ndimension of this variety as a precise measure of the expressive power of\npolynomial neural networks. We obtain several theoretical results regarding\nthis dimension as a function of architecture, including an exact formula for\nhigh activation degrees, as well as upper and lower bounds on layer widths in\norder for deep polynomials networks to fill the ambient functional space. We\nalso present computational evidence that it is profitable in terms of\nexpressiveness for layer widths to increase monotonically and then decrease\nmonotonically. Finally, we link our study to favorable optimization properties\nwhen training weights, and we draw intriguing connections with tensor and\npolynomial decompositions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:21:40 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kileel", "Joe", ""], ["Trager", "Matthew", ""], ["Bruna", "Joan", ""]]}, {"id": "1905.12213", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Giovanni Paolini, Stefano Soatto", "title": "Where is the Information in a Deep Neural Network?", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA-TR:190005", "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whatever information a deep neural network has gleaned from training data is\nencoded in its weights. How this information affects the response of the\nnetwork to future data remains largely an open question. Indeed, even defining\nand measuring information entails some subtleties, since a trained network is a\ndeterministic map, so standard information measures can be degenerate. We\nmeasure information in a neural network via the optimal trade-off between\naccuracy of the response and complexity of the weights, measured by their\ncoding length. Depending on the choice of code, the definition can reduce to\nstandard measures such as Shannon Mutual Information and Fisher Information.\nHowever, the more general definition allows us to relate information to\ngeneralization and invariance, through a novel notion of effective information\nin the activations of a deep network. We establish a novel relation between the\ninformation in the weights and the effective information in the activations,\nand use this result to show that models with low (information) complexity not\nonly generalize better, but are bound to learn invariant representations of\nfuture inputs. These relations hinge not only on the architecture of the model,\nbut also on how it is trained, highlighting the complex inter-dependency\nbetween the class of functions implemented by deep neural networks, the loss\nfunction used for training them from finite data, and the inductive bias\nimplicit in the optimization.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:38:54 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 03:15:02 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 06:55:52 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 11:02:47 GMT"}, {"version": "v5", "created": "Mon, 22 Jun 2020 03:34:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Achille", "Alessandro", ""], ["Paolini", "Giovanni", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.12217", "submitter": "Liwei Wu", "authors": "Liwei Wu, Hsiang-Fu Yu, Nikhil Rao, James Sharpnack, Cho-Jui Hsieh", "title": "Graph DNA: Deep Neighborhood Aware Graph Encoding for Collaborative\n  Filtering", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider recommender systems with side information in the\nform of graphs. Existing collaborative filtering algorithms mainly utilize only\nimmediate neighborhood information and have a hard time taking advantage of\ndeeper neighborhoods beyond 1-2 hops. The main caveat of exploiting deeper\ngraph information is the rapidly growing time and space complexity when\nincorporating information from these neighborhoods. In this paper, we propose\nusing Graph DNA, a novel Deep Neighborhood Aware graph encoding algorithm, for\nexploiting deeper neighborhood information. DNA encoding computes approximate\ndeep neighborhood information in linear time using Bloom filters, a\nspace-efficient probabilistic data structure and results in a per-node encoding\nthat is logarithmic in the number of nodes in the graph. It can be used in\nconjunction with both feature-based and graph-regularization-based\ncollaborative filtering algorithms. Graph DNA has the advantages of being\nmemory and time efficient and providing additional regularization when compared\nto directly using higher order graph information. We conduct experiments on\nreal-world datasets, showing graph DNA can be easily used with 4 popular\ncollaborative filtering algorithms and consistently leads to a performance\nboost with little computational and memory overhead.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:57:02 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wu", "Liwei", ""], ["Yu", "Hsiang-Fu", ""], ["Rao", "Nikhil", ""], ["Sharpnack", "James", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1905.12218", "submitter": "Pengfei Jin", "authors": "Pengfei Jin, Tianhao Lai, Rongjie Lai, Bin Dong", "title": "NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on\n  Point Clouds", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution plays a crucial role in various applications in signal and image\nprocessing, analysis, and recognition. It is also the main building block of\nconvolution neural networks (CNNs). Designing appropriate convolution neural\nnetworks on manifold-structured point clouds can inherit and empower recent\nadvances of CNNs to analyzing and processing point cloud data. However, one of\nthe major challenges is to define a proper way to \"sweep\" filters through the\npoint cloud as a natural generalization of the planar convolution and to\nreflect the point cloud's geometry at the same time. In this paper, we consider\ngeneralizing convolution by adapting parallel transport on the point cloud.\nInspired by a triangulated surface-based method [Stefan C. Schonsheck, Bin\nDong, and Rongjie Lai, arXiv:1805.07857.], we propose the Narrow-Band Parallel\nTransport Convolution (NPTC) using a specifically defined connection on a\nvoxel-based narrow-band approximation of point cloud data. With that, we\nfurther propose a deep convolutional neural network based on NPTC (called\nNPTC-net) for point cloud classification and segmentation. Comprehensive\nexperiments show that the proposed NPTC-net achieves similar or better results\nthan current state-of-the-art methods on point cloud classification and\nsegmentation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:07:26 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:30:41 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 13:18:10 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jin", "Pengfei", ""], ["Lai", "Tianhao", ""], ["Lai", "Rongjie", ""], ["Dong", "Bin", ""]]}, {"id": "1905.12224", "submitter": "Tomoya Murata", "authors": "Tomoya Murata, Taiji Suzuki", "title": "Accelerated Sparsified SGD with Error Feedback", "comments": "25 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic gradient method for synchronous distributed optimization is\nstudied. For reducing communication cost, we particularly focus on utilization\nof compression of communicated gradients. Several work has shown that\n{\\it{sparsified}} stochastic gradient descent method (SGD) with {\\it{error\nfeedback}} asymptotically achieves the same rate as (non-sparsified) parallel\nSGD. However, from a viewpoint of non-asymptotic behavior, the compression\nerror may cause slower convergence than non-sparsified SGD in early iterations.\nThis is problematic in practical situations since early stopping is often\nadopted to maximize the generalization ability of learned models. For improving\nthe previous results, we propose and theoretically analyse a sparsified\nstochastic gradient method with error feedback scheme combined with\n{\\it{Nesterov's acceleration}}. It is shown that the necessary per iteration\ncommunication cost for maintaining the same rate as vanilla SGD can be smaller\nthan non-accelerated methods in convex and even in nonconvex optimization\nproblems. This indicates that our proposed method makes a better use of\ncompressed information than previous methods. Numerical experiments are\nprovided and empirically validates our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:34:59 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:57:30 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Murata", "Tomoya", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1905.12226", "submitter": "Minlong Peng", "authors": "Minlong Peng, Qi Zhang", "title": "Address Instance-level Label Prediction in Multiple Instance Learning", "comments": "This work address Multiple Instance Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{Multiple Instance Learning} (MIL) is concerned with learning from\nbags of instances, where only bag labels are given and instance labels are\nunknown. Existent approaches in this field were mainly designed for the\nbag-level label prediction (predict labels for bags) but not the instance-level\n(predict labels for instances), with the task loss being only defined at the\nbag level. This restricts their application in many tasks, where the\ninstance-level labels are more interested. In this paper, we propose a novel\nalgorithm, whose loss is specifically defined at the instance level, to address\ninstance-level label prediction in MIL. We prove that the loss of this\nalgorithm can be unbiasedly and consistently estimated without using instance\nlabels, under the i.i.d assumption. Empirical study validates the above\nstatements and shows that the proposed algorithm can achieve superior\ninstance-level and comparative bag-level performance, compared to\nstate-of-the-art MIL methods. In addition, it shows that the proposed method\ncan achieve similar results as the fully supervised model (trained with\ninstance labels) for label prediction at the instance level.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:36:06 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Peng", "Minlong", ""], ["Zhang", "Qi", ""]]}, {"id": "1905.12247", "submitter": "Yuansi Chen", "authors": "Yuansi Chen, Raaz Dwivedi, Martin J. Wainwright, Bin Yu", "title": "Fast mixing of Metropolized Hamiltonian Monte Carlo: Benefits of\n  multi-step gradients", "comments": "73 pages, 2 figures, fixed a mistake in the proof of Lemma 11,\n  accepted in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a state-of-the-art Markov chain Monte Carlo\nsampling algorithm for drawing samples from smooth probability densities over\ncontinuous spaces. We study the variant most widely used in practice,\nMetropolized HMC with the St\\\"{o}rmer-Verlet or leapfrog integrator, and make\ntwo primary contributions. First, we provide a non-asymptotic upper bound on\nthe mixing time of the Metropolized HMC with explicit choices of step-size and\nnumber of leapfrog steps. This bound gives a precise quantification of the\nfaster convergence of Metropolized HMC relative to simpler MCMC algorithms such\nas the Metropolized random walk, or Metropolized Langevin algorithm. Second, we\nprovide a general framework for sharpening mixing time bounds of Markov chains\ninitialized at a substantial distance from the target distribution over\ncontinuous spaces. We apply this sharpening device to the Metropolized random\nwalk and Langevin algorithms, thereby obtaining improved mixing time bounds\nfrom a non-warm initial distribution.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:05:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 00:11:41 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 17:16:33 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chen", "Yuansi", ""], ["Dwivedi", "Raaz", ""], ["Wainwright", "Martin J.", ""], ["Yu", "Bin", ""]]}, {"id": "1905.12251", "submitter": "Feng Zhou", "authors": "Feng Zhou, Zhidong Li, Xuhui Fan, Yang Wang, Arcot Sowmya, Fang Chen", "title": "Efficient EM-Variational Inference for Hawkes Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical Hawkes process, the baseline intensity and triggering kernel are\nassumed to be a constant and parametric function respectively, which limits the\nmodel flexibility. To generalize it, we present a fully Bayesian nonparametric\nmodel, namely Gaussian process modulated Hawkes process and propose an\nEM-variational inference scheme. In this model, a transformation of Gaussian\nprocess is used as a prior on the baseline intensity and triggering kernel. By\nintroducing a latent branching structure, the inference of baseline intensity\nand triggering kernel is decoupled and the variational inference scheme is\nembedded into an EM framework naturally. We also provide a series of schemes to\naccelerate the inference. Results of synthetic and real data experiments show\nthat the underlying baseline intensity and triggering kernel can be recovered\nwithout parametric restriction and our Bayesian nonparametric estimation is\nsuperior to other state of the arts.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:21:28 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 03:55:32 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhou", "Feng", ""], ["Li", "Zhidong", ""], ["Fan", "Xuhui", ""], ["Wang", "Yang", ""], ["Sowmya", "Arcot", ""], ["Chen", "Fang", ""]]}, {"id": "1905.12253", "submitter": "Alexander Keller", "authors": "Gon\\c{c}alo Mordido and Matthijs Van Keirsbilck and Alexander Keller", "title": "Instant Quantization of Neural Networks using Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low bit-width integer weights and activations are very important for\nefficient inference, especially with respect to lower power consumption. We\npropose Monte Carlo methods to quantize the weights and activations of\npre-trained neural networks without any re-training. By performing importance\nsampling we obtain quantized low bit-width integer values from full-precision\nweights and activations. The precision, sparsity, and complexity are easily\nconfigurable by the amount of sampling performed. Our approach, called Monte\nCarlo Quantization (MCQ), is linear in both time and space, with the resulting\nquantized, sparse networks showing minimal accuracy loss when compared to the\noriginal full-precision networks. Our method either outperforms or achieves\ncompetitive results on multiple benchmarks compared to previous quantization\nmethods that do require additional training.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:31:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 03:48:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Van Keirsbilck", "Matthijs", ""], ["Keller", "Alexander", ""]]}, {"id": "1905.12254", "submitter": "Adriana-Simona Mihaita Dr.", "authors": "Adriana-Simona Mihaita, Zheyuan Liu, Chen Cai, Marian-Andrei Rizoiu", "title": "Arterial incident duration prediction using a bi-level framework of\n  extreme gradient-tree boosting", "comments": "12 pages, 10 figures, ITS World Congress 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting traffic incident duration is a major challenge for many traffic\ncentres around the world. Most research studies focus on predicting the\nincident duration on motorways rather than arterial roads, due to a high\nnetwork complexity and lack of data. In this paper we propose a bi-level\nframework for predicting the accident duration on arterial road networks in\nSydney, based on operational requirements of incident clearance target which is\nless than 45 minutes. Using incident baseline information, we first deploy a\nclassification method using various ensemble tree models in order to predict\nwhether a new incident will be cleared in less than 45min or not. If the\nincident was classified as short-term, then various regression models are\ndeveloped for predicting the actual incident duration in minutes by\nincorporating various traffic flow features. After outlier removal and\nintensive model hyper-parameter tuning through randomized search and\ncross-validation, we show that the extreme gradient boost approach outperformed\nall models, including the gradient-boosted decision-trees by almost 53%.\nFinally, we perform a feature importance evaluation for incident duration\nprediction and show that the best prediction results are obtained when\nleveraging the real-time traffic flow in vicinity road sections to the reported\naccident location.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:37:17 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Mihaita", "Adriana-Simona", ""], ["Liu", "Zheyuan", ""], ["Cai", "Chen", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "1905.12256", "submitter": "Kyungeun Lee", "authors": "Kyungeun Lee, Wonjong Rhee", "title": "DDP-GCN: Multi-Graph Convolutional Network for Spatiotemporal Traffic\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic speed forecasting is one of the core problems in Intelligent\nTransportation Systems. For a more accurate prediction, recent studies started\nusing not only the temporal speed patterns but also the spatial information on\nthe road network through the graph convolutional networks. Even though the road\nnetwork is highly complex due to its non-Euclidean and directional\ncharacteristics, previous approaches mainly focus on modeling the spatial\ndependencies only with the distance. In this paper, we identify two essential\nspatial dependencies in traffic forecasting in addition to distance, direction\nand positional relationship, for designing basic graph elements as the smallest\nbuilding blocks. Using the building blocks, we suggest DDP-GCN (Distance,\nDirection, and Positional relationship Graph Convolutional Network) to\nincorporate the three spatial relationships into prediction network for traffic\nforecasting. We evaluate the proposed model with two large-scale real-world\ndatasets, and find 7.40% average improvement for 1-hour forecasting in highly\ncomplex urban networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:46:37 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:06:07 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Lee", "Kyungeun", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1905.12260", "submitter": "Karan Singhal", "authors": "Karan Singhal, Karthik Raman, Balder ten Cate", "title": "Learning Multilingual Word Embeddings Using Image-Text Data", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-1807", "report-no": "W19-1807", "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest recently in learning multilingual word\nembeddings -- in which semantically similar words across languages have similar\nembeddings. State-of-the-art approaches have relied on expensive labeled data,\nwhich is unavailable for low-resource languages, or have involved post-hoc\nunification of monolingual embeddings. In the present paper, we investigate the\nefficacy of multilingual embeddings learned from weakly-supervised image-text\ndata. In particular, we propose methods for learning multilingual embeddings\nusing image-text data, by enforcing similarity between the representations of\nthe image and that of the text. Our experiments reveal that even without using\nany expensive labeled data, a bag-of-words-based embedding model trained on\nimage-text data achieves performance comparable to the state-of-the-art on\ncrosslingual semantic similarity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:17 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Singhal", "Karan", ""], ["Raman", "Karthik", ""], ["Cate", "Balder ten", ""]]}, {"id": "1905.12262", "submitter": "Antonio Bruto da Costa", "authors": "Antonio Anastasio Bruto da Costa and Pallab Dasgupta", "title": "Learning Temporal Causal Sequence Relationships from Real-Time\n  Time-Series", "comments": "This article appears in the Journal of Artificial Intelligence", "journal-ref": "Journal of Artificial Intelligence Research, Volume 70 (2021)\n  205-243", "doi": "10.1613/jair.1.12395", "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to mine temporal causal sequences that explain observed events\n(consequents) in time-series traces. Causal explanations of key events in a\ntime-series has applications in design debugging, anomaly detection, planning,\nroot-cause analysis and many more. We make use of decision trees and interval\narithmetic to mine sequences that explain defining events in the time-series.\nWe propose modified decision tree construction metrics to handle the\nnon-determinism introduced by the temporal dimension. The mined sequences are\nexpressed in a readable temporal logic language that is easy to interpret. The\napplication of the proposed methodology is illustrated through various\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:55 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 10:40:20 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 11:39:02 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 15:29:02 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 13:07:07 GMT"}, {"version": "v6", "created": "Sun, 24 Jan 2021 21:50:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "1905.12264", "submitter": "Borja Balle", "authors": "Borja Balle, Gilles Barthe, Marco Gaboardi, Joseph Geumlek", "title": "Privacy Amplification by Mixing and Diffusion Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental result in differential privacy states that the privacy\nguarantees of a mechanism are preserved by any post-processing of its output.\nIn this paper we investigate under what conditions stochastic post-processing\ncan amplify the privacy of a mechanism. By interpreting post-processing as the\napplication of a Markov operator, we first give a series of amplification\nresults in terms of uniform mixing properties of the Markov process defined by\nsaid operator. Next we provide amplification bounds in terms of coupling\narguments which can be applied in cases where uniform mixing is not available.\nFinally, we introduce a new family of mechanisms based on diffusion processes\nwhich are closed under post-processing, and analyze their privacy via a novel\nheat flow argument. On the applied side, we generalize the analysis of \"privacy\namplification by iteration\" in Noisy SGD and show it admits an exponential\nimprovement in the strongly convex case, and study a mechanism based on the\nOrnstein-Uhlenbeck diffusion process which contains the Gaussian mechanism with\noptimal post-processing on bounded inputs as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:07:57 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 14:20:34 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Balle", "Borja", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Geumlek", "Joseph", ""]]}, {"id": "1905.12265", "submitter": "Weihua Hu", "authors": "Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay\n  Pande, Jure Leskovec", "title": "Strategies for Pre-training Graph Neural Networks", "comments": "Accepted as a spotlight to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning require a model to make accurate\npre-dictions on test examples that are distributionally different from training\nones, while task-specific labels are scarce during training. An effective\napproach to this challenge is to pre-train a model on related tasks where data\nis abundant, and then fine-tune it on a downstream task of interest. While\npre-training has been effective in many language and vision domains, it remains\nan open question how to effectively use pre-training on graph datasets. In this\npaper, we develop a new strategy and self-supervised methods for pre-training\nGraph Neural Networks (GNNs). The key to the success of our strategy is to\npre-train an expressive GNN at the level of individual nodes as well as entire\ngraphs so that the GNN can learn useful local and global representations\nsimultaneously. We systematically study pre-training on multiple graph\nclassification datasets. We find that naive strategies, which pre-train GNNs at\nthe level of either entire graphs or individual nodes, give limited improvement\nand can even lead to negative transfer on many downstream tasks. In contrast,\nour strategy avoids negative transfer and improves generalization significantly\nacross downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC\nover non-pre-trained models and achieving state-of-the-art performance for\nmolecular property prediction and protein function prediction.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:11:52 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 22:41:43 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 19:49:48 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Hu", "Weihua", ""], ["Liu", "Bowen", ""], ["Gomes", "Joseph", ""], ["Zitnik", "Marinka", ""], ["Liang", "Percy", ""], ["Pande", "Vijay", ""], ["Leskovec", "Jure", ""]]}, {"id": "1905.12278", "submitter": "Camille Castera", "authors": "Camille Castera, J\\'er\\^ome Bolte, C\\'edric F\\'evotte, Edouard Pauwels", "title": "An Inertial Newton Algorithm for Deep Learning", "comments": "To appear in Journal of Machine Learning Research (JMLR), Volume 22,\n  acceptance date: 5/21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new second-order inertial optimization method for machine\nlearning called INNA. It exploits the geometry of the loss function while only\nrequiring stochastic approximations of the function values and the generalized\ngradients. This makes INNA fully implementable and adapted to large-scale\noptimization problems such as the training of deep neural networks. The\nalgorithm combines both gradient-descent and Newton-like behaviors as well as\ninertia. We prove the convergence of INNA for most deep learning problems. To\ndo so, we provide a well-suited framework to analyze deep learning loss\nfunctions involving tame optimization in which we study a continuous dynamical\nsystem together with its discrete stochastic approximations. We prove sublinear\nconvergence for the continuous-time differential inclusion which underlies our\nalgorithm. Additionally, we also show how standard optimization mini-batch\nmethods applied to non-smooth non-convex problems can yield a certain type of\nspurious stationary points never discussed before. We address this issue by\nproviding a theoretical framework around the new idea of $D$-criticality; we\nthen give a simple asymptotic analysis of INNA. Our algorithm allows for using\nan aggressive learning rate of $o(1/\\log k)$. From an empirical viewpoint, we\nshow that INNA returns competitive results with respect to state of the art\n(stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:00:49 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 09:55:34 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 14:15:16 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 15:18:14 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 16:52:46 GMT"}, {"version": "v6", "created": "Wed, 28 Jul 2021 15:56:11 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Castera", "Camille", ""], ["Bolte", "J\u00e9r\u00f4me", ""], ["F\u00e9votte", "C\u00e9dric", ""], ["Pauwels", "Edouard", ""]]}, {"id": "1905.12280", "submitter": "Yao Zhang", "authors": "Yao Zhang, James Jordon, Ahmed M. Alaa, Mihaela van der Schaar", "title": "Lifelong Bayesian Optimization", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Machine Learning (Auto-ML) systems tackle the problem of automating\nthe design of prediction models or pipelines for data science. In this paper,\nwe present Lifelong Bayesian Optimization (LBO), an online, multitask Bayesian\noptimization (BO) algorithm designed to solve the problem of model selection\nfor datasets arriving and evolving over time. To be suitable for \"lifelong\"\nBayesian Optimization, an algorithm needs to scale with the ever increasing\nnumber of acquisitions and should be able to leverage past optimizations in\nlearning the current best model. We cast the problem of model selection as a\nblack-box function optimization problem. In LBO, we exploit the correlation\nbetween functions by using components of previously learned functions to speed\nup the learning process for newly arriving datasets. Experiments on real and\nsynthetic data show that LBO outperforms standard BO algorithms applied\nrepeatedly on the data.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:05:29 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 10:59:58 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Yao", ""], ["Jordon", "James", ""], ["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1905.12282", "submitter": "L\\'eonard Hussenot", "authors": "L\\'eonard Hussenot, Matthieu Geist, Olivier Pietquin", "title": "CopyCAT: Taking Control of Neural Policies with Constant Attacks", "comments": "AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new perspective on adversarial attacks against deep\nreinforcement learning agents. Our main contribution is CopyCAT, a targeted\nattack able to consistently lure an agent into following an outsider's policy.\nIt is pre-computed, therefore fast inferred, and could thus be usable in a\nreal-time scenario. We show its effectiveness on Atari 2600 games in the novel\nread-only setting. In this setting, the adversary cannot directly modify the\nagent's state -- its representation of the environment -- but can only attack\nthe agent's observation -- its perception of the environment. Directly\nmodifying the agent's state would require a write-access to the agent's inner\nworkings and we argue that this assumption is too strong in realistic settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:20:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 09:28:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hussenot", "L\u00e9onard", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1905.12285", "submitter": "Pekka Siirtola", "authors": "Pekka Siirtola, Heli Koskim\\\"aki, Juha R\\\"oning", "title": "From User-independent to Personal Human Activity Recognition Models\n  Exploiting the Sensors of a Smartphone", "comments": "From User-independent to Personal Human Activity Recognition Models\n  Exploiting the Sensors of a Smartphone, European Symposium on Artificial\n  Neural Networks, Compu-tational Intelligence and Machine Learning, ESANN\n  2016., Bruges, Belgium 27-29 April 2016, 471--476", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a novel method to obtain user-dependent human activity\nrecognition models unobtrusively by exploiting the sensors of a smartphone is\npresented. The recognition consists of two models: sensor fusion-based\nuser-independent model for data labeling and single sensor-based user-dependent\nmodel for final recognition. The functioning of the presented method is tested\nwith human activity data set, including data from accelerometer and\nmagnetometer, and with two classifiers. Comparison of the detection accuracies\nof the proposed method to traditional user-independent model shows that the\npresented method has potential, in nine cases out of ten it is better than the\ntraditional method, but more experiments using different sensor combinations\nshould be made to show the full potential of the method.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:25:08 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Siirtola", "Pekka", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "1905.12292", "submitter": "Sanket Tavarageri", "authors": "Sanket Tavarageri", "title": "Categorization of Program Regions for Agile Compilation using Machine\n  Learning and Hardware Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compiler processes the code written in a high level language and produces\nmachine executable code. The compiler writers often face the challenge of\nkeeping the compilation times reasonable. That is because aggressive\noptimization passes which potentially will give rise to high performance are\noften expensive in terms of running time and memory footprint. Consequently the\ncompiler designers arrive at a compromise where they either simplify the\noptimization algorithm which may decrease the performance of the produced code,\nor they will restrict the optimization to the subset of the overall input\nprogram in which case large parts of the input application will go\nun-optimized.\n  The problem we address in this paper is that of keeping the compilation times\nreasonable, and at the same time optimizing the input program to the fullest\nextent possible. Consequently, the performance of the produced code will match\nthe performance when all the aggressive optimization passes are applied over\nthe entire input program.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:46:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tavarageri", "Sanket", ""]]}, {"id": "1905.12294", "submitter": "Federico Ricci-Tersenghi", "authors": "Giulio Biroli, Chiara Cammarota, and Federico Ricci-Tersenghi", "title": "How to iron out rough landscapes and get optimal performances: Averaged\n  Gradient Descent and its application to tensor PCA", "comments": "23 pages, 16 figures, including Supplementary Material", "journal-ref": "J. Phys. A: Math. Theor. 53, 174003 (2020)", "doi": "10.1088/1751-8121/ab7b1f", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many high-dimensional estimation problems the main task consists in\nminimizing a cost function, which is often strongly non-convex when scanned in\nthe space of parameters to be estimated. A standard solution to flatten the\ncorresponding rough landscape consists in summing the losses associated to\ndifferent data points and obtain a smoother empirical risk. Here we propose a\ncomplementary method that works for a single data point. The main idea is that\na large amount of the roughness is uncorrelated in different parts of the\nlandscape. One can then substantially reduce the noise by evaluating an\nempirical average of the gradient obtained as a sum over many random\nindependent positions in the space of parameters to be optimized. We present an\nalgorithm, called Averaged Gradient Descent, based on this idea and we apply it\nto tensor PCA, which is a very hard estimation problem. We show that Averaged\nGradient Descent over-performs physical algorithms such as gradient descent and\napproximate message passing and matches the best algorithmic thresholds known\nso far, obtained by tensor unfolding and methods based on sum-of-squares.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:49:21 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 14:40:10 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 06:33:57 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Biroli", "Giulio", ""], ["Cammarota", "Chiara", ""], ["Ricci-Tersenghi", "Federico", ""]]}, {"id": "1905.12298", "submitter": "Debabrota Basu", "authors": "Debabrota Basu, Christos Dimitrakakis, Aristide Tossou", "title": "Differential Privacy for Multi-armed Bandits: What Is It and What Is Its\n  Cost?", "comments": "27 pages, 1 figure, 2 tables, 14 theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on differential privacy (DP) framework, we introduce and unify privacy\ndefinitions for the multi-armed bandit algorithms. We represent the framework\nwith a unified graphical model and use it to connect privacy definitions. We\nderive and contrast lower bounds on the regret of bandit algorithms satisfying\nthese definitions. We leverage a unified proving technique to achieve all the\nlower bounds. We show that for all of them, the learner's regret is increased\nby a multiplicative factor dependent on the privacy level $\\epsilon$. We\nobserve that the dependency is weaker when we do not require local differential\nprivacy for the rewards.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:56:41 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 19:04:56 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""], ["Tossou", "Aristide", ""]]}, {"id": "1905.12305", "submitter": "Guichen Zhang", "authors": "Guichen Zhang, Pedram Ghamisi, Xiao Xiang Zhu", "title": "Fusion of Heterogeneous Earth Observation Data for the Classification of\n  Local Climate Zones", "comments": "accepted by TGRS", "journal-ref": null, "doi": "10.1109/TGRS.2019.2914967", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for fusing multi-temporal,\nmultispectral satellite images and OpenStreetMap (OSM) data for the\nclassification of local climate zones (LCZs). Feature stacking is the most\ncommonly-used method of data fusion but does not consider the heterogeneity of\nmultimodal optical images and OSM data, which becomes its main drawback. The\nproposed framework processes two data sources separately and then combines them\nat the model level through two fusion models (the landuse fusion model and\nbuilding fusion model), which aim to fuse optical images with landuse and\nbuildings layers of OSM data, respectively. In addition, a new approach to\ndetecting building incompleteness of OSM data is proposed. The proposed\nframework was trained and tested using data from the 2017 IEEE GRSS Data Fusion\nContest, and further validated on one additional test set containing test\nsamples which are manually labeled in Munich and New York. Experimental results\nhave indicated that compared to the feature stacking-based baseline framework\nthe proposed framework is effective in fusing optical images with OSM data for\nthe classification of LCZs with high generalization capability on a large\nscale. The classification accuracy of the proposed framework outperforms the\nbaseline framework by more than 6% and 2%, while testing on the test set of\n2017 IEEE GRSS Data Fusion Contest and the additional test set, respectively.\nIn addition, the proposed framework is less sensitive to spectral diversities\nof optical satellite images and thus achieves more stable classification\nperformance than state-of-the art frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:07:14 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhang", "Guichen", ""], ["Ghamisi", "Pedram", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "1905.12310", "submitter": "Mingfei Sun", "authors": "Mingfei Sun and Xiaojuan Ma", "title": "Adversarial Imitation Learning from Incomplete Demonstrations", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning targets deriving a mapping from states to actions, a.k.a.\npolicy, from expert demonstrations. Existing methods for imitation learning\ntypically require any actions in the demonstrations to be fully available,\nwhich is hard to ensure in real applications. Though algorithms for learning\nwith unobservable actions have been proposed, they focus solely on state\ninformation and overlook the fact that the action sequence could still be\npartially available and provide useful information for policy deriving. In this\npaper, we propose a novel algorithm called Action-Guided Adversarial Imitation\nLearning (AGAIL) that learns a policy from demonstrations with incomplete\naction sequences, i.e., incomplete demonstrations. The core idea of AGAIL is to\nseparate demonstrations into state and action trajectories, and train a policy\nwith state trajectories while using actions as auxiliary information to guide\nthe training whenever applicable. Built upon the Generative Adversarial\nImitation Learning, AGAIL has three components: a generator, a discriminator,\nand a guide. The generator learns a policy with rewards provided by the\ndiscriminator, which tries to distinguish state distributions between\ndemonstrations and samples generated by the policy. The guide provides\nadditional rewards to the generator when demonstrated actions for specific\nstates are available. We compare AGAIL to other methods on benchmark tasks and\nshow that AGAIL consistently delivers comparable performance to the\nstate-of-the-art methods even when the action sequence in demonstrations is\nonly partially available.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:18:42 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 03:44:25 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 06:11:10 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Sun", "Mingfei", ""], ["Ma", "Xiaojuan", ""]]}, {"id": "1905.12313", "submitter": "Fu-Chieh Chang", "authors": "Fu-Chieh Chang, Hao-Jen Wang, Chun-Nan Chou and Edward Y. Chang", "title": "G2R Bound: A Generalization Bound for Supervised Learning from\n  GAN-Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing supervised learning from the data synthesized by using Generative\nAdversarial Networks (GANs), dubbed GAN-synthetic data, has two important\napplications. First, GANs may generate more labeled training data, which may\nhelp improve classification accuracy. Second, in scenarios where real data\ncannot be released outside certain premises for privacy and/or security\nreasons, using GAN- synthetic data to conduct training is a plausible\nalternative. This paper proposes a generalization bound to guarantee the\ngeneralization capability of a classifier learning from GAN-synthetic data.\nThis generalization bound helps developers gauge the generalization gap between\nlearning from synthetic data and testing on real data, and can therefore\nprovide the clues to improve the generalization capability.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:22:49 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Chang", "Fu-Chieh", ""], ["Wang", "Hao-Jen", ""], ["Chou", "Chun-Nan", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1905.12321", "submitter": "Jesper S\\\"oren Dramsch", "authors": "Jesper S\\\"oren Dramsch, Mikael L\\\"uthje, Anders Nymark Christensen", "title": "Complex-valued neural networks for machine learning on non-stationary\n  physical data", "comments": "17 pages total, 15 pages, 2 pages references, paper, 11 figures, 28\n  networks", "journal-ref": null, "doi": "10.1016/j.cageo.2020.104643", "report-no": null, "categories": "cs.LG cs.CV physics.comp-ph physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become an area of interest in most scientific areas,\nincluding physical sciences. Modern networks apply real-valued transformations\non the data. Particularly, convolutions in convolutional neural networks\ndiscard phase information entirely. Many deterministic signals, such as seismic\ndata or electrical signals, contain significant information in the phase of the\nsignal. We explore complex-valued deep convolutional networks to leverage\nnon-linear feature maps. Seismic data commonly has a lowcut filter applied, to\nattenuate noise from ocean waves and similar long wavelength contributions.\nDiscarding the phase information leads to low-frequency aliasing analogous to\nthe Nyquist-Shannon theorem for high frequencies. In non-stationary data, the\nphase content can stabilize training and improve the generalizability of neural\nnetworks. While it has been shown that phase content can be restored in deep\nneural networks, we show how including phase information in feature maps\nimproves both training and inference from deterministic physical data.\nFurthermore, we show that the reduction of parameters in a complex network\noutperforms larger real-valued networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:47:42 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 09:11:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Dramsch", "Jesper S\u00f6ren", ""], ["L\u00fcthje", "Mikael", ""], ["Christensen", "Anders Nymark", ""]]}, {"id": "1905.12322", "submitter": "Dheevatsa Mudigere", "authors": "Dhiraj Kalamkar, Dheevatsa Mudigere, Naveen Mellempudi, Dipankar Das,\n  Kunal Banerjee, Sasikanth Avancha, Dharma Teja Vooturi, Nataraj\n  Jammalamadaka, Jianyu Huang, Hector Yuen, Jiyan Yang, Jongsoo Park, Alexander\n  Heinecke, Evangelos Georganas, Sudarshan Srinivasan, Abhisek Kundu, Misha\n  Smelyanskiy, Bharat Kaul, Pradeep Dubey", "title": "A Study of BFLOAT16 for Deep Learning Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first comprehensive empirical study demonstrating the\nefficacy of the Brain Floating Point (BFLOAT16) half-precision format for Deep\nLearning training across image classification, speech recognition, language\nmodeling, generative networks and industrial recommendation systems. BFLOAT16\nis attractive for Deep Learning training for two reasons: the range of values\nit can represent is the same as that of IEEE 754 floating-point format (FP32)\nand conversion to/from FP32 is simple. Maintaining the same range as FP32 is\nimportant to ensure that no hyper-parameter tuning is required for convergence;\ne.g., IEEE 754 compliant half-precision floating point (FP16) requires\nhyper-parameter tuning. In this paper, we discuss the flow of tensors and\nvarious key operations in mixed precision training, and delve into details of\noperations, such as the rounding modes for converting FP32 tensors to BFLOAT16.\nWe have implemented a method to emulate BFLOAT16 operations in Tensorflow,\nCaffe2, IntelCaffe, and Neon for our experiments. Our results show that deep\nlearning training using BFLOAT16 tensors achieves the same state-of-the-art\n(SOTA) results across domains as FP32 tensors in the same number of iterations\nand with no changes to hyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 10:50:32 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 10:16:51 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 17:55:30 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kalamkar", "Dhiraj", ""], ["Mudigere", "Dheevatsa", ""], ["Mellempudi", "Naveen", ""], ["Das", "Dipankar", ""], ["Banerjee", "Kunal", ""], ["Avancha", "Sasikanth", ""], ["Vooturi", "Dharma Teja", ""], ["Jammalamadaka", "Nataraj", ""], ["Huang", "Jianyu", ""], ["Yuen", "Hector", ""], ["Yang", "Jiyan", ""], ["Park", "Jongsoo", ""], ["Heinecke", "Alexander", ""], ["Georganas", "Evangelos", ""], ["Srinivasan", "Sudarshan", ""], ["Kundu", "Abhisek", ""], ["Smelyanskiy", "Misha", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1905.12330", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Alessandro Lazaric, Emmanuel\n  Dupoux and Marco Baroni", "title": "Word-order biases in deep-agent emergent communication", "comments": "Conference: Association for Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-processing neural networks led to remarkable progress on many NLP\ntasks. As a consequence, there has been increasing interest in understanding to\nwhat extent they process language as humans do. We aim here to uncover which\nbiases such models display with respect to \"natural\" word-order constraints. We\ntrain models to communicate about paths in a simple gridworld, using miniature\nlanguages that reflect or violate various natural language trends, such as the\ntendency to avoid redundancy or to minimize long-distance dependencies. We\nstudy how the controlled characteristics of our miniature languages affect\nindividual learning and their stability across multiple network generations.\nThe results draw a mixed picture. On the one hand, neural networks show a\nstrong tendency to avoid long-distance dependencies. On the other hand, there\nis no clear preference for the efficient, non-redundant encoding of information\nthat is widely attested in natural language. We thus suggest inoculating a\nnotion of \"effort\" into neural networks, as a possible way to make their\nlinguistic behavior more human-like.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:17:59 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:52:47 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 08:08:45 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Lazaric", "Alessandro", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12334", "submitter": "Naveen Mellempudi", "authors": "Naveen Mellempudi, Sudarshan Srinivasan, Dipankar Das, Bharat Kaul", "title": "Mixed Precision Training With 8-bit Floating Point", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced precision computation for deep neural networks is one of the key\nareas addressing the widening compute gap driven by an exponential growth in\nmodel size. In recent years, deep learning training has largely migrated to\n16-bit precision, with significant gains in performance and energy efficiency.\nHowever, attempts to train DNNs at 8-bit precision have met with significant\nchallenges because of the higher precision and dynamic range requirements of\nback-propagation. In this paper, we propose a method to train deep neural\nnetworks using 8-bit floating point representation for weights, activations,\nerrors, and gradients. In addition to reducing compute precision, we also\nreduced the precision requirements for the master copy of weights from 32-bit\nto 16-bit. We demonstrate state-of-the-art accuracy across multiple data sets\n(imagenet-1K, WMT16) and a broader set of workloads (Resnet-18/34/50, GNMT,\nTransformer) than previously reported. We propose an enhanced loss scaling\nmethod to augment the reduced subnormal range of 8-bit floating point for\nimproved error propagation. We also examine the impact of quantization noise on\ngeneralization and propose a stochastic rounding technique to address gradient\nnoise. As a result of applying all these techniques, we report slightly higher\nvalidation accuracy compared to full precision baseline.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:25:09 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Mellempudi", "Naveen", ""], ["Srinivasan", "Sudarshan", ""], ["Das", "Dipankar", ""], ["Kaul", "Bharat", ""]]}, {"id": "1905.12337", "submitter": "Gavneet Singh Chadha", "authors": "Gavneet Singh Chadha and Andreas Schwung", "title": "Learning the Non-linearity in Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the introduction of nonlinear operation into the feature\ngeneration process in convolutional neural networks. This nonlinearity can be\nimplemented in various ways. First we discuss the use of nonlinearities in the\nprocess of data augmentation to increase the robustness of the neural networks\nrecognition capacity. To this end, we randomly disturb the input data set by\napplying exponents within a certain numerical range to individual data points\nof the input space. Second we propose nonlinear convolutional neural networks\nwhere we apply the exponential operation to each element of the receptive\nfield. To this end, we define an additional weight matrix of the same dimension\nas the standard kernel weight matrix. The weights of this matrix then\nconstitute the exponents of the corresponding components of the receptive\nfield. In the basic setting, we keep the weight parameters fixed during\ntraining by defining suitable parameters. Alternatively, we make the\nexponential weight parameters end-to-end trainable using a suitable\nparameterization. The network architecture is applied to time series analysis\ndata set showing a considerable increase in the classification performance\ncompared to baseline networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:32:06 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Chadha", "Gavneet Singh", ""], ["Schwung", "Andreas", ""]]}, {"id": "1905.12340", "submitter": "Alexander Keller", "authors": "Matthijs Van Keirsbilck and Alexander Keller and Xiaodong Yang", "title": "Rethinking Full Connectivity in Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are omnipresent in sequence modeling tasks.\nPractical models usually consist of several layers of hundreds or thousands of\nneurons which are fully connected. This places a heavy computational and memory\nburden on hardware, restricting adoption in practical low-cost and low-power\ndevices. Compared to fully convolutional models, the costly sequential\noperation of RNNs severely hinders performance on parallel hardware. This paper\nchallenges the convention of full connectivity in RNNs. We study structurally\nsparse RNNs, showing that they are well suited for acceleration on parallel\nhardware, with a greatly reduced cost of the recurrent operations as well as\norders of magnitude less recurrent weights. Extensive experiments on\nchallenging tasks ranging from language modeling and speech recognition to\nvideo action recognition reveal that structurally sparse RNNs achieve\ncompetitive performance as compared to fully-connected networks. This allows\nfor using large sparse RNNs for a wide range of real-world tasks that\npreviously were too costly with fully connected networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:35:18 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Van Keirsbilck", "Matthijs", ""], ["Keller", "Alexander", ""], ["Yang", "Xiaodong", ""]]}, {"id": "1905.12341", "submitter": "Yuangang Pan", "authors": "Yuangang Pan, Weijie Chen, Gang Niu, Ivor W. Tsang, Masashi Sugiyama", "title": "Fast and Robust Rank Aggregation against Model Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In rank aggregation, preferences from different users are summarized into a\ntotal order under the homogeneous data assumption. Thus, model misspecification\narises and rank aggregation methods take some noise models into account.\nHowever, they all rely on certain noise model assumptions and cannot handle\nagnostic noises in the real world. In this paper, we propose CoarsenRank, which\nrectifies the underlying data distribution directly and aligns it to the\nhomogeneous data assumption without involving any noise model. To this end, we\ndefine a neighborhood of the data distribution over which Bayesian inference of\nCoarsenRank is performed, and therefore the resultant posterior enjoys\nrobustness against model misspecification. Further, we derive a tractable\nclosed-form solution for CoarsenRank making it computationally efficient.\nExperiments on real-world datasets show that CoarsenRank is fast and robust,\nachieving consistent improvement over baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:35:28 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Pan", "Yuangang", ""], ["Chen", "Weijie", ""], ["Niu", "Gang", ""], ["Tsang", "Ivor W.", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1905.12345", "submitter": "Weichang Wu", "authors": "Weichang Wu, Junchi Yan, Xiaokang Yang, Hongyuan Zha", "title": "Reinforcement Learning with Policy Mixture Model for Temporal Point\n  Processes Clustering", "comments": "8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point process is an expressive tool for modeling event sequences\nover time. In this paper, we take a reinforcement learning view whereby the\nobserved sequences are assumed to be generated from a mixture of latent\npolicies. The purpose is to cluster the sequences with different temporal\npatterns into the underlying policies while learning each of the policy model.\nThe flexibility of our model lies in: i) all the components are networks\nincluding the policy network for modeling the intensity function of temporal\npoint process; ii) to handle varying-length event sequences, we resort to\ninverse reinforcement learning by decomposing the observed sequence into states\n(RNN hidden embedding of history) and actions (time interval to next event) in\norder to learn the reward function, thus achieving better performance or\nincreasing efficiency compared to existing methods using rewards over the\nentire sequence such as log-likelihood or Wasserstein distance. We adopt an\nexpectation-maximization framework with the E-step estimating the cluster\nlabels for each sequence, and the M-step aiming to learn the respective policy.\nExtensive experiments show the efficacy of our method against\nstate-of-the-arts.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:49:55 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 03:53:09 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 14:37:36 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Wu", "Weichang", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1905.12346", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel, Joachim Schreurs and Johan A.K. Suykens", "title": "Nystr\\\"om landmark sampling and regularized Christoffel functions", "comments": "Improved presentation. Typos corrected", "journal-ref": null, "doi": null, "report-no": "19-67", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting diverse and important items, called landmarks, from a large set is\na problem of interest in machine learning. As a specific example, in order to\ndeal with large training sets, kernel methods often rely on low rank matrix\nNystr\\\"om approximations based on the selection or sampling of landmarks. In\nthis context, we propose a deterministic and a randomized adaptive algorithm\nfor selecting landmark points within a training data set, which are related to\nthe minima of a sequence of kernelized Christoffel functions. Beyond the known\nconnection between Christoffel functions and leverage scores, a connection of\nour method with determinantal point processes (DPPs) is also explained. Namely,\nour construction promotes diversity among important landmark points in a way\nsimilar to DPPs. Also, we explain how our randomized adaptive algorithm can\ninfluence the accuracy of Kernel Ridge Regression.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 11:50:52 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 09:22:12 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 19:26:39 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1905.12356", "submitter": "Ayten Ozge Akmandor", "authors": "Ayten Ozge Akmandor, Jorge Ortiz, Irene Manotas, Bongjun Ko, and Niraj\n  K. Jha", "title": "SECRET: Semantically Enhanced Classification of Real-world Tasks", "comments": "16 pages, 20 figures, 2 tables - IEEE Transactions on Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning (ML) algorithms are aimed at maximizing\nclassification performance under available energy and storage constraints. They\ntry to map the training data to the corresponding labels while ensuring\ngeneralizability to unseen data. However, they do not integrate meaning-based\nrelationships among labels in the decision process. On the other hand, natural\nlanguage processing (NLP) algorithms emphasize the importance of semantic\ninformation. In this paper, we synthesize the complementary advantages of\nsupervised ML and NLP algorithms into one method that we refer to as SECRET\n(Semantically Enhanced Classification of REal-world Tasks). SECRET performs\nclassifications by fusing the semantic information of the labels with the\navailable data: it combines the feature space of the supervised algorithms with\nthe semantic space of the NLP algorithms and predicts labels based on this\njoint space. Experimental results indicate that, compared to traditional\nsupervised learning, SECRET achieves up to 14.0% accuracy and 13.1% F1 score\nimprovements. Moreover, compared to ensemble methods, SECRET achieves up to\n12.7% accuracy and 13.3% F1 score improvements. This points to a new research\ndirection for supervised classification based on incorporation of semantic\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:05:31 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 16:53:02 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 01:56:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Akmandor", "Ayten Ozge", ""], ["Ortiz", "Jorge", ""], ["Manotas", "Irene", ""], ["Ko", "Bongjun", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1905.12363", "submitter": "Arthur Mensch", "authors": "Carles Domingo Enrich (CIMS), Samy Jelassi, Carles Domingo-Enrich,\n  Damien Scieur, Arthur Mensch (DMA, CIMS), Joan Bruna (CIMS)", "title": "Extragradient with player sampling for faster Nash equilibrium finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven modeling increasingly requires to find a Nash equilibrium in\nmulti-player games, e.g. when training GANs. In this paper, we analyse a new\nextra-gradient method for Nash equilibrium finding, that performs gradient\nextrapolations and updates on a random subset of players at each iteration.\nThis approach provably exhibits a better rate of convergence than full\nextra-gradient for non-smooth convex games with noisy gradient oracle. We\npropose an additional variance reduction mechanism to obtain speed-ups in\nsmooth convex games. Our approach makes extrapolation amenable to massive\nmultiplayer settings, and brings empirical speed-ups, in particular when using\na heuristic cyclic sampling scheme. Most importantly, it allows to train faster\nand better GANs and mixtures of GANs.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:10:23 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 08:43:23 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 15:06:01 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 13:41:32 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 14:32:51 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Enrich", "Carles Domingo", "", "CIMS"], ["Jelassi", "Samy", "", "DMA, CIMS"], ["Domingo-Enrich", "Carles", "", "DMA, CIMS"], ["Scieur", "Damien", "", "DMA, CIMS"], ["Mensch", "Arthur", "", "DMA, CIMS"], ["Bruna", "Joan", "", "CIMS"]]}, {"id": "1905.12370", "submitter": "Chang Li", "authors": "Chang Li and Maarten de Rijke", "title": "Cascading Non-Stationary Bandits: Online Learning to Rank in the\n  Non-Stationary Cascade Model", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2019/396", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-stationarity appears in many online applications such as web search and\nadvertising. In this paper, we study the online learning to rank problem in a\nnon-stationary environment where user preferences change abruptly at an unknown\nmoment in time. We consider the problem of identifying the K most attractive\nitems and propose cascading non-stationary bandits, an online learning variant\nof the cascading model, where a user browses a ranked list from top to bottom\nand clicks on the first attractive item. We propose two algorithms for solving\nthis non-stationary problem: CascadeDUCB and CascadeSWUCB. We analyze their\nperformance and derive gap-dependent upper bounds on the n-step regret of these\nalgorithms. We also establish a lower bound on the regret for cascading\nnon-stationary bandits and show that both algorithms match the lower bound up\nto a logarithmic factor. Finally, we evaluate their performance on a real-world\nweb search click dataset.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:18:51 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 13:47:47 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 15:47:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Li", "Chang", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1905.12374", "submitter": "Edward De Brouwer", "authors": "Edward De Brouwer and Jaak Simm and Adam Arany and Yves Moreau", "title": "GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series", "comments": "Accepted at NeurIPS 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling real-world multidimensional time series can be particularly\nchallenging when these are sporadically observed (i.e., sampling is irregular\nboth in time and across dimensions)-such as in the case of clinical patient\ndata. To address these challenges, we propose (1) a continuous-time version of\nthe Gated Recurrent Unit, building upon the recent Neural Ordinary Differential\nEquations (Chen et al., 2018), and (2) a Bayesian update network that processes\nthe sporadic observations. We bring these two ideas together in our\nGRU-ODE-Bayes method. We then demonstrate that the proposed method encodes a\ncontinuity prior for the latent process and that it can exactly represent the\nFokker-Planck dynamics of complex processes driven by a multidimensional\nstochastic differential equation. Additionally, empirical evaluation shows that\nour method outperforms the state of the art on both synthetic data and\nreal-world data with applications in healthcare and climate forecast. What is\nmore, the continuity prior is shown to be well suited for low number of samples\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:25:49 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 17:11:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["De Brouwer", "Edward", ""], ["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["Moreau", "Yves", ""]]}, {"id": "1905.12375", "submitter": "Cole Hurwitz", "authors": "Cole L. Hurwitz, Kai Xu, Akash Srivastava, Alessio P. Buccino,\n  Matthias H. Hennig", "title": "Scalable Spike Source Localization in Extracellular Recordings using\n  Amortized Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the positions of neurons in an extracellular recording is useful\nfor investigating functional properties of the underlying neural circuitry. In\nthis work, we present a Bayesian modelling approach for localizing the source\nof individual spikes on high-density, microelectrode arrays. To allow for\nscalable inference, we implement our model as a variational autoencoder and\nperform amortized variational inference. We evaluate our method on both\nbiophysically realistic simulated and real extracellular datasets,\ndemonstrating that it is more accurate than and can improve spike sorting\nperformance over heuristic localization methods such as center of mass.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:30:24 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:01:00 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 16:28:54 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Hurwitz", "Cole L.", ""], ["Xu", "Kai", ""], ["Srivastava", "Akash", ""], ["Buccino", "Alessio P.", ""], ["Hennig", "Matthias H.", ""]]}, {"id": "1905.12385", "submitter": "Benjamin Aubin", "authors": "Benjamin Aubin, Bruno Loureiro, Antoine Maillard, Florent Krzakala,\n  Lenka Zdeborov\\'a", "title": "The spiked matrix model with generative priors", "comments": "12 + 56, 8 figures, v2 lighter jpeg figures", "journal-ref": "Advances in Neural Information Processing Systems, pp. 8364-8375.\n  2019", "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a low-dimensional parametrization of signals is a generic and powerful\nway to enhance performance in signal processing and statistical inference. A\nvery popular and widely explored type of dimensionality reduction is sparsity;\nanother type is generative modelling of signal distributions. Generative models\nbased on neural networks, such as GANs or variational auto-encoders, are\nparticularly performant and are gaining on applicability. In this paper we\nstudy spiked matrix models, where a low-rank matrix is observed through a noisy\nchannel. This problem with sparse structure of the spikes has attracted broad\nattention in the past literature. Here, we replace the sparsity assumption by\ngenerative modelling, and investigate the consequences on statistical and\nalgorithmic properties. We analyze the Bayes-optimal performance under specific\ngenerative models for the spike. In contrast with the sparsity assumption, we\ndo not observe regions of parameters where statistical performance is superior\nto the best known algorithmic performance. We show that in the analyzed cases\nthe approximate message passing algorithm is able to reach optimal performance.\nWe also design enhanced spectral algorithms and analyze their performance and\nthresholds using random matrix theory, showing their superiority to the\nclassical principal component analysis. We complement our theoretical results\nby illustrating the performance of the spectral algorithms when the spikes come\nfrom real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:47:05 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 15:03:52 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Aubin", "Benjamin", ""], ["Loureiro", "Bruno", ""], ["Maillard", "Antoine", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1905.12386", "submitter": "Erwin Quiring", "authors": "Erwin Quiring, Alwin Maier and Konrad Rieck", "title": "Misleading Authorship Attribution of Source Code using Adversarial\n  Learning", "comments": "USENIX Security Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel attack against authorship attribution of\nsource code. We exploit that recent attribution methods rest on machine\nlearning and thus can be deceived by adversarial examples of source code. Our\nattack performs a series of semantics-preserving code transformations that\nmislead learning-based attribution but appear plausible to a developer. The\nattack is guided by Monte-Carlo tree search that enables us to operate in the\ndiscrete domain of source code. In an empirical evaluation with source code\nfrom 204 programmers, we demonstrate that our attack has a substantial effect\non two recent attribution methods, whose accuracy drops from over 88% to 1%\nunder attack. Furthermore, we show that our attack can imitate the coding style\nof developers with high accuracy and thereby induce false attributions. We\nconclude that current approaches for authorship attribution are inappropriate\nfor practical application and there is a need for resilient analysis\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:51:31 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 08:42:28 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Quiring", "Erwin", ""], ["Maier", "Alwin", ""], ["Rieck", "Konrad", ""]]}, {"id": "1905.12403", "submitter": "Jeppe N{\\o}rregaard", "authors": "Jeppe N{\\o}rregaard and Lars Kai Hansen", "title": "Probabilistic Decoupling of Labels in Classification", "comments": "8 pages + 10 pages of supplementary material. NeurIPS preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate probabilistic decoupling of labels supplied for training, from\nthe underlying classes for prediction. Decoupling enables an inference scheme\ngeneral enough to implement many classification problems, including supervised,\nsemi-supervised, positive-unlabelled, noisy-label and suggests a general\nsolution to the multi-positive-unlabelled learning problem. We test the method\non the Fashion MNIST and 20 News Groups datasets for performance benchmarks,\nwhere we simulate noise, partial labelling etc.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:07:39 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["N\u00f8rregaard", "Jeppe", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1905.12407", "submitter": "Ayman Boustati", "authors": "Ayman Boustati, Theodoros Damoulas, Richard S. Savage", "title": "Non-linear Multitask Learning with Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-task learning formulation for Deep Gaussian processes\n(DGPs), through non-linear mixtures of latent processes. The latent space is\ncomposed of private processes that capture within-task information and shared\nprocesses that capture across-task dependencies. We propose two different\nmethods for segmenting the latent space: through hard coding shared and\ntask-specific processes or through soft sharing with Automatic Relevance\nDetermination kernels. We show that our formulation is able to improve the\nlearning performance and transfer information between the tasks, outperforming\nother probabilistic multi-task learning models across real-world and\nbenchmarking settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:13:56 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 23:19:58 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Boustati", "Ayman", ""], ["Damoulas", "Theodoros", ""], ["Savage", "Richard S.", ""]]}, {"id": "1905.12411", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Nhien-An Le-Khac and M-Tahar Kechadi", "title": "Designing and Implementing Data Warehouse for Agricultural Big Data", "comments": "Business intelligent, data warehouse, constellation schema, Big Data,\n  precision agriculture", "journal-ref": "BigData 2019", "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, precision agriculture that uses modern information and\ncommunication technologies is becoming very popular. Raw and semi-processed\nagricultural data are usually collected through various sources, such as:\nInternet of Thing (IoT), sensors, satellites, weather stations, robots, farm\nequipment, farmers and agribusinesses, etc. Besides, agricultural datasets are\nvery large, complex, unstructured, heterogeneous, non-standardized, and\ninconsistent. Hence, the agricultural data mining is considered as Big Data\napplication in terms of volume, variety, velocity and veracity. It is a key\nfoundation to establishing a crop intelligence platform, which will enable\nresource efficient agronomy decision making and recommendations. In this paper,\nwe designed and implemented a continental level agricultural data warehouse by\ncombining Hive, MongoDB and Cassandra. Our data warehouse capabilities: (1)\nflexible schema; (2) data integration from real agricultural multi datasets;\n(3) data science and business intelligent support; (4) high performance; (5)\nhigh storage; (6) security; (7) governance and monitoring; (8) replication and\nrecovery; (9) consistency, availability and partition tolerant; (10)\ndistributed and cloud deployment. We also evaluate the performance of our data\nwarehouse.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:18:03 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "1905.12412", "submitter": "Zhize Li", "authors": "Guanghui Lan, Zhize Li, Yi Zhou", "title": "A unified variance-reduced accelerated gradient method for convex\n  optimization", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel randomized incremental gradient algorithm, namely,\nVAriance-Reduced Accelerated Gradient (Varag), for finite-sum optimization.\nEquipped with a unified step-size policy that adjusts itself to the value of\nthe condition number, Varag exhibits the unified optimal rates of convergence\nfor solving smooth convex finite-sum problems directly regardless of their\nstrong convexity. Moreover, Varag is the first accelerated randomized\nincremental gradient method that benefits from the strong convexity of the\ndata-fidelity term to achieve the optimal linear convergence. It also\nestablishes an optimal linear rate of convergence for solving a wide class of\nproblems only satisfying a certain error bound condition rather than strong\nconvexity. Varag can also be extended to solve stochastic finite-sum problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:20:27 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:39:13 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 22:11:01 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Lan", "Guanghui", ""], ["Li", "Zhize", ""], ["Zhou", "Yi", ""]]}, {"id": "1905.12413", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Vladimir Makarenkov", "title": "VecHGrad for Solving Accurately Complex Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition, a collection of factorization techniques for\nmultidimensional arrays, are among the most general and powerful tools for\nscientific analysis. However, because of their increasing size, today's data\nsets require more complex tensor decomposition involving factorization with\nmultiple matrices and diagonal tensors such as DEDICOM or PARATUCK2.\nTraditional tensor resolution algorithms such as Stochastic Gradient Descent\n(SGD), Non-linear Conjugate Gradient descent (NCG) or Alternating Least Square\n(ALS), cannot be easily applied to complex tensor decomposition or often lead\nto poor accuracy at convergence. We propose a new resolution algorithm, called\nVecHGrad, for accurate and efficient stochastic resolution over all existing\ntensor decomposition, specifically designed for complex decomposition. VecHGrad\nrelies on gradient, Hessian-vector product and adaptive line search to ensure\nthe convergence during optimization. Our experiments on five real-world data\nsets with the state-of-the-art deep learning gradient optimization models show\nthat VecHGrad is capable of converging considerably faster because of its\nsuperior theoretical convergence rate per step. Therefore, VecHGrad targets as\nwell deep learning optimizer algorithms. The experiments are performed for\nvarious tensor decomposition including CP, DEDICOM and PARATUCK2. Although it\ninvolves a slightly more complex update rule, VecHGrad's runtime is similar in\npractice to that of gradient methods such as SGD, Adam or RMSProp.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:29:49 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 01:47:50 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Charlier", "Jeremy", ""], ["Makarenkov", "Vladimir", ""]]}, {"id": "1905.12417", "submitter": "Danielle Maddix", "authors": "Yuyang Wang, Alex Smola, Danielle C. Maddix, Jan Gasthaus, Dean\n  Foster, Tim Januschowski", "title": "Deep Factors for Forecasting", "comments": "http://proceedings.mlr.press/v97/wang19k/wang19k.pdf. arXiv admin\n  note: substantial text overlap with arXiv:1812.00098", "journal-ref": "Proceedings of Machine Learning Research, Volume 97: International\n  Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing probabilistic forecasts for large collections of similar and/or\ndependent time series is a practically relevant and challenging task. Classical\ntime series models fail to capture complex patterns in the data, and\nmultivariate techniques struggle to scale to large problem sizes. Their\nreliance on strong structural assumptions makes them data-efficient, and allows\nthem to provide uncertainty estimates. The converse is true for models based on\ndeep neural networks, which can learn complex patterns and dependencies given\nenough data. In this paper, we propose a hybrid model that incorporates the\nbenefits of both approaches. Our new method is data-driven and scalable via a\nlatent, global, deep component. It also handles uncertainty through a local\nclassical model. We provide both theoretical and empirical evidence for the\nsoundness of our approach through a necessary and sufficient decomposition of\nexchangeable time series into a global and a local part. Our experiments\ndemonstrate the advantages of our model both in term of data efficiency,\naccuracy and computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:27:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wang", "Yuyang", ""], ["Smola", "Alex", ""], ["Maddix", "Danielle C.", ""], ["Gasthaus", "Jan", ""], ["Foster", "Dean", ""], ["Januschowski", "Tim", ""]]}, {"id": "1905.12418", "submitter": "Salman Alsubaihi", "authors": "Salman Alsubaihi, Adel Bibi, Modar Alfadly, Abdullah Hamdi and Bernard\n  Ghanem", "title": "Expected Tight Bounds for Robust Training", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Deep Neural Networks that are robust to norm bounded adversarial\nattacks remains an elusive problem. While exact and inexact verification-based\nmethods are generally too expensive to train large networks, it was\ndemonstrated that bounded input intervals can be inexpensively propagated from\na layer to another through deep networks. This interval bound propagation\napproach (IBP) not only has improved both robustness and certified accuracy but\nwas the first to be employed on large/deep networks. However, due to the very\nloose nature of the IBP bounds, the required training procedure is complex and\ninvolved. In this paper, we closely examine the bounds of a block of layers\ncomposed in the form of Affine-ReLU-Affine. To this end, we propose expected\ntight bounds (true bounds in expectation), referred to as ETB, which are\nprovably tighter than IBP bounds in expectation. We then extend this result to\ndeeper networks through blockwise propagation and show that we can achieve\norders of magnitudes tighter bounds compared to IBP. Furthermore, using a\nsimple standard training procedure, we can achieve impressive\nrobustness-accuracy trade-off on both MNIST and CIFAR10.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:07:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 10:58:47 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 08:48:13 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 15:28:52 GMT"}, {"version": "v5", "created": "Sat, 12 Jun 2021 22:35:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Alsubaihi", "Salman", ""], ["Bibi", "Adel", ""], ["Alfadly", "Modar", ""], ["Hamdi", "Abdullah", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1905.12425", "submitter": "Aristide Charles Yedia Tossou", "authors": "Aristide Tossou, Debabrota Basu, Christos Dimitrakakis", "title": "Near-optimal Optimistic Reinforcement Learning using Empirical Bernstein\n  Inequalities", "comments": "the algorithm has been simplified (no need to look at lower bound of\n  the reward and transitions). Proof has been significantly clean-up. The\n  previous \"assumption\" is clarified as a condition of the algorithm well-known\n  as sub-modularity. The proof that the bounds satisfy the submodularity is\n  clean-up", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model-based reinforcement learning in an unknown finite\ncommunicating Markov decision process. We propose a simple algorithm that\nleverages a variance based confidence interval. We show that the proposed\nalgorithm, UCRL-V, achieves the optimal regret\n$\\tilde{\\mathcal{O}}(\\sqrt{DSAT})$ up to logarithmic factors, and so our work\ncloses a gap with the lower bound without additional assumptions on the MDP. We\nperform experiments in a variety of environments that validates the theoretical\nbounds as well as prove UCRL-V to be better than the state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:15:54 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 18:01:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Tossou", "Aristide", ""], ["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1905.12429", "submitter": "Haizhong Zheng", "authors": "Haizhong Zheng, Earlence Fernandes, Atul Prakash", "title": "Analyzing the Interpretability Robustness of Self-Explaining Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, interpretable models called self-explaining models (SEMs) have been\nproposed with the goal of providing interpretability robustness. We evaluate\nthe interpretability robustness of SEMs and show that explanations provided by\nSEMs as currently proposed are not robust to adversarial inputs. Specifically,\nwe successfully created adversarial inputs that do not change the model outputs\nbut cause significant changes in the explanations. We find that even though\ncurrent SEMs use stable co-efficients for mapping explanations to output\nlabels, they do not consider the robustness of the first stage of the model\nthat creates interpretable basis concepts from the input, leading to non-robust\nexplanations. Our work makes a case for future work to start examining how to\ngenerate interpretable basis concepts in a robust way.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:33:35 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 22:16:07 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:28:02 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zheng", "Haizhong", ""], ["Fernandes", "Earlence", ""], ["Prakash", "Atul", ""]]}, {"id": "1905.12430", "submitter": "Antoine Ledent", "authors": "Antoine Ledent and Waleed Mustafa and Yunwen Lei and Marius Kloft", "title": "Norm-based generalisation bounds for multi-class convolutional neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show generalisation error bounds for deep learning with two main\nimprovements over the state of the art. (1) Our bounds have no explicit\ndependence on the number of classes except for logarithmic factors. This holds\neven when formulating the bounds in terms of the $L^2$-norm of the weight\nmatrices, where previous bounds exhibit at least a square-root dependence on\nthe number of classes. (2) We adapt the classic Rademacher analysis of DNNs to\nincorporate weight sharing -- a task of fundamental theoretical importance\nwhich was previously attempted only under very restrictive assumptions. In our\nresults, each convolutional filter contributes only once to the bound,\nregardless of how many times it is applied. Further improvements exploiting\npooling and sparse connections are provided. The presented bounds scale as the\nnorms of the parameter matrices, rather than the number of parameters. In\nparticular, contrary to bounds based on parameter counting, they are\nasymptotically tight (up to log factors) when the weights approach\ninitialisation, making them suitable as a basic ingredient in bounds sensitive\nto the optimisation procedure. We also show how to adapt the recent technique\nof loss function augmentation to our situation to replace spectral norms by\nempirical analogues whilst maintaining the advantages of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:28:42 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:25:25 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 09:46:48 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 19:54:53 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 19:39:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ledent", "Antoine", ""], ["Mustafa", "Waleed", ""], ["Lei", "Yunwen", ""], ["Kloft", "Marius", ""]]}, {"id": "1905.12432", "submitter": "Bradley Gram-Hansen", "authors": "Bradley Gram-Hansen, Christian Schr\\\"oder de Witt, Tom Rainforth,\n  Philip H.S. Torr, Yee Whye Teh, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin", "title": "Hijacking Malaria Simulators with Probabilistic Programming", "comments": "6 pages, 3 figures, Accepted at the International Conference on\n  Machine Learning AI for Social Good Workshop, Long Beach, United States, 2019", "journal-ref": "ICML Workshop on AI for Social Good, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemiology simulations have become a fundamental tool in the fight against\nthe epidemics of various infectious diseases like AIDS and malaria. However,\nthe complicated and stochastic nature of these simulators can mean their output\nis difficult to interpret, which reduces their usefulness to policymakers. In\nthis paper, we introduce an approach that allows one to treat a large class of\npopulation-based epidemiology simulators as probabilistic generative models.\nThis is achieved by hijacking the internal random number generator calls,\nthrough the use of a universal probabilistic programming system (PPS). In\ncontrast to other methods, our approach can be easily retrofitted to simulators\nwritten in popular industrial programming frameworks. We demonstrate that our\nmethod can be used for interpretable introspection and inference, thus shedding\nlight on black-box simulators. This reinstates much-needed trust between\npolicymakers and evidence-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:31:30 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gram-Hansen", "Bradley", ""], ["de Witt", "Christian Schr\u00f6der", ""], ["Rainforth", "Tom", ""], ["Torr", "Philip H. S.", ""], ["Teh", "Yee Whye", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""]]}, {"id": "1905.12434", "submitter": "Philip Becker-Ehmck", "authors": "Philip Becker-Ehmck, Jan Peters, Patrick van der Smagt", "title": "Switching Linear Dynamics for Variational Bayes Filtering", "comments": "Appears in Proceedings of the 36th International Conference on\n  Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System identification of complex and nonlinear systems is a central problem\nfor model predictive control and model-based reinforcement learning. Despite\ntheir complexity, such systems can often be approximated well by a set of\nlinear dynamical systems if broken into appropriate subsequences. This\nmechanism not only helps us find good approximations of dynamics, but also\ngives us deeper insight into the underlying system. Leveraging Bayesian\ninference, Variational Autoencoders and Concrete relaxations, we show how to\nlearn a richer and more meaningful state space, e.g. encoding joint constraints\nand collisions with walls in a maze, from partial and high-dimensional\nobservations. This representation translates into a gain of accuracy of learned\ndynamics showcased on various simulated tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:33:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Becker-Ehmck", "Philip", ""], ["Peters", "Jan", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1905.12439", "submitter": "Dorien Herremans", "authors": "Balamurali BT, Kin Wah Edward Lin, Simon Lui, Jer-Ming Chen, Dorien\n  Herremans", "title": "Towards robust audio spoofing detection: a detailed comparison of\n  traditional and learned features", "comments": null, "journal-ref": "IEEE Access. 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification, like every other biometric system, is\nvulnerable to spoofing attacks. Using only a few minutes of recorded voice of a\ngenuine client of a speaker verification system, attackers can develop a\nvariety of spoofing attacks that might trick such systems. Detecting these\nattacks using the audio cues present in the recordings is an important\nchallenge. Most existing spoofing detection systems depend on knowing the used\nspoofing technique. With this research, we aim at overcoming this limitation,\nby examining robust audio features, both traditional and those learned through\nan autoencoder, that are generalizable over different types of replay spoofing.\nFurthermore, we provide a detailed account of all the steps necessary in\nsetting up state-of-the-art audio feature detection, pre-, and postprocessing,\nsuch that the (non-audio expert) machine learning researcher can implement such\nsystems. Finally, we evaluate the performance of our robust replay speaker\ndetection system with a wide variety and different combinations of both\nextracted and machine learned audio features on the `out in the wild' ASVspoof\n2017 dataset. This dataset contains a variety of new spoofing configurations.\nSince our focus is on examining which features will ensure robustness, we base\nour system on a traditional Gaussian Mixture Model-Universal Background Model.\nWe then systematically investigate the relative contribution of each feature\nset. The fused models, based on both the known audio features and the machine\nlearned features respectively, have a comparable performance with an Equal\nError Rate (EER) of 12. The final best performing model, which obtains an EER\nof 10.8, is a hybrid model that contains both known and machine learned\nfeatures, thus revealing the importance of incorporating both types of features\nwhen developing a robust spoofing prediction model.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:51:18 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 01:27:28 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["BT", "Balamurali", ""], ["Lin", "Kin Wah Edward", ""], ["Lui", "Simon", ""], ["Chen", "Jer-Ming", ""], ["Herremans", "Dorien", ""]]}, {"id": "1905.12440", "submitter": "Minsuk Shin", "authors": "Minsuk Shin, Young Lee, and Jun S. Liu", "title": "Generative Parameter Sampler For Scalable Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification has been a core of the statistical machine\nlearning, but its computational bottleneck has been a serious challenge for\nboth Bayesians and frequentists. We propose a model-based framework in\nquantifying uncertainty, called predictive-matching Generative Parameter\nSampler (GPS). This procedure considers an Uncertainty Quantification (UQ)\ndistribution on the targeted parameter, which matches the corresponding\npredictive distribution to the observed data. This framework adopts a\nhierarchical modeling perspective such that each observation is modeled by an\nindividual parameter. This individual parameterization permits the resulting\ninference to be computationally scalable and robust to outliers. Our approach\nis illustrated for linear models, Poisson processes, and deep neural networks\nfor classification. The results show that the GPS is successful in providing\nuncertainty quantification as well as additional flexibility beyond what is\nallowed by classical statistical procedures under the postulated statistical\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:52:51 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 20:15:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shin", "Minsuk", ""], ["Lee", "Young", ""], ["Liu", "Jun S.", ""]]}, {"id": "1905.12454", "submitter": "Rahul Gupta", "authors": "Rahul Gupta, Aditya Kanade, Shirish Shevade", "title": "Deep Learning for Bug-Localization in Student Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing feedback is an integral part of teaching. Most open online courses\non programming make use of automated grading systems to support programming\nassignments and give real-time feedback. These systems usually rely on test\nresults to quantify the programs' functional correctness. They return failing\ntests to the students as feedback. However, students may find it difficult to\ndebug their programs if they receive no hints about where the bug is and how to\nfix it. In this work, we present the first deep learning based technique that\ncan localize bugs in a faulty program w.r.t. a failing test, without even\nrunning the program. At the heart of our technique is a novel tree\nconvolutional neural network which is trained to predict whether a program\npasses or fails a given test. To localize the bugs, we analyze the trained\nnetwork using a state-of-the-art neural prediction attribution technique and\nsee which lines of the programs make it predict the test outcomes. Our\nexperiments show that the proposed technique is generally more accurate than\ntwo state-of-the-art program-spectrum based and one syntactic difference based\nbug-localization baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:08:07 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gupta", "Rahul", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "1905.12470", "submitter": "Shiwei Tong", "authors": "Qi Liu, Shiwei Tong, Chuanren Liu, Hongke Zhao, Enhong Chen, Haiping\n  Ma, Shijin Wang", "title": "Exploiting Cognitive Structure for Adaptive Learning", "comments": "Accepted by KDD 2019 Research Track. In Proceedings of the 25th ACM\n  SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'19)", "journal-ref": null, "doi": "10.1145/3292500.3330922", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive learning, also known as adaptive teaching, relies on learning path\nrecommendation, which sequentially recommends personalized learning items\n(e.g., lectures, exercises) to satisfy the unique needs of each learner.\nAlthough it is well known that modeling the cognitive structure including\nknowledge level of learners and knowledge structure (e.g., the prerequisite\nrelations) of learning items is important for learning path recommendation,\nexisting methods for adaptive learning often separately focus on either\nknowledge levels of learners or knowledge structure of learning items. To fully\nexploit the multifaceted cognitive structure for learning path recommendation,\nwe propose a Cognitive Structure Enhanced framework for Adaptive Learning,\nnamed CSEAL. By viewing path recommendation as a Markov Decision Process and\napplying an actor-critic algorithm, CSEAL can sequentially identify the right\nlearning items to different learners. Specifically, we first utilize a\nrecurrent neural network to trace the evolving knowledge levels of learners at\neach learning step. Then, we design a navigation algorithm on the knowledge\nstructure to ensure the logicality of learning paths, which reduces the search\nspace in the decision process. Finally, the actor-critic algorithm is used to\ndetermine what to learn next and whose parameters are dynamically updated along\nthe learning path. Extensive experiments on real-world data demonstrate the\neffectiveness and robustness of CSEAL.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:23:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Liu", "Qi", ""], ["Tong", "Shiwei", ""], ["Liu", "Chuanren", ""], ["Zhao", "Hongke", ""], ["Chen", "Enhong", ""], ["Ma", "Haiping", ""], ["Wang", "Shijin", ""]]}, {"id": "1905.12480", "submitter": "Hongtao Liu", "authors": "Hongtao Liu, Fangzhao Wu, Wenjun Wang, Xianchen Wang, Pengfei Jiao,\n  Chuhan Wu, Xing Xie", "title": "NRPA: Neural Recommendation with Personalized Attention", "comments": "4 pages, 4 figures", "journal-ref": "sigir 2019", "doi": "10.1145/3331184.3331371", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing review-based recommendation methods usually use the same model to\nlearn the representations of all users/items from reviews posted by users\ntowards items. However, different users have different preference and different\nitems have different characteristics. Thus, the same word or similar reviews\nmay have different informativeness for different users and items. In this paper\nwe propose a neural recommendation approach with personalized attention to\nlearn personalized representations of users and items from reviews. We use a\nreview encoder to learn representations of reviews from words, and a user/item\nencoder to learn representations of users or items from reviews. We propose a\npersonalized attention model, and apply it to both review and user/item\nencoders to select different important words and reviews for different\nusers/items. Experiments on five datasets validate our approach can effectively\nimprove the performance of neural recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:16:17 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Hongtao", ""], ["Wu", "Fangzhao", ""], ["Wang", "Wenjun", ""], ["Wang", "Xianchen", ""], ["Jiao", "Pengfei", ""], ["Wu", "Chuhan", ""], ["Xie", "Xing", ""]]}, {"id": "1905.12495", "submitter": "Nathan Kallus", "authors": "Andrew Bennett, Nathan Kallus, Tobias Schnabel", "title": "Deep Generalized Method of Moments for Instrumental Variable Analysis", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (2019)\n  3564--3574", "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumental variable analysis is a powerful tool for estimating causal\neffects when randomization or full control of confounders is not possible. The\napplication of standard methods such as 2SLS, GMM, and more recent variants are\nsignificantly impeded when the causal effects are complex, the instruments are\nhigh-dimensional, and/or the treatment is high-dimensional. In this paper, we\npropose the DeepGMM algorithm to overcome this. Our algorithm is based on a new\nvariational reformulation of GMM with optimal inverse-covariance weighting that\nallows us to efficiently control very many moment conditions. We further\ndevelop practical techniques for optimization and model selection that make it\nparticularly successful in practice. Our algorithm is also computationally\ntractable and can handle large-scale datasets. Numerical results show our\nalgorithm matches the performance of the best tuned methods in standard\nsettings and continues to work in high-dimensional settings where even recent\nmethods break.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:30:09 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:28:47 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""], ["Schnabel", "Tobias", ""]]}, {"id": "1905.12506", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Francesco Locatello, J\\\"urgen Schmidhuber,\n  Olivier Bachem", "title": "Are Disentangled Representations Helpful for Abstract Visual Reasoning?", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A disentangled representation encodes information about the salient factors\nof variation in the data independently. Although it is often argued that this\nrepresentational format is useful in learning to solve many real-world\ndown-stream tasks, there is little empirical evidence that supports this claim.\nIn this paper, we conduct a large-scale study that investigates whether\ndisentangled representations are more suitable for abstract reasoning tasks.\nUsing two new tasks similar to Raven's Progressive Matrices, we evaluate the\nusefulness of the representations learned by 360 state-of-the-art unsupervised\ndisentanglement models. Based on these representations, we train 3600 abstract\nreasoning models and observe that disentangled representations do in fact lead\nto better down-stream performance. In particular, they enable quicker learning\nusing fewer samples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:52:32 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 17:00:42 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 14:36:07 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Locatello", "Francesco", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Bachem", "Olivier", ""]]}, {"id": "1905.12511", "submitter": "Han Bao", "authors": "Han Bao, Masashi Sugiyama", "title": "Calibrated Surrogate Maximization of Linear-fractional Utility in Binary\n  Classification", "comments": "AISTATS2020 camera ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex classification performance metrics such as the F${}_\\beta$-measure\nand Jaccard index are often used, in order to handle class-imbalanced cases\nsuch as information retrieval and image segmentation. These performance metrics\nare not decomposable, that is, they cannot be expressed in a per-example\nmanner, which hinders a straightforward application of M-estimation widely used\nin supervised learning. In this paper, we consider linear-fractional metrics,\nwhich are a family of classification performance metrics that encompasses many\nstandard ones such as the F${}_\\beta$-measure and Jaccard index, and propose\nmethods to directly maximize performances under those metrics. A clue to tackle\ntheir direct optimization is a calibrated surrogate utility, which is a\ntractable lower bound of the true utility function representing a given metric.\nWe characterize sufficient conditions which make the surrogate maximization\ncoincide with the maximization of the true utility. Simulation results on\nbenchmark datasets validate the effectiveness of our calibrated surrogate\nmaximization especially if the sample sizes are extremely small.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:59:36 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 00:51:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bao", "Han", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1905.12516", "submitter": "Thomas Davidson", "authors": "Thomas Davidson, Debasmita Bhattacharya, Ingmar Weber", "title": "Racial Bias in Hate Speech and Abusive Language Detection Datasets", "comments": "To appear in the proceedings of the Third Abusive Language Workshop\n  (https://sites.google.com/view/alw3/) at the Annual Meeting for the\n  Association for Computational Linguistics 2019. Please cite the published\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies for abusive language detection are being developed and applied\nwith little consideration of their potential biases. We examine racial bias in\nfive different sets of Twitter data annotated for hate speech and abusive\nlanguage. We train classifiers on these datasets and compare the predictions of\nthese classifiers on tweets written in African-American English with those\nwritten in Standard American English. The results show evidence of systematic\nracial bias in all datasets, as classifiers trained on them tend to predict\nthat tweets written in African-American English are abusive at substantially\nhigher rates. If these abusive language detection systems are used in the field\nthey will therefore have a disproportionate negative impact on African-American\nsocial media users. Consequently, these systems may discriminate against the\ngroups who are often the targets of the abuse we are trying to detect.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 15:12:58 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Davidson", "Thomas", ""], ["Bhattacharya", "Debasmita", ""], ["Weber", "Ingmar", ""]]}, {"id": "1905.12534", "submitter": "Ricard Durall Lopez", "authors": "Ricard Durall, Franz-Josef Pfreundt, Janis Keuper", "title": "Stabilizing GANs with Soft Octave Convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by recently published methods using frequency decompositions of\nconvolutions (e.g. Octave Convolutions), we propose a novel convolution scheme\nto stabilize the training and reduce the likelihood of a mode collapse. The\nbasic idea of our approach is to split convolutional filters into additive high\nand low frequency parts, while shifting weight updates from low to high during\nthe training. Intuitively, this method forces GANs to learn low frequency\ncoarse image structures before descending into fine (high frequency) details.\nWe also show, that the use of the proposed soft octave convolutions reduces\ncommon artifacts in the frequency domain of generated images. Our approach is\northogonal and complementary to existing stabilization methods and can simply\nbe plugged into any CNN based GAN architecture. Experiments on the CelebA\ndataset show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 15:28:54 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 14:13:12 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 15:49:57 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Durall", "Ricard", ""], ["Pfreundt", "Franz-Josef", ""], ["Keuper", "Janis", ""]]}, {"id": "1905.12552", "submitter": "Adarsh Barik", "authors": "Adarsh Barik, Jean Honorio", "title": "Learning Bayesian Networks with Low Rank Conditional Probability Tables", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a method to learn the directed structure of a\nBayesian network using data. The data is accessed by making conditional\nprobability queries to a black-box model. We introduce a notion of simplicity\nof representation of conditional probability tables for the nodes in the\nBayesian network, that we call \"low rankness\". We connect this notion to the\nFourier transformation of real valued set functions and propose a method which\nlearns the exact directed structure of a `low rank` Bayesian network using very\nfew queries. We formally prove that our method correctly recovers the true\ndirected structure, runs in polynomial time and only needs polynomial samples\nwith respect to the number of nodes. We also provide further improvements in\nefficiency if we have access to some observational data.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:03:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "1905.12558", "submitter": "Frederik Kunstner", "authors": "Frederik Kunstner, Lukas Balles, Philipp Hennig", "title": "Limitations of the Empirical Fisher Approximation for Natural Gradient\n  Descent", "comments": "V3: Minor corrections (typographic errors)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural gradient descent, which preconditions a gradient descent update with\nthe Fisher information matrix of the underlying statistical model, is a way to\ncapture partial second-order information. Several highly visible works have\nadvocated an approximation known as the empirical Fisher, drawing connections\nbetween approximate second-order methods and heuristics like Adam. We dispute\nthis argument by showing that the empirical Fisher---unlike the Fisher---does\nnot generally capture second-order information. We further argue that the\nconditions under which the empirical Fisher approaches the Fisher (and the\nHessian) are unlikely to be met in practice, and that, even on simple\noptimization problems, the pathologies of the empirical Fisher can have\nundesirable effects.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:11:00 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:42:53 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 16:20:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kunstner", "Frederik", ""], ["Balles", "Lukas", ""], ["Hennig", "Philipp", ""]]}, {"id": "1905.12560", "submitter": "Joan Bruna", "authors": "Zhengdao Chen, Soledad Villar, Lei Chen, Joan Bruna", "title": "On the equivalence between graph isomorphism testing and function\n  approximation with GNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved lots of success on\ngraph-structured data. In the light of this, there has been increasing interest\nin studying their representation power. One line of work focuses on the\nuniversal approximation of permutation-invariant functions by certain classes\nof GNNs, and another demonstrates the limitation of GNNs via graph isomorphism\ntests.\n  Our work connects these two perspectives and proves their equivalence. We\nfurther develop a framework of the representation power of GNNs with the\nlanguage of sigma-algebra, which incorporates both viewpoints. Using this\nframework, we compare the expressive power of different classes of GNNs as well\nas other methods on graphs. In particular, we prove that order-2 Graph\nG-invariant networks fail to distinguish non-isomorphic regular graphs with the\nsame degree. We then extend them to a new architecture, Ring-GNNs, which\nsucceeds on distinguishing these graphs and provides improvements on real-world\nsocial network datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:14:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Chen", "Zhengdao", ""], ["Villar", "Soledad", ""], ["Chen", "Lei", ""], ["Bruna", "Joan", ""]]}, {"id": "1905.12561", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Emmanuel Dupoux and Marco Baroni", "title": "Anti-efficient encoding in emergent communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:14:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:46:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 16:58:54 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 11:56:14 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12567", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Gaston Ormazabal, Radu State, Jean Hilger", "title": "MQLV: Optimal Policy of Money Management in Retail Banking with\n  Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has become one of the best approach to train a\ncomputer game emulator capable of human level performance. In a reinforcement\nlearning approach, an optimal value function is learned across a set of\nactions, or decisions, that leads to a set of states giving different rewards,\nwith the objective to maximize the overall reward. A policy assigns to each\nstate-action pairs an expected return. We call an optimal policy a policy for\nwhich the value function is optimal. QLBS, Q-Learner in the\nBlack-Scholes(-Merton) Worlds, applies the reinforcement learning concepts, and\nnoticeably, the popular Q-learning algorithm, to the financial stochastic model\nof Black, Scholes and Merton. It is, however, specifically optimized for the\ngeometric Brownian motion and the vanilla options. Its range of application is,\ntherefore, limited to vanilla option pricing within financial markets. We\npropose MQLV, Modified Q-Learner for the Vasicek model, a new reinforcement\nlearning approach that determines the optimal policy of money management based\non the aggregated financial transactions of the clients. It unlocks new\nfrontiers to establish personalized credit card limits or to fulfill bank loan\napplications, targeting the retail banking industry. MQLV extends the\nsimulation to mean reverting stochastic diffusion processes and it uses a\ndigital function, a Heaviside step function expressed in its discrete form, to\nestimate the probability of a future event such as a payment default. In our\nexperiments, we first show the similarities between a set of historical\nfinancial transactions and Vasicek generated transactions and, then, we\nunderline the potential of MQLV on generated Monte Carlo simulations. Finally,\nMQLV is the first Q-learning Vasicek-based methodology addressing transparent\ndecision making processes in retail banking.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:02:27 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 07:11:36 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 07:51:22 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Charlier", "Jeremy", ""], ["Ormazabal", "Gaston", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.12568", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Radu State, Jean Hilger", "title": "Predicting Sparse Clients' Actions with CPOPT-Net in the Banking\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digital revolution of the banking system with evolving European\nregulations have pushed the major banking actors to innovate by a newly use of\ntheir clients' digital information. Given highly sparse client activities, we\npropose CPOPT-Net, an algorithm that combines the CP canonical tensor\ndecomposition, a multidimensional matrix decomposition that factorizes a tensor\nas the sum of rank-one tensors, and neural networks. CPOPT-Net removes\nefficiently sparse information with a gradient-based resolution while relying\non neural networks for time series predictions. Our experiments show that\nCPOPT-Net is capable to perform accurate predictions of the clients' actions in\nthe context of personalized recommendation. CPOPT-Net is the first algorithm to\nuse non-linear conjugate gradient tensor resolution with neural networks to\npropose predictions of financial activities on a public data set.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:43:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Charlier", "Jeremy", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.12569", "submitter": "Yaodong Yang Mr.", "authors": "Rui Luo, Qiang Zhang, Yaodong Yang, and Jun Wang", "title": "Replica-exchange Nos\\'e-Hoover dynamics for Bayesian learning on large\n  datasets", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new practical method for Bayesian learning that\ncan rapidly draw representative samples from complex posterior distributions\nwith multiple isolated modes in the presence of mini-batch noise. This is\nachieved by simulating a collection of replicas in parallel with different\ntemperatures and periodically swapping them. When evolving the replicas'\nstates, the Nos\\'e-Hoover dynamics is applied, which adaptively neutralizes the\nmini-batch noise. To perform proper exchanges, a new protocol is developed with\na noise-aware test of acceptance, by which the detailed balance is reserved in\nan asymptotic way. While its efficacy on complex multimodal posteriors has been\nillustrated by testing over synthetic distributions, experiments with deep\nBayesian neural networks on large-scale datasets have shown its significant\nimprovements over strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:22:32 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 18:10:56 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 23:43:42 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2021 14:44:28 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Luo", "Rui", ""], ["Zhang", "Qiang", ""], ["Yang", "Yaodong", ""], ["Wang", "Jun", ""]]}, {"id": "1905.12576", "submitter": "Babhru Joshi", "authors": "Paul Hand and Babhru Joshi", "title": "Global Guarantees for Blind Demodulation with Generative Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a deep learning inspired formulation for the blind demodulation\nproblem, which is the task of recovering two unknown vectors from their\nentrywise multiplication. We consider the case where the unknown vectors are in\nthe range of known deep generative models,\n$\\mathcal{G}^{(1)}:\\mathbb{R}^n\\rightarrow\\mathbb{R}^\\ell$ and\n$\\mathcal{G}^{(2)}:\\mathbb{R}^p\\rightarrow\\mathbb{R}^\\ell$. In the case when\nthe networks corresponding to the generative models are expansive, the weight\nmatrices are random and the dimension of the unknown vectors satisfy $\\ell =\n\\Omega(n^2+p^2)$, up to log factors, we show that the empirical risk objective\nhas a favorable landscape for optimization. That is, the objective function has\na descent direction at every point outside of a small neighborhood around four\nhyperbolic curves. We also characterize the local maximizers of the empirical\nrisk objective and, hence, show that there does not exist any other stationary\npoints outside of these neighborhood around four hyperbolic curves and the set\nof local maximizers. We also implement a gradient descent scheme inspired by\nthe geometry of the landscape of the objective function. In order to converge\nto a global minimizer, this gradient descent scheme exploits the fact that\nexactly one of the hyperbolic curve corresponds to the global minimizer, and\nthus points near this hyperbolic curve have a lower objective value than points\nclose to the other spurious hyperbolic curves. We show that this gradient\ndescent scheme can effectively remove distortions synthetically introduced to\nthe MNIST dataset.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:43:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Hand", "Paul", ""], ["Joshi", "Babhru", ""]]}, {"id": "1905.12580", "submitter": "Horia Mania", "authors": "Horia Mania, John Miller, Ludwig Schmidt, Moritz Hardt, Benjamin Recht", "title": "Model Similarity Mitigates Test Set Overuse", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessive reuse of test data has become commonplace in today's machine\nlearning workflows. Popular benchmarks, competitions, industrial scale tuning,\namong other applications, all involve test data reuse beyond guidance by\nstatistical confidence bounds. Nonetheless, recent replication studies give\nevidence that popular benchmarks continue to support progress despite years of\nextensive reuse. We proffer a new explanation for the apparent longevity of\ntest data: Many proposed models are similar in their predictions and we prove\nthat this similarity mitigates overfitting. Specifically, we show empirically\nthat models proposed for the ImageNet ILSVRC benchmark agree in their\npredictions well beyond what we can conclude from their accuracy levels alone.\nLikewise, models created by large scale hyperparameter search enjoy high levels\nof similarity. Motivated by these empirical observations, we give a\nnon-asymptotic generalization bound that takes similarity into account, leading\nto meaningful confidence bounds in practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:54:37 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Mania", "Horia", ""], ["Miller", "John", ""], ["Schmidt", "Ludwig", ""], ["Hardt", "Moritz", ""], ["Recht", "Benjamin", ""]]}, {"id": "1905.12588", "submitter": "Khurram Javed Mr", "authors": "Khurram Javed and Martha White", "title": "Meta-Learning Representations for Continual Learning", "comments": "Accepted at NeurIPS19, 15 pages, 10 figures, open-source,\n  representation learning, continual learning, online learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continual learning agent should be able to build on top of existing\nknowledge to learn on new data quickly while minimizing forgetting. Current\nintelligent systems based on neural network function approximators arguably do\nthe opposite---they are highly prone to forgetting and rarely trained to\nfacilitate future learning. One reason for this poor behavior is that they\nlearn from a representation that is not explicitly trained for these two goals.\nIn this paper, we propose OML, an objective that directly minimizes\ncatastrophic interference by learning representations that accelerate future\nlearning and are robust to forgetting under online updates in continual\nlearning. We show that it is possible to learn naturally sparse representations\nthat are more effective for online updating. Moreover, our algorithm is\ncomplementary to existing continual learning strategies, such as MER and GEM.\nFinally, we demonstrate that a basic online updating strategy on\nrepresentations learned by OML is competitive with rehearsal based methods for\ncontinual learning. We release an implementation of our method at\nhttps://github.com/khurramjaved96/mrcl .\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:09:31 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:36:25 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Javed", "Khurram", ""], ["White", "Martha", ""]]}, {"id": "1905.12590", "submitter": "Gianluca Stringhini", "authors": "Yun Shen, Gianluca Stringhini", "title": "ATTACK2VEC: Leveraging Temporal Word Embeddings to Understand the\n  Evolution of Cyberattacks", "comments": null, "journal-ref": "2019 USENIX Security Symposium", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that cyberattacks are constantly growing in complexity, the\nresearch community still lacks effective tools to easily monitor and understand\nthem. In particular, there is a need for techniques that are able to not only\ntrack how prominently certain malicious actions, such as the exploitation of\nspecific vulnerabilities, are exploited in the wild, but also (and more\nimportantly) how these malicious actions factor in as attack steps in more\ncomplex cyberattacks. In this paper we present ATTACK2VEC, a system that uses\ntemporal word embeddings to model how attack steps are exploited in the wild,\nand track how they evolve. We test ATTACK2VEC on a dataset of billions of\nsecurity events collected from the customers of a commercial Intrusion\nPrevention System over a period of two years, and show that our approach is\neffective in monitoring the emergence of new attack strategies in the wild and\nin flagging which attack steps are often used together by attackers (e.g.,\nvulnerabilities that are frequently exploited together). ATTACK2VEC provides a\nuseful tool for researchers and practitioners to better understand cyberattacks\nand their evolution, and use this knowledge to improve situational awareness\nand develop proactive defenses.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:10:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shen", "Yun", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1905.12592", "submitter": "Si Kai Lee", "authors": "Si Kai Lee, Luigi Gresele, Mijung Park, Krikamol Muandet", "title": "Privacy-Preserving Causal Inference via Inverse Probability Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of inverse probability weighting (IPW) methods to estimate the causal\neffect of treatments from observational studies is widespread in econometrics,\nmedicine and social sciences. Although these studies often involve sensitive\ninformation, thus far there has been no work on privacy-preserving IPW methods.\nWe address this by providing a novel framework for privacy-preserving IPW\n(PP-IPW) methods. We include a theoretical analysis of the effects of our\nproposed privatisation procedure on the estimated average treatment effect, and\nevaluate our PP-IPW framework on synthetic, semi-synthetic and real datasets.\nThe empirical results are consistent with our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:11:14 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:24:57 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Lee", "Si Kai", ""], ["Gresele", "Luigi", ""], ["Park", "Mijung", ""], ["Muandet", "Krikamol", ""]]}, {"id": "1905.12596", "submitter": "Michiel Straat", "authors": "Michiel Straat, Jorrit Oosterhof", "title": "Segmentation of blood vessels in retinal fundus images", "comments": "Conference: SC@RUG 2017, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several automatic segmentation methods have been proposed\nfor blood vessels in retinal fundus images, ranging from using cheap and fast\ntrainable filters to complicated neural networks and even deep learning. One\nexample of a filted-based segmentation method is B-COSFIRE. In this approach\nthe image filter is trained with example prototype patterns, to which the\nfilter becomes selective by finding points in a Difference of Gaussian response\non circles around the center with large intensity variation. In this paper we\ndiscuss and evaluate several of these vessel segmentation methods. We take a\ncloser look at B-COSFIRE and study the performance of B-COSFIRE on the recently\npublished IOSTAR dataset by experiments and we examine how the parameter values\naffect the performance. In the experiment we manage to reach a segmentation\naccuracy of 0.9419. Based on our findings we discuss when B-COSFIRE is the\npreferred method to use and in which circumstances it could be beneficial to\nuse a more (computationally) complex segmentation method. We also shortly\ndiscuss areas beyond blood vessel segmentation where these methods can be used\nto segment elongated structures, such as rivers in satellite images or nerves\nof a leaf.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:17:45 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Straat", "Michiel", ""], ["Oosterhof", "Jorrit", ""]]}, {"id": "1905.12600", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "Generalization bounds for deep convolutional neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds on the generalization error of convolutional networks. The\nbounds are in terms of the training loss, the number of parameters, the\nLipschitz constant of the loss and the distance from the weights to the initial\nweights. They are independent of the number of pixels in the input, and the\nheight and width of hidden feature maps. We present experiments using CIFAR-10\nwith varying hyperparameters of a deep convolutional network, comparing our\nbounds with practical generalization gaps.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:20:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 16:54:56 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 16:39:20 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 01:55:42 GMT"}, {"version": "v5", "created": "Sun, 9 Feb 2020 20:00:07 GMT"}, {"version": "v6", "created": "Wed, 8 Apr 2020 05:10:39 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1905.12601", "submitter": "Nithin Nagaraj", "authors": "Harikrishnan N B and Nithin Nagaraj", "title": "A Novel Chaos Theory Inspired Neuronal Architecture", "comments": "6 pages, 5 figures. This is a pre-print version of the manuscript\n  which we will be submitting soon to an international conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical success of widely used machine learning (ML) and deep learning\n(DL) algorithms in Artificial Intelligence (AI) community owes to availability\nof large datasets for training and huge computational resources. Despite the\nenormous practical success of AI, these algorithms are only loosely inspired\nfrom the biological brain and do not mimic any of the fundamental properties of\nneurons in the brain, one such property being the chaotic firing of biological\nneurons. This motivates us to develop a novel neuronal architecture where the\nindividual neurons are intrinsically chaotic in nature. By making use of the\ntopological transitivity property of chaos, our neuronal network is able to\nperform classification tasks with very less number of training samples. For the\nMNIST dataset, with as low as $0.1 \\%$ of the total training data, our method\noutperforms ML and matches DL in classification accuracy for up to $7$ training\nsamples/class. For the Iris dataset, our accuracy is comparable with ML\nalgorithms, and even with just two training samples/class, we report an\naccuracy as high as $95.8 \\%$. This work highlights the effectiveness of chaos\nand its properties for learning and paves the way for chaos-inspired neuronal\narchitectures by closely mimicking the chaotic nature of neurons in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:45:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["B", "Harikrishnan N", ""], ["Nagaraj", "Nithin", ""]]}, {"id": "1905.12605", "submitter": "Daniel Michelsanti", "authors": "Daniel Michelsanti, Zheng-Hua Tan, Sigurdur Sigurdsson, Jesper Jensen", "title": "Deep-Learning-Based Audio-Visual Speech Enhancement in Presence of\n  Lombard Effect", "comments": null, "journal-ref": null, "doi": "10.1016/j.specom.2019.10.006", "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When speaking in presence of background noise, humans reflexively change\ntheir way of speaking in order to improve the intelligibility of their speech.\nThis reflex is known as Lombard effect. Collecting speech in Lombard conditions\nis usually hard and costly. For this reason, speech enhancement systems are\ngenerally trained and evaluated on speech recorded in quiet to which noise is\nartificially added. Since these systems are often used in situations where\nLombard speech occurs, in this work we perform an analysis of the impact that\nLombard effect has on audio, visual and audio-visual speech enhancement,\nfocusing on deep-learning-based systems, since they represent the current state\nof the art in the field.\n  We conduct several experiments using an audio-visual Lombard speech corpus\nconsisting of utterances spoken by 54 different talkers. The results show that\ntraining deep-learning-based models with Lombard speech is beneficial in terms\nof both estimated speech quality and estimated speech intelligibility at low\nsignal to noise ratios, where the visual modality can play an important role in\nacoustically challenging situations. We also find that a performance difference\nbetween genders exists due to the distinct Lombard speech exhibited by males\nand females, and we analyse it in relation with acoustic and visual features.\nFurthermore, listening tests conducted with audio-visual stimuli show that the\nspeech quality of the signals processed with systems trained using Lombard\nspeech is statistically significantly better than the one obtained using\nsystems trained with non-Lombard speech at a signal to noise ratio of -5 dB.\nRegarding speech intelligibility, we find a general tendency of the benefit in\ntraining the systems with Lombard speech.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:37:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Michelsanti", "Daniel", ""], ["Tan", "Zheng-Hua", ""], ["Sigurdsson", "Sigurdur", ""], ["Jensen", "Jesper", ""]]}, {"id": "1905.12612", "submitter": "Ashish Kumar", "authors": "Ashish Kumar, Saurabh Gupta, Jitendra Malik", "title": "Learning Navigation Subroutines from Egocentric Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning at a higher level of abstraction instead of low level torques\nimproves the sample efficiency in reinforcement learning, and computational\nefficiency in classical planning. We propose a method to learn such\nhierarchical abstractions, or subroutines from egocentric video data of experts\nperforming tasks. We learn a self-supervised inverse model on small amounts of\nrandom interaction data to pseudo-label the expert egocentric videos with agent\nactions. Visuomotor subroutines are acquired from these pseudo-labeled videos\nby learning a latent intent-conditioned policy that predicts the inferred\npseudo-actions from the corresponding image observations. We demonstrate our\nproposed approach in context of navigation, and show that we can successfully\nlearn consistent and diverse visuomotor subroutines from passive egocentric\nvideos. We demonstrate the utility of our acquired visuomotor subroutines by\nusing them as is for exploration, and as sub-policies in a hierarchical RL\nframework for reaching point goals and semantic goals. We also demonstrate\nbehavior of our subroutines in the real world, by deploying them on a real\nrobotic platform. Project website:\nhttps://ashishkumar1993.github.io/subroutines/.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:50:19 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 08:10:25 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Kumar", "Ashish", ""], ["Gupta", "Saurabh", ""], ["Malik", "Jitendra", ""]]}, {"id": "1905.12614", "submitter": "Irina Higgins", "authors": "Sunny Duan, Loic Matthey, Andre Saraiva, Nicholas Watters, Christopher\n  P. Burgess, Alexander Lerchner, Irina Higgins", "title": "Unsupervised Model Selection for Variational Disentangled Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representations have recently been shown to improve fairness,\ndata efficiency and generalisation in simple supervised and reinforcement\nlearning tasks. To extend the benefits of disentangled representations to more\ncomplex domains and practical applications, it is important to enable\nhyperparameter tuning and model selection of existing unsupervised approaches\nwithout requiring access to ground truth attribute labels, which are not\navailable for most datasets. This paper addresses this problem by introducing a\nsimple yet robust and reliable method for unsupervised disentangled model\nselection. Our approach, Unsupervised Disentanglement Ranking (UDR), leverages\nthe recent theoretical results that explain why variational autoencoders\ndisentangle (Rolinek et al, 2019), to quantify the quality of disentanglement\nby performing pairwise comparisons between trained model representations. We\nshow that our approach performs comparably to the existing supervised\nalternatives across 5,400 models from six state of the art unsupervised\ndisentangled representation learning model classes. Furthermore, we show that\nthe ranking produced by our approach correlates well with the final task\nperformance on two different domains.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:56:58 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 11:20:04 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 12:40:43 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 12:10:51 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Duan", "Sunny", ""], ["Matthey", "Loic", ""], ["Saraiva", "Andre", ""], ["Watters", "Nicholas", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""], ["Higgins", "Irina", ""]]}, {"id": "1905.12615", "submitter": "Quanquan Gu", "authors": "Pan Xu and Felicia Gao and Quanquan Gu", "title": "An Improved Convergence Analysis of Stochastic Variance-Reduced Policy\n  Gradient", "comments": "10 pages, 2 figures, 1 table. To appear in the proceedings of the\n  35th International Conference on Uncertainty in Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the stochastic variance-reduced policy gradient (SVRPG) method\nproposed by Papini et al. (2018) for reinforcement learning. We provide an\nimproved convergence analysis of SVRPG and show that it can find an\n$\\epsilon$-approximate stationary point of the performance function within\n$O(1/\\epsilon^{5/3})$ trajectories. This sample complexity improves upon the\nbest known result $O(1/\\epsilon^2)$ by a factor of $O(1/\\epsilon^{1/3})$. At\nthe core of our analysis is (i) a tighter upper bound for the variance of\nimportance sampling weights, where we prove that the variance can be controlled\nby the parameter distance between different policies; and (ii) a fine-grained\nanalysis of the epoch length and batch size parameters such that we can\nsignificantly reduce the number of trajectories required in each iteration of\nSVRPG. We also empirically demonstrate the effectiveness of our theoretical\nclaims of batch sizes on reinforcement learning benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:57:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Xu", "Pan", ""], ["Gao", "Felicia", ""], ["Gu", "Quanquan", ""]]}, {"id": "1905.12621", "submitter": "Giulia Vezzani", "authors": "Giulia Vezzani, Abhishek Gupta, Lorenzo Natale, Pieter Abbeel", "title": "Learning latent state representation for speeding up exploration", "comments": "7 pages, 8 figures, workshop", "journal-ref": "2nd Exploration in Reinforcement Learning Workshop at the 36 th\n  International Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is an extremely challenging problem in reinforcement learning,\nespecially in high dimensional state and action spaces and when only sparse\nrewards are available. Effective representations can indicate which components\nof the state are task relevant and thus reduce the dimensionality of the space\nto explore. In this work, we take a representation learning viewpoint on\nexploration, utilizing prior experience to learn effective latent\nrepresentations, which can subsequently indicate which regions to explore.\nPrior experience on separate but related tasks help learn representations of\nthe state which are effective at predicting instantaneous rewards. These\nlearned representations can then be used with an entropy-based exploration\nmethod to effectively perform exploration in high dimensional spaces by\neffectively lowering the dimensionality of the search space. We show the\nbenefits of this representation for meta-exploration in a simulated object\npushing environment.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:25:16 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Vezzani", "Giulia", ""], ["Gupta", "Abhishek", ""], ["Natale", "Lorenzo", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1905.12624", "submitter": "Idan Rejwan", "authors": "Idan Rejwan and Yishay Mansour", "title": "Top-k Combinatorial Bandits with Full-Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-k Combinatorial Bandits generalize multi-armed bandits, where at each\nround any subset of $k$ out of $n$ arms may be chosen and the sum of the\nrewards is gained. We address the full-bandit feedback, in which the agent\nobserves only the sum of rewards, in contrast to the semi-bandit feedback, in\nwhich the agent observes also the individual arms' rewards. We present the\nCombinatorial Successive Accepts and Rejects (CSAR) algorithm, which\ngeneralizes SAR (Bubeck et al, 2013) for top-k combinatorial bandits. Our main\ncontribution is an efficient sampling scheme that uses Hadamard matrices in\norder to estimate accurately the individual arms' expected rewards. We discuss\ntwo variants of the algorithm, the first minimizes the sample complexity and\nthe second minimizes the regret. We also prove a lower bound on sample\ncomplexity, which is tight for $k=O(1)$. Finally, we run experiments and show\nthat our algorithm outperforms other methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:04:39 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 17:46:30 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Rejwan", "Idan", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.12628", "submitter": "Pekka Siirtola", "authors": "Pekka Siirtola, Heli Koskim\\\"aki, Juha R\\\"oning", "title": "Personalizing human activity recognition models using incremental\n  learning", "comments": "26th European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning, ESANN 2018, April 25-27, 627-632", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, the aim is to personalize inertial sensor data-based human\nactivity recognition models using incremental learning. At first, the\nrecognition is based on user-independent model. However, when personal\nstreaming data becomes available, the incremental learning-based recognition\nmodel can be updated, and therefore personalized, based on the data without\nuser-interruption. The used incremental learning algorithm is Learn++ which is\nan ensemble method that can use any classifier as a base classifier. In fact,\nstudy compares three different base classifiers: linear discriminant analysis\n(LDA), quadratic discriminant analysis (QDA) and classification and regression\ntree (CART). Experiments are based on publicly open data set and they show that\nalready a small personal training data set can improve the classification\naccuracy. Improvement using LDA as base classifier is 4.6 percentage units,\nusing QDA 2.0 percentage units, and 2.3 percentage units using CART. However,\nif the user-independent model used in the first phase of the recognition\nprocess is not accurate enough, personalization cannot improve recognition\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:29:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Siirtola", "Pekka", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "1905.12629", "submitter": "Fabio Paolizzo", "authors": "Fabio Paolizzo, Natalia Pichierri, Daniele Casali, Daniele Giardino,\n  Marco Matta, Giovanni Costantini", "title": "A New Multilabel System for Automatic Music Emotion Recognition", "comments": "2 tables. Research supported by the EU through the MUSICAL-MOODS\n  project funded by the Marie Sklodowska-Curie Actions Individual Fellowships\n  Global Fellowships (MSCA-IF-GF) of the Horizon 2020 Programme\n  H2020/2014-2020, REA grant agreement n.659434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving advancements in automatic recognition of emotions that music can\ninduce require considering multiplicity and simultaneity of emotions.\nComparison of different machine learning algorithms performing multilabel and\nmulticlass classification is the core of our work. The study analyzes the\nimplementation of the Geneva Emotional Music Scale 9 in the Emotify music\ndataset and investigates its adoption from a machine-learning perspective. We\napproach the scenario of emotions expression/induction through music as a\nmultilabel and multiclass problem, where multiple emotion labels can be adopted\nfor the same music track by each annotator (multilabel), and each emotion can\nbe identified or not in the music (multiclass). The aim is the automatic\nrecognition of induced emotions through music.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:33:20 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 21:55:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Paolizzo", "Fabio", ""], ["Pichierri", "Natalia", ""], ["Casali", "Daniele", ""], ["Giardino", "Daniele", ""], ["Matta", "Marco", ""], ["Costantini", "Giovanni", ""]]}, {"id": "1905.12648", "submitter": "Shicong Cen", "authors": "Shicong Cen, Huishuai Zhang, Yuejie Chi, Wei Chen, Tie-Yan Liu", "title": "Convergence of Distributed Stochastic Variance Reduced Methods without\n  Sampling Extra Data", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3005291", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance reduced methods have gained a lot of interest recently\nfor empirical risk minimization due to its appealing run time complexity. When\nthe data size is large and disjointly stored on different machines, it becomes\nimperative to distribute the implementation of such variance reduced methods.\nIn this paper, we consider a general framework that directly distributes\npopular stochastic variance reduced methods in the master/slave model, by\nassigning outer loops to the parameter server, and inner loops to worker\nmachines. This framework is natural and friendly to implement, but its\ntheoretical convergence is not well understood. We obtain a comprehensive\nunderstanding of algorithmic convergence with respect to data homogeneity by\nmeasuring the smoothness of the discrepancy between the local and global loss\nfunctions. We establish the linear convergence of distributed versions of a\nfamily of stochastic variance reduced algorithms, including those using\naccelerated and recursive gradient updates, for minimizing strongly convex\nlosses. Our theory captures how the convergence of distributed algorithms\nbehaves as the number of machines and the size of local data vary. Furthermore,\nwe show that when the data are less balanced, regularization can be used to\nensure convergence at a slower rate. We also demonstrate that our analysis can\nbe further extended to handle nonconvex loss functions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:00:56 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:13:19 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 18:26:42 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Cen", "Shicong", ""], ["Zhang", "Huishuai", ""], ["Chi", "Yuejie", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1905.12654", "submitter": "Huan Wang", "authors": "Huan Wang, Stephan Zheng, Caiming Xiong, Richard Socher", "title": "On the Generalization Gap in Reparameterizable Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 36 th International Conference on Machine\n  Learning, Long Beach, California, PMLR 97, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding generalization in reinforcement learning (RL) is a significant\nchallenge, as many common assumptions of traditional supervised learning theory\ndo not apply. We focus on the special class of reparameterizable RL problems,\nwhere the trajectory distribution can be decomposed using the reparametrization\ntrick. For this problem class, estimating the expected return is efficient and\nthe trajectory can be computed deterministically given peripheral random\nvariables, which enables us to study reparametrizable RL using supervised\nlearning and transfer learning theory. Through these relationships, we derive\nguarantees on the gap between the expected and empirical return for both\nintrinsic and external errors, based on Rademacher complexity as well as the\nPAC-Bayes bound. Our bound suggests the generalization capability of\nreparameterizable RL is related to multiple factors including \"smoothness\" of\nthe environment transition, reward and agent policy function class. We also\nempirically verify the relationship between the generalization gap and these\nfactors through simulations.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:05:01 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Wang", "Huan", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1905.12659", "submitter": "Mingzhang Yin", "authors": "Mingzhang Yin, Mingyuan Zhou", "title": "Semi-Implicit Generative Model", "comments": "Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montreal,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combine explicit and implicit generative models, we introduce\nsemi-implicit generator (SIG) as a flexible hierarchical model that can be\ntrained in the maximum likelihood framework. Both theoretically and\nexperimentally, we demonstrate that SIG can generate high quality samples\nespecially when dealing with multi-modality. By introducing SIG as an unbiased\nregularizer to the generative adversarial network (GAN), we show the interplay\nbetween maximum likelihood and adversarial learning can stabilize the\nadversarial training, resist the notorious mode collapsing problem of GANs, and\nimprove the diversity of generated random samples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:08:26 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 02:40:17 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1905.12660", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Sebastian Ewert, Simon Dixon", "title": "Training Generative Adversarial Networks from Incomplete Observations\n  using Factorised Discriminators", "comments": "10 pages plus 14 pages appendix. Accepted at the International\n  Conference on Learning Representations (ICLR) 2020. Camera-ready submission.\n  Implementation available at https://github.com/f90/FactorGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown great success in\napplications such as image generation and inpainting. However, they typically\nrequire large datasets, which are often not available, especially in the\ncontext of prediction tasks such as image segmentation that require labels.\nTherefore, methods such as the CycleGAN use more easily available unlabelled\ndata, but do not offer a way to leverage additional labelled data for improved\nperformance. To address this shortcoming, we show how to factorise the joint\ndata distribution into a set of lower-dimensional distributions along with\ntheir dependencies. This allows splitting the discriminator in a GAN into\nmultiple \"sub-discriminators\" that can be independently trained from incomplete\nobservations. Their outputs can be combined to estimate the density ratio\nbetween the joint real and the generator distribution, which enables training\ngenerators as in the original GAN framework. We apply our method to image\ngeneration, image segmentation and audio source separation, and obtain improved\nperformance over a standard GAN when additional incomplete training examples\nare available. For the Cityscapes segmentation task in particular, our method\nalso improves accuracy by an absolute 14.9% over CycleGAN while using only 25\nadditional paired examples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:10:08 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 15:35:37 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Stoller", "Daniel", ""], ["Ewert", "Sebastian", ""], ["Dixon", "Simon", ""]]}, {"id": "1905.12663", "submitter": "Adam Bielski", "authors": "Adam Bielski, Paolo Favaro", "title": "Emergence of Object Segmentation in Perturbed Generative Models", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework to build a model that can learn how to segment\nobjects from a collection of images without any human annotation. Our method\nbuilds on the observation that the location of object segments can be perturbed\nlocally relative to a given background without affecting the realism of a\nscene. Our approach is to first train a generative model of a layered scene.\nThe layered representation consists of a background image, a foreground image\nand the mask of the foreground. A composite image is then obtained by\noverlaying the masked foreground image onto the background. The generative\nmodel is trained in an adversarial fashion against a discriminator, which\nforces the generative model to produce realistic composite images. To force the\ngenerator to learn a representation where the foreground layer corresponds to\nan object, we perturb the output of the generative model by introducing a\nrandom shift of both the foreground image and mask relative to the background.\nBecause the generator is unaware of the shift before computing its output, it\nmust produce layered representations that are realistic for any such random\nperturbation. Finally, we learn to segment an image by defining an autoencoder\nconsisting of an encoder, which we train, and the pre-trained generator as the\ndecoder, which we freeze. The encoder maps an image to a feature vector, which\nis fed as input to the generator to give a composite image matching the\noriginal input image. Because the generator outputs an explicit layered\nrepresentation of the scene, the encoder learns to detect and segment objects.\nWe demonstrate this framework on real images of several object categories.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:17:39 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 17:46:33 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bielski", "Adam", ""], ["Favaro", "Paolo", ""]]}, {"id": "1905.12665", "submitter": "Ad\\'in Ram\\'irez Rivera", "authors": "Darwin Saire Pilco and Ad\\'in Ram\\'irez Rivera", "title": "Graph Learning Network: A Structure Learning Algorithm", "comments": "Accepted for publication at ICML 2019 Workshop on Learning and\n  Reasoning with Graph-Structured Data. Code available at\n  https://gitlab.com/mipl/graph-learning-network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, graph neural networks (GNNs) have proved to be suitable in tasks on\nunstructured data. Particularly in tasks as community detection, node\nclassification, and link prediction. However, most GNN models still operate\nwith static relationships. We propose the Graph Learning Network (GLN), a\nsimple yet effective process to learn node embeddings and structure prediction\nfunctions. Our model uses graph convolutions to propose expected node features,\nand predict the best structure based on them. We repeat these steps recursively\nto enhance the prediction and the embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:20:47 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 13:31:15 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 19:21:33 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Pilco", "Darwin Saire", ""], ["Rivera", "Ad\u00edn Ram\u00edrez", ""]]}, {"id": "1905.12666", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou", "title": "Evaluating structure learning algorithms with a balanced scoring\n  function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several structure learning algorithms have been proposed towards discovering\ncausal or Bayesian Network (BN) graphs. The validity of these algorithms tends\nto be evaluated by assessing the relationship between the learnt and the ground\ntruth graph. However, there is no agreed scoring metric to determine this\nrelationship. Moreover, this paper shows that some of the commonly used metrics\ntend to be biased in favour of graphs that minimise edges. While graphs that\nare less complex are desirable, some of the metrics favour underfitted graphs,\nthereby encouraging limited propagation of evidence. This paper proposes the\nBalanced Scoring Function (BSF) that eliminates this bias by adjusting the\nreward function based on the difficulty of discovering an edge, or no edge,\nproportional to their occurrence rate in the ground truth graph. The BSF score\ncan be used in conjunction with other traditional metrics to provide an\nalternative and unbiased assessment about the capability of a structure\nlearning algorithm in discovering causal or BN graphs.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:23:17 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 13:35:28 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 10:01:12 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Constantinou", "Anthony C.", ""]]}, {"id": "1905.12667", "submitter": "Yunhao Tang", "authors": "Krzysztof Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang", "title": "Structured Monte Carlo Sampling for Nonisotropic Distributions via\n  Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of structured methods for Monte Carlo (MC) sampling,\ncalled DPPMC, designed for high-dimensional nonisotropic distributions where\nsamples are correlated to reduce the variance of the estimator via\ndeterminantal point processes. We successfully apply DPPMCs to problems\ninvolving nonisotropic distributions arising in guided evolution strategy (GES)\nmethods for RL, CMA-ES techniques and trust region algorithms for blackbox\noptimization, improving state-of-the-art in all these settings. In particular,\nwe show that DPPMCs drastically improve exploration profiles of the existing\nevolution strategy algorithms. We further confirm our results, analyzing random\nfeature map estimators for Gaussian mixture kernels. We provide theoretical\njustification of our empirical results, showing a connection between DPPMCs and\nstructured orthogonal MC methods for isotropic distributions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:25:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""]]}, {"id": "1905.12673", "submitter": "Young Hun Jung", "authors": "Young Hun Jung, Ambuj Tewari", "title": "Regret Bounds for Thompson Sampling in Episodic Restless Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restless bandit problems are instances of non-stationary multi-armed bandits.\nThese problems have been studied well from the optimization perspective, where\nthe goal is to efficiently find a near-optimal policy when system parameters\nare known. However, very few papers adopt a learning perspective, where the\nparameters are unknown. In this paper, we analyze the performance of Thompson\nsampling in episodic restless bandits with unknown parameters. We consider a\ngeneral policy map to define our competitor and prove an\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ Bayesian regret bound. Our competitor is\nflexible enough to represent various benchmarks including the best fixed action\npolicy, the optimal policy, the Whittle index policy, or the myopic policy. We\nalso present empirical results that support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:38:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 19:41:54 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Jung", "Young Hun", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1905.12678", "submitter": "Rozenn Dahyot", "authors": "Rozenn Dahyot and Hana Alghamdi and Mairead Grogan", "title": "Entropic Regularisation of Robust Optimal Transport", "comments": "8 pages", "journal-ref": "Proceeding of Irish Machine Vision and Image Processing conference\n  IMVIP 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grogan et al [11,12] have recently proposed a solution to colour transfer by\nminimising the Euclidean distance L2 between two probability density functions\ncapturing the colour distributions of two images (palette and target). It was\nshown to be very competitive to alternative solutions based on Optimal\nTransport for colour transfer. We show that in fact Grogan et al's formulation\ncan also be understood as a new robust Optimal Transport based framework with\nentropy regularisation over marginals.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:51:11 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Dahyot", "Rozenn", ""], ["Alghamdi", "Hana", ""], ["Grogan", "Mairead", ""]]}, {"id": "1905.12681", "submitter": "Weiyao Wang", "authors": "Weiyao Wang and Du Tran and Matt Feiszli", "title": "What Makes Training Multi-Modal Classification Networks Hard?", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider end-to-end training of a multi-modal vs. a single-modal network on a\ntask with multiple input modalities: the multi-modal network receives more\ninformation, so it should match or outperform its single-modal counterpart. In\nour experiments, however, we observe the opposite: the best single-modal\nnetwork always outperforms the multi-modal network. This observation is\nconsistent across different combinations of modalities and on different tasks\nand benchmarks.\n  This paper identifies two main causes for this performance drop: first,\nmulti-modal networks are often prone to overfitting due to increased capacity.\nSecond, different modalities overfit and generalize at different rates, so\ntraining them jointly with a single optimization strategy is sub-optimal. We\naddress these two problems with a technique we call Gradient Blending, which\ncomputes an optimal blend of modalities based on their overfitting behavior. We\ndemonstrate that Gradient Blending outperforms widely-used baselines for\navoiding overfitting and achieves state-of-the-art accuracy on various tasks\nincluding human action recognition, ego-centric action recognition, and\nacoustic event detection.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:10:06 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 18:24:31 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2019 07:04:17 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 22:49:19 GMT"}, {"version": "v5", "created": "Fri, 3 Apr 2020 00:36:42 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wang", "Weiyao", ""], ["Tran", "Du", ""], ["Feiszli", "Matt", ""]]}, {"id": "1905.12686", "submitter": "Sophie Hilgard", "authors": "Sophie Hilgard, Nir Rosenfeld, Mahzarin R. Banaji, Jack Cao, David C.\n  Parkes", "title": "Learning Representations by Humans, for Humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of optimizing machines to support human decision-making is often\nconflated with that of optimizing machines for accuracy even though they are\nmaterially different. Whereas it is typical for learning systems to prescribe\nactions through prediction, here we propose an approach in which the role of\nmachines is to reframe problems in order to directly support human decisions.\nInspired by the success of representation learning in promoting machine\nperformance, we frame the problem as one of learning representations that are\nconducive to good human performance. This \"Man Composed with Machine\" framework\nincorporates a human decision-making model directly into the representation\nlearning paradigm with optimization achieved through a novel human-in-the-loop\ntraining procedure. We empirically demonstrate on various tasks and\nrepresentational forms that the framework is capable of learning\nrepresentations that better coincide with human decision-making processes and\ncan lead to good decisions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:19:09 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:41:49 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 13:55:11 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Hilgard", "Sophie", ""], ["Rosenfeld", "Nir", ""], ["Banaji", "Mahzarin R.", ""], ["Cao", "Jack", ""], ["Parkes", "David C.", ""]]}, {"id": "1905.12692", "submitter": "Harlin Lee", "authors": "Rohan Varma, Harlin Lee, Jelena Kova\\v{c}evi\\'c, Yuejie Chi", "title": "Vector-Valued Graph Trend Filtering with Non-Convex Penalties", "comments": "The first two authors contributed equally", "journal-ref": "IEEE Transactions on Signal and Information Processing over\n  Networks, vol. 6, pp. 48-62, 2020", "doi": "10.1109/TSIPN.2019.2957717", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the denoising of piecewise smooth graph signals that\nexhibit inhomogeneous levels of smoothness over a graph, where the value at\neach node can be vector-valued. We extend the graph trend filtering framework\nto denoising vector-valued graph signals with a family of non-convex\nregularizers, which exhibit superior recovery performance over existing convex\nregularizers. Using an oracle inequality, we establish the statistical error\nrates of first-order stationary points of the proposed non-convex method for\ngeneric graphs. Furthermore, we present an ADMM-based algorithm to solve the\nproposed method and establish its convergence. Numerical experiments are\nconducted on both synthetic and real-world data for denoising, support\nrecovery, event detection, and semi-supervised classification.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:29:29 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 00:23:07 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 19:58:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Varma", "Rohan", ""], ["Lee", "Harlin", ""], ["Kova\u010devi\u0107", "Jelena", ""], ["Chi", "Yuejie", ""]]}, {"id": "1905.12698", "submitter": "Ronny Luss", "authors": "Ronny Luss, Pin-Yu Chen, Amit Dhurandhar, Prasanna Sattigeri, Yunfeng\n  Zhang, Karthikeyan Shanmugam, Chun-Chen Tu", "title": "Leveraging Latent Features for Local Explanations", "comments": "Accepted to KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the application of deep neural networks proliferates in numerous areas\nsuch as medical imaging, video surveillance, and self driving cars, the need\nfor explaining the decisions of these models has become a hot research topic,\nboth at the global and local level. Locally, most explanation methods have\nfocused on identifying relevance of features, limiting the types of\nexplanations possible. In this paper, we investigate a new direction by\nleveraging latent features to generate contrastive explanations; predictions\nare explained not only by highlighting aspects that are in themselves\nsufficient to justify the classification, but also by new aspects which if\nadded will change the classification. The key contribution of this paper lies\nin how we add features to rich data in a formal yet humanly interpretable way\nthat leads to meaningful results. Our new definition of \"addition\" uses latent\nfeatures to move beyond the limitations of previous explanations and resolve an\nopen question laid out in Dhurandhar, et. al. (2018), which creates local\ncontrastive explanations but is limited to simple datasets such as grayscale\nimages. The strength of our approach in creating intuitive explanations that\nare also quantitatively superior to other methods is demonstrated on three\ndiverse image datasets (skin lesions, faces, and fashion apparel). A user study\nwith 200 participants further exemplifies the benefits of contrastive\ninformation, which can be viewed as complementary to other state-of-the-art\ninterpretability methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:48:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 15:58:03 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 20:30:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Luss", "Ronny", ""], ["Chen", "Pin-Yu", ""], ["Dhurandhar", "Amit", ""], ["Sattigeri", "Prasanna", ""], ["Zhang", "Yunfeng", ""], ["Shanmugam", "Karthikeyan", ""], ["Tu", "Chun-Chen", ""]]}, {"id": "1905.12707", "submitter": "Giorgio Gnecco", "authors": "Falco J. Bargagli-Stoffi and Kristof De-Witte and Giorgio Gnecco", "title": "Heterogeneous causal effects with imperfect compliance: a novel Bayesian\n  machine learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an innovative Bayesian machine learning algorithm to\ndraw interpretable inference on heterogeneous causal effects in the presence of\nimperfect compliance (e.g., under an irregular assignment mechanism). We show,\nthrough Monte Carlo simulations, that the proposed Bayesian Causal Forest with\nInstrumental Variable (BCF-IV) methodology outperforms other machine learning\ntechniques tailored for causal inference in discovering and estimating the\nheterogeneous causal effects. BCF-IV sheds a light on the heterogeneity of\ncausal effects in instrumental variable scenarios and, in turn, provides the\npolicy-makers with a relevant tool for targeted policies. Its empirical\napplication evaluates the effects of additional funding on students'\nperformances. The results indicate that BCF-IV could be used to enhance the\neffectiveness of school funding on students' performance. Code is available at\nhttps://github.com/fbargaglistoffi/BCF-IV.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:25:34 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 09:04:36 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 22:42:39 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Bargagli-Stoffi", "Falco J.", ""], ["De-Witte", "Kristof", ""], ["Gnecco", "Giorgio", ""]]}, {"id": "1905.12712", "submitter": "Benson Chen", "authors": "Benson Chen, Regina Barzilay, Tommi Jaakkola", "title": "Path-Augmented Graph Transformer Network", "comments": "Appears in ICML LRG Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the recent work on learning molecular representations has been based\non Graph Convolution Networks (GCN). These models rely on local aggregation\noperations and can therefore miss higher-order graph properties. To remedy\nthis, we propose Path-Augmented Graph Transformer Networks (PAGTN) that are\nexplicitly built on longer-range dependencies in graph-structured data.\nSpecifically, we use path features in molecular graphs to create global\nattention layers. We compare our PAGTN model against the GCN model and show\nthat our model consistently outperforms GCNs on molecular property prediction\ndatasets including quantum chemistry (QM7, QM8, QM9), physical chemistry (ESOL,\nLipophilictiy) and biochemistry (BACE, BBBP).\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:39:39 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Chen", "Benson", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1905.12717", "submitter": "Shay Moran", "authors": "Akshay Balsubramani, Sanjoy Dasgupta, Yoav Freund, Shay Moran", "title": "An adaptive nearest neighbor rule for classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the $k$-nearest neighbor classifier in which $k$ is\nchosen adaptively for each query, rather than supplied as a parameter. The\nchoice of $k$ depends on properties of each neighborhood, and therefore may\nsignificantly vary between different points. (For example, the algorithm will\nuse larger $k$ for predicting the labels of points in noisy regions.)\n  We provide theory and experiments that demonstrate that the algorithm\nperforms comparably to, and sometimes better than, $k$-NN with an optimal\nchoice of $k$. In particular, we derive bounds on the convergence rates of our\nclassifier that depend on a local quantity we call the `advantage' which is\nsignificantly weaker than the Lipschitz conditions used in previous convergence\nrate proofs. These generalization bounds hinge on a variant of the seminal\nUniform Convergence Theorem due to Vapnik and Chervonenkis; this variant\nconcerns conditional probabilities and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:46:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Balsubramani", "Akshay", ""], ["Dasgupta", "Sanjoy", ""], ["Freund", "Yoav", ""], ["Moran", "Shay", ""]]}, {"id": "1905.12721", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky, Tamas Sarlos", "title": "Matrix-Free Preconditioning in Online Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an online convex optimization algorithm with regret that\ninterpolates between the regret of an algorithm using an optimal\npreconditioning matrix and one using a diagonal preconditioning matrix. Our\nregret bound is never worse than that obtained by diagonal preconditioning, and\nin certain setting even surpasses that of algorithms with full-matrix\npreconditioning. Importantly, our algorithm runs in the same time and space\ncomplexity as online gradient descent. Along the way we incorporate new\ntechniques that mildly streamline and improve logarithmic factors in prior\nregret analyses. We conclude by benchmarking our algorithm on synthetic data\nand deep learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:00:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Sarlos", "Tamas", ""]]}, {"id": "1905.12724", "submitter": "Henry Li", "authors": "Henry Li, Ofir Lindenbaum, Xiuyuan Cheng, Alexander Cloninger", "title": "Variational Diffusion Autoencoders with Random Walk Sampling", "comments": "24 pages, 9 figures, 1 table; accepted to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) and generative adversarial networks (GANs)\nenjoy an intuitive connection to manifold learning: in training the\ndecoder/generator is optimized to approximate a homeomorphism between the data\ndistribution and the sampling space. This is a construction that strives to\ndefine the data manifold. A major obstacle to VAEs and GANs, however, is\nchoosing a suitable prior that matches the data topology. Well-known\nconsequences of poorly picked priors are posterior and mode collapse. To our\nknowledge, no existing method sidesteps this user choice. Conversely,\n$\\textit{diffusion maps}$ automatically infer the data topology and enjoy a\nrigorous connection to manifold learning, but do not scale easily or provide\nthe inverse homeomorphism (i.e. decoder/generator). We propose a method that\ncombines these approaches into a generative model that inherits the asymptotic\nguarantees of $\\textit{diffusion maps}$ while preserving the scalability of\ndeep models. We prove approximation theoretic results for the dimension\ndependence of our proposed method. Finally, we demonstrate the effectiveness of\nour method with various real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:06:09 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 20:29:51 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 00:13:22 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 12:52:00 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Li", "Henry", ""], ["Lindenbaum", "Ofir", ""], ["Cheng", "Xiuyuan", ""], ["Cloninger", "Alexander", ""]]}, {"id": "1905.12726", "submitter": "Marc Brittain", "authors": "Marc Brittain, Josh Bertram, Xuxi Yang, Peng Wei", "title": "Prioritized Sequence Experience Replay", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is widely used in deep reinforcement learning algorithms\nand allows agents to remember and learn from experiences from the past. In an\neffort to learn more efficiently, researchers proposed prioritized experience\nreplay (PER) which samples important transitions more frequently. In this\npaper, we propose Prioritized Sequence Experience Replay (PSER) a framework for\nprioritizing sequences of experience in an attempt to both learn more\nefficiently and to obtain better performance. We compare the performance of PER\nand PSER sampling techniques in a tabular Q-learning environment and in DQN on\nthe Atari 2600 benchmark. We prove theoretically that PSER is guaranteed to\nconverge faster than PER and empirically show PSER substantially improves upon\nPER.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:38:00 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:04:29 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Brittain", "Marc", ""], ["Bertram", "Josh", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "1905.12728", "submitter": "Fernando Mart\\'inez Plumed", "authors": "Fernando Mart\\'inez-Plumed, C\\`esar Ferri, David Nieves, Jos\\'e\n  Hern\\'andez-Orallo", "title": "Fairness and Missing Values", "comments": "Preprint submitted to Decision Support Systems Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causes underlying unfair decision making are complex, being internalised\nin different ways by decision makers, other actors dealing with data and\nmodels, and ultimately by the individuals being affected by these decisions.\nOne frequent manifestation of all these latent causes arises in the form of\nmissing values: protected groups are more reluctant to give information that\ncould be used against them, delicate information for some groups can be erased\nby human operators, or data acquisition may simply be less complete and\nsystematic for minority groups. As a result, missing values and bias in data\nare two phenomena that are tightly coupled. However, most recent techniques,\nlibraries and experimental results dealing with fairness in machine learning\nhave simply ignored missing data. In this paper, we claim that fairness\nresearch should not miss the opportunity to deal properly with missing data. To\nsupport this claim, (1) we analyse the sources of missing data and bias, and we\nmap the common causes, (2) we find that rows containing missing values are\nusually fairer than the rest, which should not be treated as the uncomfortable\nugly data that different techniques and libraries get rid of at the first\noccasion, and (3) we study the trade-off between performance and fairness when\nthe rows with missing values are used (either because the technique deals with\nthem directly or by imputation methods). We end the paper with a series of\nrecommended procedures about what to do with missing data when aiming for fair\ndecision making.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:09:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mart\u00ednez-Plumed", "Fernando", ""], ["Ferri", "C\u00e8sar", ""], ["Nieves", "David", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""]]}, {"id": "1905.12730", "submitter": "Rina Panigrahy", "authors": "Badih Ghazi, Rina Panigrahy, Joshua R. Wang", "title": "Recursive Sketches for Modular Deep Learning", "comments": "Published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanism to compute a sketch (succinct summary) of how a\ncomplex modular deep network processes its inputs. The sketch summarizes\nessential information about the inputs and outputs of the network and can be\nused to quickly identify key components and summary statistics of the inputs.\nFurthermore, the sketch is recursive and can be unrolled to identify\nsub-components of these components and so forth, capturing a potentially\ncomplicated DAG structure. These sketches erase gracefully; even if we erase a\nfraction of the sketch at random, the remainder still retains the `high-weight'\ninformation present in the original sketch. The sketches can also be organized\nin a repository to implicitly form a `knowledge graph'; it is possible to\nquickly retrieve sketches in the repository that are related to a sketch of\ninterest; arranged in this fashion, the sketches can also be used to learn\nemerging concepts by looking for new clusters in sketch space. Finally, in the\nscenario where we want to learn a ground truth deep network, we show that\naugmenting input/output pairs with these sketches can theoretically make it\neasier to do so.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:10:58 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 22:36:23 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ghazi", "Badih", ""], ["Panigrahy", "Rina", ""], ["Wang", "Joshua R.", ""]]}, {"id": "1905.12737", "submitter": "Kashyap Chitta", "authors": "Kashyap Chitta, Jose M. Alvarez, Elmar Haussmann, Clement Farabet", "title": "Training Data Subset Search with Ensemble Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) often rely on very large datasets for training.\nGiven the large size of such datasets, it is conceivable that they contain\ncertain samples that either do not contribute or negatively impact the DNN's\noptimization. Modifying the training distribution in a way that excludes such\nsamples could provide an effective solution to both improve performance and\nreduce training time. In this paper, we propose to scale up ensemble Active\nLearning (AL) methods to perform acquisition at a large scale (10k to 500k\nsamples at a time). We do this with ensembles of hundreds of models, obtained\nat a minimal computational cost by reusing intermediate training checkpoints.\nThis allows us to automatically and efficiently perform a training data subset\nsearch for large labeled datasets. We observe that our approach obtains\nfavorable subsets of training data, which can be used to train more accurate\nDNNs than training with the entire dataset. We perform an extensive\nexperimental study of this phenomenon on three image classification benchmarks\n(CIFAR-10, CIFAR-100 and ImageNet), as well as an internal object detection\nbenchmark for prototyping perception models for autonomous driving. Unlike\nexisting studies, our experiments on object detection are at the scale required\nfor production-ready autonomous driving systems. We provide insights on the\nimpact of different initialization schemes, acquisition functions and ensemble\nconfigurations at this scale. Our results provide strong empirical evidence\nthat optimizing the training data distribution can provide significant benefits\non large scale vision tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:23:23 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:50:18 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 14:21:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chitta", "Kashyap", ""], ["Alvarez", "Jose M.", ""], ["Haussmann", "Elmar", ""], ["Farabet", "Clement", ""]]}, {"id": "1905.12741", "submitter": "Victor Veitch", "authors": "Victor Veitch and Dhanya Sridhar and David M. Blei", "title": "Adapting Text Embeddings for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does adding a theorem to a paper affect its chance of acceptance? Does\nlabeling a post with the author's gender affect the post popularity? This paper\ndevelops a method to estimate such causal effects from observational text data,\nadjusting for confounding features of the text such as the subject or writing\nquality. We assume that the text suffices for causal adjustment but that, in\npractice, it is prohibitively high-dimensional. To address this challenge, we\ndevelop causally sufficient embeddings, low-dimensional document\nrepresentations that preserve sufficient information for causal identification\nand allow for efficient estimation of causal effects. Causally sufficient\nembeddings combine two ideas. The first is supervised dimensionality reduction:\ncausal adjustment requires only the aspects of text that are predictive of both\nthe treatment and outcome. The second is efficient language modeling:\nrepresentations of text are designed to dispose of linguistically irrelevant\ninformation, and this information is also causally irrelevant. Our method\nadapts language models (specifically, word embeddings and topic models) to\nlearn document embeddings that are able to predict both treatment and outcome.\nWe study causally sufficient embeddings with semi-synthetic datasets and find\nthat they improve causal estimation over related embedding methods. We\nillustrate the methods by answering the two motivating questions---the effect\nof a theorem on paper acceptance and the effect of a gender label on post\npopularity. Code and data available at\nhttps://github.com/vveitch/causal-text-embeddings-tf2}{github.com/vveitch/causal-text-embeddings-tf2\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:29:37 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 21:00:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Veitch", "Victor", ""], ["Sridhar", "Dhanya", ""], ["Blei", "David M.", ""]]}, {"id": "1905.12752", "submitter": "Aurko Roy", "authors": "Aurko Roy and David Grangier", "title": "Unsupervised Paraphrasing without Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrasing exemplifies the ability to abstract semantic content from\nsurface forms. Recent work on automatic paraphrasing is dominated by methods\nleveraging Machine Translation (MT) as an intermediate step. This contrasts\nwith humans, who can paraphrase without being bilingual. This work proposes to\nlearn paraphrasing models from an unlabeled monolingual corpus only. To that\nend, we propose a residual variant of vector-quantized variational\nauto-encoder.\n  We compare with MT-based approaches on paraphrase identification, generation,\nand training augmentation. Monolingual paraphrasing outperforms unsupervised\ntranslation in all settings. Comparisons with supervised translation are more\nmixed: monolingual paraphrasing is interesting for identification and\naugmentation; supervised translation is superior for generation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:15:38 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Roy", "Aurko", ""], ["Grangier", "David", ""]]}, {"id": "1905.12753", "submitter": "Alessandro Epasto", "authors": "Sara Ahmadian, Alessandro Epasto, Ravi Kumar, Mohammad Mahdian", "title": "Clustering without Over-Representation", "comments": "10 pages, 6 figures, in KDD 2019", "journal-ref": "in Proceedings of The 25th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining, KDD 2019", "doi": "10.1145/3292500.3330987", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider clustering problems in which each point is endowed\nwith a color. The goal is to cluster the points to minimize the classical\nclustering cost but with the additional constraint that no color is\nover-represented in any cluster. This problem is motivated by practical\nclustering settings, e.g., in clustering news articles where the color of an\narticle is its source, it is preferable that no single news source dominates\nany cluster.\n  For the most general version of this problem, we obtain an algorithm that has\nprovable guarantees of performance; our algorithm is based on finding a\nfractional solution using a linear program and rounding the solution\nsubsequently. For the special case of the problem where no color has an\nabsolute majority in any cluster, we obtain a simpler combinatorial algorithm\nalso with provable guarantees. Experiments on real-world data shows that our\nalgorithms are effective in finding good clustering without\nover-representation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:21:47 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ahmadian", "Sara", ""], ["Epasto", "Alessandro", ""], ["Kumar", "Ravi", ""], ["Mahdian", "Mohammad", ""]]}, {"id": "1905.12760", "submitter": "Miko{\\l}aj Bi\\'nkowski", "authors": "Miko{\\l}aj Bi\\'nkowski, R Devon Hjelm and Aaron Courville", "title": "Batch weight for domain adaptation with mass shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain transfer is the task of transferring or translating\nsamples from a source distribution to a different target distribution. Current\nsolutions unsupervised domain transfer often operate on data on which the modes\nof the distribution are well-matched, for instance have the same frequencies of\nclasses between source and target distributions. However, these models do not\nperform well when the modes are not well-matched, as would be the case when\nsamples are drawn independently from two different, but related, domains. This\nmode imbalance is problematic as generative adversarial networks (GANs), a\nsuccessful approach in this setting, are sensitive to mode frequency, which\nresults in a mismatch of semantics between source samples and generated samples\nof the target distribution. We propose a principled method of re-weighting\ntraining samples to correct for such mass shift between the transferred\ndistributions, which we call batch-weight. We also provide rigorous\nprobabilistic setting for domain transfer and new simplified objective for\ntraining transfer networks, an alternative to complex, multi-component loss\nfunctions used in the current state-of-the art image-to-image translation\nmodels. The new objective stems from the discrimination of joint distributions\nand enforces cycle-consistency in an abstract, high-level, rather than\npixel-wise, sense. Lastly, we experimentally show the effectiveness of the\nproposed methods in several image-to-image translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:43:29 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bi\u0144kowski", "Miko\u0142aj", ""], ["Hjelm", "R Devon", ""], ["Courville", "Aaron", ""]]}, {"id": "1905.12762", "submitter": "Adnan Qayyum", "authors": "Adnan Qayyum, Muhammad Usama, Junaid Qadir, and Ala Al-Fuqaha", "title": "Securing Connected & Autonomous Vehicles: Challenges Posed by\n  Adversarial Machine Learning and The Way Forward", "comments": null, "journal-ref": "IEEE Communications Surveys and Tutorials 2020", "doi": "10.1109/COMST.2020.2975048", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and autonomous vehicles (CAVs) will form the backbone of future\nnext-generation intelligent transportation systems (ITS) providing travel\ncomfort, road safety, along with a number of value-added services. Such a\ntransformation---which will be fuelled by concomitant advances in technologies\nfor machine learning (ML) and wireless communications---will enable a future\nvehicular ecosystem that is better featured and more efficient. However, there\nare lurking security problems related to the use of ML in such a critical\nsetting where an incorrect ML decision may not only be a nuisance but can lead\nto loss of precious lives. In this paper, we present an in-depth overview of\nthe various challenges associated with the application of ML in vehicular\nnetworks. In addition, we formulate the ML pipeline of CAVs and present various\npotential security issues associated with the adoption of ML methods. In\nparticular, we focus on the perspective of adversarial ML attacks on CAVs and\noutline a solution to defend against adversarial attacks in multiple settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:44:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Qayyum", "Adnan", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1905.12766", "submitter": "Lifan Liang", "authors": "Lifan Liang, Songjian Lu", "title": "Noisy and Incomplete Boolean Matrix Factorizationvia Expectation\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic approach to Boolean matrix factorization can provide solutions\nrobustagainst noise and missing values with linear computational complexity.\nHowever,the assumption about latent factors can be problematic in real world\napplications.This study proposed a new probabilistic algorithm free of\nassumptions of latentfactors, while retaining the advantages of previous\nalgorithms. Real data experimentshowed that our algorithm was favourably\ncompared with current state-of-the-artprobabilistic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:54:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liang", "Lifan", ""], ["Lu", "Songjian", ""]]}, {"id": "1905.12767", "submitter": "Eugene Ie", "authors": "Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui\n  Wu, Heng-Tze Cheng, Morgane Lustman, Vince Gatto, Paul Covington, Jim\n  McFadden, Tushar Chandra, Craig Boutilier", "title": "Reinforcement Learning for Slate-based Recommender Systems: A Tractable\n  Decomposition and Practical Methodology", "comments": "Short version to appear IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most practical recommender systems focus on estimating immediate user\nengagement without considering the long-term effects of recommendations on user\nbehavior. Reinforcement learning (RL) methods offer the potential to optimize\nrecommendations for long-term user engagement. However, since users are often\npresented with slates of multiple items - which may have interacting effects on\nuser choice - methods are required to deal with the combinatorics of the RL\naction space. In this work, we address the challenge of making slate-based\nrecommendations to optimize long-term value using RL. Our contributions are\nthree-fold. (i) We develop SLATEQ, a decomposition of value-based\ntemporal-difference and Q-learning that renders RL tractable with slates. Under\nmild assumptions on user choice behavior, we show that the long-term value\n(LTV) of a slate can be decomposed into a tractable function of its component\nitem-wise LTVs. (ii) We outline a methodology that leverages existing myopic\nlearning-based recommenders to quickly develop a recommender that handles LTV.\n(iii) We demonstrate our methods in simulation, and validate the scalability of\ndecomposed TD-learning using SLATEQ in live experiments on YouTube.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:55:28 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 07:27:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ie", "Eugene", ""], ["Jain", "Vihan", ""], ["Wang", "Jing", ""], ["Narvekar", "Sanmit", ""], ["Agarwal", "Ritesh", ""], ["Wu", "Rui", ""], ["Cheng", "Heng-Tze", ""], ["Lustman", "Morgane", ""], ["Gatto", "Vince", ""], ["Covington", "Paul", ""], ["McFadden", "Jim", ""], ["Chandra", "Tushar", ""], ["Boutilier", "Craig", ""]]}, {"id": "1905.12774", "submitter": "Sasi Kumar Murakonda", "authors": "Sasi Kumar Murakonda, Reza Shokri, George Theodorakopoulos", "title": "Quantifying the Privacy Risks of Learning High-Dimensional Graphical\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models leak information about their training data. This enables attackers to\ninfer sensitive information about their training sets, notably determine if a\ndata sample was part of the model's training set. The existing works\nempirically show the possibility of these membership inference (tracing)\nattacks against complex deep learning models. However, the attack results are\ndependent on the specific training data, can be obtained only after the tedious\nprocess of training the model and performing the attack, and are missing any\nmeasure of the confidence and unused potential power of the attack.\n  In this paper, we theoretically analyze the maximum power of tracing attacks\nagainst high-dimensional graphical models, with the focus on Bayesian networks.\nWe provide a tight upper bound on the power (true positive rate) of these\nattacks, with respect to their error (false positive rate), for a given model\nstructure even before learning its parameters. As it should be, the bound is\nindependent of the knowledge and algorithm of any specific attack. It can help\nin identifying which model structures leak more information, how adding new\nparameters to the model increases its privacy risk, and what can be gained by\nadding new data points to decrease the overall information leakage. It provides\na measure of the potential leakage of a model given its structure, as a\nfunction of the model complexity and the size of the training set.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:14:45 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:03:34 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 05:51:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Murakonda", "Sasi Kumar", ""], ["Shokri", "Reza", ""], ["Theodorakopoulos", "George", ""]]}, {"id": "1905.12775", "submitter": "Ragav Venkatesan", "authors": "Xiang Xu, Xiong Zhou, Ragav Venkatesan, Gurumurthy Swaminathan and\n  Orchid Majumder", "title": "$d$-SNE: Domain Adaptation using Stochastic Neighborhood Embedding", "comments": "Accepted as Oral at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often require copious amount of labeled-data to train\ntheir scads of parameters. Training larger and deeper networks is hard without\nappropriate regularization, particularly while using a small dataset.\nLaterally, collecting well-annotated data is expensive, time-consuming and\noften infeasible. A popular way to regularize these networks is to simply train\nthe network with more data from an alternate representative dataset. This can\nlead to adverse effects if the statistics of the representative dataset are\ndissimilar to our target. This predicament is due to the problem of domain\nshift. Data from a shifted domain might not produce bespoke features when a\nfeature extractor from the representative domain is used. In this paper, we\npropose a new technique ($d$-SNE) of domain adaptation that cleverly uses\nstochastic neighborhood embedding techniques and a novel modified-Hausdorff\ndistance. The proposed technique is learnable end-to-end and is therefore,\nideally suited to train neural networks. Extensive experiments demonstrate that\n$d$-SNE outperforms the current states-of-the-art and is robust to the\nvariances in different datasets, even in the one-shot and semi-supervised\nlearning settings. $d$-SNE also demonstrates the ability to generalize to\nmultiple domains concurrently.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:16:51 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Xu", "Xiang", ""], ["Zhou", "Xiong", ""], ["Venkatesan", "Ragav", ""], ["Swaminathan", "Gurumurthy", ""], ["Majumder", "Orchid", ""]]}, {"id": "1905.12776", "submitter": "Gautam Goel", "authors": "Gautam Goel, Yiheng Lin, Haoyuan Sun, Adam Wierman", "title": "Beyond Online Balanced Descent: An Optimal Algorithm for Smoothed Online\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online convex optimization in a setting where the learner seeks to\nminimize the sum of a per-round hitting cost and a movement cost which is\nincurred when changing decisions between rounds. We prove a new lower bound on\nthe competitive ratio of any online algorithm in the setting where the costs\nare $m$-strongly convex and the movement costs are the squared $\\ell_2$ norm.\nThis lower bound shows that no algorithm can achieve a competitive ratio that\nis $o(m^{-1/2})$ as $m$ tends to zero. No existing algorithms have competitive\nratios matching this bound, and we show that the state-of-the-art algorithm,\nOnline Balanced Decent (OBD), has a competitive ratio that is\n$\\Omega(m^{-2/3})$. We additionally propose two new algorithms, Greedy OBD\n(G-OBD) and Regularized OBD (R-OBD) and prove that both algorithms have an\n$O(m^{-1/2})$ competitive ratio. The result for G-OBD holds when the hitting\ncosts are quasiconvex and the movement costs are the squared $\\ell_2$ norm,\nwhile the result for R-OBD holds when the hitting costs are $m$-strongly convex\nand the movement costs are Bregman Divergences. Further, we show that R-OBD\nsimultaneously achieves constant, dimension-free competitive ratio and\nsublinear regret when hitting costs are strongly convex.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:21:09 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 04:29:42 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 22:30:58 GMT"}, {"version": "v4", "created": "Mon, 21 Oct 2019 18:53:25 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Goel", "Gautam", ""], ["Lin", "Yiheng", ""], ["Sun", "Haoyuan", ""], ["Wierman", "Adam", ""]]}, {"id": "1905.12777", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Jonas Mueller, Regina Barzilay, Tommi Jaakkola", "title": "Educating Text Autoencoders: Latent Representation Guidance via\n  Denoising", "comments": "ICML 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative autoencoders offer a promising approach for controllable text\ngeneration by leveraging their latent sentence representations. However,\ncurrent models struggle to maintain coherent latent spaces required to perform\nmeaningful text manipulations via latent vector operations. Specifically, we\ndemonstrate by example that neural encoders do not necessarily map similar\nsentences to nearby latent vectors. A theoretical explanation for this\nphenomenon establishes that high capacity autoencoders can learn an arbitrary\nmapping between sequences and associated latent representations. To remedy this\nissue, we augment adversarial autoencoders with a denoising objective where\noriginal sentences are reconstructed from perturbed versions (referred to as\nDAAE). We prove that this simple modification guides the latent space geometry\nof the resulting model by encouraging the encoder to map similar texts to\nsimilar latent representations. In empirical comparisons with various types of\nautoencoders, our model provides the best trade-off between generation quality\nand reconstruction capacity. Moreover, the improved geometry of the DAAE latent\nspace enables zero-shot text style transfer via simple latent vector\narithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:22:56 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 04:33:41 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 17:51:30 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Shen", "Tianxiao", ""], ["Mueller", "Jonas", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1905.12781", "submitter": "Utkarsh Upadhyay", "authors": "Utkarsh Upadhyay, Robert Busa-Fekete, Wojciech Kotlowski, David Pal,\n  Balazs Szorenyi", "title": "Learning to Crawl", "comments": "Published at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web crawling is the problem of keeping a cache of webpages fresh, i.e.,\nhaving the most recent copy available when a page is requested. This problem is\nusually coupled with the natural restriction that the bandwidth available to\nthe web crawler is limited. The corresponding optimization problem was solved\noptimally by Azar et al. [2018] under the assumption that, for each webpage,\nboth the elapsed time between two changes and the elapsed time between two\nrequests follow a Poisson distribution with known parameters. In this paper, we\nstudy the same control problem but under the assumption that the change rates\nare unknown a priori, and thus we need to estimate them in an online fashion\nusing only partial observations (i.e., single-bit signals indicating whether\nthe page has changed since the last refresh). As a point of departure, we\ncharacterise the conditions under which one can solve the problem with such\npartial observability. Next, we propose a practical estimator and compute\nconfidence intervals for it in terms of the elapsed time between the\nobservations. Finally, we show that the explore-and-commit algorithm achieves\nan $\\mathcal{O}(\\sqrt{T})$ regret with a carefully chosen exploration horizon.\nOur simulation study shows that our online policy scales well and achieves\nclose to optimal performance for a wide range of the parameters.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:33:26 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:46:48 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Upadhyay", "Utkarsh", ""], ["Busa-Fekete", "Robert", ""], ["Kotlowski", "Wojciech", ""], ["Pal", "David", ""], ["Szorenyi", "Balazs", ""]]}, {"id": "1905.12782", "submitter": "Mina Karzand", "authors": "Mina Karzand, and Robert D. Nowak", "title": "MaxiMin Active Learning in Overparameterized Model Classes}", "comments": "43 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating labeled training datasets has become a major bottleneck in Machine\nLearning (ML) pipelines. Active ML aims to address this issue by designing\nlearning algorithms that automatically and adaptively select the most\ninformative examples for labeling so that human time is not wasted labeling\nirrelevant, redundant, or trivial examples. This paper proposes a new approach\nto active ML with nonparametric or overparameterized models such as kernel\nmethods and neural networks. In the context of binary classification, the new\napproach is shown to possess a variety of desirable properties that allow\nactive learning algorithms to automatically and efficiently identify decision\nboundaries and data clusters.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:34:44 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 04:18:40 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Karzand", "Mina", ""], ["Nowak", "Robert D.", ""]]}, {"id": "1905.12784", "submitter": "Alessio Ansuini PhD", "authors": "Alessio Ansuini, Alessandro Laio, Jakob H. Macke and Davide Zoccolan", "title": "Intrinsic dimension of data representations in deep neural networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks progressively transform their inputs across multiple\nprocessing layers. What are the geometrical properties of the representations\nlearned by these networks? Here we study the intrinsic dimensionality (ID) of\ndata-representations, i.e. the minimal number of parameters needed to describe\na representation. We find that, in a trained network, the ID is orders of\nmagnitude smaller than the number of units in each layer. Across layers, the ID\nfirst increases and then progressively decreases in the final layers.\nRemarkably, the ID of the last hidden layer predicts classification accuracy on\nthe test set. These results can neither be found by linear dimensionality\nestimates (e.g., with principal component analysis), nor in representations\nthat had been artificially linearized. They are neither found in untrained\nnetworks, nor in networks that are trained on randomized labels. This suggests\nthat neural networks that can generalize are those that transform the data into\nlow-dimensional, but not necessarily flat manifolds.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:36:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 11:19:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ansuini", "Alessio", ""], ["Laio", "Alessandro", ""], ["Macke", "Jakob H.", ""], ["Zoccolan", "Davide", ""]]}, {"id": "1905.12786", "submitter": "Anjishnu Kumar", "authors": "Daniele Bonadiman, Anjishnu Kumar and Arpit Mittal", "title": "Large Scale Question Paraphrase Retrieval with Smoothed Deep Metric\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a Question Paraphrase Retrieval (QPR) system is to retrieve\nequivalent questions that result in the same answer as the original question.\nSuch a system can be used to understand and answer rare and noisy\nreformulations of common questions by mapping them to a set of canonical forms.\nThis has large-scale applications for community Question Answering (cQA) and\nopen-domain spoken language question answering systems. In this paper we\ndescribe a new QPR system implemented as a Neural Information Retrieval (NIR)\nsystem consisting of a neural network sentence encoder and an approximate\nk-Nearest Neighbour index for efficient vector retrieval. We also describe our\nmechanism to generate an annotated dataset for question paraphrase retrieval\nexperiments automatically from question-answer logs via distant supervision. We\nshow that the standard loss function in NIR, triplet loss, does not perform\nwell with noisy labels. We propose smoothed deep metric loss (SDML) and with\nour experiments on two QPR datasets we show that it significantly outperforms\ntriplet loss in the noisy label setting.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:40:54 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bonadiman", "Daniele", ""], ["Kumar", "Anjishnu", ""], ["Mittal", "Arpit", ""]]}, {"id": "1905.12787", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Mark Crowley", "title": "The Theory Behind Overfitting, Cross Validation, Regularization,\n  Bagging, and Boosting: Tutorial", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial paper, we first define mean squared error, variance,\ncovariance, and bias of both random variables and classification/predictor\nmodels. Then, we formulate the true and generalization errors of the model for\nboth training and validation/test instances where we make use of the Stein's\nUnbiased Risk Estimator (SURE). We define overfitting, underfitting, and\ngeneralization using the obtained true and generalization errors. We introduce\ncross validation and two well-known examples which are $K$-fold and\nleave-one-out cross validations. We briefly introduce generalized cross\nvalidation and then move on to regularization where we use the SURE again. We\nwork on both $\\ell_2$ and $\\ell_1$ norm regularizations. Then, we show that\nbootstrap aggregating (bagging) reduces the variance of estimation. Boosting,\nspecifically AdaBoost, is introduced and it is explained as both an additive\nmodel and a maximum margin model, i.e., Support Vector Machine (SVM). The upper\nbound on the generalization error of boosting is also provided to show why\nboosting prevents from overfitting. As examples of regularization, the theory\nof ridge and lasso regressions, weight decay, noise injection to input/weights,\nand early stopping are explained. Random forest, dropout, histogram of oriented\ngradients, and single shot multi-box detector are explained as examples of\nbagging in machine learning and computer vision. Finally, boosting tree and SVM\nmodels are mentioned as examples of boosting.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 08:18:09 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Crowley", "Mark", ""]]}, {"id": "1905.12790", "submitter": "Elman Mansimov", "authors": "Elman Mansimov, Alex Wang, Sean Welleck, Kyunghyun Cho", "title": "A Generalized Framework of Sequence Generation with Application to\n  Undirected Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected neural sequence models such as BERT (Devlin et al., 2019) have\nreceived renewed interest due to their success on discriminative natural\nlanguage understanding tasks such as question-answering and natural language\ninference. The problem of generating sequences directly from these models has\nreceived relatively little attention, in part because generating from\nundirected models departs significantly from conventional monotonic generation\nin directed sequence models. We investigate this problem by proposing a\ngeneralized model of sequence generation that unifies decoding in directed and\nundirected models. The proposed framework models the process of generation\nrather than the resulting sequence, and under this framework, we derive various\nneural sequence models as special cases, such as autoregressive,\nsemi-autoregressive, and refinement-based non-autoregressive models. This\nunification enables us to adapt decoding algorithms originally developed for\ndirected sequence models to undirected sequence models. We demonstrate this by\nevaluating various handcrafted and learned decoding strategies on a BERT-like\nmachine translation model (Lample & Conneau, 2019). The proposed approach\nachieves constant-time translation results on par with linear-time translation\nresults from the same undirected sequence model, while both are competitive\nwith the state-of-the-art on WMT'14 English-German translation.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:47:17 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 13:18:42 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Mansimov", "Elman", ""], ["Wang", "Alex", ""], ["Welleck", "Sean", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1905.12791", "submitter": "Songbai Yan", "authors": "Songbai Yan, Kamalika Chaudhuri and Tara Javidi", "title": "The Label Complexity of Active Learning from Observational Data", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning from observational data involves learning a\nclassifier on an entire population based on data that is observed conditioned\non a selection policy. This work considers this problem in an active setting,\nwhere the learner additionally has access to unlabeled examples and can choose\nto get a subset of these labeled by an oracle.\n  Prior work on this problem uses disagreement-based active learning, along\nwith an importance weighted loss estimator to account for counterfactuals,\nwhich leads to a high label complexity. We show how to instead incorporate a\nmore efficient counterfactual risk minimizer into the active learning\nalgorithm. This requires us to modify both the counterfactual risk to make it\namenable to active learning, as well as the active learning process to make it\namenable to the risk. We provably demonstrate that the result of this is an\nalgorithm which is statistically consistent as well as more label-efficient\nthan prior work.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:48:16 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 03:03:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yan", "Songbai", ""], ["Chaudhuri", "Kamalika", ""], ["Javidi", "Tara", ""]]}, {"id": "1905.12793", "submitter": "Yixin Wang", "authors": "Yixin Wang, David M. Blei", "title": "Multiple Causes: A Causal Graphical View", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unobserved confounding is a major hurdle for causal inference from\nobservational data. Confounders---the variables that affect both the causes and\nthe outcome---induce spurious non-causal correlations between the two. Wang &\nBlei (2018) lower this hurdle with \"the blessings of multiple causes,\" where\nthe correlation structure of multiple causes provides indirect evidence for\nunobserved confounding. They leverage these blessings with an algorithm, called\nthe deconfounder, that uses probabilistic factor models to correct for the\nconfounders. In this paper, we take a causal graphical view of the\ndeconfounder. In a graph that encodes shared confounding, we show how the\nmultiplicity of causes can help identify intervention distributions. We then\njustify the deconfounder, showing that it makes valid inferences of the\nintervention. Finally, we expand the class of graphs, and its theory, to those\nthat include other confounders and selection variables. Our results expand the\ntheory in Wang & Blei (2018), justify the deconfounder for causal graphs, and\nextend the settings where it can be used.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:03:30 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1905.12797", "submitter": "Yuping Lin", "authors": "Yuping Lin, Kasra Ahmadi K. A., Hui Jiang", "title": "Bandlimiting Neural Networks Against Adversarial Attacks", "comments": "Summitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the adversarial attack and defence problem in deep\nlearning from the perspective of Fourier analysis. We first explicitly compute\nthe Fourier transform of deep ReLU neural networks and show that there exist\ndecaying but non-zero high frequency components in the Fourier spectrum of\nneural networks. We demonstrate that the vulnerability of neural networks\ntowards adversarial samples can be attributed to these insignificant but\nnon-zero high frequency components. Based on this analysis, we propose to use a\nsimple post-averaging technique to smooth out these high frequency components\nto improve the robustness of neural networks against adversarial attacks.\nExperimental results on the ImageNet dataset have shown that our proposed\nmethod is universally effective to defend many existing adversarial attacking\nmethods proposed in the literature, including FGSM, PGD, DeepFool and C&W\nattacks. Our post-averaging method is simple since it does not require any\nre-training, and meanwhile it can successfully defend over 95% of the\nadversarial samples generated by these methods without introducing any\nsignificant performance degradation (less than 1%) on the original clean\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:34:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lin", "Yuping", ""], ["A.", "Kasra Ahmadi K.", ""], ["Jiang", "Hui", ""]]}, {"id": "1905.12799", "submitter": "Byung Hoon Ahn", "authors": "Byung Hoon Ahn, Prannoy Pilligundla, Hadi Esmaeilzadeh", "title": "Reinforcement Learning and Adaptive Sampling for Optimized DNN\n  Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving faster execution with shorter compilation time can enable further\ndiversity and innovation in neural networks. However, the current paradigm of\nexecuting neural networks either relies on hand-optimized libraries,\ntraditional compilation heuristics, or very recently, simulated annealing and\ngenetic algorithms. Our work takes a unique approach by formulating compiler\noptimizations for neural networks as a reinforcement learning problem, whose\nsolution takes fewer steps to converge. This solution, dubbed ReLeASE, comes\nwith a sampling algorithm that leverages clustering to focus the costly samples\n(real hardware measurements) on representative points, subsuming an entire\nsubspace. Our adaptive sampling not only reduces the number of samples, but\nalso improves the quality of samples for better exploration in shorter time. As\nsuch, experimentation with real hardware shows that reinforcement learning with\nadaptive sampling provides 4.45x speed up in optimization time over AutoTVM,\nwhile also improving inference time of the modern deep networks by 5.6%.\nFurther experiments also confirm that our adaptive sampling can even improve\nAutoTVM's simulated annealing by 4.00x.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:37:26 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ahn", "Byung Hoon", ""], ["Pilligundla", "Prannoy", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1905.12804", "submitter": "Angelo Mendes", "authors": "Angelo C. Mendes da Silva and Mauricio A. Nunes and Raul Fonseca Neto", "title": "A Music Classification Model based on Metric Learning and Feature\n  Extraction from MP3 Audio Files", "comments": "In a review process, I found some errors and made some changes in\n  methodology that improved my results. Once I finish the experiments, I will\n  upload the new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of models for learning music similarity and feature\nextraction from audio media files is an increasingly important task for the\nentertainment industry. This work proposes a novel music classification model\nbased on metric learning and feature extraction from MP3 audio files. The\nmetric learning process considers the learning of a set of parameterized\ndistances employing a structured prediction approach from a set of MP3 audio\nfiles containing several music genres. The main objective of this work is to\nmake possible learning a personalized metric for each customer. To extract the\nacoustic information we use the Mel-Frequency Cepstral Coefficient (MFCC) and\nmake a dimensionality reduction with the use of Principal Components Analysis.\nWe attest the model validity performing a set of experiments and comparing the\ntraining and testing results with baseline algorithms, such as K-means and Soft\nMargin Linear Support Vector Machine (SVM). Experiments show promising results\nand encourage the future development of an online version of the learning\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:52:57 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 22:29:02 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["da Silva", "Angelo C. Mendes", ""], ["Nunes", "Mauricio A.", ""], ["Neto", "Raul Fonseca", ""]]}, {"id": "1905.12806", "submitter": "Philipp Seeb\\\"ock", "authors": "Philipp Seeb\\\"ock, Jos\\'e Ignacio Orlando, Thomas Schlegl, Sebastian\n  M. Waldstein, Hrvoje Bogunovi\\'c, Sophie Klimscha, Georg Langs, Ursula\n  Schmidt-Erfurth", "title": "Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly\n  Detection in Retinal OCT", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging,\n  2019", "journal-ref": null, "doi": "10.1109/TMI.2019.2919951", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis and treatment guidance are aided by detecting relevant biomarkers\nin medical images. Although supervised deep learning can perform accurate\nsegmentation of pathological areas, it is limited by requiring a-priori\ndefinitions of these regions, large-scale annotations, and a representative\npatient cohort in the training set. In contrast, anomaly detection is not\nlimited to specific definitions of pathologies and allows for training on\nhealthy samples without annotation. Anomalous regions can then serve as\ncandidates for biomarker discovery. Knowledge about normal anatomical structure\nbrings implicit information for detecting anomalies. We propose to take\nadvantage of this property using bayesian deep learning, based on the\nassumption that epistemic uncertainties will correlate with anatomical\ndeviations from a normal training set. A Bayesian U-Net is trained on a\nwell-defined healthy environment using weak labels of healthy anatomy produced\nby existing methods. At test time, we capture epistemic uncertainty estimates\nof our model using Monte Carlo dropout. A novel post-processing technique is\nthen applied to exploit these estimates and transfer their layered appearance\nto smooth blob-shaped segmentations of the anomalies. We experimentally\nvalidated this approach in retinal optical coherence tomography (OCT) images,\nusing weak labels of retinal layers. Our method achieved a Dice index of 0.789\nin an independent anomaly test set of age-related macular degeneration (AMD)\ncases. The resulting segmentations allowed very high accuracy for separating\nhealthy and diseased cases with late wet AMD, dry geographic atrophy (GA),\ndiabetic macular edema (DME) and retinal vein occlusion (RVO). Finally, we\nqualitatively observed that our approach can also detect other deviations in\nnormal scans such as cut edge artifacts.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:39:42 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Seeb\u00f6ck", "Philipp", ""], ["Orlando", "Jos\u00e9 Ignacio", ""], ["Schlegl", "Thomas", ""], ["Waldstein", "Sebastian M.", ""], ["Bogunovi\u0107", "Hrvoje", ""], ["Klimscha", "Sophie", ""], ["Langs", "Georg", ""], ["Schmidt-Erfurth", "Ursula", ""]]}, {"id": "1905.12807", "submitter": "Ari Kobren", "authors": "Ari Kobren, Pablo Barrio, Oksana Yakhnenko, Johann Hibschman, Ian\n  Langmore", "title": "Constructing High Precision Knowledge Bases with Subjective and Factual\n  Attributes", "comments": "Appears at KDD 2019 Applied Data Science Track, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge bases (KBs) are the backbone of many ubiquitous applications and\nare thus required to exhibit high precision. However, for KBs that store\nsubjective attributes of entities, e.g., whether a movie is \"kid friendly\",\nsimply estimating precision is complicated by the inherent ambiguity in\nmeasuring subjective phenomena. In this work, we develop a method for\nconstructing KBs with tunable precision--i.e., KBs that can be made to operate\nat a specific false positive rate, despite storing both difficult-to-evaluate\nsubjective attributes and more traditional factual attributes. The key to our\napproach is probabilistically modeling user consensus with respect to each\nentity-attribute pair, rather than modeling each pair as either True or False.\nUncertainty in the model is explicitly represented and used to control the KB's\nprecision. We propose three neural networks for fitting the consensus model and\nevaluate each one on data from Google Maps--a large KB of locations and their\nsubjective and factual attributes. The results demonstrate that our learned\nmodels are well-calibrated and thus can successfully be used to control the\nKB's precision. Moreover, when constrained to maintain 95% precision, the best\nconsensus model matches the F-score of a baseline that models each\nentity-attribute pair as a binary variable and does not support tunable\nprecision. When unconstrained, our model dominates the same baseline by 12%\nF-score. Finally, we perform an empirical analysis of attribute-attribute\ncorrelations and show that leveraging them effectively contributes to reduced\nuncertainty and better performance in attribute prediction.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:43:23 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 23:45:18 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 13:21:06 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kobren", "Ari", ""], ["Barrio", "Pablo", ""], ["Yakhnenko", "Oksana", ""], ["Hibschman", "Johann", ""], ["Langmore", "Ian", ""]]}, {"id": "1905.12813", "submitter": "Amrita Roy Chowdhury", "authors": "Amrita Roy Chowdhury, Theodoros Rekatsinas, Somesh Jha", "title": "Data-Dependent Differentially Private Parameter Learning for Directed\n  Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphical models (DGMs) are a class of probabilistic models that are\nwidely used for predictive analysis in sensitive domains, such as medical\ndiagnostics. In this paper we present an algorithm for differentially private\nlearning of the parameters of a DGM with a publicly known graph structure over\nfully observed data. Our solution optimizes for the utility of inference\nqueries over the DGM and \\textit{adds noise that is customized to the\nproperties of the private input dataset and the graph structure of the DGM}. To\nthe best of our knowledge, this is the first explicit data-dependent privacy\nbudget allocation algorithm for DGMs. We compare our algorithm with a standard\ndata-independent approach over a diverse suite of DGM benchmarks and\ndemonstrate that our solution requires a privacy budget that is $3\\times$\nsmaller to obtain the same or higher utility.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 01:26:38 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:24:17 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 18:24:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chowdhury", "Amrita Roy", ""], ["Rekatsinas", "Theodoros", ""], ["Jha", "Somesh", ""]]}, {"id": "1905.12827", "submitter": "Huitong Ding", "authors": "Ning An, Huitong Ding, Jiaoyun Yang, Rhoda Au, Ting Fang Alvin Ang", "title": "Deep ensemble learning for Alzheimers disease classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning use multiple algorithms to obtain better predictive\nperformance than any single one of its constituent algorithms could. With\ngrowing popularity of deep learning, researchers have started to ensemble them\nfor various purposes. Few if any, however, has used the deep learning approach\nas a means to ensemble algorithms. This paper presents a deep ensemble learning\nframework which aims to harness deep learning algorithms to integrate\nmultisource data and tap the wisdom of experts. At the voting layer, a sparse\nautoencoder is trained for feature learning to reduce the correlation of\nattributes and diversify the base classifiers ultimately. At the stacking\nlayer, a nonlinear feature-weighted method based on deep belief networks is\nproposed to rank the base classifiers which may violate the conditional\nindependence. Neural network is used as meta classifier. At the optimizing\nlayer, under-sampling and threshold-moving are used to cope with cost-sensitive\nproblem. Optimized predictions are obtained based on ensemble of probabilistic\npredictions by similarity calculation. The proposed deep ensemble learning\nframework is used for Alzheimers disease classification. Experiments with the\nclinical dataset from national Alzheimers coordinating center demonstrate that\nthe classification accuracy of our proposed framework is 4% better than 6\nwell-known ensemble approaches as well as the standard stacking algorithm.\nAdequate coverage of more accurate diagnostic services can be provided by\nutilizing the wisdom of averaged physicians. This paper points out a new way to\nboost the primary care of Alzheimers disease from the view of machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:04:57 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["An", "Ning", ""], ["Ding", "Huitong", ""], ["Yang", "Jiaoyun", ""], ["Au", "Rhoda", ""], ["Ang", "Ting Fang Alvin", ""]]}, {"id": "1905.12828", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh", "title": "Wasserstein Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Gaussian optimal transport for Image style transfer in an\nEncoder/Decoder framework. Optimal transport for Gaussian measures has closed\nforms Monge mappings from source to target distributions. Moreover interpolates\nbetween a content and a style image can be seen as geodesics in the Wasserstein\nGeometry. Using this insight, we show how to mix different target styles ,\nusing Wasserstein barycenter of Gaussian measures. Since Gaussians are closed\nunder Wasserstein barycenter, this allows us a simple style transfer and style\nmixing and interpolation. Moreover we show how mixing different styles can be\nachieved using other geodesic metrics between gaussians such as the Fisher Rao\nmetric, while the transport of the content to the new interpolate style is\nstill performed with Gaussian OT maps. Our simple methodology allows to\ngenerate new stylized content interpolating between many artistic styles. The\nmetric used in the interpolation results in different stylizations.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:09:28 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mroueh", "Youssef", ""]]}, {"id": "1905.12835", "submitter": "Peng Jin", "authors": "Xingyuan Chen, Yanzhe Li, Peng Jin, Jiuhua Zhang, Xinyu Dai, Jiajun\n  Chen and Gang Song", "title": "Adversarial Sub-sequence for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GAN) has been successfully introduced for\ngenerating text to alleviate the exposure bias. However, discriminators in\nthese models only evaluate the entire sequence, which causes feedback sparsity\nand mode collapse. To tackle these problems, we propose a novel mechanism. It\nfirst segments the entire sequence into several sub-sequences. Then these\nsub-sequences, together with the entire sequence, are evaluated individually by\nthe discriminator. At last these feedback signals are all used to guide the\nlearning of GAN. This mechanism learns the generation of both the entire\nsequence and the sub-sequences simultaneously. Learning to generate\nsub-sequences is easy and is helpful in generating an entire sequence. It is\neasy to improve the existing GAN-based models with this mechanism. We rebuild\nthree previous well-designed models with our mechanism, and the experimental\nresults on benchmark data show these models are improved significantly, the\nbest one outperforms the state-of-the-art model.\\footnote[1]{All code and data\nare available at https://github.com/liyzcj/seggan.git\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:51:15 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Chen", "Xingyuan", ""], ["Li", "Yanzhe", ""], ["Jin", "Peng", ""], ["Zhang", "Jiuhua", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""], ["Song", "Gang", ""]]}, {"id": "1905.12842", "submitter": "Stephen Tu", "authors": "Karl Krauth and Stephen Tu and Benjamin Recht", "title": "Finite-time Analysis of Approximate Policy Iteration for the Linear\n  Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of approximate policy iteration (PI) for the\nLinear Quadratic Regulator (LQR), building on a recent line of work using LQR\nas a testbed to understand the limits of reinforcement learning (RL) algorithms\non continuous control tasks. Our analysis quantifies the tension between policy\nimprovement and policy evaluation, and suggests that policy evaluation is the\ndominant factor in terms of sample complexity. Specifically, we show that to\nobtain a controller that is within $\\varepsilon$ of the optimal LQR controller,\neach step of policy evaluation requires at most $(n+d)^3/\\varepsilon^2$\nsamples, where $n$ is the dimension of the state vector and $d$ is the\ndimension of the input vector. On the other hand, only $\\log(1/\\varepsilon)$\npolicy improvement steps suffice, resulting in an overall sample complexity of\n$(n+d)^3 \\varepsilon^{-2} \\log(1/\\varepsilon)$. We furthermore build on our\nanalysis and construct a simple adaptive procedure based on\n$\\varepsilon$-greedy exploration which relies on approximate PI as a\nsub-routine and obtains $T^{2/3}$ regret, improving upon a recent result of\nAbbasi-Yadkori et al.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 03:36:40 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Krauth", "Karl", ""], ["Tu", "Stephen", ""], ["Recht", "Benjamin", ""]]}, {"id": "1905.12843", "submitter": "Zhiwei Steven Wu", "authors": "Alekh Agarwal, Miroslav Dud\\'ik, Zhiwei Steven Wu", "title": "Fair Regression: Quantitative Definitions and Reduction-based Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the prediction of a real-valued target, such as a\nrisk score or recidivism rate, while guaranteeing a quantitative notion of\nfairness with respect to a protected attribute such as gender or race. We call\nthis class of problems \\emph{fair regression}. We propose general schemes for\nfair regression under two notions of fairness: (1) statistical parity, which\nasks that the prediction be statistically independent of the protected\nattribute, and (2) bounded group loss, which asks that the prediction error\nrestricted to any protected group remain below some pre-determined level. While\nwe only study these two notions of fairness, our schemes are applicable to\narbitrary Lipschitz-continuous losses, and so they encompass least-squares\nregression, logistic regression, quantile regression, and many other tasks. Our\nschemes only require access to standard risk minimization algorithms (such as\nstandard classification or least-squares regression) while providing\ntheoretical guarantees on the optimality and fairness of the obtained\nsolutions. In addition to analyzing theoretical properties of our schemes, we\nempirically demonstrate their ability to uncover fairness--accuracy frontiers\non several standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 03:39:02 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1905.12849", "submitter": "Yu Bai", "authors": "Yu Bai, Tengyang Xie, Nan Jiang, Yu-Xiang Wang", "title": "Provably Efficient Q-Learning with Low Switching Cost", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take initial steps in studying PAC-MDP algorithms with limited adaptivity,\nthat is, algorithms that change its exploration policy as infrequently as\npossible during regret minimization. This is motivated by the difficulty of\nrunning fully adaptive algorithms in real-world applications (such as medical\ndomains), and we propose to quantify adaptivity using the notion of local\nswitching cost. Our main contribution, Q-Learning with UCB2 exploration, is a\nmodel-free algorithm for H-step episodic MDP that achieves sublinear regret\nwhose local switching cost in K episodes is $O(H^3SA\\log K)$, and we provide a\nlower bound of $\\Omega(HSA)$ on the local switching cost for any no-regret\nalgorithm. Our algorithm can be naturally adapted to the concurrent setting,\nwhich yields nontrivial results that improve upon prior work in certain\naspects.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 04:35:13 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 02:44:16 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 04:03:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Bai", "Yu", ""], ["Xie", "Tengyang", ""], ["Jiang", "Nan", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1905.12859", "submitter": "Evgeniy Ozhegov M.", "authors": "Evgeniy M. Ozhegov, Alina Ozhegova", "title": "Heterogeneity in demand and optimal price conditioning for local rail\n  transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the results of research project on optimal pricing for\nLLC \"Perm Local Rail Company\". In this study we propose a regression tree based\napproach for estimation of demand function for local rail tickets considering\nhigh degree of demand heterogeneity by various trip directions and the goals of\ntravel. Employing detailed data on ticket sales for 5 years we estimate the\nparameters of demand function and reveal the significant variation in price\nelasticity of demand. While in average the demand is elastic by price, near a\nquarter of trips is characterized by weakly elastic demand. Lower elasticity of\ndemand is correlated with lower degree of competition with other transport and\ninflexible frequency of travel.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:32:20 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ozhegov", "Evgeniy M.", ""], ["Ozhegova", "Alina", ""]]}, {"id": "1905.12864", "submitter": "Samuel Barham", "authors": "Samuel Barham and Soheil Feizi", "title": "Interpretable Adversarial Training for Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating high-quality and interpretable adversarial examples in the text\ndomain is a much more daunting task than it is in the image domain. This is due\npartly to the discrete nature of text, partly to the problem of ensuring that\nthe adversarial examples are still probable and interpretable, and partly to\nthe problem of maintaining label invariance under input perturbations. In order\nto address some of these challenges, we introduce sparse projected gradient\ndescent (SPGD), a new approach to crafting interpretable adversarial examples\nfor text. SPGD imposes a directional regularization constraint on input\nperturbations by projecting them onto the directions to nearby word embeddings\nwith highest cosine similarities. This constraint ensures that perturbations\nmove each word embedding in an interpretable direction (i.e., towards another\nnearby word embedding). Moreover, SPGD imposes a sparsity constraint on\nperturbations at the sentence level by ignoring word-embedding perturbations\nwhose norms are below a certain threshold. This constraint ensures that our\nmethod changes only a few words per sequence, leading to higher quality\nadversarial examples. Our experiments with the IMDB movie review dataset show\nthat the proposed SPGD method improves adversarial example interpretability and\nlikelihood (evaluated by average per-word perplexity) compared to\nstate-of-the-art methods, while suffering little to no loss in training\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:55:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Barham", "Samuel", ""], ["Feizi", "Soheil", ""]]}, {"id": "1905.12867", "submitter": "Dae Ung Jo", "authors": "Dae Ung Jo, ByeongJu Lee, Jongwon Choi, Haanju Yoo and Jin Young Choi", "title": "Cross-modal Variational Auto-encoder with Distributed Latent Spaces and\n  Associators", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel structure for a cross-modal data\nassociation, which is inspired by the recent research on the associative\nlearning structure of the brain. We formulate the cross-modal association in\nBayesian inference framework realized by a deep neural network with multiple\nvariational auto-encoders and variational associators. The variational\nassociators transfer the latent spaces between auto-encoders that represent\ndifferent modalities. The proposed structure successfully associates even\nheterogeneous modal data and easily incorporates the additional modality to the\nentire network via the proposed cross-modal associator. Furthermore, the\nproposed structure can be trained with only a small amount of paired data since\nauto-encoders can be trained by unsupervised manner. Through experiments, the\neffectiveness of the proposed structure is validated on various datasets\nincluding visual and auditory data.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:02:33 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Jo", "Dae Ung", ""], ["Lee", "ByeongJu", ""], ["Choi", "Jongwon", ""], ["Yoo", "Haanju", ""], ["Choi", "Jin Young", ""]]}, {"id": "1905.12868", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Matthieu Kirchmeyer, Pranjul Yadav, S. Sathiya\n  Keerthi, Patrick Gallinari", "title": "Benchmarking Regression Methods: A comparison with CGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, impressive progress has been made in the design of implicit\nprobabilistic models via Generative Adversarial Networks (GAN) and its\nextension, the Conditional GAN (CGAN). Excellent solutions have been\ndemonstrated mostly in image processing applications which involve large,\ncontinuous output spaces. There is almost no application of these powerful\ntools to problems having small dimensional output spaces. Regression problems\ninvolving the inductive learning of a map, $y=f(x,z)$, $z$ denoting noise,\n$f:\\mathbb{R}^n\\times \\mathbb{R}^k \\rightarrow \\mathbb{R}^m$, with $m$ small\n(e.g., $m=1$ or just a few) is one good case in point. The standard approach to\nsolve regression problems is to probabilistically model the output $y$ as the\nsum of a mean function $m(x)$ and a noise term $z$; it is also usual to take\nthe noise to be a Gaussian. These are done for convenience sake so that the\nlikelihood of observed data is expressible in closed form. In the real world,\non the other hand, stochasticity of the output is usually caused by missing or\nnoisy input variables. Such a real world situation is best represented using an\nimplicit model in which an extra noise vector, $z$ is included with $x$ as\ninput. CGAN is naturally suited to design such implicit models. This paper\nmakes the first step in this direction and compares the existing regression\nmethods with CGAN.\n  We notice however, that the existing methods like mixture density networks\n(MDN) and XGBoost do quite well compared to CGAN in terms of likelihood and\nmean absolute error, respectively. Both these methods are comparatively easier\nto train than CGANs. CGANs need more innovation to have a comparable modeling\nand ease-of-training with respect to the existing regression solvers. In\nsummary, for modeling uncertainty MDNs are better while XGBoost is better for\nthe cases where accurate prediction is more important.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:02:43 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:06:42 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 04:15:38 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 18:21:12 GMT"}, {"version": "v5", "created": "Tue, 4 Feb 2020 20:14:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Aggarwal", "Karan", ""], ["Kirchmeyer", "Matthieu", ""], ["Yadav", "Pranjul", ""], ["Keerthi", "S. Sathiya", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1905.12874", "submitter": "Nicolas Pinchaud", "authors": "Nicolas Pinchaud", "title": "Information theoretic learning of robust deep representations", "comments": "NIPS 2011 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel objective function for learning robust deep\nrepresentations of data based on information theory. Data is projected into a\nfeature-vector space such that the mutual information of all subsets of\nfeatures relative to the supervising signal is maximized. This objective\nfunction gives rise to robust representations by conserving available\ninformation relative to supervision in the face of noisy or unavailable\nfeatures. Although the objective function is not directly tractable, we are\nable to derive a surrogate objective function. Minimizing this surrogate loss\nencourages features to be non-redundant and conditionally independent relative\nto the supervising signal. To evaluate the quality of obtained solutions, we\nhave performed a set of preliminary experiments that show promising results.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:27:12 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Pinchaud", "Nicolas", ""]]}, {"id": "1905.12879", "submitter": "Shiyin Lu", "authors": "Shiyin Lu, Guanghui Wang, Yao Hu, Lijun Zhang", "title": "Multi-Objective Generalized Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the multi-objective bandits (MOB) problem, where a\nlearner repeatedly selects one arm to play and then receives a reward vector\nconsisting of multiple objectives. MOB has found many real-world applications\nas varied as online recommendation and network routing. On the other hand,\nthese applications typically contain contextual information that can guide the\nlearning process which, however, is ignored by most of existing work. To\nutilize this information, we associate each arm with a context vector and\nassume the reward follows the generalized linear model (GLM). We adopt the\nnotion of Pareto regret to evaluate the learner's performance and develop a\nnovel algorithm for minimizing it. The essential idea is to apply a variant of\nthe online Newton step to estimate model parameters, based on which we utilize\nthe upper confidence bound (UCB) policy to construct an approximation of the\nPareto front, and then uniformly at random choose one arm from the approximate\nPareto front. Theoretical analysis shows that the proposed algorithm achieves\nan $\\tilde O(d\\sqrt{T})$ Pareto regret, where $T$ is the time horizon and $d$\nis the dimension of contexts, which matches the optimal result for single\nobjective contextual bandits problem. Numerical experiments demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:01:24 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lu", "Shiyin", ""], ["Wang", "Guanghui", ""], ["Hu", "Yao", ""], ["Zhang", "Lijun", ""]]}, {"id": "1905.12881", "submitter": "Emanuele Bugliarello", "authors": "Emanuele Bugliarello and Swayambhoo Jain and Vineeth Rakesh", "title": "Matrix Completion in the Unit Hypercube via Structured Matrix\n  Factorization", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/282", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several complex tasks that arise in organizations can be simplified by\nmapping them into a matrix completion problem. In this paper, we address a key\nchallenge faced by our company: predicting the efficiency of artists in\nrendering visual effects (VFX) in film shots. We tackle this challenge by using\na two-fold approach: first, we transform this task into a constrained matrix\ncompletion problem with entries bounded in the unit interval [0, 1]; second, we\npropose two novel matrix factorization models that leverage our knowledge of\nthe VFX environment. Our first approach, expertise matrix factorization (EMF),\nis an interpretable method that structures the latent factors as weighted\nuser-item interplay. The second one, survival matrix factorization (SMF), is\ninstead a probabilistic model for the underlying process defining employees'\nefficiencies. We show the effectiveness of our proposed models by extensive\nnumerical tests on our VFX dataset and two additional datasets with values that\nare also bounded in the [0, 1] interval.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:03:23 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bugliarello", "Emanuele", ""], ["Jain", "Swayambhoo", ""], ["Rakesh", "Vineeth", ""]]}, {"id": "1905.12882", "submitter": "Hrushikesh Mhaskar", "authors": "H. N. Mhaskar, T. Poggio", "title": "Function approximation by deep networks", "comments": "To appear in Communications in pure and applied mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that deep networks are better than shallow networks at approximating\nfunctions that can be expressed as a composition of functions described by a\ndirected acyclic graph, because the deep networks can be designed to have the\nsame compositional structure, while a shallow network cannot exploit this\nknowledge. Thus, the blessing of compositionality mitigates the curse of\ndimensionality. On the other hand, a theorem called good propagation of errors\nallows to `lift' theorems about shallow networks to those about deep networks\nwith an appropriate choice of norms, smoothness, etc. We illustrate this in\nthree contexts where each channel in the deep network calculates a spherical\npolynomial, a non-smooth ReLU network, or another zonal function network\nrelated closely with the ReLU network.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:05:10 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 04:43:57 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Mhaskar", "H. N.", ""], ["Poggio", "T.", ""]]}, {"id": "1905.12885", "submitter": "Xiao Ma", "authors": "Xiao Ma, Peter Karkus, David Hsu, Wee Sun Lee", "title": "Particle Filter Recurrent Neural Networks", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been extraordinarily successful for\nprediction with sequential data. To tackle highly variable and noisy real-world\ndata, we introduce Particle Filter Recurrent Neural Networks (PF-RNNs), a new\nRNN family that explicitly models uncertainty in its internal structure: while\nan RNN relies on a long, deterministic latent state vector, a PF-RNN maintains\na latent state distribution, approximated as a set of particles. For effective\nlearning, we provide a fully differentiable particle filter algorithm that\nupdates the PF-RNN latent state distribution according to the Bayes rule.\nExperiments demonstrate that the proposed PF-RNNs outperform the corresponding\nstandard gated RNNs on a synthetic robot localization dataset and 10 real-world\nsequence prediction datasets for text classification, stock price prediction,\netc.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:09:22 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 07:12:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ma", "Xiao", ""], ["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1905.12886", "submitter": "Salman Khan Dr.", "authors": "Syed Waqas Zamir, Aditya Arora, Akshita Gupta, Salman Khan, Guolei\n  Sun, Fahad Shahbaz Khan, Fan Zhu, Ling Shao, Gui-Song Xia, Xiang Bai", "title": "iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images", "comments": "CVPR'19 Workshops (Detecting Objects in Aerial Images). The dataset\n  is publicly available at: https://captain-whu.github.io/iSAID/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Earth Vision datasets are either suitable for semantic segmentation\nor object detection. In this work, we introduce the first benchmark dataset for\ninstance segmentation in aerial imagery that combines instance-level object\ndetection and pixel-level segmentation tasks. In comparison to instance\nsegmentation in natural scenes, aerial images present unique challenges e.g., a\nhuge number of instances per image, large object-scale variations and abundant\ntiny objects. Our large-scale and densely annotated Instance Segmentation in\nAerial Images Dataset (iSAID) comes with 655,451 object instances for 15\ncategories across 2,806 high-resolution images. Such precise per-pixel\nannotations for each instance ensure accurate localization that is essential\nfor detailed scene analysis. Compared to existing small-scale aerial image\nbased instance segmentation datasets, iSAID contains 15$\\times$ the number of\nobject categories and 5$\\times$ the number of instances. We benchmark our\ndataset using two popular instance segmentation approaches for natural images,\nnamely Mask R-CNN and PANet. In our experiments we show that direct application\nof off-the-shelf Mask R-CNN and PANet on aerial images provide suboptimal\ninstance segmentation results, thus requiring specialized solutions from the\nresearch community. The dataset is publicly available at:\nhttps://captain-whu.github.io/iSAID/index.html\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:18:28 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 05:57:00 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zamir", "Syed Waqas", ""], ["Arora", "Aditya", ""], ["Gupta", "Akshita", ""], ["Khan", "Salman", ""], ["Sun", "Guolei", ""], ["Khan", "Fahad Shahbaz", ""], ["Zhu", "Fan", ""], ["Shao", "Ling", ""], ["Xia", "Gui-Song", ""], ["Bai", "Xiang", ""]]}, {"id": "1905.12887", "submitter": "Brady Zhou", "authors": "Brady Zhou, Philipp Kr\\\"ahenb\\\"uhl, and Vladlen Koltun", "title": "Does computer vision matter for action?", "comments": "Published in Science Robotics, 4(30), May 2019", "journal-ref": "Science Robotics 22 May 2019: Vol. 4, Issue 30, eaaw6661", "doi": "10.1126/scirobotics.aaw6661", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision produces representations of scene content. Much computer\nvision research is predicated on the assumption that these intermediate\nrepresentations are useful for action. Recent work at the intersection of\nmachine learning and robotics calls this assumption into question by training\nsensorimotor systems directly for the task at hand, from pixels to actions,\nwith no explicit intermediate representations. Thus the central question of our\nwork: Does computer vision matter for action? We probe this question and its\noffshoots via immersive simulation, which allows us to conduct controlled\nreproducible experiments at scale. We instrument immersive three-dimensional\nenvironments to simulate challenges such as urban driving, off-road trail\ntraversal, and battle. Our main finding is that computer vision does matter.\nModels equipped with intermediate representations train faster, achieve higher\ntask performance, and generalize better to previously unseen environments. A\nvideo that summarizes the work and illustrates the results can be found at\nhttps://youtu.be/4MfWa2yZ0Jc\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:18:33 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 06:33:45 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhou", "Brady", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1905.12888", "submitter": "Liyiming Ke", "authors": "Liyiming Ke, Sanjiban Choudhury, Matt Barnes, Wen Sun, Gilwoo Lee,\n  Siddhartha Srinivasa", "title": "Imitation Learning as $f$-Divergence Minimization", "comments": "International Workshop on the Algorithmic Foundations of Robotics\n  (WAFR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.RO math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of imitation learning with multi-modal demonstrations.\nInstead of attempting to learn all modes, we argue that in many tasks it is\nsufficient to imitate any one of them. We show that the state-of-the-art\nmethods such as GAIL and behavior cloning, due to their choice of loss\nfunction, often incorrectly interpolate between such modes. Our key insight is\nto minimize the right divergence between the learner and the expert\nstate-action distributions, namely the reverse KL divergence or I-projection.\nWe propose a general imitation learning framework for estimating and minimizing\nany f-Divergence. By plugging in different divergences, we are able to recover\nexisting algorithms such as Behavior Cloning (Kullback-Leibler), GAIL (Jensen\nShannon) and Dagger (Total Variation). Empirical results show that our\napproximate I-projection technique is able to imitate multi-modal behaviors\nmore reliably than GAIL and behavior cloning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:19:13 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 08:38:33 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Ke", "Liyiming", ""], ["Choudhury", "Sanjiban", ""], ["Barnes", "Matt", ""], ["Sun", "Wen", ""], ["Lee", "Gilwoo", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1905.12889", "submitter": "Nicolas Pinchaud", "authors": "Nicolas Pinchaud", "title": "Unsupervised pre-training helps to conserve views from input\n  distribution", "comments": "ICML 2012 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effects of the unsupervised pre-training method under the\nperspective of information theory. If the input distribution displays multiple\nviews of the supervision, then unsupervised pre-training allows to learn\nhierarchical representation which communicates these views across layers, while\ndisentangling the supervision. Disentanglement of supervision leads learned\nfeatures to be independent conditionally to the label. In case of binary\nfeatures, we show that conditional independence allows to extract label's\ninformation with a linear model and therefore helps to solve under-fitting. We\nsuppose that representations displaying multiple views help to solve\nover-fitting because each view provides information that helps to reduce\nmodel's variance. We propose a practical method to measure both disentanglement\nof supervision and quantity of views within a binary representation. We show\nthat unsupervised pre-training helps to conserve views from input distribution,\nwhereas representations learned using supervised models disregard most of them.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:26:52 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Pinchaud", "Nicolas", ""]]}, {"id": "1905.12892", "submitter": "Aditya Grover", "authors": "Aditya Grover, Christopher Chute, Rui Shu, Zhangjie Cao, Stefano Ermon", "title": "AlignFlow: Cycle Consistent Learning from Multiple Domains via\n  Normalizing Flows", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given datasets from multiple domains, a key challenge is to efficiently\nexploit these data sources for modeling a target domain. Variants of this\nproblem have been studied in many contexts, such as cross-domain translation\nand domain adaptation. We propose AlignFlow, a generative modeling framework\nthat models each domain via a normalizing flow. The use of normalizing flows\nallows for a) flexibility in specifying learning objectives via adversarial\ntraining, maximum likelihood estimation, or a hybrid of the two methods; and b)\nlearning and exact inference of a shared representation in the latent space of\nthe generative model. We derive a uniform set of conditions under which\nAlignFlow is marginally-consistent for the different learning objectives.\nFurthermore, we show that AlignFlow guarantees exact cycle consistency in\nmapping datapoints from a source domain to target and back to the source\ndomain. Empirically, AlignFlow outperforms relevant baselines on image-to-image\ntranslation and unsupervised domain adaptation and can be used to\nsimultaneously interpolate across the various domains using the learned\nrepresentation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:28:26 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 08:31:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Grover", "Aditya", ""], ["Chute", "Christopher", ""], ["Shu", "Rui", ""], ["Cao", "Zhangjie", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.12893", "submitter": "Dave Deriso", "authors": "Dave Deriso, Stephen Boyd", "title": "A General Optimization Framework for Dynamic Time Warping", "comments": "22 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of dynamic time warping is to transform or warp time in order to\napproximately align two signals together. We pose the choice of warping\nfunction as an optimization problem with several terms in the objective. The\nfirst term measures the misalignment of the time-warped signals. Two additional\nregularization terms penalize the cumulative warping and the instantaneous rate\nof time warping; constraints on the warping can be imposed by assigning the\nvalue +inf to the regularization terms. Different choices of the three\nobjective terms yield different time warping functions that trade off signal\nfit or alignment and properties of the warping function. The optimization\nproblem we formulate is a classical optimal control problem, with initial and\nterminal constraints, and a state dimension of one. We describe an effective\ngeneral method that minimizes the objective by discretizing the values of the\noriginal and warped time, and using standard dynamic programming to compute the\n(globally) optimal warping function with the discretized values. Iterated\nrefinement of this scheme yields a high accuracy warping function in just a few\niterations. Our method is implemented as an open source Python package GDTW.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:29:49 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 06:57:34 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Deriso", "Dave", ""], ["Boyd", "Stephen", ""]]}, {"id": "1905.12909", "submitter": "Gabriel Dulac-Arnold", "authors": "Gabriel Dulac-Arnold, Neil Zeghidour, Marco Cuturi, Lucas Beyer,\n  Jean-Philippe Vert", "title": "Deep multi-class learning from label proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning algorithm capable of learning from label proportions\ninstead of direct data labels. In this scenario, our data are arranged into\nvarious bags of a certain size, and only the proportions of each label within a\ngiven bag are known. This is a common situation in cases where per-data\nlabeling is lengthy, but a more general label is easily accessible. Several\napproaches have been proposed to learn in this setting with linear models in\nthe multiclass setting, or with nonlinear models in the binary classification\nsetting. Here we investigate the more general nonlinear multiclass setting, and\ncompare two differentiable loss functions to train end-to-end deep neural\nnetworks from bags with label proportions. We illustrate the relevance of our\nmethods on an image classification benchmark, and demonstrate the possibility\nto learn accurate image classifiers from bags of images.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 08:26:47 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 12:20:13 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Dulac-Arnold", "Gabriel", ""], ["Zeghidour", "Neil", ""], ["Cuturi", "Marco", ""], ["Beyer", "Lucas", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1905.12914", "submitter": "Hae Beom Lee", "authors": "Hae Beom Lee, Taewook Nam, Eunho Yang, Sung Ju Hwang", "title": "Meta Dropout: Learning to Perturb Features for Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning model that generalizes well should obtain low errors on\nunseen test examples. Thus, if we know how to optimally perturb training\nexamples to account for test examples, we may achieve better generalization\nperformance. However, obtaining such perturbation is not possible in standard\nmachine learning frameworks as the distribution of the test data is unknown. To\ntackle this challenge, we propose a novel regularization method, meta-dropout,\nwhich learns to perturb the latent features of training examples for\ngeneralization in a meta-learning framework. Specifically, we meta-learn a\nnoise generator which outputs a multiplicative noise distribution for latent\nfeatures, to obtain low errors on the test instances in an input-dependent\nmanner. Then, the learned noise generator can perturb the training examples of\nunseen tasks at the meta-test time for improved generalization. We validate our\nmethod on few-shot classification datasets, whose results show that it\nsignificantly improves the generalization performance of the base model, and\nlargely outperforms existing regularization methods such as information\nbottleneck, manifold mixup, and information dropout.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 08:44:16 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 18:52:06 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lee", "Hae Beom", ""], ["Nam", "Taewook", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1905.12916", "submitter": "Yang-En Chen", "authors": "Yang-En Chen, Kai-Fu Tang, Yu-Shao Peng, Edward Y. Chang", "title": "Effective Medical Test Suggestions Using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective medical test suggestions benefit both patients and physicians to\nconserve time and improve diagnosis accuracy. In this work, we show that an\nagent can learn to suggest effective medical tests. We formulate the problem as\na stage-wise Markov decision process and propose a reinforcement learning\nmethod to train the agent. We introduce a new representation of multiple action\npolicy along with the training method of the proposed representation.\nFurthermore, a new exploration scheme is proposed to accelerate the learning of\ndisease distributions. Our experimental results demonstrate that the accuracy\nof disease diagnosis can be significantly improved with good medical test\nsuggestions.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:06:58 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 13:21:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chen", "Yang-En", ""], ["Tang", "Kai-Fu", ""], ["Peng", "Yu-Shao", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1905.12917", "submitter": "Donghyun Na", "authors": "Hae Beom Lee, Hayeon Lee, Donghyun Na, Saehoon Kim, Minseop Park,\n  Eunho Yang, Sung Ju Hwang", "title": "Learning to Balance: Bayesian Meta-Learning for Imbalanced and\n  Out-of-distribution Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While tasks could come with varying the number of instances and classes in\nrealistic settings, the existing meta-learning approaches for few-shot\nclassification assume that the number of instances per task and class is fixed.\nDue to such restriction, they learn to equally utilize the meta-knowledge\nacross all the tasks, even when the number of instances per task and class\nlargely varies. Moreover, they do not consider distributional difference in\nunseen tasks, on which the meta-knowledge may have less usefulness depending on\nthe task relatedness. To overcome these limitations, we propose a novel\nmeta-learning model that adaptively balances the effect of the meta-learning\nand task-specific learning within each task. Through the learning of the\nbalancing variables, we can decide whether to obtain a solution by relying on\nthe meta-knowledge or task-specific learning. We formulate this objective into\na Bayesian inference framework and tackle it using variational inference. We\nvalidate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple\nrealistic task- and class-imbalanced datasets, on which it significantly\noutperforms existing meta-learning approaches. Further ablation study confirms\nthe effectiveness of each balancing component and the Bayesian learning\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:07:22 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 10:29:03 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Lee", "Hae Beom", ""], ["Lee", "Hayeon", ""], ["Na", "Donghyun", ""], ["Kim", "Saehoon", ""], ["Park", "Minseop", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1905.12921", "submitter": "Yifan Qian", "authors": "Yifan Qian, Paul Expert, Tom Rieu, Pietro Panzarasa and Mauricio\n  Barahona", "title": "Quantifying the Alignment of Graph and Features in Deep Learning", "comments": "Published in IEEE Transactions on Neural Networks and Learning\n  Systems; Date of Publication: 11 January 2021", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3043196", "report-no": null, "categories": "cs.LG cs.NE cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the classification performance of graph convolutional networks\n(GCNs) is related to the alignment between features, graph, and ground truth,\nwhich we quantify using a subspace alignment measure (SAM) corresponding to the\nFrobenius norm of the matrix of pairwise chordal distances between three\nsubspaces associated with features, graph, and ground truth. The proposed\nmeasure is based on the principal angles between subspaces and has both\nspectral and geometrical interpretations. We showcase the relationship between\nthe SAM and the classification performance through the study of limiting cases\nof GCNs and systematic randomizations of both features and graph structure\napplied to a constructive example and several examples of citation networks of\ndifferent origins. The analysis also reveals the relative importance of the\ngraph and features for classification purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:14:58 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 22:22:01 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 17:04:26 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Qian", "Yifan", ""], ["Expert", "Paul", ""], ["Rieu", "Tom", ""], ["Panzarasa", "Pietro", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1905.12925", "submitter": "Tom Hess", "authors": "Tom Hess and Sivan Sabato", "title": "Sequential no-Substitution k-Median-Clustering", "comments": "to appear at AISTATS 2020", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics (AISTATS), 962--972, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample-based k-median clustering objective under a sequential\nsetting without substitutions. In this setting, an i.i.d. sequence of examples\nis observed. An example can be selected as a center only immediately after it\nis observed, and it cannot be substituted later. The goal is to select a set of\ncenters with a good k-median cost on the distribution which generated the\nsequence. We provide an efficient algorithm for this setting, and show that its\nmultiplicative approximation factor is twice the approximation factor of an\nefficient offline algorithm. In addition, we show that if efficiency\nrequirements are removed, there is an algorithm that can obtain the same\napproximation factor as the best offline algorithm. We demonstrate in\nexperiments the performance of the efficient algorithm on real data sets. Our\ncode is available at https://github.com/tomhess/No_Substitution_K_Median.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:28:26 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 06:20:26 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 11:53:30 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Hess", "Tom", ""], ["Sabato", "Sivan", ""]]}, {"id": "1905.12930", "submitter": "Ieva Kazlauskaite", "authors": "Ivan Ustyuzhaninov, Ieva Kazlauskaite, Carl Henrik Ek and Neill D. F.\n  Campbell", "title": "Monotonic Gaussian Process Flow", "comments": "Proceedings of the 23nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020 (14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for imposing monotonicity constraints in a\nBayesian nonparametric setting based on numerical solutions of stochastic\ndifferential equations. We derive a nonparametric model of monotonic functions\nthat allows for interpretable priors and principled quantification of\nhierarchical uncertainty. We demonstrate the efficacy of the proposed model by\nproviding competitive results to other probabilistic monotonic models on a\nnumber of benchmark functions. In addition, we consider the utility of a\nmonotonic random process as a part of a hierarchical probabilistic model; we\nexamine the task of temporal alignment of time-series data where it is\nbeneficial to use a monotonic random process in order to preserve the\nuncertainty in the temporal warpings.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:43:59 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 09:22:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ustyuzhaninov", "Ivan", ""], ["Kazlauskaite", "Ieva", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1905.12931", "submitter": "Nicolas Pinchaud", "authors": "Nicolas Pinchaud", "title": "Weakly supervised training of pixel resolution segmentation models on\n  whole slide images", "comments": "Performance update", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to train pixel resolution segmentation models on\nwhole slide images in a weakly supervised setup. The model is trained to\nclassify patches extracted from slides. This leads the training to be made\nunder noisy labeled data. We solve the problem with two complementary\nstrategies. First, the patches are sampled online using the model's knowledge\nby focusing on regions where the model's confidence is higher. Second, we\npropose an extension of the KL divergence that is robust to noisy labels. Our\npreliminary experiment on CAMELYON 16 data set show promising results. The\nmodel can successfully segment tumor areas with strong morphological\nconsistency.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:47:11 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 20:00:22 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Pinchaud", "Nicolas", ""]]}, {"id": "1905.12937", "submitter": "Jan Melchior", "authors": "Jan Melchior and Mehdi Bayati and Amir Azizi and Sen Cheng and Laurenz\n  Wiskott", "title": "A Hippocampus Model for Online One-Shot Storage of Pattern Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational model based on the CRISP theory (Content\nRepresentation, Intrinsic Sequences, and Pattern completion) of the hippocampus\nthat allows to continuously store pattern sequences online in a one-shot\nfashion. Rather than storing a sequence in CA3, CA3 provides a pre-trained\nsequence that is hetero-associated with the input sequence, which allows the\nsystem to perform one-shot learning. Plasticity on a short time scale therefore\nonly happens in the incoming and outgoing connections of CA3. Stored sequences\ncan later be recalled from a single cue pattern. We identify the pattern\nseparation performed by subregion DG to be necessary for storing sequences that\ncontain correlated patterns. A design principle of the model is that we use a\nsingle learning rule named Hebbiand-escent to train all parts of the system.\nHebbian-descent has an inherent forgetting mechanism that allows the system to\ncontinuously memorize new patterns while forgetting early stored ones. The\nmodel shows a plausible behavior when noisy and new patterns are presented and\nhas a rather high capacity of about 40% in terms of the number of neurons in\nCA3. One notable property of our model is that it is capable of\n`boot-strapping' (improving) itself without external input in a process we\nrefer to as `dreaming'. Besides artificially generated input sequences we also\nshow that the model works with sequences of encoded handwritten digits or\nnatural images. To our knowledge this is the first model of the hippocampus\nthat allows to store correlated pattern sequences online in a one-shot fashion\nwithout a consolidation process, which can instantaneously be recalled later.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:51:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Melchior", "Jan", ""], ["Bayati", "Mehdi", ""], ["Azizi", "Amir", ""], ["Cheng", "Sen", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1905.12947", "submitter": "Przemys{\\l}aw Spurek", "authors": "Przemys{\\l}aw Spurek, Szymon Knop, Jacek Tabor, Igor Podolak, Bartosz\n  W\\'ojcik", "title": "One-element Batch Training by Moving Window", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several deep models, esp. the generative, compare the samples from two\ndistributions (e.g. WAE like AutoEncoder models, set-processing deep networks,\netc) in their cost functions. Using all these methods one cannot train the\nmodel directly taking small size (in extreme -- one element) batches, due to\nthe fact that samples are to be compared.\n  We propose a generic approach to training such models using one-element\nmini-batches. The idea is based on splitting the batch in latent into parts:\nprevious, i.e. historical, elements used for latent space distribution matching\nand the current ones, used both for latent distribution computation and the\nminimization process. Due to the smaller memory requirements, this allows to\ntrain networks on higher resolution images then in the classical approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:25:53 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 17:53:59 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Spurek", "Przemys\u0142aw", ""], ["Knop", "Szymon", ""], ["Tabor", "Jacek", ""], ["Podolak", "Igor", ""], ["W\u00f3jcik", "Bartosz", ""]]}, {"id": "1905.12948", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Yin-Peng Xie, Hao Gao, Wu-Jun Li", "title": "Global Momentum Compression for Sparse Communication in Distributed SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of data, distributed stochastic gradient descent~(DSGD)\nhas been widely used for solving large-scale machine learning problems. Due to\nthe latency and limited bandwidth of network, communication has become the\nbottleneck of DSGD when we need to train large scale models, like deep neural\nnetworks. Communication compression with sparsified gradient, abbreviated as\n\\emph{sparse communication}, has been widely used for reducing communication\ncost in DSGD. Recently, there has appeared one method, called deep gradient\ncompression~(DGC), to combine memory gradient and momentum SGD for sparse\ncommunication. DGC has achieved promising performance in practise. However, the\ntheory about the convergence of DGC is lack. In this paper, we propose a novel\nmethod, called \\emph{\\underline{g}}lobal \\emph{\\underline{m}}omentum\n\\emph{\\underline{c}}ompression~(GMC), for sparse communication in DSGD. GMC\nalso combines memory gradient and momentum SGD. But different from DGC which\nadopts local momentum, GMC adopts global momentum. We theoretically prove the\nconvergence rate of GMC for both convex and non-convex problems. To the best of\nour knowledge, this is the first work that proves the convergence of\ndistributed momentum SGD~(DMSGD) with sparse communication and memory gradient.\nEmpirical results show that, compared with the DMSGD counterpart without sparse\ncommunication, GMC can reduce the communication cost by approximately 100 fold\nwithout loss of generalization accuracy. GMC can also achieve\ncomparable~(sometimes better) performance compared with DGC, with extra\ntheoretical guarantee.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:33:11 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 16:46:30 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Xie", "Yin-Peng", ""], ["Gao", "Hao", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1905.12950", "submitter": "Kai Zheng", "authors": "Kai Zheng, Haipeng Luo, Ilias Diakonikolas, Liwei Wang", "title": "Equipping Experts/Bandits with Long-term Memory", "comments": "25 pages, accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first reduction-based approach to obtaining long-term memory\nguarantees for online learning in the sense of Bousquet and Warmuth, 2002, by\nreducing the problem to achieving typical switching regret. Specifically, for\nthe classical expert problem with $K$ actions and $T$ rounds, using our\nframework we develop various algorithms with a regret bound of order\n$\\mathcal{O}(\\sqrt{T(S\\ln T + n \\ln K)})$ compared to any sequence of experts\nwith $S-1$ switches among $n \\leq \\min\\{S, K\\}$ distinct experts. In addition,\nby plugging specific adaptive algorithms into our framework we also achieve the\nbest of both stochastic and adversarial environments simultaneously. This\nresolves an open problem of Warmuth and Koolen, 2014. Furthermore, we extend\nour results to the sparse multi-armed bandit setting and show both negative and\npositive results for long-term memory guarantees. As a side result, our lower\nbound also implies that sparse losses do not help improve the worst-case regret\nfor contextual bandits, a sharp contrast with the non-contextual case.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:38:45 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 04:05:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zheng", "Kai", ""], ["Luo", "Haipeng", ""], ["Diakonikolas", "Ilias", ""], ["Wang", "Liwei", ""]]}, {"id": "1905.12957", "submitter": "Chung Chan", "authors": "Chung Chan, Ali Al-Bashabsheh, Hing Pang Huang, Michael Lim, Da Sun\n  Handason Tam, Chao Zhao", "title": "Neural Entropic Estimation: A faster path to mutual information\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out a limitation of the mutual information neural estimation (MINE)\nwhere the network fails to learn at the initial training phase, leading to slow\nconvergence in the number of training iterations. To solve this problem, we\npropose a faster method called the mutual information neural entropic\nestimation (MI-NEE). Our solution first generalizes MINE to estimate the\nentropy using a custom reference distribution. The entropy estimate can then be\nused to estimate the mutual information. We argue that the seemingly redundant\nintermediate step of entropy estimation allows one to improve the convergence\nby an appropriate reference distribution. In particular, we show that MI-NEE\nreduces to MINE in the special case when the reference distribution is the\nproduct of marginal distributions, but faster convergence is possible by\nchoosing the uniform distribution as the reference distribution instead.\nCompared to the product of marginals, the uniform distribution introduces more\nsamples in low-density regions and fewer samples in high-density regions, which\nappear to lead to an overall larger gradient for faster convergence.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:51:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 02:19:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chan", "Chung", ""], ["Al-Bashabsheh", "Ali", ""], ["Huang", "Hing Pang", ""], ["Lim", "Michael", ""], ["Tam", "Da Sun Handason", ""], ["Zhao", "Chao", ""]]}, {"id": "1905.12960", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Hao Gao, Wu-Jun Li", "title": "On the Convergence of Memory-Based Distributed SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent~(DSGD) has been widely used for\noptimizing large-scale machine learning models, including both convex and\nnon-convex models. With the rapid growth of model size, huge communication cost\nhas been the bottleneck of traditional DSGD. Recently, many communication\ncompression methods have been proposed. Memory-based distributed stochastic\ngradient descent~(M-DSGD) is one of the efficient methods since each worker\ncommunicates a sparse vector in each iteration so that the communication cost\nis small. Recent works propose the convergence rate of M-DSGD when it adopts\nvanilla SGD. However, there is still a lack of convergence theory for M-DSGD\nwhen it adopts momentum SGD. In this paper, we propose a universal convergence\nanalysis for M-DSGD by introducing \\emph{transformation equation}. The\ntransformation equation describes the relation between traditional DSGD and\nM-DSGD so that we can transform M-DSGD to its corresponding DSGD. Hence we get\nthe convergence rate of M-DSGD with momentum for both convex and non-convex\nproblems. Furthermore, we combine M-DSGD and stagewise learning that the\nlearning rate of M-DSGD in each stage is a constant and is decreased by stage,\ninstead of iteration. Using the transformation equation, we propose the\nconvergence rate of stagewise M-DSGD which bridges the gap between theory and\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:01:16 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Gao", "Hao", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1905.12962", "submitter": "Mike Gartrell", "authors": "Mike Gartrell, Victor-Emmanuel Brunel, Elvis Dohmatob, Syrine Krichene", "title": "Learning Nonsymmetric Determinantal Point Processes", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have attracted substantial attention as\nan elegant probabilistic model that captures the balance between quality and\ndiversity within sets. DPPs are conventionally parameterized by a positive\nsemi-definite kernel matrix, and this symmetric kernel encodes only repulsive\ninteractions between items. These so-called symmetric DPPs have significant\nexpressive power, and have been successfully applied to a variety of machine\nlearning tasks, including recommendation systems, information retrieval, and\nautomatic summarization, among many others. Efficient algorithms for learning\nsymmetric DPPs and sampling from these models have been reasonably well\nstudied. However, relatively little attention has been given to nonsymmetric\nDPPs, which relax the symmetric constraint on the kernel. Nonsymmetric DPPs\nallow for both repulsive and attractive item interactions, which can\nsignificantly improve modeling power, resulting in a model that may better fit\nfor some applications. We present a method that enables a tractable algorithm,\nbased on maximum likelihood estimation, for learning nonsymmetric DPPs from\ndata composed of observed subsets. Our method imposes a particular\ndecomposition of the nonsymmetric kernel that enables such tractable learning\nalgorithms, which we analyze both theoretically and experimentally. We evaluate\nour model on synthetic and real-world datasets, demonstrating improved\npredictive performance compared to symmetric DPPs, which have previously shown\nstrong performance on modeling tasks associated with these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:09:16 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 15:16:33 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 02:42:02 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Gartrell", "Mike", ""], ["Brunel", "Victor-Emmanuel", ""], ["Dohmatob", "Elvis", ""], ["Krichene", "Syrine", ""]]}, {"id": "1905.12969", "submitter": "Sara Wade", "authors": "Charles W.L. Gadd and Sara Wade and Alexis Boukouvalas", "title": "Enriched Mixtures of Gaussian Process Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of experts probabilistically divide the input space into regions,\nwhere the assumptions of each expert, or conditional model, need only hold\nlocally. Combined with Gaussian process (GP) experts, this results in a\npowerful and highly flexible model. We focus on alternative mixtures of GP\nexperts, which model the joint distribution of the inputs and targets\nexplicitly. We highlight issues of this approach in multi-dimensional input\nspaces, namely, poor scalability and the need for an unnecessarily large number\nof experts, degrading the predictive performance and increasing uncertainty. We\nconstruct a novel model to address these issues through a nested partitioning\nscheme that automatically infers the number of components at both levels.\nMultiple response types are accommodated through a generalised GP framework,\nwhile multiple input types are included through a factorised exponential family\nstructure. We show the effectiveness of our approach in estimating a\nparsimonious probabilistic description of both synthetic data of increasing\ndimension and an Alzheimer's challenge dataset.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:24:57 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gadd", "Charles W. L.", ""], ["Wade", "Sara", ""], ["Boukouvalas", "Alexis", ""]]}, {"id": "1905.12982", "submitter": "Aaron Klein", "authors": "Aaron Klein and Zhenwen Dai and Frank Hutter and Neil Lawrence and\n  Javier Gonzalez", "title": "Meta-Surrogate Benchmarking for Hyperparameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent progress in hyperparameter optimization (HPO), available\nbenchmarks that resemble real-world scenarios consist of a few and very large\nproblem instances that are expensive to solve. This blocks researchers and\npractitioners not only from systematically running large-scale comparisons that\nare needed to draw statistically significant results but also from reproducing\nexperiments that were conducted before. This work proposes a method to\nalleviate these issues by means of a meta-surrogate model for HPO tasks trained\non off-line generated data. The model combines a probabilistic encoder with a\nmulti-task model such that it can generate inexpensive and realistic tasks of\nthe class of problems of interest. We demonstrate that benchmarking HPO methods\non samples of the generative model allows us to draw more coherent and\nstatistically significant conclusions that can be reached orders of magnitude\nfaster than using the original tasks. We provide evidence of our findings for\nvarious HPO methods on a wide class of problems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:52:23 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 17:45:59 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Klein", "Aaron", ""], ["Dai", "Zhenwen", ""], ["Hutter", "Frank", ""], ["Lawrence", "Neil", ""], ["Gonzalez", "Javier", ""]]}, {"id": "1905.12989", "submitter": "James Murphy", "authors": "Mauro Maggioni and James M. Murphy", "title": "Learning by Active Nonlinear Diffusion", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes an active learning method for high dimensional data,\nbased on intrinsic data geometries learned through diffusion processes on\ngraphs. Diffusion distances are used to parametrize low-dimensional structures\non the dataset, which allow for high-accuracy labelings of the dataset with\nonly a small number of carefully chosen labels. The geometric structure of the\ndata suggests regions that have homogeneous labels, as well as regions with\nhigh label complexity that should be queried for labels. The proposed method\nenjoys theoretical performance guarantees on a general geometric data model, in\nwhich clusters corresponding to semantically meaningful classes are permitted\nto have nonlinear geometries, high ambient dimensionality, and suffer from\nsignificant noise and outlier corruption. The proposed algorithm is implemented\nin a manner that is quasilinear in the number of unlabeled data points, and\nexhibits competitive empirical performance on synthetic datasets and real\nhyperspectral remote sensing images.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:05:33 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Maggioni", "Mauro", ""], ["Murphy", "James M.", ""]]}, {"id": "1905.12995", "submitter": "Nicolas Gillis", "authors": "Junjun Pan, Nicolas Gillis", "title": "Generalized Separable Nonnegative Matrix Factorization", "comments": "31 pages, 12 figures, 4 tables. We have added discussions about the\n  identifiability of the model, we have modified the first synthetic\n  experiment, we have clarified some aspects of the contribution", "journal-ref": "IEEE Trans. on Pattern Analysis and Machine Intelligence 43 (5),\n  pp. 1546-1561, 2021", "doi": "10.1109/TPAMI.2019.2956046", "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is a linear dimensionality technique\nfor nonnegative data with applications such as image analysis, text mining,\naudio source separation and hyperspectral unmixing. Given a data matrix $M$ and\na factorization rank $r$, NMF looks for a nonnegative matrix $W$ with $r$\ncolumns and a nonnegative matrix $H$ with $r$ rows such that $M \\approx WH$.\nNMF is NP-hard to solve in general. However, it can be computed efficiently\nunder the separability assumption which requires that the basis vectors appear\nas data points, that is, that there exists an index set $\\mathcal{K}$ such that\n$W = M(:,\\mathcal{K})$. In this paper, we generalize the separability\nassumption: We only require that for each rank-one factor $W(:,k)H(k,:)$ for\n$k=1,2,\\dots,r$, either $W(:,k) = M(:,j)$ for some $j$ or $H(k,:) = M(i,:)$ for\nsome $i$. We refer to the corresponding problem as generalized separable NMF\n(GS-NMF). We discuss some properties of GS-NMF and propose a convex\noptimization model which we solve using a fast gradient method. We also propose\na heuristic algorithm inspired by the successive projection algorithm. To\nverify the effectiveness of our methods, we compare them with several\nstate-of-the-art separable NMF algorithms on synthetic, document and image data\nsets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:18:25 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 11:22:33 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pan", "Junjun", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1905.13000", "submitter": "Nicol\\`o Pagliana", "authors": "Nicol\\`o Pagliana and Lorenzo Rosasco", "title": "Implicit Regularization of Accelerated Methods in Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning properties of accelerated gradient descent methods for\nlinear least-squares in Hilbert spaces. We analyze the implicit regularization\nproperties of Nesterov acceleration and a variant of heavy-ball in terms of\ncorresponding learning error bounds. Our results show that acceleration can\nprovides faster bias decay than gradient descent, but also suffers of a more\nunstable behavior. As a result acceleration cannot be in general expected to\nimprove learning accuracy with respect to gradient descent, but rather to\nachieve the same accuracy with reduced computations. Our theoretical results\nare validated by numerical simulations. Our analysis is based on studying\nsuitable polynomials induced by the accelerated dynamics and combining spectral\ntechniques with concentration inequalities.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:37:23 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 10:41:40 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 07:34:58 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 03:47:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Pagliana", "Nicol\u00f2", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1905.13020", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Francois Petit, Gaston Ormazabal, Radu State, Jean\n  Hilger", "title": "Visualization of AE's Training on Credit Card Transactions with\n  Persistent Homology", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.09894", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoders are among the most popular neural network architecture for\ndimension reduction. They are composed of two parts: the encoder which maps the\nmodel distribution to a latent manifold and the decoder which maps the latent\nmanifold to a reconstructed distribution. However, auto-encoders are known to\nprovoke chaotically scattered data distribution in the latent manifold\nresulting in an incomplete reconstructed distribution. Current distance\nmeasures fail to detect this problem because they are not able to acknowledge\nthe shape of the data manifolds, i.e. their topological features, and the scale\nat which the manifolds should be analyzed. We propose Persistent Homology for\nWasserstein Auto-Encoders, called PHom-WAE, a new methodology to assess and\nmeasure the data distribution of a generative model. PHom-WAE minimizes the\nWasserstein distance between the true distribution and the reconstructed\ndistribution and uses persistent homology, the study of the topological\nfeatures of a space at different spatial resolutions, to compare the nature of\nthe latent manifold and the reconstructed distribution. Our experiments\nunderline the potential of persistent homology for Wasserstein Auto-Encoders in\ncomparison to Variational Auto-Encoders, another type of generative model. The\nexperiments are conducted on a real-world data set particularly challenging for\ntraditional distance measures and auto-encoders. PHom-WAE is the first\nmethodology to propose a topological distance measure, the bottleneck distance,\nfor Wasserstein Auto-Encoders used to compare decoded samples of high quality\nin the context of credit card transactions.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:48:11 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 06:16:58 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Charlier", "Jeremy", ""], ["Petit", "Francois", ""], ["Ormazabal", "Gaston", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.13021", "submitter": "Amir Najafi", "authors": "Amir Najafi, Shin-ichi Maeda, Masanori Koyama and Takeru Miyato", "title": "Robustness to Adversarial Perturbations in Learning from Incomplete Data", "comments": "41 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the role of unlabeled data in an inference problem, when the presumed\nunderlying distribution is adversarially perturbed? To provide a concrete\nanswer to this question, this paper unifies two major learning frameworks:\nSemi-Supervised Learning (SSL) and Distributionally Robust Learning (DRL). We\ndevelop a generalization theory for our framework based on a number of novel\ncomplexity measures, such as an adversarial extension of Rademacher complexity\nand its semi-supervised analogue. Moreover, our analysis is able to quantify\nthe role of unlabeled data in the generalization under a more general condition\ncompared to the existing theoretical works in SSL. Based on our framework, we\nalso present a hybrid of DRL and EM algorithms that has a guaranteed\nconvergence rate. When implemented with deep neural networks, our method shows\na comparable performance to those of the state-of-the-art on a number of\nreal-world benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:00:05 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Najafi", "Amir", ""], ["Maeda", "Shin-ichi", ""], ["Koyama", "Masanori", ""], ["Miyato", "Takeru", ""]]}, {"id": "1905.13049", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Wei Feng, Zhiqing Sun, Zhi-Hong Deng", "title": "Neural Consciousness Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of reasoning beyond data fitting is substantial to deep learning\nsystems in order to make a leap forward towards artificial general\nintelligence. A lot of efforts have been made to model neural-based reasoning\nas an iterative decision-making process based on recurrent networks and\nreinforcement learning. Instead, inspired by the consciousness prior proposed\nby Yoshua Bengio, we explore reasoning with the notion of attentive awareness\nfrom a cognitive perspective, and formulate it in the form of attentive message\npassing on graphs, called neural consciousness flow (NeuCFlow). Aiming to\nbridge the gap between deep learning systems and reasoning, we propose an\nattentive computation framework with a three-layer architecture, which consists\nof an unconsciousness flow layer, a consciousness flow layer, and an attention\nflow layer. We implement the NeuCFlow model with graph neural networks (GNNs)\nand conditional transition matrices. Our attentive computation greatly reduces\nthe complexity of vanilla GNN-based methods, capable of running on large-scale\ngraphs. We validate our model for knowledge graph reasoning by solving a series\nof knowledge base completion (KBC) tasks. The experimental results show\nNeuCFlow significantly outperforms previous state-of-the-art KBC methods,\nincluding the embedding-based and the path-based. The reproducible code can be\nfound by the link below.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 13:33:55 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Xu", "Xiaoran", ""], ["Feng", "Wei", ""], ["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1905.13082", "submitter": "Manuele Rusci Mr.", "authors": "Manuele Rusci, Alessandro Capotondi, Luca Benini", "title": "Memory-Driven Mixed Low Precision Quantization For Enabling Deep Network\n  Inference On Microcontrollers", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel end-to-end methodology for enabling the\ndeployment of low-error deep networks on microcontrollers. To fit the memory\nand computational limitations of resource-constrained edge-devices, we exploit\nmixed low-bitwidth compression, featuring 8, 4 or 2-bit uniform quantization,\nand we model the inference graph with integer-only operations. Our approach\naims at determining the minimum bit precision of every activation and weight\ntensor given the memory constraints of a device. This is achieved through a\nrule-based iterative procedure, which cuts the number of bits of the most\nmemory-demanding layers, aiming at meeting the memory constraints. After a\nquantization-aware retraining step, the fake-quantized graph is converted into\nan inference integer-only model by inserting the Integer Channel-Normalization\n(ICN) layers, which introduce a negligible loss as demonstrated on INT4\nMobilenetV1 models. We report the latency-accuracy evaluation of\nmixed-precision MobilenetV1 family networks on a STM32H7 microcontroller. Our\nexperimental results demonstrate an end-to-end deployment of an integer-only\nMobilenet network with Top1 accuracy of 68% on a device with only 2MB of FLASH\nmemory and 512kB of RAM, improving by 8% the Top1 accuracy with respect to\npreviously published 8 bit implementations for microcontrollers.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 14:50:42 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Rusci", "Manuele", ""], ["Capotondi", "Alessandro", ""], ["Benini", "Luca", ""]]}, {"id": "1905.13100", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Adri\\'an Csisz\\'arik, Henryk Michalewski, Cezary\n  Kaliszyk, Josef Urban", "title": "Towards Finding Longer Proofs", "comments": "16 pages, 3 figures, published at TABLEAUX2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning (RL) based guidance system for automated\ntheorem proving geared towards Finding Longer Proofs (FLoP). Unlike most\nlearning based approaches, we focus on generalising from very little training\ndata and achieving near complete confidence. We use several simple, structured\ndatasets with very long proofs to show that FLoP can successfully generalise a\nsingle training proof to a large class of related problems. On these\nbenchmarks, FLoP is competitive with strong theorem provers despite using very\nlimited search, due to its ability to solve problems that are prohibitively\nlong for other systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:23:26 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:15:58 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zombori", "Zsolt", ""], ["Csisz\u00e1rik", "Adri\u00e1n", ""], ["Michalewski", "Henryk", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1905.13105", "submitter": "Christophe Zimmer", "authors": "Wei Ouyang, Florian Mueller, Martin Hjelmare, Emma Lundberg,\n  Christophe Zimmer", "title": "ImJoy: an open-source computational platform for the deep learning era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have shown extraordinary potential for analyzing very\ndiverse biomedical data, but their dissemination beyond developers is hindered\nby important computational hurdles. We introduce ImJoy (https://imjoy.io/), a\nflexible and open-source browser-based platform designed to facilitate\nwidespread reuse of deep learning solutions in biomedical research. We\nhighlight ImJoy's main features and illustrate its functionalities with deep\nlearning plugins for mobile and interactive image analysis and genomics.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:35:31 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ouyang", "Wei", ""], ["Mueller", "Florian", ""], ["Hjelmare", "Martin", ""], ["Lundberg", "Emma", ""], ["Zimmer", "Christophe", ""]]}, {"id": "1905.13118", "submitter": "Usman Raza", "authors": "Aftab Khan, Tim Farnham, Roget Kou, Usman Raza, Thajanee Premalal,\n  Aleksandar Stanoev, William Thompson", "title": "Standing on the Shoulders of Giants: AI-driven Calibration of\n  Localisation Technologies", "comments": "Pre-print version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High accuracy localisation technologies exist but are prohibitively expensive\nto deploy for large indoor spaces such as warehouses, factories, and\nsupermarkets to track assets and people. However, these technologies can be\nused to lend their highly accurate localisation capabilities to low-cost,\ncommodity, and less-accurate technologies. In this paper, we bridge this link\nby proposing a technology-agnostic calibration framework based on artificial\nintelligence to assist such low-cost technologies through highly accurate\nlocalisation systems. A single-layer neural network is used to calibrate less\naccurate technology using more accurate one such as BLE using UWB and UWB using\na professional motion tracking system. On a real indoor testbed, we demonstrate\nan increase in accuracy of approximately 70% for BLE and 50% for UWB. Not only\nthe proposed approach requires a very short measurement campaign, the low\ncomplexity of the single-layer neural network also makes it ideal for\ndeployment on constrained devices typically for localisation purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:50:14 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Khan", "Aftab", ""], ["Farnham", "Tim", ""], ["Kou", "Roget", ""], ["Raza", "Usman", ""], ["Premalal", "Thajanee", ""], ["Stanoev", "Aleksandar", ""], ["Thompson", "William", ""]]}, {"id": "1905.13120", "submitter": "Tingting Zhao", "authors": "Tingting Zhao and Alexandre Bouchard-C\\^ot\\'e", "title": "Analysis of high-dimensional Continuous Time Markov Chains using the\n  Local Bouncy Particle Sampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling the parameters of high-dimensional Continuous Time Markov Chains\n(CTMC) is a challenging problem with important applications in many fields of\napplied statistics. In this work a recently proposed type of non-reversible\nrejection-free Markov Chain Monte Carlo (MCMC) sampler, the Bouncy Particle\nSampler (BPS), is brought to bear to this problem. BPS has demonstrated its\nfavorable computational efficiency compared with state-of-the-art MCMC\nalgorithms, however to date applications to real-data scenario were scarce. An\nimportant aspect of the practical implementation of BPS is the simulation of\nevent times. Default implementations use conservative thinning bounds. Such\nbounds can slow down the algorithm and limit the computational performance. Our\npaper develops an algorithm with an exact analytical solution to the random\nevent times in the context of CTMCs. Our local version of BPS algorithm takes\nadvantage of the sparse structure in the target factor graph and we also\nprovide a framework for assessing the computational complexity of local BPS\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:50:57 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 01:56:29 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 14:33:07 GMT"}, {"version": "v4", "created": "Sun, 30 May 2021 03:19:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhao", "Tingting", ""], ["Bouchard-C\u00f4t\u00e9", "Alexandre", ""]]}, {"id": "1905.13121", "submitter": "Benjamin Lansdell", "authors": "Benjamin Lansdell, Sofia Triantafillou, Konrad Kording", "title": "Rarely-switching linear bandits: optimization of causal effects for the\n  real world", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessively changing policies in many real world scenarios is difficult,\nunethical, or expensive. After all, doctor guidelines, tax codes, and price\nlists can only be reprinted so often. We may thus want to only change a policy\nwhen it is probable that the change is beneficial. In cases that a policy is a\nthreshold on contextual variables we can estimate treatment effects for\npopulations lying at the threshold. This allows for a schedule of incremental\npolicy updates that let us optimize a policy while making few detrimental\nchanges. Using this idea, and the theory of linear contextual bandits, we\npresent a conservative policy updating procedure which updates a deterministic\npolicy only when justified. We extend the theory of linear bandits to this\nrarely-switching case, proving that such procedures share the same regret, up\nto constant scaling, as the common LinUCB algorithm. However the algorithm\nmakes far fewer changes to its policy and, of those changes, fewer are\ndetrimental. We provide simulations and an analysis of an infant health\nwell-being causal inference dataset, showing the algorithm efficiently learns a\ngood policy with few changes. Our approach allows efficiently solving problems\nwhere changes are to be avoided, with potential applications in medicine,\neconomics and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:52:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 14:37:09 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lansdell", "Benjamin", ""], ["Triantafillou", "Sofia", ""], ["Kording", "Konrad", ""]]}, {"id": "1905.13125", "submitter": "Ari Biswas", "authors": "Ari Biswas, Thai T Pham, Michael Vogelsong, Benjamin Snyder, Houssam\n  Nassif", "title": "Seeker: Real-Time Interactive Search", "comments": "This paper will appear in KDD 2019", "journal-ref": "Knowledge Discovery in Databases Conference (KDD'19), Anchorage,\n  Alaska, pp. 2867-2875, 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces Seeker, a system that allows users to interactively\nrefine search rankings in real time, through feedback in the form of likes and\ndislikes. When searching online, users may not know how to accurately describe\ntheir product of choice in words. An alternative approach is to search an\nembedding space, allowing the user to query using a representation of the item\n(like a tune for a song, or a picture for an object). However, this approach\nrequires the user to possess an example representation of their desired item.\nAdditionally, most current search systems do not allow the user to dynamically\nadapt the results with further feedback. On the other hand, users often have a\nmental picture of the desired item and are able to answer ordinal questions of\nthe form: \"Is this item similar to what you have in mind?\" With this\nassumption, our algorithm allows for users to provide sequential feedback on\nsearch results to adapt the search feed. We show that our proposed approach\nworks well both qualitatively and quantitatively. Unlike most previous\nrepresentation-based search systems, we can quantify the quality of our\nalgorithm by evaluating humans-in-the-loop experiments.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 23:52:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Biswas", "Ari", ""], ["Pham", "Thai T", ""], ["Vogelsong", "Michael", ""], ["Snyder", "Benjamin", ""], ["Nassif", "Houssam", ""]]}, {"id": "1905.13126", "submitter": "Piper Armstrong", "authors": "Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Courtni\n  Byun, Jordan Boyd-Graber, and Kevin Seppi", "title": "Automatic Evaluation of Local Topic Quality", "comments": "8 pages 4 figures 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are typically evaluated with respect to the global topic\ndistributions that they generate, using metrics such as coherence, but without\nregard to local (token-level) topic assignments. Token-level assignments are\nimportant for downstream tasks such as classification. Even recent models,\nwhich aim to improve the quality of these token-level topic assignments, have\nbeen evaluated only with respect to global metrics. We propose a task designed\nto elicit human judgments of token-level topic assignments. We use a variety of\ntopic model types and parameters and discover that global metrics agree poorly\nwith human assignments.\n  Since human evaluation is expensive we propose a variety of automated metrics\nto evaluate topic models at a local level. Finally, we correlate our proposed\nmetrics with human judgments from the task on several datasets. We show that an\nevaluation based on the percent of topic switches correlates most strongly with\nhuman judgment of local topic quality. We suggest that this new metric, which\nwe call consistency, be adopted alongside global metrics such as topic\ncoherence when evaluating new topic models.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 00:44:47 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lund", "Jeffrey", ""], ["Armstrong", "Piper", ""], ["Fearn", "Wilson", ""], ["Cowley", "Stephen", ""], ["Byun", "Courtni", ""], ["Boyd-Graber", "Jordan", ""], ["Seppi", "Kevin", ""]]}, {"id": "1905.13127", "submitter": "Xiao Zhou", "authors": "Xiao Zhou, Cecilia Mascolo and Zhongxiang Zhao", "title": "Topic-Enhanced Memory Networks for Personalised Point-of-Interest\n  Recommendation", "comments": "11 pages, 6 figures, The 25th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330781", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-Interest (POI) recommender systems play a vital role in people's\nlives by recommending unexplored POIs to users and have drawn extensive\nattention from both academia and industry. Despite their value, however, they\nstill suffer from the challenges of capturing complicated user preferences and\nfine-grained user-POI relationship for spatio-temporal sensitive POI\nrecommendation. Existing recommendation algorithms, including both shallow and\ndeep approaches, usually embed the visiting records of a user into a single\nlatent vector to model user preferences: this has limited power of\nrepresentation and interpretability. In this paper, we propose a novel\ntopic-enhanced memory network (TEMN), a deep architecture to integrate the\ntopic model and memory network capitalising on the strengths of both the global\nstructure of latent patterns and local neighbourhood-based features in a\nnonlinear fashion. We further incorporate a geographical module to exploit\nuser-specific spatial preference and POI-specific spatial influence to enhance\nrecommendations. The proposed unified hybrid model is widely applicable to\nvarious POI recommendation scenarios. Extensive experiments on real-world\nWeChat datasets demonstrate its effectiveness (improvement ratio of 3.25% and\n29.95% for context-aware and sequential recommendation, respectively). Also,\nqualitative analysis of the attention weights and topic modeling provides\ninsight into the model's recommendation process and results.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 18:00:05 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhou", "Xiao", ""], ["Mascolo", "Cecilia", ""], ["Zhao", "Zhongxiang", ""]]}, {"id": "1905.13128", "submitter": "Olivier Gouvert Mr.", "authors": "Olivier Gouvert, Thomas Oberlin, C\\'edric F\\'evotte", "title": "Recommendation from Raw Data with Adaptive Compound Poisson\n  Factorization", "comments": "Accepted for publication at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count data are often used in recommender systems: they are widespread (song\nplay counts, product purchases, clicks on web pages) and can reveal user\npreference without any explicit rating from the user. Such data are known to be\nsparse, over-dispersed and bursty, which makes their direct use in recommender\nsystems challenging, often leading to pre-processing steps such as\nbinarization. The aim of this paper is to build recommender systems from these\nraw data, by means of the recently proposed compound Poisson Factorization\n(cPF). The paper contributions are three-fold: we present a unified framework\nfor discrete data (dcPF), leading to an adaptive and scalable algorithm; we\nshow that our framework achieves a trade-off between Poisson Factorization (PF)\napplied to raw and binarized data; we study four specific instances that are\nrelevant to recommendation and exhibit new links with combinatorics.\nExperiments with three different datasets show that dcPF is able to effectively\nadjust to over-dispersion, leading to better recommendation scores when\ncompared with PF on either raw or binarized data.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:00:49 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 09:58:51 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gouvert", "Olivier", ""], ["Oberlin", "Thomas", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1905.13129", "submitter": "Jiani Zhang", "authors": "Jiani Zhang, Xingjian Shi, Shenglin Zhao, Irwin King", "title": "STAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for\n  Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new STAcked and Reconstructed Graph Convolutional Networks\n(STAR-GCN) architecture to learn node representations for boosting the\nperformance in recommender systems, especially in the cold start scenario.\nSTAR-GCN employs a stack of GCN encoder-decoders combined with intermediate\nsupervision to improve the final prediction performance. Unlike the graph\nconvolutional matrix completion model with one-hot encoding node inputs, our\nSTAR-GCN learns low-dimensional user and item latent factors as the input to\nrestrain the model space complexity. Moreover, our STAR-GCN can produce node\nembeddings for new nodes by reconstructing masked input node embeddings, which\nessentially tackles the cold start problem. Furthermore, we discover a label\nleakage issue when training GCN-based models for link prediction tasks and\npropose a training strategy to avoid the issue. Empirical results on multiple\nrating prediction benchmarks demonstrate our model achieves state-of-the-art\nperformance in four out of five real-world datasets and significant\nimprovements in predicting ratings in the cold start scenario. The code\nimplementation is available in https://github.com/jennyzhang0215/STAR-GCN.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:21:33 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Zhang", "Jiani", ""], ["Shi", "Xingjian", ""], ["Zhao", "Shenglin", ""], ["King", "Irwin", ""]]}, {"id": "1905.13130", "submitter": "Raehyun Kim", "authors": "Seoungjun Yun, Raehyun Kim, Miyoung Ko, Jaewoo Kang", "title": "SAIN: Self-Attentive Integration Network for Recommendation", "comments": "SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331342", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing importance of personalized recommendation, numerous\nrecommendation models have been proposed recently. Among them, Matrix\nFactorization (MF) based models are the most widely used in the recommendation\nfield due to their high performance. However, MF based models suffer from cold\nstart problems where user-item interactions are sparse. To deal with this\nproblem, content based recommendation models which use the auxiliary attributes\nof users and items have been proposed. Since these models use auxiliary\nattributes, they are effective in cold start settings. However, most of the\nproposed models are either unable to capture complex feature interactions or\nnot properly designed to combine user-item feedback information with content\ninformation. In this paper, we propose Self-Attentive Integration Network\n(SAIN) which is a model that effectively combines user-item feedback\ninformation and auxiliary information for recommendation task. In SAIN, a\nself-attention mechanism is used in the feature-level interaction layer to\neffectively consider interactions between multiple features, while the\ninformation integration layer adaptively combines content and feedback\ninformation. The experimental results on two public datasets show that our\nmodel outperforms the state-of-the-art models by 2.13%\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:27:36 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 07:58:23 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Yun", "Seoungjun", ""], ["Kim", "Raehyun", ""], ["Ko", "Miyoung", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1905.13131", "submitter": "Mathias Kraus", "authors": "Mathias Kraus, Stefan Feuerriegel", "title": "Personalized Purchase Prediction of Market Baskets with\n  Wasserstein-Based Sequence Matching", "comments": "Accepted for oral presentation at 25th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD 2019)", "journal-ref": null, "doi": "10.1145/3292500.3330791", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization in marketing aims at improving the shopping experience of\ncustomers by tailoring services to individuals. In order to achieve this,\nbusinesses must be able to make personalized predictions regarding the next\npurchase. That is, one must forecast the exact list of items that will comprise\nthe next purchase, i.e., the so-called market basket. Despite its relevance to\nfirm operations, this problem has received surprisingly little attention in\nprior research, largely due to its inherent complexity. In fact,\nstate-of-the-art approaches are limited to intuitive decision rules for pattern\nextraction. However, the simplicity of the pre-coded rules impedes performance,\nsince decision rules operate in an autoregressive fashion: the rules can only\nmake inferences from past purchases of a single customer without taking into\naccount the knowledge transfer that takes place between customers. In contrast,\nour research overcomes the limitations of pre-set rules by contributing a novel\npredictor of market baskets from sequential purchase histories: our predictions\nare based on similarity matching in order to identify similar purchase habits\namong the complete shopping histories of all customers. Our contributions are\nas follows: (1) We propose similarity matching based on subsequential dynamic\ntime warping (SDTW) as a novel predictor of market baskets. Thereby, we can\neffectively identify cross-customer patterns. (2) We leverage the Wasserstein\ndistance for measuring the similarity among embedded purchase histories. (3) We\ndevelop a fast approximation algorithm for computing a lower bound of the\nWasserstein distance in our setting. An extensive series of computational\nexperiments demonstrates the effectiveness of our approach. The accuracy of\nidentifying the exact market baskets based on state-of-the-art decision rules\nfrom the literature is outperformed by a factor of 4.0.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:08:18 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 16:05:25 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kraus", "Mathias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1905.13132", "submitter": "Kevin Joseph", "authors": "Kevin Joseph, Hui Jiang", "title": "Content based News Recommendation via Shortest Entity Distance over\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-based news recommendation systems need to recommend news articles\nbased on the topics and content of articles without using user specific\ninformation. Many news articles describe the occurrence of specific events and\nnamed entities including people, places or objects. In this paper, we propose a\ngraph traversal algorithm as well as a novel weighting scheme for cold-start\ncontent based news recommendation utilizing these named entities. Seeking to\ncreate a higher degree of user-specific relevance, our algorithm computes the\nshortest distance between named entities, across news articles, over a large\nknowledge graph. Moreover, we have created a new human annotated data set for\nevaluating content based news recommendation systems. Experimental results show\nour method is suitable to tackle the hard cold-start problem and it produces\nstronger Pearson correlation to human similarity scores than other cold-start\nmethods. Our method is also complementary and a combination with the\nconventional cold-start recommendation methods may yield significant\nperformance gains. The dataset, CNRec, is available at:\nhttps://github.com/kevinj22/CNRec\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:06:06 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Joseph", "Kevin", ""], ["Jiang", "Hui", ""]]}, {"id": "1905.13133", "submitter": "Kai-Lang Yao", "authors": "Kai-Lang Yao and Wu-Jun Li", "title": "Collaborative Self-Attention for Recommender Systems", "comments": "There are large modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RS), which have been an essential part in a wide range\nof applications, can be formulated as a matrix completion (MC) problem. To\nboost the performance of MC, matrix completion with side information, called\ninductive matrix completion (IMC), was further proposed. In real applications,\nthe factorized version of IMC is more favored due to its efficiency of\noptimization and implementation. Regarding the factorized version, traditional\nIMC method can be interpreted as learning an individual representation for each\nfeature, which is independent from each other. Moreover, representations for\nthe same features are shared across all users/items. However, the independent\ncharacteristic for features and shared characteristic for the same features\nacross all users/items may limit the expressiveness of the model. The\nlimitation also exists in variants of IMC, such as deep learning based IMC\nmodels. To break the limitation, we generalize recent advances of\nself-attention mechanism to IMC and propose a context-aware model called\ncollaborative self-attention (CSA), which can jointly learn context-aware\nrepresentations for features and perform inductive matrix completion process.\nExtensive experiments on three large-scale datasets from real RS applications\ndemonstrate effectiveness of CSA.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:05:26 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:44:32 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yao", "Kai-Lang", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1905.13136", "submitter": "Amber Nigam", "authors": "Amber Nigam, Aakash Roy, Arpan Saxena, and Hartaran Singh", "title": "Job Recommendation through Progression of Job Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job recommendation has traditionally been treated as a filter-based match or\nas a recommendation based on the features of jobs and candidates as discrete\nentities. In this paper, we introduce a methodology where we leverage the\nprogression of job selection by candidates using machine learning.\nAdditionally, our recommendation is composed of several other\nsub-recommendations that contribute to at least one of a) making\nrecommendations serendipitous for the end user b) overcoming cold-start for\nboth candidates and jobs. One of the unique selling propositions of our\nmethodology is the way we have used skills as embedded features and derived\nlatent competencies from them, thereby attempting to expand the skills of\ncandidates and jobs to achieve more coverage in the skill domain. We have\ndeployed our model in a real-world job recommender system and have achieved the\nbest click-through rate through a blended approach of machine-learned\nrecommendations and other sub-recommendations. For recommending jobs through\nmachine learning that forms a significant part of our recommendation, we\nachieve the best results through Bi-LSTM with attention.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:36:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 18:24:31 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Nigam", "Amber", ""], ["Roy", "Aakash", ""], ["Saxena", "Arpan", ""], ["Singh", "Hartaran", ""]]}, {"id": "1905.13149", "submitter": "Fangda Han", "authors": "Fangda Han, Ricardo Guerrero, Vladimir Pavlovic", "title": "The Art of Food: Meal Image Synthesis from Ingredients", "comments": "12 pages, 6 figures, 2 tables, under review as a conference paper at\n  BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a new computational framework, based on generative\ndeep models, for synthesis of photo-realistic food meal images from textual\ndescriptions of its ingredients. Previous works on synthesis of images from\ntext typically rely on pre-trained text models to extract text features,\nfollowed by a generative neural networks (GANs) aimed to generate realistic\nimages conditioned on the text features. These works mainly focus on generating\nspatially compact and well-defined categories of objects, such as birds or\nflowers. In contrast, meal images are significantly more complex, consisting of\nmultiple ingredients whose appearance and spatial qualities are further\nmodified by cooking methods. We propose a method that first builds an\nattention-based ingredients-image association model, which is then used to\ncondition a generative neural network tasked with synthesizing meal images.\nFurthermore, a cycle-consistent constraint is added to further improve image\nquality and control appearance. Extensive experiments show our model is able to\ngenerate meal image corresponding to the ingredients, which could be used to\naugment existing dataset for solving other computational food analysis\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:57:51 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Han", "Fangda", ""], ["Guerrero", "Ricardo", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1905.13159", "submitter": "Subhojyoti Mukherjee", "authors": "Subhojyoti Mukherjee, Odalric-Ambrym Maillard", "title": "Distribution-dependent and Time-uniform Bounds for Piecewise i.i.d\n  Bandits", "comments": "Proceedings of the Reinforcement Learning for Real Life (RL4RealLife)\n  Workshop in the 36th International Conference on Machine Learning, Long\n  Beach, California, USA, 2019", "journal-ref": "Proceedings of the Reinforcement Learning for Real Life\n  (RL4RealLife) Workshop in the 36th International Conference on Machine\n  Learning, Long Beach, California, USA, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setup of stochastic multi-armed bandits in the case when\nreward distributions are piecewise i.i.d. and bounded with unknown\nchangepoints. We focus on the case when changes happen simultaneously on all\narms, and in stark contrast with the existing literature, we target\ngap-dependent (as opposed to only gap-independent) regret bounds involving the\nmagnitude of changes $(\\Delta^{chg}_{i,g})$ and optimality-gaps\n($\\Delta^{opt}_{i,g}$). Diverging from previous works, we assume the more\nrealistic scenario that there can be undetectable changepoint gaps and under a\ndifferent set of assumptions, we show that as long as the compounded delayed\ndetection for each changepoint is bounded there is no need for forced\nexploration to actively detect changepoints. We introduce two adaptations of\nUCB-strategies that employ scan-statistics in order to actively detect the\nchangepoints, without knowing in advance the changepoints and also the mean\nbefore and after any change. Our first method \\UCBLCPD does not know the number\nof changepoints $G$ or time horizon $T$ and achieves the first time-uniform\nconcentration bound for this setting using the Laplace method of integration.\nThe second strategy \\ImpCPD makes use of the knowledge of $T$ to achieve the\norder optimal regret bound of $\\min\\big\\lbrace O(\\sum\\limits_{i=1}^{K}\n\\sum\\limits_{g=1}^{G}\\frac{\\log(T/H_{1,g})}{\\Delta^{opt}_{i,g}}),\nO(\\sqrt{GT})\\big\\rbrace$, (where $H_{1,g}$ is the problem complexity) thereby\nclosing an important gap with respect to the lower bound in a specific\nchallenging setting. Our theoretical findings are supported by numerical\nexperiments on synthetic and real-life datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:30:19 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:54:31 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Mukherjee", "Subhojyoti", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1905.13160", "submitter": "Wenqi Fan", "authors": "Wenqi Fan, Tyler Derr, Yao Ma, Jianping Wang, Jiliang Tang and Qing Li", "title": "Deep Adversarial Social Recommendation", "comments": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed rapid developments on social recommendation\ntechniques for improving the performance of recommender systems due to the\ngrowing influence of social networks to our daily life. The majority of\nexisting social recommendation methods unify user representation for the\nuser-item interactions (item domain) and user-user connections (social domain).\nHowever, it may restrain user representation learning in each respective\ndomain, since users behave and interact differently in the two domains, which\nmakes their representations to be heterogeneous. In addition, most of\ntraditional recommender systems can not efficiently optimize these objectives,\nsince they utilize negative sampling technique which is unable to provide\nenough informative guidance towards the training during the optimization\nprocess. In this paper, to address the aforementioned challenges, we propose a\nnovel deep adversarial social recommendation framework DASO. It adopts a\nbidirectional mapping method to transfer users' information between social\ndomain and item domain using adversarial learning. Comprehensive experiments on\ntwo real-world datasets show the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:32:19 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Fan", "Wenqi", ""], ["Derr", "Tyler", ""], ["Ma", "Yao", ""], ["Wang", "Jianping", ""], ["Tang", "Jiliang", ""], ["Li", "Qing", ""]]}, {"id": "1905.13167", "submitter": "Niranjani Prasad", "authors": "Niranjani Prasad, Barbara E Engelhardt, Finale Doshi-Velez", "title": "Defining Admissible Rewards for High Confidence Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key impediment to reinforcement learning (RL) in real applications with\nlimited, batch data is defining a reward function that reflects what we\nimplicitly know about reasonable behaviour for a task and allows for robust\noff-policy evaluation. In this work, we develop a method to identify an\nadmissible set of reward functions for policies that (a) do not diverge too far\nfrom past behaviour, and (b) can be evaluated with high confidence, given only\na collection of past trajectories. Together, these ensure that we propose\npolicies that we trust to be implemented in high-risk settings. We demonstrate\nour approach to reward design on synthetic domains as well as in a critical\ncare context, for a reward that consolidates clinical objectives to learn a\npolicy for weaning patients from mechanical ventilation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:51:49 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Prasad", "Niranjani", ""], ["Engelhardt", "Barbara E", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1905.13168", "submitter": "Jiyeon Han", "authors": "Jiyeon Han, Kyowoon Lee, Anh Tong, Jaesik Choi", "title": "Confirmatory Bayesian Online Change Point Detection in the Covariance\n  Structure of Gaussian Processes", "comments": "IJCAI 2019 Comments: 12 pages, LaTeX; Revised conditions of Theorems\n  in section 4, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of sequential data, the detection of abrupt changes is\nimportant in predicting future changes. In this paper, we propose statistical\nhypothesis tests for detecting covariance structure changes in locally smooth\ntime series modeled by Gaussian Processes (GPs). We provide theoretically\njustified thresholds for the tests, and use them to improve Bayesian Online\nChange Point Detection (BOCPD) by confirming statistically significant changes\nand non-changes. Our Confirmatory BOCPD (CBOCPD) algorithm finds multiple\nstructural breaks in GPs even when hyperparameters are not tuned precisely. We\nalso provide conditions under which CBOCPD provides the lower prediction error\ncompared to BOCPD. Experimental results on synthetic and real-world datasets\nshow that our new tests correctly detect changes in the covariance structure in\nGPs. The proposed algorithm also outperforms existing methods for the\nprediction of nonstationarity in terms of both regression error and log\nlikelihood.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:52:42 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 06:35:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Han", "Jiyeon", ""], ["Lee", "Kyowoon", ""], ["Tong", "Anh", ""], ["Choi", "Jaesik", ""]]}, {"id": "1905.13177", "submitter": "Jenny Liu", "authors": "Jenny Liu, Aviral Kumar, Jimmy Ba, Jamie Kiros, Kevin Swersky", "title": "Graph Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce graph normalizing flows: a new, reversible graph neural network\nmodel for prediction and generation. On supervised tasks, graph normalizing\nflows perform similarly to message passing neural networks, but at a\nsignificantly reduced memory footprint, allowing them to scale to larger\ngraphs. In the unsupervised case, we combine graph normalizing flows with a\nnovel graph auto-encoder to create a generative model of graph structures. Our\nmodel is permutation-invariant, generating entire graphs with a single\nfeed-forward pass, and achieves competitive results with the state-of-the art\nauto-regressive models, while being better suited to parallel computing\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:03:41 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Jenny", ""], ["Kumar", "Aviral", ""], ["Ba", "Jimmy", ""], ["Kiros", "Jamie", ""], ["Swersky", "Kevin", ""]]}, {"id": "1905.13179", "submitter": "Jesse Hostetler", "authors": "Jesse Hostetler (SRI International, Princeton, NJ, USA)", "title": "Toward Runtime-Throttleable Neural Networks", "comments": "13 pages, 5 figures, submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": "SRI588", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural network (NN) methods have matured, there has been increasing\ninterest in deploying NN solutions to \"edge computing\" platforms such as mobile\nphones or embedded controllers. These platforms are often resource-constrained,\nespecially in energy storage and power, but state-of-the-art NN architectures\nare designed with little regard for resource use. Existing techniques for\nreducing the resource footprint of NN models produce static models that occupy\na single point in the trade-space between performance and resource use. This\npaper presents an approach to creating runtime-throttleable NNs that can\nadaptively balance performance and resource use in response to a control\nsignal. Throttleable networks allow intelligent resource management, for\nexample by allocating fewer resources in \"easy\" conditions or when battery\npower is low. We describe a generic formulation of throttling via block-level\ngating, apply it to create throttleable versions of several standard CNN\narchitectures, and demonstrate that our approach allows smooth performance\nthrottling over a wide range of operating points in image classification and\nobject detection tasks, with only a small loss in peak accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:06:18 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Hostetler", "Jesse", "", "SRI International, Princeton, NJ, USA"]]}, {"id": "1905.13181", "submitter": "Sophie Fosson", "authors": "Sophie M. Fosson and Mohammad Abuabiah", "title": "Recovery of binary sparse signals from compressed linear measurements\n  via polynomial optimization", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2919943", "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recovery of signals with finite-valued components from few linear\nmeasurements is a problem with widespread applications and interesting\nmathematical characteristics. In the compressed sensing framework, tailored\nmethods have been recently proposed to deal with the case of finite-valued\nsparse signals. In this work, we focus on binary sparse signals and we propose\na novel formulation, based on polynomial optimization. This approach is\nanalyzed and compared to the state-of-the-art binary compressed sensing\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:09:17 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Fosson", "Sophie M.", ""], ["Abuabiah", "Mohammad", ""]]}, {"id": "1905.13183", "submitter": "Minjie Xu", "authors": "Minjie Xu and Gary Kazantsev", "title": "Understanding Goal-Oriented Active Learning via Influence Functions", "comments": "14 pages, to be presented at the NeurIPS 2019 workshop on \"ML with\n  Guarantees\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) concerns itself with learning a model from as few\nlabelled data as possible through actively and iteratively querying an oracle\nwith selected unlabelled samples. In this paper, we focus on analyzing a\npopular type of AL in which the utility of a sample is measured by a specified\ngoal achieved by the retrained model after accounting for the sample's marginal\ninfluence. Such AL strategies attract a lot of attention thanks to their\nintuitive motivations, yet they also suffer from impractically high\ncomputational costs due to their need for many iterations of model retraining.\nWith the help of influence functions, we present an effective approximation\nthat bypasses model retraining altogether, and propose a general efficient\nimplementation that makes such AL strategies applicable in practice, both in\nthe serial and the more challenging batch-mode setting. Additionally, we\npresent both theoretical and empirical findings which call into question a few\ncommon practices and beliefs about such AL strategies.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:09:39 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 18:14:52 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 22:10:07 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Xu", "Minjie", ""], ["Kazantsev", "Gary", ""]]}, {"id": "1905.13192", "submitter": "Simon Du", "authors": "Simon S. Du, Kangcheng Hou, Barnab\\'as P\\'oczos, Ruslan Salakhutdinov,\n  Ruosong Wang, Keyulu Xu", "title": "Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph\n  Kernels", "comments": "In NeurIPS 2019. Code available: https://github.com/KangchengHou/gntk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While graph kernels (GKs) are easy to train and enjoy provable theoretical\nguarantees, their practical performances are limited by their expressive power,\nas the kernel function often depends on hand-crafted combinatorial features of\ngraphs. Compared to graph kernels, graph neural networks (GNNs) usually achieve\nbetter practical performance, as GNNs use multi-layer architectures and\nnon-linear activation functions to extract high-order information of graphs as\nfeatures. However, due to the large number of hyper-parameters and the\nnon-convex nature of the training procedure, GNNs are harder to train.\nTheoretical guarantees of GNNs are also not well-understood. Furthermore, the\nexpressive power of GNNs scales with the number of parameters, and thus it is\nhard to exploit the full power of GNNs when computing resources are limited.\nThe current paper presents a new class of graph kernels, Graph Neural Tangent\nKernels (GNTKs), which correspond to infinitely wide multi-layer GNNs trained\nby gradient descent. GNTKs enjoy the full expressive power of GNNs and inherit\nadvantages of GKs. Theoretically, we show GNTKs provably learn a class of\nsmooth functions on graphs. Empirically, we test GNTKs on graph classification\ndatasets and show they achieve strong performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:23:23 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 15:30:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Du", "Simon S.", ""], ["Hou", "Kangcheng", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""], ["Xu", "Keyulu", ""]]}, {"id": "1905.13194", "submitter": "Giulia Luise", "authors": "Giulia Luise, Saverio Salzo, Massimiliano Pontil, Carlo Ciliberto", "title": "Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm", "comments": "46 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm to estimate the barycenter of arbitrary\nprobability distributions with respect to the Sinkhorn divergence. Based on a\nFrank-Wolfe optimization strategy, our approach proceeds by populating the\nsupport of the barycenter incrementally, without requiring any pre-allocation.\nWe consider discrete as well as continuous distributions, proving convergence\nrates of the proposed algorithm in both settings. Key elements of our analysis\nare a new result showing that the Sinkhorn divergence on compact domains has\nLipschitz continuous gradient with respect to the Total Variation and a\ncharacterization of the sample complexity of Sinkhorn potentials. Experiments\nvalidate the effectiveness of our method in practice.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:27:03 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Luise", "Giulia", ""], ["Salzo", "Saverio", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "1905.13195", "submitter": "Raanan Rohekar", "authors": "Raanan Y. Rohekar, Yaniv Gurwicz, Shami Nisimov, Gal Novik", "title": "Modeling Uncertainty by Learning a Hierarchy of Deep Neural Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Modeling uncertainty in deep neural networks, despite recent important\nadvances, is still an open problem. Bayesian neural networks are a powerful\nsolution, where the prior over network weights is a design choice, often a\nnormal distribution or other distribution encouraging sparsity. However, this\nprior is agnostic to the generative process of the input data, which might lead\nto unwarranted generalization for out-of-distribution tested data. We suggest\nthe presence of a confounder for the relation between the input data and the\ndiscriminative function given the target label. We propose an approach for\nmodeling this confounder by sharing neural connectivity patterns between the\ngenerative and discriminative networks. This approach leads to a new deep\narchitecture, where networks are sampled from the posterior of local causal\nstructures, and coupled into a compact hierarchy. We demonstrate that sampling\nnetworks from this hierarchy, proportionally to their posterior, is efficient\nand enables estimating various types of uncertainties. Empirical evaluations of\nour method demonstrate significant improvement compared to state-of-the-art\ncalibration and out-of-distribution detection methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:36:19 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 12:27:49 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rohekar", "Raanan Y.", ""], ["Gurwicz", "Yaniv", ""], ["Nisimov", "Shami", ""], ["Novik", "Gal", ""]]}, {"id": "1905.13196", "submitter": "Peter Bubenik", "authors": "Peter Bubenik, Michael Hull, Dhruv Patel, and Benjamin Whittle", "title": "Persistent homology detects curvature", "comments": "22 pages, corrections thanks to anonymous referees", "journal-ref": "Inverse Problems, 36, 025008 (2020)", "doi": "10.1088/1361-6420/ab4ac0", "report-no": null, "categories": "cs.CG cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topological data analysis, persistent homology is used to study the \"shape\nof data\". Persistent homology computations are completely characterized by a\nset of intervals called a bar code. It is often said that the long intervals\nrepresent the \"topological signal\" and the short intervals represent \"noise\".\nWe give evidence to dispute this thesis, showing that the short intervals\nencode geometric information. Specifically, we prove that persistent homology\ndetects the curvature of disks from which points have been sampled. We describe\na general computational framework for solving inverse problems using the\naverage persistence landscape, a continuous mapping from metric spaces with a\nprobability measure to a Hilbert space. In the present application, the average\npersistence landscapes of points sampled from disks of constant curvature\nresults in a path in this Hilbert space which may be learned using standard\ntools from statistical and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:36:58 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:49:29 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 16:04:05 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bubenik", "Peter", ""], ["Hull", "Michael", ""], ["Patel", "Dhruv", ""], ["Whittle", "Benjamin", ""]]}, {"id": "1905.13200", "submitter": "Vineeth S. Bhaskara", "authors": "Vineeth S. Bhaskara, Sneha Desai", "title": "Exploiting Uncertainty of Loss Landscape for Stochastic Optimization", "comments": "15 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel variants of momentum by incorporating the variance of the\nstochastic loss function. The variance characterizes the confidence or\nuncertainty of the local features of the averaged loss surface across the\ni.i.d. subsets of the training data defined by the mini-batches. We show two\napplications of the gradient of the variance of the loss function. First, as a\nbias to the conventional momentum update to encourage conformity of the local\nfeatures of the loss function (e.g. local minima) across mini-batches to\nimprove generalization and the cumulative training progress made per epoch.\nSecond, as an alternative direction for \"exploration\" in the parameter space,\nespecially, for non-convex objectives, that exploits both the optimistic and\npessimistic views of the loss function in the face of uncertainty. We also\nintroduce a novel data-driven stochastic regularization technique through the\nparameter update rule that is model-agnostic and compatible with arbitrary\narchitectures. We further establish connections to probability distributions\nover loss functions and the REINFORCE policy gradient update with baseline in\nRL. Finally, we incorporate the new variants of momentum proposed into Adam,\nand empirically show that our methods improve the rate of convergence of\ntraining based on our experiments on the MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:42:41 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bhaskara", "Vineeth S.", ""], ["Desai", "Sneha", ""]]}, {"id": "1905.13205", "submitter": "Cristian Zanoci", "authors": "Eric R. Anschuetz and Cristian Zanoci", "title": "Near-Term Quantum-Classical Associative Adversarial Networks", "comments": "11 pages, 9 figures", "journal-ref": "Phys. Rev. A 100, 052327 (2019)", "doi": "10.1103/PhysRevA.100.052327", "report-no": "MIT-CTP/5125", "categories": "cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new hybrid quantum-classical adversarial machine learning\narchitecture called a quantum-classical associative adversarial network (QAAN).\nThis architecture consists of a classical generative adversarial network with a\nsmall auxiliary quantum Boltzmann machine that is simultaneously trained on an\nintermediate layer of the discriminator of the generative network. We\nnumerically study the performance of QAANs compared to their classical\ncounterparts on the MNIST and CIFAR-10 data sets, and show that QAANs attain a\nhigher quality of learning when evaluated using the Inception score and the\nFr\\'{e}chet Inception distance. As the QAAN architecture only relies on\nsampling simple local observables of a small quantum Boltzmann machine, this\nmodel is particularly amenable for implementation on the current and next\ngenerations of quantum devices.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:48:51 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Anschuetz", "Eric R.", ""], ["Zanoci", "Cristian", ""]]}, {"id": "1905.13209", "submitter": "Michael S. Ryoo", "authors": "Michael S. Ryoo, AJ Piergiovanni, Mingxing Tan, Anelia Angelova", "title": "AssembleNet: Searching for Multi-Stream Neural Connectivity in Video\n  Architectures", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to represent videos is a very challenging task both algorithmically\nand computationally. Standard video CNN architectures have been designed by\ndirectly extending architectures devised for image understanding to include the\ntime dimension, using modules such as 3D convolutions, or by using two-stream\ndesign to capture both appearance and motion in videos. We interpret a video\nCNN as a collection of multi-stream convolutional blocks connected to each\nother, and propose the approach of automatically finding neural architectures\nwith better connectivity and spatio-temporal interactions for video\nunderstanding. This is done by evolving a population of overly-connected\narchitectures guided by connection weight learning. Architectures combining\nrepresentations that abstract different input types (i.e., RGB and optical\nflow) at multiple temporal resolutions are searched for, allowing different\ntypes or sources of information to interact with each other. Our method,\nreferred to as AssembleNet, outperforms prior approaches on public video\ndatasets, in some cases by a great margin. We obtain 58.6% mAP on Charades and\n34.27% accuracy on Moments-in-Time.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:51:03 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 17:54:13 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 17:48:45 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 15:56:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ryoo", "Michael S.", ""], ["Piergiovanni", "AJ", ""], ["Tan", "Mingxing", ""], ["Angelova", "Anelia", ""]]}, {"id": "1905.13210", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Quanquan Gu", "title": "Generalization Bounds of Stochastic Gradient Descent for Wide and Deep\n  Neural Networks", "comments": "25 pages, 1 figure. In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the training and generalization of deep neural networks (DNNs) in\nthe over-parameterized regime, where the network width (i.e., number of hidden\nnodes per layer) is much larger than the number of training data points. We\nshow that, the expected $0$-$1$ loss of a wide enough ReLU network trained with\nstochastic gradient descent (SGD) and random initialization can be bounded by\nthe training loss of a random feature model induced by the network gradient at\ninitialization, which we call a neural tangent random feature (NTRF) model. For\ndata distributions that can be classified by NTRF model with sufficiently small\nerror, our result yields a generalization error bound in the order of\n$\\tilde{\\mathcal{O}}(n^{-1/2})$ that is independent of the network width. Our\nresult is more general and sharper than many existing generalization error\nbounds for over-parameterized neural networks. In addition, we establish a\nstrong connection between our generalization error bound and the neural tangent\nkernel (NTK) proposed in recent work.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:53:07 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 17:34:56 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 18:34:49 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1905.13211", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "What Can Neural Networks Reason About?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:53:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 21:50:31 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 20:42:29 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 06:56:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Xu", "Keyulu", ""], ["Li", "Jingling", ""], ["Zhang", "Mozhi", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.13214", "submitter": "Ilija Radosavovic", "authors": "Ilija Radosavovic, Justin Johnson, Saining Xie, Wan-Yen Lo, Piotr\n  Doll\\'ar", "title": "On Network Design Spaces for Visual Recognition", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past several years progress in designing better neural network\narchitectures for visual recognition has been substantial. To help sustain this\nrate of progress, in this work we propose to reexamine the methodology for\ncomparing network architectures. In particular, we introduce a new comparison\nparadigm of distribution estimates, in which network design spaces are compared\nby applying statistical techniques to populations of sampled models, while\ncontrolling for confounding factors like network complexity. Compared to\ncurrent methodologies of comparing point and curve estimates of model families,\ndistribution estimates paint a more complete picture of the entire design\nlandscape. As a case study, we examine design spaces used in neural\narchitecture search (NAS). We find significant statistical differences between\nrecent NAS design space variants that have been largely overlooked.\nFurthermore, our analysis reveals that the design spaces for standard model\nfamilies like ResNeXt can be comparable to the more complex ones used in recent\nNAS work. We hope these insights into distribution analysis will enable more\nrobust progress toward discovering better networks for visual recognition.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:56:17 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Radosavovic", "Ilija", ""], ["Johnson", "Justin", ""], ["Xie", "Saining", ""], ["Lo", "Wan-Yen", ""], ["Doll\u00e1r", "Piotr", ""]]}, {"id": "1905.13229", "submitter": "Gautam Kamath", "authors": "Mark Bun, Gautam Kamath, Thomas Steinke, Zhiwei Steven Wu", "title": "Private Hypothesis Selection", "comments": "Appeared in NeurIPS 2019. Final version to appear in IEEE\n  Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a differentially private algorithm for hypothesis selection. Given\nsamples from an unknown probability distribution $P$ and a set of $m$\nprobability distributions $\\mathcal{H}$, the goal is to output, in a\n$\\varepsilon$-differentially private manner, a distribution from $\\mathcal{H}$\nwhose total variation distance to $P$ is comparable to that of the best such\ndistribution (which we denote by $\\alpha$). The sample complexity of our basic\nalgorithm is $O\\left(\\frac{\\log m}{\\alpha^2} + \\frac{\\log m}{\\alpha\n\\varepsilon}\\right)$, representing a minimal cost for privacy when compared to\nthe non-private algorithm. We also can handle infinite hypothesis classes\n$\\mathcal{H}$ by relaxing to $(\\varepsilon,\\delta)$-differential privacy.\n  We apply our hypothesis selection algorithm to give learning algorithms for a\nnumber of natural distribution classes, including Gaussians, product\ndistributions, sums of independent random variables, piecewise polynomials, and\nmixture classes. Our hypothesis selection procedure allows us to generically\nconvert a cover for a class to a learning algorithm, complementing known\nlearning lower bounds which are in terms of the size of the packing number of\nthe class. As the covering and packing numbers are often closely related, for\nconstant $\\alpha$, our algorithms achieve the optimal sample complexity for\nmany classes of interest. Finally, we describe an application to private\ndistribution-free PAC learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:00:00 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 23:12:32 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 23:50:16 GMT"}, {"version": "v4", "created": "Thu, 31 Dec 2020 05:22:24 GMT"}, {"version": "v5", "created": "Mon, 4 Jan 2021 18:30:15 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bun", "Mark", ""], ["Kamath", "Gautam", ""], ["Steinke", "Thomas", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1905.13251", "submitter": "Tianyi Yao", "authors": "Tianyi Yao and Genevera I. Allen", "title": "Clustered Gaussian Graphical Model via Symmetric Convex Clustering", "comments": "To appear in IEEE DSW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge of functional groupings of neurons can shed light on structures of\nneural circuits and is valuable in many types of neuroimaging studies. However,\naccurately determining which neurons carry out similar neurological tasks via\ncontrolled experiments is both labor-intensive and prohibitively expensive on a\nlarge scale. Thus, it is of great interest to cluster neurons that have similar\nconnectivity profiles into functionally coherent groups in a data-driven\nmanner. In this work, we propose the clustered Gaussian graphical model (GGM)\nand a novel symmetric convex clustering penalty in an unified convex\noptimization framework for inferring functional clusters among neurons from\nneural activity data. A parallelizable multi-block Alternating Direction Method\nof Multipliers (ADMM) algorithm is used to solve the corresponding convex\noptimization problem. In addition, we establish convergence guarantees for the\nproposed ADMM algorithm. Experimental results on both synthetic data and\nreal-world neuroscientific data demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:15:01 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Yao", "Tianyi", ""], ["Allen", "Genevera I.", ""]]}, {"id": "1905.13267", "submitter": "Blake Mason", "authors": "Blake Mason, Ardhendu Tripathy, and Robert Nowak", "title": "Learning Nearest Neighbor Graphs from Noisy Distance Samples", "comments": "21 total pages (8 main pages + appendices), 7 figures, submitted to\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the nearest neighbor graph of a dataset\nof n items. The metric is unknown, but we can query an oracle to obtain a noisy\nestimate of the distance between any pair of items. This framework applies to\nproblem domains where one wants to learn people's preferences from responses\ncommonly modeled as noisy distance judgments. In this paper, we propose an\nactive algorithm to find the graph with high probability and analyze its query\ncomplexity. In contrast to existing work that forces Euclidean structure, our\nmethod is valid for general metrics, assuming only symmetry and the triangle\ninequality. Furthermore, we demonstrate efficiency of our method empirically\nand theoretically, needing only O(n log(n)Delta^-2) queries in favorable\nsettings, where Delta^-2 accounts for the effect of noise. Using crowd-sourced\ndata collected for a subset of the UT Zappos50K dataset, we apply our algorithm\nto learn which shoes people believe are most similar and show that it beats\nboth an active baseline and ordinal embedding.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:24:50 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Mason", "Blake", ""], ["Tripathy", "Ardhendu", ""], ["Nowak", "Robert", ""]]}, {"id": "1905.13268", "submitter": "Johannes G\\\"unther", "authors": "Johannes G\\\"unther, Elias Reichensd\\\"orfer, Patrick M. Pilarski and\n  Klaus Diepold", "title": "Interpretable PID Parameter Tuning for Control Engineering using General\n  Dynamic Neural Networks: An Extensive Comparison", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0243320", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern automation systems rely on closed loop control, wherein a controller\ninteracts with a controlled process, based on observations. These systems are\nincreasingly complex, yet most controllers are linear\nProportional-Integral-Derivative (PID) controllers. PID controllers perform\nwell on linear and near-linear systems but their simplicity is at odds with the\nrobustness required to reliably control complex processes. Modern machine\nlearning offers a way to extend PID controllers beyond their linear\ncapabilities by using neural networks. However, such an extension comes at the\ncost of losing stability guarantees and controller interpretability. In this\npaper, we examine the utility of extending PID controllers with recurrent\nneural networks-namely, General Dynamic Neural Networks (GDNN); we show that\nGDNN (neural) PID controllers perform well on a range of control systems and\nhighlight how they can be a scalable and interpretable option for control\nsystems. To do so, we provide an extensive study using four benchmark systems\nthat represent the most common control engineering benchmarks. All control\nbenchmarks are evaluated with and without noise as well as with and without\ndisturbances. The neural PID controller performs better than standard PID\ncontrol in 15 of 16 tasks and better than model-based control in 13 of 16\ntasks. As a second contribution, we address the lack of interpretability that\nprevents neural networks from being used in real-world control processes. We\nuse bounded-input bounded-output stability analysis to evaluate the parameters\nsuggested by the neural network, thus making them understandable. This\ncombination of rigorous evaluation paired with better interpretability is an\nimportant step towards the acceptance of neural-network-based control\napproaches. It is furthermore an important step towards interpretable and\nsafely applied artificial intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:26:10 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 21:45:34 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 20:18:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["G\u00fcnther", "Johannes", ""], ["Reichensd\u00f6rfer", "Elias", ""], ["Pilarski", "Patrick M.", ""], ["Diepold", "Klaus", ""]]}, {"id": "1905.13271", "submitter": "Isaac Lage", "authors": "Isaac Lage, Daphna Lifschitz, Finale Doshi-Velez, Ofra Amir", "title": "Exploring Computational User Models for Agent Policy Summarization", "comments": "To appear at IJCAI 2019. 14 pages (incl references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI agents are being developed to support high stakes decision-making\nprocesses from driving cars to prescribing drugs, making it increasingly\nimportant for human users to understand their behavior. Policy summarization\nmethods aim to convey strengths and weaknesses of such agents by demonstrating\ntheir behavior in a subset of informative states. Some policy summarization\nmethods extract a summary that optimizes the ability to reconstruct the agent's\npolicy under the assumption that users will deploy inverse reinforcement\nlearning. In this paper, we explore the use of different models for extracting\nsummaries. We introduce an imitation learning-based approach to policy\nsummarization; we demonstrate through computational simulations that a mismatch\nbetween the model used to extract a summary and the model used to reconstruct\nthe policy results in worse reconstruction quality; and we demonstrate through\na human-subject study that people use different models to reconstruct policies\nin different contexts, and that matching the summary extraction model to these\ncan improve performance. Together, our results suggest that it is important to\ncarefully consider user models in policy summarization.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:32:46 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lage", "Isaac", ""], ["Lifschitz", "Daphna", ""], ["Doshi-Velez", "Finale", ""], ["Amir", "Ofra", ""]]}, {"id": "1905.13272", "submitter": "Alina Ene", "authors": "Alina Ene, Huy L. Nguyen", "title": "Parallel Algorithm for Non-Monotone DR-Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we give a new parallel algorithm for the problem of maximizing\na non-monotone diminishing returns submodular function subject to a cardinality\nconstraint. For any desired accuracy $\\epsilon$, our algorithm achieves a $1/e\n- \\epsilon$ approximation using $O(\\log{n} \\log(1/\\epsilon) / \\epsilon^3)$\nparallel rounds of function evaluations. The approximation guarantee nearly\nmatches the best approximation guarantee known for the problem in the\nsequential setting and the number of parallel rounds is nearly-optimal for any\nconstant $\\epsilon$. Previous algorithms achieve worse approximation guarantees\nusing $\\Omega(\\log^2{n})$ parallel rounds. Our experimental evaluation suggests\nthat our algorithm obtains solutions whose objective value nearly matches the\nvalue obtained by the state of the art sequential algorithms, and it\noutperforms previous parallel algorithms in number of parallel rounds,\niterations, and solution quality.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:35:18 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ene", "Alina", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "1905.13276", "submitter": "Hrayr Harutyunyan", "authors": "Hrayr Harutyunyan, Daniel Moyer, Hrant Khachatrian, Greg Ver Steeg,\n  Aram Galstyan", "title": "Efficient Covariance Estimation from Temporal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the covariance structure of multivariate time series is a\nfundamental problem with a wide-range of real-world applications -- from\nfinancial modeling to fMRI analysis. Despite significant recent advances,\ncurrent state-of-the-art methods are still severely limited in terms of\nscalability, and do not work well in high-dimensional undersampled regimes. In\nthis work we propose a novel method called Temporal Correlation Explanation, or\nT-CorEx, that (a) has linear time and memory complexity with respect to the\nnumber of variables, and can scale to very large temporal datasets that are not\ntractable with existing methods; (b) gives state-of-the-art results in highly\nundersampled regimes on both synthetic and real-world datasets; and (c) makes\nminimal assumptions about the character of the dynamics of the system. T-CorEx\noptimizes an information-theoretic objective function to learn a latent factor\ngraphical model for each time period and applies two regularization techniques\nto induce temporal consistency of estimates. We perform extensive evaluation of\nT-Corex using both synthetic and real-world data and demonstrate that it can be\nused for detecting sudden changes in the underlying covariance matrix,\ncapturing transient correlations and analyzing extremely high-dimensional\ncomplex multivariate time series such as high-resolution fMRI data.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:54:20 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 10:22:08 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Harutyunyan", "Hrayr", ""], ["Moyer", "Daniel", ""], ["Khachatrian", "Hrant", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1905.13277", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Stefano Soatto", "title": "Time Matters in Regularizing Deep Networks: Weight Decay and Data\n  Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is typically understood as improving generalization by\naltering the landscape of local extrema to which the model eventually\nconverges. Deep neural networks (DNNs), however, challenge this view: We show\nthat removing regularization after an initial transient period has little\neffect on generalization, even if the final loss landscape is the same as if\nthere had been no regularization. In some cases, generalization even improves\nafter interrupting regularization. Conversely, if regularization is applied\nonly after the initial transient, it has no effect on the final solution, whose\ngeneralization gap is as bad as if regularization never happened. This suggests\nthat what matters for training deep networks is not just whether or how, but\nwhen to regularize. The phenomena we observe are manifest in different datasets\n(CIFAR-10, CIFAR-100), different architectures (ResNet-18, All-CNN), different\nregularization methods (weight decay, data augmentation), different learning\nrate schedules (exponential, piece-wise constant). They collectively suggest\nthat there is a ``critical period'' for regularizing deep networks that is\ndecisive of the final performance. More analysis should, therefore, focus on\nthe transient rather than asymptotic behavior of learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:57:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1905.13283", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Andrej Risteski", "title": "Sum-of-squares meets square loss: Fast rates for agnostic tensor\n  completion", "comments": "To appear at COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study tensor completion in the agnostic setting. In the classical tensor\ncompletion problem, we receive $n$ entries of an unknown rank-$r$ tensor and\nwish to exactly complete the remaining entries. In agnostic tensor completion,\nwe make no assumption on the rank of the unknown tensor, but attempt to predict\nunknown entries as well as the best rank-$r$ tensor.\n  For agnostic learning of third-order tensors with the square loss, we give\nthe first polynomial time algorithm that obtains a \"fast\" (i.e., $O(1/n)$-type)\nrate improving over the rate obtained by reduction to matrix completion. Our\nprediction error rate to compete with the best $d\\times{}d\\times{}d$ tensor of\nrank-$r$ is $\\tilde{O}(r^{2}d^{3/2}/n)$. We also obtain an exact oracle\ninequality that trades off estimation and approximation error.\n  Our algorithm is based on the degree-six sum-of-squares relaxation of the\ntensor nuclear norm. The key feature of our analysis is to show that a certain\ncharacterization for the subgradient of the tensor nuclear norm can be encoded\nin the sum-of-squares proof system. This unlocks the standard toolbox for\nlocalization of empirical processes under the square loss, and allows us to\nestablish restricted eigenvalue-type guarantees for various tensor regression\nmodels, with tensor completion as a special case. The new analysis of the\nrelaxation complements Barak and Moitra (2016), who gave slow rates for\nagnostic tensor completion, and Potechin and Steurer (2017), who gave exact\nrecovery guarantees for the noiseless setting. Our techniques are\nuser-friendly, and we anticipate that they will find use elsewhere.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:05:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Foster", "Dylan J.", ""], ["Risteski", "Andrej", ""]]}, {"id": "1905.13284", "submitter": "Rangeet Pan", "authors": "Rangeet Pan and Md Johirul Islam and Shibbir Ahmed and Hridesh Rajan", "title": "Identifying Classes Susceptible to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous attempts to defend deep learning based image classifiers,\nthey remain susceptible to the adversarial attacks. This paper proposes a\ntechnique to identify susceptible classes, those classes that are more easily\nsubverted. To identify the susceptible classes we use distance-based measures\nand apply them on a trained model. Based on the distance among original\nclasses, we create mapping among original classes and adversarial classes that\nhelps to reduce the randomness of a model to a significant amount in an\nadversarial setting. We analyze the high dimensional geometry among the feature\nclasses and identify the k most susceptible target classes in an adversarial\nattack. We conduct experiments using MNIST, Fashion MNIST, CIFAR-10 (ImageNet\nand ResNet-32) datasets. Finally, we evaluate our techniques in order to\ndetermine which distance-based measure works best and how the randomness of a\nmodel changes with perturbation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:08:35 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Pan", "Rangeet", ""], ["Islam", "Md Johirul", ""], ["Ahmed", "Shibbir", ""], ["Rajan", "Hridesh", ""]]}, {"id": "1905.13285", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Jelena Diakonikolas, Michael I. Jordan, Peter L.\n  Bartlett", "title": "Langevin Monte Carlo without smoothness", "comments": "Updated to match the AISTATS 2020 camera ready version. Some example\n  applications added and typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Langevin Monte Carlo (LMC) is an iterative algorithm used to generate samples\nfrom a distribution that is known only up to a normalizing constant. The\nnonasymptotic dependence of its mixing time on the dimension and target\naccuracy is understood mainly in the setting of smooth (gradient-Lipschitz)\nlog-densities, a serious limitation for applications in machine learning. In\nthis paper, we remove this limitation, providing polynomial-time convergence\nguarantees for a variant of LMC in the setting of nonsmooth log-concave\ndistributions. At a high level, our results follow by leveraging the implicit\nsmoothing of the log-density that comes from a small Gaussian perturbation that\nwe add to the iterates of the algorithm and controlling the bias and variance\nthat are induced by this perturbation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:12:22 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 23:00:35 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 19:49:40 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Diakonikolas", "Jelena", ""], ["Jordan", "Michael I.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1905.13288", "submitter": "You Lu", "authors": "You Lu, Bert Huang", "title": "Structured Output Learning with Conditional Generative Flows", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional structured prediction models try to learn the conditional\nlikelihood, i.e., p(y|x), to capture the relationship between the structured\noutput y and the input features x. For many models, computing the likelihood is\nintractable. These models are therefore hard to train, requiring the use of\nsurrogate objectives or variational inference to approximate likelihood. In\nthis paper, we propose conditional Glow (c-Glow), a conditional generative flow\nfor structured output learning. C-Glow benefits from the ability of flow-based\nmodels to compute p(y|x) exactly and efficiently. Learning with c-Glow does not\nrequire a surrogate objective or performing inference during training. Once\ntrained, we can directly and efficiently generate conditional samples. We\ndevelop a sample-based prediction method, which can use this advantage to do\nefficient and effective inference. In our experiments, we test c-Glow on five\ndifferent tasks. C-Glow outperforms the state-of-the-art baselines in some\ntasks and predicts comparable outputs in the other tasks. The results show that\nc-Glow is versatile and is applicable to many different structured prediction\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:21:59 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:37:32 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 01:42:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Lu", "You", ""], ["Huang", "Bert", ""]]}, {"id": "1905.13289", "submitter": "Pang Wei Koh", "authors": "Pang Wei Koh, Kai-Siang Ang, Hubert H. K. Teo, Percy Liang", "title": "On the Accuracy of Influence Functions for Measuring Group Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence functions estimate the effect of removing a training point on a\nmodel without the need to retrain. They are based on a first-order Taylor\napproximation that is guaranteed to be accurate for sufficiently small changes\nto the model, and so are commonly used to study the effect of individual points\nin large datasets. However, we often want to study the effects of large groups\nof training points, e.g., to diagnose batch effects or apportion credit between\ndifferent data sources. Removing such large groups can result in significant\nchanges to the model. Are influence functions still accurate in this setting?\nIn this paper, we find that across many different types of groups and for a\nrange of real-world datasets, the predicted effect (using influence functions)\nof a group correlates surprisingly well with its actual effect, even if the\nabsolute and relative errors are large. Our theoretical analysis shows that\nsuch strong correlation arises only under certain settings and need not hold in\ngeneral, indicating that real-world datasets have particular properties that\nallow the influence approximation to be accurate.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:24:17 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 06:49:54 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Koh", "Pang Wei", ""], ["Ang", "Kai-Siang", ""], ["Teo", "Hubert H. K.", ""], ["Liang", "Percy", ""]]}, {"id": "1905.13290", "submitter": "Jennifer Cardona", "authors": "Jennifer L Cardona, Michael F Howland, John O Dabiri", "title": "Seeing the Wind: Visual Wind Speed Prediction with a Coupled\n  Convolutional and Recurrent Neural Network", "comments": "NeurIPS 2019 (to appear). The dataset has been expanded to include\n  videos of a tree canopy in addition to flags. The models were retrained, and\n  results were updated accordingly. The introduction and related work sections\n  were also expand upon. Clarifying details were added to explain author\n  choices such as time averaging windows and to further discuss test set\n  results", "journal-ref": "Advances in Neural Information Processing Systems 32 (2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind energy resource quantification, air pollution monitoring, and weather\nforecasting all rely on rapid, accurate measurement of local wind conditions.\nVisual observations of the effects of wind---the swaying of trees and flapping\nof flags, for example---encode information regarding local wind conditions that\ncan potentially be leveraged for visual anemometry that is inexpensive and\nubiquitous. Here, we demonstrate a coupled convolutional neural network and\nrecurrent neural network architecture that extracts the wind speed encoded in\nvisually recorded flow-structure interactions of a flag and tree in naturally\noccurring wind. Predictions for wind speeds ranging from 0.75-11 m/s showed\nagreement with measurements from a cup anemometer on site, with a\nroot-mean-squared error approaching the natural wind speed variability due to\natmospheric turbulence. Generalizability of the network was demonstrated by\nsuccessful prediction of wind speed based on recordings of other flags in the\nfield and in a controlled wind tunnel test. Furthermore, physics-based scaling\nof the flapping dynamics accurately predicts the dependence of the network\nperformance on the video frame rate and duration.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:24:25 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 05:28:16 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 20:55:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cardona", "Jennifer L", ""], ["Howland", "Michael F", ""], ["Dabiri", "John O", ""]]}, {"id": "1905.13291", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Min-hwan Oh and Peder Olsen and Karthikeyan Natesan Ramamurthy", "title": "Counting and Segmenting Sorghum Heads", "comments": "23 pages, 23 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phenotyping is the process of measuring an organism's observable traits.\nManual phenotyping of crops is a labor-intensive, time-consuming, costly, and\nerror prone process. Accurate, automated, high-throughput phenotyping can\nrelieve a huge burden in the crop breeding pipeline. In this paper, we propose\na scalable, high-throughput approach to automatically count and segment\npanicles (heads), a key phenotype, from aerial sorghum crop imagery. Our\ncounting approach uses the image density map obtained from dot or region\nannotation as the target with a novel deep convolutional neural network\narchitecture. We also propose a novel instance segmentation algorithm using the\nestimated density map, to identify the individual panicles in the presence of\nocclusion. With real Sorghum aerial images, we obtain a mean absolute error\n(MAE) of 1.06 for counting which is better than using well-known crowd counting\napproaches such as CCNN, MCNN and CSRNet models. The instance segmentation\nmodel also produces respectable results which will be ultimately useful in\nreducing the manual annotation workload for future data.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:27:26 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Oh", "Min-hwan", ""], ["Olsen", "Peder", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1905.13294", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta, Sanchita Basak, Pallabi Saikia, Sayak Paul,\n  Vasilios Tsalavoutis, Frederick Atiah, Vadlamani Ravi, Alan Peters", "title": "A Review of Deep Learning with Special Emphasis on Architectures,\n  Applications and Recent Trends", "comments": "29 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has solved a problem that as little as five years ago was\nthought by many to be intractable - the automatic recognition of patterns in\ndata; and it can do so with accuracy that often surpasses human beings. It has\nsolved problems beyond the realm of traditional, hand-crafted machine learning\nalgorithms and captured the imagination of practitioners trying to make sense\nout of the flood of data that now inundates our society. As public awareness of\nthe efficacy of DL increases so does the desire to make use of it. But even for\nhighly trained professionals it can be daunting to approach the rapidly\nincreasing body of knowledge produced by experts in the field. Where does one\nstart? How does one determine if a particular model is applicable to their\nproblem? How does one train and deploy such a network? A primer on the subject\ncan be a good place to start. With that in mind, we present an overview of some\nof the key multilayer ANNs that comprise DL. We also discuss some new automatic\narchitecture optimization protocols that use multi-agent approaches. Further,\nsince guaranteeing system uptime is becoming critical to many computer\napplications, we include a section on using neural networks for fault detection\nand subsequent mitigation. This is followed by an exploratory survey of several\napplication areas where DL has emerged as a game-changing technology: anomalous\nbehavior detection in financial applications or in financial time-series\nforecasting, predictive and prescriptive analytics, medical image processing\nand analysis and power systems research. The thrust of this review is to\noutline emerging areas of application-oriented research within the DL community\nas well as to provide a reference to researchers seeking to use it in their\nwork for what it does best: statistical pattern recognition with unparalleled\nlearning capacity with the ability to scale with information.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:38:50 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 04:22:44 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 03:54:05 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Sengupta", "Saptarshi", ""], ["Basak", "Sanchita", ""], ["Saikia", "Pallabi", ""], ["Paul", "Sayak", ""], ["Tsalavoutis", "Vasilios", ""], ["Atiah", "Frederick", ""], ["Ravi", "Vadlamani", ""], ["Peters", "Alan", ""]]}, {"id": "1905.13298", "submitter": "Mostafa Elhoushi", "authors": "Mostafa Elhoushi, Zihao Chen, Farhan Shafiq, Ye Henry Tian, Joey Yiwei\n  Li", "title": "DeepShift: Towards Multiplication-Less Neural Networks", "comments": "-Added results for 8-bit and 16-bit fixed point activations, as well\n  as 5-bit, 4-bit, 3-bit, and 2-bit weights. - Added link to GitHub code -\n  Updated and fixed the training algorithm - Introduced 2 approaches for\n  backward and forward pases - Showed better results for training from scratch\n  on CIFAR10 and Imagenet - Added implementation on NVIDIA's GPU -Accepted in\n  CVPR Mobile AI 2021 Workshop", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) Workshops, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computation, memory, and power budgets of inferring convolutional\nneural networks (CNNs) are major bottlenecks of model deployment to edge\ncomputing platforms, e.g., mobile devices and IoT. Moreover, training CNNs is\ntime and energy-intensive even on high-grade servers. Convolution layers and\nfully connected layers, because of their intense use of multiplications, are\nthe dominant contributor to this computation budget.\n  We propose to alleviate this problem by introducing two new operations:\nconvolutional shifts and fully-connected shifts which replace multiplications\nwith bitwise shift and sign flipping during both training and inference. During\ninference, both approaches require only 5 bits (or less) to represent the\nweights. This family of neural network architectures (that use convolutional\nshifts and fully connected shifts) is referred to as DeepShift models. We\npropose two methods to train DeepShift models: DeepShift-Q which trains regular\nweights constrained to powers of 2, and DeepShift-PS that trains the values of\nthe shifts and sign flips directly.\n  Very close accuracy, and in some cases higher accuracy, to baselines are\nachieved. Converting pre-trained 32-bit floating-point baseline models of\nResNet18, ResNet50, VGG16, and GoogleNet to DeepShift and training them for 15\nto 30 epochs, resulted in Top-1/Top-5 accuracies higher than that of the\noriginal model.\n  Last but not least, we implemented the convolutional shifts and fully\nconnected shift GPU kernels and showed a reduction in latency time of 25% when\ninferring ResNet18 compared to unoptimized multiplication-based GPU kernels.\nThe code can be found at https://github.com/mostafaelhoushi/DeepShift.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:50:21 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 13:55:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 04:01:26 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 23:50:32 GMT"}, {"version": "v5", "created": "Thu, 8 Jul 2021 00:45:34 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elhoushi", "Mostafa", ""], ["Chen", "Zihao", ""], ["Shafiq", "Farhan", ""], ["Tian", "Ye Henry", ""], ["Li", "Joey Yiwei", ""]]}, {"id": "1905.13300", "submitter": "Haizhao Yang", "authors": "Lin Chen and Haizhao Yang", "title": "Generative Imaging and Image Processing via Generative Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel generative encoder (GE) model for generative\nimaging and image processing with applications in compressed sensing and\nimaging, image compression, denoising, inpainting, deblurring, and\nsuper-resolution. The GE model consists of a pre-training phase and a solving\nphase. In the pre-training phase, we separately train two deep neural networks:\na generative adversarial network (GAN) with a generator $\\G$ that captures the\ndata distribution of a given image set, and an auto-encoder (AE) network with\nan encoder $\\EN$ that compresses images following the estimated distribution by\nGAN. In the solving phase, given a noisy image $x=\\mathcal{P}(x^*)$, where\n$x^*$ is the target unknown image, $\\mathcal{P}$ is an operator adding an\naddictive, or multiplicative, or convolutional noise, or equivalently given\nsuch an image $x$ in the compressed domain, i.e., given $m=\\EN(x)$, we solve\nthe optimization problem\n  \\[\n  z^*=\\underset{z}{\\mathrm{argmin}} \\|\\EN(\\G(z))-m\\|_2^2+\\lambda\\|z\\|_2^2\n  \\] to recover the image $x^*$ in a generative way via\n$\\hat{x}:=\\G(z^*)\\approx x^*$, where $\\lambda>0$ is a hyperparameter. The GE\nmodel unifies the generative capacity of GANs and the stability of AEs in an\noptimization framework above instead of stacking GANs and AEs into a single\nnetwork or combining their loss functions into one as in existing literature.\nNumerical experiments show that the proposed model outperforms several\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:11:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chen", "Lin", ""], ["Yang", "Haizhao", ""]]}, {"id": "1905.13305", "submitter": "Tsung Wei Tsai", "authors": "Tsung Wei Tsai, Chongxuan Li, Jun Zhu", "title": "Countering Noisy Labels By Learning From Auxiliary Clean Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the learning from noisy labels (NL) problem which emerges in many\nreal-world applications. In addition to the widely-studied synthetic noise in\nthe NL literature, we also consider the pseudo labels in semi-supervised\nlearning (Semi-SL) as a special case of NL. For both types of noise, we argue\nthat the generalization performance of existing methods is highly coupled with\nthe quality of noisy labels. Therefore, we counter the problem from a novel and\nunified perspective: learning from the auxiliary clean labels. Specifically, we\npropose the Rotational-Decoupling Consistency Regularization (RDCR) framework\nthat integrates the consistency-based methods with the self-supervised rotation\ntask to learn noise-tolerant representations. The experiments show that RDCR\nachieves comparable or superior performance than the state-of-the-art methods\nunder small noise, while outperforms the existing methods significantly when\nthere is large noise.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:20:17 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 06:20:03 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Tsai", "Tsung Wei", ""], ["Li", "Chongxuan", ""], ["Zhu", "Jun", ""]]}, {"id": "1905.13306", "submitter": "Charles Lehman", "authors": "Charles Lehman, Dogancan Temel, and Ghassan AlRegib", "title": "Implicit Background Estimation for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene understanding and semantic segmentation are at the core of many\ncomputer vision tasks, many of which, involve interacting with humans in\npotentially dangerous ways. It is therefore paramount that techniques for\nprincipled design of robust models be developed. In this paper, we provide\nanalytic and empirical evidence that correcting potentially errant non-distinct\nmappings that result from the softmax function can result in improving\nrobustness characteristics on a state-of-the-art semantic segmentation model\nwith minimal impact to performance and minimal changes to the code base.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:20:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lehman", "Charles", ""], ["Temel", "Dogancan", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "1905.13307", "submitter": "Javier Felip Leon", "authors": "Javier Felip and Nilesh Ahuja and David G\\'omez-Guti\\'errez and Omesh\n  Tickoo and Vikash Mansinghka", "title": "Real-time Approximate Bayesian Computation for Scene Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider scene understanding problems such as predicting where a person is\nprobably reaching, or inferring the pose of 3D objects from depth images, or\ninferring the probable street crossings of pedestrians at a busy intersection.\nThis paper shows how to solve these problems using Approximate Bayesian\nComputation. The underlying generative models are built from realistic\nsimulation software, wrapped in a Bayesian error model for the gap between\nsimulation outputs and real data. The simulators are drawn from off-the-shelf\ncomputer graphics, video game, and traffic simulation code. The paper\nintroduces two techniques for speeding up inference that can be used separately\nor in combination. The first is to train neural surrogates of the simulators,\nusing a simple form of domain randomization to make the surrogates more robust\nto the gap between the simulation and reality. The second is to adaptively\ndiscretize the latent variables using a Tree-pyramid approach adapted from\ncomputer graphics. This paper also shows performance and accuracy measurements\non real-world problems, establishing that it is feasible to solve these\nproblems in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:03:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Felip", "Javier", ""], ["Ahuja", "Nilesh", ""], ["G\u00f3mez-Guti\u00e9rrez", "David", ""], ["Tickoo", "Omesh", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1905.13308", "submitter": "Jesse Livezey", "authors": "Jesse A. Livezey, Ahyeon Hwang, Jacob Yeung, Kristofer E. Bouchard", "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for\n  Investigating Learned Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:20:58 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 17:13:10 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Livezey", "Jesse A.", ""], ["Hwang", "Ahyeon", ""], ["Yeung", "Jacob", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "1905.13309", "submitter": "Jordan Masakuna F", "authors": "Jordan F. Masakuna", "title": "Machine Learning Methods for Shark Detection", "comments": "19 figures, 31 pages. This is a project for masters degree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This essay reviews human observer-based methods employed in shark spotting in\nMuizenberg Beach. It investigates Machine Learning methods for automated shark\ndetection with the aim of enhancing human observation. A questionnaire and\ninterview were used to collect information about shark spotting, the motivation\nof the actual Shark Spotter program and its limitations. We have defined a list\nof desirable properties for our model and chosen the adequate mathematical\ntechniques. The preliminary results of the research show that we can expect to\nextract useful information from shark images despite the geometric\ntransformations that sharks perform, its features do not change. To conclude,\nwe have partially implemented our model; the remaining implementation requires\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:34:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Masakuna", "Jordan F.", ""]]}, {"id": "1905.13313", "submitter": "Junwei Liang", "authors": "Junwei Liang and Jay D. Aronson and Alexander Hauptmann", "title": "Technical Report of the Video Event Reconstruction and Analysis (VERA)\n  System -- Shooter Localization, Models, Interface, and Beyond", "comments": "The code and models are available at\n  https://github.com/JunweiLiang/VERA_Shooter_Localization . Our system is live\n  at https://vera.cs.cmu.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every minute, hundreds of hours of video are uploaded to social media sites\nand the Internet from around the world. This material creates a visual record\nof the experiences of a significant percentage of humanity and can help\nilluminate how we live in the present moment. When properly analyzed, this\nvideo can also help analysts to reconstruct events of interest, including war\ncrimes, human rights violations, and terrorist acts. Machine learning and\ncomputer vision can play a crucial role in this process. In this technical\nreport, we describe the Video Event Reconstruction and Analysis (VERA) system.\nThis new tool brings together a variety of capabilities we have developed over\nthe past few years (including video synchronization and geolocation to order\nunstructured videos lacking metadata over time and space, and sound recognition\nalgorithms) to enable the reconstruction and analysis of events captured on\nvideo. Among other uses, VERA enables the localization of a shooter from just a\nfew videos that include the sound of gunshots. To demonstrate the efficacy of\nthis suite of tools, we present the results of estimating the shooter's\nlocation of the Las Vegas Shooting in 2017 and show that VERA accurately\npredicts the shooter's location using only the first few gunshots. We then\npoint out future directions that can help improve the system and further reduce\nunnecessary human labor in the process. All of the components of VERA run\nthrough a web interface that enables human-in-the-loop verification to ensure\naccurate estimations. All relevant source code, including the web interface and\nmachine learning models, is freely available on Github. We hope that\nresearchers and software developers will be inspired to improve and expand this\nsystem moving forward to better meet the needs of human rights and public\nsafety.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 17:55:50 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 21:12:12 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 16:04:11 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2019 06:15:49 GMT"}, {"version": "v5", "created": "Fri, 5 Jul 2019 05:23:13 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Liang", "Junwei", ""], ["Aronson", "Jay D.", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1905.13320", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Dipendra Misra, Seungchan Kim, Michel L. Littman", "title": "Combating the Compounding-Error Problem with a Multi-step Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning is an appealing framework for creating\nagents that learn, plan, and act in sequential environments. Model-based\nalgorithms typically involve learning a transition model that takes a state and\nan action and outputs the next state---a one-step model. This model can be\ncomposed with itself to enable predicting multiple steps into the future, but\none-step prediction errors can get magnified, leading to unacceptable\ninaccuracy. This compounding-error problem plagues planning and undermines\nmodel-based reinforcement learning. In this paper, we address the\ncompounding-error problem by introducing a multi-step model that directly\noutputs the outcome of executing a sequence of actions. Novel theoretical and\nempirical results indicate that the multi-step model is more conducive to\nefficient value-function estimation, and it yields better action selection\ncompared to the one-step model. These results make a strong case for using\nmulti-step models in the context of model-based reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:30:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Asadi", "Kavosh", ""], ["Misra", "Dipendra", ""], ["Kim", "Seungchan", ""], ["Littman", "Michel L.", ""]]}, {"id": "1905.13321", "submitter": "Will Rice", "authors": "William Rice", "title": "Applying Generative Adversarial Networks to Intelligent Subsurface\n  Imaging and Identification", "comments": "Master's thesis, Networked Intelligence lab in the University of\n  Tennessee at Chattanooga\u00e2\u0080\u0099s Sim Center (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To augment training data for machine learning models in Ground Penetrating\nRadar (GPR) data classification and identification, this thesis focuses on the\ngeneration of realistic GPR data using Generative Adversarial Networks. An\ninnovative GAN architecture is proposed for generating GPR B-scans, which is,\nto the author's knowledge, the first successful application of GAN to GPR\nB-scans. As one of the major contributions, a novel loss function is formulated\nby merging frequency domain with time domain features. To test the efficacy of\ngenerated B-scans, a real time object classifier is proposed to measure the\nperformance gain derived from augmented B-Scan images. The numerical experiment\nillustrated that, based on the augmented training data, the proposed GAN\narchitecture demonstrated a significant increase (from 82% to 98%) in the\naccuracy of the object classifier.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:37:38 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Rice", "William", ""]]}, {"id": "1905.13331", "submitter": "Rui Wang", "authors": "Rui Wang, Guoyin Wang, Ricardo Henao", "title": "Discriminative Clustering for Robust Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation seeks to learn an invariant and discriminative\nrepresentation for an unlabeled target domain by leveraging the information of\na labeled source dataset. We propose to improve the discriminative ability of\nthe target domain representation by simultaneously learning tightly clustered\ntarget representations while encouraging that each cluster is assigned to a\nunique and different class from the source. This strategy alleviates the\neffects of negative transfer when combined with adversarial domain matching\nbetween source and target representations. Our approach is robust to\ndifferences in the source and target label distributions and thus applicable to\nboth balanced and imbalanced domain adaptation tasks, and with a simple\nextension, it can also be used for partial domain adaptation. Experiments on\nseveral benchmark datasets for domain adaptation demonstrate that our approach\ncan achieve state-of-the-art performance in all three scenarios, namely,\nbalanced, imbalanced and partial domain adaptation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:56:06 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wang", "Rui", ""], ["Wang", "Guoyin", ""], ["Henao", "Ricardo", ""]]}, {"id": "1905.13341", "submitter": "Nan Jiang", "authors": "Nan Jiang", "title": "On Value Functions and the Agent-Environment Boundary", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When function approximation is deployed in reinforcement learning (RL), the\nsame problem may be formulated in different ways, often by treating a\npre-processing step as a part of the environment or as part of the agent. As a\nconsequence, fundamental concepts in RL, such as (optimal) value functions, are\nnot uniquely defined as they depend on where we draw this agent-environment\nboundary, causing problems in theoretical analyses that provide optimality\nguarantees. We address this issue via a simple and novel boundary-invariant\nanalysis of Fitted Q-Iteration, a representative RL algorithm, where the\nassumptions and the guarantees are invariant to the choice of boundary. We also\ndiscuss closely related issues on state resetting and Monte-Carlo Tree Search,\ndeterministic vs stochastic systems, imitation learning, and the verifiability\nof theoretical assumptions from data.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:39:57 GMT"}, {"version": "v2", "created": "Sun, 16 Jun 2019 04:58:36 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 03:28:44 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Jiang", "Nan", ""]]}, {"id": "1905.13343", "submitter": "Zaccary Alperstein", "authors": "Zaccary Alperstein, Artem Cherkasov, Jason Tyler Rolfe", "title": "All SMILES Variational Autoencoder", "comments": "Expanded acronym in title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) defined over SMILES string and graph-based\nrepresentations of molecules promise to improve the optimization of molecular\nproperties, thereby revolutionizing the pharmaceuticals and materials\nindustries. However, these VAEs are hindered by the non-unique nature of SMILES\nstrings and the computational cost of graph convolutions. To efficiently pass\nmessages along all paths through the molecular graph, we encode multiple SMILES\nstrings of a single molecule using a set of stacked recurrent neural networks,\npooling hidden representations of each atom between SMILES representations, and\nuse attentional pooling to build a final fixed-length latent representation. By\nthen decoding to a disjoint set of SMILES strings of the molecule, our All\nSMILES VAE learns an almost bijective mapping between molecules and latent\nrepresentations near the high-probability-mass subspace of the prior. Our\nSMILES-derived but molecule-based latent representations significantly surpass\nthe state-of-the-art in a variety of fully- and semi-supervised property\nregression and molecular property optimization tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:43:37 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 17:25:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Alperstein", "Zaccary", ""], ["Cherkasov", "Artem", ""], ["Rolfe", "Jason Tyler", ""]]}, {"id": "1905.13344", "submitter": "Vaishnavh Nagarajan", "authors": "Vaishnavh Nagarajan, J. Zico Kolter", "title": "Deterministic PAC-Bayesian generalization bounds for deep networks via\n  generalizing noise-resilience", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of overparameterized deep networks to generalize well has been\nlinked to the fact that stochastic gradient descent (SGD) finds solutions that\nlie in flat, wide minima in the training loss -- minima where the output of the\nnetwork is resilient to small random noise added to its parameters. So far this\nobservation has been used to provide generalization guarantees only for neural\nnetworks whose parameters are either \\textit{stochastic} or\n\\textit{compressed}. In this work, we present a general PAC-Bayesian framework\nthat leverages this observation to provide a bound on the original network\nlearned -- a network that is deterministic and uncompressed. What enables us to\ndo this is a key novelty in our approach: our framework allows us to show that\nif on training data, the interactions between the weight matrices satisfy\ncertain conditions that imply a wide training loss minimum, these conditions\nthemselves {\\em generalize} to the interactions between the matrices on test\ndata, thereby implying a wide test loss minimum. We then apply our general\nframework in a setup where we assume that the pre-activation values of the\nnetwork are not too small (although we assume this only on the training data).\nIn this setup, we provide a generalization guarantee for the original\n(deterministic, uncompressed) network, that does not scale with product of the\nspectral norms of the weight matrices -- a guarantee that would not have been\npossible with prior approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:45:06 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1905.13345", "submitter": "Daniel Mckenzie", "authors": "Daniel Mckenzie, Steven Damelin", "title": "Power Weighted Shortest Paths for Clustering Euclidean Data", "comments": "24 pages. Final version. To appear in Foundations of Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of power weighted shortest path distance functions for\nclustering high dimensional Euclidean data, under the assumption that the data\nis drawn from a collection of disjoint low dimensional manifolds. We argue,\ntheoretically and experimentally, that this leads to higher clustering\naccuracy. We also present a fast algorithm for computing these distances.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 22:46:19 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 23:23:26 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 00:26:16 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Mckenzie", "Daniel", ""], ["Damelin", "Steven", ""]]}, {"id": "1905.13348", "submitter": "Qian Li", "authors": "Francisco Romero, Qian Li, Neeraja J. Yadwadkar, Christos Kozyrakis", "title": "INFaaS: A Model-less and Managed Inference Serving System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite existing work in machine learning inference serving, ease-of-use and\ncost efficiency remain challenges at large scales. Developers must manually\nsearch through thousands of model-variants -- versions of already-trained\nmodels that differ in hardware, resource footprints, latencies, costs, and\naccuracies -- to meet the diverse application requirements. Since requirements,\nquery load, and applications themselves evolve over time, these decisions need\nto be made dynamically for each inference query to avoid excessive costs\nthrough naive autoscaling. To avoid navigating through the large and complex\ntrade-off space of model-variants, developers often fix a variant across\nqueries, and replicate it when load increases. However, given the diversity\nacross variants and hardware platforms in the cloud, a lack of understanding of\nthe trade-off space can incur significant costs to developers.\n  This paper introduces INFaaS, a managed and model-less system for distributed\ninference serving, where developers simply specify the performance and accuracy\nrequirements for their applications without needing to specify a specific\nmodel-variant for each query. INFaaS generates model-variants, and efficiently\nnavigates the large trade-off space of model-variants on behalf of developers\nto meet application-specific objectives: (a) for each query, it selects a\nmodel, hardware architecture, and model optimizations, (b) it combines VM-level\nhorizontal autoscaling with model-level autoscaling, where multiple, different\nmodel-variants are used to serve queries within each machine. By leveraging\ndiverse variants and sharing hardware resources across models, INFaaS achieves\n1.3x higher throughput, violates latency objectives 1.6x less often, and saves\nup to 21.6x in cost (8.5x on average) compared to state-of-the-art inference\nserving systems on AWS EC2.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:08:29 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 15:56:30 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 04:41:59 GMT"}, {"version": "v4", "created": "Tue, 24 Sep 2019 17:32:22 GMT"}, {"version": "v5", "created": "Wed, 25 Sep 2019 22:14:38 GMT"}, {"version": "v6", "created": "Tue, 15 Dec 2020 21:04:54 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Romero", "Francisco", ""], ["Li", "Qian", ""], ["Yadwadkar", "Neeraja J.", ""], ["Kozyrakis", "Christos", ""]]}, {"id": "1905.13350", "submitter": "Sabine Wehnert", "authors": "Sabine Wehnert and Sayed Anisul Hoque and Wolfram Fenske and Gunter\n  Saake", "title": "Threshold-Based Retrieval and Textual Entailment Detection on Legal Bar\n  Exam Questions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Getting an overview over the legal domain has become challenging, especially\nin a broad, international context. Legal question answering systems have the\npotential to alleviate this task by automatically retrieving relevant legal\ntexts for a specific statement and checking whether the meaning of the\nstatement can be inferred from the found documents. We investigate a\ncombination of the BM25 scoring method of Elasticsearch with word embeddings\ntrained on English translations of the German and Japanese civil law. For this,\nwe define criteria which select a dynamic number of relevant documents\naccording to threshold scores. Exploiting two deep learning classifiers and\ntheir respective prediction bias with a threshold-based answer inclusion\ncriterion has shown to be beneficial for the textual entailment task, when\ncompared to the baseline.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:17:26 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wehnert", "Sabine", ""], ["Hoque", "Sayed Anisul", ""], ["Fenske", "Wolfram", ""], ["Saake", "Gunter", ""]]}, {"id": "1905.13357", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal and Arnob Ghosh and Nilay Tiwari", "title": "Reinforcement Learning for Mean Field Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic games provide a framework for interactions among multiple agents\nand enable a myriad of applications. In these games, agents decide on actions\nsimultaneously, the state of every agent moves to the next state, and each\nagent receives a reward. However, finding an equilibrium (if exists) in this\ngame is often difficult when the number of agents becomes large. This paper\nfocuses on finding a mean-field equilibrium (MFE) in an action coupled\nstochastic game setting in an episodic framework. It is assumed that the impact\nof the other agents' can be assumed by the empirical distribution of the mean\nof the actions. All agents know the action distribution and employ lower-myopic\nbest response dynamics to choose the optimal oblivious strategy. This paper\nproposes a posterior sampling based approach for reinforcement learning in the\nmean-field game, where each agent samples a transition probability from the\nprevious transitions. We show that the policy and action distributions converge\nto the optimal oblivious strategy and the limiting distribution, respectively,\nwhich constitute an MFE.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:58:22 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 18:29:06 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""], ["Ghosh", "Arnob", ""], ["Tiwari", "Nilay", ""]]}, {"id": "1905.13360", "submitter": "Hanzhang Hu", "authors": "Hanzhang Hu and John Langford and Rich Caruana and Saurajit Mukherjee\n  and Eric Horvitz and Debadeepta Dey", "title": "Efficient Forward Architecture Search", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural architecture search (NAS) algorithm, Petridish, to\niteratively add shortcut connections to existing network layers. The added\nshortcut connections effectively perform gradient boosting on the augmented\nlayers. The proposed algorithm is motivated by the feature selection algorithm\nforward stage-wise linear regression, since we consider NAS as a generalization\nof feature selection for regression, where NAS selects shortcuts among layers\ninstead of selecting features. In order to reduce the number of trials of\npossible connection combinations, we train jointly all possible connections at\neach stage of growth while leveraging feature selection techniques to choose a\nsubset of them. We experimentally show this process to be an efficient forward\narchitecture search algorithm that can find competitive models using few GPU\ndays in both the search space of repeatable network modules (cell-search) and\nthe space of general networks (macro-search). Petridish is particularly\nwell-suited for warm-starting from existing models crucial for\nlifelong-learning scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:10:17 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hu", "Hanzhang", ""], ["Langford", "John", ""], ["Caruana", "Rich", ""], ["Mukherjee", "Saurajit", ""], ["Horvitz", "Eric", ""], ["Dey", "Debadeepta", ""]]}, {"id": "1905.13367", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi, Peter D. Grunwald, Benjamin Guedj", "title": "PAC-Bayes Un-Expected Bernstein Inequality", "comments": "24 pages, 6 figures. To Appear in NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new PAC-Bayesian generalization bound. Standard bounds contain a\n$\\sqrt{L_n \\cdot \\KL/n}$ complexity term which dominates unless $L_n$, the\nempirical error of the learning algorithm's randomized predictions, vanishes.\nWe manage to replace $L_n$ by a term which vanishes in many more situations,\nessentially whenever the employed learning algorithm is sufficiently stable on\nthe dataset at hand. Our new bound consistently beats state-of-the-art bounds\nboth on a toy example and on UCI datasets (with large enough $n$).\nTheoretically, unlike existing bounds, our new bound can be expected to\nconverge to $0$ faster whenever a Bernstein/Tsybakov condition holds, thus\nconnecting PAC-Bayesian generalization and {\\em excess risk\\/} bounds---for the\nlatter it has long been known that faster convergence can be obtained under\nBernstein conditions. Our main technical tool is a new concentration inequality\nwhich is like Bernstein's but with $X^2$ taken outside its expectation.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:02:26 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 05:18:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Grunwald", "Peter D.", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1905.13368", "submitter": "Rekha Singhal Dr.", "authors": "Rekha Singhal, Gautam Shroff, Mukund Kumar, Sharod Roy, Sanket\n  Kadarkar, Rupinder virk, Siddharth Verma and Vartika Tiwari", "title": "Fast Online \"Next Best Offers\" using Deep Learning", "comments": "7 Pages, Accepted in COMAD-CODS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present iPrescribe, a scalable low-latency architecture for\nrecommending 'next-best-offers' in an online setting. The paper presents the\ndesign of iPrescribe and compares its performance for implementations using\ndifferent real-time streaming technology stacks. iPrescribe uses an ensemble of\ndeep learning and machine learning algorithms for prediction. We describe the\nscalable real-time streaming technology stack and optimized machine-learning\nimplementations to achieve a 90th percentile recommendation latency of 38\nmilliseconds. Optimizations include a novel mechanism to deploy recurrent Long\nShort Term Memory (LSTM) deep learning networks efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:03:04 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Singhal", "Rekha", ""], ["Shroff", "Gautam", ""], ["Kumar", "Mukund", ""], ["Roy", "Sharod", ""], ["Kadarkar", "Sanket", ""], ["virk", "Rupinder", ""], ["Verma", "Siddharth", ""], ["Tiwari", "Vartika", ""]]}, {"id": "1905.13372", "submitter": "Mariya Popova", "authors": "Mariya Popova, Mykhailo Shvets, Junier Oliva, Olexandr Isayev", "title": "MolecularRNN: Generating realistic molecular graphs with optimized\n  properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.MN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing new molecules with a set of predefined properties is a core problem\nin modern drug discovery and development. There is a growing need for de-novo\ndesign methods that would address this problem. We present MolecularRNN, the\ngraph recurrent generative model for molecular structures. Our model generates\ndiverse realistic molecular graphs after likelihood pretraining on a big\ndatabase of molecules. We perform an analysis of our pretrained models on\nlarge-scale generated datasets of 1 million samples. Further, the model is\ntuned with policy gradient algorithm, provided a critic that estimates the\nreward for the property of interest. We show a significant distribution shift\nto the desired range for lipophilicity, drug-likeness, and melting point\noutperforming state-of-the-art works. With the use of rejection sampling based\non valency constraints, our model yields 100% validity. Moreover, we show that\ninvalid molecules provide a rich signal to the model through the use of\nstructure penalty in our reinforcement learning pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:33:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Popova", "Mariya", ""], ["Shvets", "Mykhailo", ""], ["Oliva", "Junier", ""], ["Isayev", "Olexandr", ""]]}, {"id": "1905.13378", "submitter": "Hoon Lee", "authors": "Hoon Lee, Sang Hyun Lee, Tony Q. S. Quek", "title": "Deep Learning for Distributed Optimization: Applications to Wireless\n  Resource Management", "comments": "to appear in IEEE J. Sel. Areas Commun", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a deep learning (DL) framework to solve distributed\nnon-convex constrained optimizations in wireless networks where multiple\ncomputing nodes, interconnected via backhaul links, desire to determine an\nefficient assignment of their states based on local observations. Two different\nconfigurations are considered: First, an infinite-capacity backhaul enables\nnodes to communicate in a lossless way, thereby obtaining the solution by\ncentralized computations. Second, a practical finite-capacity backhaul leads to\nthe deployment of distributed solvers equipped along with quantizers for\ncommunication through capacity-limited backhaul. The distributed nature and the\nnonconvexity of the optimizations render the identification of the solution\nunwieldy. To handle them, deep neural networks (DNNs) are introduced to\napproximate an unknown computation for the solution accurately. In consequence,\nthe original problems are transformed to training tasks of the DNNs subject to\nnon-convex constraints where existing DL libraries fail to extend\nstraightforwardly. A constrained training strategy is developed based on the\nprimal-dual method. For distributed implementation, a novel binarization\ntechnique at the output layer is developed for quantization at each node. Our\nproposed distributed DL framework is examined in various network configurations\nof wireless resource management. Numerical results verify the effectiveness of\nour proposed approach over existing optimization techniques.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:54:53 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lee", "Hoon", ""], ["Lee", "Sang Hyun", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "1905.13383", "submitter": "Nate Gruver", "authors": "Nate Gruver, Ali Malik, Brahm Capoor, Chris Piech, Mitchell L.\n  Stevens, Andreas Paepcke", "title": "Using Latent Variable Models to Observe Academic Pathways", "comments": "Twelfth International Conference on Educational Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding large-scale patterns in student course enrollment is a problem\nof great interest to university administrators and educational researchers. Yet\nimportant decisions are often made without a good quantitative framework of the\nprocess underlying student choices. We propose a probabilistic approach to\nmodelling course enrollment decisions, drawing inspiration from multilabel\nclassification and mixture models. We use ten years of anonymized student\ntranscripts from a large university to construct a Gaussian latent variable\nmodel that learns the joint distribution over course enrollments. The models\nallow for a diverse set of inference queries and robustness to data sparsity.\nWe demonstrate the efficacy of this approach in comparison to others, including\ndeep learning architectures, and demonstrate its ability to infer the\nunderlying student interests that guide enrollment decisions.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:28:21 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Gruver", "Nate", ""], ["Malik", "Ali", ""], ["Capoor", "Brahm", ""], ["Piech", "Chris", ""], ["Stevens", "Mitchell L.", ""], ["Paepcke", "Andreas", ""]]}, {"id": "1905.13386", "submitter": "Kai Rothauge", "authors": "Kai Rothauge, Zhewei Yao, Zixi Hu, Michael W. Mahoney", "title": "Residual Networks as Nonlinear Systems: Stability Analysis using\n  Linearization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We regard pre-trained residual networks (ResNets) as nonlinear systems and\nuse linearization, a common method used in the qualitative analysis of\nnonlinear systems, to understand the behavior of the networks under small\nperturbations of the input images. We work with ResNet-56 and ResNet-110\ntrained on the CIFAR-10 data set. We linearize these networks at the level of\nresidual units and network stages, and the singular value decomposition is used\nin the stability analysis of these components. It is found that most of the\nsingular values of the linearizations of residual units are 1 and, in spite of\nthe fact that the linearizations depend directly on the activation maps, the\nsingular values differ only slightly for different input images. However,\nadjusting the scaling of the skip connection or the values of the weights in a\nresidual unit has a significant impact on the singular value distributions.\nInspection of how random and adversarial perturbations of input images\npropagate through the network reveals that there is a dramatic jump in the\nmagnitude of adversarial perturbations towards the end of the final stage of\nthe network that is not present in the case of random perturbations. We attempt\nto gain a better understanding of this phenomenon by projecting the\nperturbations onto singular vectors of the linearizations of the residual\nunits.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:44:28 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Rothauge", "Kai", ""], ["Yao", "Zhewei", ""], ["Hu", "Zixi", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1905.13391", "submitter": "Shah Rukh Qasim", "authors": "Shah Rukh Qasim, Hassan Mahmood, and Faisal Shafait", "title": "Rethinking Table Recognition using Graph Neural Networks", "comments": "Accepted to ICDAR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document structure analysis, such as zone segmentation and table recognition,\nis a complex problem in document processing and is an active area of research.\nThe recent success of deep learning in solving various computer vision and\nmachine learning problems has not been reflected in document structure analysis\nsince conventional neural networks are not well suited to the input structure\nof the problem. In this paper, we propose an architecture based on graph\nnetworks as a better alternative to standard neural networks for table\nrecognition. We argue that graph networks are a more natural choice for these\nproblems, and explore two gradient-based graph neural networks. Our proposed\narchitecture combines the benefits of convolutional neural networks for visual\nfeature extraction and graph networks for dealing with the problem structure.\nWe empirically demonstrate that our method outperforms the baseline by a\nsignificant margin. In addition, we identify the lack of large scale datasets\nas a major hindrance for deep learning research for structure analysis and\npresent a new large scale synthetic dataset for the problem of table\nrecognition. Finally, we open-source our implementation of dataset generation\nand the training framework of our graph networks to promote reproducible\nresearch in this direction.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:58:04 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 17:59:36 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Qasim", "Shah Rukh", ""], ["Mahmood", "Hassan", ""], ["Shafait", "Faisal", ""]]}, {"id": "1905.13392", "submitter": "V\\'ictor Manuel Vargas Yun", "authors": "V\\'ictor-Manuel Vargas and Pedro-Antonio Guti\\'errez and C\\'esar\n  Herv\\'as-Mart\\'inez", "title": "Cumulative link models for deep ordinal classification", "comments": "24 pages, 3 figures. Submitted to Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep convolutional neural network model for ordinal\nregression by considering a family of probabilistic ordinal link functions in\nthe output layer. The link functions are those used for cumulative link models,\nwhich are traditional statistical linear models based on projecting each\npattern into a 1-dimensional space. A set of ordered thresholds splits this\nspace into the different classes of the problem. In our case, the projections\nare estimated by a non-linear deep neural network. To further improve the\nresults, we combine these ordinal models with a loss function that takes into\naccount the distance between the categories, based on the weighted Kappa index.\nThree different link functions are studied in the experimental study, and the\nresults are contrasted with statistical analysis. The experiments run over two\ndifferent ordinal classification problems and the statistical tests confirm\nthat these models improve the results of a nominal model and outperform other\nrobust proposals considered in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:21:47 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 11:46:18 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Vargas", "V\u00edctor-Manuel", ""], ["Guti\u00e9rrez", "Pedro-Antonio", ""], ["Herv\u00e1s-Mart\u00ednez", "C\u00e9sar", ""]]}, {"id": "1905.13399", "submitter": "Yuan Gong", "authors": "Yuan Gong, Boyang Li, Christian Poellabauer, Yiyu Shi", "title": "Real-Time Adversarial Attacks", "comments": "To Appear in the Proceedings of the 28th International Joint\n  Conference on Artificial Intelligence (IJCAI 2019). Code:\n  https://github.com/YuanGongND/realtime-adversarial-attack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many efforts have demonstrated that modern machine learning\nalgorithms are vulnerable to adversarial attacks, where small, but carefully\ncrafted, perturbations on the input can make them fail. While these attack\nmethods are very effective, they only focus on scenarios where the target model\ntakes static input, i.e., an attacker can observe the entire original sample\nand then add a perturbation at any point of the sample. These attack approaches\nare not applicable to situations where the target model takes streaming input,\ni.e., an attacker is only able to observe past data points and add\nperturbations to the remaining (unobserved) data points of the input. In this\npaper, we propose a real-time adversarial attack scheme for machine learning\nmodels with streaming inputs.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:32:10 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 07:49:38 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gong", "Yuan", ""], ["Li", "Boyang", ""], ["Poellabauer", "Christian", ""], ["Shi", "Yiyu", ""]]}, {"id": "1905.13402", "submitter": "Ashwin Balakrishna", "authors": "Brijen Thananjeyan, Ashwin Balakrishna, Ugo Rosolia, Felix Li, Rowan\n  McAllister, Joseph E. Gonzalez, Sergey Levine, Francesco Borrelli, Ken\n  Goldberg", "title": "Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep\n  Model-Based RL for Sparse Cost Robotic Tasks", "comments": "Robotics and Automation Letters and International Conference on\n  Robotics and Automation 2020. First two authors contributed equally", "journal-ref": "Robotics and Automation Letters 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) for robotics is challenging due to the difficulty\nin hand-engineering a dense cost function, which can lead to unintended\nbehavior, and dynamical uncertainty, which makes exploration and constraint\nsatisfaction challenging. We address these issues with a new model-based\nreinforcement learning algorithm, Safety Augmented Value Estimation from\nDemonstrations (SAVED), which uses supervision that only identifies task\ncompletion and a modest set of suboptimal demonstrations to constrain\nexploration and learn efficiently while handling complex constraints. We then\ncompare SAVED with 3 state-of-the-art model-based and model-free RL algorithms\non 6 standard simulation benchmarks involving navigation and manipulation and a\nphysical knot-tying task on the da Vinci surgical robot. Results suggest that\nSAVED outperforms prior methods in terms of success rate, constraint\nsatisfaction, and sample efficiency, making it feasible to safely learn a\ncontrol policy directly on a real robot in less than an hour. For tasks on the\nrobot, baselines succeed less than 5% of the time while SAVED has a success\nrate of over 75% in the first 50 training iterations. Code and supplementary\nmaterial is available at https://tinyurl.com/saved-rl.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:54:25 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 02:50:36 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 08:07:58 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 09:24:29 GMT"}, {"version": "v5", "created": "Sat, 8 Feb 2020 05:27:55 GMT"}, {"version": "v6", "created": "Tue, 3 Mar 2020 10:03:00 GMT"}, {"version": "v7", "created": "Sat, 2 May 2020 00:34:47 GMT"}, {"version": "v8", "created": "Sat, 16 May 2020 00:05:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Rosolia", "Ugo", ""], ["Li", "Felix", ""], ["McAllister", "Rowan", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""], ["Borrelli", "Francesco", ""], ["Goldberg", "Ken", ""]]}, {"id": "1905.13403", "submitter": "Jiaxu Cui", "authors": "Jiaxu Cui and Bo Yang and Xia Hu", "title": "Deep Bayesian Optimization on Attributed Graphs", "comments": "Published in the Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed graphs, which contain rich contextual features beyond just network\nstructure, are ubiquitous and have been observed to benefit various network\nanalytics applications. Graph structure optimization, aiming to find the\noptimal graphs in terms of some specific measures, has become an effective\ncomputational tool in complex network analysis. However, traditional model-free\nmethods suffer from the expensive computational cost of evaluating graphs;\nexisting vectorial Bayesian optimization methods cannot be directly applied to\nattributed graphs and have the scalability issue due to the use of Gaussian\nprocesses (GPs). To bridge the gap, in this paper, we propose a novel scalable\nDeep Graph Bayesian Optimization (DGBO) method on attributed graphs. The\nproposed DGBO prevents the cubical complexity of the GPs by adopting a deep\ngraph neural network to surrogate black-box functions, and can scale linearly\nwith the number of observations. Intensive experiments are conducted on both\nartificial and real-world problems, including molecular discovery and urban\nroad network design, and demonstrate the effectiveness of the DGBO compared\nwith the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:55:47 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Cui", "Jiaxu", ""], ["Yang", "Bo", ""], ["Hu", "Xia", ""]]}, {"id": "1905.13404", "submitter": "Jamie Haddock", "authors": "Jesus A. De Loera, Jamie Haddock, Anna Ma, Deanna Needell", "title": "Data-driven Algorithm Selection and Parameter Tuning: Two Case studies\n  in Optimization and Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms typically rely on optimization subroutines and\nare well-known to provide very effective outcomes for many types of problems.\nHere, we flip the reliance and ask the reverse question: can machine learning\nalgorithms lead to more effective outcomes for optimization problems? Our goal\nis to train machine learning methods to automatically improve the performance\nof optimization and signal processing algorithms. As a proof of concept, we use\nour approach to improve two popular data processing subroutines in data\nscience: stochastic gradient descent and greedy methods in compressed sensing.\nWe provide experimental results that demonstrate the answer is ``yes'', machine\nlearning algorithms do lead to more effective outcomes for optimization\nproblems, and show the future potential for this research direction.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:58:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 20:57:58 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["De Loera", "Jesus A.", ""], ["Haddock", "Jamie", ""], ["Ma", "Anna", ""], ["Needell", "Deanna", ""]]}, {"id": "1905.13405", "submitter": "Yuandong Tian", "authors": "Yuandong Tian and Tina Jiang and Qucheng Gong and Ari Morcos", "title": "Luck Matters: Understanding Training Dynamics of Deep ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the dynamics of training deep ReLU networks and their implications\non generalization capability. Using a teacher-student setting, we discovered a\nnovel relationship between the gradient received by hidden student nodes and\nthe activations of teacher nodes for deep ReLU networks. With this relationship\nand the assumption of small overlapping teacher node activations, we prove that\n(1) student nodes whose weights are initialized to be close to teacher nodes\nconverge to them at a faster rate, and (2) in over-parameterized regimes and\n2-layer case, while a small set of lucky nodes do converge to the teacher\nnodes, the fan-out weights of other nodes converge to zero. This framework\nprovides insight into multiple puzzling phenomena in deep learning like\nover-parameterization, implicit regularization, lottery tickets, etc. We verify\nour assumption by showing that the majority of BatchNorm biases of pre-trained\nVGG11/16 models are negative. Experiments on (1) random deep teacher networks\nwith Gaussian inputs, (2) teacher network pre-trained on CIFAR-10 and (3)\nextensive ablation studies validate our multiple theoretical predictions.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:07:58 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 19:58:56 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 05:12:15 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 16:44:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Tian", "Yuandong", ""], ["Jiang", "Tina", ""], ["Gong", "Qucheng", ""], ["Morcos", "Ari", ""]]}, {"id": "1905.13409", "submitter": "Reza Shokri", "authors": "Te Juin Lester Tan and Reza Shokri", "title": "Bypassing Backdoor Detection Algorithms in Deep Learning", "comments": "IEEE European Symposium on Security and Privacy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to various adversarial manipulations of\ntheir training data, parameters, and input sample. In particular, an adversary\ncan modify the training data and model parameters to embed backdoors into the\nmodel, so the model behaves according to the adversary's objective if the input\ncontains the backdoor features, referred to as the backdoor trigger (e.g., a\nstamp on an image). The poisoned model's behavior on clean data, however,\nremains unchanged. Many detection algorithms are designed to detect backdoors\non input samples or model parameters, through the statistical difference\nbetween the latent representations of adversarial and clean input samples in\nthe poisoned model. In this paper, we design an adversarial backdoor embedding\nalgorithm that can bypass the existing detection algorithms including the\nstate-of-the-art techniques. We design an adaptive adversarial training\nalgorithm that optimizes the original loss function of the model, and also\nmaximizes the indistinguishability of the hidden representations of poisoned\ndata and clean data. This work calls for designing adversary-aware defense\nmechanisms for backdoor detection.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:28:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 17:56:42 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Tan", "Te Juin Lester", ""], ["Shokri", "Reza", ""]]}, {"id": "1905.13418", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis, Michael Moortgat, Tejaswini Deoskar", "title": "Constructive Type-Logical Supertagging with Self-Attention Networks", "comments": "REPL4NLP 4, ACL 2019", "journal-ref": "Proceedings of the 4th Workshop on Representation Learning for NLP\n  (RepL4NLP-2019)", "doi": "10.18653/v1/W19-4314", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel application of self-attention networks towards grammar\ninduction. We present an attention-based supertagger for a refined type-logical\ngrammar, trained on constructing types inductively. In addition to achieving a\nhigh overall type accuracy, our model is able to learn the syntax of the\ngrammar's type system along with its denotational semantics. This lifts the\nclosed world assumption commonly made by lexicalized grammar supertaggers,\ngreatly enhancing its generalization potential. This is evidenced both by its\nadequate accuracy over sparse word types and its ability to correctly construct\ncomplex types never seen during training, which, to the best of our knowledge,\nwas as of yet unaccomplished.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:16:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kogkalidis", "Konstantinos", ""], ["Moortgat", "Michael", ""], ["Deoskar", "Tejaswini", ""]]}, {"id": "1905.13420", "submitter": "Yang Liu", "authors": "Yang Liu, Yunan Luo, Yuanyi Zhong, Xi Chen, Qiang Liu, Jian Peng", "title": "Sequence Modeling of Temporal Credit Assignment for Episodic\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep reinforcement learning algorithms have shown great\npotential and success for solving many challenging real-world problems,\nincluding Go game and robotic applications. Usually, these algorithms need a\ncarefully designed reward function to guide training in each time step.\nHowever, in real world, it is non-trivial to design such a reward function, and\nthe only signal available is usually obtained at the end of a trajectory, also\nknown as the episodic reward or return. In this work, we introduce a new\nalgorithm for temporal credit assignment, which learns to decompose the\nepisodic return back to each time-step in the trajectory using deep neural\nnetworks. With this learned reward signal, the learning efficiency can be\nsubstantially improved for episodic reinforcement learning. In particular, we\nfind that expressive language models such as the Transformer can be adopted for\nlearning the importance and the dependency of states in the trajectory,\ntherefore providing high-quality and interpretable learned reward signals. We\nhave performed extensive experiments on a set of MuJoCo continuous locomotive\ncontrol tasks with only episodic returns and demonstrated the effectiveness of\nour algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:20:12 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Liu", "Yang", ""], ["Luo", "Yunan", ""], ["Zhong", "Yuanyi", ""], ["Chen", "Xi", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1905.13422", "submitter": "Youngjoo Seo", "authors": "Younjoo Seo, Andreas Loukas, Nathana\\\"el Perraudin", "title": "Discriminative structural graph classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the discrimination capacity of aggregation functions:\nthese are the permutation invariant functions used by graph neural networks to\ncombine the features of nodes. Realizing that the most powerful aggregation\nfunctions suffer from a dimensionality curse, we consider a restricted setting.\nIn particular, we show that the standard sum and a novel histogram-based\nfunction have the capacity to discriminate between any fixed number of inputs\nchosen by an adversary. Based on our insights, we design a graph neural network\naiming, not to maximize discrimination capacity, but to learn discriminative\ngraph representations that generalize well. Our empirical evaluation provides\nevidence that our choices can yield benefits to the problem of structural graph\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:38:33 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 16:26:18 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Seo", "Younjoo", ""], ["Loukas", "Andreas", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "1905.13428", "submitter": "Matthew A. Wright", "authors": "Matthew A. Wright and Roberto Horowitz", "title": "Attentional Policies for Cross-Context Multi-Agent Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many potential applications of reinforcement learning in the real world\ninvolve interacting with other agents whose numbers vary over time. We propose\nnew neural policy architectures for these multi-agent problems. In contrast to\nother methods of training an individual, discrete policy for each agent and\nthen enforcing cooperation through some additional inter-policy mechanism, we\nfollow the spirit of recent work on the power of relational inductive biases in\ndeep networks by learning multi-agent relationships at the policy level via an\nattentional architecture. In our method, all agents share the same policy, but\nindependently apply it in their own context to aggregate the other agents'\nstate information when selecting their next action. The structure of our\narchitectures allow them to be applied on environments with varying numbers of\nagents. We demonstrate our architecture on a benchmark multi-agent autonomous\nvehicle coordination problem, obtaining superior results to a full-knowledge,\nfully-centralized reference solution, and significantly outperforming it when\nscaling to large numbers of agents.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:02:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wright", "Matthew A.", ""], ["Horowitz", "Roberto", ""]]}, {"id": "1905.13430", "submitter": "Yair Meidan", "authors": "Yair Meidan, Vinay Sachidananda, Yuval Elovici, and Asaf Shabtai", "title": "Privacy-Preserving Detection of IoT Devices Connected Behind a NAT in a\n  Smart Home Setup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, telecommunication service providers (telcos) are exposed to\ncyber-attacks executed by compromised IoT devices connected to their customers'\nnetworks. Such attacks might have severe effects not only on the target of\nattacks but also on the telcos themselves. To mitigate those risks we propose a\nmachine learning based method that can detect devices of specific vulnerable\nIoT models connected behind a domestic NAT, thereby identifying home networks\nthat pose a risk to the telco's infrastructure and availability of services. As\npart of the effort to preserve the domestic customers' privacy, our method\nrelies on NetFlow data solely, refraining from inspecting the payload. To\npromote future research in this domain we share our novel dataset, collected in\nour lab from numerous and various commercial IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:09:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Meidan", "Yair", ""], ["Sachidananda", "Vinay", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1905.13435", "submitter": "Kohei Miyaguchi", "authors": "Kohei Miyaguchi", "title": "PAC-Bayesian Transportation Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirically, the PAC-Bayesian analysis is known to produce tight risk bounds\nfor practical machine learning algorithms. However, in its naive form, it can\nonly deal with stochastic predictors while such predictors are rarely used and\ndeterministic predictors often performs well in practice. To fill this gap, we\ndevelop a new generalization error bound, the PAC-Bayesian transportation\nbound, unifying the PAC-Bayesian analysis and the chaining method in view of\nthe optimal transportation. It is the first PAC-Bayesian bound that relates the\nrisks of any two predictors according to their distance, and capable of\nevaluating the cost of de-randomization of stochastic predictors faced with\ncontinuous loss functions. As an example, we give an upper bound on the\nde-randomization cost of spectrally normalized neural networks (NNs) to\nevaluate how much randomness contributes to the generalization of NNs.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:30:35 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 02:29:24 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 03:31:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Miyaguchi", "Kohei", ""]]}, {"id": "1905.13436", "submitter": "Yilun Xu", "authors": "Peng Cao, Yilun Xu, Yuqing Kong, Yizhou Wang", "title": "Max-MIG: an Information Theoretic Approach for Joint Learning from\n  Crowds", "comments": "Accepted by ICLR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eliciting labels from crowds is a potential way to obtain large labeled data.\nDespite a variety of methods developed for learning from crowds, a key\nchallenge remains unsolved: \\emph{learning from crowds without knowing the\ninformation structure among the crowds a priori, when some people of the crowds\nmake highly correlated mistakes and some of them label effortlessly (e.g.\nrandomly)}. We propose an information theoretic approach, Max-MIG, for joint\nlearning from crowds, with a common assumption: the crowdsourced labels and the\ndata are independent conditioning on the ground truth. Max-MIG simultaneously\naggregates the crowdsourced labels and learns an accurate data classifier.\nFurthermore, we devise an accurate data-crowds forecaster that employs both the\ndata and the crowdsourced labels to forecast the ground truth. To the best of\nour knowledge, this is the first algorithm that solves the aforementioned\nchallenge of learning from crowds. In addition to the theoretical validation,\nwe also empirically show that our algorithm achieves the new state-of-the-art\nresults in most settings, including the real-world data, and is the first\nalgorithm that is robust to various information structures. Codes are available\nat\n\\hyperlink{https://github.com/Newbeeer/Max-MIG}{https://github.com/Newbeeer/Max-MIG}\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:32:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cao", "Peng", ""], ["Xu", "Yilun", ""], ["Kong", "Yuqing", ""], ["Wang", "Yizhou", ""]]}, {"id": "1905.13449", "submitter": "Tobias Joppen", "authors": "Tobias Joppen, Tilman Str\\\"ubig, Johannes F\\\"urnkranz", "title": "Ordinal Bucketing for Game Trees using Dynamic Quantile Approximation", "comments": "preprint", "journal-ref": "Proc. IEEE CoG 2019", "doi": "10.1109/CIG.2019.8847965", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple and cheap ordinal bucketing algorithm that\napproximately generates $q$-quantiles from an incremental data stream. The\nbucketing is done dynamically in the sense that the amount of buckets $q$\nincreases with the number of seen samples. We show how this can be used in\nOrdinal Monte Carlo Tree Search (OMCTS) to yield better bounds on time and\nspace complexity, especially in the presence of noisy rewards. Besides\ncomplexity analysis and quality tests of quantiles, we evaluate our method\nusing OMCTS in the General Video Game Framework (GVGAI). Our results\ndemonstrate its dominance over vanilla Monte Carlo Tree Search in the presence\nof noise, where OMCTS without bucketing has a very bad time and space\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:35:03 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Joppen", "Tobias", ""], ["Str\u00fcbig", "Tilman", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1905.13452", "submitter": "Haowen Xu", "authors": "Haowen Xu, Wenxiao Chen, Jinlin Lai, Zhihan Li, Youjian Zhao, Dan Pei", "title": "On the Necessity and Effectiveness of Learning the Prior of Variational\n  Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using powerful posterior distributions is a popular approach to achieving\nbetter variational inference. However, recent works showed that the aggregated\nposterior may fail to match unit Gaussian prior, thus learning the prior\nbecomes an alternative way to improve the lower-bound. In this paper, for the\nfirst time in the literature, we prove the necessity and effectiveness of\nlearning the prior when aggregated posterior does not match unit Gaussian\nprior, analyze why this situation may happen, and propose a hypothesis that\nlearning the prior may improve reconstruction loss, all of which are supported\nby our extensive experiment results. We show that using learned Real NVP prior\nand just one latent variable in VAE, we can achieve test NLL comparable to very\ndeep state-of-the-art hierarchical VAE, outperforming many previous works with\ncomplex hierarchical VAE architectures.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:55:59 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Xu", "Haowen", ""], ["Chen", "Wenxiao", ""], ["Lai", "Jinlin", ""], ["Li", "Zhihan", ""], ["Zhao", "Youjian", ""], ["Pei", "Dan", ""]]}, {"id": "1905.13453", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "MultiQA: An Empirical Investigation of Generalization and Transfer in\n  Reading Comprehension", "comments": "accepted as a long paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of reading comprehension (RC) datasets has been created\nrecently, but little analysis has been done on whether they generalize to one\nanother, and the extent to which existing datasets can be leveraged for\nimproving performance on new ones. In this paper, we conduct such an\ninvestigation over ten RC datasets, training on one or more source RC datasets,\nand evaluating generalization, as well as transfer to a target RC dataset. We\nanalyze the factors that contribute to generalization, and show that training\non a source RC dataset and transferring to a target dataset substantially\nimproves performance, even in the presence of powerful contextual\nrepresentations from BERT (Devlin et al., 2019). We also find that training on\nmultiple source RC datasets leads to robust generalization and transfer, and\ncan reduce the cost of example collection for a new RC dataset. Following our\nanalysis, we propose MultiQA, a BERT-based model, trained on multiple RC\ndatasets, which leads to state-of-the-art performance on five RC datasets. We\nshare our infrastructure for the benefit of the research community.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:05:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1905.13462", "submitter": "Giuseppe Marra", "authors": "Giuseppe Marra and Ond\\v{r}ej Ku\\v{z}elka", "title": "Neural Markov Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce neural Markov logic networks (NMLNs), a statistical relational\nlearning system that borrows ideas from Markov logic. Like Markov logic\nnetworks (MLNs), NMLNs are an exponential-family model for modelling\ndistributions over possible worlds, but unlike MLNs, they do not rely on\nexplicitly specified first-order logic rules. Instead, NMLNs learn an implicit\nrepresentation of such rules as a neural network that acts as a potential\nfunction on fragments of the relational structure. Similarly to many neural\nsymbolic methods, NMLNs can exploit embeddings of constants but, unlike them,\nNMLNs work well also in their absence. This is extremely important for\npredicting in settings other than the transductive one. We showcase the\npotential of NMLNs on knowledge-base completion, triple classification and on\ngeneration of molecular (graph) data.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 08:32:18 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 16:54:39 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:01:02 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Marra", "Giuseppe", ""], ["Ku\u017eelka", "Ond\u0159ej", ""]]}, {"id": "1905.13469", "submitter": "Ben Deverett", "authors": "Ben Deverett, Ryan Faulkner, Meire Fortunato, Greg Wayne, Joel Z.\n  Leibo", "title": "Interval timing in deep reinforcement learning agents", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of time is central to intelligent behavior. We know that both\nanimals and artificial agents can successfully use temporal dependencies to\nselect actions. In artificial agents, little work has directly addressed (1)\nwhich architectural components are necessary for successful development of this\nability, (2) how this timing ability comes to be represented in the units and\nactions of the agent, and (3) whether the resulting behavior of the system\nconverges on solutions similar to those of biology. Here we studied interval\ntiming abilities in deep reinforcement learning agents trained end-to-end on an\ninterval reproduction paradigm inspired by experimental literature on\nmechanisms of timing. We characterize the strategies developed by recurrent and\nfeedforward agents, which both succeed at temporal reproduction using distinct\nmechanisms, some of which bear specific and intriguing similarities to\nbiological systems. These findings advance our understanding of how agents come\nto represent time, and they highlight the value of experimentally inspired\napproaches to characterizing agent abilities.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:05:31 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 15:56:26 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Deverett", "Ben", ""], ["Faulkner", "Ryan", ""], ["Fortunato", "Meire", ""], ["Wayne", "Greg", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1905.13472", "submitter": "Andrey Malinin", "authors": "Andrey Malinin and Mark Gales", "title": "Reverse KL-Divergence Training of Prior Networks: Improved Uncertainty\n  and Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble approaches for uncertainty estimation have recently been applied to\nthe tasks of misclassification detection, out-of-distribution input detection\nand adversarial attack detection. Prior Networks have been proposed as an\napproach to efficiently \\emph{emulate} an ensemble of models for classification\nby parameterising a Dirichlet prior distribution over output distributions.\nThese models have been shown to outperform alternative ensemble approaches,\nsuch as Monte-Carlo Dropout, on the task of out-of-distribution input\ndetection. However, scaling Prior Networks to complex datasets with many\nclasses is difficult using the training criteria originally proposed. This\npaper makes two contributions. First, we show that the appropriate training\ncriterion for Prior Networks is the \\emph{reverse} KL-divergence between\nDirichlet distributions. This addresses issues in the nature of the training\ndata target distributions, enabling prior networks to be successfully trained\non classification tasks with arbitrarily many classes, as well as improving\nout-of-distribution detection performance. Second, taking advantage of this new\ntraining criterion, this paper investigates using Prior Networks to detect\nadversarial attacks and proposes a generalized form of adversarial training. It\nis shown that the construction of successful \\emph{adaptive} whitebox attacks,\nwhich affect the prediction and evade detection, against Prior Networks trained\non CIFAR-10 and CIFAR-100 using the proposed approach requires a greater amount\nof computational effort than against networks defended using standard\nadversarial training or MC-dropout.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:07:45 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 14:50:14 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "1905.13476", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski and Daniele Calandriello and Michal Valko", "title": "Exact sampling of determinantal point processes with sublinear time\n  preprocessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of sampling from a distribution over all index\nsubsets of the set $\\{1,...,n\\}$ with the probability of a subset $S$\nproportional to the determinant of the submatrix $\\mathbf{L}_S$ of some\n$n\\times n$ p.s.d. matrix $\\mathbf{L}$, where $\\mathbf{L}_S$ corresponds to the\nentries of $\\mathbf{L}$ indexed by $S$. Known as a determinantal point process,\nthis distribution is used in machine learning to induce diversity in subset\nselection. In practice, we often wish to sample multiple subsets $S$ with small\nexpected size $k = E[|S|] \\ll n$ from a very large matrix $\\mathbf{L}$, so it\nis important to minimize the preprocessing cost of the procedure (performed\nonce) as well as the sampling cost (performed repeatedly). For this purpose, we\npropose a new algorithm which, given access to $\\mathbf{L}$, samples exactly\nfrom a determinantal point process while satisfying the following two\nproperties: (1) its preprocessing cost is $n \\cdot \\text{poly}(k)$, i.e.,\nsublinear in the size of $\\mathbf{L}$, and (2) its sampling cost is\n$\\text{poly}(k)$, i.e., independent of the size of $\\mathbf{L}$. Prior to our\nresults, state-of-the-art exact samplers required $O(n^3)$ preprocessing time\nand sampling time linear in $n$ or dependent on the spectral properties of\n$\\mathbf{L}$. We also give a reduction which allows using our algorithm for\nexact sampling from cardinality constrained determinantal point processes with\n$n\\cdot\\text{poly}(k)$ time preprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:21:26 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 22:08:47 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Calandriello", "Daniele", ""], ["Valko", "Michal", ""]]}, {"id": "1905.13526", "submitter": "Jonas M. K\\\"ubler", "authors": "Jonas M. K\\\"ubler, Krikamol Muandet, Bernhard Sch\\\"olkopf", "title": "Quantum Mean Embedding of Probability Distributions", "comments": "7 pages, 2 figures", "journal-ref": "Phys. Rev. Research 1, 033159 (2019)", "doi": "10.1103/PhysRevResearch.1.033159", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel mean embedding of probability distributions is commonly used in\nmachine learning as an injective mapping from distributions to functions in an\ninfinite dimensional Hilbert space. It allows us, for example, to define a\ndistance measure between probability distributions, called maximum mean\ndiscrepancy (MMD). In this work, we propose to represent probability\ndistributions in a pure quantum state of a system that is described by an\ninfinite dimensional Hilbert space. This enables us to work with an explicit\nrepresentation of the mean embedding, whereas classically one can only work\nimplicitly with an infinite dimensional Hilbert space through the use of the\nkernel trick. We show how this explicit representation can speed up methods\nthat rely on inner products of mean embeddings and discuss the theoretical and\nexperimental challenges that need to be solved in order to achieve these\nspeedups.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:47:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["K\u00fcbler", "Jonas M.", ""], ["Muandet", "Krikamol", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1905.13528", "submitter": "Daniele Castellana", "authors": "Daniele Castellana, Davide Bacciu", "title": "Bayesian Tensor Factorisation for Bottom-up Hidden Tree Markov Models", "comments": "Accepted at IJCNN19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bottom-Up Hidden Tree Markov Model is a highly expressive model for\ntree-structured data. Unfortunately, it cannot be used in practice due to the\nintractable size of its state-transition matrix. We propose a new approximation\nwhich lies on the Tucker factorisation of tensors. The probabilistic\ninterpretation of such approximation allows us to define a new probabilistic\nmodel for tree-structured data. Hence, we define the new approximated model and\nwe derive its learning algorithm. Then, we empirically assess the effective\npower of the new model evaluating it on two different tasks. In both cases, our\nmodel outperforms the other approximated model known in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 12:03:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Castellana", "Daniele", ""], ["Bacciu", "Davide", ""]]}, {"id": "1905.13536", "submitter": "Christopher Canel", "authors": "Christopher Canel, Thomas Kim, Giulio Zhou, Conglong Li, Hyeontaek\n  Lim, David G. Andersen, Michael Kaminsky, Subramanya R. Dulloor", "title": "Scaling Video Analytics on Constrained Edge Nodes", "comments": "This paper is an extended version of a paper with the same title\n  published in the 2nd SysML Conference, SysML '19 (Canel et. al., 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As video camera deployments continue to grow, the need to process large\nvolumes of real-time data strains wide area network infrastructure. When\nper-camera bandwidth is limited, it is infeasible for applications such as\ntraffic monitoring and pedestrian tracking to offload high-quality video\nstreams to a datacenter. This paper presents FilterForward, a new edge-to-cloud\nsystem that enables datacenter-based applications to process content from\nthousands of cameras by installing lightweight edge filters that backhaul only\nrelevant video frames. FilterForward introduces fast and expressive\nper-application microclassifiers that share computation to simultaneously\ndetect dozens of events on computationally constrained edge nodes. Only\nmatching events are transmitted to the cloud. Evaluation on two real-world\ncamera feed datasets shows that FilterForward reduces bandwidth use by an order\nof magnitude while improving computational efficiency and event detection\naccuracy for challenging video content.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 23:11:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Canel", "Christopher", ""], ["Kim", "Thomas", ""], ["Zhou", "Giulio", ""], ["Li", "Conglong", ""], ["Lim", "Hyeontaek", ""], ["Andersen", "David G.", ""], ["Kaminsky", "Michael", ""], ["Dulloor", "Subramanya R.", ""]]}, {"id": "1905.13538", "submitter": "Guillaume Jaume", "authors": "Guillaume Jaume, Hazim Kemal Ekenel, Jean-Philippe Thiran", "title": "FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents", "comments": "ICDAR'19 OST workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new dataset for form understanding in noisy scanned documents\n(FUNSD) that aims at extracting and structuring the textual content of forms.\nThe dataset comprises 199 real, fully annotated, scanned forms. The documents\nare noisy and vary widely in appearance, making form understanding (FoUn) a\nchallenging task. The proposed dataset can be used for various tasks, including\ntext detection, optical character recognition, spatial layout analysis, and\nentity labeling/linking. To the best of our knowledge, this is the first\npublicly available dataset with comprehensive annotations to address FoUn task.\nWe also present a set of baselines and introduce metrics to evaluate\nperformance on the FUNSD dataset, which can be downloaded at\nhttps://guillaumejaume.github.io/FUNSD/.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:40:40 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:46:39 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Jaume", "Guillaume", ""], ["Ekenel", "Hazim Kemal", ""], ["Thiran", "Jean-Philippe", ""]]}, {"id": "1905.13539", "submitter": "Mickael Chen", "authors": "Micka\\\"el Chen, Thierry Arti\\`eres, Ludovic Denoyer", "title": "Unsupervised Object Segmentation by Redrawing", "comments": "Presented at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object segmentation is a crucial problem that is usually solved by using\nsupervised learning approaches over very large datasets composed of both images\nand corresponding object masks. Since the masks have to be provided at pixel\nlevel, building such a dataset for any new domain can be very time-consuming.\nWe present ReDO, a new model able to extract objects from images without any\nannotation in an unsupervised way. It relies on the idea that it should be\npossible to change the textures or colors of the objects without changing the\noverall distribution of the dataset. Following this assumption, our approach is\nbased on an adversarial architecture where the generator is guided by an input\nsample: given an image, it extracts the object mask, then redraws a new object\nat the same location. The generator is controlled by a discriminator that\nensures that the distribution of generated images is aligned to the original\none. We experiment with this method on different datasets and demonstrate the\ngood quality of extracted masks.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:34:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 17:33:04 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 16:38:18 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 17:00:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Chen", "Micka\u00ebl", ""], ["Arti\u00e8res", "Thierry", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1905.13540", "submitter": "Junyeong Kim", "authors": "Junyeong Kim, Minuk Ma, Kyungsu Kim, Sungjin Kim, Chang D. Yoo", "title": "Gaining Extra Supervision via Multi-task learning for Multi-Modal Video\n  Question Answering", "comments": "Accepted to IJCNN2019, oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to gain extra supervision via multi-task\nlearning for multi-modal video question answering. Multi-modal video question\nanswering is an important task that aims at the joint understanding of vision\nand language. However, establishing large scale dataset for multi-modal video\nquestion answering is expensive and the existing benchmarks are relatively\nsmall to provide sufficient supervision. To overcome this challenge, this paper\nproposes a multi-task learning method which is composed of three main\ncomponents: (1) multi-modal video question answering network that answers the\nquestion based on the both video and subtitle feature, (2) temporal retrieval\nnetwork that predicts the time in the video clip where the question was\ngenerated from and (3) modality alignment network that solves metric learning\nproblem to find correct association of video and subtitle modalities. By\nsimultaneously solving related auxiliary tasks with hierarchically shared\nintermediate layers, the extra synergistic supervisions are provided. Motivated\nby curriculum learning, multi task ratio scheduling is proposed to learn easier\ntask earlier to set inductive bias at the beginning of the training. The\nexperiments on publicly available dataset TVQA shows state-of-the-art results,\nand ablation studies are conducted to prove the statistical validity.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:46:20 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Kim", "Junyeong", ""], ["Ma", "Minuk", ""], ["Kim", "Kyungsu", ""], ["Kim", "Sungjin", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1905.13543", "submitter": "Xiawu Zheng", "authors": "Xiawu Zheng, Rongrong Ji, Lang Tang, Yan Wan, Baochang Zhang, Yongjian\n  Wu, Yunsheng Wu, Ling Shao", "title": "Dynamic Distribution Pruning for Efficient Network Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network architectures obtained by Neural Architecture Search (NAS) have shown\nstate-of-the-art performance in various computer vision tasks. Despite the\nexciting progress, the computational complexity of the forward-backward\npropagation and the search process makes it difficult to apply NAS in practice.\nIn particular, most previous methods require thousands of GPU days for the\nsearch process to converge. In this paper, we propose a dynamic distribution\npruning method towards extremely efficient NAS, which samples architectures\nfrom a joint categorical distribution. The search space is dynamically pruned\nevery a few epochs to update this distribution, and the optimal neural\narchitecture is obtained when there is only one structure remained. We conduct\nexperiments on two widely-used datasets in NAS. On CIFAR-10, the optimal\nstructure obtained by our method achieves the state-of-the-art $1.9$\\% test\nerror, while the search process is more than $1,000$ times faster (only $1.5$\nGPU hours on a Tesla V100) than the state-of-the-art NAS algorithms. On\nImageNet, our model achieves 75.2\\% top-1 accuracy under the MobileNet\nsettings, with a time cost of only $2$ GPU days that is $100\\%$ acceleration\nover the fastest NAS algorithm. The code is available at \\url{\nhttps://github.com/tanglang96/DDPNAS}\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:35:52 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 11:42:41 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zheng", "Xiawu", ""], ["Ji", "Rongrong", ""], ["Tang", "Lang", ""], ["Wan", "Yan", ""], ["Zhang", "Baochang", ""], ["Wu", "Yongjian", ""], ["Wu", "Yunsheng", ""], ["Shao", "Ling", ""]]}, {"id": "1905.13545", "submitter": "Haohan Wang", "authors": "Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P. Xing", "title": "High Frequency Component Helps Explain the Generalization of\n  Convolutional Neural Networks", "comments": "To appear at CVPR 2020 as an Oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between the frequency spectrum of image data\nand the generalization behavior of convolutional neural networks (CNN). We\nfirst notice CNN's ability in capturing the high-frequency components of\nimages. These high-frequency components are almost imperceptible to a human.\nThus the observation leads to multiple hypotheses that are related to the\ngeneralization behaviors of CNN, including a potential explanation for\nadversarial examples, a discussion of CNN's trade-off between robustness and\naccuracy, and some evidence in understanding training heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 19:42:04 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 11:57:59 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 20:22:59 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Wang", "Haohan", ""], ["Wu", "Xindi", ""], ["Huang", "Zeyi", ""], ["Xing", "Eric P.", ""]]}, {"id": "1905.13546", "submitter": "Oliver Struckmeier", "authors": "Oliver Struckmeier", "title": "LeagueAI: Improving object detector performance and flexibility through\n  automatically generated training data and domain randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report I present my method for automatic synthetic dataset\ngeneration for object detection and demonstrate it on the video game League of\nLegends. This report furthermore serves as a handbook on how to automatically\ngenerate datasets and as an introduction on the dataset generation part of the\nLeagueAI framework. The LeagueAI framework is a software framework that\nprovides detailed information about the game League of Legends based on the\nsame input a human player would have, namely vision. The framework allows\nresearchers and enthusiasts to develop their own intelligent agents or to\nextract detailed information about the state of the game. A big problem of\nmachine vision applications usually is the laborious work of gathering large\namounts of hand labeled data. Thus, a crucial part of the vision pipeline of\nthe LeagueAI framework, the dataset generation, is presented in this report.\nThe method involves extracting image raw data from the game's 3D models and\ncombining them with the game background to create game-like synthetic images\nand to generate the corresponding labels automatically. In an experiment I\ncompared a model trained on synthetic data to a model trained on hand labeled\ndata and a model trained on a combined dataset. The model trained on the\nsynthetic data showed higher detection precision on more classes and more\nreliable tracking performance of the player character. The model trained on the\ncombined dataset did not perform better because of the different formats of the\nolder hand labeled dataset and the synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:07:22 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Struckmeier", "Oliver", ""]]}, {"id": "1905.13547", "submitter": "Benjamin Gravell", "authors": "Benjamin Gravell, Peyman Mohajerin Esfahani, Tyler Summers", "title": "Learning robust control for LQR systems with multiplicative noise via\n  policy gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear quadratic regulator (LQR) problem has reemerged as an important\ntheoretical benchmark for reinforcement learning-based control of complex\ndynamical systems with continuous state and action spaces. In contrast with\nnearly all recent work in this area, we consider multiplicative noise models,\nwhich are increasingly relevant because they explicitly incorporate inherent\nuncertainty and variation in the system dynamics and thereby improve robustness\nproperties of the controller. Robustness is a critical and poorly understood\nissue in reinforcement learning; existing methods which do not account for\nuncertainty can converge to fragile policies or fail to converge at all.\nAdditionally, intentional injection of multiplicative noise into learning\nalgorithms can enhance robustness of policies, as observed in ad hoc work on\ndomain randomization. Although policy gradient algorithms require optimization\nof a non-convex cost function, we show that the multiplicative noise LQR cost\nhas a special property called gradient domination, which is exploited to prove\nglobal convergence of policy gradient algorithms to the globally optimum\ncontrol policy with polynomial dependence on problem parameters. Results are\nprovided both in the model-known and model-unknown settings where samples of\nsystem trajectories are used to estimate policy gradients.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:22:24 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:21:35 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 02:51:18 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 16:42:29 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gravell", "Benjamin", ""], ["Esfahani", "Peyman Mohajerin", ""], ["Summers", "Tyler", ""]]}, {"id": "1905.13548", "submitter": "Benjamin Gravell", "authors": "Benjamin Gravell, Yi Guo, Tyler Summers", "title": "Sparse optimal control of networks with multiplicative noise via policy\n  gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms for designing near-optimal sparse controllers using policy\ngradient with applications to control of systems corrupted by multiplicative\nnoise, which is increasingly important in emerging complex dynamical networks.\nVarious regularization schemes are examined and incorporated into the\noptimization by the use of gradient, subgradient, and proximal gradient\nmethods. Numerical experiments on a large networked system show that the\nalgorithms converge to performant sparse mean-square stabilizing controllers.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:32:53 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Gravell", "Benjamin", ""], ["Guo", "Yi", ""], ["Summers", "Tyler", ""]]}, {"id": "1905.13550", "submitter": "Pei Du", "authors": "Pei Du, Jianzhou Wang, Yan Hao, Tong Niu, Wendong Yang", "title": "A novel hybrid model based on multi-objective Harris hawks optimization\n  algorithm for daily PM2.5 and PM10 forecasting", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High levels of air pollution may seriously affect people's living environment\nand even endanger their lives. In order to reduce air pollution concentrations,\nand warn the public before the occurrence of hazardous air pollutants, it is\nurgent to design an accurate and reliable air pollutant forecasting model.\nHowever, most previous research have many deficiencies, such as ignoring the\nimportance of predictive stability, and poor initial parameters and so on,\nwhich have significantly effect on the performance of air pollution prediction.\nTherefore, to address these issues, a novel hybrid model is proposed in this\nstudy. Specifically, a powerful data preprocessing techniques is applied to\ndecompose the original time series into different modes from low- frequency to\nhigh- frequency. Next, a new multi-objective algorithm called MOHHO is first\ndeveloped in this study, which are introduced to tune the parameters of ELM\nmodel with high forecasting accuracy and stability for air pollution series\nprediction, simultaneously. And the optimized ELM model is used to perform the\ntime series prediction. Finally, a scientific and robust evaluation system\nincluding several error criteria, benchmark models, and several experiments\nusing six air pollutant concentrations time series from three cities in China\nis designed to perform a compressive assessment for the presented hybrid\nforecasting model. Experimental results indicate that the proposed hybrid model\ncan guarantee a more stable and higher predictive performance compared to\nothers, whose superior prediction ability may help to develop effective plans\nfor air pollutant emissions and prevent health problems caused by air\npollution.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:33:59 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Du", "Pei", ""], ["Wang", "Jianzhou", ""], ["Hao", "Yan", ""], ["Niu", "Tong", ""], ["Yang", "Wendong", ""]]}, {"id": "1905.13551", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang", "title": "Recurrent Existence Determination Through Policy Optimization", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary determination of the presence of objects is one of the problems where\nhumans perform extraordinarily better than computer vision systems, in terms of\nboth speed and preciseness. One of the possible reasons is that humans can skip\nmost of the clutter and attend only on salient regions. Recurrent attention\nmodels (RAM) are the first computational models to imitate the way humans\nprocess images via the REINFORCE algorithm. Despite that RAM is originally\ndesigned for image recognition, we extend it and present recurrent existence\ndetermination, an attention-based mechanism to solve the existence\ndetermination. Our algorithm employs a novel $k$-maximum aggregation layer and\na new reward mechanism to address the issue of delayed rewards, which would\nhave caused the instability of the training process. The experimental analysis\ndemonstrates significant efficiency and accuracy improvement over existing\napproaches, on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 06:40:51 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 21:38:05 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Baoxiang", ""]]}, {"id": "1905.13559", "submitter": "Martin Mladenov", "authors": "Martin Mladenov, Ofer Meshi, Jayden Ooi, Dale Schuurmans, Craig\n  Boutilier", "title": "Advantage Amplification in Slowly Evolving Latent-State Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent-state environments with long horizons, such as those faced by\nrecommender systems, pose significant challenges for reinforcement learning\n(RL). In this work, we identify and analyze several key hurdles for RL in such\nenvironments, including belief state error and small action advantage. We\ndevelop a general principle of advantage amplification that can overcome these\nhurdles through the use of temporal abstraction. We propose several aggregation\nmethods and prove they induce amplification in certain settings. We also bound\nthe loss in optimality incurred by our methods in environments where latent\nstate evolves slowly and demonstrate their performance empirically in a\nstylized user-modeling task.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 21:57:02 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Mladenov", "Martin", ""], ["Meshi", "Ofer", ""], ["Ooi", "Jayden", ""], ["Schuurmans", "Dale", ""], ["Boutilier", "Craig", ""]]}, {"id": "1905.13560", "submitter": "Xing Liu", "authors": "Xing Liu, Takayuki Okatani", "title": "Evaluating Artificial Systems for Pairwise Ranking Tasks Sensitive to\n  Individual Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the advancement of deep learning, artificial systems are now rival\nto humans in several pattern recognition tasks, such as visual recognition of\nobject categories. However, this is only the case with the tasks for which\ncorrect answers exist independent of human perception. There is another type of\ntasks for which what to predict is human perception itself, in which there are\noften individual differences. Then, there are no longer single \"correct\"\nanswers to predict, which makes evaluation of artificial systems difficult. In\nthis paper, focusing on pairwise ranking tasks sensitive to individual\ndifferences, we propose an evaluation method. Given a ranking result for\nmultiple item pairs that is generated by an artificial system, our method\nquantifies the probability that the same ranking result will be generated by\nhumans, and judges if it is distinguishable from human-generated results. We\nintroduce a probabilistic model of human ranking behavior, and present an\nefficient computation method for the judgment. To estimate model parameters\naccurately from small-size samples, we present a method that uses confidence\nscores given by annotators for ranking each item pair. Taking as an example a\ntask of ranking image pairs according to material attributes of objects, we\ndemonstrate how the proposed method works.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:13:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Liu", "Xing", ""], ["Okatani", "Takayuki", ""]]}, {"id": "1905.13561", "submitter": "Fuming Fang", "authors": "Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen, Massimiliano\n  Todisco, Nicholas Evans, Jean-Francois Bonastre", "title": "Speaker Anonymization Using X-vector and Neural Waveform Models", "comments": "Submitted to the 10th ISCA Speech Synthesis Workshop (SSW10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social media revolution has produced a plethora of web services to which\nusers can easily upload and share multimedia documents. Despite the popularity\nand convenience of such services, the sharing of such inherently personal data,\nincluding speech data, raises obvious security and privacy concerns. In\nparticular, a user's speech data may be acquired and used with speech synthesis\nsystems to produce high-quality speech utterances which reflect the same user's\nspeaker identity. These utterances may then be used to attack speaker\nverification systems. One solution to mitigate these concerns involves the\nconcealing of speaker identities before the sharing of speech data. For this\npurpose, we present a new approach to speaker anonymization. The idea is to\nextract linguistic and speaker identity features from an utterance and then to\nuse these with neural acoustic and waveform models to synthesize anonymized\nspeech. The original speaker identity, in the form of timbre, is suppressed and\nreplaced with that of an anonymous pseudo identity. The approach exploits\nstate-of-the-art x-vector speaker representations. These are used to derive\nanonymized pseudo speaker identities through the combination of multiple,\nrandom speaker x-vectors. Experimental results show that the proposed approach\nis effective in concealing speaker identities. It increases the equal error\nrate of a speaker verification system while maintaining high quality,\nanonymized speech.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 01:33:31 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""], ["Todisco", "Massimiliano", ""], ["Evans", "Nicholas", ""], ["Bonastre", "Jean-Francois", ""]]}, {"id": "1905.13562", "submitter": "Mohammadreza Nazari", "authors": "Mohammadreza Nazari, Majid Jahani, Lawrence V. Snyder, Martin\n  Tak\\'a\\v{c}", "title": "Don't Forget Your Teacher: A Corrective Reinforcement Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although reinforcement learning (RL) can provide reliable solutions in many\nsettings, practitioners are often wary of the discrepancies between the RL\nsolution and their status quo procedures. Therefore, they may be reluctant to\nadapt to the novel way of executing tasks proposed by RL. On the other hand,\nmany real-world problems require relatively small adjustments from the status\nquo policies to achieve improved performance. Therefore, we propose a\nstudent-teacher RL mechanism in which the RL (the \"student\") learns to maximize\nits reward, subject to a constraint that bounds the difference between the RL\npolicy and the \"teacher\" policy. The teacher can be another RL policy (e.g.,\ntrained under a slightly different setting), the status quo policy, or any\nother exogenous policy. We formulate this problem using a stochastic\noptimization model and solve it using a primal-dual policy gradient algorithm.\nWe prove that the policy is asymptotically optimal. However, a naive\nimplementation suffers from high variance and convergence to a stochastic\noptimal policy. With a few practical adjustments to address these issues, our\nnumerical experiments confirm the effectiveness of our proposed method in\nmultiple GridWorld scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 01:47:18 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Nazari", "Mohammadreza", ""], ["Jahani", "Majid", ""], ["Snyder", "Lawrence V.", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1905.13565", "submitter": "Ronny Luss", "authors": "Amit Dhurandhar, Karthikeyan Shanmugam, Ronny Luss", "title": "Enhancing Simple Models by Exploiting What They Already Know", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent interest in improving performance of simple models for\nmultiple reasons such as interpretability, robust learning from small data,\ndeployment in memory constrained settings as well as environmental\nconsiderations. In this paper, we propose a novel method SRatio that can\nutilize information from high performing complex models (viz. deep neural\nnetworks, boosted trees, random forests) to reweight a training dataset for a\npotentially low performing simple model of much lower complexity such as a\ndecision tree or a shallow network enhancing its performance. Our method also\nleverages the per sample hardness estimate of the simple model which is not the\ncase with the prior works which primarily consider the complex model's\nconfidences/predictions and is thus conceptually novel. Moreover, we generalize\nand formalize the concept of attaching probes to intermediate layers of a\nneural network to other commonly used classifiers and incorporate this into our\nmethod. The benefit of these contributions is witnessed in the experiments\nwhere on 6 UCI datasets and CIFAR-10 we outperform competitors in a majority\n(16 out of 27) of the cases and tie for best performance in the remaining\ncases. In fact, in a couple of cases, we even approach the complex model's\nperformance. We also conduct further experiments to validate assertions and\nintuitively understand why our method works. Theoretically, we motivate our\napproach by showing that the weighted loss minimized by simple models using our\nweighting upper bounds the loss of the complex model.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 03:16:36 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 20:19:38 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 21:17:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Shanmugam", "Karthikeyan", ""], ["Luss", "Ronny", ""]]}, {"id": "1905.13566", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Recent Advances in Imitation Learning from Observation", "comments": "International Joint Conference on Artificial Intelligence (IJCAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is the process by which one agent tries to learn how to\nperform a certain task using information generated by another, often\nmore-expert agent performing that same task. Conventionally, the imitator has\naccess to both state and action information generated by an expert performing\nthe task (e.g., the expert may provide a kinesthetic demonstration of object\nplacement using a robotic arm). However, requiring the action information\nprevents imitation learning from a large number of existing valuable learning\nresources such as online videos of humans performing tasks. To overcome this\nissue, the specific problem of imitation from observation (IfO) has recently\ngarnered a great deal of attention, in which the imitator only has access to\nthe state information (e.g., video frames) generated by the expert. In this\npaper, we provide a literature review of methods developed for IfO, and then\npoint out some open research problems and potential future work.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:54:30 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 03:55:09 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1905.13568", "submitter": "Kunping Li", "authors": "Kunping Li", "title": "Quantization Loss Re-Learning Method", "comments": "9 pages, 2 figures, 6 tables, 33rd Conference on Neural Information\n  Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to quantize the gate parameters of the LSTM (Long Short-Term Memory)\nneural network model with almost no recognition performance degraded, a new\nquantization method named Quantization Loss Re-Learn Method is proposed in this\npaper. The method does lossy quantization on gate parameters during training\niterations, and the weight parameters learn to offset the loss of gate\nparameters quantization by adjusting the gradient in back propagation during\nweight parameters optimization. We proved the effectiveness of this method\nthrough theoretical derivation and experiments. The gate parameters had been\nquantized to 0, 0.5, 1 three values, and on the Named Entity Recognition\ndataset, the F1 score of the model with the new quantization method on gate\nparameters decreased by only 0.7% compared to the baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 08:19:04 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Li", "Kunping", ""]]}, {"id": "1905.13570", "submitter": "Tan Zhi-Xuan", "authors": "Tan Zhi-Xuan, Harold Soh, Desmond C. Ong", "title": "Factorized Inference in Deep Markov Models for Incomplete Multimodal\n  Time Series", "comments": "8 pages, 4 figures, accepted to AAAI 2020, code available at:\n  https://github.com/ztangent/multimodal-dmm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating deep learning with latent state space models has the potential to\nyield temporal models that are powerful, yet tractable and interpretable.\nUnfortunately, current models are not designed to handle missing data or\nmultiple data modalities, which are both prevalent in real-world data. In this\nwork, we introduce a factorized inference method for Multimodal Deep Markov\nModels (MDMMs), allowing us to filter and smooth in the presence of missing\ndata, while also performing uncertainty-aware multimodal fusion. We derive this\nmethod by factorizing the posterior p(z|x) for non-linear state space models,\nand develop a variational backward-forward algorithm for inference. Because our\nmethod handles incompleteness over both time and modalities, it is capable of\ninterpolation, extrapolation, conditional generation, label prediction, and\nweakly supervised learning of multimodal time series. We demonstrate these\ncapabilities on both synthetic and real-world multimodal data under high levels\nof data deletion. Our method performs well even with more than 50% missing\ndata, and outperforms existing deep approaches to inference in latent time\nseries.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:20:32 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 11:41:49 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:34:39 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhi-Xuan", "Tan", ""], ["Soh", "Harold", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1905.13573", "submitter": "Sheng-Lun Kao", "authors": "Yi-Wen Liu, Sheng-Lun Kao, Hau-Tieng Wu, Tzu-Chi Liu, Te-Yung Fang,\n  Pa-Chun Wang", "title": "Transient-evoked otoacoustic emission signals predicting outcomes of\n  acute sensorineural hearing loss in patients with Meniere's Disease", "comments": "This is a journal version accepted by Acta Oto-Laryngologica on\n  December 6, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Fluctuating hearing loss is characteristic of Meniere's Disease\n(MD) during acute episodes. However, no reliable audiometric hallmarks are\navailable for counselling the hearing recovery possibility. Aims/Objectives: To\nfind parameters for predicting MD hearing outcomes. Material and Methods: We\napplied machine learning techniques to analyse transient-evoked otoacoustic\nemission (TEOAE) signals recorded from patients with MD. Thirty unilateral MD\npatients were recruited prospectively after onset of acute cochleo-vestibular\nsymptoms. Serial TEOAE and pure-tone audiogram (PTA) data were recorded\nlongitudinally. Denoised TEOAE signals were projected onto the three most\nprominent principal directions through a linear transformation. Binary\nclassification was performed using a support vector machine (SVM). TEOAE signal\nparameters, including signal energy and group delay, were compared between\nimproved and nonimproved groups using Welchs t-test. Results: Signal energy did\nnot differ (p = 0.64) but a significant difference in 1-kHz (p = 0.045) group\ndelay was recorded between improved and nonimproved groups. The SVM achieved a\ncross-validated accuracy of >80% in predicting hearing outcomes. Conclusions\nand Significance: This study revealed that baseline TEOAE parameters obtained\nduring acute MD episodes, when processed through machine learning technology,\nmay provide information on outer hair cell function to predict hearing\nrecovery.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:31:52 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 03:44:42 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Liu", "Yi-Wen", ""], ["Kao", "Sheng-Lun", ""], ["Wu", "Hau-Tieng", ""], ["Liu", "Tzu-Chi", ""], ["Fang", "Te-Yung", ""], ["Wang", "Pa-Chun", ""]]}, {"id": "1905.13577", "submitter": "Quanming Yao", "authors": "Quanming Yao and Ju Xu and Wei-Wei Tu and Zhanxing Zhu", "title": "Efficient Neural Architecture Search via Proximal Iterations", "comments": "Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) recently attracts much research attention\nbecause of its ability to identify better architectures than handcrafted ones.\nHowever, many NAS methods, which optimize the search process in a discrete\nsearch space, need many GPU days for convergence. Recently, DARTS, which\nconstructs a differentiable search space and then optimizes it by gradient\ndescent, can obtain high-performance architecture and reduces the search time\nto several days. However, DARTS is still slow as it updates an ensemble of all\noperations and keeps only one after convergence. Besides, DARTS can converge to\ninferior architectures due to the strong correlation among operations. In this\npaper, we propose a new differentiable Neural Architecture Search method based\non Proximal gradient descent (denoted as NASP). Different from DARTS, NASP\nreformulates the search process as an optimization problem with a constraint\nthat only one operation is allowed to be updated during forward and backward\npropagation. Since the constraint is hard to deal with, we propose a new\nalgorithm inspired by proximal iterations to solve it. Experiments on various\ntasks demonstrate that NASP can obtain high-performance architectures with 10\ntimes of speedup on the computational time than DARTS.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:24:09 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 01:43:23 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 23:29:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yao", "Quanming", ""], ["Xu", "Ju", ""], ["Tu", "Wei-Wei", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1905.13587", "submitter": "Soeren Laue", "authors": "S\\\"oren Laue, Matthias Mitterreiter, Joachim Giesen", "title": "GENO -- GENeric Optimization for Classical Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although optimization is the longstanding algorithmic backbone of machine\nlearning, new models still require the time-consuming implementation of new\nsolvers. As a result, there are thousands of implementations of optimization\nalgorithms for machine learning problems. A natural question is, if it is\nalways necessary to implement a new solver, or if there is one algorithm that\nis sufficient for most models. Common belief suggests that such a\none-algorithm-fits-all approach cannot work, because this algorithm cannot\nexploit model specific structure and thus cannot be efficient and robust on a\nwide variety of problems. Here, we challenge this common belief. We have\ndesigned and implemented the optimization framework GENO (GENeric Optimization)\nthat combines a modeling language with a generic solver. GENO generates a\nsolver from the declarative specification of an optimization problem class. The\nframework is flexible enough to encompass most of the classical machine\nlearning problems. We show on a wide variety of classical but also some\nrecently suggested problems that the automatically generated solvers are (1) as\nefficient as well-engineered specialized solvers, (2) more efficient by a\ndecent margin than recent state-of-the-art solvers, and (3) orders of magnitude\nmore efficient than classical modeling language plus solver approaches.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 12:50:08 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Laue", "S\u00f6ren", ""], ["Mitterreiter", "Matthias", ""], ["Giesen", "Joachim", ""]]}, {"id": "1905.13598", "submitter": "Ayokunle Damilola Familua Dr", "authors": "Ayokunle Damilola Familua", "title": "A Block Diagonal Markov Model for Indoor Software-Defined Power Line\n  Communication", "comments": "Conference Paper with 9 pages, 6 figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Semi-Hidden Markov Model (SHMM) for bursty error channels is defined by a\nstate transition probability matrix $A$, a prior probability vector $\\Pi$, and\nthe state dependent output symbol error probability matrix $B$. Several\nprocesses are utilized for estimating $A$, $\\Pi$ and $B$ from a given\nempirically obtained or simulated error sequence. However, despite placing some\nrestrictions on the underlying Markov model structure, we still have a\ncomputationally intensive estimation procedure, especially given a large error\nsequence containing long burst of identical symbols. Thus, in this paper, we\nutilize under some moderate assumptions, a Markov model with random state\ntransition matrix $A$ equivalent to a unique Block Diagonal Markov model with\nstate transition matrix $\\Lambda$ to model an indoor software-defined power\nline communication system. A computationally efficient modified Baum-Welch\nalgorithm for estimation of $\\Lambda$ given an experimentally obtained error\nsequence from the indoor PLC channel is utilized. Resulting Equivalent Block\nDiagonal Markov models assist designers to accelerate and facilitate the\nprocedure of novel PLC systems design and evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:35:05 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Familua", "Ayokunle Damilola", ""]]}, {"id": "1905.13607", "submitter": "Richard Jiang", "authors": "Gary Storey, Richard Jiang, Shelagh Keogh, Ahmed Bouridane and\n  Chang-Tsun Li", "title": "3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework\n  using Fully 3D Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to perform facial analysis from video sequences has\nsignificant potential to positively impact in many areas of life. One such area\nrelates to the medical domain to specifically aid in the diagnosis and\nrehabilitation of patients with facial palsy. With this application in mind,\nthis paper presents an end-to-end framework, named 3DPalsyNet, for the tasks of\nmouth motion recognition and facial palsy grading. 3DPalsyNet utilizes a 3D CNN\narchitecture with a ResNet backbone for the prediction of these dynamic tasks.\nLeveraging transfer learning from a 3D CNNs pre-trained on the Kinetics data\nset for general action recognition, the model is modified to apply joint\nsupervised learning using center and softmax loss concepts. 3DPalsyNet is\nevaluated on a test set consisting of individuals with varying ranges of facial\npalsy and mouth motions and the results have shown an attractive level of\nclassification accuracy in these task of 82% and 86% respectively. The frame\nduration and the loss function affect was studied in terms of the predictive\nqualities of the proposed 3DPalsyNet, where it was found shorter frame\nduration's of 8 performed best for this specific task. Centre loss and softmax\nhave shown improvements in spatio-temporal feature learning than softmax loss\nalone, this is in agreement with earlier work involving the spatial domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:24:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Storey", "Gary", ""], ["Jiang", "Richard", ""], ["Keogh", "Shelagh", ""], ["Bouridane", "Ahmed", ""], ["Li", "Chang-Tsun", ""]]}, {"id": "1905.13611", "submitter": "Junxiang Wang", "authors": "Junxiang Wang, Fuxun Yu, Xiang Chen and Liang Zhao", "title": "ADMM for Efficient Deep Learning with Global Convergence", "comments": "accepted by KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330936", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Direction Method of Multipliers (ADMM) has been used successfully\nin many conventional machine learning applications and is considered to be a\nuseful alternative to Stochastic Gradient Descent (SGD) as a deep learning\noptimizer. However, as an emerging domain, several challenges remain, including\n1) The lack of global convergence guarantees, 2) Slow convergence towards\nsolutions, and 3) Cubic time complexity with regard to feature dimensions. In\nthis paper, we propose a novel optimization framework for deep learning via\nADMM (dlADMM) to address these challenges simultaneously. The parameters in\neach layer are updated backward and then forward so that the parameter\ninformation in each layer is exchanged efficiently. The time complexity is\nreduced from cubic to quadratic in (latent) feature dimensions via a dedicated\nalgorithm design for subproblems that enhances them utilizing iterative\nquadratic approximations and backtracking. Finally, we provide the first proof\nof global convergence for an ADMM-based method (dlADMM) in a deep neural\nnetwork problem under mild conditions. Experiments on benchmark datasets\ndemonstrated that our proposed dlADMM algorithm outperforms most of the\ncomparison methods.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:32:26 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 04:58:37 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 14:38:25 GMT"}, {"version": "v4", "created": "Tue, 6 Jul 2021 02:58:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "Junxiang", ""], ["Yu", "Fuxun", ""], ["Chen", "Xiang", ""], ["Zhao", "Liang", ""]]}, {"id": "1905.13612", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis", "title": "Leveraging Trust and Distrust in Recommender Systems via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data scarcity of user preferences and the cold-start problem often appear\nin real-world applications and limit the recommendation accuracy of\ncollaborative filtering strategies. Leveraging the selections of social friends\nand foes can efficiently face both problems. In this study, we propose a\nstrategy that performs social deep pairwise learning. Firstly, we design a\nranking loss function incorporating multiple ranking criteria based on the\nchoice in users, and the choice in their friends and foes to improve the\naccuracy in the top-k recommendation task. We capture the nonlinear\ncorrelations between user preferences and the social information of trust and\ndistrust relationships via a deep learning strategy. In each backpropagation\nstep, we follow a social negative sampling strategy to meet the multiple\nranking criteria of our ranking loss function. We conduct comprehensive\nexperiments on a benchmark dataset from Epinions, among the largest publicly\navailable that has been reported in the relevant literature. The experimental\nresults demonstrate that the proposed model beats other state-of-the art\nmethods, attaining an 11.49% average improvement over the most competitive\nmodel. We show that our deep learning strategy plays an important role in\ncapturing the nonlinear correlations between user preferences and the social\ninformation of trust and distrust relationships, and demonstrate the importance\nof our social negative sampling strategy on the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:35:34 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Rafailidis", "Dimitrios", ""]]}, {"id": "1905.13613", "submitter": "Arnout Devos", "authors": "Arnout Devos, Matthias Grossglauser", "title": "Regression Networks for Meta-Learning Few-Shot Classification", "comments": "7th ICML Workshop on Automated Machine Learning (2020)", "journal-ref": "ICML Workshop on Automated Machine Learning (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose regression networks for the problem of few-shot classification,\nwhere a classifier must generalize to new classes not seen in the training set,\ngiven only a small number of examples of each class. In high dimensional\nembedding spaces the direction of data generally contains richer information\nthan magnitude. Next to this, state-of-the-art few-shot metric methods that\ncompare distances with aggregated class representations, have shown superior\nperformance. Combining these two insights, we propose to meta-learn\nclassification of embedded points by regressing the closest approximation in\nevery class subspace while using the regression error as a distance metric.\nSimilarly to recent approaches for few-shot learning, regression networks\nreflect a simple inductive bias that is beneficial in this limited-data regime\nand they achieve excellent results, especially when more aggregate class\nrepresentations can be formed with multiple shots.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:35:41 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:09:01 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Devos", "Arnout", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1905.13614", "submitter": "R\\'emy Garnier", "authors": "R\\'emy Garnier and Arnaud Belletoile", "title": "A multi-series framework for demand forecasts in E-commerce", "comments": "Presented at APIA 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sales forecasts are crucial for the E-commerce business. State-of-the-art\ntechniques typically apply only univariate methods to make prediction for each\nseries independently. However, due to the short nature of sales times series in\nE-commerce, univariate methods don't apply well. In this article, we propose a\nglobal model which outperforms state-of-the-art models on real dataset. It is\nachieved by using Tree Boosting Methods that exploit non-linearity and\ncross-series information. We also proposed a preprocessing framework to\novercome the inherent difficulties in the E-commerce data. In particular, we\nuse different schemes to limit the impact of the volatility of the data.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:40:15 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Garnier", "R\u00e9my", ""], ["Belletoile", "Arnaud", ""]]}, {"id": "1905.13628", "submitter": "Tailai Wen", "authors": "Tailai Wen, Roy Keyes", "title": "Time Series Anomaly Detection Using Convolutional Neural Networks and\n  Transfer Learning", "comments": "8 pages, 8 figures, AI for Internet of Things Workshop in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomaly detection plays a critical role in automated monitoring\nsystems. Most previous deep learning efforts related to time series anomaly\ndetection were based on recurrent neural networks (RNN). In this paper, we\npropose a time series segmentation approach based on convolutional neural\nnetworks (CNN) for anomaly detection. Moreover, we propose a transfer learning\nframework that pretrains a model on a large-scale synthetic univariate time\nseries data set and then fine-tunes its weights on small-scale, univariate or\nmultivariate data sets with previously unseen classes of anomalies. For the\nmultivariate case, we introduce a novel network architecture. The approach was\ntested on multiple synthetic and real data sets successfully.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:12:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wen", "Tailai", ""], ["Keyes", "Roy", ""]]}, {"id": "1905.13633", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Updates of Equilibrium Prop Match Gradients of Backprop Through Time in\n  an RNN with Static Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically inspired learning algorithm\nfor convergent recurrent neural networks, i.e. RNNs that are fed by a static\ninput x and settle to a steady state. Training convergent RNNs consists in\nadjusting the weights until the steady state of output neurons coincides with a\ntarget y. Convergent RNNs can also be trained with the more conventional\nBackpropagation Through Time (BPTT) algorithm. In its original formulation EP\nwas described in the case of real-time neuronal dynamics, which is\ncomputationally costly. In this work, we introduce a discrete-time version of\nEP with simplified equations and with reduced simulation time, bringing EP\ncloser to practical machine learning tasks. We first prove theoretically, as\nwell as numerically that the neural and weight updates of EP, computed by\nforward-time dynamics, are step-by-step equal to the ones obtained by BPTT,\nwith gradients computed backward in time. The equality is strict when the\ntransition function of the dynamics derives from a primitive function and the\nsteady state is maintained long enough. We then show for more standard\ndiscrete-time neural network dynamics that the same property is approximately\nrespected and we subsequently demonstrate training with EP with equivalent\nperformance to BPTT. In particular, we define the first convolutional\narchitecture trained with EP achieving ~ 1% test error on MNIST, which is the\nlowest error reported with EP. These results can guide the development of deep\nneural networks trained with EP.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:26:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "1905.13637", "submitter": "Wenpeng Hu", "authors": "Wenpeng Hu, Zhangming Chan, Bing Liu, Dongyan Zhao, Jinwen Ma, Rui Yan", "title": "GSN: A Graph-Structured Network for Multi-Party Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Existing neural models for dialogue response generation assume that\nutterances are sequentially organized. However, many real-world dialogues\ninvolve multiple interlocutors (i.e., multi-party dialogues), where the\nassumption does not hold as utterances from different interlocutors can occur\n\"in parallel.\" This paper generalizes existing sequence-based models to a\nGraph-Structured neural Network (GSN) for dialogue modeling. The core of GSN is\na graph-based encoder that can model the information flow along the\ngraph-structured dialogues (two-party sequential dialogues are a special case).\nExperimental results show that GSN significantly outperforms existing\nsequence-based models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:30:49 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hu", "Wenpeng", ""], ["Chan", "Zhangming", ""], ["Liu", "Bing", ""], ["Zhao", "Dongyan", ""], ["Ma", "Jinwen", ""], ["Yan", "Rui", ""]]}, {"id": "1905.13639", "submitter": "Sang-Yeon Hwang", "authors": "Jaechang Lim, Sang-Yeon Hwang, Seungsu Kim, Seokhyun Moon, Woo Youn\n  Kim", "title": "Scaffold-based molecular design using graph generative model", "comments": "33 pages, 3 tables, 5 figures", "journal-ref": "Chem. Sci. 11 (2020) 1153-1164", "doi": "10.1039/C9SC04503A", "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching new molecules in areas like drug discovery often starts from the\ncore structures of candidate molecules to optimize the properties of interest.\nThe way as such has called for a strategy of designing molecules retaining a\nparticular scaffold as a substructure. On this account, our present work\nproposes a scaffold-based molecular generative model. The model generates\nmolecular graphs by extending the graph of a scaffold through sequential\nadditions of vertices and edges. In contrast to previous related models, our\nmodel guarantees the generated molecules to retain the given scaffold with\ncertainty. Our evaluation of the model using unseen scaffolds showed the\nvalidity, uniqueness, and novelty of generated molecules as high as the case\nusing seen scaffolds. This confirms that the model can generalize the learned\nchemical rules of adding atoms and bonds rather than simply memorizing the\nmapping from scaffolds to molecules during learning. Furthermore, despite the\nrestraint of fixing core structures, our model could simultaneously control\nmultiple molecular properties when generating new molecules.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:34:35 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lim", "Jaechang", ""], ["Hwang", "Sang-Yeon", ""], ["Kim", "Seungsu", ""], ["Moon", "Seokhyun", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1905.13651", "submitter": "Adriano Fazzone", "authors": "Aris Anagnostopoulos, Luca Becchetti, Adriano Fazzone, Cristina\n  Menghini, Chris Schwiegelshohn", "title": "Principal Fairness: Removing Bias via Projections", "comments": "Partially supported by the ERC Advanced Grant 788893 AMDROMA\n  \"Algorithmic and Mechanism Design Research in Online Markets\" and MIUR PRIN\n  project ALGADIMAR \"Algorithms, Games, and Digital Markets\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing hidden bias in the data and ensuring fairness in algorithmic data\nanalysis has recently received significant attention. We complement several\nrecent papers in this line of research by introducing a general method to\nreduce bias in the data through random projections in a \"fair\" subspace.\n  We apply this method to densest subgraph problem. For densest subgraph, our\napproach based on fair projections allows to recover both theoretically and\nempirically an almost optimal, fair, dense subgraph hidden in the input data.\nWe also show that, under the small set expansion hypothesis, approximating this\nproblem beyond a factor of 2 is NP-hard and we show a polynomial time algorithm\nwith a matching approximation bound.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:52:56 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 01:01:05 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 00:02:06 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Anagnostopoulos", "Aris", ""], ["Becchetti", "Luca", ""], ["Fazzone", "Adriano", ""], ["Menghini", "Cristina", ""], ["Schwiegelshohn", "Chris", ""]]}, {"id": "1905.13652", "submitter": "S. Asim Ahmed", "authors": "S. Asim Ahmed", "title": "L0 Regularization Based Neural Network Design and Compression", "comments": "4 pages 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider complexity of Deep Neural Networks (DNNs) and their associated\nmassive over-parameterization. Such over-parametrization may entail\nsusceptibility to adversarial attacks, loss of interpretability and adverse\nSize, Weight and Power - Cost (SWaP-C) considerations. We ask if there are\nmethodical ways (regularization) to reduce complexity and how can we interpret\ntrade-off between desired metric and complexity of DNN. Reducing complexity is\ndirectly applicable to scaling of AI applications to real world problems\n(especially for off-the-cloud applications). We show that presence and\nevaluation of the knee of the tradeoff curve. We apply a form of L0\nregularization to MNIST data and signal modulation classifications. We show\nthat such regularization captures saliency in the input space as well.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:53:30 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ahmed", "S. Asim", ""]]}, {"id": "1905.13654", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Arnaud Doucet, Judith Rousseau", "title": "Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks", "comments": "42 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Jacot et al. (2018) has shown that training a neural network\nof any kind with gradient descent in parameter space is strongly related to\nkernel gradient descent in function space with respect to the Neural Tangent\nKernel (NTK). Lee et al. (2019) built on this result by establishing that the\noutput of a neural network trained using gradient descent can be approximated\nby a linear model for wide networks. In parallel, a recent line of studies\n(Schoenholz et al. 2017; Hayou et al. 2019) has suggested that a special\ninitialization, known as the Edge of Chaos, improves training. In this paper,\nwe bridge the gap between these two concepts by quantifying the impact of the\ninitialization and the activation function on the NTK when the network depth\nbecomes large. In particular, we show that the performance of wide deep neural\nnetworks cannot be explained by the NTK regime and we provide experiments\nillustrating our theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:53:59 GMT"}, {"version": "v10", "created": "Sun, 23 May 2021 17:14:22 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 16:59:15 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 07:47:17 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 07:29:52 GMT"}, {"version": "v5", "created": "Tue, 18 Feb 2020 18:00:25 GMT"}, {"version": "v6", "created": "Mon, 20 Apr 2020 02:41:16 GMT"}, {"version": "v7", "created": "Mon, 22 Jun 2020 17:27:26 GMT"}, {"version": "v8", "created": "Wed, 23 Dec 2020 12:12:07 GMT"}, {"version": "v9", "created": "Sat, 9 Jan 2021 13:54:48 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Hayou", "Soufiane", ""], ["Doucet", "Arnaud", ""], ["Rousseau", "Judith", ""]]}, {"id": "1905.13655", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Wei Hu, Yuping Luo", "title": "Implicit Regularization in Deep Matrix Factorization", "comments": "Published at the conference on Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts to understand the generalization mystery in deep learning have led to\nthe belief that gradient-based optimization induces a form of implicit\nregularization, a bias towards models of low \"complexity.\" We study the\nimplicit regularization of gradient descent over deep linear neural networks\nfor matrix completion and sensing, a model referred to as deep matrix\nfactorization. Our first finding, supported by theory and experiments, is that\nadding depth to a matrix factorization enhances an implicit tendency towards\nlow-rank solutions, oftentimes leading to more accurate recovery. Secondly, we\npresent theoretical and empirical arguments questioning a nascent view by which\nimplicit regularization in matrix factorization can be captured using simple\nmathematical norms. Our results point to the possibility that the language of\nstandard regularizers may not be rich enough to fully encompass the implicit\nregularization brought forth by gradient-based optimization.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:54:36 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:46:10 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 07:09:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Hu", "Wei", ""], ["Luo", "Yuping", ""]]}, {"id": "1905.13657", "submitter": "William Stephenson", "authors": "William T. Stephenson and Tamara Broderick", "title": "Approximate Cross-Validation in High Dimensions with Guarantees", "comments": "Accepted to AISTATS 2020. 33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leave-one-out cross-validation (LOOCV) can be particularly accurate among\ncross-validation (CV) variants for machine learning assessment tasks -- e.g.,\nassessing methods' error or variability. But it is expensive to re-fit a model\n$N$ times for a dataset of size $N$. Previous work has shown that\napproximations to LOOCV can be both fast and accurate -- when the unknown\nparameter is of small, fixed dimension. But these approximations incur a\nrunning time roughly cubic in dimension -- and we show that, besides\ncomputational issues, their accuracy dramatically deteriorates in high\ndimensions. Authors have suggested many potential and seemingly intuitive\nsolutions, but these methods have not yet been systematically evaluated or\ncompared. We find that all but one perform so poorly as to be unusable for\napproximating LOOCV. Crucially, though, we are able to show, both empirically\nand theoretically, that one approximation can perform well in high dimensions\n-- in cases where the high-dimensional parameter exhibits sparsity. Under\ninterpretable assumptions, our theory demonstrates that the problem can be\nreduced to working within an empirically recovered (small) support. This\nprocedure is straightforward to implement, and we prove that its running time\nand error depend on the (small) support size even when the full parameter\ndimension is large.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:57:01 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 18:25:09 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 19:55:53 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 23:00:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Stephenson", "William T.", ""], ["Broderick", "Tamara", ""]]}, {"id": "1905.13658", "submitter": "Niall Twomey", "authors": "Niall Twomey, Rafael Poyiadzi, Callum Mann, and Ra\\'ul\n  Santos-Rodr\\'iguez", "title": "Ordinal Regression as Structured Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends the class of ordinal regression models with a structured\ninterpretation of the problem by applying a novel treatment of encoded labels.\nThe net effect of this is to transform the underlying problem from an ordinal\nregression task to a (structured) classification task which we solve with\nconditional random fields, thereby achieving a coherent and probabilistic model\nin which all model parameters are jointly learnt. Importantly, we show that\nalthough we have cast ordinal regression to classification, our method still\nfall within the class of decomposition methods in the ordinal regression\nontology. This is an important link since our experience is that many\napplications of machine learning to healthcare ignores completely the important\nnature of the label ordering, and hence these approaches should considered\nnaive in this ontology. We also show that our model is flexible both in how it\nadapts to data manifolds and in terms of the operations that are available for\npractitioner to execute. Our empirical evaluation demonstrates that the\nproposed approach overwhelmingly produces superior and often statistically\nsignificant results over baseline approaches on forty popular ordinal\nregression models, and demonstrate that the proposed model significantly\nout-performs baselines on synthetic and real datasets. Our implementation,\ntogether with scripts to reproduce the results of this work, will be available\non a public GitHub repository.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:58:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Twomey", "Niall", ""], ["Poyiadzi", "Rafael", ""], ["Mann", "Callum", ""], ["Santos-Rodr\u00edguez", "Ra\u00fal", ""]]}, {"id": "1905.13659", "submitter": "Liyuan Xu", "authors": "Liyuan Xu, Junya Honda, Gang Niu, Masashi Sugiyama", "title": "Uncoupled Regression from Pairwise Comparison Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncoupled regression is the problem to learn a model from unlabeled data and\nthe set of target values while the correspondence between them is unknown. Such\na situation arises in predicting anonymized targets that involve sensitive\ninformation, e.g., one's annual income. Since existing methods for uncoupled\nregression often require strong assumptions on the true target function, and\nthus, their range of applications is limited, we introduce a novel framework\nthat does not require such assumptions in this paper. Our key idea is to\nutilize pairwise comparison data, which consists of pairs of unlabeled data\nthat we know which one has a larger target value. Such pairwise comparison data\nis easy to collect, as typically discussed in the learning-to-rank scenario,\nand does not break the anonymity of data. We propose two practical methods for\nuncoupled regression from pairwise comparison data and show that the learned\nregression model converges to the optimal model with the optimal parametric\nconvergence rate when the target variable distributes uniformly. Moreover, we\nempirically show that for linear models the proposed methods are comparable to\nordinary supervised regression with labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:00:14 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 05:52:30 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Xu", "Liyuan", ""], ["Honda", "Junya", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1905.13662", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Gabriele Abbati, Tom Rainforth, Stefan Bauer,\n  Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "On the Fairness of Disentangled Representations", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a significant interest in learning disentangled\nrepresentations, as they promise increased interpretability, generalization to\nunseen scenarios and faster learning on downstream tasks. In this paper, we\ninvestigate the usefulness of different notions of disentanglement for\nimproving the fairness of downstream prediction tasks based on representations.\nWe consider the setting where the goal is to predict a target variable based on\nthe learned representation of high-dimensional observations (such as images)\nthat depend on both the target variable and an \\emph{unobserved} sensitive\nvariable. We show that in this setting both the optimal and empirical\npredictions can be unfair, even if the target variable and the sensitive\nvariable are independent. Analyzing the representations of more than\n\\num{12600} trained state-of-the-art disentangled models, we observe that\nseveral disentanglement scores are consistently correlated with increased\nfairness, suggesting that disentanglement may be a useful property to encourage\nfairness when sensitive variables are not observed.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:03:12 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 10:56:08 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Locatello", "Francesco", ""], ["Abbati", "Gabriele", ""], ["Rainforth", "Tom", ""], ["Bauer", "Stefan", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "1905.13667", "submitter": "Jeffrey Ede BSc MPhys", "authors": "Jeffrey M. Ede, Richard Beanland", "title": "Partial Scanning Transmission Electron Microscopy with Deep Learning", "comments": "20 pages, 11 figures", "journal-ref": "Sci Rep 10, 8332 (2020)", "doi": "10.1038/s41598-020-65261-0", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compressed sensing algorithms are used to decrease electron microscope scan\ntime and electron beam exposure with minimal information loss. Following\nsuccessful applications of deep learning to compressed sensing, we have\ndeveloped a two-stage multiscale generative adversarial neural network to\ncomplete realistic 512$\\times$512 scanning transmission electron micrographs\nfrom spiral, jittered gridlike, and other partial scans. For spiral scans and\nmean squared error based pre-training, this enables electron beam coverage to\nbe decreased by 17.9$\\times$ with a 3.8\\% test set root mean squared intensity\nerror, and by 87.0$\\times$ with a 6.2\\% error. Our generator networks are\ntrained on partial scans created from a new dataset of 16227 scanning\ntransmission electron micrographs. High performance is achieved with adaptive\nlearning rate clipping of loss spikes and an auxiliary trainer network. Our\nsource code, new dataset, and pre-trained models have been made publicly\navailable at https://github.com/Jeffrey-Ede/partial-STEM\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:13:32 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:50:23 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ede", "Jeffrey M.", ""], ["Beanland", "Richard", ""]]}, {"id": "1905.13668", "submitter": "Jens Schreiber", "authors": "Jens Schreiber, Artjom Buschin, Bernhard Sick", "title": "Influences in Forecast Errors for Wind and Photovoltaic Power: A Study\n  on Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing importance of forecasts of renewable energy, current\nplanning studies only address a general estimate of the forecast quality to be\nexpected and selected forecast horizons.\n  However, these estimates allow only a limited and highly uncertain use in the\nplanning of electric power distribution. More reliable planning processes\nrequire considerably more information about future forecast quality.\n  In this article, we present an in-depth analysis and comparison of\ninfluencing factors regarding uncertainty in wind and photovoltaic power\nforecasts, based on four different machine learning (ML) models.\n  In our analysis, we found substantial differences in uncertainty depending on\nML models, data coverage, and seasonal patterns that have to be considered in\nfuture planning studies.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:14:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Schreiber", "Jens", ""], ["Buschin", "Artjom", ""], ["Sick", "Bernhard", ""]]}, {"id": "1905.13672", "submitter": "Jiaoyan Chen", "authors": "Freddy Lecue and Jiaoyan Chen and Jeff Z. Pan and Huajun Chen", "title": "Augmenting Transfer Learning with Semantic Reasoning", "comments": "7 pages", "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims at building robust prediction models by transferring\nknowledge gained from one problem to another. In the semantic Web, learning\ntasks are enhanced with semantic representations. We exploit their semantics to\naugment transfer learning by dealing with when to transfer with semantic\nmeasurements and what to transfer with semantic embeddings. We further present\na general framework that integrates the above measurements and embeddings with\nexisting transfer learning algorithms for higher performance. It has\ndemonstrated to be robust in two real-world applications: bus delay forecasting\nand air quality forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:21:10 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 21:12:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Lecue", "Freddy", ""], ["Chen", "Jiaoyan", ""], ["Pan", "Jeff Z.", ""], ["Chen", "Huajun", ""]]}, {"id": "1905.13678", "submitter": "Aidan N. Gomez", "authors": "Aidan N. Gomez, Ivan Zhang, Siddhartha Rao Kamalakara, Divyam Madaan,\n  Kevin Swersky, Yarin Gal, Geoffrey E. Hinton", "title": "Learning Sparse Networks Using Targeted Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are easier to optimise when they have many more weights than\nare required for modelling the mapping from inputs to outputs. This suggests a\ntwo-stage learning procedure that first learns a large net and then prunes away\nconnections or hidden units. But standard training does not necessarily\nencourage nets to be amenable to pruning. We introduce targeted dropout, a\nmethod for training a neural network so that it is robust to subsequent\npruning. Before computing the gradients for each weight update, targeted\ndropout stochastically selects a set of units or weights to be dropped using a\nsimple self-reinforcing sparsity criterion and then computes the gradients for\nthe remaining weights. The resulting network is robust to post hoc pruning of\nweights or units that frequently occur in the dropped sets. The method improves\nupon more complicated sparsifying regularisers while being simple to implement\nand easy to tune.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:40:36 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:19:12 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 09:19:52 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 18:34:54 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 11:27:36 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gomez", "Aidan N.", ""], ["Zhang", "Ivan", ""], ["Kamalakara", "Siddhartha Rao", ""], ["Madaan", "Divyam", ""], ["Swersky", "Kevin", ""], ["Gal", "Yarin", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1905.13682", "submitter": "Andrea Testa", "authors": "Andrea Testa, Francesco Farina, Giuseppe Notarstefano", "title": "Distributed Submodular Minimization via Block-Wise Updates and\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with a network of computing agents with local\nprocessing and neighboring communication capabilities that aim at solving\n(without any central unit) a submodular optimization problem. The cost function\nis the sum of many local submodular functions and each agent in the network has\naccess to one function in the sum only. In this \\emph{distributed} set-up, in\norder to preserve their own privacy, agents communicate with neighbors but do\nnot share their local cost functions. We propose a distributed algorithm in\nwhich agents resort to the Lov\\`{a}sz extension of their local submodular\nfunctions and perform local updates and communications in terms of single\nblocks of the entire optimization variable. Updates are performed by means of a\ngreedy algorithm which is run only until the selected block is computed, thus\nresulting in a reduced computational burden. The proposed algorithm is shown to\nconverge in expected value to the optimal cost of the problem, and an\napproximate solution to the submodular problem is retrieved by a thresholding\noperation. As an application, we consider a distributed image segmentation\nproblem in which each agent has access only to a portion of the entire image.\nWhile agents cannot segment the entire image on their own, they correctly\ncomplete the task by cooperating through the proposed distributed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:43:49 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 10:20:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Testa", "Andrea", ""], ["Farina", "Francesco", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1905.13686", "submitter": "Federico Baldassarre", "authors": "Federico Baldassarre, Hossein Azizpour", "title": "Explainability Techniques for Graph Convolutional Networks", "comments": "Accepted at the ICML 2019 Workshop \"Learning and Reasoning with\n  Graph-Structured Representations\" (poster + spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Networks are used to make decisions in potentially complex scenarios\nbut it is usually not obvious how or why they made them. In this work, we study\nthe explainability of Graph Network decisions using two main classes of\ntechniques, gradient-based and decomposition-based, on a toy dataset and a\nchemistry task. Our study sets the ground for future development as well as\napplication to real-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:51:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Baldassarre", "Federico", ""], ["Azizpour", "Hossein", ""]]}, {"id": "1905.13687", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Rahma Chaabouni and Diane Bouchacourt and Marco\n  Baroni", "title": "Entropy Minimization In Emergent Languages", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in studying the languages that emerge when neural\nagents are jointly trained to solve tasks requiring communication through a\ndiscrete channel. We investigate here the information-theoretic complexity of\nsuch languages, focusing on the basic two-agent, one-exchange setup. We find\nthat, under common training procedures, the emergent languages are subject to\nan entropy minimization pressure that has also been detected in human language,\nwhereby the mutual information between the communicating agent's inputs and the\nmessages is minimized, within the range afforded by the need for successful\ncommunication. That is, emergent languages are (nearly) as simple as the task\nthey are developed for allow them to be. This pressure is amplified as we\nincrease communication channel discreteness. Further, we observe that stronger\ndiscrete-channel-driven entropy minimization leads to representations with\nincreased robustness to overfitting and adversarial attacks. We conclude by\ndiscussing the implications of our findings for the study of natural and\nartificial communication systems.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:54:41 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:08:33 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 10:03:02 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Chaabouni", "Rahma", ""], ["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.13695", "submitter": "Halaleh Kamari", "authors": "Halaleh Kamari, Sylvie Huet, Marie-Luce Taupin", "title": "RKHSMetaMod: An R package to estimate the Hoeffding decomposition of a\n  complex model by solving RKHS ridge group sparse optimization problem", "comments": "arXiv admin note: text overlap with arXiv:1701.04671", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an R package, called RKHSMetaMod, that implements a procedure for\nestimating a meta-model of a complex model $m$. The meta-model approximates the\nHoeffding decomposition of $m$ and allows to perform sensitivity analysis on\nit. It belongs to a reproducing kernel Hilbert space that is constructed as a\ndirect sum of Hilbert spaces. The estimator of the meta-model is the solution\nof a penalized empirical least-squares minimization with the sum of the Hilbert\nnorm and the empirical $L^2$-norm. This procedure, called RKHS ridge group\nsparse, allows both to select and estimate the terms in the Hoeffding\ndecomposition, and therefore, to select and estimate the Sobol indices that are\nnon-zero. The RKHSMetaMod package provides an interface from R statistical\ncomputing environment to the C++ libraries Eigen and GSL. In order to speed up\nthe execution time and optimize the storage memory, except for a function that\nis written in R, all of the functions of this package are written using the\nefficient C++ libraries through RcppEigen and RcppGSL packages. These functions\nare then interfaced in the R environment in order to propose an user friendly\npackage.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:13:07 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 12:54:31 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 10:38:08 GMT"}, {"version": "v4", "created": "Sat, 19 Sep 2020 11:14:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamari", "Halaleh", ""], ["Huet", "Sylvie", ""], ["Taupin", "Marie-Luce", ""]]}, {"id": "1905.13697", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak, Jacob Gardner", "title": "Neural Likelihoods for Multi-Output Gaussian Processes", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct flexible likelihoods for multi-output Gaussian process models\nthat leverage neural networks as components. We make use of sparse variational\ninference methods to enable scalable approximate inference for the resulting\nclass of models. An attractive feature of these models is that they can admit\nanalytic predictive means even when the likelihood is non-linear and the\npredictive distributions are non-Gaussian. We validate the modeling potential\nof these models in a variety of experiments in both the supervised and\nunsupervised setting. We demonstrate that the flexibility of these `neural'\nlikelihoods can improve prediction quality as compared to simpler Gaussian\nprocess models and that neural likelihoods can be readily combined with a\nvariety of underlying Gaussian process models, including deep Gaussian\nprocesses.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:16:11 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jankowiak", "Martin", ""], ["Gardner", "Jacob", ""]]}, {"id": "1905.13703", "submitter": "Yang Yu", "authors": "Yi-Qi Hu and Yang Yu and Jun-Da Liao", "title": "Cascaded Algorithm-Selection and Hyper-Parameter Optimization with\n  Extreme-Region Upper Confidence Bound Bandit", "comments": "Appears in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automatic machine learning (AutoML) task is to select the best algorithm\nand its hyper-parameters simultaneously. Previously, the hyper-parameters of\nall algorithms are joint as a single search space, which is not only huge but\nalso redundant, because many dimensions of hyper-parameters are irrelevant with\nthe selected algorithms. In this paper, we propose a cascaded approach for\nalgorithm selection and hyper-parameter optimization. While a search procedure\nis employed at the level of hyper-parameter optimization, a bandit strategy\nruns at the level of algorithm selection to allocate the budget based on the\nsearch feedbacks. Since the bandit is required to select the algorithm with the\nmaximum performance, instead of the average performance, we thus propose the\nextreme-region upper confidence bound (ER-UCB) strategy, which focuses on the\nextreme region of the underlying feedback distribution. We show theoretically\nthat the ER-UCB has a regret upper bound $O\\left(K \\ln n\\right)$ with\nindependent feedbacks, which is as efficient as the classical UCB bandit. We\nalso conduct experiments on a synthetic problem as well as a set of AutoML\ntasks. The results verify the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:29:42 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hu", "Yi-Qi", ""], ["Yu", "Yang", ""], ["Liao", "Jun-Da", ""]]}, {"id": "1905.13715", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Xaq Pitkow", "title": "Improved memory in recurrent neural networks with sequential non-normal\n  dynamics", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks (RNNs) is a hard problem due to\ndegeneracies in the optimization landscape, a problem also known as\nvanishing/exploding gradients. Short of designing new RNN architectures,\nprevious methods for dealing with this problem usually boil down to\northogonalization of the recurrent dynamics, either at initialization or during\nthe entire training period. The basic motivation behind these methods is that\northogonal transformations are isometries of the Euclidean space, hence they\npreserve (Euclidean) norms and effectively deal with vanishing/exploding\ngradients. However, this ignores the crucial effects of non-linearity and\nnoise. In the presence of a non-linearity, orthogonal transformations no longer\npreserve norms, suggesting that alternative transformations might be better\nsuited to non-linear networks. Moreover, in the presence of noise, norm\npreservation itself ceases to be the ideal objective. A more sensible objective\nis maximizing the signal-to-noise ratio (SNR) of the propagated signal instead.\nPrevious work has shown that in the linear case, recurrent networks that\nmaximize the SNR display strongly non-normal, sequential dynamics and\northogonal networks are highly suboptimal by this measure. Motivated by this\nfinding, here we investigate the potential of non-normal RNNs, i.e. RNNs with a\nnon-normal recurrent connectivity matrix, in sequential processing tasks. Our\nexperimental results show that non-normal RNNs outperform their orthogonal\ncounterparts in a diverse range of benchmarks. We also find evidence for\nincreased non-normality and hidden chain-like feedforward motifs in trained\nRNNs initialized with orthogonal recurrent connectivity matrices.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:50:46 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 15:46:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Orhan", "A. Emin", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1905.13719", "submitter": "Yang Yu", "authors": "Wen-Ji Zhou and Yang Yu and Yingfeng Chen and Kai Guan and Tangjie Lv\n  and Changjie Fan and Zhi-Hua Zhou", "title": "Reinforcement Learning Experience Reuse with Policy Residual\n  Representation", "comments": "Conference version appears in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience reuse is key to sample-efficient reinforcement learning. One of\nthe critical issues is how the experience is represented and stored.\nPreviously, the experience can be stored in the forms of features, individual\nmodels, and the average model, each lying at a different granularity. However,\nnew tasks may require experience across multiple granularities. In this paper,\nwe propose the policy residual representation (PRR) network, which can extract\nand store multiple levels of experience. PRR network is trained on a set of\ntasks with a multi-level architecture, where a module in each level corresponds\nto a subset of the tasks. Therefore, the PRR network represents the experience\nin a spectrum-like way. When training on a new task, PRR can provide different\nlevels of experience for accelerating the learning. We experiment with the PRR\nnetwork on a set of grid world navigation tasks, locomotion tasks, and fighting\ntasks in a video game. The results show that the PRR network leads to better\nreuse of experience and thus outperforms some state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:56:05 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zhou", "Wen-Ji", ""], ["Yu", "Yang", ""], ["Chen", "Yingfeng", ""], ["Guan", "Kai", ""], ["Lv", "Tangjie", ""], ["Fan", "Changjie", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1905.13725", "submitter": "Jonathan Uesato", "authors": "Jonathan Uesato, Jean-Baptiste Alayrac, Po-Sen Huang, Robert\n  Stanforth, Alhussein Fawzi, Pushmeet Kohli", "title": "Are Labels Required for Improving Adversarial Robustness?", "comments": "Appears in the Thirty-Third Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has uncovered the interesting (and somewhat surprising) finding\nthat training models to be invariant to adversarial perturbations requires\nsubstantially larger datasets than those required for standard classification.\nThis result is a key hurdle in the deployment of robust machine learning models\nin many real world applications where labeled data is expensive. Our main\ninsight is that unlabeled data can be a competitive alternative to labeled data\nfor training adversarially robust models. Theoretically, we show that in a\nsimple statistical setting, the sample complexity for learning an adversarially\nrobust model from unlabeled data matches the fully supervised case up to\nconstant factors. On standard datasets like CIFAR-10, a simple Unsupervised\nAdversarial Training (UAT) approach using unlabeled data improves robust\naccuracy by 21.7% over using 4K supervised examples alone, and captures over\n95% of the improvement from the same number of labeled examples. Finally, we\nreport an improvement of 4% over the previous state-of-the-art on CIFAR-10\nagainst the strongest known attack by using additional unlabeled data from the\nuncurated 80 Million Tiny Images dataset. This demonstrates that our finding\nextends as well to the more realistic case where unlabeled data is also\nuncurated, therefore opening a new avenue for improving adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:19:13 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 16:00:26 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 16:41:12 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 16:57:27 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Uesato", "Jonathan", ""], ["Alayrac", "Jean-Baptiste", ""], ["Huang", "Po-Sen", ""], ["Stanforth", "Robert", ""], ["Fawzi", "Alhussein", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1905.13727", "submitter": "Thijs Vogels", "authors": "Thijs Vogels and Sai Praneeth Karimireddy and Martin Jaggi", "title": "PowerSGD: Practical Low-Rank Gradient Compression for Distributed\n  Optimization", "comments": "Presented at NeurIPS 2019", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study gradient compression methods to alleviate the communication\nbottleneck in data-parallel distributed optimization. Despite the significant\nattention received, current compression schemes either do not scale well or\nfail to achieve the target test accuracy. We propose a new low-rank gradient\ncompressor based on power iteration that can i) compress gradients rapidly, ii)\nefficiently aggregate the compressed gradients using all-reduce, and iii)\nachieve test performance on par with SGD. The proposed algorithm is the only\nmethod evaluated that achieves consistent wall-clock speedups when benchmarked\nagainst regular SGD with an optimized communication backend. We demonstrate\nreduced training times for convolutional networks as well as LSTMs on common\ndatasets. Our code is available at https://github.com/epfml/powersgd.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:25:13 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:19:34 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 14:13:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Vogels", "Thijs", ""], ["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""]]}, {"id": "1905.13728", "submitter": "Ziniu Hu", "authors": "Ziniu Hu and Changjun Fan and Ting Chen and Kai-Wei Chang and Yizhou\n  Sun", "title": "Pre-Training Graph Neural Networks for Generic Structural Feature\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are shown to be successful in modeling\napplications with graph structures. However, training an accurate GNN model\nrequires a large collection of labeled data and expressive features, which\nmight be inaccessible for some applications. To tackle this problem, we propose\na pre-training framework that captures generic graph structural information\nthat is transferable across tasks. Our framework can leverage the following\nthree tasks: 1) denoising link reconstruction, 2) centrality score ranking, and\n3) cluster preserving. The pre-training procedure can be conducted purely on\nthe synthetic graphs, and the pre-trained GNN is then adapted for downstream\napplications. With the proposed pre-training procedure, the generic structural\ninformation is learned and preserved, thus the pre-trained GNN requires less\namount of labeled data and fewer domain-specific features to achieve high\nperformance on different downstream tasks. Comprehensive experiments\ndemonstrate that our proposed framework can significantly enhance the\nperformance of various tasks at the level of node, link, and graph.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:25:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hu", "Ziniu", ""], ["Fan", "Changjun", ""], ["Chen", "Ting", ""], ["Chang", "Kai-Wei", ""], ["Sun", "Yizhou", ""]]}, {"id": "1905.13732", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Eric Ewing, Bistra Dilkina, Milind Tambe", "title": "End to end learning and optimization on graphs", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications often combine learning and optimization problems on\ngraphs. For instance, our objective may be to cluster the graph in order to\ndetect meaningful communities (or solve other common graph optimization\nproblems such as facility location, maxcut, and so on). However, graphs or\nrelated attributes are often only partially observed, introducing learning\nproblems such as link prediction which must be solved prior to optimization.\nStandard approaches treat learning and optimization entirely separately, while\nrecent machine learning work aims to predict the optimal solution directly from\nthe inputs. Here, we propose an alternative decision-focused learning approach\nthat integrates a differentiable proxy for common graph optimization problems\nas a layer in learned systems. The main idea is to learn a representation that\nmaps the original optimization problem onto a simpler proxy problem that can be\nefficiently differentiated through. Experimental results show that our\nClusterNet system outperforms both pure end-to-end approaches (that directly\npredict the optimal solution) and standard approaches that entirely separate\nlearning and optimization. Code for our system is available at\nhttps://github.com/bwilder0/clusternet.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:34:04 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 17:55:15 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 11:42:01 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Wilder", "Bryan", ""], ["Ewing", "Eric", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1905.13736", "submitter": "Yair Carmon", "authors": "Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang and John\n  C. Duchi", "title": "Unlabeled Data Improves Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate, theoretically and empirically, that adversarial robustness\ncan significantly benefit from semisupervised learning. Theoretically, we\nrevisit the simple Gaussian model of Schmidt et al. that shows a sample\ncomplexity gap between standard and robust classification. We prove that\nunlabeled data bridges this gap: a simple semisupervised learning procedure\n(self-training) achieves high robust accuracy using the same number of labels\nrequired for achieving high standard accuracy. Empirically, we augment CIFAR-10\nwith 500K unlabeled images sourced from 80 Million Tiny Images and use robust\nself-training to outperform state-of-the-art robust accuracies by over 5 points\nin (i) $\\ell_\\infty$ robustness against several strong attacks via adversarial\ntraining and (ii) certified $\\ell_2$ and $\\ell_\\infty$ robustness via\nrandomized smoothing. On SVHN, adding the dataset's own extra training set with\nthe labels removed provides gains of 4 to 10 points, within 1 point of the gain\nfrom using the extra labels.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:41:33 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:27:27 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 00:17:16 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Carmon", "Yair", ""], ["Raghunathan", "Aditi", ""], ["Schmidt", "Ludwig", ""], ["Liang", "Percy", ""], ["Duchi", "John C.", ""]]}, {"id": "1905.13741", "submitter": "Mario Krenn", "authors": "Mario Krenn, Florian H\\\"ase, AkshatKumar Nigam, Pascal Friederich,\n  Al\\'an Aspuru-Guzik", "title": "Self-Referencing Embedded Strings (SELFIES): A 100% robust molecular\n  string representation", "comments": "6+3 pages, 6+1 figures", "journal-ref": "Machine Learning: Science and Technology 1, 045024 (2020)", "doi": "10.1088/2632-2153/aba947", "report-no": null, "categories": "cs.LG physics.chem-ph quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of novel materials and functional molecules can help to solve\nsome of society's most urgent challenges, ranging from efficient energy\nharvesting and storage to uncovering novel pharmaceutical drug candidates.\nTraditionally matter engineering -- generally denoted as inverse design -- was\nbased massively on human intuition and high-throughput virtual screening. The\nlast few years have seen the emergence of significant interest in\ncomputer-inspired designs based on evolutionary or deep learning methods. The\nmajor challenge here is that the standard strings molecular representation\nSMILES shows substantial weaknesses in that task because large fractions of\nstrings do not correspond to valid molecules. Here, we solve this problem at a\nfundamental level and introduce SELFIES (SELF-referencIng Embedded Strings), a\nstring-based representation of molecules which is 100\\% robust. Every SELFIES\nstring corresponds to a valid molecule, and SELFIES can represent every\nmolecule. SELFIES can be directly applied in arbitrary machine learning models\nwithout the adaptation of the models; each of the generated molecule candidates\nis valid. In our experiments, the model's internal memory stores two orders of\nmagnitude more diverse molecules than a similar test with SMILES. Furthermore,\nas all molecules are valid, it allows for explanation and interpretation of the\ninternal working of the generative models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:51:07 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 04:30:47 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Krenn", "Mario", ""], ["H\u00e4se", "Florian", ""], ["Nigam", "AkshatKumar", ""], ["Friederich", "Pascal", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "1905.13742", "submitter": "Zhenyu Liao", "authors": "Xiaoyi Mai, Zhenyu Liao", "title": "High Dimensional Classification via Regularized and Unregularized\n  Empirical Risk Minimization: Precise Error and Optimal Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides, through theoretical analysis, an in-depth\nunderstanding of the classification performance of the empirical risk\nminimization framework, in both ridge-regularized and unregularized cases, when\nhigh dimensional data are considered. Focusing on the fundamental problem of\nseparating a two-class Gaussian mixture, the proposed analysis allows for a\nprecise prediction of the classification error for a set of numerous data\nvectors $\\mathbf{x} \\in \\mathbb R^p$ of sufficiently large dimension $p$. This\nprecise error depends on the loss function, the number of training samples, and\nthe statistics of the mixture data model. It is shown to hold beyond Gaussian\ndistribution under some additional non-sparsity condition of the data\nstatistics. Building upon this quantitative error analysis, we identify the\nsimple square loss as the optimal choice for high dimensional classification in\nboth ridge-regularized and unregularized cases, regardless of the number of\ntraining samples.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:52:26 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 02:51:19 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Mai", "Xiaoyi", ""], ["Liao", "Zhenyu", ""]]}, {"id": "1905.13746", "submitter": "Sanjay Sahay", "authors": "Sanjay K. Sahay and Mayank Chaudhari", "title": "An Efficient Detection of Malware by Naive Bayes Classifier Using GPGPU", "comments": "Conference paper, 9 pages, 4 figures", "journal-ref": "Springer, Advances in Computer Communication and Computational\n  Sciences, Vol. 924, pp. 255-262, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to continuous increase in the number of malware (according to AV-Test\ninstitute total ~8 x 10^8 malware are already known, and every day they\nregister ~2.5 x 10^4 malware) and files in the computational devices, it is\nvery important to design a system which not only effectively but can also\nefficiently detect the new or previously unseen malware to prevent/minimize the\ndamages. Therefore, this paper presents a novel group-wise approach for the\nefficient detection of malware by parallelizing the classification using the\npower of GPGPU and shown that by using the Naive Bayes classifier the detection\nspeed-up can be boosted up to 200x. The investigation also shows that the\nclassification time increases significantly with the number of features.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:37:09 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Sahay", "Sanjay K.", ""], ["Chaudhari", "Mayank", ""]]}]