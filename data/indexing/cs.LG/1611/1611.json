[{"id": "1611.00020", "submitter": "Chen Liang", "authors": "Chen Liang, Jonathan Berant, Quoc Le, Kenneth D. Forbus, Ni Lao", "title": "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with\n  Weak Supervision", "comments": "ACL 2017 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harnessing the statistical power of neural networks to perform language\nunderstanding and symbolic reasoning is difficult, when it requires executing\nefficient discrete operations against a large knowledge-base. In this work, we\nintroduce a Neural Symbolic Machine, which contains (a) a neural \"programmer\",\ni.e., a sequence-to-sequence model that maps language utterances to programs\nand utilizes a key-variable memory to handle compositionality (b) a symbolic\n\"computer\", i.e., a Lisp interpreter that performs program execution, and helps\nfind good programs by pruning the search space. We apply REINFORCE to directly\noptimize the task reward of this structured prediction problem. To train with\nweak supervision and improve the stability of REINFORCE, we augment it with an\niterative maximum-likelihood training process. NSM outperforms the\nstate-of-the-art on the WebQuestionsSP dataset when trained from\nquestion-answer pairs only, without requiring any feature engineering or\ndomain-specific knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 20:07:23 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 05:25:19 GMT"}, {"version": "v3", "created": "Thu, 3 Nov 2016 16:24:24 GMT"}, {"version": "v4", "created": "Sun, 23 Apr 2017 07:16:13 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Liang", "Chen", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Forbus", "Kenneth D.", ""], ["Lao", "Ni", ""]]}, {"id": "1611.00035", "submitter": "Thomas Powers", "authors": "Scott Wisdom, Thomas Powers, John R. Hershey, Jonathan Le Roux, and\n  Les Atlas", "title": "Full-Capacity Unitary Recurrent Neural Networks", "comments": "9 pages, to appear in NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are powerful models for processing sequential data,\nbut they are generally plagued by vanishing and exploding gradient problems.\nUnitary recurrent neural networks (uRNNs), which use unitary recurrence\nmatrices, have recently been proposed as a means to avoid these issues.\nHowever, in previous experiments, the recurrence matrices were restricted to be\na product of parameterized unitary matrices, and an open question remains: when\ndoes such a parameterization fail to represent all unitary matrices, and how\ndoes this restricted representational capacity limit what can be learned? To\naddress this question, we propose full-capacity uRNNs that optimize their\nrecurrence matrix over all unitary matrices, leading to significantly improved\nperformance over uRNNs that use a restricted-capacity recurrence matrix. Our\ncontribution consists of two main components. First, we provide a theoretical\nargument to determine if a unitary parameterization has restricted capacity.\nUsing this argument, we show that a recently proposed unitary parameterization\nhas restricted capacity for hidden state dimension greater than 7. Second, we\nshow how a complete, full-capacity unitary recurrence matrix can be optimized\nover the differentiable manifold of unitary matrices. The resulting\nmultiplicative gradient step is very simple and does not require gradient\nclipping or learning rate adaptation. We confirm the utility of our claims by\nempirically evaluating our new full-capacity uRNNs on both synthetic and\nnatural data, achieving superior performance compared to both LSTMs and the\noriginal restricted-capacity uRNNs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 20:43:21 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Wisdom", "Scott", ""], ["Powers", "Thomas", ""], ["Hershey", "John R.", ""], ["Roux", "Jonathan Le", ""], ["Atlas", "Les", ""]]}, {"id": "1611.00050", "submitter": "Eder Santana", "authors": "Eder Santana, Matthew Emigh, Pablo Zegers, Jose C Principe", "title": "Exploiting Spatio-Temporal Structure with Recurrent Winner-Take-All\n  Networks", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convolutional recurrent neural network, with Winner-Take-All\ndropout for high dimensional unsupervised feature learning in multi-dimensional\ntime series. We apply the proposedmethod for object recognition with temporal\ncontext in videos and obtain better results than comparable methods in the\nliterature, including the Deep Predictive Coding Networks previously proposed\nby Chalasani and Principe.Our contributions can be summarized as a scalable\nreinterpretation of the Deep Predictive Coding Networks trained end-to-end with\nbackpropagation through time, an extension of the previously proposed\nWinner-Take-All Autoencoders to sequences in time, and a new technique for\ninitializing and regularizing convolutional-recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 21:16:46 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 16:01:43 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Santana", "Eder", ""], ["Emigh", "Matthew", ""], ["Zegers", "Pablo", ""], ["Principe", "Jose C", ""]]}, {"id": "1611.00058", "submitter": "Sergiy Peredriy", "authors": "Sergiy Peredriy, Deovrat Kakde, Arin Chaudhuri", "title": "Kernel Bandwidth Selection for SVDD: Peak Criterion Approach for Large\n  Data", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2017.8258344", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Data Description (SVDD) provides a useful approach to\nconstruct a description of multivariate data for single-class classification\nand outlier detection with various practical applications. Gaussian kernel used\nin SVDD formulation allows flexible data description defined by observations\ndesignated as support vectors. The data boundary of such description is\nnon-spherical and conforms to the geometric features of the data. By varying\nthe Gaussian kernel bandwidth parameter, the SVDD-generated boundary can be\nmade either smoother (more spherical) or tighter/jagged. The former case may\nlead to under-fitting, whereas the latter may result in overfitting. Peak\ncriterion has been proposed to select an optimal value of the kernel bandwidth\nto strike the balance between the data boundary smoothness and its ability to\ncapture the general geometric shape of the data. Peak criterion involves\ntraining SVDD at various values of the kernel bandwidth parameter. When\ntraining datasets are large, the time required to obtain the optimal value of\nthe Gaussian kernel bandwidth parameter according to Peak method can become\nprohibitively large. This paper proposes an extension of Peak method for the\ncase of large data. The proposed method gives good results when applied to\nseveral datasets. Two existing alternative methods of computing the Gaussian\nkernel bandwidth parameter (Coefficient of Variation and Distance to the\nFarthest Neighbor) were modified to allow comparison with the proposed method\non convergence. Empirical comparison demonstrates the advantage of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 22:04:54 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 20:30:59 GMT"}, {"version": "v3", "created": "Fri, 19 May 2017 19:13:20 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Peredriy", "Sergiy", ""], ["Kakde", "Deovrat", ""], ["Chaudhuri", "Arin", ""]]}, {"id": "1611.00065", "submitter": "Samuel Elder", "authors": "Sam Elder", "title": "Bayesian Adaptive Data Analysis Guarantees from Subgaussianity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new field of adaptive data analysis seeks to provide algorithms and\nprovable guarantees for models of machine learning that allow researchers to\nreuse their data, which normally falls outside of the usual statistical\nparadigm of static data analysis. In 2014, Dwork, Feldman, Hardt, Pitassi,\nReingold and Roth introduced one potential model and proposed several solutions\nbased on differential privacy. In previous work in 2016, we described a problem\nwith this model and instead proposed a Bayesian variant, but also found that\nthe analogous Bayesian methods cannot achieve the same statistical guarantees\nas in the static case.\n  In this paper, we prove the first positive results for the Bayesian model,\nshowing that with a Dirichlet prior, the posterior mean algorithm indeed\nmatches the statistical guarantees of the static case. The main ingredient is a\nnew theorem showing that the $\\mathrm{Beta}(\\alpha,\\beta)$ distribution is\nsubgaussian with variance proxy $O(1/(\\alpha+\\beta+1))$, a concentration result\nalso of independent interest. We provide two proofs of this result: a\nprobabilistic proof utilizing a simple condition for the raw moments of a\npositive random variable and a learning-theoretic proof based on considering\nthe beta distribution as a posterior, both of which have implications to other\nrelated problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 22:24:49 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 19:58:08 GMT"}, {"version": "v3", "created": "Mon, 20 Mar 2017 20:07:55 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Elder", "Sam", ""]]}, {"id": "1611.00137", "submitter": "Hailin Shi", "authors": "Hailin Shi, Yang Yang, Xiangyu Zhu, Shengcai Liao, Zhen Lei, Weishi\n  Zheng, Stan Z. Li", "title": "Embedding Deep Metric for Person Re-identication A Study Against Large\n  Variations", "comments": "Published in ECCV2016. arXiv admin note: substantial text overlap\n  with arXiv:1511.07545", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification is challenging due to the large variations of pose,\nillumination, occlusion and camera view. Owing to these variations, the\npedestrian data is distributed as highly-curved manifolds in the feature space,\ndespite the current convolutional neural networks (CNN)'s capability of feature\nextraction. However, the distribution is unknown, so it is difficult to use the\ngeodesic distance when comparing two samples. In practice, the current deep\nembedding methods use the Euclidean distance for the training and test. On the\nother hand, the manifold learning methods suggest to use the Euclidean distance\nin the local range, combining with the graphical relationship between samples,\nfor approximating the geodesic distance. From this point of view, selecting\nsuitable positive i.e. intra-class) training samples within a local range is\ncritical for training the CNN embedding, especially when the data has large\nintra-class variations. In this paper, we propose a novel moderate positive\nsample mining method to train robust CNN for person re-identification, dealing\nwith the problem of large variation. In addition, we improve the learning by a\nmetric weight constraint, so that the learned metric has a better\ngeneralization ability. Experiments show that these two strategies are\neffective in learning robust deep metrics for person re-identification, and\naccordingly our deep model significantly outperforms the state-of-the-art\nmethods on several benchmarks of person re-identification. Therefore, the study\npresented in this paper may be useful in inspiring new designs of deep models\nfor person re-identification.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 06:03:48 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Shi", "Hailin", ""], ["Yang", "Yang", ""], ["Zhu", "Xiangyu", ""], ["Liao", "Shengcai", ""], ["Lei", "Zhen", ""], ["Zheng", "Weishi", ""], ["Li", "Stan Z.", ""]]}, {"id": "1611.00138", "submitter": "Sebastian Raschka SR", "authors": "Sebastian Raschka", "title": "MusicMood: Predicting the mood of music from song lyrics using machine\n  learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment prediction of contemporary music can have a wide-range of\napplications in modern society, for instance, selecting music for public\ninstitutions such as hospitals or restaurants to potentially improve the\nemotional well-being of personnel, patients, and customers, respectively. In\nthis project, music recommendation system built upon on a naive Bayes\nclassifier, trained to predict the sentiment of songs based on song lyrics\nalone. The experimental results show that music corresponding to a happy mood\ncan be detected with high precision based on text features obtained from song\nlyrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 06:05:49 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Raschka", "Sebastian", ""]]}, {"id": "1611.00144", "submitter": "Yanru Qu", "authors": "Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, Jun Wang", "title": "Product-based Neural Networks for User Response Prediction", "comments": "6 pages, 5 figures, ICDM2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting user responses, such as clicks and conversions, is of great\nimportance and has found its usage in many Web applications including\nrecommender systems, web search and online advertising. The data in those\napplications is mostly categorical and contains multiple fields; a typical\nrepresentation is to transform it into a high-dimensional sparse binary feature\nrepresentation via one-hot encoding. Facing with the extreme sparsity,\ntraditional models may limit their capacity of mining shallow patterns from the\ndata, i.e. low-order feature combinations. Deep models like deep neural\nnetworks, on the other hand, cannot be directly applied for the\nhigh-dimensional input because of the huge feature space. In this paper, we\npropose a Product-based Neural Networks (PNN) with an embedding layer to learn\na distributed representation of the categorical data, a product layer to\ncapture interactive patterns between inter-field categories, and further fully\nconnected layers to explore high-order feature interactions. Our experimental\nresults on two large-scale real-world ad click datasets demonstrate that PNNs\nconsistently outperform the state-of-the-art models on various metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 07:10:22 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Qu", "Yanru", ""], ["Cai", "Han", ""], ["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wen", "Ying", ""], ["Wang", "Jun", ""]]}, {"id": "1611.00175", "submitter": "Moontae Lee", "authors": "Moontae Lee, David Bindel, David Mimno", "title": "Robust Spectral Inference for Joint Stochastic Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral inference provides fast algorithms and provable optimality for\nlatent topic analysis. But for real data these algorithms require additional\nad-hoc heuristics, and even then often produce unusable results. We explain\nthis poor performance by casting the problem of topic inference in the\nframework of Joint Stochastic Matrix Factorization (JSMF) and showing that\nprevious methods violate the theoretical conditions necessary for a good\nsolution to exist. We then propose a novel rectification method that learns\nhigh quality topics and their interactions even on small, noisy data. This\nmethod achieves results comparable to probabilistic techniques in several\ndomains while maintaining scalability and provable optimality.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 10:06:57 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Lee", "Moontae", ""], ["Bindel", "David", ""], ["Mimno", "David", ""]]}, {"id": "1611.00228", "submitter": "Amit Mishra", "authors": "Amit Kumar Mishra", "title": "Application Specific Instrumentation (ASIN): A Bio-inspired Paradigm to\n  Instrumentation using recognition before detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new scheme for instrumentation, which has been\ninspired by the way small mammals sense their environment. We call this scheme\nApplication Specific Instrumentation (ASIN). A conventional instrumentation\nsystem focuses on gathering as much information about the scene as possible.\nThis, usually, is a generic system whose data can be used by another system to\ntake a specific action. ASIN fuses these two steps into one. The major merit of\nthe proposed scheme is that it uses low resolution sensors and much less\ncomputational overhead to give good performance for a highly specialised\napplication\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 10:58:12 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Mishra", "Amit Kumar", ""]]}, {"id": "1611.00252", "submitter": "Wenjun Zhang", "authors": "Rory P. Bunker, Wenjun Zhang, M. Asif Naeem", "title": "Improving a Credit Scoring Model by Incorporating Bank Statement Derived\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the extent to which features derived from bank\nstatements provided by loan applicants, and which are not declared on an\napplication form, can enhance a credit scoring model for a New Zealand lending\ncompany. Exploring the potential of such information to improve credit scoring\nmodels in this manner has not been studied previously. We construct a baseline\nmodel based solely on the existing scoring features obtained from the loan\napplication form, and a second baseline model based solely on the new bank\nstatement-derived features. A combined feature model is then created by\naugmenting the application form features with the new bank statement derived\nfeatures. Our experimental results using ROC analysis show that a combined\nfeature model performs better than both of the two baseline models, and show\nthat a number of the bank statement-derived features have value in improving\nthe credit scoring model. The target data set used for modelling was highly\nimbalanced, and Naive Bayes was found to be the best performing model, and\noutperformed a number of other classifiers commonly used in credit scoring,\nsuggesting its potential for future use on highly imbalanced data sets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 21:09:27 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 23:40:46 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Bunker", "Rory P.", ""], ["Zhang", "Wenjun", ""], ["Naeem", "M. Asif", ""]]}, {"id": "1611.00255", "submitter": "Nathanael Perraudin N. P.", "authors": "Andreas Loukas and Nathana\\\"el Perraudin", "title": "Stationary time-vertex signal processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers regression tasks involving high-dimensional multivariate\nprocesses whose structure is dependent on some {known} graph topology. We put\nforth a new definition of time-vertex wide-sense stationarity, or joint\nstationarity for short, that goes beyond product graphs. Joint stationarity\nhelps by reducing the estimation variance and recovery complexity. In\nparticular, for any jointly stationary process (a) one reliably learns the\ncovariance structure from as little as a single realization of the process, and\n(b) solves MMSE recovery problems, such as interpolation and denoising, in\ncomputational time nearly linear on the number of edges and timesteps.\nExperiments with three datasets suggest that joint stationarity can yield\naccuracy improvements in the recovery of high-dimensional processes evolving\nover a graph, even when the latter is only approximately known, or the process\nis not strictly stationary.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 14:56:33 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 18:35:44 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 12:34:27 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Loukas", "Andreas", ""], ["Perraudin", "Nathana\u00ebl", ""]]}, {"id": "1611.00301", "submitter": "Timothy O'Shea", "authors": "Timothy J O'Shea, T. Charles Clancy, Robert W. McGwier", "title": "Recurrent Neural Radio Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a powerful recurrent neural network based method for novelty\ndetection to the application of detecting radio anomalies. This approach holds\npromise in significantly increasing the ability of naive anomaly detection to\ndetect small anomalies in highly complex complexity multi-user radio bands. We\ndemonstrate the efficacy of this approach on a number of common real over the\nair radio communications bands of interest and quantify detection performance\nin terms of probability of detection an false alarm rates across a range of\ninterference to band power ratios and compare to baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 17:17:26 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["O'Shea", "Timothy J", ""], ["Clancy", "T. Charles", ""], ["McGwier", "Robert W.", ""]]}, {"id": "1611.00303", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, Nathan West, Matthew Vondal, T. Charles Clancy", "title": "Semi-Supervised Radio Signal Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio emitter recognition in dense multi-user environments is an important\ntool for optimizing spectrum utilization, identifying and minimizing\ninterference, and enforcing spectrum policy. Radio data is readily available\nand easy to obtain from an antenna, but labeled and curated data is often\nscarce making supervised learning strategies difficult and time consuming in\npractice. We demonstrate that semi-supervised learning techniques can be used\nto scale learning beyond supervised datasets, allowing for discerning and\nrecalling new radio signals by using sparse signal representations based on\nboth unsupervised and supervised methods for nonlinear feature learning and\nclustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 17:21:50 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 18:23:49 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["West", "Nathan", ""], ["Vondal", "Matthew", ""], ["Clancy", "T. Charles", ""]]}, {"id": "1611.00326", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Jun Qin", "title": "Enhanced Factored Three-Way Restricted Boltzmann Machines for Speech\n  Detection", "comments": "8 pages, Pattern Recognition Letter 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we propose enhanced factored three way restricted Boltzmann\nmachines (EFTW-RBMs) for speech detection. The proposed model incorporates\nconditional feature learning by multiplying the dynamical state of the third\nunit, which allows a modulation over the visible-hidden node pairs. Instead of\nstacking previous frames of speech as the third unit in a recursive manner, the\ncorrelation related weighting coefficients are assigned to the contextual\nneighboring frames. Specifically, a threshold function is designed to capture\nthe long-term features and blend the globally stored speech structure. A\nfactored low rank approximation is introduced to reduce the parameters of the\nthree-dimensional interaction tensor, on which non-negative constraint is\nimposed to address the sparsity characteristic. The validations through the\narea-under-ROC-curve (AUC) and signal distortion ratio (SDR) show that our\napproach outperforms several existing 1D and 2D (i.e., time and time-frequency\ndomain) speech detection algorithms in various noisy environments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 18:38:12 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 06:01:20 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 18:43:29 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Sun", "Pengfei", ""], ["Qin", "Jun", ""]]}, {"id": "1611.00328", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Dustin Tran, Rajesh Ranganath, John Paisley, David M.\n  Blei", "title": "Variational Inference via $\\chi$-Upper Bound Minimization", "comments": "Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) is widely used as an efficient alternative to\nMarkov chain Monte Carlo. It posits a family of approximating distributions $q$\nand finds the closest member to the exact posterior $p$. Closeness is usually\nmeasured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this\napproach also has problems. Notably, it typically leads to underestimation of\nthe posterior variance. In this paper we propose CHIVI, a black-box variational\ninference algorithm that minimizes $D_{\\chi}(p || q)$, the $\\chi$-divergence\nfrom $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we\nterm the $\\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved\nposterior uncertainty, and it can also be used with the classical VI lower\nbound (ELBO) to provide a sandwich estimate of the model evidence. We study\nCHIVI on three models: probit regression, Gaussian process classification, and\na Cox process model of basketball plays. When compared to expectation\npropagation and classical VI, CHIVI produces better error rates and more\naccurate estimates of posterior variance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 18:40:23 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 03:00:03 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 00:29:21 GMT"}, {"version": "v4", "created": "Sun, 12 Nov 2017 19:00:57 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Dieng", "Adji B.", ""], ["Tran", "Dustin", ""], ["Ranganath", "Rajesh", ""], ["Paisley", "John", ""], ["Blei", "David M.", ""]]}, {"id": "1611.00336", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P. Xing", "title": "Stochastic Variational Deep Kernel Learning", "comments": "13 pages, 6 tables, 3 figures. Appearing in NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning combines the non-parametric flexibility of kernel\nmethods with the inductive biases of deep learning architectures. We propose a\nnovel deep kernel learning model and stochastic variational inference procedure\nwhich generalizes deep kernel learning approaches to enable classification,\nmulti-task learning, additive covariance structures, and stochastic gradient\ntraining. Specifically, we apply additive base kernels to subsets of output\nfeatures from deep neural architectures, and jointly learn the parameters of\nthe base kernels and deep network through a Gaussian process marginal\nlikelihood objective. Within this framework, we derive an efficient form of\nstochastic variational inference which leverages local kernel interpolation,\ninducing points, and structure exploiting algebra. We show improved performance\nover stand alone deep networks, SVMs, and state of the art scalable Gaussian\nprocesses on several classification benchmarks, including an airline delay\ndataset containing 6 million training points, CIFAR, and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:04:47 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 18:06:16 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Hu", "Zhiting", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1611.00347", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Mert G\\\"urb\\\"uzbalaban and Alejandro Ribeiro", "title": "Surpassing Gradient Descent Provably: A Cyclic Incremental Method with\n  Linear Convergence Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been growing interest in developing optimization methods\nfor solving large-scale machine learning problems. Most of these problems boil\ndown to the problem of minimizing an average of a finite set of smooth and\nstrongly convex functions where the number of functions $n$ is large. Gradient\ndescent method (GD) is successful in minimizing convex problems at a fast\nlinear rate; however, it is not applicable to the considered large-scale\noptimization setting because of the high computational complexity. Incremental\nmethods resolve this drawback of gradient methods by replacing the required\ngradient for the descent direction with an incremental gradient approximation.\nThey operate by evaluating one gradient per iteration and executing the average\nof the $n$ available gradients as a gradient approximate. Although, incremental\nmethods reduce the computational cost of GD, their convergence rates do not\njustify their advantage relative to GD in terms of the total number of gradient\nevaluations until convergence. In this paper, we introduce a Double Incremental\nAggregated Gradient method (DIAG) that computes the gradient of only one\nfunction at each iteration, which is chosen based on a cyclic scheme, and uses\nthe aggregated average gradient of all the functions to approximate the full\ngradient. The iterates of the proposed DIAG method uses averages of both\niterates and gradients in oppose to classic incremental methods that utilize\ngradient averages but do not utilize iterate averages. We prove that not only\nthe proposed DIAG method converges linearly to the optimal solution, but also\nits linear convergence factor justifies the advantage of incremental methods on\nGD. In particular, we prove that the worst case performance of DIAG is better\nthan the worst case performance of GD.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:40:33 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 21:25:45 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Mokhtari", "Aryan", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1611.00350", "submitter": "Justin Khim", "authors": "Justin Khim, Varun Jog, Po-Ling Loh", "title": "Adversarial Influence Maximization", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of influence maximization in fixed networks for\ncontagion models in an adversarial setting. The goal is to select an optimal\nset of nodes to seed the influence process, such that the number of influenced\nnodes at the conclusion of the campaign is as large as possible. We formulate\nthe problem as a repeated game between a player and adversary, where the\nadversary specifies the edges along which the contagion may spread, and the\nplayer chooses sets of nodes to influence in an online fashion. We establish\nupper and lower bounds on the minimax pseudo-regret in both undirected and\ndirected networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:46:01 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 16:55:50 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Khim", "Justin", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1611.00356", "submitter": "Matthew Connelly", "authors": "Renato Rocha Souza, Flavio Codeco Coelho, Rohan Shah, Matthew Connelly", "title": "Using Artificial Intelligence to Identify State Secrets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether officials can be trusted to protect national security information has\nbecome a matter of great public controversy, reigniting a long-standing debate\nabout the scope and nature of official secrecy. The declassification of\nmillions of electronic records has made it possible to analyze these issues\nwith greater rigor and precision. Using machine-learning methods, we examined\nnearly a million State Department cables from the 1970s to identify features of\nrecords that are more likely to be classified, such as international\nnegotiations, military operations, and high-level communications. Even with\nincomplete data, algorithms can use such features to identify 90% of classified\ncables with <11% false positives. But our results also show that there are\nlongstanding problems in the identification of sensitive information. Error\nanalysis reveals many examples of both overclassification and\nunderclassification. This indicates both the need for research on inter-coder\nreliability among officials as to what constitutes classified material and the\nopportunity to develop recommender systems to better manage both classification\nand declassification.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:59:48 GMT"}], "update_date": "2016-11-06", "authors_parsed": [["Souza", "Renato Rocha", ""], ["Coelho", "Flavio Codeco", ""], ["Shah", "Rohan", ""], ["Connelly", "Matthew", ""]]}, {"id": "1611.00379", "submitter": "Baptiste Caramiaux", "authors": "Rebecca Fiebrink, Baptiste Caramiaux", "title": "The Machine Learning Algorithm as Creative Musical Tool", "comments": "Pre-print to appear in the Oxford Handbook on Algorithmic Music.\n  Oxford University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is the capacity of a computational system to learn\nstructures from datasets in order to make predictions on newly seen data. Such\nan approach offers a significant advantage in music scenarios in which\nmusicians can teach the system to learn an idiosyncratic style, or can break\nthe rules to explore the system's capacity in unexpected ways. In this chapter\nwe draw on music, machine learning, and human-computer interaction to elucidate\nan understanding of machine learning algorithms as creative tools for music and\nthe sonic arts. We motivate a new understanding of learning algorithms as\nhuman-computer interfaces. We show that, like other interfaces, learning\nalgorithms can be characterised by the ways their affordances intersect with\ngoals of human users. We also argue that the nature of interaction between\nusers and algorithms impacts the usability and usefulness of those algorithms\nin profound ways. This human-centred view of machine learning motivates our\nconcluding discussion of what it means to employ machine learning as a creative\ntool.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 20:35:46 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Fiebrink", "Rebecca", ""], ["Caramiaux", "Baptiste", ""]]}, {"id": "1611.00384", "submitter": "Oren Barkan", "authors": "Oren Barkan, Noam Koenigstein, Eylon Yogev and Ori Katz", "title": "CB2CF: A Neural Multiview Content-to-Collaborative Filtering Model for\n  Completely Cold Item Recommendations", "comments": "In Proceedings of Recsys'19. ACM, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Recommender Systems research, algorithms are often characterized as either\nCollaborative Filtering (CF) or Content Based (CB). CF algorithms are trained\nusing a dataset of user preferences while CB algorithms are typically based on\nitem profiles. These approaches harness different data sources and therefore\nthe resulting recommended items are generally very different. This paper\npresents the CB2CF, a deep neural multiview model that serves as a bridge from\nitems content into their CF representations. CB2CF is a real-world algorithm\ndesigned for Microsoft Store services that handle around a billion users\nworldwide. CB2CF is demonstrated on movies and apps recommendations, where it\nis shown to outperform an alternative CB model on completely cold items.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 20:48:34 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 13:59:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Barkan", "Oren", ""], ["Koenigstein", "Noam", ""], ["Yogev", "Eylon", ""], ["Katz", "Ori", ""]]}, {"id": "1611.00429", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, H. Brendan McMahan", "title": "Distributed Mean Estimation with Limited Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need for distributed learning and optimization algorithms\nwith low communication cost, we study communication efficient algorithms for\ndistributed mean estimation. Unlike previous works, we make no probabilistic\nassumptions on the data. We first show that for $d$ dimensional data with $n$\nclients, a naive stochastic binary rounding approach yields a mean squared\nerror (MSE) of $\\Theta(d/n)$ and uses a constant number of bits per dimension\nper client. We then extend this naive algorithm in two ways: we show that\napplying a structured random rotation before quantization reduces the error to\n$\\mathcal{O}((\\log d)/n)$ and a better coding strategy further reduces the\nerror to $\\mathcal{O}(1/n)$ and uses a constant number of bits per dimension\nper client. We also show that the latter coding strategy is optimal up to a\nconstant in the minimax sense i.e., it achieves the best MSE for a given\ncommunication cost. We finally demonstrate the practicality of our algorithms\nby applying them to distributed Lloyd's algorithm for k-means and power\niteration for PCA.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 00:16:18 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 17:37:14 GMT"}, {"version": "v3", "created": "Mon, 25 Sep 2017 15:10:54 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Suresh", "Ananda Theertha", ""], ["Yu", "Felix X.", ""], ["Kumar", "Sanjiv", ""], ["McMahan", "H. Brendan", ""]]}, {"id": "1611.00448", "submitter": "Hao Wang", "authors": "Hao Wang, Xingjian Shi, Dit-Yan Yeung", "title": "Natural-Parameter Networks: A Class of Probabilistic Neural Networks", "comments": "To appear at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) have achieved state-of-the-art performance in various\napplications. Unfortunately in applications where training data is\ninsufficient, they are often prone to overfitting. One effective way to\nalleviate this problem is to exploit the Bayesian approach by using Bayesian\nneural networks (BNN). Another shortcoming of NN is the lack of flexibility to\ncustomize different distributions for the weights and neurons according to the\ndata, as is often done in probabilistic graphical models. To address these\nproblems, we propose a class of probabilistic neural networks, dubbed\nnatural-parameter networks (NPN), as a novel and lightweight Bayesian treatment\nof NN. NPN allows the usage of arbitrary exponential-family distributions to\nmodel the weights and neurons. Different from traditional NN and BNN, NPN takes\ndistributions as input and goes through layers of transformation before\nproducing distributions to match the target output distributions. As a Bayesian\ntreatment, efficient backpropagation (BP) is performed to learn the natural\nparameters for the distributions over both the weights and neurons. The output\ndistributions of each layer, as byproducts, may be used as second-order\nrepresentations for the associated tasks such as link prediction. Experiments\non real-world datasets show that NPN can achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:32:05 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wang", "Hao", ""], ["Shi", "Xingjian", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1611.00454", "submitter": "Hao Wang", "authors": "Hao Wang, Xingjian Shi, Dit-Yan Yeung", "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n  the Blanks", "comments": "To appear at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid methods that utilize both content and rating information are commonly\nused in many recommender systems. However, most of them use either handcrafted\nfeatures or the bag-of-words representation as a surrogate for the content\ninformation but they are neither effective nor natural enough. To address this\nproblem, we develop a collaborative recurrent autoencoder (CRAE) which is a\ndenoising recurrent autoencoder (DRAE) that models the generation of content\nsequences in the collaborative filtering (CF) setting. The model generalizes\nrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n(CF-based) input and provides a new denoising scheme along with a novel\nlearnable pooling scheme for the recurrent autoencoder. To do this, we first\ndevelop a hierarchical Bayesian model for the DRAE and then generalize it to\nthe CF setting. The synergy between denoising and CF enables CRAE to make\naccurate recommendations while learning to fill in the blanks in sequences.\nExperiments on real-world datasets from different domains (CiteULike and\nNetflix) show that, by jointly modeling the order-aware generation of sequences\nfor the content information and performing CF for the ratings, CRAE is able to\nsignificantly outperform the state of the art on both the recommendation task\nbased on ratings and the sequence generation task based on content information.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:49:44 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Wang", "Hao", ""], ["Shi", "Xingjian", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1611.00481", "submitter": "Weixiang Shao", "authors": "Weixiang Shao, Lifang He, Chun-Ta Lu, Philip S. Yu", "title": "Online Multi-view Clustering with Incomplete Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, it is common to have data with multiple modalities or\ncoming from multiple sources, known as \"multi-view data\". Multi-view clustering\nprovides a natural way to generate clusters from such data. Since different\nviews share some consistency and complementary information, previous works on\nmulti-view clustering mainly focus on how to combine various numbers of views\nto improve clustering performance. However, in reality, each view may be\nincomplete, i.e., instances missing in the view. Furthermore, the size of data\ncould be extremely huge. It is unrealistic to apply multi-view clustering in\nlarge real-world applications without considering the incompleteness of views\nand the memory requirement. None of previous works have addressed all these\nchallenges simultaneously. In this paper, we propose an online multi-view\nclustering algorithm, OMVC, which deals with large-scale incomplete views. We\nmodel the multi-view clustering problem as a joint weighted nonnegative matrix\nfactorization problem and process the multi-view data chunk by chunk to reduce\nthe memory requirement. OMVC learns the latent feature matrices for all the\nviews and pushes them towards a consensus. We further increase the robustness\nof the learned latent feature matrices in OMVC via lasso regularization. To\nminimize the influence of incompleteness, dynamic weight setting is introduced\nto give lower weights to the incoming missing instances in different views.\nMore importantly, to reduce the computational time, we incorporate a faster\nprojected gradient descent by utilizing the Hessian matrices in OMVC. Extensive\nexperiments conducted on four real data demonstrate the effectiveness of the\nproposed OMVC method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 06:29:46 GMT"}, {"version": "v2", "created": "Sun, 6 Nov 2016 18:05:35 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Shao", "Weixiang", ""], ["He", "Lifang", ""], ["Lu", "Chun-Ta", ""], ["Yu", "Philip S.", ""]]}, {"id": "1611.00591", "submitter": "Kshiteej Sheth Jitesh", "authors": "Kshiteej Sheth", "title": "Deep Neural Networks for HDR imaging", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel methods of solving two tasks using Convolutional Neural\nNetworks, firstly the task of generating HDR map of a static scene using\ndifferently exposed LDR images of the scene captured using conventional cameras\nand secondly the task of finding an optimal tone mapping operator that would\ngive a better score on the TMQI metric compared to the existing methods. We\nquantitatively show the performance of our networks and illustrate the cases\nwhere our networks performs good as well as bad.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 16:20:13 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Sheth", "Kshiteej", ""]]}, {"id": "1611.00625", "submitter": "Gabriel Synnaeve", "authors": "Gabriel Synnaeve, Nantas Nardelli, Alex Auvolat, Soumith Chintala,\n  Timoth\\'ee Lacroix, Zeming Lin, Florian Richoux, Nicolas Usunier", "title": "TorchCraft: a Library for Machine Learning Research on Real-Time\n  Strategy Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TorchCraft, a library that enables deep learning research on\nReal-Time Strategy (RTS) games such as StarCraft: Brood War, by making it\neasier to control these games from a machine learning framework, here Torch.\nThis white paper argues for using RTS games as a benchmark for AI research, and\ndescribes the design and components of TorchCraft.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 05:01:24 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 21:54:28 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Synnaeve", "Gabriel", ""], ["Nardelli", "Nantas", ""], ["Auvolat", "Alex", ""], ["Chintala", "Soumith", ""], ["Lacroix", "Timoth\u00e9e", ""], ["Lin", "Zeming", ""], ["Richoux", "Florian", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1611.00710", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Giacomo Indiveri, Michael Pfeiffer", "title": "Deep counter networks for asynchronous event-based processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their advantages in terms of computational resources, latency, and\npower consumption, event-based implementations of neural networks have not been\nable to achieve the same performance figures as their equivalent\nstate-of-the-art deep network models. We propose counter neurons as minimal\nspiking neuron models which only require addition and comparison operations,\nthus avoiding costly multiplications. We show how inference carried out in deep\ncounter networks converges to the same accuracy levels as are achieved with\nstate-of-the-art conventional networks. As their event-based style of\ncomputation leads to reduced latency and sparse updates, counter networks are\nideally suited for efficient compact and low-power hardware implementation. We\npresent theory and training methods for counter networks, and demonstrate on\nthe MNIST benchmark that counter networks converge quickly, both in terms of\ntime and number of operations required, to state-of-the-art classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 18:22:33 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Binas", "Jonathan", ""], ["Indiveri", "Giacomo", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "1611.00712", "submitter": "Chris J. Maddison", "authors": "Chris J. Maddison, Andriy Mnih, Yee Whye Teh", "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random\n  Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reparameterization trick enables optimizing large scale stochastic\ncomputation graphs via gradient descent. The essence of the trick is to\nrefactor each stochastic node into a differentiable function of its parameters\nand a random variable with fixed distribution. After refactoring, the gradients\nof the loss propagated by the chain rule through the graph are low variance\nunbiased estimators of the gradients of the expected loss. While many\ncontinuous random variables have such reparameterizations, discrete random\nvariables lack useful reparameterizations due to the discontinuous nature of\ndiscrete states. In this work we introduce Concrete random\nvariables---continuous relaxations of discrete random variables. The Concrete\ndistribution is a new family of distributions with closed form densities and a\nsimple reparameterization. Whenever a discrete stochastic node of a computation\ngraph can be refactored into a one-hot bit representation that is treated\ncontinuously, Concrete stochastic nodes can be used with automatic\ndifferentiation to produce low-variance biased gradients of objectives\n(including objectives that depend on the log-probability of latent stochastic\nnodes) on the corresponding discrete graph. We demonstrate the effectiveness of\nConcrete relaxations on density estimation and structured prediction tasks\nusing neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 18:25:40 GMT"}, {"version": "v2", "created": "Sun, 6 Nov 2016 23:25:23 GMT"}, {"version": "v3", "created": "Sun, 5 Mar 2017 16:59:44 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Maddison", "Chris J.", ""], ["Mnih", "Andriy", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1611.00714", "submitter": "Alexander Jung", "authors": "Alexander Jung and Alfred O. Hero III and Alexandru Mara and Sabeur\n  Aridhi", "title": "Scalable Semi-Supervised Learning over Networks using Nonsmooth Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable method for semi-supervised (transductive) learning from\nmassive network-structured datasets. Our approach to semi-supervised learning\nis based on representing the underlying hypothesis as a graph signal with small\ntotal variation. Requiring a small total variation of the graph signal\nrepresenting the underlying hypothesis corresponds to the central smoothness\nassumption that forms the basis for semi-supervised learning, i.e., input\npoints forming clusters have similar output values or labels. We formulate the\nlearning problem as a nonsmooth convex optimization problem which we solve by\nappealing to Nesterovs optimal first-order method for nonsmooth optimization.\nWe also provide a message passing formulation of the learning method which\nallows for a highly scalable implementation in big data frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 18:27:53 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Jung", "Alexander", ""], ["Hero", "Alfred O.", "III"], ["Mara", "Alexandru", ""], ["Aridhi", "Sabeur", ""]]}, {"id": "1611.00740", "submitter": "Qianli Liao", "authors": "Tomaso Poggio, Hrushikesh Mhaskar, Lorenzo Rosasco, Brando Miranda,\n  Qianli Liao", "title": "Why and When Can Deep -- but Not Shallow -- Networks Avoid the Curse of\n  Dimensionality: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper characterizes classes of functions for which deep learning can be\nexponentially better than shallow learning. Deep convolutional networks are a\nspecial case of these conditions, though weight sharing is not the main reason\nfor their exponential advantage.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 19:35:52 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 06:15:39 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 21:24:07 GMT"}, {"version": "v4", "created": "Wed, 25 Jan 2017 01:09:40 GMT"}, {"version": "v5", "created": "Sat, 4 Feb 2017 09:10:41 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Poggio", "Tomaso", ""], ["Mhaskar", "Hrushikesh", ""], ["Rosasco", "Lorenzo", ""], ["Miranda", "Brando", ""], ["Liao", "Qianli", ""]]}, {"id": "1611.00760", "submitter": "Yiming Huang", "authors": "Yiming Huang, Xiaoyu Li", "title": "Quantum Laplacian Eigenmap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Laplacian eigenmap algorithm is a typical nonlinear model for dimensionality\nreduction in classical machine learning. We propose an efficient quantum\nLaplacian eigenmap algorithm to exponentially speed up the original\ncounterparts. In our work, we demonstrate that the Hermitian chain product\nproposed in quantum linear discriminant analysis (arXiv:1510.00113,2015) can be\napplied to implement quantum Laplacian eigenmap algorithm. While classical\nLaplacian eigenmap algorithm requires polynomial time to solve the eigenvector\nproblem, our algorithm is able to exponentially speed up nonlinear\ndimensionality reduction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 03:48:01 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Huang", "Yiming", ""], ["Li", "Xiaoyu", ""]]}, {"id": "1611.00800", "submitter": "Andy Jinhua Ma", "authors": "Frodo Kin Sun Chan, Andy J Ma, Pong C Yuen, Terry Cheuk-Fung Yip,\n  Yee-Kit Tse, Vincent Wai-Sun Wong and Grace Lai-Hung Wong", "title": "Temporal Matrix Completion with Locally Linear Latent Factors for\n  Medical Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular medical records are useful for medical practitioners to analyze and\nmonitor patient health status especially for those with chronic disease, but\nsuch records are usually incomplete due to unpunctuality and absence of\npatients. In order to resolve the missing data problem over time, tensor-based\nmodel is suggested for missing data imputation in recent papers because this\napproach makes use of low rank tensor assumption for highly correlated data.\nHowever, when the time intervals between records are long, the data correlation\nis not high along temporal direction and such assumption is not valid. To\naddress this problem, we propose to decompose a matrix with missing data into\nits latent factors. Then, the locally linear constraint is imposed on these\nfactors for matrix completion in this paper. By using a publicly available\ndataset and two medical datasets collected from hospital, experimental results\nshow that the proposed algorithm achieves the best performance by comparing\nwith the existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 12:02:53 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Chan", "Frodo Kin Sun", ""], ["Ma", "Andy J", ""], ["Yuen", "Pong C", ""], ["Yip", "Terry Cheuk-Fung", ""], ["Tse", "Yee-Kit", ""], ["Wong", "Vincent Wai-Sun", ""], ["Wong", "Grace Lai-Hung", ""]]}, {"id": "1611.00829", "submitter": "Adrian Vladu", "authors": "Ilan Lobel, Renato Paes Leme, Adrian Vladu", "title": "Multidimensional Binary Search for Contextual Decision-Making", "comments": "Appears in EC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multidimensional search problem that is motivated by questions\nin contextual decision-making, such as dynamic pricing and personalized\nmedicine. Nature selects a state from a $d$-dimensional unit ball and then\ngenerates a sequence of $d$-dimensional directions. We are given access to the\ndirections, but not access to the state. After receiving a direction, we have\nto guess the value of the dot product between the state and the direction. Our\ngoal is to minimize the number of times when our guess is more than $\\epsilon$\naway from the true answer. We construct a polynomial time algorithm that we\ncall Projected Volume achieving regret $O(d\\log(d/\\epsilon))$, which is optimal\nup to a $\\log d$ factor. The algorithm combines a volume cutting strategy with\na new geometric technique that we call cylindrification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 22:38:32 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 02:29:51 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Lobel", "Ilan", ""], ["Leme", "Renato Paes", ""], ["Vladu", "Adrian", ""]]}, {"id": "1611.00838", "submitter": "Da Tang", "authors": "Da Tang and Tony Jebara", "title": "Initialization and Coordinate Optimization for Multi-way Matching", "comments": "Artificial Intelligence and Statistics (AISTATS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of consistently matching multiple sets of elements to\neach other, which is a common task in fields such as computer vision. To solve\nthe underlying NP-hard objective, existing methods often relax or approximate\nit, but end up with unsatisfying empirical performance due to a misaligned\nobjective. We propose a coordinate update algorithm that directly optimizes the\ntarget objective. By using pairwise alignment information to build an\nundirected graph and initializing the permutation matrices along the edges of\nits Maximum Spanning Tree, our algorithm successfully avoids bad local optima.\nTheoretically, with high probability our algorithm guarantees an optimal\nsolution under reasonable noise assumptions. Empirically, our algorithm\nconsistently and significantly outperforms existing methods on several\nbenchmark tasks on real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 23:12:05 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 20:10:26 GMT"}, {"version": "v3", "created": "Wed, 8 Mar 2017 07:32:24 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 14:25:37 GMT"}, {"version": "v5", "created": "Thu, 18 Jul 2019 05:34:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tang", "Da", ""], ["Jebara", "Tony", ""]]}, {"id": "1611.00847", "submitter": "Leslie Smith", "authors": "Leslie N. Smith and Nicholay Topin", "title": "Deep Convolutional Neural Network Design Patterns", "comments": "Submitted as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in the deep learning field has produced a plethora of new\narchitectures. At the same time, a growing number of groups are applying deep\nlearning to new applications. Some of these groups are likely to be composed of\ninexperienced deep learning practitioners who are baffled by the dizzying array\nof architecture choices and therefore opt to use an older architecture (i.e.,\nAlexnet). Here we attempt to bridge this gap by mining the collective knowledge\ncontained in recent deep learning research to discover underlying principles\nfor designing neural network architectures. In addition, we describe several\narchitectural innovations, including Fractal of FractalNet network, Stagewise\nBoosting Networks, and Taylor Series Networks (our Caffe code and prototxt\nfiles is available at https://github.com/iPhysicist/CNNDesignPatterns). We hope\nothers are inspired to build on our preliminary work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 23:48:04 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 00:49:46 GMT"}, {"version": "v3", "created": "Mon, 14 Nov 2016 14:10:41 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Smith", "Leslie N.", ""], ["Topin", "Nicholay", ""]]}, {"id": "1611.00862", "submitter": "Paul Weng", "authors": "Hugo Gilbert and Paul Weng", "title": "Quantile Reinforcement Learning", "comments": "AWRL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, the standard criterion to evaluate policies in a\nstate is the expectation of (discounted) sum of rewards. However, this\ncriterion may not always be suitable, we consider an alternative criterion\nbased on the notion of quantiles. In the case of episodic reinforcement\nlearning problems, we propose an algorithm based on stochastic approximation\nwith two timescales. We evaluate our proposition on a simple model of the TV\nshow, Who wants to be a millionaire.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 02:28:53 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Gilbert", "Hugo", ""], ["Weng", "Paul", ""]]}, {"id": "1611.00873", "submitter": "Qiang Lyu", "authors": "Qiang Lyu, Yixin Chen, Zhaorong Li, Zhicheng Cui, Ling Chen, Xing\n  Zhang, Haihua Shen", "title": "Extracting Actionability from Machine Learning Models by Sub-optimal\n  Deterministic Planning", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main focus of machine learning research has been improving the\ngeneralization accuracy and efficiency of prediction models. Many models such\nas SVM, random forest, and deep neural nets have been proposed and achieved\ngreat success. However, what emerges as missing in many applications is\nactionability, i.e., the ability to turn prediction results into actions. For\nexample, in applications such as customer relationship management, clinical\nprediction, and advertisement, the users need not only accurate prediction, but\nalso actionable instructions which can transfer an input to a desirable goal\n(e.g., higher profit repays, lower morbidity rates, higher ads hit rates).\nExisting effort in deriving such actionable knowledge is few and limited to\nsimple action models which restricted to only change one attribute for each\naction. The dilemma is that in many real applications those action models are\noften more complex and harder to extract an optimal solution.\n  In this paper, we propose a novel approach that achieves actionability by\ncombining learning with planning, two core areas of AI. In particular, we\npropose a framework to extract actionable knowledge from random forest, one of\nthe most widely used and best off-the-shelf classifiers. We formulate the\nactionability problem to a sub-optimal action planning (SOAP) problem, which is\nto find a plan to alter certain features of a given input so that the random\nforest would yield a desirable output, while minimizing the total costs of\nactions. Technically, the SOAP problem is formulated in the SAS+ planning\nformalism, and solved using a Max-SAT based approach. Our experimental results\ndemonstrate the effectiveness and efficiency of the proposed approach on a\npersonal credit dataset and other benchmarks. Our work represents a new\napplication of automated planning on an emerging and challenging machine\nlearning paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 03:53:41 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Lyu", "Qiang", ""], ["Chen", "Yixin", ""], ["Li", "Zhaorong", ""], ["Cui", "Zhicheng", ""], ["Chen", "Ling", ""], ["Zhang", "Xing", ""], ["Shen", "Haihua", ""]]}, {"id": "1611.00898", "submitter": "Zhao Song", "authors": "Zhao Song, David P. Woodruff, Peilin Zhong", "title": "Low Rank Approximation with Entrywise $\\ell_1$-Norm Error", "comments": "STOC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the $\\ell_1$-low rank approximation problem, where for a given $n\n\\times d$ matrix $A$ and approximation factor $\\alpha \\geq 1$, the goal is to\noutput a rank-$k$ matrix $\\widehat{A}$ for which\n  $$\\|A-\\widehat{A}\\|_1 \\leq \\alpha \\cdot \\min_{\\textrm{rank-}k\\textrm{\nmatrices}~A'}\\|A-A'\\|_1,$$ where for an $n \\times d$ matrix $C$, we let\n$\\|C\\|_1 = \\sum_{i=1}^n \\sum_{j=1}^d |C_{i,j}|$. This error measure is known to\nbe more robust than the Frobenius norm in the presence of outliers and is\nindicated in models where Gaussian assumptions on the noise may not apply. The\nproblem was shown to be NP-hard by Gillis and Vavasis and a number of\nheuristics have been proposed. It was asked in multiple places if there are any\napproximation algorithms.\n  We give the first provable approximation algorithms for $\\ell_1$-low rank\napproximation, showing that it is possible to achieve approximation factor\n$\\alpha = (\\log d) \\cdot \\mathrm{poly}(k)$ in $\\mathrm{nnz}(A) + (n+d)\n\\mathrm{poly}(k)$ time, where $\\mathrm{nnz}(A)$ denotes the number of non-zero\nentries of $A$. If $k$ is constant, we further improve the approximation ratio\nto $O(1)$ with a $\\mathrm{poly}(nd)$-time algorithm. Under the Exponential Time\nHypothesis, we show there is no $\\mathrm{poly}(nd)$-time algorithm achieving a\n$(1+\\frac{1}{\\log^{1+\\gamma}(nd)})$-approximation, for $\\gamma > 0$ an\narbitrarily small constant, even when $k = 1$.\n  We give a number of additional results for $\\ell_1$-low rank approximation:\nnearly tight upper and lower bounds for column subset selection, CUR\ndecompositions, extensions to low rank approximation with respect to\n$\\ell_p$-norms for $1 \\leq p < 2$ and earthmover distance, low-communication\ndistributed protocols and low-memory streaming algorithms, algorithms with\nlimited randomness, and bicriteria algorithms. We also give a preliminary\nempirical evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 07:13:20 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 13:57:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Zhong", "Peilin", ""]]}, {"id": "1611.00938", "submitter": "Johann Paratte", "authors": "Johan Paratte and Lionel Martin", "title": "Fast Eigenspace Approximation using Random Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus in this work on the estimation of the first $k$ eigenvectors of any\ngraph Laplacian using filtering of Gaussian random signals. We prove that we\nonly need $k$ such signals to be able to exactly recover as many of the\nsmallest eigenvectors, regardless of the number of nodes in the graph. In\naddition, we address key issues in implementing the theoretical concepts in\npractice using accurate approximated methods. We also propose fast algorithms\nboth for eigenspace approximation and for the determination of the $k$th\nsmallest eigenvalue $\\lambda_k$. The latter proves to be extremely efficient\nunder the assumption of locally uniform distribution of the eigenvalue over the\nspectrum. Finally, we present experiments which show the validity of our method\nin practice and compare it to state-of-the-art methods for clustering and\nvisualization both on synthetic small-scale datasets and larger real-world\nproblems of millions of nodes. We show that our method allows a better scaling\nwith the number of nodes than all previous methods while achieving an almost\nperfect reconstruction of the eigenspace formed by the first $k$ eigenvectors.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 10:08:22 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 09:25:41 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Paratte", "Johan", ""], ["Martin", "Lionel", ""]]}, {"id": "1611.00962", "submitter": "Marco Frasca", "authors": "Marco Frasca and Nicol\\`o Cesa Bianchi", "title": "Multitask Protein Function Prediction Through Task Dissimilarity", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": "10.1109/TCBB.2017.2684127", "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated protein function prediction is a challenging problem with\ndistinctive features, such as the hierarchical organization of protein\nfunctions and the scarcity of annotated proteins for most biological functions.\nWe propose a multitask learning algorithm addressing both issues. Unlike\nstandard multitask algorithms, which use task (protein functions) similarity\ninformation as a bias to speed up learning, we show that dissimilarity\ninformation enforces separation of rare class labels from frequent class\nlabels, and for this reason is better suited for solving unbalanced protein\nfunction prediction problems. We support our claim by showing that a multitask\nextension of the label propagation algorithm empirically works best when the\ntask relatedness information is represented using a dissimilarity matrix as\nopposed to a similarity matrix. Moreover, the experimental comparison carried\nout on three model organism shows that our method has a more stable performance\nin both \"protein-centric\" and \"function-centric\" evaluation settings.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 11:40:59 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Frasca", "Marco", ""], ["Bianchi", "Nicol\u00f2 Cesa", ""]]}, {"id": "1611.01046", "submitter": "Gilles Louppe", "authors": "Gilles Louppe, Michael Kagan, Kyle Cranmer", "title": "Learning to Pivot with Adversarial Networks", "comments": "v1: Original submission. v2: Fixed references. v3: version submitted\n  to NIPS'2017. Code available at\n  https://github.com/glouppe/paper-learning-to-pivot", "journal-ref": "Advances in Neural Information Processing Systems 30, pages\n  981-990, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several techniques for domain adaptation have been proposed to account for\ndifferences in the distribution of the data used for training and testing. The\nmajority of this work focuses on a binary domain label. Similar problems occur\nin a scientific context where there may be a continuous family of plausible\ndata generation processes associated to the presence of systematic\nuncertainties. Robust inference is possible if it is based on a pivot -- a\nquantity whose distribution does not depend on the unknown values of the\nnuisance parameters that parametrize this family of data generation processes.\nIn this work, we introduce and derive theoretical results for a training\nprocedure based on adversarial networks for enforcing the pivotal property (or,\nequivalently, fairness with respect to continuous attributes) on a predictive\nmodel. The method includes a hyperparameter to control the trade-off between\naccuracy and robustness. We demonstrate the effectiveness of this approach with\na toy example and examples from particle physics.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 14:41:40 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 12:31:03 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 19:04:01 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Louppe", "Gilles", ""], ["Kagan", "Michael", ""], ["Cranmer", "Kyle", ""]]}, {"id": "1611.01055", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Michiel van de Panne", "title": "Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space\n  Matter?", "comments": null, "journal-ref": null, "doi": "10.1145/3099564.3099567", "report-no": null, "categories": "cs.LG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep reinforcement learning allows for high-dimensional state\ndescriptors, but little is known about how the choice of action representation\nimpacts the learning difficulty and the resulting performance. We compare the\nimpact of four different action parameterizations (torques, muscle-activations,\ntarget joint angles, and target joint-angle velocities) in terms of learning\ntime, policy robustness, motion quality, and policy query rates. Our results\nare evaluated on a gait-cycle imitation task for multiple planar articulated\nfigures and multiple gaits. We demonstrate that the local feedback provided by\nhigher-level action parameterizations can significantly impact the learning,\nrobustness, and quality of the resulting policies.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 15:15:00 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Peng", "Xue Bin", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1611.01060", "submitter": "Renato Cordeiro de Amorim", "authors": "Renato Cordeiro de Amorim, Vladimir Makarenkov, Boris Mirkin", "title": "A-Ward_p\\b{eta}: Effective hierarchical clustering using the Minkowski\n  metric and a fast k -means initialisation", "comments": null, "journal-ref": "Information Sciences, 370, 343-354 (2016)", "doi": "10.1016/j.ins.2016.07.076", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we make two novel contributions to hierarchical clustering.\nFirst, we introduce an anomalous pattern initialisation method for hierarchical\nclustering algorithms, called A-Ward, capable of substantially reducing the\ntime they take to converge. This method generates an initial partition with a\nsufficiently large number of clusters. This allows the cluster merging process\nto start from this partition rather than from a trivial partition composed\nsolely of singletons. Our second contribution is an extension of the Ward and\nWard p algorithms to the situation where the feature weight exponent can differ\nfrom the exponent of the Minkowski distance. This new method, called A-Ward\np\\b{eta} , is able to generate a much wider variety of clustering solutions. We\nalso demonstrate that its parameters can be estimated reasonably well by using\na cluster validity index. We perform numerous experiments using data sets with\ntwo types of noise, insertion of noise features and blurring within-cluster\nvalues of some features. These experiments allow us to conclude: (i) our\nanomalous pattern initialisation method does indeed reduce the time a\nhierarchical clustering algorithm takes to complete, without negatively\nimpacting its cluster recovery ability; (ii) A-Ward p\\b{eta} provides better\ncluster recovery than both Ward and Ward p.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 15:23:53 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["de Amorim", "Renato Cordeiro", ""], ["Makarenkov", "Vladimir", ""], ["Mirkin", "Boris", ""]]}, {"id": "1611.01129", "submitter": "Anru Zhang", "authors": "Anru Zhang", "title": "Cross: Efficient Low-rank Tensor Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The completion of tensors, or high-order arrays, attracts significant\nattention in recent research. Current literature on tensor completion primarily\nfocuses on recovery from a set of uniformly randomly measured entries, and the\nrequired number of measurements to achieve recovery is not guaranteed to be\noptimal. In addition, the implementation of some previous methods is NP-hard.\nIn this article, we propose a framework for low-rank tensor completion via a\nnovel tensor measurement scheme we name Cross. The proposed procedure is\nefficient and easy to implement. In particular, we show that a third order\ntensor of Tucker rank-$(r_1, r_2, r_3)$ in $p_1$-by-$p_2$-by-$p_3$ dimensional\nspace can be recovered from as few as $r_1r_2r_3 + r_1(p_1-r_1) + r_2(p_2-r_2)\n+ r_3(p_3-r_3)$ noiseless measurements, which matches the sample complexity\nlower-bound. In the case of noisy measurements, we also develop a theoretical\nupper bound and the matching minimax lower bound for recovery error over\ncertain classes of low-rank tensors for the proposed procedure. The results can\nbe further extended to fourth or higher-order tensors. Simulation studies show\nthat the method performs well under a variety of settings. Finally, the\nprocedure is illustrated through a real dataset in neuroimaging.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 19:02:02 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 18:08:38 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Anru", ""]]}, {"id": "1611.01142", "submitter": "Wade Genders", "authors": "Wade Genders, Saiedeh Razavi", "title": "Using a Deep Reinforcement Learning Agent for Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring transportation systems are efficient is a priority for modern\nsociety. Technological advances have made it possible for transportation\nsystems to collect large volumes of varied data on an unprecedented scale. We\npropose a traffic signal control system which takes advantage of this new, high\nquality data, with minimal abstraction compared to other proposed systems. We\napply modern deep reinforcement learning methods to build a truly adaptive\ntraffic signal control agent in the traffic microsimulator SUMO. We propose a\nnew state space, the discrete traffic state encoding, which is information\ndense. The discrete traffic state encoding is used as input to a deep\nconvolutional neural network, trained using Q-learning with experience replay.\nOur agent was compared against a one hidden layer neural network traffic signal\ncontrol agent and reduces average cumulative delay by 82%, average queue length\nby 66% and average travel time by 20%.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 19:46:19 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Genders", "Wade", ""], ["Razavi", "Saiedeh", ""]]}, {"id": "1611.01144", "submitter": "Eric Jang", "authors": "Eric Jang, Shixiang Gu, Ben Poole", "title": "Categorical Reparameterization with Gumbel-Softmax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical variables are a natural choice for representing discrete\nstructure in the world. However, stochastic neural networks rarely use\ncategorical latent variables due to the inability to backpropagate through\nsamples. In this work, we present an efficient gradient estimator that replaces\nthe non-differentiable sample from a categorical distribution with a\ndifferentiable sample from a novel Gumbel-Softmax distribution. This\ndistribution has the essential property that it can be smoothly annealed into a\ncategorical distribution. We show that our Gumbel-Softmax estimator outperforms\nstate-of-the-art gradient estimators on structured output prediction and\nunsupervised generative modeling tasks with categorical latent variables, and\nenables large speedups on semi-supervised classification.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 19:48:08 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 23:18:13 GMT"}, {"version": "v3", "created": "Fri, 17 Mar 2017 05:16:36 GMT"}, {"version": "v4", "created": "Sat, 1 Apr 2017 15:33:06 GMT"}, {"version": "v5", "created": "Sat, 5 Aug 2017 22:45:19 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Jang", "Eric", ""], ["Gu", "Shixiang", ""], ["Poole", "Ben", ""]]}, {"id": "1611.01170", "submitter": "Wei Xie", "authors": "Wei Xie, Yang Wang, Steven M. Boker, Donald E. Brown", "title": "PrivLogit: Efficient Privacy-preserving Logistic Regression by Tailoring\n  Numerical Optimizers", "comments": "24 pages, 4 figures. Work done and circulated since 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safeguarding privacy in machine learning is highly desirable, especially in\ncollaborative studies across many organizations. Privacy-preserving distributed\nmachine learning (based on cryptography) is popular to solve the problem.\nHowever, existing cryptographic protocols still incur excess computational\noverhead. Here, we make a novel observation that this is partially due to naive\nadoption of mainstream numerical optimization (e.g., Newton method) and failing\nto tailor for secure computing. This work presents a contrasting perspective:\ncustomizing numerical optimization specifically for secure settings. We propose\na seemingly less-favorable optimization method that can in fact significantly\naccelerate privacy-preserving logistic regression. Leveraging this new method,\nwe propose two new secure protocols for conducting logistic regression in a\nprivacy-preserving and distributed manner. Extensive theoretical and empirical\nevaluations prove the competitive performance of our two secure proposals while\nwithout compromising accuracy or privacy: with speedup up to 2.3x and 8.1x,\nrespectively, over state-of-the-art; and even faster as data scales up. Such\ndrastic speedup is on top of and in addition to performance improvements from\nexisting (and future) state-of-the-art cryptography. Our work provides a new\nway towards efficient and practical privacy-preserving logistic regression for\nlarge-scale studies which are common for modern science.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 20:04:29 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Xie", "Wei", ""], ["Wang", "Yang", ""], ["Boker", "Steven M.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1611.01186", "submitter": "Sihan Li", "authors": "Sihan Li, Jiantao Jiao, Yanjun Han, Tsachy Weissman", "title": "Demystifying ResNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Residual Network (ResNet), proposed in He et al. (2015), utilized\nshortcut connections to significantly reduce the difficulty of training, which\nresulted in great performance boosts in terms of both training and\ngeneralization error.\n  It was empirically observed in He et al. (2015) that stacking more layers of\nresidual blocks with shortcut 2 results in smaller training error, while it is\nnot true for shortcut of length 1 or 3. We provide a theoretical explanation\nfor the uniqueness of shortcut 2.\n  We show that with or without nonlinearities, by adding shortcuts that have\ndepth two, the condition number of the Hessian of the loss function at the zero\ninitial point is depth-invariant, which makes training very deep models no more\ndifficult than shallow ones. Shortcuts of higher depth result in an extremely\nflat (high-order) stationary point initially, from which the optimization\nalgorithm is hard to escape. The shortcut 1, however, is essentially equivalent\nto no shortcuts, which has a condition number exploding to infinity as the\nnumber of layers grows. We further argue that as the number of layers tends to\ninfinity, it suffices to only look at the loss function at the zero initial\npoint.\n  Extensive experiments are provided accompanying our theoretical results. We\nshow that initializing the network to small weights with shortcut 2 achieves\nsignificantly better results than random Gaussian (Xavier) initialization,\northogonal initialization, and shortcuts of deeper depth, from various\nperspectives ranging from final loss, learning dynamics and stability, to the\nbehavior of the Hessian along the learning process.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 20:55:49 GMT"}, {"version": "v2", "created": "Sat, 20 May 2017 10:18:06 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Li", "Sihan", ""], ["Jiao", "Jiantao", ""], ["Han", "Yanjun", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1611.01190", "submitter": "Igor Carboni Oliveira", "authors": "Igor C. Oliveira, Rahul Santhanam", "title": "Conspiracies between Learning Algorithms, Circuit Lower Bounds and\n  Pseudorandomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several results giving new and stronger connections between\nlearning, circuit lower bounds and pseudorandomness. Among other results, we\nshow a generic learning speedup lemma, equivalences between various learning\nmodels in the exponential time and subexponential time regimes, a dichotomy\nbetween learning and pseudorandomness, consequences of non-trivial learning for\ncircuit lower bounds, Karp-Lipton theorems for probabilistic exponential time,\nand NC$^1$-hardness for the Minimum Circuit Size Problem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 21:08:38 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Oliveira", "Igor C.", ""], ["Santhanam", "Rahul", ""]]}, {"id": "1611.01211", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Kamyar Azizzadenesheli, Abhishek Kumar, Lihong Li,\n  Jianfeng Gao, Li Deng", "title": "Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical environments contain catastrophic states that an optimal agent\nwould visit infrequently or never. Even on toy problems, Deep Reinforcement\nLearning (DRL) agents tend to periodically revisit these states upon forgetting\ntheir existence under a new policy. We introduce intrinsic fear (IF), a learned\nreward shaping that guards DRL agents against periodic catastrophes. IF agents\npossess a fear model trained to predict the probability of imminent\ncatastrophe. This score is then used to penalize the Q-learning objective. Our\ntheoretical analysis bounds the reduction in average return due to learning on\nthe perturbed objective. We also prove robustness to classification errors. As\na bonus, IF models tend to learn faster, owing to reward shaping. Experiments\ndemonstrate that intrinsic-fear DQNs solve otherwise pathological environments\nand improve on several Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 22:30:10 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 04:22:31 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2016 01:27:56 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 21:32:25 GMT"}, {"version": "v5", "created": "Mon, 15 May 2017 05:05:08 GMT"}, {"version": "v6", "created": "Tue, 23 May 2017 01:39:00 GMT"}, {"version": "v7", "created": "Sun, 8 Oct 2017 05:40:45 GMT"}, {"version": "v8", "created": "Tue, 13 Mar 2018 21:24:47 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Kumar", "Abhishek", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1611.01224", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Victor Bapst, Nicolas Heess, Volodymyr Mnih, Remi Munos,\n  Koray Kavukcuoglu, Nando de Freitas", "title": "Sample Efficient Actor-Critic with Experience Replay", "comments": "20 pages. Prepared for ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an actor-critic deep reinforcement learning agent with\nexperience replay that is stable, sample efficient, and performs remarkably\nwell on challenging environments, including the discrete 57-game Atari domain\nand several continuous control problems. To achieve this, the paper introduces\nseveral innovations, including truncated importance sampling with bias\ncorrection, stochastic dueling network architectures, and a new trust region\npolicy optimization method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 23:21:32 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 14:38:10 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Wang", "Ziyu", ""], ["Bapst", "Victor", ""], ["Heess", "Nicolas", ""], ["Mnih", "Volodymyr", ""], ["Munos", "Remi", ""], ["Kavukcuoglu", "Koray", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.01232", "submitter": "Samuel Schoenholz", "authors": "Samuel S. Schoenholz, Justin Gilmer, Surya Ganguli and Jascha\n  Sohl-Dickstein", "title": "Deep Information Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of untrained neural networks whose weights and biases\nare randomly distributed using mean field theory. We show the existence of\ndepth scales that naturally limit the maximum depth of signal propagation\nthrough these random networks. Our main practical result is to show that random\nnetworks may be trained precisely when information can travel through them.\nThus, the depth scales that we identify provide bounds on how deep a network\nmay be trained for a specific choice of hyperparameters. As a corollary to\nthis, we argue that in networks at the edge of chaos, one of these depth scales\ndiverges. Thus arbitrarily deep networks may be trained only sufficiently close\nto criticality. We show that the presence of dropout destroys the\norder-to-chaos critical point and therefore strongly limits the maximum\ntrainable depth for random networks. Finally, we develop a mean field theory\nfor backpropagation and we show that the ordered and chaotic phases correspond\nto regions of vanishing and exploding gradient respectively.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 00:44:32 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 19:36:14 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Schoenholz", "Samuel S.", ""], ["Gilmer", "Justin", ""], ["Ganguli", "Surya", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1611.01236", "submitter": "Alexey Kurakin", "authors": "Alexey Kurakin, Ian Goodfellow, Samy Bengio", "title": "Adversarial Machine Learning at Scale", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs designed to fool machine learning\nmodels. They often transfer from one model to another, allowing attackers to\nmount black box attacks without knowledge of the target model's parameters.\nAdversarial training is the process of explicitly training a model on\nadversarial examples, in order to make it more robust to attack or to reduce\nits test error on clean inputs. So far, adversarial training has primarily been\napplied to small problems. In this research, we apply adversarial training to\nImageNet. Our contributions include: (1) recommendations for how to succesfully\nscale adversarial training to large models and datasets, (2) the observation\nthat adversarial training confers robustness to single-step attack methods, (3)\nthe finding that multi-step attack methods are somewhat less transferable than\nsingle-step attack methods, so single-step attacks are the best for mounting\nblack-box attacks, and (4) resolution of a \"label leaking\" effect that causes\nadversarially trained models to perform better on adversarial examples than on\nclean examples, because the adversarial example construction process uses the\ntrue label and the model can learn to exploit regularities in the construction\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 01:11:02 GMT"}, {"version": "v2", "created": "Sat, 11 Feb 2017 00:15:46 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""], ["Bengio", "Samy", ""]]}, {"id": "1611.01239", "submitter": "Seiya Tokui", "authors": "Seiya Tokui and Issei sato", "title": "Reparameterization trick for discrete variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-variance gradient estimation is crucial for learning directed graphical\nmodels parameterized by neural networks, where the reparameterization trick is\nwidely used for those with continuous variables. While this technique gives\nlow-variance gradient estimates, it has not been directly applicable to\ndiscrete variables, the sampling of which inherently requires discontinuous\noperations. We argue that the discontinuity can be bypassed by marginalizing\nout the variable of interest, which results in a new reparameterization trick\nfor discrete variables. This reparameterization greatly reduces the variance,\nwhich is understood by regarding the method as an application of common random\nnumbers to the estimation. The resulting estimator is theoretically guaranteed\nto have a variance not larger than that of the likelihood-ratio method with the\noptimal input-dependent baseline. We give empirical results for variational\nlearning of sigmoid belief networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 01:46:47 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Tokui", "Seiya", ""], ["sato", "Issei", ""]]}, {"id": "1611.01259", "submitter": "Nika Haghtalab", "authors": "Avrim Blum, Nika Haghtalab", "title": "Generalized Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been significant activity in developing algorithms with\nprovable guarantees for topic modeling. In standard topic models, a topic (such\nas sports, business, or politics) is viewed as a probability distribution $\\vec\na_i$ over words, and a document is generated by first selecting a mixture $\\vec\nw$ over topics, and then generating words i.i.d. from the associated mixture\n$A{\\vec w}$. Given a large collection of such documents, the goal is to recover\nthe topic vectors and then to correctly classify new documents according to\ntheir topic mixture.\n  In this work we consider a broad generalization of this framework in which\nwords are no longer assumed to be drawn i.i.d. and instead a topic is a complex\ndistribution over sequences of paragraphs. Since one could not hope to even\nrepresent such a distribution in general (even if paragraphs are given using\nsome natural feature representation), we aim instead to directly learn a\ndocument classifier. That is, we aim to learn a predictor that given a new\ndocument, accurately predicts its topic mixture, without learning the\ndistributions explicitly. We present several natural conditions under which one\ncan do this efficiently and discuss issues such as noise tolerance and sample\ncomplexity in this model. More generally, our model can be viewed as a\ngeneralization of the multi-view or co-training setting in machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 03:45:03 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Blum", "Avrim", ""], ["Haghtalab", "Nika", ""]]}, {"id": "1611.01260", "submitter": "Pedro H. P. Savarese", "authors": "Pedro H. P. Savarese and Leonardo O. Mazza and Daniel R. Figueiredo", "title": "Learning Identity Mappings with Residual Gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new layer design by adding a linear gating mechanism to shortcut\nconnections. By using a scalar parameter to control each gate, we provide a way\nto learn identity mappings by optimizing only one parameter. We build upon the\nmotivation behind Residual Networks, where a layer is reformulated in order to\nmake learning identity mappings less problematic to the optimizer. The\naugmentation introduces only one extra parameter per layer, and provides easier\noptimization by making degeneration into identity mappings simpler. We propose\na new model, the Gated Residual Network, which is the result when augmenting\nResidual Networks. Experimental results show that augmenting layers provides\nbetter optimization, increased performance, and more layer independence. We\nevaluate our method on MNIST using fully-connected networks, showing empirical\nindications that our augmentation facilitates the optimization of deep models,\nand that it provides high tolerance to full layer removal: the model retains\nover 90% of its performance even after half of its layers have been randomly\nremoved. We also evaluate our model on CIFAR-10 and CIFAR-100 using Wide Gated\nResNets, achieving 3.65% and 18.27% error, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 04:34:38 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 01:36:47 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Savarese", "Pedro H. P.", ""], ["Mazza", "Leonardo O.", ""], ["Figueiredo", "Daniel R.", ""]]}, {"id": "1611.01268", "submitter": "Hyo-Eun Kim", "authors": "Hyo-Eun Kim, Sangheum Hwang, Kyunghyun Cho", "title": "Semantic Noise Modeling for Better Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent representation learned from multi-layered neural networks via\nhierarchical feature abstraction enables recent success of deep learning. Under\nthe deep learning framework, generalization performance highly depends on the\nlearned latent representation which is obtained from an appropriate training\nscenario with a task-specific objective on a designed network model. In this\nwork, we propose a novel latent space modeling method to learn better latent\nrepresentation. We designed a neural network model based on the assumption that\ngood base representation can be attained by maximizing the total correlation\nbetween the input, latent, and output variables. From the base model, we\nintroduce a semantic noise modeling method which enables class-conditional\nperturbation on latent space to enhance the representational power of learned\nlatent feature. During training, latent vector representation can be\nstochastically perturbed by a modeled class-conditional additive noise while\nmaintaining its original semantic feature. It implicitly brings the effect of\nsemantic augmentation on the latent space. The proposed model can be easily\nlearned by back-propagation with common gradient-based optimization algorithms.\nExperimental results show that the proposed method helps to achieve performance\nbenefits against various previous approaches. We also provide the empirical\nanalyses for the proposed class-conditional perturbation process including\nt-SNE visualization.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 05:52:17 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Kim", "Hyo-Eun", ""], ["Hwang", "Sangheum", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1611.01276", "submitter": "Qi Meng", "authors": "Qi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma and\n  Tie-Yan Liu", "title": "A Communication-Efficient Parallel Algorithm for Decision Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree (and its extensions such as Gradient Boosting Decision Trees\nand Random Forest) is a widely used machine learning algorithm, due to its\npractical effectiveness and model interpretability. With the emergence of big\ndata, there is an increasing need to parallelize the training process of\ndecision tree. However, most existing attempts along this line suffer from high\ncommunication costs. In this paper, we propose a new algorithm, called\n\\emph{Parallel Voting Decision Tree (PV-Tree)}, to tackle this challenge. After\npartitioning the training data onto a number of (e.g., $M$) machines, this\nalgorithm performs both local voting and global voting in each iteration. For\nlocal voting, the top-$k$ attributes are selected from each machine according\nto its local data. Then, globally top-$2k$ attributes are determined by a\nmajority voting among these local candidates. Finally, the full-grained\nhistograms of the globally top-$2k$ attributes are collected from local\nmachines in order to identify the best (most informative) attribute and its\nsplit point. PV-Tree can achieve a very low communication cost (independent of\nthe total number of attributes) and thus can scale out very well. Furthermore,\ntheoretical analysis shows that this algorithm can learn a near optimal\ndecision tree, since it can find the best attribute with a large probability.\nOur experiments on real-world datasets show that PV-Tree significantly\noutperforms the existing parallel decision tree algorithms in the trade-off\nbetween accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 07:09:03 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Meng", "Qi", ""], ["Ke", "Guolin", ""], ["Wang", "Taifeng", ""], ["Chen", "Wei", ""], ["Ye", "Qiwei", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1611.01353", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Stefano Soatto", "title": "Information Dropout: Learning Optimal Representations Through Noisy\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cross-entropy loss commonly used in deep learning is closely related to\nthe defining properties of optimal representations, but does not enforce some\nof the key properties. We show that this can be solved by adding a\nregularization term, which is in turn related to injecting multiplicative noise\nin the activations of a Deep Neural Network, a special case of which is the\ncommon practice of dropout. We show that our regularized loss function can be\nefficiently minimized using Information Dropout, a generalization of dropout\nrooted in information theoretic principles that automatically adapts to the\ndata and can better exploit architectures of limited capacity. When the task is\nthe reconstruction of the input, we show that our loss function yields a\nVariational Autoencoder as a special case, thus providing a link between\nrepresentation learning, information theory and variational inference. Finally,\nwe prove that we can promote the creation of disentangled representations\nsimply by enforcing a factorized prior, a fact that has been observed\nempirically in recent work. Our experiments validate the theoretical intuitions\nbehind our method, and we find that information dropout achieves a comparable\nor better generalization performance than binary dropout, especially on smaller\nmodels, since it can automatically adapt the noise to the structure of the\nnetwork, as well as to the test sample.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 12:46:37 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 00:40:19 GMT"}, {"version": "v3", "created": "Sun, 12 Feb 2017 09:26:25 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1611.01400", "submitter": "Jesse Lingeman", "authors": "Jesse M Lingeman, Hong Yu", "title": "Learning to Rank Scientific Documents from the Crowd", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding related published articles is an important task in any science, but\nwith the explosion of new work in the biomedical domain it has become\nespecially challenging. Most existing methodologies use text similarity metrics\nto identify whether two articles are related or not. However biomedical\nknowledge discovery is hypothesis-driven. The most related articles may not be\nones with the highest text similarities. In this study, we first develop an\ninnovative crowd-sourcing approach to build an expert-annotated\ndocument-ranking corpus. Using this corpus as the gold standard, we then\nevaluate the approaches of using text similarity to rank the relatedness of\narticles. Finally, we develop and evaluate a new supervised model to\nautomatically rank related scientific articles. Our results show that authors'\nranking differ significantly from rankings by text-similarity-based models. By\ntraining a learning-to-rank model on a subset of the annotated corpus, we found\nthe best supervised learning-to-rank model (SVM-Rank) significantly surpassed\nstate-of-the-art baseline systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 14:43:44 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Lingeman", "Jesse M", ""], ["Yu", "Hong", ""]]}, {"id": "1611.01414", "submitter": "Wentao Huang", "authors": "Wentao Huang and Kechen Zhang", "title": "Information-Theoretic Bounds and Approximations in Neural Population\n  Coding", "comments": null, "journal-ref": "Neural Computation. 30(2018)885-944", "doi": "10.1162/NECO_a_01056", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Shannon's mutual information has widespread applications in many\ndisciplines, for practical applications it is often difficult to calculate its\nvalue accurately for high-dimensional variables because of the curse of\ndimensionality. This paper is focused on effective approximation methods for\nevaluating mutual information in the context of neural population coding. For\nlarge but finite neural populations, we derive several information-theoretic\nasymptotic bounds and approximation formulas that remain valid in\nhigh-dimensional spaces. We prove that optimizing the population density\ndistribution based on these approximation formulas is a convex optimization\nproblem which allows efficient numerical solutions. Numerical simulation\nresults confirmed that our asymptotic formulas were highly accurate for\napproximating mutual information for large neural populations. In special\ncases, the approximation formulas are exactly equal to the true mutual\ninformation. We also discuss techniques of variable transformation and\ndimensionality reduction to facilitate computation of the approximations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:12:47 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 23:33:13 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 17:11:42 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Huang", "Wentao", ""], ["Zhang", "Kechen", ""]]}, {"id": "1611.01423", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Pankajan Chanthirasegaran, Pushmeet Kohli,\n  Charles Sutton", "title": "Learning Continuous Semantic Representations of Symbolic Expressions", "comments": "Accepted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining abstract, symbolic reasoning with continuous neural reasoning is a\ngrand challenge of representation learning. As a step in this direction, we\npropose a new architecture, called neural equivalence networks, for the problem\nof learning continuous semantic representations of algebraic and logical\nexpressions. These networks are trained to represent semantic equivalence, even\nof expressions that are syntactically very different. The challenge is that\nsemantic representations must be computed in a syntax-directed manner, because\nsemantics is compositional, but at the same time, small changes in syntax can\nlead to very large changes in semantics, which can be difficult for continuous\nneural architectures. We perform an exhaustive evaluation on the task of\nchecking equivalence on a highly diverse class of symbolic algebraic and\nboolean expression types, showing that our model significantly outperforms\nexisting architectures.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:30:43 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 19:18:55 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Chanthirasegaran", "Pankajan", ""], ["Kohli", "Pushmeet", ""], ["Sutton", "Charles", ""]]}, {"id": "1611.01427", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Carlo Condo and Warren J. Gross", "title": "Sparsely-Connected Neural Networks: Towards Efficient VLSI\n  Implementation of Deep Neural Networks", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have received considerable attention due to\ntheir ability to extract and represent high-level abstractions in data sets.\nDeep neural networks such as fully-connected and convolutional neural networks\nhave shown excellent performance on a wide range of recognition and\nclassification tasks. However, their hardware implementations currently suffer\nfrom large silicon area and high power consumption due to the their high degree\nof complexity. The power/energy consumption of neural networks is dominated by\nmemory accesses, the majority of which occur in fully-connected networks. In\nfact, they contain most of the deep neural network parameters. In this paper,\nwe propose sparsely-connected networks, by showing that the number of\nconnections in fully-connected networks can be reduced by up to 90% while\nimproving the accuracy performance on three popular datasets (MNIST, CIFAR10\nand SVHN). We then propose an efficient hardware architecture based on\nlinear-feedback shift registers to reduce the memory requirements of the\nproposed sparsely-connected networks. The proposed architecture can save up to\n90% of memory compared to the conventional implementations of fully-connected\nneural networks. Moreover, implementation results show up to 84% reduction in\nthe energy consumption of a single neuron of the proposed sparsely-connected\nnetworks compared to a single neuron of fully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:47:32 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 15:52:44 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 19:51:47 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ardakani", "Arash", ""], ["Condo", "Carlo", ""], ["Gross", "Warren J.", ""]]}, {"id": "1611.01449", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Nir Ailon", "title": "Semi-supervised deep learning by metric embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are successfully used as classification models yielding\nstate-of-the-art results when trained on a large number of labeled samples.\nThese models, however, are usually much less suited for semi-supervised\nproblems because of their tendency to overfit easily when trained on small\namounts of data. In this work we will explore a new training objective that is\ntargeting a semi-supervised regime with only a small subset of labeled data.\nThis criterion is based on a deep metric embedding over distance relations\nwithin the set of labeled samples, together with constraints over the\nembeddings of the unlabeled set. The final learned representations are\ndiscriminative in euclidean space, and hence can be used with subsequent\nnearest-neighbor classification using the labeled samples.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 16:39:20 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 15:39:28 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hoffer", "Elad", ""], ["Ailon", "Nir", ""]]}, {"id": "1611.01455", "submitter": "Hanock Kwak", "authors": "Hanock Kwak and Byoung-Tak Zhang", "title": "Ways of Conditioning Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GANs are generative models whose random samples realistically reflect\nnatural images. It also can generate samples with specific attributes by\nconcatenating a condition vector into the input, yet research on this field is\nnot well studied. We propose novel methods of conditioning generative\nadversarial networks (GANs) that achieve state-of-the-art results on MNIST and\nCIFAR-10. We mainly introduce two models: an information retrieving model that\nextracts conditional information from the samples, and a spatial bilinear\npooling model that forms bilinear features derived from the spatial cross\nproduct of an image and a condition vector. These methods significantly enhance\nlog-likelihood of test data under the conditional distributions compared to the\nmethods of concatenation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 17:08:54 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Kwak", "Hanock", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1611.01456", "submitter": "Dorina Thanou", "authors": "Dorina Thanou, Xiaowen Dong, Daniel Kressner, and Pascal Frossard", "title": "Learning heat diffusion graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective information analysis generally boils down to properly identifying\nthe structure or geometry of the data, which is often represented by a graph.\nIn some applications, this structure may be partly determined by design\nconstraints or pre-determined sensing arrangements, like in road transportation\nnetworks for example. In general though, the data structure is not readily\navailable and becomes pretty difficult to define. In particular, the global\nsmoothness assumptions, that most of the existing works adopt, are often too\ngeneral and unable to properly capture localized properties of data. In this\npaper, we go beyond this classical data model and rather propose to represent\ninformation as a sparse combination of localized functions that live on a data\nstructure represented by a graph. Based on this model, we focus on the problem\nof inferring the connectivity that best explains the data samples at different\nvertices of a graph that is a priori unknown. We concentrate on the case where\nthe observed data is actually the sum of heat diffusion processes, which is a\nquite common model for data on networks or other irregular structures. We cast\na new graph learning problem and solve it with an efficient nonconvex\noptimization algorithm. Experiments on both synthetic and real world data\nfinally illustrate the benefits of the proposed graph learning framework and\nconfirm that the data structure can be efficiently learned from data\nobservations only. We believe that our algorithm will help solving key\nquestions in diverse application domains such as social and biological network\nanalysis where it is crucial to unveil proper geometry for data understanding\nand inference.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 17:16:17 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Thanou", "Dorina", ""], ["Dong", "Xiaowen", ""], ["Kressner", "Daniel", ""], ["Frossard", "Pascal", ""]]}, {"id": "1611.01457", "submitter": "Asier Mujika", "authors": "Asier Mujika", "title": "Multi-task learning with deep model based reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, model-free methods that use deep learning have achieved\ngreat success in many different reinforcement learning environments. Most\nsuccessful approaches focus on solving a single task, while multi-task\nreinforcement learning remains an open problem. In this paper, we present a\nmodel based approach to deep reinforcement learning which we use to solve\ndifferent tasks simultaneously. We show that our approach not only does not\ndegrade but actually benefits from learning multiple tasks. For our model, we\nalso present a new kind of recurrent neural network inspired by residual\nnetworks that decouples memory from computation allowing to model complex\nenvironments that do not require lots of memory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 17:20:22 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 12:48:31 GMT"}, {"version": "v3", "created": "Mon, 22 May 2017 09:08:44 GMT"}, {"version": "v4", "created": "Tue, 23 May 2017 18:52:37 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Mujika", "Asier", ""]]}, {"id": "1611.01462", "submitter": "Hakan Inan", "authors": "Hakan Inan, Khashayar Khosravi, Richard Socher", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been very successful at predicting sequences\nof words in tasks such as language modeling. However, all such models are based\non the conventional classification framework, where the model is trained\nagainst one-hot targets, and each word is represented both as an input and as\nan output in isolation. This causes inefficiencies in learning both in terms of\nutilizing all of the information and in terms of the number of parameters\nneeded to train. We introduce a novel theoretical framework that facilitates\nbetter learning in language modeling, and show that our framework leads to\ntying together the input embedding and the output projection matrices, greatly\nreducing the number of trainable variables. Our framework leads to state of the\nart performance on the Penn Treebank with a variety of network models.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 17:36:20 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 22:30:23 GMT"}, {"version": "v3", "created": "Sat, 11 Mar 2017 19:13:52 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Inan", "Hakan", ""], ["Khosravi", "Khashayar", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01491", "submitter": "Anirbit Mukherjee", "authors": "Raman Arora, Amitabh Basu, Poorya Mianjy and Anirbit Mukherjee", "title": "Understanding Deep Neural Networks with Rectified Linear Units", "comments": "The poly(data) exact training algorithm has been improved to now be\n  applicable to any single hidden layer R^n-> R ReLU DNN and there is a cleaner\n  pseudocode for it given on page 8. Also now on page 7 there is a more precise\n  description about when and how the Zonotope construction improves on the\n  Theorem 4 of this paper, arXiv:1402.1869", "journal-ref": "ICLR 2028", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the family of functions representable by deep\nneural networks (DNN) with rectified linear units (ReLU). We give an algorithm\nto train a ReLU DNN with one hidden layer to *global optimality* with runtime\npolynomial in the data size albeit exponential in the input dimension. Further,\nwe improve on the known lower bounds on size (from exponential to super\nexponential) for approximating a ReLU deep net function by a shallower ReLU\nnet. Our gap theorems hold for smoothly parametrized families of \"hard\"\nfunctions, contrary to countable, discrete families known in the literature. An\nexample consequence of our gap theorems is the following: for every natural\nnumber $k$ there exists a function representable by a ReLU DNN with $k^2$\nhidden layers and total size $k^3$, such that any ReLU DNN with at most $k$\nhidden layers will require at least $\\frac{1}{2}k^{k+1}-1$ total nodes.\nFinally, for the family of $\\mathbb{R}^n\\to \\mathbb{R}$ DNNs with ReLU\nactivations, we show a new lowerbound on the number of affine pieces, which is\nlarger than previous constructions in certain regimes of the network\narchitecture and most distinctively our lowerbound is demonstrated by an\nexplicit construction of a *smoothly parameterized* family of functions\nattaining this scaling. Our construction utilizes the theory of zonotopes from\npolyhedral theory.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 18:54:50 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 20:25:56 GMT"}, {"version": "v3", "created": "Sat, 26 Nov 2016 17:38:11 GMT"}, {"version": "v4", "created": "Mon, 29 May 2017 20:06:50 GMT"}, {"version": "v5", "created": "Tue, 18 Jul 2017 17:17:14 GMT"}, {"version": "v6", "created": "Wed, 28 Feb 2018 02:23:47 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Arora", "Raman", ""], ["Basu", "Amitabh", ""], ["Mianjy", "Poorya", ""], ["Mukherjee", "Anirbit", ""]]}, {"id": "1611.01503", "submitter": "Akosua Busia", "authors": "Akosua Busia, Jasmine Collins, Navdeep Jaitly", "title": "Protein Secondary Structure Prediction Using Deep Multi-scale\n  Convolutional Neural Networks and Next-Step Conditioning", "comments": "10 pages, 2 figures, submitted to RECOMB 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed deep learning techniques have significantly improved the\naccuracy of various speech and image recognition systems. In this paper we\nadapt some of these techniques for protein secondary structure prediction. We\nfirst train a series of deep neural networks to predict eight-class secondary\nstructure labels given a protein's amino acid sequence information and find\nthat using recent methods for regularization, such as dropout and weight-norm\nconstraining, leads to measurable gains in accuracy. We then adapt recent\nconvolutional neural network architectures--Inception, ReSNet, and DenseNet\nwith Batch Normalization--to the problem of protein structure prediction. These\nconvolutional architectures make heavy use of multi-scale filter layers that\nsimultaneously compute features on several scales, and use residual connections\nto prevent underfitting. Using a carefully modified version of these\narchitectures, we achieve state-of-the-art performance of 70.0% per amino acid\naccuracy on the public CB513 benchmark dataset. Finally, we explore additions\nfrom sequence-to-sequence learning, altering the model to make its predictions\nconditioned on both the protein's amino acid sequence and its past secondary\nstructure labels. We introduce a new method of ensembling such a conditional\nmodel with our convolutional model, an approach which reaches 70.6% Q8 accuracy\non CB513. We argue that these results can be further refined for larger boosts\nin prediction accuracy through more sophisticated attempts to control\noverfitting of conditional models. We aim to release the code for these\nexperiments as part of the TensorFlow repository.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 19:32:15 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Busia", "Akosua", ""], ["Collins", "Jasmine", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1611.01504", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Frederick Eberhardt and Pietro Perona", "title": "Estimating Causal Direction and Confounding of Two Discrete Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to classify the causal relationship between two discrete\nvariables given only the joint distribution of the variables, acknowledging\nthat the method is subject to an inherent baseline error. We assume that the\ncausal system is acyclicity, but we do allow for hidden common causes. Our\nalgorithm presupposes that the probability distributions $P(C)$ of a cause $C$\nis independent from the probability distribution $P(E\\mid C)$ of the\ncause-effect mechanism. While our classifier is trained with a Bayesian\nassumption of flat hyperpriors, we do not make this assumption about our test\ndata. This work connects to recent developments on the identifiability of\ncausal models over continuous variables under the assumption of \"independent\nmechanisms\". Carefully-commented Python notebooks that reproduce all our\nexperiments are available online at\nhttp://vision.caltech.edu/~kchalupk/code.html.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 19:33:35 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Eberhardt", "Frederick", ""], ["Perona", "Pietro", ""]]}, {"id": "1611.01505", "submitter": "Jayanth Koushik", "authors": "Hiroaki Hayashi, Jayanth Koushik, Graham Neubig", "title": "Eve: A Gradient Based Optimization Method with Locally and Globally\n  Adaptive Learning Rates", "comments": "New experiments, rewrite", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods for stochastic optimization adjust the learning\nrate for each parameter locally. However, there is also a global learning rate\nwhich must be tuned in order to get the best performance. In this paper, we\npresent a new algorithm that adapts the learning rate locally for each\nparameter separately, and also globally for all parameters together.\nSpecifically, we modify Adam, a popular method for training deep learning\nmodels, with a coefficient that captures properties of the objective function.\nEmpirically, we show that our method, which we call Eve, outperforms Adam and\nother popular methods in training deep neural networks, like convolutional\nneural networks for image classification, and recurrent neural networks for\nlanguage tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 19:42:45 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 04:39:29 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 04:28:33 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Hayashi", "Hiroaki", ""], ["Koushik", "Jayanth", ""], ["Neubig", "Graham", ""]]}, {"id": "1611.01540", "submitter": "Daniel Freeman", "authors": "C. Daniel Freeman and Joan Bruna", "title": "Topology and Geometry of Half-Rectified Network Optimization", "comments": "22 Pages (10 main + Appendices), 4 Figures, 1 Table, Published as a\n  conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss surface of deep neural networks has recently attracted interest in\nthe optimization and machine learning communities as a prime example of\nhigh-dimensional non-convex problem. Some insights were recently gained using\nspin glass models and mean-field approximations, but at the expense of strongly\nsimplifying the nonlinear nature of the model.\n  In this work, we do not make any such assumption and study conditions on the\ndata distribution and model architecture that prevent the existence of bad\nlocal minima. Our theoretical work quantifies and formalizes two important\n\\emph{folklore} facts: (i) the landscape of deep linear networks has a\nradically different topology from that of deep half-rectified ones, and (ii)\nthat the energy landscape in the non-linear case is fundamentally controlled by\nthe interplay between the smoothness of the data distribution and model\nover-parametrization. Our main theoretical contribution is to prove that\nhalf-rectified single layer networks are asymptotically connected, and we\nprovide explicit bounds that reveal the aforementioned interplay.\n  The conditioning of gradient descent is the next challenge we address. We\nstudy this question through the geometry of the level sets, and we introduce an\nalgorithm to efficiently estimate the regularity of such sets on large-scale\nnetworks. Our empirical results show that these level sets remain connected\nthroughout all the learning phase, suggesting a near convex behavior, but they\nbecome exponentially more curvy as the energy level decays, in accordance to\nwhat is observed in practice with very low curvature attractors.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 21:17:42 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 00:26:16 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 04:17:46 GMT"}, {"version": "v4", "created": "Thu, 1 Jun 2017 19:46:41 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Freeman", "C. Daniel", ""], ["Bruna", "Joan", ""]]}, {"id": "1611.01541", "submitter": "Yanming Li", "authors": "Yanming Li, Hyokyoung Hong, Jian Kang, Kevin He, Ji Zhu, Yi Li", "title": "Classification with Ultrahigh-Dimensional Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although much progress has been made in classification with high-dimensional\nfeatures \\citep{Fan_Fan:2008, JGuo:2010, CaiSun:2014, PRXu:2014},\nclassification with ultrahigh-dimensional features, wherein the features much\noutnumber the sample size, defies most existing work. This paper introduces a\nnovel and computationally feasible multivariate screening and classification\nmethod for ultrahigh-dimensional data. Leveraging inter-feature correlations,\nthe proposed method enables detection of marginally weak and sparse signals and\nrecovery of the true informative feature set, and achieves asymptotic optimal\nmisclassification rates. We also show that the proposed procedure provides more\npowerful discovery boundaries compared to those in \\citet{CaiSun:2014} and\n\\citet{JJin:2009}. The performance of the proposed procedure is evaluated using\nsimulation studies and demonstrated via classification of patients with\ndifferent post-transplantation renal functional types.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 21:21:53 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Li", "Yanming", ""], ["Hong", "Hyokyoung", ""], ["Kang", "Jian", ""], ["He", "Kevin", ""], ["Zhu", "Ji", ""], ["Li", "Yi", ""]]}, {"id": "1611.01547", "submitter": "Philip Blair", "authors": "Philip Blair, Yuval Merhav, and Joel Barry", "title": "Automated Generation of Multilingual Clusters for the Evaluation of\n  Distributed Representations", "comments": "Published as a workshop paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a language-agnostic way of automatically generating sets of\nsemantically similar clusters of entities along with sets of \"outlier\"\nelements, which may then be used to perform an intrinsic evaluation of word\nembeddings in the outlier detection task. We used our methodology to create a\ngold-standard dataset, which we call WikiSem500, and evaluated multiple\nstate-of-the-art embeddings. The results show a correlation between performance\non this dataset and performance on sentiment analysis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 21:35:07 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 13:21:17 GMT"}, {"version": "v3", "created": "Fri, 9 Dec 2016 15:58:37 GMT"}, {"version": "v4", "created": "Wed, 21 Dec 2016 17:51:57 GMT"}, {"version": "v5", "created": "Wed, 5 Apr 2017 15:26:51 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Blair", "Philip", ""], ["Merhav", "Yuval", ""], ["Barry", "Joel", ""]]}, {"id": "1611.01576", "submitter": "James Bradbury", "authors": "James Bradbury, Stephen Merity, Caiming Xiong, Richard Socher", "title": "Quasi-Recurrent Neural Networks", "comments": "Submitted to conference track at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful tool for modeling sequential data,\nbut the dependence of each timestep's computation on the previous timestep's\noutput limits parallelism and makes RNNs unwieldy for very long sequences. We\nintroduce quasi-recurrent neural networks (QRNNs), an approach to neural\nsequence modeling that alternates convolutional layers, which apply in parallel\nacross timesteps, and a minimalist recurrent pooling function that applies in\nparallel across channels. Despite lacking trainable recurrent layers, stacked\nQRNNs have better predictive accuracy than stacked LSTMs of the same hidden\nsize. Due to their increased parallelism, they are up to 16 times faster at\ntrain and test time. Experiments on language modeling, sentiment\nclassification, and character-level neural machine translation demonstrate\nthese advantages and underline the viability of QRNNs as a basic building block\nfor a variety of sequence tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:31:25 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 20:52:34 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Bradbury", "James", ""], ["Merity", "Stephen", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01578", "submitter": "Quoc Le", "authors": "Barret Zoph and Quoc V. Le", "title": "Neural Architecture Search with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are powerful and flexible models that work well for many\ndifficult learning tasks in image, speech and natural language understanding.\nDespite their success, neural networks are still hard to design. In this paper,\nwe use a recurrent network to generate the model descriptions of neural\nnetworks and train this RNN with reinforcement learning to maximize the\nexpected accuracy of the generated architectures on a validation set. On the\nCIFAR-10 dataset, our method, starting from scratch, can design a novel network\narchitecture that rivals the best human-invented architecture in terms of test\nset accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is\n0.09 percent better and 1.05x faster than the previous state-of-the-art model\nthat used a similar architectural scheme. On the Penn Treebank dataset, our\nmodel can compose a novel recurrent cell that outperforms the widely-used LSTM\ncell, and other state-of-the-art baselines. Our cell achieves a test set\nperplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than\nthe previous state-of-the-art model. The cell can also be transferred to the\ncharacter language modeling task on PTB and achieves a state-of-the-art\nperplexity of 1.214.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:41:37 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 05:28:05 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Zoph", "Barret", ""], ["Le", "Quoc V.", ""]]}, {"id": "1611.01586", "submitter": "Gang Niu", "authors": "Marthinus C. du Plessis, Gang Niu, and Masashi Sugiyama", "title": "Class-prior Estimation for Learning from Positive and Unlabeled Data", "comments": "To appear in Machine Learning", "journal-ref": null, "doi": "10.1007/s10994-016-5604-6", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the class prior in an unlabeled\ndataset. Under the assumption that an additional labeled dataset is available,\nthe class prior can be estimated by fitting a mixture of class-wise data\ndistributions to the unlabeled data distribution. However, in practice, such an\nadditional labeled dataset is often not available. In this paper, we show that,\nwith additional samples coming only from the positive class, the class prior of\nthe unlabeled dataset can be estimated correctly. Our key idea is to use\nproperly penalized divergences for model fitting to cancel the error caused by\nthe absence of negative samples. We further show that the use of the penalized\n$L_1$-distance gives a computationally efficient algorithm with an analytic\nsolution. The consistency, stability, and estimation error are theoretically\nanalyzed. Finally, we experimentally demonstrate the usefulness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 01:58:12 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Plessis", "Marthinus C. du", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1611.01599", "submitter": "Yannis Assael", "authors": "Yannis M. Assael, Brendan Shillingford, Shimon Whiteson, Nando de\n  Freitas", "title": "LipNet: End-to-End Sentence-level Lipreading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipreading is the task of decoding text from the movement of a speaker's\nmouth. Traditional approaches separated the problem into two stages: designing\nor learning visual features, and prediction. More recent deep lipreading\napproaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman,\n2016a). However, existing work on models trained end-to-end perform only word\nclassification, rather than sentence-level sequence prediction. Studies have\nshown that human lipreading performance increases for longer words (Easton &\nBasala, 1982), indicating the importance of features capturing temporal context\nin an ambiguous communication channel. Motivated by this observation, we\npresent LipNet, a model that maps a variable-length sequence of video frames to\ntext, making use of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. To the\nbest of our knowledge, LipNet is the first end-to-end sentence-level lipreading\nmodel that simultaneously learns spatiotemporal visual features and a sequence\nmodel. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level,\noverlapped speaker split task, outperforming experienced human lipreaders and\nthe previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016).\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:05:18 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 16:09:34 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Assael", "Yannis M.", ""], ["Shillingford", "Brendan", ""], ["Whiteson", "Shimon", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.01600", "submitter": "Lu Hou", "authors": "Lu Hou, Quanming Yao, James T. Kwok", "title": "Loss-aware Binarization of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models, though very powerful and highly successful, are\ncomputationally expensive in terms of space and time. Recently, there have been\na number of attempts on binarizing the network weights and activations. This\ngreatly reduces the network size, and replaces the underlying multiplications\nto additions or even XNOR bit operations. However, existing binarization\nschemes are based on simple matrix approximation and ignore the effect of\nbinarization on the loss. In this paper, we propose a proximal Newton algorithm\nwith diagonal Hessian approximation that directly minimizes the loss w.r.t. the\nbinarized weights. The underlying proximal step has an efficient closed-form\nsolution, and the second-order information can be efficiently obtained from the\nsecond moments already computed by the Adam optimizer. Experiments on both\nfeedforward and recurrent networks show that the proposed loss-aware\nbinarization algorithm outperforms existing binarization schemes, and is also\nmore robust for wide and deep networks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:23:42 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 02:49:19 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 11:20:09 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Hou", "Lu", ""], ["Yao", "Quanming", ""], ["Kwok", "James T.", ""]]}, {"id": "1611.01606", "submitter": "Alexander Schwing", "authors": "Frank S. He and Yang Liu and Alexander G. Schwing and Jian Peng", "title": "Learning to Play in a Day: Faster Deep Reinforcement Learning by\n  Optimality Tightening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel training algorithm for reinforcement learning which\ncombines the strength of deep Q-learning with a constrained optimization\napproach to tighten optimality and encourage faster reward propagation. Our\nnovel technique makes deep reinforcement learning more practical by drastically\nreducing the training time. We evaluate the performance of our approach on the\n49 games of the challenging Arcade Learning Environment, and report significant\nimprovements in both training time and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 05:42:40 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["He", "Frank S.", ""], ["Liu", "Yang", ""], ["Schwing", "Alexander G.", ""], ["Peng", "Jian", ""]]}, {"id": "1611.01626", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue, Remi Munos, Koray Kavukcuoglu and Volodymyr Mnih", "title": "Combining policy gradient and Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient is an efficient technique for improving a policy in a\nreinforcement learning setting. However, vanilla online variants are on-policy\nonly and not able to take advantage of off-policy data. In this paper we\ndescribe a new technique that combines policy gradient with off-policy\nQ-learning, drawing experience from a replay buffer. This is motivated by\nmaking a connection between the fixed points of the regularized policy gradient\nalgorithm and the Q-values. This connection allows us to estimate the Q-values\nfrom the action preferences of the policy, to which we apply Q-learning\nupdates. We refer to the new technique as 'PGQL', for policy gradient and\nQ-learning. We also establish an equivalency between action-value fitting\ntechniques and actor-critic algorithms, showing that regularized policy\ngradient techniques can be interpreted as advantage function learning\nalgorithms. We conclude with some numerical examples that demonstrate improved\ndata efficiency and stability of PGQL. In particular, we tested PGQL on the\nfull suite of Atari games and achieved performance exceeding that of both\nasynchronous advantage actor-critic (A3C) and Q-learning.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 10:49:37 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 12:38:42 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 15:20:05 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["O'Donoghue", "Brendan", ""], ["Munos", "Remi", ""], ["Kavukcuoglu", "Koray", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1611.01639", "submitter": "Patrick McClure", "authors": "Patrick McClure, Nikolaus Kriegeskorte", "title": "Robustly representing uncertainty in deep neural networks through\n  sampling", "comments": "Bayesian Deep Learning Workshop (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) are applied to increasingly challenging\nproblems, they will need to be able to represent their own uncertainty.\nModeling uncertainty is one of the key features of Bayesian methods. Using\nBernoulli dropout with sampling at prediction time has recently been proposed\nas an efficient and well performing variational inference method for DNNs.\nHowever, sampling from other multiplicative noise based variational\ndistributions has not been investigated in depth. We evaluated Bayesian DNNs\ntrained with Bernoulli or Gaussian multiplicative masking of either the units\n(dropout) or the weights (dropconnect). We tested the calibration of the\nprobabilistic predictions of Bayesian convolutional neural networks (CNNs) on\nMNIST and CIFAR-10. Sampling at prediction time increased the calibration of\nthe DNNs' probabalistic predictions. Sampling weights, whether Gaussian or\nBernoulli, led to more robust representation of uncertainty compared to\nsampling of units. However, using either Gaussian or Bernoulli dropout led to\nincreased test set classification accuracy. Based on these findings we used\nboth Bernoulli dropout and Gaussian dropconnect concurrently, which we show\napproximates the use of a spike-and-slab variational distribution without\nincreasing the number of learned parameters. We found that spike-and-slab\nsampling had higher test set performance than Gaussian dropconnect and more\nrobustly represented its uncertainty compared to Bernoulli dropout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 12:32:16 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 09:27:46 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2017 10:21:33 GMT"}, {"version": "v4", "created": "Fri, 1 Sep 2017 02:50:59 GMT"}, {"version": "v5", "created": "Tue, 5 Dec 2017 16:11:17 GMT"}, {"version": "v6", "created": "Fri, 8 Dec 2017 17:36:22 GMT"}, {"version": "v7", "created": "Sat, 20 Jan 2018 13:44:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["McClure", "Patrick", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1611.01655", "submitter": "Yuval Filmus", "authors": "Yuval Dagan, Yuval Filmus, Ariel Gabizon, Shay Moran", "title": "Twenty (simple) questions", "comments": "33 pages; to appear in STOC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.IT cs.LG math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic combinatorial interpretation of Shannon's entropy function is via the\n\"20 questions\" game. This cooperative game is played by two players, Alice and\nBob: Alice picks a distribution $\\pi$ over the numbers $\\{1,\\ldots,n\\}$, and\nannounces it to Bob. She then chooses a number $x$ according to $\\pi$, and Bob\nattempts to identify $x$ using as few Yes/No queries as possible, on average.\n  An optimal strategy for the \"20 questions\" game is given by a Huffman code\nfor $\\pi$: Bob's questions reveal the codeword for $x$ bit by bit. This\nstrategy finds $x$ using fewer than $H(\\pi)+1$ questions on average. However,\nthe questions asked by Bob could be arbitrary. In this paper, we investigate\nthe following question: Are there restricted sets of questions that match the\nperformance of Huffman codes, either exactly or approximately?\n  Our first main result shows that for every distribution $\\pi$, Bob has a\nstrategy that uses only questions of the form \"$x < c$?\" and \"$x = c$?\", and\nuncovers $x$ using at most $H(\\pi)+1$ questions on average, matching the\nperformance of Huffman codes in this sense. We also give a natural set of\n$O(rn^{1/r})$ questions that achieve a performance of at most $H(\\pi)+r$, and\nshow that $\\Omega(rn^{1/r})$ questions are required to achieve such a\nguarantee.\n  Our second main result gives a set $\\mathcal{Q}$ of $1.25^{n+o(n)}$ questions\nsuch that for every distribution $\\pi$, Bob can implement an optimal strategy\nfor $\\pi$ using only questions from $\\mathcal{Q}$. We also show that\n$1.25^{n-o(n)}$ questions are needed, for infinitely many $n$. If we allow a\nsmall slack of $r$ over the optimal strategy, then roughly $(rn)^{\\Theta(1/r)}$\nquestions are necessary and sufficient.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 13:55:25 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 14:00:21 GMT"}, {"version": "v3", "created": "Tue, 25 Apr 2017 10:44:06 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Dagan", "Yuval", ""], ["Filmus", "Yuval", ""], ["Gabizon", "Ariel", ""], ["Moran", "Shay", ""]]}, {"id": "1611.01673", "submitter": "Ian Gemp", "authors": "Ishan Durugkar, Ian Gemp, Sridhar Mahadevan", "title": "Generative Multi-Adversarial Networks", "comments": "Accepted as a conference paper (poster) at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a framework for producing a\ngenerative model by way of a two-player minimax game. In this paper, we propose\nthe \\emph{Generative Multi-Adversarial Network} (GMAN), a framework that\nextends GANs to multiple discriminators. In previous work, the successful\ntraining of GANs requires modifying the minimax objective to accelerate\ntraining early on. In contrast, GMAN can be reliably trained with the original,\nuntampered objective. We explore a number of design perspectives with the\ndiscriminator role ranging from formidable adversary to forgiving teacher.\nImage generation tasks comparing the proposed framework to standard GANs\ndemonstrate GMAN produces higher quality samples in a fraction of the\niterations when measured by a pairwise GAM-type metric.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 16:56:44 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 15:33:09 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 21:20:59 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Durugkar", "Ishan", ""], ["Gemp", "Ian", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1611.01678", "submitter": "Morsal Madani", "authors": "Mirmorsal Madani", "title": "Comparing learning algorithms in neural network for diagnosing\n  cardiovascular disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today data mining techniques are exploited in medical science for diagnosing,\novercoming and treating diseases. Neural network is one of the techniques which\nare widely used for diagnosis in medical field. In this article efficiency of\nnine algorithms, which are basis of neural network learning in diagnosing\ncardiovascular diseases, will be assessed. Algorithms are assessed in terms of\naccuracy, sensitivity, transparency, AROC and convergence rate by means of 10\nfold cross validation. The results suggest that in training phase, Lonberg-M\nalgorithm has the best efficiency in terms of all metrics, algorithm OSS has\nmaximum accuracy in testing phase, algorithm SCG has the maximum transparency\nand algorithm CGB has the maximum sensitivity.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 17:17:14 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Madani", "Mirmorsal", ""]]}, {"id": "1611.01688", "submitter": "Nika Haghtalab", "authors": "Miroslav Dud\\'ik, Nika Haghtalab, Haipeng Luo, Robert E. Schapire,\n  Vasilis Syrgkanis, Jennifer Wortman Vaughan", "title": "Oracle-Efficient Online Learning and Auction Design", "comments": "An earlier version of this paper appeared in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design of computationally efficient online learning\nalgorithms in an adversarial setting in which the learner has access to an\noffline optimization oracle. We present an algorithm called Generalized\nFollow-the-Perturbed-Leader and provide conditions under which it is\noracle-efficient while achieving vanishing regret. Our results make significant\nprogress on an open problem raised by Hazan and Koren, who showed that\noracle-efficient algorithms do not exist in general and asked whether one can\nidentify properties under which oracle-efficient online learning may be\npossible.\n  Our auction-design framework considers an auctioneer learning an optimal\nauction for a sequence of adversarially selected valuations with the goal of\nachieving revenue that is almost as good as the optimal auction in hindsight,\namong a class of auctions. We give oracle-efficient learning results for: (1)\nVCG auctions with bidder-specific reserves in single-parameter settings, (2)\nenvy-free item pricing in multi-item auctions, and (3) s-level auctions of\nMorgenstern and Roughgarden for single-item settings. The last result leads to\nan approximation of the overall optimal Myerson auction when bidders'\nvaluations are drawn according to a fast-mixing Markov process, extending prior\nwork that only gave such guarantees for the i.i.d. setting.\n  Finally, we derive various extensions, including: (1) oracle-efficient\nalgorithms for the contextual learning setting in which the learner has access\nto side information (such as bidder demographics), (2) learning with\napproximate oracles such as those based on Maximal-in-Range algorithms, and (3)\nno-regret bidding in simultaneous auctions, resolving an open problem of\nDaskalakis and Syrgkanis.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 18:54:59 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 08:21:30 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 14:10:08 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Dud\u00edk", "Miroslav", ""], ["Haghtalab", "Nika", ""], ["Luo", "Haipeng", ""], ["Schapire", "Robert E.", ""], ["Syrgkanis", "Vasilis", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "1611.01702", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Chong Wang, Jianfeng Gao, John Paisley", "title": "TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency", "comments": "International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose TopicRNN, a recurrent neural network (RNN)-based\nlanguage model designed to directly capture the global semantic meaning\nrelating words in a document via latent topics. Because of their sequential\nnature, RNNs are good at capturing the local structure of a word sequence -\nboth semantic and syntactic - but might face difficulty remembering long-range\ndependencies. Intuitively, these long-range dependencies are of semantic\nnature. In contrast, latent topic models are able to capture the global\nunderlying semantic structure of a document but do not account for word\nordering. The proposed TopicRNN model integrates the merits of RNNs and latent\ntopic models: it captures local (syntactic) dependencies using an RNN and\nglobal (semantic) dependencies using latent topics. Unlike previous work on\ncontextual RNN language modeling, our model is learned end-to-end. Empirical\nresults on word prediction show that TopicRNN outperforms existing contextual\nRNN baselines. In addition, TopicRNN can be used as an unsupervised feature\nextractor for documents. We do this for sentiment analysis on the IMDB movie\nreview dataset and report an error rate of $6.28\\%$. This is comparable to the\nstate-of-the-art $5.91\\%$ resulting from a semi-supervised approach. Finally,\nTopicRNN also yields sensible topics, making it a useful alternative to\ndocument models such as latent Dirichlet allocation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 21:25:07 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 03:03:38 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Dieng", "Adji B.", ""], ["Wang", "Chong", ""], ["Gao", "Jianfeng", ""], ["Paisley", "John", ""]]}, {"id": "1611.01708", "submitter": "Feras Saad", "authors": "Feras Saad, Vikash Mansinghka", "title": "Detecting Dependencies in Sparse, Multivariate Databases Using\n  Probabilistic Programming and Non-parametric Bayes", "comments": null, "journal-ref": "Proceedings of the 20th International Conference on Artificial\n  Intelligence and Statistics, PMLR 54:632-641, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets with hundreds of variables and many missing values are commonplace.\nIn this setting, it is both statistically and computationally challenging to\ndetect true predictive relationships between variables and also to suppress\nfalse positives. This paper proposes an approach that combines probabilistic\nprogramming, information theory, and non-parametric Bayes. It shows how to use\nBayesian non-parametric modeling to (i) build an ensemble of joint probability\nmodels for all the variables; (ii) efficiently detect marginal independencies;\nand (iii) estimate the conditional mutual information between arbitrary subsets\nof variables, subject to a broad class of constraints. Users can access these\ncapabilities using BayesDB, a probabilistic programming platform for\nprobabilistic data analysis, by writing queries in a simple, SQL-like language.\nThis paper demonstrates empirically that the method can (i) detect\ncontext-specific (in)dependencies on challenging synthetic problems and (ii)\nyield improved sensitivity and specificity over baselines from statistics and\nmachine learning, on a real-world database of over 300 sparsely observed\nindicators of macroeconomic development and public health.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 23:02:25 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 03:07:49 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Saad", "Feras", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1611.01714", "submitter": "Nathan Hodas", "authors": "Ark Anderson, Kyle Shaffer, Artem Yankov, Court D. Corley, Nathan O.\n  Hodas", "title": "Beyond Fine Tuning: A Modular Approach to Learning on Small Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a technique to train neural network models on small\namounts of data. Current methods for training neural networks on small amounts\nof rich data typically rely on strategies such as fine-tuning a pre-trained\nneural network or the use of domain-specific hand-engineered features. Here we\ntake the approach of treating network layers, or entire networks, as modules\nand combine pre-trained modules with untrained modules, to learn the shift in\ndistributions between data sets. The central impact of using a modular approach\ncomes from adding new representations to a network, as opposed to replacing\nrepresentations via fine-tuning. Using this technique, we are able surpass\nresults using standard fine-tuning transfer learning approaches, and we are\nalso able to significantly increase performance over such approaches when using\nsmaller amounts of data.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 01:32:39 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Anderson", "Ark", ""], ["Shaffer", "Kyle", ""], ["Yankov", "Artem", ""], ["Corley", "Court D.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1611.01722", "submitter": "Dilin Wang", "authors": "Dilin Wang, Qiang Liu", "title": "Learning to Draw Samples: With Application to Amortized MLE for\n  Generative Adversarial Learning", "comments": "Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple algorithm to train stochastic neural networks to draw\nsamples from given target distributions for probabilistic inference. Our method\nis based on iteratively adjusting the neural network parameters so that the\noutput changes along a Stein variational gradient that maximumly decreases the\nKL divergence with the target distribution. Our method works for any target\ndistribution specified by their unnormalized density function, and can train\nany black-box architectures that are differentiable in terms of the parameters\nwe want to adapt. As an application of our method, we propose an amortized MLE\nalgorithm for training deep energy model, where a neural sampler is adaptively\ntrained to approximate the likelihood function. Our method mimics an\nadversarial game between the deep energy model and the neural sampler, and\nobtains realistic-looking images competitive with the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 02:40:41 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 01:08:47 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Wang", "Dilin", ""], ["Liu", "Qiang", ""]]}, {"id": "1611.01724", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Bhuwan Dhingra, Ye Yuan, Junjie Hu, William W. Cohen,\n  Ruslan Salakhutdinov", "title": "Words or Characters? Fine-grained Gating for Reading Comprehension", "comments": "Accepted as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work combines word-level and character-level representations using\nconcatenation or scalar weighting, which is suboptimal for high-level tasks\nlike reading comprehension. We present a fine-grained gating mechanism to\ndynamically combine word-level and character-level representations based on\nproperties of the words. We also extend the idea of fine-grained gating to\nmodeling the interaction between questions and paragraphs for reading\ncomprehension. Experiments show that our approach can improve the performance\non reading comprehension tasks, achieving new state-of-the-art results on the\nChildren's Book Test dataset. To demonstrate the generality of our gating\nmechanism, we also show improved results on a social media tag prediction task.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 03:17:42 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 21:00:30 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Yang", "Zhilin", ""], ["Dhingra", "Bhuwan", ""], ["Yuan", "Ye", ""], ["Hu", "Junjie", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1611.01726", "submitter": "Gyuwan Kim", "authors": "Gyuwan Kim, Hayoon Yi, Jangho Lee, Yunheung Paek, Sungroh Yoon", "title": "LSTM-Based System-Call Language Modeling and Robust Ensemble Method for\n  Designing Host-Based Intrusion Detection Systems", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer security, designing a robust intrusion detection system is one of\nthe most fundamental and important problems. In this paper, we propose a\nsystem-call language-modeling approach for designing anomaly-based host\nintrusion detection systems. To remedy the issue of high false-alarm rates\ncommonly arising in conventional methods, we employ a novel ensemble method\nthat blends multiple thresholding classifiers into a single one, making it\npossible to accumulate 'highly normal' sequences. The proposed system-call\nlanguage model has various advantages leveraged by the fact that it can learn\nthe semantic meaning and interactions of each system call that existing methods\ncannot effectively consider. Through diverse experiments on public benchmark\ndatasets, we demonstrate the validity and effectiveness of the proposed method.\nMoreover, we show that our model possesses high portability, which is one of\nthe key aspects of realizing successful intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 04:07:29 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Kim", "Gyuwan", ""], ["Yi", "Hayoon", ""], ["Lee", "Jangho", ""], ["Paek", "Yunheung", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.01752", "submitter": "Pavol Bielik", "authors": "Pavol Bielik, Veselin Raychev, Martin Vechev", "title": "Learning a Static Analyzer from Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be practically useful, modern static analyzers must precisely model the\neffect of both, statements in the programming language as well as frameworks\nused by the program under analysis. While important, manually addressing these\nchallenges is difficult for at least two reasons: (i) the effects on the\noverall analysis can be non-trivial, and (ii) as the size and complexity of\nmodern libraries increase, so is the number of cases the analysis must handle.\n  In this paper we present a new, automated approach for creating static\nanalyzers: instead of manually providing the various inference rules of the\nanalyzer, the key idea is to learn these rules from a dataset of programs. Our\nmethod consists of two ingredients: (i) a synthesis algorithm capable of\nlearning a candidate analyzer from a given dataset, and (ii) a counter-example\nguided learning procedure which generates new programs beyond those in the\ninitial dataset, critical for discovering corner cases and ensuring the learned\nanalysis generalizes to unseen programs.\n  We implemented and instantiated our approach to the task of learning\nJavaScript static analysis rules for a subset of points-to analysis and for\nallocation sites analysis. These are challenging yet important problems that\nhave received significant research attention. We show that our approach is\neffective: our system automatically discovered practical and useful inference\nrules for many cases that are tricky to manually identify and are missed by\nstate-of-the-art, manually tuned analyzers.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 10:35:56 GMT"}, {"version": "v2", "created": "Sun, 25 Jun 2017 16:32:21 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Bielik", "Pavol", ""], ["Raychev", "Veselin", ""], ["Vechev", "Martin", ""]]}, {"id": "1611.01779", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy and Vladlen Koltun", "title": "Learning to Act by Predicting the Future", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to sensorimotor control in immersive environments. Our\napproach utilizes a high-dimensional sensory stream and a lower-dimensional\nmeasurement stream. The cotemporal structure of these streams provides a rich\nsupervisory signal, which enables training a sensorimotor control model by\ninteracting with the environment. The model is trained using supervised\nlearning techniques, but without extraneous supervision. It learns to act based\non raw sensory input from a complex three-dimensional environment. The\npresented formulation enables learning without a fixed goal at training time,\nand pursuing dynamically changing goals at test time. We conduct extensive\nexperiments in three-dimensional simulations based on the classical\nfirst-person game Doom. The results demonstrate that the presented approach\noutperforms sophisticated prior formulations, particularly on challenging\ntasks. The results also show that trained models successfully generalize across\nenvironments and goals. A model trained using the presented approach won the\nFull Deathmatch track of the Visual Doom AI Competition, which was held in\npreviously unseen environments.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 13:45:00 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 19:47:46 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1611.01787", "submitter": "Rudy Bunel", "authors": "Rudy Bunel, Alban Desmaison, M. Pawan Kumar, Philip H.S. Torr and\n  Pushmeet Kohli", "title": "Learning to superoptimize programs", "comments": "Accepted to ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code super-optimization is the task of transforming any given program to a\nmore efficient version while preserving its input-output behaviour. In some\nsense, it is similar to the paraphrase problem from natural language processing\nwhere the intention is to change the syntax of an utterance without changing\nits semantics. Code-optimization has been the subject of years of research that\nhas resulted in the development of rule-based transformation strategies that\nare used by compilers. More recently, however, a class of stochastic search\nbased methods have been shown to outperform these strategies. This approach\ninvolves repeated sampling of modifications to the program from a proposal\ndistribution, which are accepted or rejected based on whether they preserve\ncorrectness, and the improvement they achieve. These methods, however, neither\nlearn from past behaviour nor do they try to leverage the semantics of the\nprogram under consideration. Motivated by this observation, we present a novel\nlearning based approach for code super-optimization. Intuitively, our method\nworks by learning the proposal distribution using unbiased estimators of the\ngradient of the expected improvement. Experiments on benchmarks comprising of\nautomatically generated as well as existing (\"Hacker's Delight\") programs show\nthat the proposed method is able to significantly outperform state of the art\napproaches for code super-optimization.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 14:35:38 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 14:59:49 GMT"}, {"version": "v3", "created": "Wed, 28 Jun 2017 15:04:46 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Bunel", "Rudy", ""], ["Desmaison", "Alban", ""], ["Kumar", "M. Pawan", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1611.01796", "submitter": "Jacob Andreas", "authors": "Jacob Andreas and Dan Klein and Sergey Levine", "title": "Modular Multitask Reinforcement Learning with Policy Sketches", "comments": "To appear at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework for multitask deep reinforcement learning guided by\npolicy sketches. Sketches annotate tasks with sequences of named subtasks,\nproviding information about high-level structural relationships among tasks but\nnot how to implement them---specifically not providing the detailed guidance\nused by much previous work on learning policy abstractions for RL (e.g.\nintermediate rewards, subtask completion signals, or intrinsic motivations). To\nlearn from sketches, we present a model that associates every subtask with a\nmodular subpolicy, and jointly maximizes reward over full task-specific\npolicies by tying parameters across shared subpolicies. Optimization is\naccomplished via a decoupled actor--critic training objective that facilitates\nlearning common behaviors from multiple dissimilar reward functions. We\nevaluate the effectiveness of our approach in three environments featuring both\ndiscrete and continuous control, and with sparse rewards that can be obtained\nonly after completing a number of high-level subgoals. Experiments show that\nusing our approach to learn policies guided by sketches gives better\nperformance than existing techniques for learning task-specific or shared\npolicies, while naturally inducing a library of interpretable primitive\nbehaviors that can be recombined to rapidly adapt to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 15:36:56 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 01:49:12 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Andreas", "Jacob", ""], ["Klein", "Dan", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.01799", "submitter": "Shuangfei Zhai", "authors": "Shuangfei Zhai, Yu Cheng, Rogerio Feris, Zhongfei Zhang", "title": "Generative Adversarial Networks as Variational Training of Energy Based\n  Models", "comments": "Under review at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study deep generative models for effective unsupervised\nlearning. We propose VGAN, which works by minimizing a variational lower bound\nof the negative log likelihood (NLL) of an energy based model (EBM), where the\nmodel density $p(\\mathbf{x})$ is approximated by a variational distribution\n$q(\\mathbf{x})$ that is easy to sample from. The training of VGAN takes a two\nstep procedure: given $p(\\mathbf{x})$, $q(\\mathbf{x})$ is updated to maximize\nthe lower bound; $p(\\mathbf{x})$ is then updated one step with samples drawn\nfrom $q(\\mathbf{x})$ to decrease the lower bound. VGAN is inspired by the\ngenerative adversarial networks (GANs), where $p(\\mathbf{x})$ corresponds to\nthe discriminator and $q(\\mathbf{x})$ corresponds to the generator, but with\nseveral notable differences. We hence name our model variational GANs (VGANs).\nVGAN provides a practical solution to training deep EBMs in high dimensional\nspace, by eliminating the need of MCMC sampling. From this view, we are also\nable to identify causes to the difficulty of training GANs and propose viable\nsolutions. \\footnote{Experimental code is available at\nhttps://github.com/Shuangfei/vgan}\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 16:04:48 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Zhai", "Shuangfei", ""], ["Cheng", "Yu", ""], ["Feris", "Rogerio", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1611.01838", "submitter": "Pratik Chaudhari", "authors": "Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo\n  Baldassi, Christian Borgs, Jennifer Chayes, Levent Sagun, Riccardo Zecchina", "title": "Entropy-SGD: Biasing Gradient Descent Into Wide Valleys", "comments": "ICLR '17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new optimization algorithm called Entropy-SGD for\ntraining deep neural networks that is motivated by the local geometry of the\nenergy landscape. Local extrema with low generalization error have a large\nproportion of almost-zero eigenvalues in the Hessian with very few positive or\nnegative eigenvalues. We leverage upon this observation to construct a\nlocal-entropy-based objective function that favors well-generalizable solutions\nlying in large flat regions of the energy landscape, while avoiding\npoorly-generalizable solutions located in the sharp valleys. Conceptually, our\nalgorithm resembles two nested loops of SGD where we use Langevin dynamics in\nthe inner loop to compute the gradient of the local entropy before each update\nof the weights. We show that the new objective has a smoother energy landscape\nand show improved generalization over SGD using uniform stability, under\ncertain assumptions. Our experiments on convolutional and recurrent networks\ndemonstrate that Entropy-SGD compares favorably to state-of-the-art techniques\nin terms of generalization error and training time.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 20:22:49 GMT"}, {"version": "v2", "created": "Sun, 13 Nov 2016 23:49:08 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 15:17:18 GMT"}, {"version": "v4", "created": "Sat, 14 Jan 2017 04:25:53 GMT"}, {"version": "v5", "created": "Fri, 21 Apr 2017 07:16:30 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Chaudhari", "Pratik", ""], ["Choromanska", "Anna", ""], ["Soatto", "Stefano", ""], ["LeCun", "Yann", ""], ["Baldassi", "Carlo", ""], ["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Sagun", "Levent", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1611.01843", "submitter": "Misha Denil", "authors": "Misha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter\n  Battaglia, Nando de Freitas", "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When encountering novel objects, humans are able to infer a wide range of\nphysical properties such as mass, friction and deformability by interacting\nwith them in a goal driven way. This process of active interaction is in the\nsame spirit as a scientist performing experiments to discover hidden facts.\nRecent advances in artificial intelligence have yielded machines that can\nachieve superhuman performance in Go, Atari, natural language processing, and\ncomplex control problems; however, it is not clear that these systems can rival\nthe scientific intuition of even a young child. In this work we introduce a\nbasic set of tasks that require agents to estimate properties such as mass and\ncohesion of objects in an interactive simulated environment where they can\nmanipulate the objects and observe the consequences. We found that state of art\ndeep reinforcement learning methods can learn to perform the experiments\nnecessary to discover such hidden properties. By systematically manipulating\nthe problem difficulty and the cost incurred by the agent for performing\nexperiments, we found that agents learn different strategies that balance the\ncost of gathering information against the cost of making mistakes in different\nsituations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 20:55:19 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 16:40:58 GMT"}, {"version": "v3", "created": "Thu, 17 Aug 2017 19:51:29 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Denil", "Misha", ""], ["Agrawal", "Pulkit", ""], ["Kulkarni", "Tejas D", ""], ["Erez", "Tom", ""], ["Battaglia", "Peter", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.01875", "submitter": "Jundong Li", "authors": "Jundong Li, Huan Liu", "title": "Challenges of Feature Selection for Big Data Analytics", "comments": "Special Issue on Big Data, IEEE Intelligent Systems, 2016. arXiv\n  admin note: text overlap with arXiv:1601.07996", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are surrounded by huge amounts of large-scale high dimensional data. It is\ndesirable to reduce the dimensionality of data for many learning tasks due to\nthe curse of dimensionality. Feature selection has shown its effectiveness in\nmany applications by building simpler and more comprehensive model, improving\nlearning performance, and preparing clean, understandable data. Recently, some\nunique characteristics of big data such as data velocity and data variety\npresent challenges to the feature selection problem. In this paper, we envision\nthese challenges of feature selection for big data analytics. In particular, we\nfirst give a brief introduction about feature selection and then detail the\nchallenges of feature selection for structured, heterogeneous and streaming\ndata as well as its scalability and stability issues. At last, to facilitate\nand promote the feature selection research, we present an open-source feature\nselection repository (scikit-feature), which consists of most of current\npopular feature selection algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 02:17:43 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Li", "Jundong", ""], ["Liu", "Huan", ""]]}, {"id": "1611.01886", "submitter": "Wentao Huang", "authors": "Wentao Huang and Kechen Zhang", "title": "An Information-Theoretic Framework for Fast and Robust Unsupervised\n  Learning via Neural Population Infomax", "comments": "25 pages, 7 figures, 5th International Conference on Learning\n  Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is presented for unsupervised learning of representations based\non infomax principle for large-scale neural populations. We use an asymptotic\napproximation to the Shannon's mutual information for a large neural population\nto demonstrate that a good initial approximation to the global\ninformation-theoretic optimum can be obtained by a hierarchical infomax method.\nStarting from the initial solution, an efficient algorithm based on gradient\ndescent of the final objective function is proposed to learn representations\nfrom the input datasets, and the method works for complete, overcomplete, and\nundercomplete bases. As confirmed by numerical experiments, our method is\nrobust and highly efficient for extracting salient features from input\ndatasets. Compared with the main existing methods, our algorithm has a distinct\nadvantage in both the training speed and the robustness of unsupervised\nrepresentation learning. Furthermore, the proposed method is easily extended to\nthe supervised or unsupervised model for training deep structure networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 04:17:28 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 17:53:31 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 17:11:34 GMT"}, {"version": "v4", "created": "Fri, 10 Mar 2017 16:41:16 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Huang", "Wentao", ""], ["Zhang", "Kechen", ""]]}, {"id": "1611.01891", "submitter": "Masahiro Suzuki", "authors": "Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo", "title": "Joint Multimodal Learning with Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep generative models that can exchange multiple modalities\nbi-directionally, e.g., generating images from corresponding texts and vice\nversa. Recently, some studies handle multiple modalities on deep generative\nmodels, such as variational autoencoders (VAEs). However, these models\ntypically assume that modalities are forced to have a conditioned relation,\ni.e., we can only generate modalities in one direction. To achieve our\nobjective, we should extract a joint representation that captures high-level\nconcepts among all modalities and through which we can exchange them\nbi-directionally. As described herein, we propose a joint multimodal\nvariational autoencoder (JMVAE), in which all modalities are independently\nconditioned on joint representation. In other words, it models a joint\ndistribution of modalities. Furthermore, to be able to generate missing\nmodalities from the remaining modalities properly, we develop an additional\nmethod, JMVAE-kl, that is trained by reducing the divergence between JMVAE's\nencoder and prepared networks of respective modalities. Our experiments show\nthat our proposed method can obtain appropriate joint representation from\nmultiple modalities and that it can generate and reconstruct them more properly\nthan conventional VAEs. We further demonstrate that JMVAE can generate multiple\nmodalities bi-directionally.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 04:45:05 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Suzuki", "Masahiro", ""], ["Nakayama", "Kotaro", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1611.01919", "submitter": "Sam Fletcher", "authors": "Sam Fletcher, Md Zahidul Islam", "title": "Decision Tree Classification with Differential Privacy: A Survey", "comments": "Pre-print of paper accepted in ACM Computing Surveys, 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining information about people is becoming increasingly important in\nthe data-driven society of the 21st century. Unfortunately, sometimes there are\nreal-world considerations that conflict with the goals of data mining;\nsometimes the privacy of the people being data mined needs to be considered.\nThis necessitates that the output of data mining algorithms be modified to\npreserve privacy while simultaneously not ruining the predictive power of the\noutputted model. Differential privacy is a strong, enforceable definition of\nprivacy that can be used in data mining algorithms, guaranteeing that nothing\nwill be learned about the people in the data that could not already be\ndiscovered without their participation. In this survey, we focus on one\nparticular data mining algorithm -- decision trees -- and how differential\nprivacy interacts with each of the components that constitute decision tree\nalgorithms. We analyze both greedy and random decision trees, and the conflicts\nthat arise when trying to balance privacy requirements with the accuracy of the\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 07:13:27 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:32:43 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Fletcher", "Sam", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "1611.01929", "submitter": "Oron Anschel", "authors": "Oron Anschel, Nir Baram, Nahum Shimkin", "title": "Averaged-DQN: Variance Reduction and Stabilization for Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instability and variability of Deep Reinforcement Learning (DRL) algorithms\ntend to adversely affect their performance. Averaged-DQN is a simple extension\nto the DQN algorithm, based on averaging previously learned Q-values estimates,\nwhich leads to a more stable training procedure and improved performance by\nreducing approximation error variance in the target values. To understand the\neffect of the algorithm, we examine the source of value function estimation\nerrors and provide an analytical comparison within a simplified model. We\nfurther present experiments on the Arcade Learning Environment benchmark that\ndemonstrate significantly improved stability and performance due to the\nproposed extension.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 08:12:53 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 08:40:02 GMT"}, {"version": "v3", "created": "Wed, 8 Mar 2017 13:50:38 GMT"}, {"version": "v4", "created": "Fri, 10 Mar 2017 09:52:52 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Anschel", "Oron", ""], ["Baram", "Nir", ""], ["Shimkin", "Nahum", ""]]}, {"id": "1611.01942", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, Tarek Abdelzaher", "title": "DeepSense: A Unified Deep Learning Framework for Time-Series Mobile\n  Sensing Data Processing", "comments": "Published in WWW2017. Code available on\n  https://github.com/yscacaca/DeepSense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sensing applications usually require time-series inputs from sensors.\nSome applications, such as tracking, can use sensed acceleration and rate of\nrotation to calculate displacement based on physical system models. Other\napplications, such as activity recognition, extract manually designed features\nfrom sensor inputs for classification. Such applications face two challenges.\nOn one hand, on-device sensor measurements are noisy. For many mobile\napplications, it is hard to find a distribution that exactly describes the\nnoise in practice. Unfortunately, calculating target quantities based on\nphysical system and noise models is only as accurate as the noise assumptions.\nSimilarly, in classification applications, although manually designed features\nhave proven to be effective, it is not always straightforward to find the most\nrobust features to accommodate diverse sensor noise patterns and user\nbehaviors. To this end, we propose DeepSense, a deep learning framework that\ndirectly addresses the aforementioned noise and feature customization\nchallenges in a unified manner. DeepSense integrates convolutional and\nrecurrent neural networks to exploit local interactions among similar mobile\nsensors, merge local interactions of different sensory modalities into global\ninteractions, and extract temporal relationships to model signal dynamics.\nDeepSense thus provides a general signal estimation and classification\nframework that accommodates a wide range of applications. We demonstrate the\neffectiveness of DeepSense using three representative and challenging tasks:\ncar tracking with motion sensors, heterogeneous human activity recognition, and\nuser identification with biometric motion analysis. DeepSense significantly\noutperforms the state-of-the-art methods for all three tasks. In addition,\nDeepSense is feasible to implement on smartphones due to its moderate energy\nconsumption and low latency\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 09:10:06 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 22:02:21 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Yao", "Shuochao", ""], ["Hu", "Shaohan", ""], ["Zhao", "Yiran", ""], ["Zhang", "Aston", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1611.01957", "submitter": "Chao Qu", "authors": "Chao Qu, Yan Li, Huan Xu", "title": "Linear Convergence of SVRG in Statistical Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SVRG and its variants are among the state of art optimization algorithms for\nlarge scale machine learning problems. It is well known that SVRG converges\nlinearly when the objective function is strongly convex. However this setup can\nbe restrictive, and does not include several important formulations such as\nLasso, group Lasso, logistic regression, and some non-convex models including\ncorrected Lasso and SCAD. In this paper, we prove that, for a class of\nstatistical M-estimators covering examples mentioned above, SVRG solves the\nformulation with {\\em a linear convergence rate} without strong convexity or\neven convexity. Our analysis makes use of {\\em restricted strong convexity},\nunder which we show that SVRG converges linearly to the fundamental statistical\nprecision of the model, i.e., the difference between true unknown parameter\n$\\theta^*$ and the optimal solution $\\hat{\\theta}$ of the model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 09:38:12 GMT"}, {"version": "v2", "created": "Sat, 28 Jan 2017 16:23:41 GMT"}, {"version": "v3", "created": "Thu, 27 Jul 2017 06:34:45 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Qu", "Chao", ""], ["Li", "Yan", ""], ["Xu", "Huan", ""]]}, {"id": "1611.01964", "submitter": "Kalina Jasinska", "authors": "Kalina Jasinska, Nikos Karampatziakis", "title": "Log-time and Log-space Extreme Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LTLS, a technique for multiclass and multilabel prediction that\ncan perform training and inference in logarithmic time and space. LTLS embeds\nlarge classification problems into simple structured prediction problems and\nrelies on efficient dynamic programming algorithms for inference. We train LTLS\nwith stochastic gradient descent on a number of multiclass and multilabel\ndatasets and show that despite its small memory footprint it is often\ncompetitive with existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 10:10:43 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Jasinska", "Kalina", ""], ["Karampatziakis", "Nikos", ""]]}, {"id": "1611.01967", "submitter": "Pau Rodr\\'iguez L\\'opez", "authors": "Pau Rodr\\'iguez, Jordi Gonz\\`alez, Guillem Cucurull, Josep M. Gonfaus,\n  Xavier Roca", "title": "Regularizing CNNs with Locally Constrained Decorrelations", "comments": "Accepted at ICLR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is key for deep learning since it allows training more complex\nmodels while keeping lower levels of overfitting. However, the most prevalent\nregularizations do not leverage all the capacity of the models since they rely\non reducing the effective number of parameters. Feature decorrelation is an\nalternative for using the full capacity of the models but the overfitting\nreduction margins are too narrow given the overhead it introduces. In this\npaper, we show that regularizing negatively correlated features is an obstacle\nfor effective decorrelation and present OrthoReg, a novel regularization\ntechnique that locally enforces feature orthogonality. As a result, imposing\nlocality constraints in feature decorrelation removes interferences between\nnegatively correlated feature weights, allowing the regularizer to reach higher\ndecorrelation bounds, and reducing the overfitting more effectively. In\nparticular, we show that the models regularized with OrthoReg have higher\naccuracy bounds even when batch normalization and dropout are present.\nMoreover, since our regularization is directly performed on the weights, it is\nespecially suitable for fully convolutional neural networks, where the weight\nspace is constant compared to the feature map space. As a result, we are able\nto reduce the overfitting of state-of-the-art CNNs on CIFAR-10, CIFAR-100, and\nSVHN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 10:15:40 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 08:18:28 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Rodr\u00edguez", "Pau", ""], ["Gonz\u00e0lez", "Jordi", ""], ["Cucurull", "Guillem", ""], ["Gonfaus", "Josep M.", ""], ["Roca", "Xavier", ""]]}, {"id": "1611.01971", "submitter": "Nicolas Goix", "authors": "Nicolas Goix (LTCI), Nicolas Drougard (ISAE), Romain Brault (LTCI),\n  Ma\\\"el Chiapino (LTCI)", "title": "One Class Splitting Criteria for Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests (RFs) are strong machine learning tools for classification and\nregression. However, they remain supervised algorithms, and no extension of RFs\nto the one-class setting has been proposed, except for techniques based on\nsecond-class sampling. This work fills this gap by proposing a natural\nmethodology to extend standard splitting criteria to the one-class setting,\nstructurally generalizing RFs to one-class classification. An extensive\nbenchmark of seven state-of-the-art anomaly detection algorithms is also\npresented. This empirically demonstrates the relevance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 10:25:15 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 13:11:22 GMT"}, {"version": "v3", "created": "Mon, 21 Nov 2016 08:54:54 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Goix", "Nicolas", "", "LTCI"], ["Drougard", "Nicolas", "", "ISAE"], ["Brault", "Romain", "", "LTCI"], ["Chiapino", "Ma\u00ebl", "", "LTCI"]]}, {"id": "1611.01972", "submitter": "Peisong Wang", "authors": "Peisong Wang and Jian Cheng", "title": "Fixed-point Factorized Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, Deep Neural Networks (DNN) based methods have achieved\nremarkable performance in a wide range of tasks and have been among the most\npowerful and widely used techniques in computer vision. However, DNN-based\nmethods are both computational-intensive and resource-consuming, which hinders\nthe application of these methods on embedded systems like smart phones. To\nalleviate this problem, we introduce a novel Fixed-point Factorized Networks\n(FFN) for pretrained models to reduce the computational complexity as well as\nthe storage requirement of networks. The resulting networks have only weights\nof -1, 0 and 1, which significantly eliminates the most resource-consuming\nmultiply-accumulate operations (MACs). Extensive experiments on large-scale\nImageNet classification task show the proposed FFN only requires one-thousandth\nof multiply operations with comparable accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 10:26:41 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 09:46:41 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Wang", "Peisong", ""], ["Cheng", "Jian", ""]]}, {"id": "1611.01988", "submitter": "Marc Brockschmidt", "authors": "John K. Feser, Marc Brockschmidt, Alexander L. Gaunt, Daniel Tarlow", "title": "Differentiable Functional Program Interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by Example (PBE) is the task of inducing computer programs from\ninput-output examples. It can be seen as a type of machine learning where the\nhypothesis space is the set of legal programs in some programming language.\nRecent work on differentiable interpreters relaxes the discrete space of\nprograms into a continuous space so that search over programs can be performed\nusing gradient-based optimization. While conceptually powerful, so far\ndifferentiable interpreter-based program synthesis has only been capable of\nsolving very simple problems. In this work, we study modeling choices that\narise when constructing a differentiable programming language and their impact\non the success of synthesis. The main motivation for the modeling choices comes\nfrom functional programming: we study the effect of memory allocation schemes,\nimmutable data, type systems, and built-in control-flow structures. Empirically\nwe show that incorporating functional programming ideas into differentiable\nprogramming languages allows us to learn much more complex programs than is\npossible with existing differentiable languages.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 11:09:19 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 13:26:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Feser", "John K.", ""], ["Brockschmidt", "Marc", ""], ["Gaunt", "Alexander L.", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1611.01989", "submitter": "Marc Brockschmidt", "authors": "Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, Sebastian Nowozin,\n  Daniel Tarlow", "title": "DeepCoder: Learning to Write Programs", "comments": "Submitted to ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a first line of attack for solving programming competition-style\nproblems from input-output examples using deep learning. The approach is to\ntrain a neural network to predict properties of the program that generated the\noutputs from the inputs. We use the neural network's predictions to augment\nsearch techniques from the programming languages community, including\nenumerative search and an SMT-based solver. Empirically, we show that our\napproach leads to an order of magnitude speedup over the strong non-augmented\nbaselines and a Recurrent Neural Network approach, and that we are able to\nsolve problems of difficulty comparable to the simplest problems on programming\ncompetition websites.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 11:09:45 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 11:50:33 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Balog", "Matej", ""], ["Gaunt", "Alexander L.", ""], ["Brockschmidt", "Marc", ""], ["Nowozin", "Sebastian", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1611.02019", "submitter": "Mickael Chen", "authors": "Micka\\\"el Chen and Ludovic Denoyer", "title": "Multi-view Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-71246-8_11", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning over multi-view data is a challenging problem with strong practical\napplications. Most related studies focus on the classification point of view\nand assume that all the views are available at any time. We consider an\nextension of this framework in two directions. First, based on the BiGAN model,\nthe Multi-view BiGAN (MV-BiGAN) is able to perform density estimation from\nmulti-view inputs. Second, it can deal with missing views and is able to update\nits prediction when additional views are provided. We illustrate these\nproperties on a set of experiments over different datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:29:19 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 11:38:13 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Chen", "Micka\u00ebl", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1611.02041", "submitter": "Weihua Hu", "authors": "Weihua Hu, Gang Niu, Issei Sato, Masashi Sugiyama", "title": "Does Distributionally Robust Supervised Learning Give Robust\n  Classifiers?", "comments": "ICML 2018 camera-ready (final submission version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally Robust Supervised Learning (DRSL) is necessary for building\nreliable machine learning systems. When machine learning is deployed in the\nreal world, its performance can be significantly degraded because test data may\nfollow a different distribution from training data. DRSL with f-divergences\nexplicitly considers the worst-case distribution shift by minimizing the\nadversarially reweighted training loss. In this paper, we analyze this DRSL,\nfocusing on the classification scenario. Since the DRSL is explicitly\nformulated for a distribution shift scenario, we naturally expect it to give a\nrobust classifier that can aggressively handle shifted distributions. However,\nsurprisingly, we prove that the DRSL just ends up giving a classifier that\nexactly fits the given training distribution, which is too pessimistic. This\npessimism comes from two sources: the particular losses used in classification\nand the fact that the variety of distributions to which the DRSL tries to be\nrobust is too wide. Motivated by our analysis, we propose simple DRSL that\novercomes this pessimism and empirically demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 13:19:45 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 06:38:24 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 10:48:48 GMT"}, {"version": "v4", "created": "Mon, 12 Feb 2018 10:23:50 GMT"}, {"version": "v5", "created": "Thu, 7 Jun 2018 14:14:15 GMT"}, {"version": "v6", "created": "Sun, 22 Jul 2018 07:49:28 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Hu", "Weihua", ""], ["Niu", "Gang", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1611.02047", "submitter": "Andrey Filchenkov", "authors": "Ivan Smetannikov, Ilya Isaev, Andrey Filchenkov", "title": "Reinforcement Learning Approach for Parallelization in Filters\n  Aggregation Based Feature Selection Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the classical problems in machine learning and data mining is feature\nselection. A feature selection algorithm is expected to be quick, and at the\nsame time it should show high performance. MeLiF algorithm effectively solves\nthis problem using ensembles of ranking filters. This article describes two\ndifferent ways to improve MeLiF algorithm performance with parallelization.\nExperiments show that proposed schemes significantly improves algorithm\nperformance and increase feature selection quality.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 13:43:38 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Smetannikov", "Ivan", ""], ["Isaev", "Ilya", ""], ["Filchenkov", "Andrey", ""]]}, {"id": "1611.02053", "submitter": "Andrey Filchenkov", "authors": "Valeria Efimova, Andrey Filchenkov, Anatoly Shalyto", "title": "Reinforcement-based Simultaneous Algorithm and its Hyperparameters\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms for data analysis exist, especially for classification\nproblems. To solve a data analysis problem, a proper algorithm should be\nchosen, and also its hyperparameters should be selected. In this paper, we\npresent a new method for the simultaneous selection of an algorithm and its\nhyperparameters. In order to do so, we reduced this problem to the multi-armed\nbandit problem. We consider an algorithm as an arm and algorithm\nhyperparameters search during a fixed time as the corresponding arm play. We\nalso suggest a problem-specific reward function. We performed the experiments\non 10 real datasets and compare the suggested method with the existing one\nimplemented in Auto-WEKA. The results show that our method is significantly\nbetter in most of the cases and never worse than the Auto-WEKA.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 13:55:00 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Efimova", "Valeria", ""], ["Filchenkov", "Andrey", ""], ["Shalyto", "Anatoly", ""]]}, {"id": "1611.02101", "submitter": "Ilya Trofimov", "authors": "Ilya Trofimov, Alexander Genkin", "title": "Distributed Coordinate Descent for Generalized Linear Models with\n  Regularization", "comments": "fix typos. arXiv admin note: text overlap with arXiv:1411.6520", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized linear model with $L_1$ and $L_2$ regularization is a widely used\ntechnique for solving classification, class probability estimation and\nregression problems. With the numbers of both features and examples growing\nrapidly in the fields like text mining and clickstream data analysis\nparallelization and the use of cluster architectures becomes important. We\npresent a novel algorithm for fitting regularized generalized linear models in\nthe distributed environment. The algorithm splits data between nodes by\nfeatures, uses coordinate descent on each node and line search to merge results\nglobally. Convergence proof is provided. A modifications of the algorithm\naddresses slow node problem. For an important particular case of logistic\nregression we empirically compare our program with several state-of-the art\napproaches that rely on different algorithmic and data spitting methods.\nExperiments demonstrate that our approach is scalable and superior when\ntraining on large and sparse datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:19:54 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 13:35:23 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Trofimov", "Ilya", ""], ["Genkin", "Alexander", ""]]}, {"id": "1611.02109", "submitter": "Marc Brockschmidt", "authors": "Alexander L. Gaunt, Marc Brockschmidt, Nate Kushman, Daniel Tarlow", "title": "Differentiable Programs with Neural Libraries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for combining differentiable programming languages\nwith neural networks. Using this framework we create end-to-end trainable\nsystems that learn to write interpretable algorithms with perceptual\ncomponents. We explore the benefits of inductive biases for strong\ngeneralization and modularity that come from the program-like structure of our\nmodels. In particular, modularity allows us to learn a library of (neural)\nfunctions which grows and improves as more tasks are solved. Empirically, we\nshow that this leads to lifelong learning systems that transfer knowledge to\nnew tasks more effectively than baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:25:53 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 13:34:48 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Gaunt", "Alexander L.", ""], ["Brockschmidt", "Marc", ""], ["Kushman", "Nate", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1611.02120", "submitter": "Brett Meyer", "authors": "Sean C. Smithson and Guang Yang and Warren J. Gross and Brett H. Meyer", "title": "Neural Networks Designing Neural Networks: Multi-Objective\n  Hyper-Parameter Optimization", "comments": "To appear in ICCAD'16. The authoritative version will appear in the\n  ACM Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have gone through a recent rise in popularity,\nachieving state-of-the-art results in various fields, including image\nclassification, speech recognition, and automated control. Both the performance\nand computational complexity of such models are heavily dependant on the design\nof characteristic hyper-parameters (e.g., number of hidden layers, nodes per\nlayer, or choice of activation functions), which have traditionally been\noptimized manually. With machine learning penetrating low-power mobile and\nembedded areas, the need to optimize not only for performance (accuracy), but\nalso for implementation complexity, becomes paramount. In this work, we present\na multi-objective design space exploration method that reduces the number of\nsolution networks trained and evaluated through response surface modelling.\nGiven spaces which can easily exceed 1020 solutions, manually designing a\nnear-optimal architecture is unlikely as opportunities to reduce network\ncomplexity, while maintaining performance, may be overlooked. This problem is\nexacerbated by the fact that hyper-parameters which perform well on specific\ndatasets may yield sub-par results on others, and must therefore be designed on\na per-application basis. In our work, machine learning is leveraged by training\nan artificial neural network to predict the performance of future candidate\nnetworks. The method is evaluated on the MNIST and CIFAR-10 image datasets,\noptimizing for both recognition accuracy and computational complexity.\nExperimental results demonstrate that the proposed method can closely\napproximate the Pareto-optimal front, while only exploring a small fraction of\nthe design space.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:38:39 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Smithson", "Sean C.", ""], ["Yang", "Guang", ""], ["Gross", "Warren J.", ""], ["Meyer", "Brett H.", ""]]}, {"id": "1611.02163", "submitter": "Luke Metz", "authors": "Luke Metz, Ben Poole, David Pfau, Jascha Sohl-Dickstein", "title": "Unrolled Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to stabilize Generative Adversarial Networks (GANs) by\ndefining the generator objective with respect to an unrolled optimization of\nthe discriminator. This allows training to be adjusted between using the\noptimal discriminator in the generator's objective, which is ideal but\ninfeasible in practice, and using the current value of the discriminator, which\nis often unstable and leads to poor solutions. We show how this technique\nsolves the common problem of mode collapse, stabilizes training of GANs with\ncomplex recurrent generators, and increases diversity and coverage of the data\ndistribution by the generator.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 16:42:09 GMT"}, {"version": "v2", "created": "Sun, 15 Jan 2017 04:35:50 GMT"}, {"version": "v3", "created": "Tue, 31 Jan 2017 18:12:26 GMT"}, {"version": "v4", "created": "Fri, 12 May 2017 23:52:12 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Metz", "Luke", ""], ["Poole", "Ben", ""], ["Pfau", "David", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1611.02167", "submitter": "Otkrist Gupta", "authors": "Bowen Baker, Otkrist Gupta, Nikhil Naik and Ramesh Raskar", "title": "Designing Neural Network Architectures using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, designing convolutional neural network (CNN) architectures\nrequires both human expertise and labor. New architectures are handcrafted by\ncareful experimentation or modified from a handful of existing networks. We\nintroduce MetaQNN, a meta-modeling algorithm based on reinforcement learning to\nautomatically generate high-performing CNN architectures for a given learning\ntask. The learning agent is trained to sequentially choose CNN layers using\n$Q$-learning with an $\\epsilon$-greedy exploration strategy and experience\nreplay. The agent explores a large but finite space of possible architectures\nand iteratively discovers designs with improved performance on the learning\ntask. On image classification benchmarks, the agent-designed networks\n(consisting of only standard convolution, pooling, and fully-connected layers)\nbeat existing networks designed with the same layer types and are competitive\nagainst the state-of-the-art methods that use more complex layer types. We also\noutperform existing meta-modeling approaches for network design on image\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 16:49:43 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 20:26:41 GMT"}, {"version": "v3", "created": "Wed, 22 Mar 2017 20:08:30 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Baker", "Bowen", ""], ["Gupta", "Otkrist", ""], ["Naik", "Nikhil", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1611.02181", "submitter": "Wen Dong", "authors": "Zhen Xu, Wen Dong and Sargur Srihari", "title": "Using Social Dynamics to Make Individual Predictions: Variational\n  Inference with a Stochastic Kinetic Model", "comments": "In proceedings of 29th Conference on Neural Information Processing\n  Systems (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Social dynamics is concerned primarily with interactions among individuals\nand the resulting group behaviors, modeling the temporal evolution of social\nsystems via the interactions of individuals within these systems. In\nparticular, the availability of large-scale data from social networks and\nsensor networks offers an unprecedented opportunity to predict state-changing\nevents at the individual level. Examples of such events include disease\ntransmission, opinion transition in elections, and rumor propagation. Unlike\nprevious research focusing on the collective effects of social systems, this\nstudy makes efficient inferences at the individual level. In order to cope with\ndynamic interactions among a large number of individuals, we introduce the\nstochastic kinetic model to capture adaptive transition probabilities and\npropose an efficient variational inference algorithm the complexity of which\ngrows linearly --- rather than exponentially --- with the number of\nindividuals. To validate this method, we have performed epidemic-dynamics\nexperiments on wireless sensor network data collected from more than ten\nthousand people over three years. The proposed algorithm was used to track\ndisease transmission and predict the probability of infection for each\nindividual. Our results demonstrate that this method is more efficient than\nsampling while nonetheless achieving high accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 17:29:51 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Xu", "Zhen", ""], ["Dong", "Wen", ""], ["Srihari", "Sargur", ""]]}, {"id": "1611.02185", "submitter": "Leonard Berrada", "authors": "Leonard Berrada, Andrew Zisserman, M. Pawan Kumar", "title": "Trusting SVM for Piecewise Linear CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel layerwise optimization algorithm for the learning\nobjective of Piecewise-Linear Convolutional Neural Networks (PL-CNNs), a large\nclass of convolutional neural networks. Specifically, PL-CNNs employ piecewise\nlinear non-linearities such as the commonly used ReLU and max-pool, and an SVM\nclassifier as the final layer. The key observation of our approach is that the\nproblem corresponding to the parameter estimation of a layer can be formulated\nas a difference-of-convex (DC) program, which happens to be a latent structured\nSVM. We optimize the DC program using the concave-convex procedure, which\nrequires us to iteratively solve a structured SVM problem. This allows to\ndesign an optimization algorithm with an optimal learning rate that does not\nrequire any tuning. Using the MNIST, CIFAR and ImageNet data sets, we show that\nour approach always improves over the state of the art variants of\nbackpropagation and scales to large data and large network settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 17:41:20 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 23:54:26 GMT"}, {"version": "v3", "created": "Sat, 17 Dec 2016 09:19:58 GMT"}, {"version": "v4", "created": "Mon, 30 Jan 2017 16:42:22 GMT"}, {"version": "v5", "created": "Mon, 6 Mar 2017 16:21:35 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Berrada", "Leonard", ""], ["Zisserman", "Andrew", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1611.02189", "submitter": "Virginia Smith", "authors": "Virginia Smith, Simone Forte, Chenxin Ma, Martin Takac, Michael I.\n  Jordan, Martin Jaggi", "title": "CoCoA: A General Framework for Communication-Efficient Distributed\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of modern datasets necessitates the development of efficient\ndistributed optimization methods for machine learning. We present a\ngeneral-purpose framework for distributed computing environments, CoCoA, that\nhas an efficient communication scheme and is applicable to a wide variety of\nproblems in machine learning and signal processing. We extend the framework to\ncover general non-strongly-convex regularizers, including L1-regularized\nproblems like lasso, sparse logistic regression, and elastic net\nregularization, and show how earlier work can be derived as a special case. We\nprovide convergence guarantees for the class of convex regularized loss\nminimization objectives, leveraging a novel approach in handling\nnon-strongly-convex regularizers and non-smooth loss functions. The resulting\nframework has markedly improved performance over state-of-the-art methods, as\nwe illustrate with an extensive set of experiments on real distributed\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 17:49:49 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 00:23:51 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Smith", "Virginia", ""], ["Forte", "Simone", ""], ["Ma", "Chenxin", ""], ["Takac", "Martin", ""], ["Jordan", "Michael I.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1611.02205", "submitter": "Nadav Bhonker", "authors": "Nadav Bhonker, Shai Rozenberg and Itay Hubara", "title": "Playing SNES in the Retro Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mastering a video game requires skill, tactics and strategy. While these\nattributes may be acquired naturally by human players, teaching them to a\ncomputer program is a far more challenging task. In recent years, extensive\nresearch was carried out in the field of reinforcement learning and numerous\nalgorithms were introduced, aiming to learn how to perform human tasks such as\nplaying video games. As a result, the Arcade Learning Environment (ALE)\n(Bellemare et al., 2013) has become a commonly used benchmark environment\nallowing algorithms to train on various Atari 2600 games. In many games the\nstate-of-the-art algorithms outperform humans. In this paper we introduce a new\nlearning environment, the Retro Learning Environment --- RLE, that can run\ngames on the Super Nintendo Entertainment System (SNES), Sega Genesis and\nseveral other gaming consoles. The environment is expandable, allowing for more\nvideo games and consoles to be easily added to the environment, while\nmaintaining the same interface as ALE. Moreover, RLE is compatible with Python\nand Torch. SNES games pose a significant challenge to current algorithms due to\ntheir higher level of complexity and versatility.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 18:33:38 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 18:50:50 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Bhonker", "Nadav", ""], ["Rozenberg", "Shai", ""], ["Hubara", "Itay", ""]]}, {"id": "1611.02221", "submitter": "Amit Moscovich", "authors": "Amit Moscovich, Ariel Jaffe, Boaz Nadler", "title": "Minimax-optimal semi-supervised regression on unknown manifolds", "comments": null, "journal-ref": "Proceedings of the 20th International Conference on Artificial\n  Intelligence and Statistics, PMLR 54 (2017) 933-942", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider semi-supervised regression when the predictor variables are drawn\nfrom an unknown manifold. A simple two step approach to this problem is to: (i)\nestimate the manifold geodesic distance between any pair of points using both\nthe labeled and unlabeled instances; and (ii) apply a k nearest neighbor\nregressor based on these distance estimates. We prove that given sufficiently\nmany unlabeled points, this simple method of geodesic kNN regression achieves\nthe optimal finite-sample minimax bound on the mean squared error, as if the\nmanifold were known. Furthermore, we show how this approach can be efficiently\nimplemented, requiring only O(k N log N) operations to estimate the regression\nfunction at all N labeled and unlabeled points. We illustrate this approach on\ntwo datasets with a manifold structure: indoor localization using WiFi\nfingerprints and facial pose estimation. In both cases, geodesic kNN is more\naccurate and much faster than the popular Laplacian eigenvector regressor.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 19:26:15 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 19:13:07 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Moscovich", "Amit", ""], ["Jaffe", "Ariel", ""], ["Nadler", "Boaz", ""]]}, {"id": "1611.02247", "submitter": "Shixiang Gu", "authors": "Shixiang Gu and Timothy Lillicrap and Zoubin Ghahramani and Richard E.\n  Turner and Sergey Levine", "title": "Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic", "comments": "Conference Paper at the International Conference on Learning\n  Representations (ICLR) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) methods have been successful in a\nwide variety of simulated domains. However, a major obstacle facing deep RL in\nthe real world is their high sample complexity. Batch policy gradient methods\noffer stable learning, but at the cost of high variance, which often requires\nlarge batches. TD-style methods, such as off-policy actor-critic and\nQ-learning, are more sample-efficient but biased, and often require costly\nhyperparameter sweeps to stabilize. In this work, we aim to develop methods\nthat combine the stability of policy gradients with the efficiency of\noff-policy RL. We present Q-Prop, a policy gradient method that uses a Taylor\nexpansion of the off-policy critic as a control variate. Q-Prop is both sample\nefficient and stable, and effectively combines the benefits of on-policy and\noff-policy methods. We analyze the connection between Q-Prop and existing\nmodel-free algorithms, and use control variate theory to derive two variants of\nQ-Prop with conservative and aggressive adaptation. We show that conservative\nQ-Prop provides substantial gains in sample efficiency over trust region policy\noptimization (TRPO) with generalized advantage estimation (GAE), and improves\nstability over deep deterministic policy gradient (DDPG), the state-of-the-art\non-policy and off-policy methods, on OpenAI Gym's MuJoCo continuous control\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:09:16 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 21:57:19 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 21:48:25 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Gu", "Shixiang", ""], ["Lillicrap", "Timothy", ""], ["Ghahramani", "Zoubin", ""], ["Turner", "Richard E.", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.02252", "submitter": "Miguel L\\'azaro-Gredilla", "authors": "Miguel L\\'azaro-Gredilla, Yi Liu, D. Scott Phoenix, Dileep George", "title": "Hierarchical compositional feature learning", "comments": "Removed the \"under review\" header from every page, no changes to\n  content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the hierarchical compositional network (HCN), a directed\ngenerative model able to discover and disentangle, without supervision, the\nbuilding blocks of a set of binary images. The building blocks are binary\nfeatures defined hierarchically as a composition of some of the features in the\nlayer immediately below, arranged in a particular manner. At a high level, HCN\nis similar to a sigmoid belief network with pooling. Inference and learning in\nHCN are very challenging and existing variational approximations do not work\nsatisfactorily. A main contribution of this work is to show that both can be\naddressed using max-product message passing (MPMP) with a particular schedule\n(no EM required). Also, using MPMP as an inference engine for HCN makes new\ntasks simple: adding supervision information, classifying images, or performing\ninpainting all correspond to clamping some variables of the model to their\nknown values and running MPMP on the rest. When used for classification, fast\ninference with HCN has exactly the same functional form as a convolutional\nneural network (CNN) with linear activations and binary weights. However, HCN's\nfeatures are qualitatively very different.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:25:08 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 01:23:40 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["L\u00e1zaro-Gredilla", "Miguel", ""], ["Liu", "Yi", ""], ["Phoenix", "D. Scott", ""], ["George", "Dileep", ""]]}, {"id": "1611.02258", "submitter": "Roy Adams Roy Adams", "authors": "Roy J. Adams, Benjamin M. Marlin", "title": "Learning Time Series Detection Models from Temporally Imprecise Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a new low-quality label learning problem: learning\ntime series detection models from temporally imprecise labels. In this problem,\nthe data consist of a set of input time series, and supervision is provided by\na sequence of noisy time stamps corresponding to the occurrence of positive\nclass events. Such temporally imprecise labels commonly occur in areas like\nmobile health research where human annotators are tasked with labeling the\noccurrence of very short duration events. We propose a general learning\nframework for this problem that can accommodate different base classifiers and\nnoise models. We present results on real mobile health data showing that the\nproposed framework significantly outperforms a number of alternatives including\nassuming that the label time stamps are noise-free, transforming the problem\ninto the multiple instance learning framework, and learning on labels that were\nmanually re-aligned.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:36:56 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 17:36:23 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Adams", "Roy J.", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "1611.02261", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Abdel-rahman Mohamed, Margaret Mitchell, Sing Bing\n  Kang, Pushmeet Kohli", "title": "Memory-augmented Attention Modelling for Videos", "comments": "Revised version, minor changes, add the link for the source codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to improve video description generation by modeling\nhigher-order interactions between video frames and described concepts. By\nstoring past visual attention in the video associated to previously generated\nwords, the system is able to decide what to look at and describe in light of\nwhat it has already looked at and described. This enables not only more\neffective local attention, but tractable consideration of the video sequence\nwhile generating each word. Evaluation on the challenging and popular MSVD and\nCharades datasets demonstrates that the proposed architecture outperforms\nprevious video description approaches without requiring external temporal video\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:50:08 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 22:39:13 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 02:22:51 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 07:26:01 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Fakoor", "Rasool", ""], ["Mohamed", "Abdel-rahman", ""], ["Mitchell", "Margaret", ""], ["Kang", "Sing Bing", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1611.02266", "submitter": "Ryota Tomioka", "authors": "Liwen Zhang and John Winn and Ryota Tomioka", "title": "Gaussian Attention Model and Its Application to Knowledge Base Embedding\n  and Question Answering", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Gaussian attention model for content-based neural memory\naccess. With the proposed attention model, a neural network has the additional\ndegree of freedom to control the focus of its attention from a laser sharp\nattention to a broad attention. It is applicable whenever we can assume that\nthe distance in the latent space reflects some notion of semantics. We use the\nproposed attention model as a scoring function for the embedding of a knowledge\nbase into a continuous vector space and then train a model that performs\nquestion answering about the entities in the knowledge base. The proposed\nattention model can handle both the propagation of uncertainty when following a\nseries of relations and also the conjunction of conditions in a natural way. On\na dataset of soccer players who participated in the FIFA World Cup 2014, we\ndemonstrate that our model can handle both path queries and conjunctive queries\nwell.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:57:24 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 16:44:17 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Zhang", "Liwen", ""], ["Winn", "John", ""], ["Tomioka", "Ryota", ""]]}, {"id": "1611.02268", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "Optimal Binary Autoencoding with Pairwise Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate learning of a binary autoencoder as a biconvex optimization\nproblem which learns from the pairwise correlations between encoded and decoded\nbits. Among all possible algorithms that use this information, ours finds the\nautoencoder that reconstructs its inputs with worst-case optimal loss. The\noptimal decoder is a single layer of artificial neurons, emerging entirely from\nthe minimax loss minimization, and with weights learned by convex optimization.\nAll this is reflected in competitive experimental results, demonstrating that\nbinary autoencoding can be done efficiently by conveying information in\npairwise correlations in an optimal fashion.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:58:58 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "1611.02305", "submitter": "Xinran He", "authors": "Xinran He, Ke Xu, David Kempe and Yan Liu", "title": "Learning Influence Functions from Incomplete Observations", "comments": "Full version of paper \"Learning Influence Functions from Incomplete\n  Observations\" in NIPS16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning influence functions under incomplete\nobservations of node activations. Incomplete observations are a major concern\nas most (online and real-world) social networks are not fully observable. We\nestablish both proper and improper PAC learnability of influence functions\nunder randomly missing observations. Proper PAC learnability under the\nDiscrete-Time Linear Threshold (DLT) and Discrete-Time Independent Cascade\n(DIC) models is established by reducing incomplete observations to complete\nobservations in a modified graph. Our improper PAC learnability result applies\nfor the DLT and DIC models as well as the Continuous-Time Independent Cascade\n(CIC) model. It is based on a parametrization in terms of reachability\nfeatures, and also gives rise to an efficient and practical heuristic.\nExperiments on synthetic and real-world datasets demonstrate the ability of our\nmethod to compensate even for a fairly large fraction of missing observations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 21:28:40 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["He", "Xinran", ""], ["Xu", "Ke", ""], ["Kempe", "David", ""], ["Liu", "Yan", ""]]}, {"id": "1611.02315", "submitter": "Jacob Steinhardt", "authors": "Moses Charikar and Jacob Steinhardt and Gregory Valiant", "title": "Learning from Untrusted Data", "comments": "Updated based on STOC camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of theoretical results in machine learning and statistics\nassume that the available training data is a reasonably reliable reflection of\nthe phenomena to be learned or estimated. Similarly, the majority of machine\nlearning and statistical techniques used in practice are brittle to the\npresence of large amounts of biased or malicious data. In this work we consider\ntwo frameworks in which to study estimation, learning, and optimization in the\npresence of significant fractions of arbitrary data.\n  The first framework, list-decodable learning, asks whether it is possible to\nreturn a list of answers, with the guarantee that at least one of them is\naccurate. For example, given a dataset of $n$ points for which an unknown\nsubset of $\\alpha n$ points are drawn from a distribution of interest, and no\nassumptions are made about the remaining $(1-\\alpha)n$ points, is it possible\nto return a list of $\\operatorname{poly}(1/\\alpha)$ answers, one of which is\ncorrect? The second framework, which we term the semi-verified learning model,\nconsiders the extent to which a small dataset of trusted data (drawn from the\ndistribution in question) can be leveraged to enable the accurate extraction of\ninformation from a much larger but untrusted dataset (of which only an\n$\\alpha$-fraction is drawn from the distribution).\n  We show strong positive results in both settings, and provide an algorithm\nfor robust learning in a very general stochastic optimization setting. This\ngeneral result has immediate implications for robust estimation in a number of\nsettings, including for robustly estimating the mean of distributions with\nbounded second moments, robustly learning mixtures of such distributions, and\nrobustly finding planted partitions in random graphs in which significant\nportions of the graph have been perturbed by an adversary.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 21:43:39 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 17:48:31 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Charikar", "Moses", ""], ["Steinhardt", "Jacob", ""], ["Valiant", "Gregory", ""]]}, {"id": "1611.02320", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas Molano, Alberto Albiol Colomer, Roberto Paredes\n  Palacios", "title": "Adversarial Ladder Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of unsupervised data in addition to supervised data in training\ndiscriminative neural networks has improved the performance of this clas-\nsification scheme. However, the best results were achieved with a training\nprocess that is divided in two parts: first an unsupervised pre-training step\nis done for initializing the weights of the network and after these weights are\nrefined with the use of supervised data. On the other hand adversarial noise\nhas improved the results of clas- sical supervised learning. Recently, a new\nneural network topology called Ladder Network, where the key idea is based in\nsome properties of hierar- chichal latent variable models, has been proposed as\na technique to train a neural network using supervised and unsupervised data at\nthe same time with what is called semi-supervised learning. This technique has\nreached state of the art classification. In this work we add adversarial noise\nto the ladder network and get state of the art classification, with several\nimportant conclusions on how adversarial noise can help in addition with new\npossible lines of investi- gation. We also propose an alternative to add\nadversarial noise to unsu- pervised data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 22:03:43 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 15:22:31 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 08:16:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Molano", "Juan Maro\u00f1as", ""], ["Colomer", "Alberto Albiol", ""], ["Palacios", "Roberto Paredes", ""]]}, {"id": "1611.02345", "submitter": "David Balduzzi", "authors": "David Balduzzi, Brian McWilliams, Tony Butler-Yeoman", "title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier\n  Networks", "comments": "ICML 2017, final version", "journal-ref": "PMLR volume 70, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern convolutional networks, incorporating rectifiers and max-pooling, are\nneither smooth nor convex; standard guarantees therefore do not apply.\nNevertheless, methods from convex optimization such as gradient descent and\nAdam are widely used as building blocks for deep learning algorithms. This\npaper provides the first convergence guarantee applicable to modern convnets,\nwhich furthermore matches a lower bound for convex nonsmooth functions. The key\ntechnical tool is the neural Taylor approximation -- a straightforward\napplication of Taylor expansions to neural networks -- and the associated\nTaylor loss. Experiments on a range of optimizers, layers, and tasks provide\nevidence that the analysis accurately captures the dynamics of neural\noptimization. The second half of the paper applies the Taylor approximation to\nisolate the main difficulty in training rectifier nets -- that gradients are\nshattered -- and investigates the hypothesis that, by exploring the space of\nactivation configurations more thoroughly, adaptive optimizers such as RMSProp\nand Adam are able to converge to better solutions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 23:47:05 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 02:26:15 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 12:41:26 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""], ["McWilliams", "Brian", ""], ["Butler-Yeoman", "Tony", ""]]}, {"id": "1611.02365", "submitter": "Christopher Xie", "authors": "Christopher Xie, Avleen Bijral, Juan Lavista Ferres", "title": "NonSTOP: A NonSTationary Online Prediction Method for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present online prediction methods for time series that let us explicitly\nhandle nonstationary artifacts (e.g. trend and seasonality) present in most\nreal time series. Specifically, we show that applying appropriate\ntransformations to such time series before prediction can lead to improved\ntheoretical and empirical prediction performance. Moreover, since these\ntransformations are usually unknown, we employ the learning with experts\nsetting to develop a fully online method (NonSTOP-NonSTationary Online\nPrediction) for predicting nonstationary time series. This framework allows for\nseasonality and/or other trends in univariate time series and cointegration in\nmultivariate time series. Our algorithms and regret analysis subsume recent\nrelated work while significantly expanding the applicability of such methods.\nFor all the methods, we provide sub-linear regret bounds using relaxed\nassumptions. The theoretical guarantees do not fully capture the benefits of\nthe transformations, thus we provide a data-dependent analysis of the\nfollow-the-leader algorithm that provides insight into the success of using\nsuch transformations. We support all of our results with experiments on\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 02:20:46 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 23:10:15 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 07:35:16 GMT"}, {"version": "v4", "created": "Sun, 26 Aug 2018 19:23:06 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Xie", "Christopher", ""], ["Bijral", "Avleen", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "1611.02401", "submitter": "Joan Bruna", "authors": "Alex Nowak-Vila, David Folqu\\'e and Joan Bruna", "title": "Divide and Conquer Networks", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the learning of algorithmic tasks by mere observation of\ninput-output pairs. Rather than studying this as a black-box discrete\nregression problem with no assumption whatsoever on the input-output mapping,\nwe concentrate on tasks that are amenable to the principle of divide and\nconquer, and study what are its implications in terms of learning. This\nprinciple creates a powerful inductive bias that we leverage with neural\narchitectures that are defined recursively and dynamically, by learning two\nscale-invariant atomic operations: how to split a given input into smaller\nsets, and how to merge two partially solved tasks into a larger partial\nsolution. Our model can be trained in weakly supervised environments, namely by\njust observing input-output pairs, and in even weaker environments, using a\nnon-differentiable reward signal. Moreover, thanks to the dynamic aspect of our\narchitecture, we can incorporate the computational complexity as a\nregularization term that can be optimized by backpropagation. We demonstrate\nthe flexibility and efficiency of the Divide-and-Conquer Network on several\ncombinatorial and geometric tasks: convex hull, clustering, knapsack and\neuclidean TSP. Thanks to the dynamic programming nature of our model, we show\nsignificant improvements in terms of generalization error and computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 06:07:25 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 01:58:20 GMT"}, {"version": "v3", "created": "Sun, 13 Nov 2016 05:25:00 GMT"}, {"version": "v4", "created": "Sat, 27 May 2017 12:01:13 GMT"}, {"version": "v5", "created": "Wed, 31 May 2017 04:57:49 GMT"}, {"version": "v6", "created": "Tue, 22 May 2018 20:47:33 GMT"}, {"version": "v7", "created": "Sun, 14 Oct 2018 18:11:39 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Nowak-Vila", "Alex", ""], ["Folqu\u00e9", "David", ""], ["Bruna", "Joan", ""]]}, {"id": "1611.02416", "submitter": "Seongsik Park", "authors": "Seongsik Park, Sang-gil Lee, Hyunha Nam, Sungroh Yoon", "title": "An Efficient Approach to Boosting Performance of Deep Spiking Network\n  Training", "comments": "NIPS 2016 - Workshop on Computing with Spikes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays deep learning is dominating the field of machine learning with\nstate-of-the-art performance in various application areas. Recently, spiking\nneural networks (SNNs) have been attracting a great deal of attention, notably\nowning to their power efficiency, which can potentially allow us to implement a\nlow-power deep learning engine suitable for real-time/mobile applications.\nHowever, implementing SNN-based deep learning remains challenging, especially\ngradient-based training of SNNs by error backpropagation. We cannot simply\npropagate errors through SNNs in conventional way because of the property of\nSNNs that process discrete data in the form of a series. Consequently, most of\nthe previous studies employ a workaround technique, which first trains a\nconventional weighted-sum deep neural network and then maps the learning\nweights to the SNN under training, instead of training SNN parameters directly.\nIn order to eliminate this workaround, recently proposed is a new class of SNN\nnamed deep spiking networks (DSNs), which can be trained directly (without a\nmapping from conventional deep networks) by error backpropagation with\nstochastic gradient descent. In this paper, we show that the initialization of\nthe membrane potential on the backward path is an important step in DSN\ntraining, through diverse experiments performed under various conditions.\nFurthermore, we propose a simple and efficient method that can improve DSN\ntraining by controlling the initial membrane potential on the backward path. In\nour experiments, adopting the proposed approach allowed us to boost the\nperformance of DSN training in terms of converging time and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 07:41:54 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 09:24:09 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Park", "Seongsik", ""], ["Lee", "Sang-gil", ""], ["Nam", "Hyunha", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.02443", "submitter": "Toru Tamaki", "authors": "Toru Tamaki, Shoji Sonoyama, Takio Kurita, Tsubasa Hirakawa, Bisser\n  Raytchev, Kazufumi Kaneda, Tetsushi Koide, Shigeto Yoshida, Hiroshi Mieno,\n  Shinji Tanaka, Kazuaki Chayama", "title": "Domain Adaptation with L2 constraints for classifying images from\n  different endoscope systems", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for domain adaptation that extends the maximum\nmargin domain transfer (MMDT) proposed by Hoffman et al., by introducing L2\ndistance constraints between samples of different domains; thus, our method is\ndenoted as MMDTL2. Motivated by the differences between the images taken by\nnarrow band imaging (NBI) endoscopic devices, we utilize different NBI devices\nas different domains and estimate the transformations between samples of\ndifferent domains, i.e., image samples taken by different NBI endoscope\nsystems. We first formulate the problem in the primal form, and then derive the\ndual form with much lesser computational costs as compared to the naive\napproach. From our experimental results using NBI image datasets from two\ndifferent NBI endoscopic devices, we find that MMDTL2 is better than MMDT and\nalso support vector machines without adaptation, especially when NBI image\nfeatures are high-dimensional and the per-class training samples are greater\nthan 20.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 09:29:17 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 09:01:20 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Tamaki", "Toru", ""], ["Sonoyama", "Shoji", ""], ["Kurita", "Takio", ""], ["Hirakawa", "Tsubasa", ""], ["Raytchev", "Bisser", ""], ["Kaneda", "Kazufumi", ""], ["Koide", "Tetsushi", ""], ["Yoshida", "Shigeto", ""], ["Mieno", "Hiroshi", ""], ["Tanaka", "Shinji", ""], ["Chayama", "Kazuaki", ""]]}, {"id": "1611.02512", "submitter": "Wen-Chieh Fang", "authors": "Wen-Chieh Fang and Yi-ting Chiang", "title": "Cognitive Discriminative Mappings for Rapid Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn concepts or recognize items from just a handful of examples,\nwhile machines require many more samples to perform the same task. In this\npaper, we build a computational model to investigate the possibility of this\nkind of rapid learning. The proposed method aims to improve the learning task\nof input from sensory memory by leveraging the information retrieved from\nlong-term memory. We present a simple and intuitive technique called cognitive\ndiscriminative mappings (CDM) to explore the cognitive problem. First, CDM\nseparates and clusters the data instances retrieved from long-term memory into\ndistinct classes with a discrimination method in working memory when a sensory\ninput triggers the algorithm. CDM then maps each sensory data instance to be as\nclose as possible to the median point of the data group with the same class.\nThe experimental results demonstrate that the CDM approach is effective for\nlearning the discriminative features of supervised classifications with few\ntraining sensory input instances.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 13:26:32 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Fang", "Wen-Chieh", ""], ["Chiang", "Yi-ting", ""]]}, {"id": "1611.02568", "submitter": "Jaegul Choo", "authors": "Minjeong Kim, Minsuk Choi, Sunwoong Lee, Jian Tang, Haesun Park,\n  Jaegul Choo", "title": "PixelSNE: Visualizing Fast with Just Enough Precision via Pixel-Aligned\n  Stochastic Neighbor Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding and visualizing large-scale high-dimensional data in a\ntwo-dimensional space is an important problem since such visualization can\nreveal deep insights out of complex data. Most of the existing embedding\napproaches, however, run on an excessively high precision, ignoring the fact\nthat at the end, embedding outputs are converted into coarse-grained discrete\npixel coordinates in a screen space. Motivated by such an observation and\ndirectly considering pixel coordinates in an embedding optimization process, we\naccelerate Barnes-Hut tree-based t-distributed stochastic neighbor embedding\n(BH-SNE), known as a state-of-the-art 2D embedding method, and propose a novel\nmethod called PixelSNE, a highly-efficient, screen resolution-driven 2D\nembedding method with a linear computational complexity in terms of the number\nof data items. Our experimental results show the significantly fast running\ntime of PixelSNE by a large margin against BH-SNE, while maintaining the\nminimal degradation in the embedding quality. Finally, the source code of our\nmethod is publicly available at https://github.com/awesome-davian/PixelSNE\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 15:50:27 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 03:28:39 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 06:28:34 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Kim", "Minjeong", ""], ["Choi", "Minsuk", ""], ["Lee", "Sunwoong", ""], ["Tang", "Jian", ""], ["Park", "Haesun", ""], ["Choo", "Jaegul", ""]]}, {"id": "1611.02639", "submitter": "Ankur Taly", "authors": "Mukund Sundararajan, Ankur Taly, Qiqi Yan", "title": "Gradients of Counterfactuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradients have been used to quantify feature importance in machine learning\nmodels. Unfortunately, in nonlinear deep networks, not only individual neurons\nbut also the whole network can saturate, and as a result an important input\nfeature can have a tiny gradient. We study various networks, and observe that\nthis phenomena is indeed widespread, across many inputs.\n  We propose to examine interior gradients, which are gradients of\ncounterfactual inputs constructed by scaling down the original input. We apply\nour method to the GoogleNet architecture for object recognition in images, as\nwell as a ligand-based virtual screening network with categorical features and\nan LSTM based language model for the Penn Treebank dataset. We visualize how\ninterior gradients better capture feature importance. Furthermore, interior\ngradients are applicable to a wide variety of deep networks, and have the\nattribution property that the feature importance scores sum to the the\nprediction score.\n  Best of all, interior gradients can be computed just as easily as gradients.\nIn contrast, previous methods are complex to implement, which hinders practical\nadoption.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 18:10:44 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 19:55:26 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Sundararajan", "Mukund", ""], ["Taly", "Ankur", ""], ["Yan", "Qiqi", ""]]}, {"id": "1611.02648", "submitter": "Nat Dilokthanakul", "authors": "Nat Dilokthanakul, Pedro A.M. Mediano, Marta Garnelo, Matthew C.H.\n  Lee, Hugh Salimbeni, Kai Arulkumaran, Murray Shanahan", "title": "Deep Unsupervised Clustering with Gaussian Mixture Variational\n  Autoencoders", "comments": "12 pages, 6 figures, Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the variational autoencoder model (VAE) with a Gaussian\nmixture as a prior distribution, with the goal of performing unsupervised\nclustering through deep generative models. We observe that the known problem of\nover-regularisation that has been shown to arise in regular VAEs also manifests\nitself in our model and leads to cluster degeneracy. We show that a heuristic\ncalled minimum information constraint that has been shown to mitigate this\neffect in VAEs can also be applied to improve unsupervised clustering\nperformance with our model. Furthermore we analyse the effect of this heuristic\nand provide an intuition of the various processes with the help of\nvisualizations. Finally, we demonstrate the performance of our model on\nsynthetic data, MNIST and SVHN, showing that the obtained clusters are\ndistinct, interpretable and result in achieving competitive performance on\nunsupervised clustering to the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 18:36:36 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 17:53:10 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Dilokthanakul", "Nat", ""], ["Mediano", "Pedro A. M.", ""], ["Garnelo", "Marta", ""], ["Lee", "Matthew C. H.", ""], ["Salimbeni", "Hugh", ""], ["Arulkumaran", "Kai", ""], ["Shanahan", "Murray", ""]]}, {"id": "1611.02654", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee, Dragomir Radev", "title": "Sentence Ordering and Coherence Modeling using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the structure of coherent texts is a key NLP problem. The task of\ncoherently organizing a given set of sentences has been commonly used to build\nand evaluate models that understand such structure. We propose an end-to-end\nunsupervised deep learning approach based on the set-to-sequence framework to\naddress this problem. Our model strongly outperforms prior methods in the order\ndiscrimination task and a novel task of ordering abstracts from scientific\narticles. Furthermore, our work shows that useful text representations can be\nobtained by learning to order sentences. Visualizing the learned sentence\nrepresentations shows that the model captures high-level logical structure in\nparagraphs. Our representations perform comparably to state-of-the-art\npre-training methods on sentence similarity and paraphrase detection tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 19:04:09 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 02:36:08 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""], ["Radev", "Dragomir", ""]]}, {"id": "1611.02683", "submitter": "Prajit Ramachandran", "authors": "Prajit Ramachandran, Peter J. Liu, Quoc V. Le", "title": "Unsupervised Pretraining for Sequence to Sequence Learning", "comments": "Updated to accepted EMNLP 2017 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a general unsupervised learning method to improve the\naccuracy of sequence to sequence (seq2seq) models. In our method, the weights\nof the encoder and decoder of a seq2seq model are initialized with the\npretrained weights of two language models and then fine-tuned with labeled\ndata. We apply this method to challenging benchmarks in machine translation and\nabstractive summarization and find that it significantly improves the\nsubsequent supervised models. Our main result is that pretraining improves the\ngeneralization of seq2seq models. We achieve state-of-the art results on the\nWMT English$\\rightarrow$German task, surpassing a range of methods using both\nphrase-based machine translation and neural machine translation. Our method\nachieves a significant improvement of 1.3 BLEU from the previous best models on\nboth WMT'14 and WMT'15 English$\\rightarrow$German. We also conduct human\nevaluations on abstractive summarization and find that our method outperforms a\npurely supervised learning baseline in a statistically significant manner.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 20:42:26 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 01:57:27 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ramachandran", "Prajit", ""], ["Liu", "Peter J.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1611.02731", "submitter": "Xi Chen", "authors": "Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla\n  Dhariwal, John Schulman, Ilya Sutskever, Pieter Abbeel", "title": "Variational Lossy Autoencoder", "comments": "Added CIFAR10 experiments; ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning seeks to expose certain aspects of observed data in a\nlearned representation that's amenable to downstream tasks like classification.\nFor instance, a good representation for 2D images might be one that describes\nonly global structure and discards information about detailed texture. In this\npaper, we present a simple but principled method to learn such global\nrepresentations by combining Variational Autoencoder (VAE) with neural\nautoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE\nmodel allows us to have control over what the global latent code can learn and\n, by designing the architecture accordingly, we can force the global latent\ncode to discard irrelevant information such as texture in 2D images, and hence\nthe VAE only \"autoencodes\" data in a lossy fashion. In addition, by leveraging\nautoregressive models as both prior distribution $p(z)$ and decoding\ndistribution $p(x|z)$, we can greatly improve generative modeling performance\nof VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and\nCaltech-101 Silhouettes density estimation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 21:43:34 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 06:19:22 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Chen", "Xi", ""], ["Kingma", "Diederik P.", ""], ["Salimans", "Tim", ""], ["Duan", "Yan", ""], ["Dhariwal", "Prafulla", ""], ["Schulman", "John", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1611.02739", "submitter": "Vicen\\c{c} Rubies Royo", "authors": "Vicen\\c{c} Rubies-Royo, Claire Tomlin", "title": "Recursive Regression with Neural Networks: Approximating the HJI PDE\n  Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of methods used to compute approximations to the\nHamilton-Jacobi-Isaacs partial differential equation (HJI PDE) rely on the\ndiscretization of the state space to perform dynamic programming updates. This\ntype of approach is known to suffer from the curse of dimensionality due to the\nexponential growth in grid points with the state dimension. In this work we\npresent an approximate dynamic programming algorithm that computes an\napproximation of the solution of the HJI PDE by alternating between solving a\nregression problem and solving a minimax problem using a feedforward neural\nnetwork as the function approximator. We find that this method requires less\nmemory to run and to store the approximation than traditional gridding methods,\nand we test it on a few systems of two, three and six dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 22:09:22 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 08:50:30 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2017 00:05:30 GMT"}, {"version": "v4", "created": "Thu, 23 Mar 2017 18:40:46 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Rubies-Royo", "Vicen\u00e7", ""], ["Tomlin", "Claire", ""]]}, {"id": "1611.02755", "submitter": "Abram Friesen", "authors": "Abram L. Friesen and Pedro Domingos", "title": "Recursive Decomposition for Nonconvex Optimization", "comments": "11 pages, 7 figures, pdflatex", "journal-ref": "Proceedings of the 24th International Joint Conference on\n  Artificial Intelligence (2015), pp. 253-259", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous optimization is an important problem in many areas of AI,\nincluding vision, robotics, probabilistic inference, and machine learning.\nUnfortunately, most real-world optimization problems are nonconvex, causing\nstandard convex techniques to find only local optima, even with extensions like\nrandom restarts and simulated annealing. We observe that, in many cases, the\nlocal modes of the objective function have combinatorial structure, and thus\nideas from combinatorial optimization can be brought to bear. Based on this, we\npropose a problem-decomposition approach to nonconvex optimization. Similarly\nto DPLL-style SAT solvers and recursive conditioning in probabilistic\ninference, our algorithm, RDIS, recursively sets variables so as to simplify\nand decompose the objective function into approximately independent\nsub-functions, until the remaining functions are simple enough to be optimized\nby standard techniques like gradient descent. The variables to set are chosen\nby graph partitioning, ensuring decomposition whenever possible. We show\nanalytically that RDIS can solve a broad class of nonconvex optimization\nproblems exponentially faster than gradient descent with random restarts.\nExperimentally, RDIS outperforms standard techniques on problems like structure\nfrom motion and protein folding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 22:52:08 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Friesen", "Abram L.", ""], ["Domingos", "Pedro", ""]]}, {"id": "1611.02770", "submitter": "Xinyun Chen", "authors": "Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song", "title": "Delving into Transferable Adversarial Examples and Black-box Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intriguing property of deep neural networks is the existence of\nadversarial examples, which can transfer among different architectures. These\ntransferable adversarial examples may severely hinder deep neural network-based\napplications. Previous works mostly study the transferability using small scale\ndatasets. In this work, we are the first to conduct an extensive study of the\ntransferability over large models and a large scale dataset, and we are also\nthe first to study the transferability of targeted adversarial examples with\ntheir target labels. We study both non-targeted and targeted adversarial\nexamples, and show that while transferable non-targeted adversarial examples\nare easy to find, targeted adversarial examples generated using existing\napproaches almost never transfer with their target labels. Therefore, we\npropose novel ensemble-based approaches to generating transferable adversarial\nexamples. Using such approaches, we observe a large proportion of targeted\nadversarial examples that are able to transfer with their target labels for the\nfirst time. We also present some geometric studies to help understanding the\ntransferable adversarial examples. Finally, we show that the adversarial\nexamples generated using ensemble-based approaches can successfully attack\nClarifai.com, which is a black-box image classification system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 23:25:00 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 22:28:51 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 14:24:44 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Liu", "Yanpei", ""], ["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Song", "Dawn", ""]]}, {"id": "1611.02779", "submitter": "Yan Duan", "authors": "Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever,\n  Pieter Abbeel", "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning", "comments": "14 pages. Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has been successful in learning\nsophisticated behaviors automatically; however, the learning process requires a\nhuge number of trials. In contrast, animals can learn new tasks in just a few\ntrials, benefiting from their prior knowledge about the world. This paper seeks\nto bridge this gap. Rather than designing a \"fast\" reinforcement learning\nalgorithm, we propose to represent it as a recurrent neural network (RNN) and\nlearn it from data. In our proposed method, RL$^2$, the algorithm is encoded in\nthe weights of the RNN, which are learned slowly through a general-purpose\n(\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm\nwould receive, including observations, actions, rewards, and termination flags;\nand it retains its state across episodes in a given Markov Decision Process\n(MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on\nthe current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both\nsmall-scale and large-scale problems. On the small-scale side, we train it to\nsolve randomly generated multi-arm bandit problems and finite MDPs. After\nRL$^2$ is trained, its performance on new MDPs is close to human-designed\nalgorithms with optimality guarantees. On the large-scale side, we test RL$^2$\non a vision-based navigation task and show that it scales up to\nhigh-dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 00:13:29 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 01:17:36 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Duan", "Yan", ""], ["Schulman", "John", ""], ["Chen", "Xi", ""], ["Bartlett", "Peter L.", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1611.02796", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Shixiang Gu, Dzmitry Bahdanau, Jos\\'e Miguel\n  Hern\\'andez-Lobato, Richard E. Turner, Douglas Eck", "title": "Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models\n  with KL-control", "comments": "Add supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a general method for improving the structure and quality\nof sequences generated by a recurrent neural network (RNN), while maintaining\ninformation originally learned from data, as well as sample diversity. An RNN\nis first pre-trained on data using maximum likelihood estimation (MLE), and the\nprobability distribution over the next token in the sequence learned by this\nmodel is treated as a prior policy. Another RNN is then trained using\nreinforcement learning (RL) to generate higher-quality outputs that account for\ndomain-specific incentives while retaining proximity to the prior policy of the\nMLE RNN. To formalize this objective, we derive novel off-policy RL methods for\nRNNs from KL-control. The effectiveness of the approach is demonstrated on two\napplications; 1) generating novel musical melodies, and 2) computational\nmolecular generation. For both problems, we show that the proposed method\nimproves the desired properties and structure of the generated sequences, while\nmaintaining information learned from data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 01:46:32 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 18:54:17 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2016 14:42:30 GMT"}, {"version": "v4", "created": "Thu, 12 Jan 2017 02:18:20 GMT"}, {"version": "v5", "created": "Mon, 27 Feb 2017 20:38:06 GMT"}, {"version": "v6", "created": "Sat, 4 Mar 2017 19:38:01 GMT"}, {"version": "v7", "created": "Thu, 6 Apr 2017 15:02:04 GMT"}, {"version": "v8", "created": "Thu, 4 May 2017 17:11:45 GMT"}, {"version": "v9", "created": "Mon, 16 Oct 2017 21:31:31 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Jaques", "Natasha", ""], ["Gu", "Shixiang", ""], ["Bahdanau", "Dzmitry", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Turner", "Richard E.", ""], ["Eck", "Douglas", ""]]}, {"id": "1611.02830", "submitter": "Yi-Hsuan Kao", "authors": "Yi-Hsuan Kao, Kwame Wright, Bhaskar Krishnamachari, Fan Bai", "title": "Online Learning for Wireless Distributed Computing", "comments": "10 pages, 8 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing interest for Wireless Distributed Computing (WDC),\nwhich leverages collaborative computing over multiple wireless devices. WDC\nenables complex applications that a single device cannot support individually.\nHowever, the problem of assigning tasks over multiple devices becomes\nchallenging in the dynamic environments encountered in real-world settings,\nconsidering that the resource availability and channel conditions change over\ntime in unpredictable ways due to mobility and other factors. In this paper, we\nformulate a task assignment problem as an online learning problem using an\nadversarial multi-armed bandit framework. We propose MABSTA, a novel online\nlearning algorithm that learns the performance of unknown devices and channel\nqualities continually through exploratory probing and makes task assignment\ndecisions by exploiting the gained knowledge. For maximal adaptability, MABSTA\nis designed to make no stochastic assumption about the environment. We analyze\nit mathematically and provide a worst-case performance guarantee for any\ndynamic environment. We also compare it with the optimal offline policy as well\nas other baselines via emulations on trace-data obtained from a wireless IoT\ntestbed, and show that it offers competitive and robust performance in all\ncases. To the best of our knowledge, MABSTA is the first online algorithm in\nthis domain of task assignment problems and provides provable performance\nguarantee.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 06:21:27 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Kao", "Yi-Hsuan", ""], ["Wright", "Kwame", ""], ["Krishnamachari", "Bhaskar", ""], ["Bai", "Fan", ""]]}, {"id": "1611.02854", "submitter": "Greg Yang", "authors": "Greg Yang, Alexander M. Rush", "title": "Lie-Access Neural Turing Machines", "comments": "Published at ICLR. Rewrite and improvement of arXiv:1602.08671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  External neural memory structures have recently become a popular tool for\nalgorithmic deep learning (Graves et al. 2014, Weston et al. 2014). These\nmodels generally utilize differentiable versions of traditional discrete\nmemory-access structures (random access, stacks, tapes) to provide the storage\nnecessary for computational tasks. In this work, we argue that these neural\nmemory systems lack specific structure important for relative indexing, and\npropose an alternative model, Lie-access memory, that is explicitly designed\nfor the neural setting. In this paradigm, memory is accessed using a continuous\nhead in a key-space manifold. The head is moved via Lie group actions, such as\nshifts or rotations, generated by a controller, and memory access is performed\nby linear smoothing in key space. We argue that Lie groups provide a natural\ngeneralization of discrete memory structures, such as Turing machines, as they\nprovide inverse and identity operators while maintaining differentiability. To\nexperiment with this approach, we implement a simplified Lie-access neural\nTuring machine (LANTM) with different Lie groups. We find that this approach is\nable to perform well on a range of algorithmic tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 08:51:54 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 21:03:22 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yang", "Greg", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1611.02879", "submitter": "Abhinav Thanda", "authors": "Abhinav Thanda, Shankar M Venkatesan", "title": "Audio Visual Speech Recognition using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a training algorithm for an audio-visual automatic\nspeech recognition (AV-ASR) system using deep recurrent neural network\n(RNN).First, we train a deep RNN acoustic model with a Connectionist Temporal\nClassification (CTC) objective function. The frame labels obtained from the\nacoustic model are then used to perform a non-linear dimensionality reduction\nof the visual features using a deep bottleneck network. Audio and visual\nfeatures are fused and used to train a fusion RNN. The use of bottleneck\nfeatures for visual modality helps the model to converge properly during\ntraining. Our system is evaluated on GRID corpus. Our results show that\npresence of visual modality gives significant improvement in character error\nrate (CER) at various levels of noise even when the model is trained without\nnoisy data. We also provide a comparison of two fusion methods: feature fusion\nand decision fusion.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 10:24:52 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Thanda", "Abhinav", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "1611.02945", "submitter": "Nasser Ghadiri", "authors": "Maryam Lotfi Shahreza, Nasser Ghadiri, Seyed Rasul Mossavi, Jaleh\n  Varshosaz, James Green", "title": "Heter-LP: A heterogeneous label propagation algorithm and its\n  application in drug repositioning", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2017.03.006", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug repositioning offers an effective solution to drug discovery, saving\nboth time and resources by finding new indications for existing drugs.\nTypically, a drug takes effect via its protein targets in the cell. As a\nresult, it is necessary for drug development studies to conduct an\ninvestigation into the interrelationships of drugs, protein targets, and\ndiseases. Although previous studies have made a strong case for the\neffectiveness of integrative network-based methods for predicting these\ninterrelationships, little progress has been achieved in this regard within\ndrug repositioning research. Moreover, the interactions of new drugs and\ntargets (lacking any known targets and drugs, respectively) cannot be\naccurately predicted by most established methods. In this paper, we propose a\nnovel semi-supervised heterogeneous label propagation algorithm named Heter-LP,\nwhich applies both local as well as global network features for data\nintegration. To predict drug-target, disease-target, and drug-disease\nassociations, we use information about drugs, diseases, and targets as\ncollected from multiple sources at different levels. Our algorithm integrates\nthese various types of data into a heterogeneous network and implements a label\npropagation algorithm to find new interactions. Statistical analyses of 10-fold\ncross-validation results and experimental analysis support the effectiveness of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 20:18:57 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Shahreza", "Maryam Lotfi", ""], ["Ghadiri", "Nasser", ""], ["Mossavi", "Seyed Rasul", ""], ["Varshosaz", "Jaleh", ""], ["Green", "James", ""]]}, {"id": "1611.02960", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Hirakendu Das, Alon Orlitsky, Ananda Theertha Suresh", "title": "A Unified Maximum Likelihood Approach for Optimal Distribution Property\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of data science has spurred interest in estimating properties of\ndistributions over large alphabets. Fundamental symmetric properties such as\nsupport size, support coverage, entropy, and proximity to uniformity, received\nmost attention, with each property estimated using a different technique and\noften intricate analysis tools.\n  We prove that for all these properties, a single, simple, plug-in\nestimator---profile maximum likelihood (PML)---performs as well as the best\nspecialized techniques. This raises the possibility that PML may optimally\nestimate many other symmetric properties.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 14:59:23 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 16:36:44 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Das", "Hirakendu", ""], ["Orlitsky", "Alon", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1611.03021", "submitter": "Yu-Xiang Wang", "authors": "Ziqi Liu, Alexander J. Smola, Kyle Soska, Yu-Xiang Wang, Qinghua\n  Zheng, Jun Zhou", "title": "Attributing Hacks", "comments": "Appeared at AISTATS'17. Full version under review at the Electronic\n  Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an algorithm for estimating the provenance of hacks\non websites. That is, given properties of sites and the temporal occurrence of\nattacks, we are able to attribute individual attacks to joint causes and\nvulnerabilities, as well as estimating the evolution of these vulnerabilities\nover time. Specifically, we use hazard regression with a time-varying additive\nhazard function parameterized in a generalized linear form. The activation\ncoefficients on each feature are continuous-time functions over time. We\nformulate the problem of learning these functions as a constrained variational\nmaximum likelihood estimation problem with total variation penalty and show\nthat the optimal solution is a 0th order spline (a piecewise constant function)\nwith a finite number of known knots. This allows the inference problem to be\nsolved efficiently and at scale by solving a finite dimensional optimization\nproblem. Extensive experiments on real data sets show that our method\nsignificantly outperforms Cox's proportional hazard model. We also conduct a\ncase study and verify that the fitted functions are indeed recovering\nvulnerable features and real-life events such as the release of code to exploit\nthese features in hacker blogs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:26:58 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 18:25:34 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Liu", "Ziqi", ""], ["Smola", "Alexander J.", ""], ["Soska", "Kyle", ""], ["Wang", "Yu-Xiang", ""], ["Zheng", "Qinghua", ""], ["Zhou", "Jun", ""]]}, {"id": "1611.03068", "submitter": "Edwin D. de Jong", "authors": "Edwin D. de Jong", "title": "Incremental Sequence Learning", "comments": "Updated version: Clarified the contribution (see abstract, intro, and\n  conclusion); added figures to illustrate the architecture of the network and\n  the difference between training and generation; different selection of\n  experiments in Section 6.4; some textual edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning research over the past years has shown that by increasing the\nscope or difficulty of the learning problem over time, increasingly complex\nlearning problems can be addressed. We study incremental learning in the\ncontext of sequence learning, using generative RNNs in the form of multi-layer\nrecurrent Mixture Density Networks. While the potential of incremental or\ncurriculum learning to enhance learning is known, indiscriminate application of\nthe principle does not necessarily lead to improvement, and it is essential\ntherefore to know which forms of incremental or curriculum learning have a\npositive effect. This research contributes to that aim by comparing three\ninstantiations of incremental or curriculum learning.\n  We introduce Incremental Sequence Learning, a simple incremental approach to\nsequence learning. Incremental Sequence Learning starts out by using only the\nfirst few steps of each sequence as training data. Each time a performance\ncriterion has been reached, the length of the parts of the sequences used for\ntraining is increased.\n  We introduce and make available a novel sequence learning task and data set:\npredicting and classifying MNIST pen stroke sequences. We find that Incremental\nSequence Learning greatly speeds up sequence learning and reaches the best test\nperformance level of regular sequence learning 20 times faster, reduces the\ntest error by 74%, and in general performs more robustly; it displays lower\nvariance and achieves sustained progress after all three comparison methods\nhave stopped improving. The other instantiations of curriculum learning do not\nresult in any noticeable improvement. A trained sequence prediction model is\nalso used in transfer learning to the task of sequence classification, where it\nis found that transfer learning realizes improved classification performance\ncompared to methods that learn to classify from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 20:12:08 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 21:33:19 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["de Jong", "Edwin D.", ""]]}, {"id": "1611.03071", "submitter": "Shahin Jabbari", "authors": "Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern,\n  Aaron Roth", "title": "Fairness in Reinforcement Learning", "comments": "The short version of this paper appears in the proceedings of ICML-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of fairness in reinforcement learning, where the\nactions of a learning algorithm may affect its environment and future rewards.\nOur fairness constraint requires that an algorithm never prefers one action\nover another if the long-term (discounted) reward of choosing the latter action\nis higher. Our first result is negative: despite the fact that fairness is\nconsistent with the optimal policy, any learning algorithm satisfying fairness\nmust take time exponential in the number of states to achieve non-trivial\napproximation to the optimal policy. We then provide a provably fair polynomial\ntime algorithm under an approximate notion of fairness, thus establishing an\nexponential gap between exact and approximate fairness\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 20:19:45 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 17:46:00 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 16:35:53 GMT"}, {"version": "v4", "created": "Sun, 6 Aug 2017 00:12:49 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Jabbari", "Shahin", ""], ["Joseph", "Matthew", ""], ["Kearns", "Michael", ""], ["Morgenstern", "Jamie", ""], ["Roth", "Aaron", ""]]}, {"id": "1611.03109", "submitter": "Naresh Shanbhag", "authors": "Naresh R. Shanbhag", "title": "Energy-efficient Machine Learning in Silicon: A Communications-inspired\n  Approach", "comments": "This paper was presented at the 2016 ICML Workshop on On-Device\n  Intelligence, June 24, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This position paper advocates a communications-inspired approach to the\ndesign of machine learning systems on energy-constrained embedded `always-on'\nplatforms. The communications-inspired approach has two versions - 1) a\ndeterministic version where existing low-power communication IC design methods\nare repurposed, and 2) a stochastic version referred to as Shannon-inspired\nstatistical information processing employing information-based metrics,\nstatistical error compensation (SEC), and retraining-based methods to implement\nML systems on stochastic circuit/device fabrics operating at the limits of\nenergy-efficiency. The communications-inspired approach has the potential to\nfully leverage the opportunities afforded by ML algorithms and applications in\norder to address the challenges inherent in their deployment on\nenergy-constrained platforms.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 18:45:32 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Shanbhag", "Naresh R.", ""]]}, {"id": "1611.03125", "submitter": "Daniel McNamara", "authors": "Daniel McNamara, Cheng Soon Ong, Robert C. Williamson", "title": "A Modular Theory of Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of data, and in particular learning features for a\nsubsequent prediction task, has been a fruitful area of research delivering\nimpressive empirical results in recent years. However, relatively little is\nunderstood about what makes a representation `good'. We propose the idea of a\nrisk gap induced by representation learning for a given prediction context,\nwhich measures the difference in the risk of some learner using the learned\nfeatures as compared to the original inputs. We describe a set of sufficient\nconditions for unsupervised representation learning to provide a benefit, as\nmeasured by this risk gap. These conditions decompose the problem of when\nrepresentation learning works into its constituent parts, which can be\nseparately evaluated using an unlabeled sample, suitable domain-specific\nassumptions about the joint distribution, and analysis of the feature learner\nand subsequent supervised learner. We provide two examples of such conditions\nin the context of specific properties of the unlabeled distribution, namely\nwhen the data lies close to a low-dimensional manifold and when it forms\nclusters. We compare our approach to a recently proposed analysis of\nsemi-supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 22:40:15 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["McNamara", "Daniel", ""], ["Ong", "Cheng Soon", ""], ["Williamson", "Robert C.", ""]]}, {"id": "1611.03131", "submitter": "Yingyu Liang", "authors": "Bo Xie, Yingyu Liang, Le Song", "title": "Diverse Neural Network Learns True Target Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a powerful class of functions that can be trained with\nsimple gradient descent to achieve state-of-the-art performance on a variety of\napplications. Despite their practical success, there is a paucity of results\nthat provide theoretical guarantees on why they are so effective. Lying in the\ncenter of the problem is the difficulty of analyzing the non-convex loss\nfunction with potentially numerous local minima and saddle points. Can neural\nnetworks corresponding to the stationary points of the loss function learn the\ntrue target function? If yes, what are the key factors contributing to such\nnice optimization properties?\n  In this paper, we answer these questions by analyzing one-hidden-layer neural\nnetworks with ReLU activation, and show that despite the non-convexity, neural\nnetworks with diverse units have no spurious local minima. We bypass the\nnon-convexity issue by directly analyzing the first order optimality condition,\nand show that the loss can be made arbitrarily small if the minimum singular\nvalue of the \"extended feature matrix\" is large enough. We make novel use of\ntechniques from kernel methods and geometric discrepancy, and identify a new\nrelation linking the smallest singular value to the spectrum of a kernel\nfunction associated with the activation function and to the diversity of the\nunits. Our results also suggest a novel regularization function to promote unit\ndiversity for potentially better generalization.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 23:19:21 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 21:25:42 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 04:38:29 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Xie", "Bo", ""], ["Liang", "Yingyu", ""], ["Song", "Le", ""]]}, {"id": "1611.03158", "submitter": "Mo Chen", "authors": "Frank Jiang, Glen Chou, Mo Chen, Claire J. Tomlin", "title": "Using Neural Networks to Compute Approximate and Guaranteed Feasible\n  Hamilton-Jacobi-Bellman PDE Solutions", "comments": "Submitted to IEEE Conference on Decision and Control, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To sidestep the curse of dimensionality when computing solutions to\nHamilton-Jacobi-Bellman partial differential equations (HJB PDE), we propose an\nalgorithm that leverages a neural network to approximate the value function. We\nshow that our final approximation of the value function generates near optimal\ncontrols which are guaranteed to successfully drive the system to a target\nstate. Our framework is not dependent on state space discretization, leading to\na significant reduction in computation time and space complexity in comparison\nwith dynamic programming-based approaches. Using this grid-free approach also\nenables us to plan over longer time horizons with relatively little additional\ncomputation overhead. Unlike many previous neural network HJB PDE approximating\nformulations, our approximation is strictly conservative and hence any\ntrajectories we generate will be strictly feasible. For demonstration, we\nspecialize our new general framework to the Dubins car model and discuss how\nthe framework can be applied to other models with higher-dimensional state\nspaces.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 01:48:39 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 05:21:42 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Jiang", "Frank", ""], ["Chou", "Glen", ""], ["Chen", "Mo", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1611.03186", "submitter": "Parvez Ahammad", "authors": "Heju Jiang, Jasvir Nagra, Parvez Ahammad", "title": "SoK: Applying Machine Learning in Security - A Survey", "comments": "18 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of applying machine learning(ML) to solve problems in security\ndomains is almost 3 decades old. As information and communications grow more\nubiquitous and more data become available, many security risks arise as well as\nappetite to manage and mitigate such risks. Consequently, research on applying\nand designing ML algorithms and systems for security has grown fast, ranging\nfrom intrusion detection systems(IDS) and malware classification to security\npolicy management(SPM) and information leak checking. In this paper, we\nsystematically study the methods, algorithms, and system designs in academic\npublications from 2008-2015 that applied ML in security domains. 98 percent of\nthe surveyed papers appeared in the 6 highest-ranked academic security\nconferences and 1 conference known for pioneering ML applications in security.\nWe examine the generalized system designs, underlying assumptions,\nmeasurements, and use cases in active research. Our examinations lead to 1) a\ntaxonomy on ML paradigms and security domains for future exploration and\nexploitation, and 2) an agenda detailing open and upcoming challenges. Based on\nour survey, we also suggest a point of view that treats security as a game\ntheory problem instead of a batch-trained ML problem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 05:08:02 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Jiang", "Heju", ""], ["Nagra", "Jasvir", ""], ["Ahammad", "Parvez", ""]]}, {"id": "1611.03199", "submitter": "Bharath Ramsundar", "authors": "Han Altae-Tran, Bharath Ramsundar, Aneesh S. Pappu, and Vijay Pande", "title": "Low Data Drug Discovery with One-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning have made significant contributions to\ndrug discovery. Deep neural networks in particular have been demonstrated to\nprovide significant boosts in predictive power when inferring the properties\nand activities of small-molecule compounds. However, the applicability of these\ntechniques has been limited by the requirement for large amounts of training\ndata. In this work, we demonstrate how one-shot learning can be used to\nsignificantly lower the amounts of data required to make meaningful predictions\nin drug discovery applications. We introduce a new architecture, the residual\nLSTM embedding, that, when combined with graph convolutional neural networks,\nsignificantly improves the ability to learn meaningful distance metrics over\nsmall-molecules. We open source all models introduced in this work as part of\nDeepChem, an open-source framework for deep-learning in drug discovery.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 07:00:43 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Altae-Tran", "Han", ""], ["Ramsundar", "Bharath", ""], ["Pappu", "Aneesh S.", ""], ["Pande", "Vijay", ""]]}, {"id": "1611.03214", "submitter": "Alexander Novikov", "authors": "Timur Garipov, Dmitry Podoprikhin, Alexander Novikov, Dmitry Vetrov", "title": "Ultimate tensorization: compressing convolutional and FC layers alike", "comments": "NIPS 2016 workshop: Learning with Tensors: Why Now and How?", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks excel in image recognition tasks, but this\ncomes at the cost of high computational and memory complexity. To tackle this\nproblem, [1] developed a tensor factorization framework to compress\nfully-connected layers. In this paper, we focus on compressing convolutional\nlayers. We show that while the direct application of the tensor framework [1]\nto the 4-dimensional kernel of convolution does compress the layer, we can do\nbetter. We reshape the convolutional kernel into a tensor of higher order and\nfactorize it. We combine the proposed approach with the previous work to\ncompress both convolutional and fully-connected layers of a network and achieve\n80x network compression rate with 1.1% accuracy drop on the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 08:07:46 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Garipov", "Timur", ""], ["Podoprikhin", "Dmitry", ""], ["Novikov", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1611.03218", "submitter": "Emilio Jorge", "authors": "Emilio Jorge, Mikael K{\\aa}geb\\\"ack, Fredrik D. Johansson, Emil\n  Gustavsson", "title": "Learning to Play Guess Who? and Inventing a Grounded Language as a\n  Consequence", "comments": "Previous version was accepted to Deep Reinforcement Learning Workshop\n  at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring your first language is an incredible feat and not easily\nduplicated. Learning to communicate using nothing but a few pictureless books,\na corpus, would likely be impossible even for humans. Nevertheless, this is the\ndominating approach in most natural language processing today. As an\nalternative, we propose the use of situated interactions between agents as a\ndriving force for communication, and the framework of Deep Recurrent Q-Networks\nfor evolving a shared language grounded in the provided environment. We task\nthe agents with interactive image search in the form of the game Guess Who?.\nThe images from the game provide a non trivial environment for the agents to\ndiscuss and a natural grounding for the concepts they decide to encode in their\ncommunication. Our experiments show that the agents learn not only to encode\nphysical concepts in their words, i.e. grounding, but also that the agents\nlearn to hold a multi-step dialogue remembering the state of the dialogue from\nstep to step.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 08:44:52 GMT"}, {"version": "v2", "created": "Sun, 27 Nov 2016 14:50:50 GMT"}, {"version": "v3", "created": "Tue, 3 Jan 2017 18:28:43 GMT"}, {"version": "v4", "created": "Wed, 15 Mar 2017 11:24:49 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Jorge", "Emilio", ""], ["K\u00e5geb\u00e4ck", "Mikael", ""], ["Johansson", "Fredrik D.", ""], ["Gustavsson", "Emil", ""]]}, {"id": "1611.03220", "submitter": "Haim Avron", "authors": "Haim Avron and Kenneth L. Clarkson and David P. Woodruff", "title": "Faster Kernel Ridge Regression Using Sketching and Preconditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Ridge Regression (KRR) is a simple yet powerful technique for\nnon-parametric regression whose computation amounts to solving a linear system.\nThis system is usually dense and highly ill-conditioned. In addition, the\ndimensions of the matrix are the same as the number of data points, so direct\nmethods are unrealistic for large-scale datasets. In this paper, we propose a\npreconditioning technique for accelerating the solution of the aforementioned\nlinear system. The preconditioner is based on random feature maps, such as\nrandom Fourier features, which have recently emerged as a powerful technique\nfor speeding up and scaling the training of kernel-based methods, such as\nkernel ridge regression, by resorting to approximations. However, random\nfeature maps only provide crude approximations to the kernel function, so\ndelivering state-of-the-art results by directly solving the approximated system\nrequires the number of random features to be very large. We show that random\nfeature maps can be much more effective in forming preconditioners, since under\ncertain conditions a not-too-large number of random features is sufficient to\nyield an effective preconditioner. We empirically evaluate our method and show\nit is highly effective for datasets of up to one million training examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 08:50:05 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 21:57:20 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 06:10:52 GMT"}, {"version": "v4", "created": "Sat, 15 Jul 2017 06:31:03 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Avron", "Haim", ""], ["Clarkson", "Kenneth L.", ""], ["Woodruff", "David P.", ""]]}, {"id": "1611.03225", "submitter": "Haim Avron", "authors": "Haim Avron and Kenneth L. Clarkson and David P. Woodruff", "title": "Sharper Bounds for Regularized Data Fitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study matrix sketching methods for regularized variants of linear\nregression, low rank approximation, and canonical correlation analysis. Our\nmain focus is on sketching techniques which preserve the objective function\nvalue for regularized problems, which is an area that has remained largely\nunexplored. We study regularization both in a fairly broad setting, and in the\nspecific context of the popular and widely used technique of ridge\nregularization; for the latter, as applied to each of these problems, we show\nalgorithmic resource bounds in which the {\\em statistical dimension} appears in\nplaces where in previous bounds the rank would appear. The statistical\ndimension is always smaller than the rank, and decreases as the amount of\nregularization increases. In particular, for the ridge low-rank approximation\nproblem $\\min_{Y,X} \\lVert YX - A \\rVert_F^2 + \\lambda \\lVert Y\\rVert_F^2 +\n\\lambda\\lVert X \\rVert_F^2$, where $Y\\in\\mathbb{R}^{n\\times k}$ and\n$X\\in\\mathbb{R}^{k\\times d}$, we give an approximation algorithm needing \\[\nO(\\mathtt{nnz}(A)) + \\tilde{O}((n+d)\\varepsilon^{-1}k \\min\\{k,\n\\varepsilon^{-1}\\mathtt{sd}_\\lambda(Y^*)\\})+\n\\mathtt{poly}(\\mathtt{sd}_\\lambda(Y^*) \\varepsilon^{-1}) \\] time, where\n$s_{\\lambda}(Y^*)\\le k$ is the statistical dimension of $Y^*$, $Y^*$ is an\noptimal $Y$, $\\varepsilon$ is an error parameter, and $\\mathtt{nnz}(A)$ is the\nnumber of nonzero entries of $A$.This is faster than prior work, even when\n$\\lambda=0$.\n  We also study regularization in a much more general setting. For example, we\nobtain sketching-based algorithms for the low-rank approximation problem\n$\\min_{X,Y} \\lVert YX - A \\rVert_F^2 + f(Y,X)$ where $f(\\cdot,\\cdot)$ is a\nregularizing function satisfying some very general conditions (chiefly,\ninvariance under orthogonal transformations).\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 09:05:43 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 12:55:39 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Avron", "Haim", ""], ["Clarkson", "Kenneth L.", ""], ["Woodruff", "David P.", ""]]}, {"id": "1611.03231", "submitter": "Voot Tangkaratt", "authors": "Voot Tangkaratt, Herke van Hoof, Simone Parisi, Gerhard Neumann, Jan\n  Peters, Masashi Sugiyama", "title": "Policy Search with High-Dimensional Context Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct contextual policy search methods learn to improve policy parameters\nand simultaneously generalize these parameters to different context or task\nvariables. However, learning from high-dimensional context variables, such as\ncamera images, is still a prominent problem in many real-world tasks. A naive\napplication of unsupervised dimensionality reduction methods to the context\nvariables, such as principal component analysis, is insufficient as\ntask-relevant input may be ignored. In this paper, we propose a contextual\npolicy search method in the model-based relative entropy stochastic search\nframework with integrated dimensionality reduction. We learn a model of the\nreward that is locally quadratic in both the policy parameters and the context\nvariables. Furthermore, we perform supervised linear dimensionality reduction\non the context variables by nuclear norm regularization. The experimental\nresults show that the proposed method outperforms naive dimensionality\nreduction via principal component analysis and a state-of-the-art contextual\npolicy search method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 09:25:12 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Tangkaratt", "Voot", ""], ["van Hoof", "Herke", ""], ["Parisi", "Simone", ""], ["Neumann", "Gerhard", ""], ["Peters", "Jan", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1611.03383", "submitter": "Junbo Zhao", "authors": "Michael Mathieu, Junbo Zhao, Pablo Sprechmann, Aditya Ramesh, Yann\n  LeCun", "title": "Disentangling factors of variation in deep representations using\n  adversarial training", "comments": "Conference paper in NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a conditional generative model for learning to disentangle the\nhidden factors of variation within a set of labeled observations, and separate\nthem into complementary codes. One code summarizes the specified factors of\nvariation associated with the labels. The other summarizes the remaining\nunspecified variability. During training, the only available source of\nsupervision comes from our ability to distinguish among different observations\nbelonging to the same class. Examples of such observations include images of a\nset of labeled objects captured at different viewpoints, or recordings of set\nof speakers dictating multiple phrases. In both instances, the intra-class\ndiversity is the source of the unspecified factors of variation: each object is\nobserved at multiple viewpoints, and each speaker dictates multiple phrases.\nLearning to disentangle the specified factors from the unspecified ones becomes\neasier when strong supervision is possible. Suppose that during training, we\nhave access to pairs of images, where each pair shows two different objects\ncaptured from the same viewpoint. This source of alignment allows us to solve\nour task using existing methods. However, labels for the unspecified factors\nare usually unavailable in realistic scenarios where data acquisition is not\nstrictly controlled. We address the problem of disentanglement in this more\ngeneral setting by combining deep convolutional autoencoders with a form of\nadversarial training. Both factors of variation are implicitly captured in the\norganization of the learned embedding space, and can be used for solving\nsingle-image analogies. Experimental results on synthetic and real datasets\nshow that the proposed method is capable of generalizing to unseen classes and\nintra-class variabilities.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 16:24:16 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Mathieu", "Michael", ""], ["Zhao", "Junbo", ""], ["Sprechmann", "Pablo", ""], ["Ramesh", "Aditya", ""], ["LeCun", "Yann", ""]]}, {"id": "1611.03404", "submitter": "Jeffrey Regier", "authors": "Jeffrey Regier, Kiran Pamnany, Ryan Giordano, Rollin Thomas, David\n  Schlegel, Jon McAuliffe and Prabhat", "title": "Learning an Astronomical Catalog of the Visible Universe through\n  Scalable Bayesian Inference", "comments": "submitting to IPDPS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Celeste is a procedure for inferring astronomical catalogs that attains\nstate-of-the-art scientific results. To date, Celeste has been scaled to at\nmost hundreds of megabytes of astronomical images: Bayesian posterior inference\nis notoriously demanding computationally. In this paper, we report on a\nscalable, parallel version of Celeste, suitable for learning catalogs from\nmodern large-scale astronomical datasets. Our algorithmic innovations include a\nfast numerical optimization routine for Bayesian posterior inference and a\nstatistically efficient scheme for decomposing astronomical optimization\nproblems into subproblems.\n  Our scalable implementation is written entirely in Julia, a new high-level\ndynamic programming language designed for scientific and numerical computing.\nWe use Julia's high-level constructs for shared and distributed memory\nparallelism, and demonstrate effective load balancing and efficient scaling on\nup to 8192 Xeon cores on the NERSC Cori supercomputer.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:16:04 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Regier", "Jeffrey", ""], ["Pamnany", "Kiran", ""], ["Giordano", "Ryan", ""], ["Thomas", "Rollin", ""], ["Schlegel", "David", ""], ["McAuliffe", "Jon", ""], ["Prabhat", "", ""]]}, {"id": "1611.03410", "submitter": "Barak Pearlmutter", "authors": "Jeffrey Mark Siskind and Barak A. Pearlmutter", "title": "Binomial Checkpointing for Arbitrary Programs with No User Annotation", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heretofore, automatic checkpointing at procedure-call boundaries, to reduce\nthe space complexity of reverse mode, has been provided by systems like\nTapenade. However, binomial checkpointing, or treeverse, has only been provided\nin Automatic Differentiation (AD) systems in special cases, e.g., through\nuser-provided pragmas on DO loops in Tapenade, or as the nested taping\nmechanism in adol-c for time integration processes, which requires that user\ncode be refactored. We present a framework for applying binomial checkpointing\nto arbitrary code with no special annotation or refactoring required. This is\naccomplished by applying binomial checkpointing directly to a program trace.\nThis trace is produced by a general-purpose checkpointing mechanism that is\northogonal to AD.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:29:24 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Siskind", "Jeffrey Mark", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "1611.03423", "submitter": "Barak Pearlmutter", "authors": "At{\\i}l{\\i}m G\\\"une\\c{s} Baydin and Barak A. Pearlmutter and Jeffrey\n  Mark Siskind", "title": "DiffSharp: An AD Library for .NET Languages", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)\nlibrary for the .NET ecosystem, which is targeted by the C# and F# languages,\namong others. The library has been designed with machine learning applications\nin mind, allowing very succinct implementations of models and optimization\nroutines. DiffSharp is implemented in F# and exposes forward and reverse AD\noperators as general nestable higher-order functions, usable by any .NET\nlanguage. It provides high-performance linear algebra primitives---scalars,\nvectors, and matrices, with a generalization to tensors underway---that are\nfully supported by all the AD operators, and which use a BLAS/LAPACK backend\nvia the highly optimized OpenBLAS library. DiffSharp currently uses operator\noverloading, but we are developing a transformation-based version of the\nlibrary using F#'s \"code quotation\" metaprogramming facility. Work on a\nCUDA-based GPU backend is also underway.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:50:06 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1611.03427", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Jaime Carbonell", "title": "Multi-Task Multiple Kernel Relationship Learning", "comments": "17th SIAM International Conference on Data Mining (SDM 2017),\n  Houston, Texas, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel multitask multiple kernel learning framework that\nefficiently learns the kernel weights leveraging the relationship across\nmultiple tasks. The idea is to automatically infer this task relationship in\nthe \\textit{RKHS} space corresponding to the given base kernels. The problem is\nformulated as a regularization-based approach called \\textit{Multi-Task\nMultiple Kernel Relationship Learning} (\\textit{MK-MTRL}), which models the\ntask relationship matrix from the weights learned from latent feature spaces of\ntask-specific base kernels. Unlike in previous work, the proposed formulation\nallows one to incorporate prior knowledge for simultaneously learning several\nrelated tasks. We propose an alternating minimization algorithm to learn the\nmodel parameters, kernel weights and task relationship matrix. In order to\ntackle large-scale problems, we further propose a two-stage \\textit{MK-MTRL}\nonline learning algorithm and show that it significantly reduces the\ncomputational time, and also achieves performance comparable to that of the\njoint learning framework. Experimental results on benchmark datasets show that\nthe proposed formulations outperform several state-of-the-art multitask\nlearning methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:54:22 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 22:09:54 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1611.03451", "submitter": "Philip Thomas", "authors": "Philip S. Thomas and Emma Brunskill", "title": "Importance Sampling with Unequal Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling is often used in machine learning when training and\ntesting data come from different distributions. In this paper we propose a new\nvariant of importance sampling that can reduce the variance of importance\nsampling-based estimates by orders of magnitude when the supports of the\ntraining and testing distributions differ. After motivating and presenting our\nnew importance sampling estimator, we provide a detailed theoretical analysis\nthat characterizes both its bias and variance relative to the ordinary\nimportance sampling estimator (in various settings, which include cases where\nordinary importance sampling is biased, while our new estimator is not, and\nvice versa). We conclude with an example of how our new importance sampling\nestimator can be used to improve estimates of how well a new treatment policy\nfor diabetes will work for an individual, using only data from when the\nindividual used a previous treatment policy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 19:11:09 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Thomas", "Philip S.", ""], ["Brunskill", "Emma", ""]]}, {"id": "1611.03473", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "Statistical Query Lower Bounds for Robust Estimation of High-dimensional\n  Gaussians and Gaussian Mixtures", "comments": "Changes from v1: Revised presentation. Added more applications of the\n  technique (SQ lower bounds for robust sparse mean estimation and robust\n  covariance estimation in spectral norm). Sharpened testing lower bound to\n  linear in the dimension (compared to nearly-linear in first version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general technique that yields the first {\\em Statistical Query\nlower bounds} for a range of fundamental high-dimensional learning problems\ninvolving Gaussian distributions. Our main results are for the problems of (1)\nlearning Gaussian mixture models (GMMs), and (2) robust (agnostic) learning of\na single unknown Gaussian distribution. For each of these problems, we show a\n{\\em super-polynomial gap} between the (information-theoretic) sample\ncomplexity and the computational complexity of {\\em any} Statistical Query\nalgorithm for the problem. Our SQ lower bound for Problem (1) is qualitatively\nmatched by known learning algorithms for GMMs. Our lower bound for Problem (2)\nimplies that the accuracy of the robust learning algorithm\nin~\\cite{DiakonikolasKKLMS16} is essentially best possible among all\npolynomial-time SQ algorithms.\n  Our SQ lower bounds are attained via a unified moment-matching technique that\nis useful in other contexts and may be of broader interest. Our technique\nyields nearly-tight lower bounds for a number of related unsupervised\nestimation problems. Specifically, for the problems of (3) robust covariance\nestimation in spectral norm, and (4) robust sparse mean estimation, we\nestablish a quadratic {\\em statistical--computational tradeoff} for SQ\nalgorithms, matching known upper bounds. Finally, our technique can be used to\nobtain tight sample complexity lower bounds for high-dimensional {\\em testing}\nproblems. Specifically, for the classical problem of robustly {\\em testing} an\nunknown mean (known covariance) Gaussian, our technique implies an\ninformation-theoretic sample lower bound that scales {\\em linearly} in the\ndimension. Our sample lower bound matches the sample complexity of the\ncorresponding robust {\\em learning} problem and separates the sample complexity\nof robust testing from standard (non-robust) testing.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 20:32:48 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 15:48:34 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1611.03530", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol\n  Vinyals", "title": "Understanding deep learning requires rethinking generalization", "comments": "Published in ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n  Through extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction showing\nthat simple depth two neural networks already have perfect finite sample\nexpressivity as soon as the number of parameters exceeds the number of data\npoints as it usually does in practice.\n  We interpret our experimental findings by comparison with traditional models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 22:02:36 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 19:36:40 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Bengio", "Samy", ""], ["Hardt", "Moritz", ""], ["Recht", "Benjamin", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1611.03553", "submitter": "Abram Friesen", "authors": "Abram L. Friesen and Pedro Domingos", "title": "The Sum-Product Theorem: A Foundation for Learning Tractable Models", "comments": "15 pages (10 body, 5 pages of appendices)", "journal-ref": "Proceedings of the 33rd International Conference on Machine\n  Learning, pp. 1909-1918, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in expressive probabilistic models is generally intractable, which\nmakes them difficult to learn and limits their applicability. Sum-product\nnetworks are a class of deep models where, surprisingly, inference remains\ntractable even when an arbitrary number of hidden layers are present. In this\npaper, we generalize this result to a much broader set of learning problems:\nall those where inference consists of summing a function over a semiring. This\nincludes satisfiability, constraint satisfaction, optimization, integration,\nand others. In any semiring, for summation to be tractable it suffices that the\nfactors of every product have disjoint scopes. This unifies and extends many\nprevious results in the literature. Enforcing this condition at learning time\nthus ensures that the learned models are tractable. We illustrate the power and\ngenerality of this approach by applying it to a new type of structured\nprediction problem: learning a nonconvex function that can be globally\noptimized in polynomial time. We show empirically that this greatly outperforms\nthe standard approach of learning without regard to the cost of optimization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 00:46:33 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Friesen", "Abram L.", ""], ["Domingos", "Pedro", ""]]}, {"id": "1611.03578", "submitter": "Guangxi Li", "authors": "Guangxi Li, Zenglin Xu, Linnan Wang, Jinmian Ye, Irwin King, Michael\n  Lyu", "title": "Simple and Efficient Parallelization for Probabilistic Temporal Tensor\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Temporal Tensor Factorization (PTTF) is an effective algorithm\nto model the temporal tensor data. It leverages a time constraint to capture\nthe evolving properties of tensor data. Nowadays the exploding dataset demands\na large scale PTTF analysis, and a parallel solution is critical to accommodate\nthe trend. Whereas, the parallelization of PTTF still remains unexplored. In\nthis paper, we propose a simple yet efficient Parallel Probabilistic Temporal\nTensor Factorization, referred to as P$^2$T$^2$F, to provide a scalable PTTF\nsolution. P$^2$T$^2$F is fundamentally disparate from existing parallel tensor\nfactorizations by considering the probabilistic decomposition and the temporal\neffects of tensor data. It adopts a new tensor data split strategy to subdivide\na large tensor into independent sub-tensors, the computation of which is\ninherently parallel. We train P$^2$T$^2$F with an efficient algorithm of\nstochastic Alternating Direction Method of Multipliers, and show that the\nconvergence is guaranteed. Experiments on several real-word tensor datasets\ndemonstrate that P$^2$T$^2$F is a highly effective and efficiently scalable\nalgorithm dedicated for large scale probabilistic temporal tensor analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 03:54:00 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Li", "Guangxi", ""], ["Xu", "Zenglin", ""], ["Wang", "Linnan", ""], ["Ye", "Jinmian", ""], ["King", "Irwin", ""], ["Lyu", "Michael", ""]]}, {"id": "1611.03579", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Themis Gouleakis, John Peebles, Eric Price", "title": "Collision-based Testers are Optimal for Uniformity and Closeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problems of (i) uniformity testing of a discrete\ndistribution, and (ii) closeness testing between two discrete distributions\nwith bounded $\\ell_2$-norm. These problems have been extensively studied in\ndistribution testing and sample-optimal estimators are known for\nthem~\\cite{Paninski:08, CDVV14, VV14, DKN:15}.\n  In this work, we show that the original collision-based testers proposed for\nthese problems ~\\cite{GRdist:00, BFR+:00} are sample-optimal, up to constant\nfactors. Previous analyses showed sample complexity upper bounds for these\ntesters that are optimal as a function of the domain size $n$, but suboptimal\nby polynomial factors in the error parameter $\\epsilon$. Our main contribution\nis a new tight analysis establishing that these collision-based testers are\ninformation-theoretically optimal, up to constant factors, both in the\ndependence on $n$ and in the dependence on $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 03:59:24 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "1611.03599", "submitter": "Wei-Fan Chen", "authors": "Wei-Fan Chen and Lun-Wei Ku", "title": "UTCNN: a Deep Learning Model of Stance Classificationon on Social Media\n  Text", "comments": "11 pages, to appear in COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural network models for document classification on social media focus\non text infor-mation to the neglect of other information on these platforms. In\nthis paper, we classify post stance on social media channels and develop UTCNN,\na neural network model that incorporates user tastes, topic tastes, and user\ncomments on posts. UTCNN not only works on social media texts, but also\nanalyzes texts in forums and message boards. Experiments performed on Chinese\nFacebook data and English online debate forum data show that UTCNN achieves a\n0.755 macro-average f-score for supportive, neutral, and unsupportive stance\nclasses on Facebook data, which is significantly better than models in which\neither user, topic, or comment information is withheld. This model design\ngreatly mitigates the lack of data for the minor class without the use of\noversampling. In addition, UTCNN yields a 0.842 accuracy on English online\ndebate forum data, which also significantly outperforms results from previous\nwork as well as other deep learning models, showing that UTCNN performs well\nregardless of language or platform.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 07:05:49 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Chen", "Wei-Fan", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1611.03608", "submitter": "Xiatian Zhang", "authors": "Xiatian Zhang, Fan Yao, Yongjun Tian", "title": "Greedy Step Averaging: A parameter-free stochastic optimization method", "comments": "23 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the greedy step averaging(GSA) method, a\nparameter-free stochastic optimization algorithm for a variety of machine\nlearning problems. As a gradient-based optimization method, GSA makes use of\nthe information from the minimizer of a single sample's loss function, and\ntakes average strategy to calculate reasonable learning rate sequence. While\nmost existing gradient-based algorithms introduce an increasing number of hyper\nparameters or try to make a trade-off between computational cost and\nconvergence rate, GSA avoids the manual tuning of learning rate and brings in\nno more hyper parameters or extra cost. We perform exhaustive numerical\nexperiments for logistic and softmax regression to compare our method with the\nother state of the art ones on 16 datasets. Results show that GSA is robust on\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 08:23:30 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Zhang", "Xiatian", ""], ["Yao", "Fan", ""], ["Tian", "Yongjun", ""]]}, {"id": "1611.03673", "submitter": "Piotr Mirowski", "authors": "Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J.\n  Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray\n  Kavukcuoglu, Dharshan Kumaran and Raia Hadsell", "title": "Learning to Navigate in Complex Environments", "comments": "11 pages, 5 appendix pages, 11 figures, 3 tables, under review as a\n  conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to navigate in complex environments with dynamic elements is an\nimportant milestone in developing AI agents. In this work we formulate the\nnavigation question as a reinforcement learning problem and show that data\nefficiency and task performance can be dramatically improved by relying on\nadditional auxiliary tasks leveraging multimodal sensory inputs. In particular\nwe consider jointly learning the goal-driven reinforcement learning problem\nwith auxiliary depth prediction and loop closure classification tasks. This\napproach can learn to navigate from raw sensory input in complicated 3D mazes,\napproaching human-level performance even under conditions where the goal\nlocation changes frequently. We provide detailed analysis of the agent\nbehaviour, its ability to localise, and its network activity dynamics, showing\nthat the agent implicitly learns key navigation abilities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 12:14:45 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 18:02:53 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2017 11:15:22 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Mirowski", "Piotr", ""], ["Pascanu", "Razvan", ""], ["Viola", "Fabio", ""], ["Soyer", "Hubert", ""], ["Ballard", "Andrew J.", ""], ["Banino", "Andrea", ""], ["Denil", "Misha", ""], ["Goroshin", "Ross", ""], ["Sifre", "Laurent", ""], ["Kavukcuoglu", "Koray", ""], ["Kumaran", "Dharshan", ""], ["Hadsell", "Raia", ""]]}, {"id": "1611.03718", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Miriam Bellver, Xavier Giro-i-Nieto, Ferran Marques and Jordi Torres", "title": "Hierarchical Object Detection with Deep Reinforcement Learning", "comments": "Deep Reinforcement Learning Workshop (NIPS 2016). Project page at\n  https://imatge-upc.github.io/detection-2016-nipsws/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for performing hierarchical object detection in images\nguided by a deep reinforcement learning agent. The key idea is to focus on\nthose parts of the image that contain richer information and zoom on them. We\ntrain an intelligent agent that, given an image window, is capable of deciding\nwhere to focus the attention among five different predefined region candidates\n(smaller windows). This procedure is iterated providing a hierarchical image\nanalysis.We compare two different candidate proposal strategies to guide the\nobject search: with and without overlap. Moreover, our work compares two\ndifferent strategies to extract features from a convolutional neural network\nfor each region proposal: a first one that computes new feature maps for each\nregion proposal, and a second one that computes the feature maps for the whole\nimage to later generate crops for each region proposal. Experiments indicate\nbetter results for the overlapping candidate proposal strategy and a loss of\nperformance for the cropped image features due to the loss of spatial\nresolution. We argue that, while this loss seems unavoidable when working with\nlarge amounts of object candidates, the much more reduced amount of region\nproposals generated by our reinforcement learning agent allows considering to\nextract features for each location without sharing convolutional computation\namong regions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 14:25:54 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 14:31:07 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Bellver", "Miriam", ""], ["Giro-i-Nieto", "Xavier", ""], ["Marques", "Ferran", ""], ["Torres", "Jordi", ""]]}, {"id": "1611.03777", "submitter": "Barak Pearlmutter", "authors": "At{\\i}l{\\i}m G\\\"une\\c{s} Baydin and Barak A. Pearlmutter and Jeffrey\n  Mark Siskind", "title": "Tricks from Deep Learning", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep learning community has devised a diverse set of methods to make\ngradient optimization, using large datasets, of large and highly complex models\nwith deeply cascaded nonlinearities, practical. Taken as a whole, these methods\nconstitute a breakthrough, allowing computational structures which are quite\nwide, very deep, and with an enormous number and variety of free parameters to\nbe effectively optimized. The result now dominates much of practical machine\nlearning, with applications in machine translation, computer vision, and speech\nrecognition. Many of these methods, viewed through the lens of algorithmic\ndifferentiation (AD), can be seen as either addressing issues with the gradient\nitself, or finding ways of achieving increased efficiency using tricks that are\nAD-related, but not provided by current AD systems.\n  The goal of this paper is to explain not just those methods of most relevance\nto AD, but also the technical constraints and mindset which led to their\ndiscovery. After explaining this context, we present a \"laundry list\" of\nmethods developed by the deep learning community. Two of these are discussed in\nfurther mathematical detail: a way to dramatically reduce the size of the tape\nwhen performing reverse-mode AD on a (theoretically) time-reversible process\nlike an ODE integrator; and a new mathematical insight that allows for the\nimplementation of a stochastic Newton's method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:57:19 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1611.03814", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, Michael Wellman", "title": "Towards the Science of Security and Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning (ML) in recent years have enabled a dizzying\narray of applications such as data analytics, autonomous systems, and security\ndiagnostics. ML is now pervasive---new systems and models are being deployed in\nevery domain imaginable, leading to rapid and widespread deployment of software\nbased inference and decision making. There is growing recognition that ML\nexposes new vulnerabilities in software systems, yet the technical community's\nunderstanding of the nature and extent of these vulnerabilities remains\nlimited. We systematize recent findings on ML security and privacy, focusing on\nattacks identified on these systems and defenses crafted to date. We articulate\na comprehensive threat model for ML, and categorize attacks and defenses within\nan adversarial framework. Key insights resulting from works both in the ML and\nsecurity communities are identified and the effectiveness of approaches are\nrelated to structural elements of ML algorithms and the data used to train\nthem. We conclude by formally exploring the opposing relationship between model\naccuracy and resilience to adversarial manipulation. Through these\nexplorations, we show that there are (possibly unavoidable) tensions between\nmodel complexity, accuracy, and resilience that must be calibrated for the\nenvironments in which they will be used.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 18:57:15 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Sinha", "Arunesh", ""], ["Wellman", "Michael", ""]]}, {"id": "1611.03819", "submitter": "Yingyu Liang", "authors": "Yuanzhi Li, Yingyu Liang, Andrej Risteski", "title": "Recovery Guarantee of Non-negative Matrix Factorization via Alternating\n  Updates", "comments": "To appear in NIPS 2016. 8 pages of extended abstract; 48 pages in\n  total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization is a popular tool for decomposing data into\nfeature and weight matrices under non-negativity constraints. It enjoys\npractical success but is poorly understood theoretically. This paper proposes\nan algorithm that alternates between decoding the weights and updating the\nfeatures, and shows that assuming a generative model of the data, it provably\nrecovers the ground-truth under fairly mild conditions. In particular, its only\nessential requirement on features is linear independence. Furthermore, the\nalgorithm uses ReLU to exploit the non-negativity for decoding the weights, and\nthus can tolerate adversarial noise that can potentially be as large as the\nsignal, and can tolerate unbiased noise much larger than the signal. The\nanalysis relies on a carefully designed coupling between two potential\nfunctions, which we believe is of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 19:13:37 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""], ["Risteski", "Andrej", ""]]}, {"id": "1611.03824", "submitter": "Yutian Chen", "authors": "Yutian Chen, Matthew W. Hoffman, Sergio Gomez Colmenarejo, Misha\n  Denil, Timothy P. Lillicrap, Matt Botvinick, Nando de Freitas", "title": "Learning to Learn without Gradient Descent by Gradient Descent", "comments": "Accepted by ICML 2017. Previous version \"Learning to Learn for Global\n  Optimization of Black Box Functions\" was published in the Deep Reinforcement\n  Learning Workshop, NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn recurrent neural network optimizers trained on simple synthetic\nfunctions by gradient descent. We show that these learned optimizers exhibit a\nremarkable degree of transfer in that they can be used to efficiently optimize\na broad range of derivative-free black-box functions, including Gaussian\nprocess bandits, simple control objectives, global optimization benchmarks and\nhyper-parameter tuning tasks. Up to the training horizon, the learned\noptimizers learn to trade-off exploration and exploitation, and compare\nfavourably with heavily engineered Bayesian optimization packages for\nhyper-parameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 19:33:01 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 14:13:13 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 21:32:13 GMT"}, {"version": "v4", "created": "Tue, 9 May 2017 07:59:07 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 14:15:01 GMT"}, {"version": "v6", "created": "Mon, 12 Jun 2017 11:19:30 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Chen", "Yutian", ""], ["Hoffman", "Matthew W.", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Denil", "Misha", ""], ["Lillicrap", "Timothy P.", ""], ["Botvinick", "Matt", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.03852", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Paul Christiano, Pieter Abbeel, Sergey Levine", "title": "A Connection between Generative Adversarial Networks, Inverse\n  Reinforcement Learning, and Energy-Based Models", "comments": "NIPS 2016 Workshop on Adversarial Training. First two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a recently proposed class of\ngenerative models in which a generator is trained to optimize a cost function\nthat is being simultaneously learned by a discriminator. While the idea of\nlearning cost functions is relatively new to the field of generative modeling,\nlearning costs has long been studied in control and reinforcement learning (RL)\ndomains, typically for imitation learning from demonstrations. In these fields,\nlearning cost function underlying observed behavior is known as inverse\nreinforcement learning (IRL) or inverse optimal control. While at first the\nconnection between cost learning in RL and cost learning in generative modeling\nmay appear to be a superficial one, we show in this paper that certain IRL\nmethods are in fact mathematically equivalent to GANs. In particular, we\ndemonstrate an equivalence between a sample-based algorithm for maximum entropy\nIRL and a GAN in which the generator's density can be evaluated and is provided\nas an additional input to the discriminator. Interestingly, maximum entropy IRL\nis a special case of an energy-based model. We discuss the interpretation of\nGANs as an algorithm for training energy-based models, and relate this\ninterpretation to other recent work that seeks to connect GANs and EBMs. By\nformally highlighting the connection between GANs, IRL, and EBMs, we hope that\nresearchers in all three communities can better identify and apply transferable\nideas from one domain to another, particularly for developing more stable and\nscalable algorithms: a major challenge in all three domains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 20:53:45 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 18:11:26 GMT"}, {"version": "v3", "created": "Fri, 25 Nov 2016 08:09:55 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Finn", "Chelsea", ""], ["Christiano", "Paul", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.03879", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Siamak Ravanbakhsh, Barnabas Poczos", "title": "Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machine (RBM) is a bipartite graphical model that is\nused as the building block in energy-based deep generative models. Due to\nnumerical stability and quantifiability of the likelihood, RBM is commonly used\nwith Bernoulli units. Here, we consider an alternative member of exponential\nfamily RBM with leaky rectified linear units -- called leaky RBM. We first\nstudy the joint and marginal distributions of leaky RBM under different\nleakiness, which provides us important insights by connecting the leaky RBM\nmodel and truncated Gaussian distributions. The connection leads us to a simple\nyet efficient method for sampling from this model, where the basic idea is to\nanneal the leakiness rather than the energy; -- i.e., start from a fully\nGaussian/Linear unit and gradually decrease the leakiness over iterations. This\nserves as an alternative to the annealing of the temperature parameter and\nenables numerical estimation of the likelihood that are more efficient and more\naccurate than the commonly used annealed importance sampling (AIS). We further\ndemonstrate that the proposed sampling algorithm enjoys faster mixing property\nthan contrastive divergence algorithm, which benefits the training without any\nadditional computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 21:08:36 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Li", "Chun-Liang", ""], ["Ravanbakhsh", "Siamak", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1611.03894", "submitter": "Thai Pham", "authors": "Thai Pham and Camelia Simoiu", "title": "Unsupervised Learning For Effective User Engagement on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the effectiveness of unsupervised feature\nlearning techniques in predicting user engagement on social media.\nSpecifically, we compare two methods to predict the number of feedbacks (i.e.,\ncomments) that a blog post is likely to receive. We compare Principal Component\nAnalysis (PCA) and sparse Autoencoder to a baseline method where the data are\nonly centered and scaled, on each of two models: Linear Regression and\nRegression Tree. We find that unsupervised learning techniques significantly\nimprove the prediction accuracy on both models. For the Linear Regression\nmodel, sparse Autoencoder achieves the best result, with an improvement in the\nroot mean squared error (RMSE) on the test set of 42% over the baseline method.\nFor the Regression Tree model, PCA achieves the best result, with an\nimprovement in RMSE of 15% over the baseline.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 22:01:41 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Pham", "Thai", ""], ["Simoiu", "Camelia", ""]]}, {"id": "1611.03898", "submitter": "Thai Pham", "authors": "Derek Farren and Thai Pham and Marco Alban-Hidalgo", "title": "Low Latency Anomaly Detection and Bayesian Network Prediction of Anomaly\n  Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a supervised machine learning model that detects anomalies in\nsystems in real time. Our model processes unbounded streams of data into time\nseries which then form the basis of a low-latency anomaly detection model.\nMoreover, we extend our preliminary goal of just anomaly detection to\nsimultaneous anomaly prediction. We approach this very challenging problem by\ndeveloping a Bayesian Network framework that captures the information about the\nparameters of the lagged regressors calibrated in the first part of our\napproach and use this structure to learn local conditional probability\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 22:20:41 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Farren", "Derek", ""], ["Pham", "Thai", ""], ["Alban-Hidalgo", "Marco", ""]]}, {"id": "1611.03907", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Alessandro Lazaric, Animashree Anandkumar", "title": "Reinforcement Learning in Rich-Observation MDPs using Spectral Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in Markov decision processes (MDPs) with large\nstate spaces is a challenging problem. The performance of standard RL\nalgorithms degrades drastically with the dimensionality of state space.\nHowever, in practice, these large MDPs typically incorporate a latent or hidden\nlow-dimensional structure. In this paper, we study the setting of\nrich-observation Markov decision processes (ROMDP), where there are a small\nnumber of hidden states which possess an injective mapping to the observation\nstates. In other words, every observation state is generated through a single\nhidden state, and this mapping is unknown a priori. We introduce a spectral\ndecomposition method that consistently learns this mapping, and more\nimportantly, achieves it with low regret. The estimated mapping is integrated\ninto an optimistic RL algorithm (UCRL), which operates on the estimated hidden\nspace. We derive finite-time regret bounds for our algorithm with a weak\ndependence on the dimensionality of the observed space. In fact, our algorithm\nasymptotically achieves the same average regret as the oracle UCRL algorithm,\nwhich has the knowledge of the mapping from hidden to observed spaces. Thus, we\nderive an efficient spectral RL algorithm for ROMDPs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 22:39:01 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 01:52:32 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 01:03:33 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 20:14:54 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Lazaric", "Alessandro", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1611.03934", "submitter": "Ahmed Alaa", "authors": "Jinsung Yoon, Ahmed M. Alaa, Martin Cadeiras, and Mihaela van der\n  Schaar", "title": "Personalized Donor-Recipient Matching for Organ Transplantation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organ transplants can improve the life expectancy and quality of life for the\nrecipient but carries the risk of serious post-operative complications, such as\nseptic shock and organ rejection. The probability of a successful transplant\ndepends in a very subtle fashion on compatibility between the donor and the\nrecipient but current medical practice is short of domain knowledge regarding\nthe complex nature of recipient-donor compatibility. Hence a data-driven\napproach for learning compatibility has the potential for significant\nimprovements in match quality. This paper proposes a novel system\n(ConfidentMatch) that is trained using data from electronic health records.\nConfidentMatch predicts the success of an organ transplant (in terms of the 3\nyear survival rates) on the basis of clinical and demographic traits of the\ndonor and recipient. ConfidentMatch captures the heterogeneity of the donor and\nrecipient traits by optimally dividing the feature space into clusters and\nconstructing different optimal predictive models to each cluster. The system\ncontrols the complexity of the learned predictive model in a way that allows\nfor assuring more granular and confident predictions for a larger number of\npotential recipient-donor pairs, thereby ensuring that predictions are\n\"personalized\" and tailored to individual characteristics to the finest\npossible granularity. Experiments conducted on the UNOS heart transplant\ndataset show the superiority of the prognostic value of ConfidentMatch to other\ncompeting benchmarks; ConfidentMatch can provide predictions of success with\n95% confidence for 5,489 patients of a total population of 9,620 patients,\nwhich corresponds to 410 more patients than the most competitive benchmark\nalgorithm (DeepBoost).\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 01:53:54 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Yoon", "Jinsung", ""], ["Alaa", "Ahmed M.", ""], ["Cadeiras", "Martin", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1611.03941", "submitter": "Thai Pham", "authors": "Thai Pham and Steven Lee", "title": "Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of anomaly detection has been studied for a long time. In short,\nanomalies are abnormal or unlikely things. In financial networks, thieves and\nillegal activities are often anomalous in nature. Members of a network want to\ndetect anomalies as soon as possible to prevent them from harming the network's\ncommunity and integrity. Many Machine Learning techniques have been proposed to\ndeal with this problem; some results appear to be quite promising but there is\nno obvious superior method. In this paper, we consider anomaly detection\nparticular to the Bitcoin transaction network. Our goal is to detect which\nusers and transactions are the most suspicious; in this case, anomalous\nbehavior is a proxy for suspicious behavior. To this end, we use three\nunsupervised learning methods including k-means clustering, Mahalanobis\ndistance, and Unsupervised Support Vector Machine (SVM) on two graphs generated\nby the Bitcoin transaction network: one graph has users as nodes, and the other\nhas transactions as nodes.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 02:39:41 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 00:56:26 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Pham", "Thai", ""], ["Lee", "Steven", ""]]}, {"id": "1611.03969", "submitter": "Hien Nguyen", "authors": "Hien D. Nguyen", "title": "An Introduction to MM Algorithms for Machine Learning and Statistical", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MM (majorization--minimization) algorithms are an increasingly popular tool\nfor solving optimization problems in machine learning and statistical\nestimation. This article introduces the MM algorithm framework in general and\nvia three popular example applications: Gaussian mixture regressions,\nmultinomial logistic regressions, and support vector machines. Specific\nalgorithms for the three examples are derived and numerical demonstrations are\npresented. Theoretical and practical aspects of MM algorithm design are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 08:18:38 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Nguyen", "Hien D.", ""]]}, {"id": "1611.03981", "submitter": "Fuqiang Liu", "authors": "Fuqaing Liu, Chenwei Deng, Fukun Bi, Yiding Yang", "title": "Dual Teaching: A Practical Semi-supervised Wrapper Method", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semi-supervised wrapper methods are concerned with building effective\nsupervised classifiers from partially labeled data. Though previous works have\nsucceeded in some fields, it is still difficult to apply semi-supervised\nwrapper methods to practice because the assumptions those methods rely on tend\nto be unrealistic in practice. For practical use, this paper proposes a novel\nsemi-supervised wrapper method, Dual Teaching, whose assumptions are easy to\nset up. Dual Teaching adopts two external classifiers to estimate the false\npositives and false negatives of the base learner. Only if the recall of every\nexternal classifier is greater than zero and the sum of the precision is\ngreater than one, Dual Teaching will train a base learner from partially\nlabeled data as effectively as the fully-labeled-data-trained classifier. The\neffectiveness of Dual Teaching is proved in both theory and practice.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 10:23:53 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Liu", "Fuqaing", ""], ["Deng", "Chenwei", ""], ["Bi", "Fukun", ""], ["Yang", "Yiding", ""]]}, {"id": "1611.03993", "submitter": "Tengfei Zhou", "authors": "Tengfei Zhou, Hui Qian, Zebang Shen, Congfu Xu", "title": "Riemannian Tensor Completion with Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By restricting the iterate on a nonlinear manifold, the recently proposed\nRiemannian optimization methods prove to be both efficient and effective in low\nrank tensor completion problems. However, existing methods fail to exploit the\neasily accessible side information, due to their format mismatch. Consequently,\nthere is still room for improvement in such methods. To fill the gap, in this\npaper, a novel Riemannian model is proposed to organically integrate the\noriginal model and the side information by overcoming their inconsistency. For\nthis particular model, an efficient Riemannian conjugate gradient descent\nsolver is devised based on a new metric that captures the curvature of the\nobjective.Numerical experiments suggest that our solver is more accurate than\nthe state-of-the-art without compromising the efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 11:58:17 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 09:09:58 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Zhou", "Tengfei", ""], ["Qian", "Hui", ""], ["Shen", "Zebang", ""], ["Xu", "Congfu", ""]]}, {"id": "1611.04049", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Yan Jin, Heather Evans, Bill Lober, Xiaoning Qian, Ji Liu,\n  Shuai Huang", "title": "Prognostics of Surgical Site Infections using Dynamic Health Data", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Surgical Site Infection (SSI) is a national priority in healthcare research.\nMuch research attention has been attracted to develop better SSI risk\nprediction models. However, most of the existing SSI risk prediction models are\nbuilt on static risk factors such as comorbidities and operative factors. In\nthis paper, we investigate the use of the dynamic wound data for SSI risk\nprediction. There have been emerging mobile health (mHealth) tools that can\nclosely monitor the patients and generate continuous measurements of many\nwound-related variables and other evolving clinical variables. Since existing\nprediction models of SSI have quite limited capacity to utilize the evolving\nclinical data, we develop the corresponding solution to equip these mHealth\ntools with decision-making capabilities for SSI prediction with a seamless\nassembly of several machine learning models to tackle the analytic challenges\narising from the spatial-temporal data. The basic idea is to exploit the\nlow-rank property of the spatial-temporal data via the bilinear formulation,\nand further enhance it with automatic missing data imputation by the matrix\ncompletion technique. We derive efficient optimization algorithms to implement\nthese models and demonstrate the superior performances of our new predictive\nmodel on a real-world dataset of SSI, compared to a range of state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 22:08:15 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Ke", "Chuyang", ""], ["Jin", "Yan", ""], ["Evans", "Heather", ""], ["Lober", "Bill", ""], ["Qian", "Xiaoning", ""], ["Liu", "Ji", ""], ["Huang", "Shuai", ""]]}, {"id": "1611.04051", "submitter": "Matthew Kusner", "authors": "Matt J. Kusner, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "GANS for Sequences of Discrete Elements with the Gumbel-softmax\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have limitations when the goal is to\ngenerate sequences of discrete elements. The reason for this is that samples\nfrom a distribution on discrete objects such as the multinomial are not\ndifferentiable with respect to the distribution parameters. This problem can be\navoided by using the Gumbel-softmax distribution, which is a continuous\napproximation to a multinomial distribution parameterized in terms of the\nsoftmax function. In this work, we evaluate the performance of GANs based on\nrecurrent neural networks with Gumbel-softmax output distributions in the task\nof generating sequences of discrete elements.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 22:54:45 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Kusner", "Matt J.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1611.04069", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar, Brian E. Moore, Raj Rao Nadakuditi, and Jeffrey\n  A. Fessler", "title": "Low-rank and Adaptive Sparse Signal (LASSI) Models for Highly\n  Accelerated Dynamic Imaging", "comments": null, "journal-ref": "IEEE Tr. Med. Imaging 36(5):1116-28 May 2017", "doi": "10.1109/TMI.2017.2650960", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-based approaches have been popular in many applications in image\nprocessing and imaging. Compressed sensing exploits the sparsity of images in a\ntransform domain or dictionary to improve image recovery from undersampled\nmeasurements. In the context of inverse problems in dynamic imaging, recent\nresearch has demonstrated the promise of sparsity and low-rank techniques. For\nexample, the patches of the underlying data are modeled as sparse in an\nadaptive dictionary domain, and the resulting image and dictionary estimation\nfrom undersampled measurements is called dictionary-blind compressed sensing,\nor the dynamic image sequence is modeled as a sum of low-rank and sparse (in\nsome transform domain) components (L+S model) that are estimated from limited\nmeasurements. In this work, we investigate a data-adaptive extension of the L+S\nmodel, dubbed LASSI, where the temporal image sequence is decomposed into a\nlow-rank component and a component whose spatiotemporal (3D) patches are sparse\nin some adaptive dictionary domain. We investigate various formulations and\nefficient methods for jointly estimating the underlying dynamic signal\ncomponents and the spatiotemporal dictionary from limited measurements. We also\nobtain efficient sparsity penalized dictionary-blind compressed sensing methods\nas special cases of our LASSI approaches. Our numerical experiments demonstrate\nthe promising performance of LASSI schemes for dynamic magnetic resonance image\nreconstruction from limited k-t space data compared to recent methods such as\nk-t SLR and L+S, and compared to the proposed dictionary-blind compressed\nsensing method.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 02:21:07 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 10:27:05 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Moore", "Brian E.", ""], ["Nadakuditi", "Raj Rao", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1611.04088", "submitter": "Tarun Kathuria", "authors": "Tarun Kathuria, Amit Deshpande, Pushmeet Kohli", "title": "Batched Gaussian Process Bandit Optimization via Determinantal Point\n  Processes", "comments": "To appear at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process bandit optimization has emerged as a powerful tool for\noptimizing noisy black box functions. One example in machine learning is\nhyper-parameter optimization where each evaluation of the target function\nrequires training a model which may involve days or even weeks of computation.\nMost methods for this so-called \"Bayesian optimization\" only allow sequential\nexploration of the parameter space. However, it is often desirable to propose\nbatches or sets of parameter values to explore simultaneously, especially when\nthere are large parallel processing facilities at our disposal. Batch methods\nrequire modeling the interaction between the different evaluations in the\nbatch, which can be expensive in complex scenarios. In this paper, we propose a\nnew approach for parallelizing Bayesian optimization by modeling the diversity\nof a batch via Determinantal point processes (DPPs) whose kernels are learned\nautomatically. This allows us to generalize a previous result as well as prove\nbetter regret bounds based on DPP sampling. Our experiments on a variety of\nsynthetic and real-world robotics and hyper-parameter optimization tasks\nindicate that our DPP-based methods, especially those based on DPP sampling,\noutperform state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 05:52:58 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Kathuria", "Tarun", ""], ["Deshpande", "Amit", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1611.04149", "submitter": "Zebang Shen", "authors": "Zebang Shen, Hui Qian, Chao Zhang, and Tengfei Zhou", "title": "Accelerated Variance Reduced Block Coordinate Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms with fast convergence, small number of data access, and low\nper-iteration complexity are particularly favorable in the big data era, due to\nthe demand for obtaining \\emph{highly accurate solutions} to problems with\n\\emph{a large number of samples} in \\emph{ultra-high} dimensional space.\nExisting algorithms lack at least one of these qualities, and thus are\ninefficient in handling such big data challenge. In this paper, we propose a\nmethod enjoying all these merits with an accelerated convergence rate\n$O(\\frac{1}{k^2})$. Empirical studies on large scale datasets with more than\none million features are conducted to show the effectiveness of our methods in\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 16:01:10 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Shen", "Zebang", ""], ["Qian", "Hui", ""], ["Zhang", "Chao", ""], ["Zhou", "Tengfei", ""]]}, {"id": "1611.04199", "submitter": "Michael Lash", "authors": "Michael T. Lash and W. Nick Street", "title": "Realistic risk-mitigating recommendations via inverse classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse classification, the process of making meaningful perturbations to a\ntest point such that it is more likely to have a desired classification, has\npreviously been addressed using data from a single static point in time. Such\nan approach yields inflated probability estimates, stemming from an implicitly\nmade assumption that recommendations are implemented instantaneously. We\npropose using longitudinal data to alleviate such issues in two ways. First, we\nuse past outcome probabilities as features in the present. Use of such past\nprobabilities ties historical behavior to the present, allowing for more\ninformation to be taken into account when making initial probability estimates\nand subsequently performing inverse classification. Secondly, following inverse\nclassification application, optimized instances' unchangeable features\n(e.g.,~age) are updated using values from the next longitudinal time period.\nOptimized test instance probabilities are then reassessed. Updating the\nunchangeable features in this manner reflects the notion that improvements in\noutcome likelihood, which result from following the inverse classification\nrecommendations, do not materialize instantaneously. As our experiments\ndemonstrate, more realistic estimates of probability can be obtained by\nfactoring in such considerations.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 22:53:51 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Lash", "Michael T.", ""], ["Street", "W. Nick", ""]]}, {"id": "1611.04201", "submitter": "Fereshteh Sadeghi", "authors": "Fereshteh Sadeghi and Sergey Levine", "title": "CAD2RL: Real Single-Image Flight without a Single Real Image", "comments": "To appear at Robotics: Science and Systems Conference (R:SS), 2017.\n  Supplementary video: https://www.youtube.com/watch?v=nXBWmzFrj5s", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has emerged as a promising and powerful technique\nfor automatically acquiring control policies that can process raw sensory\ninputs, such as images, and perform complex behaviors. However, extending deep\nRL to real-world robotic tasks has proven challenging, particularly in\nsafety-critical domains such as autonomous flight, where a trial-and-error\nlearning process is often impractical. In this paper, we explore the following\nquestion: can we train vision-based navigation policies entirely in simulation,\nand then transfer them into the real world to achieve real-world flight without\na single real training image? We propose a learning method that we call\nCAD$^2$RL, which can be used to perform collision-free indoor flight in the\nreal world while being trained entirely on 3D CAD models. Our method uses\nsingle RGB images from a monocular camera, without needing to explicitly\nreconstruct the 3D geometry of the environment or perform explicit motion\nplanning. Our learned collision avoidance policy is represented by a deep\nconvolutional neural network that directly processes raw monocular images and\noutputs velocity commands. This policy is trained entirely on simulated images,\nwith a Monte Carlo policy evaluation algorithm that directly optimizes the\nnetwork's ability to produce collision-free flight. By highly randomizing the\nrendering settings for our simulated training set, we show that we can train a\npolicy that generalizes to the real world, without requiring the simulator to\nbe particularly realistic or high-fidelity. We evaluate our method by flying a\nreal quadrotor through indoor environments, and further evaluate the design\nchoices in our simulator through a series of ablation studies on depth\nprediction. For supplementary video see: https://youtu.be/nXBWmzFrj5s\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 23:08:42 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 20:48:48 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 11:47:41 GMT"}, {"version": "v4", "created": "Thu, 8 Jun 2017 07:21:39 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Sadeghi", "Fereshteh", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.04218", "submitter": "Suriya Gunasekar", "authors": "Suriya Gunasekar, Oluwasanmi Koyejo, Joydeep Ghosh", "title": "Preference Completion from Partial Rankings", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel and efficient algorithm for the collaborative preference\ncompletion problem, which involves jointly estimating individualized rankings\nfor a set of entities over a shared set of items, based on a limited number of\nobserved affinity values. Our approach exploits the observation that while\npreferences are often recorded as numerical scores, the predictive quantity of\ninterest is the underlying rankings. Thus, attempts to closely match the\nrecorded scores may lead to overfitting and impair generalization performance.\nInstead, we propose an estimator that directly fits the underlying preference\norder, combined with nuclear norm constraints to encourage low--rank\nparameters. Besides (approximate) correctness of the ranking order, the\nproposed estimator makes no generative assumption on the numerical scores of\nthe observations. One consequence is that the proposed estimator can fit any\nconsistent partial ranking over a subset of the items represented as a directed\nacyclic graph (DAG), generalizing standard techniques that can only fit\npreference scores. Despite this generality, for supervision representing total\nor blockwise total orders, the computational complexity of our algorithm is\nwithin a $\\log$ factor of the standard algorithms for nuclear norm\nregularization based estimates for matrix completion. We further show promising\nempirical results for a novel and challenging application of collaboratively\nranking of the associations between brain--regions and cognitive neuroscience\nterms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 01:17:14 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Gunasekar", "Suriya", ""], ["Koyejo", "Oluwasanmi", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1611.04228", "submitter": "Aseem Wadhwa", "authors": "Aseem Wadhwa and Upamanyu Madhow", "title": "Learning Sparse, Distributed Representations using the Hebbian Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"fire together, wire together\" Hebbian model is a central principle for\nlearning in neuroscience, but surprisingly, it has found limited applicability\nin modern machine learning. In this paper, we take a first step towards\nbridging this gap, by developing flavors of competitive Hebbian learning which\nproduce sparse, distributed neural codes using online adaptation with minimal\ntuning. We propose an unsupervised algorithm, termed Adaptive Hebbian Learning\n(AHL). We illustrate the distributed nature of the learned representations via\noutput entropy computations for synthetic data, and demonstrate superior\nperformance, compared to standard alternatives such as autoencoders, in\ntraining a deep convolutional net on standard image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:28:13 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Wadhwa", "Aseem", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "1611.04231", "submitter": "Tengyu Ma", "authors": "Moritz Hardt and Tengyu Ma", "title": "Identity Matters in Deep Learning", "comments": "ICLR 2017; fixed minor typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging design principle in deep learning is that each layer of a deep\nartificial neural network should be able to easily express the identity\ntransformation. This idea not only motivated various normalization techniques,\nsuch as \\emph{batch normalization}, but was also key to the immense success of\n\\emph{residual networks}.\n  In this work, we put the principle of \\emph{identity parameterization} on a\nmore solid theoretical footing alongside further empirical progress. We first\ngive a strikingly simple proof that arbitrarily deep linear residual networks\nhave no spurious local optima. The same result for linear feed-forward networks\nin their standard parameterization is substantially more delicate. Second, we\nshow that residual networks with ReLu activations have universal finite-sample\nexpressivity in the sense that the network can represent any function of its\nsample provided that the model has more parameters than the sample size.\n  Directly inspired by our theory, we experiment with a radically simple\nresidual architecture consisting of only residual convolutional layers and ReLu\nactivations, but no batch normalization, dropout, or max pool. Our model\nimproves significantly on previous all-convolutional networks on the CIFAR10,\nCIFAR100, and ImageNet classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:44:18 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2016 11:39:00 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 04:38:23 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Hardt", "Moritz", ""], ["Ma", "Tengyu", ""]]}, {"id": "1611.04273", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, Roger Grosse", "title": "On the Quantitative Analysis of Decoder-Based Generative Models", "comments": "Accepted to ICLR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past several years have seen remarkable progress in generative models\nwhich produce convincing samples of images and other modalities. A shared\ncomponent of many powerful generative models is a decoder network, a parametric\ndeep neural net that defines a generative distribution. Examples include\nvariational autoencoders, generative adversarial networks, and generative\nmoment matching networks. Unfortunately, it can be difficult to quantify the\nperformance of these models because of the intractability of log-likelihood\nestimation, and inspecting samples can be misleading. We propose to use\nAnnealed Importance Sampling for evaluating log-likelihoods for decoder-based\nmodels and validate its accuracy using bidirectional Monte Carlo. The\nevaluation code is provided at https://github.com/tonywu95/eval_gen. Using this\ntechnique, we analyze the performance of decoder-based models, the\neffectiveness of existing log-likelihood estimators, the degree of overfitting,\nand the degree to which these models miss important modes of the data\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 07:36:22 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 22:36:35 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Wu", "Yuhuai", ""], ["Burda", "Yuri", ""], ["Salakhutdinov", "Ruslan", ""], ["Grosse", "Roger", ""]]}, {"id": "1611.04361", "submitter": "Marek Rei", "authors": "Marek Rei, Gamal K.O. Crichton, Sampo Pyysalo", "title": "Attending to Characters in Neural Sequence Labeling Models", "comments": "Proceedings of COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 12:36:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Rei", "Marek", ""], ["Crichton", "Gamal K. O.", ""], ["Pyysalo", "Sampo", ""]]}, {"id": "1611.04416", "submitter": "Alexis Roche", "authors": "Alexis Roche", "title": "On numerical approximation schemes for expectation propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several numerical approximation strategies for the expectation-propagation\nalgorithm are studied in the context of large-scale learning: the Laplace\nmethod, a faster variant of it, Gaussian quadrature, and a deterministic\nversion of variational sampling (i.e., combining quadrature with variational\napproximation). Experiments in training linear binary classifiers show that the\nexpectation-propagation algorithm converges best using variational sampling,\nwhile it also converges well using Laplace-style methods with smooth factors\nbut tends to be unstable with non-differentiable ones. Gaussian quadrature\nyields unstable behavior or convergence to a sub-optimal solution in most\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 15:21:23 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Roche", "Alexis", ""]]}, {"id": "1611.04488", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De,\n  Aaditya Ramdas, Alex Smola, Arthur Gretton", "title": "Generative Models and Model Criticism via Optimized Maximum Mean\n  Discrepancy", "comments": "Published at ICLR 2017 (public comments:\n  http://openreview.net/forum?id=HJWHIKqgl )", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to optimize the representation and distinguishability of\nsamples from two probability distributions, by maximizing the estimated power\nof a statistical test based on the maximum mean discrepancy (MMD). This\noptimized MMD is applied to the setting of unsupervised learning by generative\nadversarial networks (GAN), in which a model attempts to generate realistic\nsamples, and a discriminator attempts to tell these apart from data samples. In\nthis context, the MMD may be used in two roles: first, as a discriminator,\neither directly on the samples, or on features of the samples. Second, the MMD\ncan be used to evaluate the performance of a generative model, by testing the\nmodel's samples against a reference data set. In the latter role, the optimized\nMMD is particularly helpful, as it gives an interpretable indication of how the\nmodel and data distributions differ, even in cases where individual model\nsamples are not easily distinguished either by eye or by classifier.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:28:27 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 13:07:50 GMT"}, {"version": "v3", "created": "Thu, 17 Nov 2016 20:30:37 GMT"}, {"version": "v4", "created": "Fri, 10 Feb 2017 18:28:49 GMT"}, {"version": "v5", "created": "Thu, 6 Jun 2019 19:54:37 GMT"}, {"version": "v6", "created": "Thu, 14 Jan 2021 06:14:42 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""], ["Tung", "Hsiao-Yu", ""], ["Strathmann", "Heiko", ""], ["De", "Soumyajit", ""], ["Ramdas", "Aaditya", ""], ["Smola", "Alex", ""], ["Gretton", "Arthur", ""]]}, {"id": "1611.04499", "submitter": "Thomas Moreau", "authors": "Thomas Moreau and Julien Audiffren", "title": "Post Training in Deep Learning with Last Kernel", "comments": "submitted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges of deep learning methods is the choice of an\nappropriate training strategy. In particular, additional steps, such as\nunsupervised pre-training, have been shown to greatly improve the performances\nof deep structures. In this article, we propose an extra training step, called\npost-training, which only optimizes the last layer of the network. We show that\nthis procedure can be analyzed in the context of kernel theory, with the first\nlayers computing an embedding of the data and the last layer a statistical\nmodel to solve the task based on this embedding. This step makes sure that the\nembedding, or representation, of the data is used in the best possible way for\nthe considered task. This idea is then tested on multiple architectures with\nvarious data sets, showing that it consistently provides a boost in\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:54:28 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:25:13 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Moreau", "Thomas", ""], ["Audiffren", "Julien", ""]]}, {"id": "1611.04500", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Jeff Schneider and Barnabas Poczos", "title": "Deep Learning with Sets and Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple permutation equivariant layer for deep learning with\nset structure.This type of layer, obtained by parameter-sharing, has a simple\nimplementation and linear-time complexity in the size of each set. We use deep\npermutation-invariant networks to perform point-could classification and\nMNIST-digit summation, where in both cases the output is invariant to\npermutations of the input. In a semi-supervised setting, where the goal is make\npredictions for each instance within a set, we demonstrate the usefulness of\nthis type of layer in set-outlier detection as well as semi-supervised learning\nwith clustering side-information.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:55:34 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 22:01:55 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 01:54:59 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1611.04520", "submitter": "Mengye Ren", "authors": "Mengye Ren, Renjie Liao, Raquel Urtasun, Fabian H. Sinz, Richard S.\n  Zemel", "title": "Normalizing the Normalizers: Comparing and Extending Network\n  Normalization Schemes", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization techniques have only recently begun to be exploited in\nsupervised learning tasks. Batch normalization exploits mini-batch statistics\nto normalize the activations. This was shown to speed up training and result in\nbetter models. However its success has been very limited when dealing with\nrecurrent neural networks. On the other hand, layer normalization normalizes\nthe activations across all activities within a layer. This was shown to work\nwell in the recurrent setting. In this paper we propose a unified view of\nnormalization techniques, as forms of divisive normalization, which includes\nlayer and batch normalization as special cases. Our second contribution is the\nfinding that a small modification to these normalization schemes, in\nconjunction with a sparse regularizer on the activations, leads to significant\nbenefits over standard normalization techniques. We demonstrate the\neffectiveness of our unified divisive normalization framework in the context of\nconvolutional neural nets and recurrent neural networks, showing improvements\nover baselines in image classification, language modeling as well as\nsuper-resolution.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 19:04:58 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 21:03:03 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Ren", "Mengye", ""], ["Liao", "Renjie", ""], ["Urtasun", "Raquel", ""], ["Sinz", "Fabian H.", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1611.04528", "submitter": "Yanbo Xue", "authors": "Dmytro Korenkevych, Yanbo Xue, Zhengbing Bian, Fabian Chudak, William\n  G. Macready, Jason Rolfe, Evgeny Andriyash", "title": "Benchmarking Quantum Hardware for Training of Fully Visible Boltzmann\n  Machines", "comments": "22 pages, 13 figures, D-Wave quantum system for sampling Boltzmann\n  machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum annealing (QA) is a hardware-based heuristic optimization and\nsampling method applicable to discrete undirected graphical models. While\nsimilar to simulated annealing, QA relies on quantum, rather than thermal,\neffects to explore complex search spaces. For many classes of problems, QA is\nknown to offer computational advantages over simulated annealing. Here we\nreport on the ability of recent QA hardware to accelerate training of fully\nvisible Boltzmann machines. We characterize the sampling distribution of QA\nhardware, and show that in many cases, the quantum distributions differ\nsignificantly from classical Boltzmann distributions. In spite of this\ndifference, training (which seeks to match data and model statistics) using\nstandard classical gradient updates is still effective. We investigate the use\nof QA for seeding Markov chains as an alternative to contrastive divergence\n(CD) and persistent contrastive divergence (PCD). Using $k=50$ Gibbs steps, we\nshow that for problems with high-energy barriers between modes, QA-based seeds\ncan improve upon chains with CD and PCD initializations. For these hard\nproblems, QA gradient estimates are more accurate, and allow for faster\nlearning. Furthermore, and interestingly, even the case of raw QA samples (that\nis, $k=0$) achieved similar improvements. We argue that this relates to the\nfact that we are training a quantum rather than classical Boltzmann\ndistribution in this case. The learned parameters give rise to hardware QA\ndistributions closely approximating classical Boltzmann distributions that are\nhard to train with CD/PCD.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 19:15:57 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Korenkevych", "Dmytro", ""], ["Xue", "Yanbo", ""], ["Bian", "Zhengbing", ""], ["Chudak", "Fabian", ""], ["Macready", "William G.", ""], ["Rolfe", "Jason", ""], ["Andriyash", "Evgeny", ""]]}, {"id": "1611.04535", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, and Colin\n  White", "title": "Learning-Theoretic Foundations of Algorithm Configuration for\n  Combinatorial Partitioning Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-cut, clustering, and many other partitioning problems that are of\nsignificant importance to machine learning and other scientific fields are\nNP-hard, a reality that has motivated researchers to develop a wealth of\napproximation algorithms and heuristics. Although the best algorithm to use\ntypically depends on the specific application domain, a worst-case analysis is\noften used to compare algorithms. This may be misleading if worst-case\ninstances occur infrequently, and thus there is a demand for optimization\nmethods which return the algorithm configuration best suited for the given\napplication's typical inputs. We address this problem for clustering, max-cut,\nand other partitioning problems, such as integer quadratic programming, by\ndesigning computationally efficient and sample efficient learning algorithms\nwhich receive samples from an application-specific distribution over problem\ninstances and learn a partitioning algorithm with high expected performance.\nOur algorithms learn over common integer quadratic programming and clustering\nalgorithm families: SDP rounding algorithms and agglomerative clustering\nalgorithms with dynamic programming. For our sample complexity analysis, we\nprovide tight bounds on the pseudodimension of these algorithm classes, and\nshow that surprisingly, even for classes of algorithms parameterized by a\nsingle parameter, the pseudo-dimension is superconstant. In this way, our work\nboth contributes to the foundations of algorithm configuration and pushes the\nboundaries of learning theory, since the algorithm classes we analyze consist\nof multi-stage optimization procedures and are significantly more complex than\nclasses typically studied in learning theory.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 19:22:21 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 23:57:09 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 10:08:24 GMT"}, {"version": "v4", "created": "Tue, 16 Oct 2018 16:07:08 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Nagarajan", "Vaishnavh", ""], ["Vitercik", "Ellen", ""], ["White", "Colin", ""]]}, {"id": "1611.04561", "submitter": "Tal Galili", "authors": "Tal Galili, Isaac Meilijson", "title": "Splitting matters: how monotone transformation of predictor variables\n  may improve the predictions of decision tree models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that the prediction accuracy of decision tree models is\ninvariant under any strictly monotone transformation of the individual\npredictor variables. However, this statement may be false when predicting new\nobservations with values that were not seen in the training-set and are close\nto the location of the split point of a tree rule. The sensitivity of the\nprediction error to the split point interpolation is high when the split point\nof the tree is estimated based on very few observations, reaching 9%\nmisclassification error when only 10 observations are used for constructing a\nsplit, and shrinking to 1% when relying on 100 observations. This study\ncompares the performance of alternative methods for split point interpolation\nand concludes that the best choice is taking the mid-point between the two\nclosest points to the split point of the tree. Furthermore, if the (continuous)\ndistribution of the predictor variable is known, then using its probability\nintegral for transforming the variable (\"quantile transformation\") will reduce\nthe model's interpolation error by up to about a half on average. Accordingly,\nthis study provides guidelines for both developers and users of decision tree\nmodels (including bagging and random forest).\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 20:34:29 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Galili", "Tal", ""], ["Meilijson", "Isaac", ""]]}, {"id": "1611.04578", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Changyou Chen, Wenqi Wang, Piyush Rai, Lawrence Carin", "title": "Earliness-Aware Deep Convolutional Networks for Early Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Earliness-Aware Deep Convolutional Networks (EA-ConvNets), an\nend-to-end deep learning framework, for early classification of time series\ndata. Unlike most existing methods for early classification of time series\ndata, that are designed to solve this problem under the assumption of the\navailability of a good set of pre-defined (often hand-crafted) features, our\nframework can jointly perform feature learning (by learning a deep hierarchy of\n\\emph{shapelets} capturing the salient characteristics in each time series),\nalong with a dynamic truncation model to help our deep feature learning\narchitecture focus on the early parts of each time series. Consequently, our\nframework is able to make highly reliable early predictions, outperforming\nvarious state-of-the-art methods for early time series classification, while\nalso being competitive when compared to the state-of-the-art time series\nclassification algorithms that work with \\emph{fully observed} time series\ndata. To the best of our knowledge, the proposed framework is the first to\nperform data-driven (deep) feature learning in the context of early\nclassification of time series data. We perform a comprehensive set of\nexperiments, on several benchmark data sets, which demonstrate that our method\nyields significantly better predictions than various state-of-the-art methods\ndesigned for early time series classification. In addition to obtaining high\naccuracies, our experiments also show that the learned deep shapelets based\nfeatures are also highly interpretable and can help gain better understanding\nof the underlying characteristics of time series data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 20:55:33 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Wang", "Wenlin", ""], ["Chen", "Changyou", ""], ["Wang", "Wenqi", ""], ["Rai", "Piyush", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.04581", "submitter": "Peter Jin", "authors": "Peter H. Jin, Qiaochu Yuan, Forrest Iandola, Kurt Keutzer", "title": "How to scale distributed deep learning?", "comments": "Extended version of paper accepted at ML Sys 2016 (at NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training time on large datasets for deep neural networks is the principal\nworkflow bottleneck in a number of important applications of deep learning,\nsuch as object classification and detection in automatic driver assistance\nsystems (ADAS). To minimize training time, the training of a deep neural\nnetwork must be scaled beyond a single machine to as many machines as possible\nby distributing the optimization method used for training. While a number of\napproaches have been proposed for distributed stochastic gradient descent\n(SGD), at the current time synchronous approaches to distributed SGD appear to\nbe showing the greatest performance at large scale. Synchronous scaling of SGD\nsuffers from the need to synchronize all processors on each gradient step and\nis not resilient in the face of failing or lagging processors. In asynchronous\napproaches using parameter servers, training is slowed by contention to the\nparameter server. In this paper we compare the convergence of synchronous and\nasynchronous SGD for training a modern ResNet network architecture on the\nImageNet classification problem. We also propose an asynchronous method,\ngossiping SGD, that aims to retain the positive features of both systems by\nreplacing the all-reduce collective operation of synchronous training with a\ngossip aggregation algorithm. We find, perhaps counterintuitively, that\nasynchronous SGD, including both elastic averaging and gossiping, converges\nfaster at fewer nodes (up to about 32 nodes), whereas synchronous SGD scales\nbetter to more nodes (up to about 100 nodes).\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 20:59:54 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Jin", "Peter H.", ""], ["Yuan", "Qiaochu", ""], ["Iandola", "Forrest", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1611.04642", "submitter": "Po-Sen Huang", "authors": "Yelong Shen, Po-Sen Huang, Ming-Wei Chang, Jianfeng Gao", "title": "Link Prediction using Embedded Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since large knowledge bases are typically incomplete, missing facts need to\nbe inferred from observed facts in a task called knowledge base completion. The\nmost successful approaches to this task have typically explored explicit paths\nthrough sequences of triples. These approaches have usually resorted to\nhuman-designed sampling procedures, since large knowledge graphs produce\nprohibitively large numbers of possible paths, most of which are uninformative.\nAs an alternative approach, we propose performing a single, short sequence of\ninteractive lookup operations on an embedded knowledge graph which has been\ntrained through end-to-end backpropagation to be an optimized and compressed\nversion of the initial knowledge base. Our proposed model, called Embedded\nKnowledge Graph Network (EKGN), achieves new state-of-the-art results on\npopular knowledge base completion benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 22:54:45 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 19:46:44 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 03:02:10 GMT"}, {"version": "v4", "created": "Wed, 8 Nov 2017 18:59:19 GMT"}, {"version": "v5", "created": "Sun, 22 Apr 2018 05:22:58 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Shen", "Yelong", ""], ["Huang", "Po-Sen", ""], ["Chang", "Ming-Wei", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1611.04666", "submitter": "Steffen Rendle", "authors": "Immanuel Bayer, Xiangnan He, Bhargav Kanagal, Steffen Rendle", "title": "A Generic Coordinate Descent Framework for Learning from Implicit\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, interest in recommender research has shifted from explicit\nfeedback towards implicit feedback data. A diversity of complex models has been\nproposed for a wide variety of applications. Despite this, learning from\nimplicit feedback is still computationally challenging. So far, most work\nrelies on stochastic gradient descent (SGD) solvers which are easy to derive,\nbut in practice challenging to apply, especially for tasks with many items. For\nthe simple matrix factorization model, an efficient coordinate descent (CD)\nsolver has been previously proposed. However, efficient CD approaches have not\nbeen derived for more complex models.\n  In this paper, we provide a new framework for deriving efficient CD\nalgorithms for complex recommender models. We identify and introduce the\nproperty of k-separable models. We show that k-separability is a sufficient\nproperty to allow efficient optimization of implicit recommender problems with\nCD. We illustrate this framework on a variety of state-of-the-art models\nincluding factorization machines and Tucker decomposition. To summarize, our\nwork provides the theory and building blocks to derive efficient implicit CD\nalgorithms for complex recommender models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 01:32:33 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Bayer", "Immanuel", ""], ["He", "Xiangnan", ""], ["Kanagal", "Bhargav", ""], ["Rendle", "Steffen", ""]]}, {"id": "1611.04686", "submitter": "Hang Zhang", "authors": "Hang Zhang, Fengyuan Zhu and Shixin Li", "title": "Robust Matrix Regression", "comments": "8 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern technologies are producing datasets with complex intrinsic structures,\nand they can be naturally represented as matrices instead of vectors. To\npreserve the latent data structures during processing, modern regression\napproaches incorporate the low-rank property to the model and achieve\nsatisfactory performance for certain applications. These approaches all assume\nthat both predictors and labels for each pair of data within the training set\nare accurate. However, in real-world applications, it is common to see the\ntraining data contaminated by noises, which can affect the robustness of these\nmatrix regression methods. In this paper, we address this issue by introducing\na novel robust matrix regression method. We also derive efficient proximal\nalgorithms for model training. To evaluate the performance of our methods, we\napply it to real world applications with comparative studies. Our method\nachieves the state-of-the-art performance, which shows the effectiveness and\nthe practical value of our method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 03:15:46 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Zhang", "Hang", ""], ["Zhu", "Fengyuan", ""], ["Li", "Shixin", ""]]}, {"id": "1611.04717", "submitter": "Haoran Tang", "authors": "Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, Xi Chen, Yan\n  Duan, John Schulman, Filip De Turck, Pieter Abbeel", "title": "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement\n  Learning", "comments": "10 pages main text + 10 pages supplementary. Published at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count-based exploration algorithms are known to perform near-optimally when\nused in conjunction with tabular reinforcement learning (RL) methods for\nsolving small discrete Markov decision processes (MDPs). It is generally\nthought that count-based methods cannot be applied in high-dimensional state\nspaces, since most states will only occur once. Recent deep RL exploration\nstrategies are able to deal with high-dimensional continuous state spaces\nthrough complex heuristics, often relying on optimism in the face of\nuncertainty or intrinsic motivation. In this work, we describe a surprising\nfinding: a simple generalization of the classic count-based approach can reach\nnear state-of-the-art performance on various high-dimensional and/or continuous\ndeep RL benchmarks. States are mapped to hash codes, which allows to count\ntheir occurrences with a hash table. These counts are then used to compute a\nreward bonus according to the classic count-based exploration theory. We find\nthat simple hash functions can achieve surprisingly good results on many\nchallenging tasks. Furthermore, we show that a domain-dependent learned hash\ncode may further improve these results. Detailed analysis reveals important\naspects of a good hash function: 1) having appropriate granularity and 2)\nencoding information relevant to solving the MDP. This exploration strategy\nachieves near state-of-the-art performance on both continuous control tasks and\nAtari 2600 games, hence providing a simple yet powerful baseline for solving\nMDPs that require considerable exploration.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 06:42:24 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2017 18:29:16 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 16:44:47 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Tang", "Haoran", ""], ["Houthooft", "Rein", ""], ["Foote", "Davis", ""], ["Stooke", "Adam", ""], ["Chen", "Xi", ""], ["Duan", "Yan", ""], ["Schulman", "John", ""], ["De Turck", "Filip", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1611.04786", "submitter": "Battista Biggio", "authors": "Igino Corona and Battista Biggio and Davide Maiorca", "title": "AdversariaLib: An Open-source Library for the Security Evaluation of\n  Machine Learning Algorithms Under Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AdversariaLib, an open-source python library for the security\nevaluation of machine learning (ML) against carefully-targeted attacks. It\nsupports the implementation of several attacks proposed thus far in the\nliterature of adversarial learning, allows for the evaluation of a wide range\nof ML algorithms, runs on multiple platforms, and has multi-processing enabled.\nThe library has a modular architecture that makes it easy to use and to extend\nby implementing novel attacks and countermeasures. It relies on other\nwidely-used open-source ML libraries, including scikit-learn and FANN.\nClassification algorithms are implemented and optimized in C/C++, allowing for\na fast evaluation of the simulated attacks. The package is distributed under\nthe GNU General Public License v3, and it is available for download at\nhttp://sourceforge.net/projects/adversarialib.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:54:58 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Corona", "Igino", ""], ["Biggio", "Battista", ""], ["Maiorca", "Davide", ""]]}, {"id": "1611.04831", "submitter": "Kfir Levy Yehuda", "authors": "Kfir Y. Levy", "title": "The Power of Normalization: Faster Evasion of Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A commonly used heuristic in non-convex optimization is Normalized Gradient\nDescent (NGD) - a variant of gradient descent in which only the direction of\nthe gradient is taken into account and its magnitude ignored. We analyze this\nheuristic and show that with carefully chosen parameters and noise injection,\nthis method can provably evade saddle points. We establish the convergence of\nNGD to a local minimum, and demonstrate rates which improve upon the fastest\nknown first order algorithm due to Ge e al. (2015).\n  The effectiveness of our method is demonstrated via an application to the\nproblem of online tensor decomposition; a task for which saddle point evasion\nis known to result in convergence to global minima.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 13:56:24 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Levy", "Kfir Y.", ""]]}, {"id": "1611.04835", "submitter": "Nauman Shahid", "authors": "Nauman Shahid, Francesco Grassi, Pierre Vandergheynst", "title": "Multilinear Low-Rank Tensors on Graphs & Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for the analysis of low-rank tensors which lies at\nthe intersection of spectral graph theory and signal processing. As a first\nstep, we present a new graph based low-rank decomposition which approximates\nthe classical low-rank SVD for matrices and multi-linear SVD for tensors. Then,\nbuilding on this novel decomposition we construct a general class of convex\noptimization problems for approximately solving low-rank tensor inverse\nproblems, such as tensor Robust PCA. The whole framework is named as\n'Multilinear Low-rank tensors on Graphs (MLRTG)'. Our theoretical analysis\nshows: 1) MLRTG stands on the notion of approximate stationarity of\nmulti-dimensional signals on graphs and 2) the approximation error depends on\nthe eigen gaps of the graphs. We demonstrate applications for a wide variety of\n4 artificial and 12 real tensor datasets, such as EEG, FMRI, BCI, surveillance\nvideos and hyperspectral images. Generalization of the tensor concepts to\nnon-euclidean domain, orders of magnitude speed-up, low-memory requirement and\nsignificantly enhanced performance at low SNR are the key aspects of our\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 14:05:43 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Shahid", "Nauman", ""], ["Grassi", "Francesco", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1611.04847", "submitter": "Arun Kadavankandy", "authors": "Arun Kadavankandy (MAESTRO), Konstantin Avrachenkov (MAESTRO), Laura\n  Cottatellucci, Rajesh Sundaresan (ECE)", "title": "The Power of Side-information in Subgraph Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we tackle the problem of hidden community detection. We\nconsider Belief Propagation (BP) applied to the problem of detecting a hidden\nErd\\H{o}s-R\\'enyi (ER) graph embedded in a larger and sparser ER graph, in the\npresence of side-information. We derive two related algorithms based on BP to\nperform subgraph detection in the presence of two kinds of side-information.\nThe first variant of side-information consists of a set of nodes, called cues,\nknown to be from the subgraph. The second variant of side-information consists\nof a set of nodes that are cues with a given probability. It was shown in past\nworks that BP without side-information fails to detect the subgraph correctly\nwhen an effective signal-to-noise ratio (SNR) parameter falls below a\nthreshold. In contrast, in the presence of non-trivial side-information, we\nshow that the BP algorithm achieves asymptotically zero error for any value of\nthe SNR parameter. We validate our results through simulations on synthetic\ndatasets as well as on a few real world networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 10:13:10 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 09:45:20 GMT"}, {"version": "v3", "created": "Mon, 6 Mar 2017 13:26:53 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Kadavankandy", "Arun", "", "MAESTRO"], ["Avrachenkov", "Konstantin", "", "MAESTRO"], ["Cottatellucci", "Laura", "", "ECE"], ["Sundaresan", "Rajesh", "", "ECE"]]}, {"id": "1611.04870", "submitter": "Ping Li PhD", "authors": "Ping Li and Jun Yu and Meng Wang and Luming Zhang and Deng Cai and\n  Xuelong Li", "title": "Constrained Low-Rank Learning Using Least Squares-Based Regularization", "comments": "14 pages, 7 figures, accepted to appear in IEEE Transactions on\n  Cybernetics", "journal-ref": "IEEE Transactions on Cybernetics, 2016", "doi": "10.1109/TCYB.2016.2623638", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank learning has attracted much attention recently due to its efficacy\nin a rich variety of real-world tasks, e.g., subspace segmentation and image\ncategorization. Most low-rank methods are incapable of capturing\nlow-dimensional subspace for supervised learning tasks, e.g., classification\nand regression. This paper aims to learn both the discriminant low-rank\nrepresentation (LRR) and the robust projecting subspace in a supervised manner.\nTo achieve this goal, we cast the problem into a constrained rank minimization\nframework by adopting the least squares regularization. Naturally, the data\nlabel structure tends to resemble that of the corresponding low-dimensional\nrepresentation, which is derived from the robust subspace projection of clean\ndata by low-rank learning. Moreover, the low-dimensional representation of\noriginal data can be paired with some informative structure by imposing an\nappropriate constraint, e.g., Laplacian regularizer. Therefore, we propose a\nnovel constrained LRR method. The objective function is formulated as a\nconstrained nuclear norm minimization problem, which can be solved by the\ninexact augmented Lagrange multiplier algorithm. Extensive experiments on image\nclassification, human pose estimation, and robust face recovery have confirmed\nthe superiority of our method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 14:50:31 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Li", "Ping", ""], ["Yu", "Jun", ""], ["Wang", "Meng", ""], ["Zhang", "Luming", ""], ["Cai", "Deng", ""], ["Li", "Xuelong", ""]]}, {"id": "1611.04871", "submitter": "Anurag Kumar", "authors": "Anurag Kumar, Bhiksha Raj", "title": "Audio Event and Scene Recognition: A Unified Approach using Strongly and\n  Weakly Labeled Data", "comments": "IJCNN 2017, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel learning framework called Supervised and\nWeakly Supervised Learning where the goal is to learn simultaneously from\nweakly and strongly labeled data. Strongly labeled data can be simply\nunderstood as fully supervised data where all labeled instances are available.\nIn weakly supervised learning only data is weakly labeled which prevents one\nfrom directly applying supervised learning methods. Our proposed framework is\nmotivated by the fact that a small amount of strongly labeled data can give\nconsiderable improvement over only weakly supervised learning. The primary\nproblem domain focus of this paper is acoustic event and scene detection in\naudio recordings. We first propose a naive formulation for leveraging labeled\ndata in both forms. We then propose a more general framework for Supervised and\nWeakly Supervised Learning (SWSL). Based on this general framework, we propose\na graph based approach for SWSL. Our main method is based on manifold\nregularization on graphs in which we show that the unified learning can be\nformulated as a constraint optimization problem which can be solved by\niterative concave-convex procedure (CCCP). Our experiments show that our\nproposed framework can address several concerns of audio content analysis using\nweakly labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 07:39:50 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 23:17:46 GMT"}, {"version": "v3", "created": "Sat, 18 Feb 2017 07:18:32 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Kumar", "Anurag", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1611.04920", "submitter": "Qinliang Su", "authors": "Qinliang Su, Xuejun Liao, Chunyuan Li, Zhe Gan, Lawrence Carin", "title": "Unsupervised Learning with Truncated Gaussian Graphical Models", "comments": "To appear in AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models (GGMs) are widely used for statistical modeling,\nbecause of ease of inference and the ubiquitous use of the normal distribution\nin practical approximations. However, they are also known for their limited\nmodeling abilities, due to the Gaussian assumption. In this paper, we introduce\na novel variant of GGMs, which relaxes the Gaussian restriction and yet admits\nefficient inference. Specifically, we impose a bipartite structure on the GGM\nand govern the hidden variables by truncated normal distributions. The\nnonlinearity of the model is revealed by its connection to rectified linear\nunit (ReLU) neural networks. Meanwhile, thanks to the bipartite structure and\nappealing properties of truncated normals, we are able to train the models\nefficiently using contrastive divergence. We consider three output constructs,\naccounting for real-valued, binary and count data. We further extend the model\nto deep constructions and show that deep models can be used for unsupervised\npre-training of rectifier neural networks. Extensive experimental results are\nprovided to validate the proposed models and demonstrate their superiority over\ncompeting models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 16:26:17 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 19:08:51 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Su", "Qinliang", ""], ["Liao", "Xuejun", ""], ["Li", "Chunyuan", ""], ["Gan", "Zhe", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.04924", "submitter": "Chia-Wen Lin", "authors": "Gene Cheung, Weng-Tai Su, Yu Mao, and Chia-Wen Lin", "title": "Robust Semi-Supervised Graph Classifier Learning with Negative Edge\n  Weights", "comments": "15 pages, revised for IEEE Transactions on Signal and Information\n  Processing over Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a semi-supervised learning scenario, (possibly noisy) partially observed\nlabels are used as input to train a classifier, in order to assign labels to\nunclassified samples. In this paper, we study this classifier learning problem\nfrom a graph signal processing (GSP) perspective. Specifically, by viewing a\nbinary classifier as a piecewise constant graph-signal in a high-dimensional\nfeature space, we cast classifier learning as a signal restoration problem via\na classical maximum a posteriori (MAP) formulation. Unlike previous\ngraph-signal restoration works, we consider in addition edges with negative\nweights that signify anti-correlation between samples. One unfortunate\nconsequence is that the graph Laplacian matrix $\\mathbf{L}$ can be indefinite,\nand previously proposed graph-signal smoothness prior $\\mathbf{x}^T \\mathbf{L}\n\\mathbf{x}$ for candidate signal $\\mathbf{x}$ can lead to pathological\nsolutions. In response, we derive an optimal perturbation matrix\n$\\boldsymbol{\\Delta}$ - based on a fast lower-bound computation of the minimum\neigenvalue of $\\mathbf{L}$ via a novel application of the Haynsworth inertia\nadditivity formula---so that $\\mathbf{L} + \\boldsymbol{\\Delta}$ is positive\nsemi-definite, resulting in a stable signal prior. Further, instead of forcing\na hard binary decision for each sample, we define the notion of generalized\nsmoothness on graph that promotes ambiguity in the classifier signal. Finally,\nwe propose an algorithm based on iterative reweighted least squares (IRLS) that\nsolves the posed MAP problem efficiently. Extensive simulation results show\nthat our proposed algorithm outperforms both SVM variants and graph-based\nclassifiers using positive-edge graphs noticeably.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 16:36:29 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 13:10:24 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Cheung", "Gene", ""], ["Su", "Weng-Tai", ""], ["Mao", "Yu", ""], ["Lin", "Chia-Wen", ""]]}, {"id": "1611.04967", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Lalana Kagal", "title": "Iterative Orthogonal Feature Projection for Diagnosing Bias in Black-Box\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are increasingly deployed for the purpose of determining\naccess to services such as credit, insurance, and employment. Despite potential\ngains in productivity and efficiency, several potential problems have yet to be\naddressed, particularly the potential for unintentional discrimination. We\npresent an iterative procedure, based on orthogonal projection of input\nattributes, for enabling interpretability of black-box predictive models.\nThrough our iterative procedure, one can quantify the relative dependence of a\nblack-box model on its input attributes.The relative significance of the inputs\nto a predictive model can then be used to assess the fairness (or\ndiscriminatory extent) of such a model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 18:10:24 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Adebayo", "Julius", ""], ["Kagal", "Lalana", ""]]}, {"id": "1611.04982", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani and Ohad Shamir", "title": "Oracle Complexity of Second-Order Methods for Finite-Sum Problems", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-sum optimization problems are ubiquitous in machine learning, and are\ncommonly solved using first-order methods which rely on gradient computations.\nRecently, there has been growing interest in \\emph{second-order} methods, which\nrely on both gradients and Hessians. In principle, second-order methods can\nrequire much fewer iterations than first-order methods, and hold the promise\nfor more efficient algorithms. Although computing and manipulating Hessians is\nprohibitive for high-dimensional problems in general, the Hessians of\nindividual functions in finite-sum problems can often be efficiently computed,\ne.g. because they possess a low-rank structure. Can second-order information\nindeed be used to solve such problems more efficiently? In this paper, we\nprovide evidence that the answer -- perhaps surprisingly -- is negative, at\nleast in terms of worst-case guarantees. However, we also discuss what\nadditional assumptions and algorithmic approaches might potentially circumvent\nthis negative result.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 18:41:55 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 11:05:59 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Arjevani", "Yossi", ""], ["Shamir", "Ohad", ""]]}, {"id": "1611.05013", "submitter": "Ishaan Gulrajani", "authors": "Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien Ali Taiga,\n  Francesco Visin, David Vazquez, Aaron Courville", "title": "PixelVAE: A Latent Variable Model for Natural Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural image modeling is a landmark challenge of unsupervised learning.\nVariational Autoencoders (VAEs) learn a useful latent representation and model\nglobal structure well but have difficulty capturing small details. PixelCNN\nmodels details very well, but lacks a latent code and is difficult to scale for\ncapturing large structures. We present PixelVAE, a VAE model with an\nautoregressive decoder based on PixelCNN. Our model requires very few expensive\nautoregressive layers compared to PixelCNN and learns latent codes that are\nmore compressed than a standard VAE while still capturing most non-trivial\nstructure. Finally, we extend our model to a hierarchy of latent variables at\ndifferent scales. Our model achieves state-of-the-art performance on binarized\nMNIST, competitive performance on 64x64 ImageNet, and high-quality samples on\nthe LSUN bedrooms dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 20:16:27 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Gulrajani", "Ishaan", ""], ["Kumar", "Kundan", ""], ["Ahmed", "Faruk", ""], ["Taiga", "Adrien Ali", ""], ["Visin", "Francesco", ""], ["Vazquez", "David", ""], ["Courville", "Aaron", ""]]}, {"id": "1611.05083", "submitter": "Ning Ge", "authors": "Ning Ge, Marc Pantel, Xavier Cr\\'egut", "title": "Probabilistic Failure Analysis in Model Validation & Verification", "comments": "In International Conference on Embedded Real Time Software and\n  Systems (ERTS 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated fault localization is an important issue in model validation and\nverification. It helps the end users in analyzing the origin of failure. In\nthis work, we show the early experiments with probabilistic analysis approaches\nin fault localization. Inspired by the Kullback-Leibler Divergence from\nBayesian probabilistic theory, we propose a suspiciousness factor to compute\nthe fault contribution for the transitions in the reachability graph of model\nchecking, using which to rank the potential faulty transitions. To\nautomatically locate design faults in the simulation model of detailed design,\nwe propose to use the statistical model Hidden Markov Model (HMM), which\nprovides statistically identical information to component's real behavior. The\ncore of this method is a fault localization algorithm that gives out the set of\nsuspicious ranked faulty components and a backward algorithm that computes the\nmatching degree between the HMM and the simulation model to evaluate the\nconfidence degree of the localization conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 22:33:48 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 11:37:29 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Ge", "Ning", ""], ["Pantel", "Marc", ""], ["Cr\u00e9gut", "Xavier", ""]]}, {"id": "1611.05095", "submitter": "Vikash Kumar", "authors": "Vikash Kumar, Abhishek Gupta, Emanuel Todorov and Sergey Levine", "title": "Learning Dexterous Manipulation Policies from Experience and Imitation", "comments": "Initial draft for a journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore learning-based approaches for feedback control of a dexterous\nfive-finger hand performing non-prehensile manipulation. First, we learn local\ncontrollers that are able to perform the task starting at a predefined initial\nstate. These controllers are constructed using trajectory optimization with\nrespect to locally-linear time-varying models learned directly from sensor\ndata. In some cases, we initialize the optimizer with human demonstrations\ncollected via teleoperation in a virtual environment. We demonstrate that such\ncontrollers can perform the task robustly, both in simulation and on the\nphysical platform, for a limited range of initial conditions around the trained\nstarting state. We then consider two interpolation methods for generalizing to\na wider range of initial conditions: deep learning, and nearest neighbors. We\nfind that nearest neighbors achieve higher performance. Nevertheless, the\nneural network has its advantages: it uses only tactile and proprioceptive\nfeedback but no visual feedback about the object (i.e. it performs the task\nblind) and learns a time-invariant policy. In contrast, the nearest neighbors\nmethod switches between time-varying local controllers based on the proximity\nof initial object states sensed via motion capture. While both generalization\nmethods leave room for improvement, our work shows that (i) local\ntrajectory-based controllers for complex non-prehensile manipulation tasks can\nbe constructed from surprisingly small amounts of training data, and (ii)\ncollections of such controllers can be interpolated to form more global\ncontrollers. Results are summarized in the supplementary video:\nhttps://youtu.be/E0wmO6deqjo\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 23:31:40 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kumar", "Vikash", ""], ["Gupta", "Abhishek", ""], ["Todorov", "Emanuel", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.05132", "submitter": "Cheng Tang", "authors": "Cheng Tang, Claire Monteleoni", "title": "Convergence rate of stochastic k-means", "comments": "arXiv admin note: substantial text overlap with arXiv:1610.04900", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze online \\cite{BottouBengio} and mini-batch \\cite{Sculley} $k$-means\nvariants. Both scale up the widely used $k$-means algorithm via stochastic\napproximation, and have become popular for large-scale clustering and\nunsupervised feature learning. We show, for the first time, that starting with\nany initial solution, they converge to a \"local optimum\" at rate\n$O(\\frac{1}{t})$ (in terms of the $k$-means objective) under general\nconditions. In addition, we show if the dataset is clusterable, when\ninitialized with a simple and scalable seeding algorithm, mini-batch $k$-means\nconverges to an optimal $k$-means solution at rate $O(\\frac{1}{t})$ with high\nprobability. The $k$-means objective is non-convex and non-differentiable: we\nexploit ideas from recent work on stochastic gradient descent for non-convex\nproblems \\cite{ge:sgd_tensor, balsubramani13} by providing a novel\ncharacterization of the trajectory of $k$-means algorithm on its solution\nspace, and circumvent the non-differentiability problem via geometric insights\nabout $k$-means update.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 03:28:08 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Tang", "Cheng", ""], ["Monteleoni", "Claire", ""]]}, {"id": "1611.05136", "submitter": "Mahtab J. Fard", "authors": "Mahtab J. Fard, Sattar Ameri, Ratna B. Chinnam, Abhilash K. Pandya,\n  Michael D. Klein, and R. Darin Ellis", "title": "Machine Learning Approach for Skill Evaluation in Robotic-Assisted\n  Surgery", "comments": null, "journal-ref": "Lecture Notes in Engineering and Computer Science: Proceedings of\n  The World Congress on Engineering and Computer Science 2016, 19-21 October,\n  2016, San Francisco, USA", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating surgeon skill has predominantly been a subjective task.\nDevelopment of objective methods for surgical skill assessment are of increased\ninterest. Recently, with technological advances such as robotic-assisted\nminimally invasive surgery (RMIS), new opportunities for objective and\nautomated assessment frameworks have arisen. In this paper, we applied machine\nlearning methods to automatically evaluate performance of the surgeon in RMIS.\nSix important movement features were used in the evaluation including\ncompletion time, path length, depth perception, speed, smoothness and\ncurvature. Different classification methods applied to discriminate expert and\nnovice surgeons. We test our method on real surgical data for suturing task and\ncompare the classification result with the ground truth data (obtained by\nmanual labeling). The experimental results show that the proposed framework can\nclassify surgical skill level with relatively high accuracy of 85.7%. This\nstudy demonstrates the ability of machine learning methods to automatically\nclassify expert and novice surgeons using movement features for different RMIS\ntasks. Due to the simplicity and generalizability of the introduced\nclassification method, it is easy to implement in existing trainers.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 03:45:12 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Fard", "Mahtab J.", ""], ["Ameri", "Sattar", ""], ["Chinnam", "Ratna B.", ""], ["Pandya", "Abhilash K.", ""], ["Klein", "Michael D.", ""], ["Ellis", "R. Darin", ""]]}, {"id": "1611.05138", "submitter": "Shuangfei Zhai", "authors": "Shuangfei Zhai, Hui Wu, Abhishek Kumar, Yu Cheng, Yongxi Lu, Zhongfei\n  Zhang, Rogerio Feris", "title": "S3Pool: Pooling with Stochastic Spatial Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature pooling layers (e.g., max pooling) in convolutional neural networks\n(CNNs) serve the dual purpose of providing increasingly abstract\nrepresentations as well as yielding computational savings in subsequent\nconvolutional layers. We view the pooling operation in CNNs as a two-step\nprocedure: first, a pooling window (e.g., $2\\times 2$) slides over the feature\nmap with stride one which leaves the spatial resolution intact, and second,\ndownsampling is performed by selecting one pixel from each non-overlapping\npooling window in an often uniform and deterministic (e.g., top-left) manner.\nOur starting point in this work is the observation that this regularly spaced\ndownsampling arising from non-overlapping windows, although intuitive from a\nsignal processing perspective (which has the goal of signal reconstruction), is\nnot necessarily optimal for \\emph{learning} (where the goal is to generalize).\nWe study this aspect and propose a novel pooling strategy with stochastic\nspatial sampling (S3Pool), where the regular downsampling is replaced by a more\ngeneral stochastic version. We observe that this general stochasticity acts as\na strong regularizer, and can also be seen as doing implicit data augmentation\nby introducing distortions in the feature maps. We further introduce a\nmechanism to control the amount of distortion to suit different datasets and\narchitectures. To demonstrate the effectiveness of the proposed approach, we\nperform extensive experiments on several popular image classification\nbenchmarks, observing excellent improvements over baseline models. Experimental\ncode is available at https://github.com/Shuangfei/s3pool.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 04:17:52 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhai", "Shuangfei", ""], ["Wu", "Hui", ""], ["Kumar", "Abhishek", ""], ["Cheng", "Yu", ""], ["Lu", "Yongxi", ""], ["Zhang", "Zhongfei", ""], ["Feris", "Rogerio", ""]]}, {"id": "1611.05141", "submitter": "Eric Hunsberger", "authors": "Eric Hunsberger, Chris Eliasmith", "title": "Training Spiking Deep Networks for Neuromorphic Hardware", "comments": "10 pages, 3 figures, 4 tables; the \"methods\" section of this article\n  draws heavily on arXiv:1510.08829", "journal-ref": null, "doi": "10.13140/RG.2.2.10967.06566", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method to train spiking deep networks that can be run using\nleaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results for\nspiking LIF networks on five datasets, including the large ImageNet ILSVRC-2012\nbenchmark. Our method for transforming deep artificial neural networks into\nspiking networks is scalable and works with a wide range of neural\nnonlinearities. We achieve these results by softening the neural response\nfunction, such that its derivative remains bounded, and by training the network\nwith noise to provide robustness against the variability introduced by spikes.\nOur analysis shows that implementations of these networks on neuromorphic\nhardware will be many times more power-efficient than the equivalent\nnon-spiking networks on traditional hardware.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 04:32:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Hunsberger", "Eric", ""], ["Eliasmith", "Chris", ""]]}, {"id": "1611.05146", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa, Jinsung Yoon, Scott Hu, Mihaela van der Schaar", "title": "A Semi-Markov Switching Linear Gaussian Model for Censored Physiological\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critically ill patients in regular wards are vulnerable to unanticipated\nclinical dete- rioration which requires timely transfer to the intensive care\nunit (ICU). To allow for risk scoring and patient monitoring in such a setting,\nwe develop a novel Semi- Markov Switching Linear Gaussian Model (SSLGM) for the\ninpatients' physiol- ogy. The model captures the patients' latent clinical\nstates and their corresponding observable lab tests and vital signs. We present\nan efficient unsupervised learn- ing algorithm that capitalizes on the\ninformatively censored data in the electronic health records (EHR) to learn the\nparameters of the SSLGM; the learned model is then used to assess the new\ninpatients' risk for clinical deterioration in an online fashion, allowing for\ntimely ICU admission. Experiments conducted on a het- erogeneous cohort of\n6,094 patients admitted to a large academic medical center show that the\nproposed model significantly outperforms the currently deployed risk scores\nsuch as Rothman index, MEWS, SOFA and APACHE.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 05:11:36 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["Yoon", "Jinsung", ""], ["Hu", "Scott", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1611.05162", "submitter": "Alireza Aghasi", "authors": "Alireza Aghasi, Afshin Abdi, Nam Nguyen, Justin Romberg", "title": "Net-Trim: Convex Pruning of Deep Neural Networks with Performance\n  Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze a new technique for model reduction for deep neural\nnetworks. While large networks are theoretically capable of learning\narbitrarily complex models, overfitting and model redundancy negatively affects\nthe prediction accuracy and model variance. Our Net-Trim algorithm prunes\n(sparsifies) a trained network layer-wise, removing connections at each layer\nby solving a convex optimization program. This program seeks a sparse set of\nweights at each layer that keeps the layer inputs and outputs consistent with\nthe originally trained model. The algorithms and associated analysis are\napplicable to neural networks operating with the rectified linear unit (ReLU)\nas the nonlinear activation. We present both parallel and cascade versions of\nthe algorithm. While the latter can achieve slightly simpler models with the\nsame generalization performance, the former can be computed in a distributed\nmanner. In both cases, Net-Trim significantly reduces the number of connections\nin the network, while also providing enough regularization to slightly reduce\nthe generalization error. We also provide a mathematical analysis of the\nconsistency between the initial network and the retrained model. To analyze the\nmodel sample complexity, we derive the general sufficient conditions for the\nrecovery of a sparse transform matrix. For a single layer taking independent\nGaussian random vectors of length $N$ as inputs, we show that if the network\nresponse can be described using a maximum number of $s$ non-zero weights per\nnode, these weights can be learned from $\\mathcal{O}(s\\log N)$ samples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 06:34:41 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 23:07:52 GMT"}, {"version": "v3", "created": "Sun, 19 Mar 2017 22:38:08 GMT"}, {"version": "v4", "created": "Thu, 23 Nov 2017 09:34:28 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Aghasi", "Alireza", ""], ["Abdi", "Afshin", ""], ["Nguyen", "Nam", ""], ["Romberg", "Justin", ""]]}, {"id": "1611.05181", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Eduardo Pavez, Antonio Ortega", "title": "Graph Learning from Data under Structural and Laplacian Constraints", "comments": "To appear in IEEE Journal of Selected Topics in Signal Processing.\n  The implementations of the algorithms proposed in this paper are available\n  at: https://github.com/STAC-USC/Graph_Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are fundamental mathematical structures used in various fields to\nrepresent data, signals and processes. In this paper, we propose a novel\nframework for learning/estimating graphs from data. The proposed framework\nincludes (i) formulation of various graph learning problems, (ii) their\nprobabilistic interpretations and (iii) associated algorithms. Specifically,\ngraph learning problems are posed as estimation of graph Laplacian matrices\nfrom some observed data under given structural constraints (e.g., graph\nconnectivity and sparsity level). From a probabilistic perspective, the\nproblems of interest correspond to maximum a posteriori (MAP) parameter\nestimation of Gaussian-Markov random field (GMRF) models, whose precision\n(inverse covariance) is a graph Laplacian matrix. For the proposed graph\nlearning problems, specialized algorithms are developed by incorporating the\ngraph Laplacian and structural constraints. The experimental results\ndemonstrate that the proposed algorithms outperform the current\nstate-of-the-art methods in terms of accuracy and computational efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 08:11:14 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 17:03:55 GMT"}, {"version": "v3", "created": "Thu, 6 Jul 2017 03:26:33 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Pavez", "Eduardo", ""], ["Ortega", "Antonio", ""]]}, {"id": "1611.05193", "submitter": "Jan Yperman", "authors": "Jan Yperman, Thijs Becker", "title": "Bayesian optimization of hyper-parameters in reservoir computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for searching the optimal hyper-parameters in reservoir\ncomputing, which consists of a Gaussian process with Bayesian optimization. It\nprovides an alternative to other frequently used optimization methods such as\ngrid, random, or manual search. In addition to a set of optimal\nhyper-parameters, the method also provides a probability distribution of the\ncost function as a function of the hyper-parameters. We apply this method to\ntwo types of reservoirs: nonlinear delay nodes and echo state networks. It\nshows excellent performance on all considered benchmarks, either matching or\nsignificantly surpassing results found in the literature. In general, the\nalgorithm achieves optimal results in fewer iterations when compared to other\noptimization methods. We have optimized up to six hyper-parameters\nsimultaneously, which would have been infeasible using, e.g., grid search. Due\nto its automated nature, this method significantly reduces the need for expert\nknowledge when optimizing the hyper-parameters in reservoir computing. Existing\nsoftware libraries for Bayesian optimization, such as Spearmint, make the\nimplementation of the algorithm straightforward. A fork of the Spearmint\nframework along with a tutorial on how to use it in practice is available at\nhttps://bitbucket.org/uhasseltmachinelearning/spearmint/\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 09:25:17 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 10:23:28 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 13:26:38 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Yperman", "Jan", ""], ["Becker", "Thijs", ""]]}, {"id": "1611.05209", "submitter": "Siddharth Agrawal", "authors": "Siddharth Agrawal, Ambedkar Dukkipati", "title": "Deep Variational Inference Without Pixel-Wise Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs), that are built upon deep neural networks\nhave emerged as popular generative models in computer vision. Most of the work\ntowards improving variational autoencoders has focused mainly on making the\napproximations to the posterior flexible and accurate, leading to tremendous\nprogress. However, there have been limited efforts to replace pixel-wise\nreconstruction, which have known shortcomings. In this work, we use real-valued\nnon-volume preserving transformations (real NVP) to exactly compute the\nconditional likelihood of the data given the latent distribution. We show that\na simple VAE with this form of reconstruction is competitive with complicated\nVAE structures, on image modeling tasks. As part of our model, we develop\npowerful conditional coupling layers that enable real NVP to learn with fewer\nintermediate layers.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 10:20:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Agrawal", "Siddharth", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1611.05317", "submitter": "Carter Lassetter", "authors": "Carter Lassetter, Eduardo Cotilla-Sanchez, Jinsub Kim", "title": "A Learning Scheme for Microgrid Islanding and Reconnection", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a potential learning scheme that can dynamically\npredict the stability of the reconnection of sub-networks to a main grid. As\nthe future electrical power systems tend towards smarter and greener\ntechnology, the deployment of self sufficient networks, or microgrids, becomes\nmore likely. Microgrids may operate on their own or synchronized with the main\ngrid, thus control methods need to take into account islanding and reconnecting\nof said networks. The ability to optimally and safely reconnect a portion of\nthe grid is not well understood and, as of now, limited to raw synchronization\nbetween interconnection points. A support vector machine (SVM) leveraging\nreal-time data from phasor measurement units (PMUs) is proposed to predict in\nreal time whether the reconnection of a sub-network to the main grid would lead\nto stability or instability. A dynamics simulator fed with pre-acquired system\nparameters is used to create training data for the SVM in various operating\nstates. The classifier was tested on a variety of cases and operating points to\nensure diversity. Accuracies of approximately 85% were observed throughout most\nconditions when making dynamic predictions of a given network.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 04:20:08 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 23:29:02 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Lassetter", "Carter", ""], ["Cotilla-Sanchez", "Eduardo", ""], ["Kim", "Jinsub", ""]]}, {"id": "1611.05340", "submitter": "Abhay Gupta", "authors": "Abhay Gupta", "title": "Approximating Wisdom of Crowds using K-RBMs", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important way to make large training sets is to gather noisy labels from\ncrowds of non experts. We propose a method to aggregate noisy labels collected\nfrom a crowd of workers or annotators. Eliciting labels is important in tasks\nsuch as judging web search quality and rating products. Our method assumes that\nlabels are generated by a probability distribution over items and labels. We\nformulate the method by drawing parallels between Gaussian Mixture Models\n(GMMs) and Restricted Boltzmann Machines (RBMs) and show that the problem of\nvote aggregation can be viewed as one of clustering. We use K-RBMs to perform\nclustering. We finally show some empirical evaluations over real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 16:01:48 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 02:48:04 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Gupta", "Abhay", ""]]}, {"id": "1611.05369", "submitter": "Melanie Mitchell", "authors": "Anthony D. Rhodes, Max H. Quinn, and Melanie Mitchell", "title": "Fast On-Line Kernel Density Estimation for Active Object Localization", "comments": "arXiv admin note: text overlap with arXiv:1607.00548", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major goal of computer vision is to enable computers to interpret visual\nsituations---abstract concepts (e.g., \"a person walking a dog,\" \"a crowd\nwaiting for a bus,\" \"a picnic\") whose image instantiations are linked more by\ntheir common spatial and semantic structure than by low-level visual\nsimilarity. In this paper, we propose a novel method for prior learning and\nactive object localization for this kind of knowledge-driven search in static\nimages. In our system, prior situation knowledge is captured by a set of\nflexible, kernel-based density estimations---a situation model---that represent\nthe expected spatial structure of the given situation. These estimations are\nefficiently updated by information gained as the system searches for relevant\nobjects, allowing the system to use context as it is discovered to narrow the\nsearch.\n  More specifically, at any given time in a run on a test image, our system\nuses image features plus contextual information it has discovered to identify a\nsmall subset of training images---an importance cluster---that is deemed most\nsimilar to the given test image, given the context. This subset is used to\ngenerate an updated situation model in an on-line fashion, using an efficient\nmultipole expansion technique.\n  As a proof of concept, we apply our algorithm to a highly varied and\nchallenging dataset consisting of instances of a \"dog-walking\" situation. Our\nresults support the hypothesis that dynamically-rendered, context-based\nprobability models can support efficient object localization in visual\nsituations. Moreover, our approach is general enough to be applied to diverse\nmachine learning paradigms requiring interpretable, probabilistic\nrepresentations generated from partially observed data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:04:35 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Rhodes", "Anthony D.", ""], ["Quinn", "Max H.", ""], ["Mitchell", "Melanie", ""]]}, {"id": "1611.05373", "submitter": "Cheng Li", "authors": "Cheng Li, Jiaqi Ma, Xiaoxiao Guo, and Qiaozhu Mei", "title": "DeepCas: an End-to-end Predictor of Information Cascades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information cascades, effectively facilitated by most social network\nplatforms, are recognized as a major factor in almost every social success and\ndisaster in these networks. Can cascades be predicted? While many believe that\nthey are inherently unpredictable, recent work has shown that some key\nproperties of information cascades, such as size, growth, and shape, can be\npredicted by a machine learning algorithm that combines many features. These\npredictors all depend on a bag of hand-crafting features to represent the\ncascade network and the global network structure. Such features, always\ncarefully and sometimes mysteriously designed, are not easy to extend or to\ngeneralize to a different platform or domain.\n  Inspired by the recent successes of deep learning in multiple data mining\ntasks, we investigate whether an end-to-end deep learning approach could\neffectively predict the future size of cascades. Such a method automatically\nlearns the representation of individual cascade graphs in the context of the\nglobal network structure, without hand-crafted features and heuristics. We find\nthat node embeddings fall short of predictive power, and it is critical to\nlearn the representation of a cascade graph as a whole. We present algorithms\nthat learn the representation of cascade graphs in an end-to-end manner, which\nsignificantly improve the performance of cascade prediction over strong\nbaselines that include feature based methods, node embedding methods, and graph\nkernel methods. Our results also provide interesting implications for cascade\nprediction in general.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:14:06 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Li", "Cheng", ""], ["Ma", "Jiaqi", ""], ["Guo", "Xiaoxiao", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.05377", "submitter": "Yongxi Lu", "authors": "Yongxi Lu, Abhishek Kumar, Shuangfei Zhai, Yu Cheng, Tara Javidi,\n  Rogerio Feris", "title": "Fully-adaptive Feature Sharing in Multi-Task Networks with Applications\n  in Person Attribute Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning aims to improve generalization performance of multiple\nprediction tasks by appropriately sharing relevant information across them. In\nthe context of deep neural networks, this idea is often realized by\nhand-designed network architectures with layers that are shared across tasks\nand branches that encode task-specific features. However, the space of possible\nmulti-task deep architectures is combinatorially large and often the final\narchitecture is arrived at by manual exploration of this space subject to\ndesigner's bias, which can be both error-prone and tedious. In this work, we\npropose a principled approach for designing compact multi-task deep learning\narchitectures. Our approach starts with a thin network and dynamically widens\nit in a greedy manner during training using a novel criterion that promotes\ngrouping of similar tasks together. Our Extensive evaluation on person\nattributes classification tasks involving facial and clothing attributes\nsuggests that the models produced by the proposed method are fast, compact and\ncan closely match or exceed the state-of-the-art accuracy from strong baselines\nby much more expensive models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:31:44 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lu", "Yongxi", ""], ["Kumar", "Abhishek", ""], ["Zhai", "Shuangfei", ""], ["Cheng", "Yu", ""], ["Javidi", "Tara", ""], ["Feris", "Rogerio", ""]]}, {"id": "1611.05378", "submitter": "Maria Francesca", "authors": "Maria Francesca and Arthur Hughes and David Gregg", "title": "Spectral Convolution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has shown that computation of convolution in the frequency\ndomain provides a significant speedup versus traditional convolution network\nimplementations. However, this performance increase comes at the expense of\nrepeatedly computing the transform and its inverse in order to apply other\nnetwork operations such as activation, pooling, and dropout. We show,\nmathematically, how convolution and activation can both be implemented in the\nfrequency domain using either the Fourier or Laplace transformation. The main\ncontributions are a description of spectral activation under the Fourier\ntransform and a further description of an efficient algorithm for computing\nboth convolution and activation under the Laplace transform. By computing both\nthe convolution and activation functions in the frequency domain, we can reduce\nthe number of transforms required, as well as reducing overall complexity. Our\ndescription of a spectral activation function, together with existing spectral\nanalogs of other network functions may then be used to compose a fully spectral\nimplementation of a convolution network.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 17:32:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Francesca", "Maria", ""], ["Hughes", "Arthur", ""], ["Gregg", "David", ""]]}, {"id": "1611.05397", "submitter": "Max Jaderberg", "authors": "Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul,\n  Joel Z Leibo, David Silver, Koray Kavukcuoglu", "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning agents have achieved state-of-the-art results by\ndirectly maximising cumulative reward. However, environments contain a much\nwider variety of possible training signals. In this paper, we introduce an\nagent that also maximises many other pseudo-reward functions simultaneously by\nreinforcement learning. All of these tasks share a common representation that,\nlike unsupervised learning, continues to develop in the absence of extrinsic\nrewards. We also introduce a novel mechanism for focusing this representation\nupon extrinsic rewards, so that learning can rapidly adapt to the most relevant\naspects of the actual task. Our agent significantly outperforms the previous\nstate-of-the-art on Atari, averaging 880\\% expert human performance, and a\nchallenging suite of first-person, three-dimensional \\emph{Labyrinth} tasks\nleading to a mean speedup in learning of 10$\\times$ and averaging 87\\% expert\nhuman performance on Labyrinth.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 18:21:29 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Jaderberg", "Max", ""], ["Mnih", "Volodymyr", ""], ["Czarnecki", "Wojciech Marian", ""], ["Schaul", "Tom", ""], ["Leibo", "Joel Z", ""], ["Silver", "David", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1611.05402", "submitter": "Hantian Zhang", "authors": "Hantian Zhang, Jerry Li, Kaan Kara, Dan Alistarh, Ji Liu, Ce Zhang", "title": "The ZipML Framework for Training Models with End-to-End Low Precision:\n  The Cans, the Cannots, and a Little Bit of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been significant interest in training machine-learning\nmodels at low precision: by reducing precision, one can reduce computation and\ncommunication by one order of magnitude. We examine training at reduced\nprecision, both from a theoretical and practical perspective, and ask: is it\npossible to train models at end-to-end low precision with provable guarantees?\nCan this lead to consistent order-of-magnitude speedups? We present a framework\ncalled ZipML to answer these questions. For linear models, the answer is yes.\nWe develop a simple framework based on one simple but novel strategy called\ndouble sampling. Our framework is able to execute training at low precision\nwith no bias, guaranteeing convergence, whereas naive quantization would\nintroduce significant bias. We validate our framework across a range of\napplications, and show that it enables an FPGA prototype that is up to 6.5x\nfaster than an implementation using full 32-bit precision. We further develop a\nvariance-optimal stochastic quantization strategy and show that it can make a\nsignificant difference in a variety of settings. When applied to linear models\ntogether with double sampling, we save up to another 1.7x in data movement\ncompared with uniform quantization. When training deep networks with quantized\nmodels, we achieve higher accuracy than the state-of-the-art XNOR-Net. Finally,\nwe extend our framework through approximation to non-linear models, such as\nSVM. We show that, although using low-precision data induces bias, we can\nappropriately bound and control the bias. We find in practice 8-bit precision\nis often sufficient to converge to the correct solution. Interestingly,\nhowever, in practice we notice that our framework does not always outperform\nthe naive rounding approach. We discuss this negative result in detail.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 18:45:09 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 23:33:12 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 14:36:00 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Zhang", "Hantian", ""], ["Li", "Jerry", ""], ["Kara", "Kaan", ""], ["Alistarh", "Dan", ""], ["Liu", "Ji", ""], ["Zhang", "Ce", ""]]}, {"id": "1611.05416", "submitter": "Xiao Zhang", "authors": "Zheng Sun, Jiaqi Liu, Zewang Zhang, Jingwen Chen, Zhao Huo, Ching Hua\n  Lee, and Xiao Zhang", "title": "Composing Music with Grammar Argumented Neural Networks and Note-Level\n  Encoding", "comments": "6 pages, 4 figures", "journal-ref": "2018 Asia-Pacific Signal and Information Processing Association\n  Annual Summit and Conference (APSIPA ASC), p1864-1867", "doi": "10.23919/APSIPA.2018.8659792", "report-no": null, "categories": "cs.LG cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating aesthetically pleasing pieces of art, including music, has been a\nlong-term goal for artificial intelligence research. Despite recent successes\nof long-short term memory (LSTM) recurrent neural networks (RNNs) in sequential\nlearning, LSTM neural networks have not, by themselves, been able to generate\nnatural-sounding music conforming to music theory. To transcend this\ninadequacy, we put forward a novel method for music composition that combines\nthe LSTM with Grammars motivated by music theory. The main tenets of music\ntheory are encoded as grammar argumented (GA) filters on the training data,\nsuch that the machine can be trained to generate music inheriting the\nnaturalness of human-composed pieces from the original dataset while adhering\nto the rules of music theory. Unlike previous approaches, pitches and durations\nare encoded as one semantic entity, which we refer to as note-level encoding.\nThis allows easy implementation of music theory grammars, as well as closer\nemulation of the thinking pattern of a musician. Although the GA rules are\napplied to the training data and never directly to the LSTM music generation,\nour machine still composes music that possess high incidences of diatonic scale\nnotes, small pitch intervals and chords, in deference to music theory.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 19:42:40 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 20:51:36 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Sun", "Zheng", ""], ["Liu", "Jiaqi", ""], ["Zhang", "Zewang", ""], ["Chen", "Jingwen", ""], ["Huo", "Zhao", ""], ["Lee", "Ching Hua", ""], ["Zhang", "Xiao", ""]]}, {"id": "1611.05480", "submitter": "Jianbo Yuan", "authors": "Jianbo Yuan, Walid Shalaby, Mohammed Korayem, David Lin, Khalifeh\n  AlJadda, and Jiebo Luo", "title": "Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep\n  Learning Approach", "comments": "in Big Data, IEEE International Conference on, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) is widely used in large-scale recommendation\nengines because of its efficiency, accuracy and scalability. However, in\npractice, the fact that recommendation engines based on CF require interactions\nbetween users and items before making recommendations, make it inappropriate\nfor new items which haven't been exposed to the end users to interact with.\nThis is known as the cold-start problem. In this paper we introduce a novel\napproach which employs deep learning to tackle this problem in any CF based\nrecommendation engine. One of the most important features of the proposed\ntechnique is the fact that it can be applied on top of any existing CF based\nrecommendation engine without changing the CF core. We successfully applied\nthis technique to overcome the item cold-start problem in Careerbuilder's CF\nbased recommendation engine. Our experiments show that the proposed technique\nis very efficient to resolve the cold-start problem while maintaining high\naccuracy of the CF recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 22:03:04 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Yuan", "Jianbo", ""], ["Shalaby", "Walid", ""], ["Korayem", "Mohammed", ""], ["Lin", "David", ""], ["AlJadda", "Khalifeh", ""], ["Luo", "Jiebo", ""]]}, {"id": "1611.05487", "submitter": "Ilya Safro", "authors": "Ehsan Sadrfaridpour, Sandeep Jeereddy, Ken Kennedy, Andre Luckow,\n  Talayeh Razzaghi, Ilya Safro", "title": "Algebraic multigrid support vector machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine is a flexible optimization-based technique widely\nused for classification problems. In practice, its training part becomes\ncomputationally expensive on large-scale data sets because of such reasons as\nthe complexity and number of iterations in parameter fitting methods,\nunderlying optimization solvers, and nonlinearity of kernels. We introduce a\nfast multilevel framework for solving support vector machine models that is\ninspired by the algebraic multigrid. Significant improvement in the running has\nbeen achieved without any loss in the quality. The proposed technique is highly\nbeneficial on imbalanced sets. We demonstrate computational results on publicly\navailable and industrial data sets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 22:32:50 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 01:10:21 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Sadrfaridpour", "Ehsan", ""], ["Jeereddy", "Sandeep", ""], ["Kennedy", "Ken", ""], ["Luckow", "Andre", ""], ["Razzaghi", "Talayeh", ""], ["Safro", "Ilya", ""]]}, {"id": "1611.05521", "submitter": "Yang Wang", "authors": "Lin Wu, Yang Wang", "title": "Robust Hashing for Multi-View Data: Jointly Learning Low-Rank Kernelized\n  Similarity Consensus and Hash Functions", "comments": "Accepted to appear in Image and Vision Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning hash functions/codes for similarity search over multi-view data is\nattracting increasing attention, where similar hash codes are assigned to the\ndata objects characterizing consistently neighborhood relationship across\nviews. Traditional methods in this category inherently suffer three\nlimitations: 1) they commonly adopt a two-stage scheme where similarity matrix\nis first constructed, followed by a subsequent hash function learning; 2) these\nmethods are commonly developed on the assumption that data samples with\nmultiple representations are noise-free,which is not practical in real-life\napplications; 3) they often incur cumbersome training model caused by the\nneighborhood graph construction using all $N$ points in the database ($O(N)$).\nIn this paper, we motivate the problem of jointly and efficiently training the\nrobust hash functions over data objects with multi-feature representations\nwhich may be noise corrupted. To achieve both the robustness and training\nefficiency, we propose an approach to effectively and efficiently learning\nlow-rank kernelized \\footnote{We use kernelized similarity rather than kernel,\nas it is not a squared symmetric matrix for data-landmark affinity matrix.}\nhash functions shared across views. Specifically, we utilize landmark graphs to\nconstruct tractable similarity matrices in multi-views to automatically\ndiscover neighborhood structure in the data. To learn robust hash functions, a\nlatent low-rank kernel function is used to construct hash functions in order to\naccommodate linearly inseparable data. In particular, a latent kernelized\nsimilarity matrix is recovered by rank minimization on multiple kernel-based\nsimilarity matrices. Extensive experiments on real-world multi-view datasets\nvalidate the efficacy of our method in the presence of error corruptions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 01:21:26 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wu", "Lin", ""], ["Wang", "Yang", ""]]}, {"id": "1611.05527", "submitter": "Tsubasa Ochiai", "authors": "Tsubasa Ochiai, Shigeki Matsuda, Hideyuki Watanabe, Shigeru Katagiri", "title": "Automatic Node Selection for Deep Neural Networks using Group Lasso\n  Regularization", "comments": "Submitted to ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effect of the Group Lasso (gLasso) regularizer in selecting\nthe salient nodes of Deep Neural Network (DNN) hidden layers by applying a\nDNN-HMM hybrid speech recognizer to TED Talks speech data. We test two types of\ngLasso regularization, one for outgoing weight vectors and another for incoming\nweight vectors, as well as two sizes of DNNs: 2048 hidden layer nodes and 4096\nnodes. Furthermore, we compare gLasso and L2 regularizers. Our experiment\nresults demonstrate that our DNN training, in which the gLasso regularizer was\nembedded, successfully selected the hidden layer nodes that are necessary and\nsufficient for achieving high classification power.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 01:43:01 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ochiai", "Tsubasa", ""], ["Matsuda", "Shigeki", ""], ["Watanabe", "Hideyuki", ""], ["Katagiri", "Shigeru", ""]]}, {"id": "1611.05552", "submitter": "Jason Kuen", "authors": "Jason Kuen, Xiangfei Kong, Gang Wang, Yap-Peng Tan", "title": "DelugeNets: Deep Networks with Efficient and Flexible Cross-layer\n  Information Inflows", "comments": "Code: https://github.com/xternalz/DelugeNets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deluge Networks (DelugeNets) are deep neural networks which efficiently\nfacilitate massive cross-layer information inflows from preceding layers to\nsucceeding layers. The connections between layers in DelugeNets are established\nthrough cross-layer depthwise convolutional layers with learnable filters,\nacting as a flexible yet efficient selection mechanism. DelugeNets can\npropagate information across many layers with greater flexibility and utilize\nnetwork parameters more effectively compared to ResNets, whilst being more\nefficient than DenseNets. Remarkably, a DelugeNet model with just model\ncomplexity of 4.31 GigaFLOPs and 20.2M network parameters, achieve\nclassification errors of 3.76% and 19.02% on CIFAR-10 and CIFAR-100 dataset\nrespectively. Moreover, DelugeNet-122 performs competitively to ResNet-200 on\nImageNet dataset, despite costing merely half of the computations needed by the\nlatter.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 03:45:48 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 07:41:33 GMT"}, {"version": "v3", "created": "Wed, 28 Dec 2016 02:08:45 GMT"}, {"version": "v4", "created": "Fri, 30 Dec 2016 04:56:02 GMT"}, {"version": "v5", "created": "Wed, 23 Aug 2017 14:09:55 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Kuen", "Jason", ""], ["Kong", "Xiangfei", ""], ["Wang", "Gang", ""], ["Tan", "Yap-Peng", ""]]}, {"id": "1611.05559", "submitter": "Fangjian Guo", "authors": "Fangjian Guo, Xiangyu Wang, Kai Fan, Tamara Broderick and David B.\n  Dunson", "title": "Boosting Variational Inference", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) provides fast approximations of a Bayesian\nposterior in part because it formulates posterior approximation as an\noptimization problem: to find the closest distribution to the exact posterior\nover some family of distributions. For practical reasons, the family of\ndistributions in VI is usually constrained so that it does not include the\nexact posterior, even as a limit point. Thus, no matter how long VI is run, the\nresulting approximation will not approach the exact posterior. We propose to\ninstead consider a more flexible approximating family consisting of all\npossible finite mixtures of a parametric base distribution (e.g., Gaussian).\nFor efficient inference, we borrow ideas from gradient boosting to develop an\nalgorithm we call boosting variational inference (BVI). BVI iteratively\nimproves the current approximation by mixing it with a new component from the\nbase distribution family and thereby yields progressively more accurate\nposterior approximations as more computing time is spent. Unlike a number of\ncommon VI variants including mean-field VI, BVI is able to capture\nmultimodality, general posterior covariance, and nonstandard posterior shapes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 04:19:16 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 21:54:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Guo", "Fangjian", ""], ["Wang", "Xiangyu", ""], ["Fan", "Kai", ""], ["Broderick", "Tamara", ""], ["Dunson", "David B.", ""]]}, {"id": "1611.05607", "submitter": "Tal Schuster", "authors": "Tal Schuster, Lior Wolf and David Gadot", "title": "Optical Flow Requires Multiple Strategies (but only one network)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the matching problem that underlies optical flow requires\nmultiple strategies, depending on the amount of image motion and other factors.\nWe then study the implications of this observation on training a deep neural\nnetwork for representing image patches in the context of descriptor based\noptical flow. We propose a metric learning method, which selects suitable\nnegative samples based on the nature of the true match. This type of training\nproduces a network that displays multiple strategies depending on the input and\nleads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 08:31:56 GMT"}, {"version": "v2", "created": "Sun, 29 Jan 2017 22:37:31 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2017 10:52:03 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Schuster", "Tal", ""], ["Wolf", "Lior", ""], ["Gadot", "David", ""]]}, {"id": "1611.05644", "submitter": "Antonia Creswell", "authors": "Antonia Creswell and Anil Anthony Bharath", "title": "Inverting The Generator Of A Generative Adversarial Network", "comments": "Accepted at NIPS 2016 Workshop on Adversarial Training", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) learn to synthesise new samples from a\nhigh-dimensional distribution by passing samples drawn from a latent space\nthrough a generative network. When the high-dimensional distribution describes\nimages of a particular data set, the network should learn to generate visually\nsimilar image samples for latent variables that are close to each other in the\nlatent space. For tasks such as image retrieval and image classification, it\nmay be useful to exploit the arrangement of the latent space by projecting\nimages into it, and using this as a representation for discriminative tasks.\nGANs often consist of multiple layers of non-linear computations, making them\nvery difficult to invert. This paper introduces techniques for projecting image\nsamples into the latent space using any pre-trained GAN, provided that the\ncomputational graph is available. We evaluate these techniques on both MNIST\ndigits and Omniglot handwritten characters. In the case of MNIST digits, we\nshow that projections into the latent space maintain information about the\nstyle and the identity of the digit. In the case of Omniglot characters, we\nshow that even characters from alphabets that have not been seen during\ntraining may be projected well into the latent space; this suggests that this\napproach may have applications in one-shot learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 11:55:16 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Creswell", "Antonia", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1611.05675", "submitter": "Xi Ma", "authors": "Xi Ma, Zhiyong Wu, Jia Jia, Mingxing Xu, Helen Meng, Lianhong Cai", "title": "Study on Feature Subspace of Archetypal Emotions for Speech Emotion\n  Recognition", "comments": "5 pages, 4 figures, ICASSP-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature subspace selection is an important part in speech emotion\nrecognition. Most of the studies are devoted to finding a feature subspace for\nrepresenting all emotions. However, some studies have indicated that the\nfeatures associated with different emotions are not exactly the same. Hence,\ntraditional methods may fail to distinguish some of the emotions with just one\nglobal feature subspace. In this work, we propose a new divide and conquer idea\nto solve the problem. First, the feature subspaces are constructed for all the\ncombinations of every two different emotions (emotion-pair). Bi-classifiers are\nthen trained on these feature subspaces respectively. The final emotion\nrecognition result is derived by the voting and competition method.\nExperimental results demonstrate that the proposed method can get better\nresults than the traditional multi-classification method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 13:32:59 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ma", "Xi", ""], ["Wu", "Zhiyong", ""], ["Jia", "Jia", ""], ["Xu", "Mingxing", ""], ["Meng", "Helen", ""], ["Cai", "Lianhong", ""]]}, {"id": "1611.05722", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Olivier Janssens, Femke Ongenae, Filip De Turck,\n  Sofie Van Hoecke", "title": "GENESIM: genetic extraction of a single, interpretable model", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models obtained by decision tree induction techniques excel in being\ninterpretable.However, they can be prone to overfitting, which results in a low\npredictive performance. Ensemble techniques are able to achieve a higher\naccuracy. However, this comes at a cost of losing interpretability of the\nresulting model. This makes ensemble techniques impractical in applications\nwhere decision support, instead of decision making, is crucial.\n  To bridge this gap, we present the GENESIM algorithm that transforms an\nensemble of decision trees to a single decision tree with an enhanced\npredictive performance by using a genetic algorithm. We compared GENESIM to\nprevalent decision tree induction and ensemble techniques using twelve publicly\navailable data sets. The results show that GENESIM achieves a better predictive\nperformance on most of these data sets than decision tree induction techniques\nand a predictive performance in the same order of magnitude as the ensemble\ntechniques. Moreover, the resulting model of GENESIM has a very low complexity,\nmaking it very interpretable, in contrast to ensemble techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 14:58:35 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Janssens", "Olivier", ""], ["Ongenae", "Femke", ""], ["De Turck", "Filip", ""], ["Van Hoecke", "Sofie", ""]]}, {"id": "1611.05724", "submitter": "Stefano Paladino", "authors": "Stefano Paladino and Francesco Trov\\`o and Marcello Restelli and\n  Nicola Gatti", "title": "Unimodal Thompson Sampling for Graph-Structured Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study, to the best of our knowledge, the first Bayesian algorithm for\nunimodal Multi-Armed Bandit (MAB) problems with graph structure. In this\nsetting, each arm corresponds to a node of a graph and each edge provides a\nrelationship, unknown to the learner, between two nodes in terms of expected\nreward. Furthermore, for any node of the graph there is a path leading to the\nunique node providing the maximum expected reward, along which the expected\nreward is monotonically increasing. Previous results on this setting describe\nthe behavior of frequentist MAB algorithms. In our paper, we design a Thompson\nSampling-based algorithm whose asymptotic pseudo-regret matches the lower bound\nfor the considered setting. We show that -as it happens in a wide number of\nscenarios- Bayesian MAB algorithms dramatically outperform frequentist ones. In\nparticular, we provide a thorough experimental evaluation of the performance of\nour and state-of-the-art algorithms as the properties of the graph vary.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 14:59:55 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 10:13:02 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Paladino", "Stefano", ""], ["Trov\u00f2", "Francesco", ""], ["Restelli", "Marcello", ""], ["Gatti", "Nicola", ""]]}, {"id": "1611.05743", "submitter": "Ping Li PhD", "authors": "Ping Li, Jiajun Bu, Chun Chen, Zhanying He, Deng Cai", "title": "Relational Multi-Manifold Co-Clustering", "comments": "11 pages, 4 figures, published in IEEE Transactions on Cybernetics\n  (TCYB)", "journal-ref": "IEEE Transactions on Cybernetics, 43(6): 1871-1881, 2013", "doi": "10.1109/TSMCB.2012.2234108", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-clustering targets on grouping the samples (e.g., documents, users) and\nthe features (e.g., words, ratings) simultaneously. It employs the dual\nrelation and the bilateral information between the samples and features. In\nmany realworld applications, data usually reside on a submanifold of the\nambient Euclidean space, but it is nontrivial to estimate the intrinsic\nmanifold of the data space in a principled way. In this study, we focus on\nimproving the co-clustering performance via manifold ensemble learning, which\nis able to maximally approximate the intrinsic manifolds of both the sample and\nfeature spaces. To achieve this, we develop a novel co-clustering algorithm\ncalled Relational Multi-manifold Co-clustering (RMC) based on symmetric\nnonnegative matrix tri-factorization, which decomposes the relational data\nmatrix into three submatrices. This method considers the intertype relationship\nrevealed by the relational data matrix, and also the intra-type information\nreflected by the affinity matrices encoded on the sample and feature data\ndistributions. Specifically, we assume the intrinsic manifold of the sample or\nfeature space lies in a convex hull of some pre-defined candidate manifolds. We\nwant to learn a convex combination of them to maximally approach the desired\nintrinsic manifold. To optimize the objective function, the multiplicative\nrules are utilized to update the submatrices alternatively. Besides, both the\nentropic mirror descent algorithm and the coordinate descent algorithm are\nexploited to learn the manifold coefficient vector. Extensive experiments on\ndocuments, images and gene expression data sets have demonstrated the\nsuperiority of the proposed algorithm compared to other well-established\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 05:33:04 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Li", "Ping", ""], ["Bu", "Jiajun", ""], ["Chen", "Chun", ""], ["He", "Zhanying", ""], ["Cai", "Deng", ""]]}, {"id": "1611.05751", "submitter": "Hamid Reza Hassanzadeh", "authors": "Hamid Reza Hassanzadeh, John H. Phan, May D. Wang", "title": "A Multi-Modal Graph-Based Semi-Supervised Pipeline for Predicting Cancer\n  Survival", "comments": "in 2016 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer survival prediction is an active area of research that can help\nprevent unnecessary therapies and improve patient's quality of life. Gene\nexpression profiling is being widely used in cancer studies to discover\ninformative biomarkers that aid predict different clinical endpoint prediction.\nWe use multiple modalities of data derived from RNA deep-sequencing (RNA-seq)\nto predict survival of cancer patients. Despite the wealth of information\navailable in expression profiles of cancer tumors, fulfilling the\naforementioned objective remains a big challenge, for the most part, due to the\npaucity of data samples compared to the high dimension of the expression\nprofiles. As such, analysis of transcriptomic data modalities calls for\nstate-of-the-art big-data analytics techniques that can maximally use all the\navailable data to discover the relevant information hidden within a significant\namount of noise. In this paper, we propose a pipeline that predicts cancer\npatients' survival by exploiting the structure of the input (manifold learning)\nand by leveraging the unlabeled samples using Laplacian support vector\nmachines, a graph-based semi supervised learning (GSSL) paradigm. We show that\nunder certain circumstances, no single modality per se will result in the best\naccuracy and by fusing different models together via a stacked generalization\nstrategy, we may boost the accuracy synergistically. We apply our approach to\ntwo cancer datasets and present promising results. We maintain that a similar\npipeline can be used for predictive tasks where labeled samples are expensive\nto acquire.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 16:01:36 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Hassanzadeh", "Hamid Reza", ""], ["Phan", "John H.", ""], ["Wang", "May D.", ""]]}, {"id": "1611.05763", "submitter": "Jane Wang", "authors": "Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z\n  Leibo, Remi Munos, Charles Blundell, Dharshan Kumaran, Matt Botvinick", "title": "Learning to reinforcement learn", "comments": "17 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years deep reinforcement learning (RL) systems have attained\nsuperhuman performance in a number of challenging task domains. However, a\nmajor limitation of such applications is their demand for massive amounts of\ntraining data. A critical present objective is thus to develop deep RL methods\nthat can adapt rapidly to new tasks. In the present work we introduce a novel\napproach to this challenge, which we refer to as deep meta-reinforcement\nlearning. Previous work has shown that recurrent networks can support\nmeta-learning in a fully supervised context. We extend this approach to the RL\nsetting. What emerges is a system that is trained using one RL algorithm, but\nwhose recurrent dynamics implement a second, quite separate RL procedure. This\nsecond, learned RL algorithm can differ from the original one in arbitrary\nways. Importantly, because it is learned, it is configured to exploit structure\nin the training domain. We unpack these points in a series of seven\nproof-of-concept experiments, each of which examines a key aspect of deep\nmeta-RL. We consider prospects for extending and scaling up the approach, and\nalso point out some potentially important implications for neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 16:29:11 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 15:35:02 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2017 12:38:24 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Wang", "Jane X", ""], ["Kurth-Nelson", "Zeb", ""], ["Tirumala", "Dhruva", ""], ["Soyer", "Hubert", ""], ["Leibo", "Joel Z", ""], ["Munos", "Remi", ""], ["Blundell", "Charles", ""], ["Kumaran", "Dharshan", ""], ["Botvinick", "Matt", ""]]}, {"id": "1611.05780", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye, Olivier Fercoq, Alexandre Gramfort and Joseph Salmon", "title": "Gap Safe screening rules for sparsity enforcing penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional regression settings, sparsity enforcing penalties have\nproved useful to regularize the data-fitting term. A recently introduced\ntechnique called screening rules propose to ignore some variables in the\noptimization leveraging the expected sparsity of the solutions and consequently\nleading to faster solvers. When the procedure is guaranteed not to discard\nvariables wrongly the rules are said to be safe. In this work, we propose a\nunifying framework for generalized linear models regularized with standard\nsparsity enforcing penalties such as $\\ell_1$ or $\\ell_1/\\ell_2$ norms. Our\ntechnique allows to discard safely more variables than previously considered\nsafe rules, particularly for low regularization parameters. Our proposed Gap\nSafe rules (so called because they rely on duality gap computation) can cope\nwith any iterative solver but are particularly well suited to (block)\ncoordinate descent methods. Applied to many standard learning tasks, Lasso,\nSparse-Group Lasso, multi-task Lasso, binary and multinomial logistic\nregression, etc., we report significant speed-ups compared to previously\nproposed safe rules on all tested data sets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 16:55:12 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 16:38:35 GMT"}, {"version": "v3", "created": "Wed, 13 Sep 2017 08:05:19 GMT"}, {"version": "v4", "created": "Wed, 27 Dec 2017 17:26:38 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Fercoq", "Olivier", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1611.05788", "submitter": "Jacob Abernethy", "authors": "Jacob Abernethy (University of Michigan), Cyrus Anderson (University\n  of Michigan), Alex Chojnacki (University of Michigan), Chengyu Dai\n  (University of Michigan), John Dryden (University of Michigan), Eric Schwartz\n  (University of Michigan), Wenbo Shen (University of Michigan), Jonathan\n  Stroud (University of Michigan), Laura Wendlandt (University of Michigan),\n  Sheng Yang (University of Michigan), Daniel Zhang (University of Michigan)", "title": "Data Science in Service of Performing Arts: Applying Machine Learning to\n  Predicting Audience Preferences", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing arts organizations aim to enrich their communities through the\narts. To do this, they strive to match their performance offerings to the taste\nof those communities. Success relies on understanding audience preference and\npredicting their behavior. Similar to most e-commerce or digital entertainment\nfirms, arts presenters need to recommend the right performance to the right\ncustomer at the right time. As part of the Michigan Data Science Team (MDST),\nwe partnered with the University Musical Society (UMS), a non-profit performing\narts presenter housed in the University of Michigan, Ann Arbor. We are\nproviding UMS with analysis and business intelligence, utilizing historical\nindividual-level sales data. We built a recommendation system based on\ncollaborative filtering, gaining insights into the artistic preferences of\ncustomers, along with the similarities between performances. To better\nunderstand audience behavior, we used statistical methods from customer-base\nanalysis. We characterized customer heterogeneity via segmentation, and we\nmodeled customer cohorts to understand and predict ticket purchasing patterns.\nFinally, we combined statistical modeling with natural language processing\n(NLP) to explore the impact of wording in program descriptions. These ongoing\nefforts provide a platform to launch targeted marketing campaigns, helping UMS\ncarry out its mission by allocating its resources more efficiently. Celebrating\nits 138th season, UMS is a 2014 recipient of the National Medal of Arts, and it\ncontinues to enrich communities by connecting world-renowned artists with\ndiverse audiences, especially students in their formative years. We aim to\ncontribute to that mission through data science and customer analytics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 03:49:16 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Abernethy", "Jacob", "", "University of Michigan"], ["Anderson", "Cyrus", "", "University\n  of Michigan"], ["Chojnacki", "Alex", "", "University of Michigan"], ["Dai", "Chengyu", "", "University of Michigan"], ["Dryden", "John", "", "University of Michigan"], ["Schwartz", "Eric", "", "University of Michigan"], ["Shen", "Wenbo", "", "University of Michigan"], ["Stroud", "Jonathan", "", "University of Michigan"], ["Wendlandt", "Laura", "", "University of Michigan"], ["Yang", "Sheng", "", "University of Michigan"], ["Zhang", "Daniel", "", "University of Michigan"]]}, {"id": "1611.05817", "submitter": "Marco Tulio Ribeiro", "authors": "Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin", "title": "Nothing Else Matters: Model-Agnostic Explanations By Identifying\n  Prediction Invariance", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the core of interpretable machine learning is the question of whether\nhumans are able to make accurate predictions about a model's behavior. Assumed\nin this question are three properties of the interpretable output: coverage,\nprecision, and effort. Coverage refers to how often humans think they can\npredict the model's behavior, precision to how accurate humans are in those\npredictions, and effort is either the up-front effort required in interpreting\nthe model, or the effort required to make predictions about a model's behavior.\n  In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that\nproduces high-precision rule-based explanations for which the coverage\nboundaries are very clear. We compare aLIME to linear LIME with simulated\nexperiments, and demonstrate the flexibility of aLIME with qualitative examples\nfrom a variety of domains and tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 19:07:00 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ribeiro", "Marco Tulio", ""], ["Singh", "Sameer", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1611.05827", "submitter": "Hao Shen", "authors": "Hao Shen", "title": "Towards a Mathematical Understanding of the Difficulty in Learning with\n  Feedforward Neural Networks", "comments": "22 pages, 1 figure, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks for solving machine learning problems is one\ngreat challenge in the field, mainly due to its associated optimisation problem\nbeing highly non-convex. Recent developments have suggested that many training\nalgorithms do not suffer from undesired local minima under certain scenario,\nand consequently led to great efforts in pursuing mathematical explanations for\nsuch observations. This work provides an alternative mathematical understanding\nof the challenge from a smooth optimisation perspective. By assuming exact\nlearning of finite samples, sufficient conditions are identified via a critical\npoint analysis to ensure any local minimum to be globally minimal as well.\nFurthermore, a state of the art algorithm, known as the Generalised\nGauss-Newton (GGN) algorithm, is rigorously revisited as an approximate\nNewton's algorithm, which shares the property of being locally quadratically\nconvergent to a global minimum under the condition of exact learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 19:29:27 GMT"}, {"version": "v2", "created": "Sun, 2 Apr 2017 21:49:39 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 22:11:13 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Shen", "Hao", ""]]}, {"id": "1611.05898", "submitter": "Franck Vermet", "authors": "Vincent Gripon, Matthias L\\\"owe, Franck Vermet", "title": "Associative Memories to Accelerate Approximate Nearest Neighbor Search", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor search is a very active field in machine learning for it\nappears in many application cases, including classification and object\nretrieval. In its canonical version, the complexity of the search is linear\nwith both the dimension and the cardinal of the collection of vectors the\nsearch is performed in. Recently many works have focused on reducing the\ndimension of vectors using quantization techniques or hashing, while providing\nan approximate result. In this paper we focus instead on tackling the cardinal\nof the collection of vectors. Namely, we introduce a technique that partitions\nthe collection of vectors and stores each part in its own associative memory.\nWhen a query vector is given to the system, associative memories are polled to\nidentify which one contain the closest match. Then an exhaustive search is\nconducted only on the part of vectors stored in the selected associative\nmemory. We study the effectiveness of the system when messages to store are\ngenerated from i.i.d. uniform $\\pm$1 random variables or 0-1 sparse i.i.d.\nrandom variables. We also conduct experiment on both synthetic data and real\ndata and show it is possible to achieve interesting trade-offs between\ncomplexity and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 16:08:31 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 12:53:20 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Gripon", "Vincent", ""], ["L\u00f6we", "Matthias", ""], ["Vermet", "Franck", ""]]}, {"id": "1611.05923", "submitter": "Michael Wojnowicz", "authors": "Mike Wojnowicz, Ben Cruz, Xuan Zhao, Brian Wallace, Matt Wolff, Jay\n  Luan, and Caleb Crable", "title": "\"Influence Sketching\": Finding Influential Samples In Large-Scale\n  Regressions", "comments": "fixed additional typos", "journal-ref": "Big Data (Big Data), 2016 IEEE International Conference on, pp.\n  3601 - 3612. IEEE, 2016", "doi": "10.1109/BigData.2016.7841024", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an especially strong need in modern large-scale data analysis to\nprioritize samples for manual inspection. For example, the inspection could\ntarget important mislabeled samples or key vulnerabilities exploitable by an\nadversarial attack. In order to solve the \"needle in the haystack\" problem of\nwhich samples to inspect, we develop a new scalable version of Cook's distance,\na classical statistical technique for identifying samples which unusually\nstrongly impact the fit of a regression model (and its downstream predictions).\nIn order to scale this technique up to very large and high-dimensional\ndatasets, we introduce a new algorithm which we call \"influence sketching.\"\nInfluence sketching embeds random projections within the influence computation;\nin particular, the influence score is calculated using the randomly projected\npseudo-dataset from the post-convergence Generalized Linear Model (GLM). We\nvalidate that influence sketching can reliably and successfully discover\ninfluential samples by applying the technique to a malware detection dataset of\nover 2 million executable files, each represented with almost 100,000 features.\nFor example, we find that randomly deleting approximately 10% of training\nsamples reduces predictive accuracy only slightly from 99.47% to 99.45%,\nwhereas deleting the same number of samples with high influence sketch scores\nreduces predictive accuracy all the way down to 90.24%. Moreover, we find that\ninfluential samples are especially likely to be mislabeled. In the case study,\nwe manually inspect the most influential samples, and find that influence\nsketching pointed us to new, previously unidentified pieces of malware.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 22:23:08 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 20:15:16 GMT"}, {"version": "v3", "created": "Thu, 23 Mar 2017 05:55:24 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Wojnowicz", "Mike", ""], ["Cruz", "Ben", ""], ["Zhao", "Xuan", ""], ["Wallace", "Brian", ""], ["Wolff", "Matt", ""], ["Luan", "Jay", ""], ["Crable", "Caleb", ""]]}, {"id": "1611.05934", "submitter": "Viktoriya Krakovna", "authors": "Viktoriya Krakovna and Finale Doshi-Velez", "title": "Increasing the Interpretability of Recurrent Neural Networks Using\n  Hidden Markov Models", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems. arXiv admin note: substantial text overlap with\n  arXiv:1606.05320", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks continue to revolutionize various application\ndomains, there is increasing interest in making these powerful models more\nunderstandable and interpretable, and narrowing down the causes of good and bad\npredictions. We focus on recurrent neural networks, state of the art models in\nspeech recognition and translation. Our approach to increasing interpretability\nis by combining a long short-term memory (LSTM) model with a hidden Markov\nmodel (HMM), a simpler and more transparent model. We add the HMM state\nprobabilities to the output layer of the LSTM, and then train the HMM and LSTM\neither sequentially or jointly. The LSTM can make use of the information from\nthe HMM, and fill in the gaps when the HMM is not performing well. A small\nhybrid model usually performs better than a standalone LSTM of the same size,\nespecially on smaller data sets. We test the algorithms on text data and\nmedical time series data, and find that the LSTM and HMM learn complementary\ninformation about the features in the text.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 00:13:32 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Krakovna", "Viktoriya", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1611.05950", "submitter": "Christopher Meek", "authors": "Christopher Meek, Patrice Simard, Xiaojin Zhu", "title": "Analysis of a Design Pattern for Teaching with Features and Labels", "comments": "Also available at\n  https://www.microsoft.com/en-us/research/publication/a-design-pattern-for-teaching-with-features-and-labels/", "journal-ref": null, "doi": null, "report-no": "MSR-TR-2016-1104", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of teaching a machine to classify objects using features\nand labels. We introduce the Error-Driven-Featuring design pattern for teaching\nusing features and labels in which a teacher prefers to introduce features only\nif they are needed. We analyze the potential risks and benefits of this\nteaching pattern through the use of teaching protocols, illustrative examples,\nand by providing bounds on the effort required for an optimal machine teacher\nusing a linear learning algorithm, the most commonly used type of learners in\ninteractive machine learning systems. Our analysis provides a deeper\nunderstanding of potential trade-offs of using different learning algorithms\nand between the effort required for featuring (creating new features) and\nlabeling (providing labels for objects).\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 02:04:57 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Meek", "Christopher", ""], ["Simard", "Patrice", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1611.05955", "submitter": "Christopher Meek", "authors": "Christopher Meek", "title": "A Characterization of Prediction Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2016-1105", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding prediction errors and determining how to fix them is critical\nto building effective predictive systems. In this paper, we delineate four\ntypes of prediction errors and demonstrate that these four types characterize\nall prediction errors. In addition, we describe potential remedies and tools\nthat can be used to reduce the uncertainty when trying to determine the source\nof a prediction error and when trying to take action to remove a prediction\nerrors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 02:33:10 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Meek", "Christopher", ""]]}, {"id": "1611.05977", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani, George Atia", "title": "Robust and Scalable Column/Row Sampling from Corrupted Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional sampling techniques fall short of drawing descriptive sketches\nof the data when the data is grossly corrupted as such corruptions break the\nlow rank structure required for them to perform satisfactorily. In this paper,\nwe present new sampling algorithms which can locate the informative columns in\npresence of severe data corruptions. In addition, we develop new scalable\nrandomized designs of the proposed algorithms. The proposed approach is\nsimultaneously robust to sparse corruption and outliers and substantially\noutperforms the state-of-the-art robust sampling algorithms as demonstrated by\nexperiments conducted using both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 05:07:21 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1611.05990", "submitter": "Cezary Kaliszyk", "authors": "Michael F\\\"arber, Cezary Kaliszyk, Josef Urban", "title": "Monte Carlo Tableau Proof Search", "comments": null, "journal-ref": "Proceedings of the 26th International Conference on Automated\n  Deduction, CADE 2017", "doi": "10.1007/978-3-319-63046-5_34", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Monte Carlo Tree Search to guide proof search in tableau calculi.\nThis includes proposing a number of proof-state evaluation heuristics, some of\nwhich are learnt from previous proofs. We present an implementation based on\nthe leanCoP prover. The system is trained and evaluated on a large suite of\nrelated problems coming from the Mizar proof assistant, showing that it is\ncapable to find new and different proofs.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 06:30:09 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 00:34:50 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1611.06080", "submitter": "Kian Hsiang Low", "authors": "Quang Minh Hoang, Trong Nghia Hoang, Kian Hsiang Low", "title": "A Generalized Stochastic Variational Bayesian Hyperparameter Learning\n  Framework for Sparse Spectrum Gaussian Process Regression", "comments": "31st AAAI Conference on Artificial Intelligence (AAAI 2017), Extended\n  version with proofs, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much research effort has been dedicated to scaling up sparse Gaussian\nprocess (GP) models based on inducing variables for big data, little attention\nis afforded to the other less explored class of low-rank GP approximations that\nexploit the sparse spectral representation of a GP kernel. This paper presents\nsuch an effort to advance the state of the art of sparse spectrum GP models to\nachieve competitive predictive performance for massive datasets. Our\ngeneralized framework of stochastic variational Bayesian sparse spectrum GP\n(sVBSSGP) models addresses their shortcomings by adopting a Bayesian treatment\nof the spectral frequencies to avoid overfitting, modeling these frequencies\njointly in its variational distribution to enable their interaction a\nposteriori, and exploiting local data for boosting the predictive performance.\nHowever, such structural improvements result in a variational lower bound that\nis intractable to be optimized. To resolve this, we exploit a variational\nparameterization trick to make it amenable to stochastic optimization.\nInterestingly, the resulting stochastic gradient has a linearly decomposable\nstructure that can be exploited to refine our stochastic optimization method to\nincur constant time per iteration while preserving its property of being an\nunbiased estimator of the exact gradient of the variational lower bound.\nEmpirical evaluation on real-world datasets shows that sVBSSGP outperforms\nstate-of-the-art stochastic implementations of sparse GP models.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 14:00:48 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Hoang", "Quang Minh", ""], ["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1611.06132", "submitter": "Pavel Izmailov", "authors": "Pavel Izmailov and Dmitry Kropotov", "title": "Faster variational inducing input Gaussian process classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) provide a prior over functions and allow finding\ncomplex regularities in data. Gaussian processes are successfully used for\nclassification/regression problems and dimensionality reduction. In this work\nwe consider the classification problem only. The complexity of standard methods\nfor GP-classification scales cubically with the size of the training dataset.\nThis complexity makes them inapplicable to big data problems. Therefore, a\nvariety of methods were introduced to overcome this limitation. In the paper we\nfocus on methods based on so called inducing inputs. This approach is based on\nvariational inference and proposes a particular lower bound for marginal\nlikelihood (evidence). This bound is then maximized w.r.t. parameters of kernel\nfunction of the Gaussian process, thus fitting the model to data. The\ncomputational complexity of this method is $O(nm^2)$, where $m$ is the number\nof inducing inputs used by the model and is assumed to be substantially smaller\nthan the size of the dataset $n$. Recently, a new evidence lower bound for\nGP-classification problem was introduced. It allows using stochastic\noptimization, which makes it suitable for big data problems. However, the new\nlower bound depends on $O(m^2)$ variational parameter, which makes optimization\nchallenging in case of big m. In this work we develop a new approach for\ntraining inducing input GP models for classification problems. Here we use\nquadratic approximation of several terms in the aforementioned evidence lower\nbound, obtaining analytical expressions for optimal values of most of the\nparameters in the optimization, thus sufficiently reducing the dimension of\noptimization space. In our experiments we achieve as well or better results,\ncompared to the existing method. Moreover, our method doesn't require the user\nto manually set the learning rate, making it more practical, than the existing\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 15:53:50 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Izmailov", "Pavel", ""], ["Kropotov", "Dmitry", ""]]}, {"id": "1611.06148", "submitter": "Yotaro Kubo", "authors": "Yotaro Kubo, George Tucker, Simon Wiesler", "title": "Compacting Neural Network Classifiers via Dropout Training", "comments": "Submitted to AISTATS 2017 (Short-version is accepted to NIPS Workshop\n  on Efficient Methods for Deep Neural Networks)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dropout compaction, a novel method for training feed-forward\nneural networks which realizes the performance gains of training a large model\nwith dropout regularization, yet extracts a compact neural network for run-time\nefficiency. In the proposed method, we introduce a sparsity-inducing prior on\nthe per unit dropout retention probability so that the optimizer can\neffectively prune hidden units during training. By changing the prior\nhyperparameters, we can control the size of the resulting network. We performed\na systematic comparison of dropout compaction and competing methods on several\nreal-world speech recognition tasks and found that dropout compaction achieved\ncomparable accuracy with fewer than 50% of the hidden units, translating to a\n2.5x speedup in run-time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 16:20:41 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 12:26:43 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Kubo", "Yotaro", ""], ["Tucker", "George", ""], ["Wiesler", "Simon", ""]]}, {"id": "1611.06175", "submitter": "Adrien Bibal", "authors": "Adrien Bibal and Benoit Fr\\'enay", "title": "Learning Interpretability for Visualizations using Adapted Cox Models\n  through a User Experiment", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to be useful, visualizations need to be interpretable. This paper\nuses a user-based approach to combine and assess quality measures in order to\nbetter model user preferences. Results show that cluster separability measures\nare outperformed by a neighborhood conservation measure, even though the former\nare usually considered as intuitively representative of user motives. Moreover,\ncombining measures, as opposed to using a single measure, further improves\nprediction performances.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 17:52:23 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Bibal", "Adrien", ""], ["Fr\u00e9nay", "Benoit", ""]]}, {"id": "1611.06188", "submitter": "Yacine Jernite", "authors": "Yacine Jernite, Edouard Grave, Armand Joulin, Tomas Mikolov", "title": "Variable Computation in Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been used extensively and with\nincreasing success to model various types of sequential data. Much of this\nprogress has been achieved through devising recurrent units and architectures\nwith the flexibility to capture complex statistics in the data, such as long\nrange dependency or localized attention phenomena. However, while many\nsequential data (such as video, speech or language) can have highly variable\ninformation flow, most recurrent models still consume input features at a\nconstant rate and perform a constant number of computations per time step,\nwhich can be detrimental to both speed and model capacity. In this paper, we\nexplore a modification to existing recurrent units which allows them to learn\nto vary the amount of computation they perform at each step, without prior\nknowledge of the sequence's time structure. We show experimentally that not\nonly do our models require fewer operations, they also lead to better\nperformance overall on evaluation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 18:13:46 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:47:59 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Jernite", "Yacine", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1611.06204", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Eduard Hovy, Louis-Philippe Morency", "title": "Visualizing and Understanding Curriculum Learning for Long Short-Term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning emphasizes the order of training instances in a\ncomputational learning setup. The core hypothesis is that simpler instances\nshould be learned early as building blocks to learn more complex ones. Despite\nits usefulness, it is still unknown how exactly the internal representation of\nmodels are affected by curriculum learning. In this paper, we study the effect\nof curriculum learning on Long Short-Term Memory (LSTM) networks, which have\nshown strong competency in many Natural Language Processing (NLP) problems. Our\nexperiments on sentiment analysis task and a synthetic task similar to sequence\nprediction tasks in NLP show that curriculum learning has a positive effect on\nthe LSTM's internal states by biasing the model towards building constructive\nrepresentations i.e. the internal representation at the previous timesteps are\nused as building blocks for the final prediction. We also find that smaller\nmodels significantly improves when they are trained with curriculum learning.\nLastly, we show that curriculum learning helps more when the amount of training\ndata is limited.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 19:38:59 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Cirik", "Volkan", ""], ["Hovy", "Eduard", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1611.06213", "submitter": "Wei Zhang", "authors": "Wei Zhang, Minwei Feng, Yunhui Zheng, Yufei Ren, Yandong Wang, Ji Liu,\n  Peng Liu, Bing Xiang, Li Zhang, Bowen Zhou, Fei Wang", "title": "GaDei: On Scale-up Training As A Service For Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) training-as-a-service (TaaS) is an important emerging\nindustrial workload. The unique challenge of TaaS is that it must satisfy a\nwide range of customers who have no experience and resources to tune DL\nhyper-parameters, and meticulous tuning for each user's dataset is\nprohibitively expensive. Therefore, TaaS hyper-parameters must be fixed with\nvalues that are applicable to all users. IBM Watson Natural Language Classifier\n(NLC) service, the most popular IBM cognitive service used by thousands of\nenterprise-level clients around the globe, is a typical TaaS service. By\nevaluating the NLC workloads, we show that only the conservative\nhyper-parameter setup (e.g., small mini-batch size and small learning rate) can\nguarantee acceptable model accuracy for a wide range of customers. We further\njustify theoretically why such a setup guarantees better model convergence in\ngeneral. Unfortunately, the small mini-batch size causes a high volume of\ncommunication traffic in a parameter-server based system. We characterize the\nhigh communication bandwidth requirement of TaaS using representative\nindustrial deep learning workloads and demonstrate that none of the\nstate-of-the-art scale-up or scale-out solutions can satisfy such a\nrequirement. We then present GaDei, an optimized shared-memory based scale-up\nparameter server design. We prove that the designed protocol is deadlock-free\nand it processes each gradient exactly once. Our implementation is evaluated on\nboth commercial benchmarks and public benchmarks to demonstrate that it\nsignificantly outperforms the state-of-the-art parameter-server based\nimplementation while maintaining the required accuracy and our implementation\nreaches near the best possible runtime performance, constrained only by the\nhardware limitation. Furthermore, to the best of our knowledge, GaDei is the\nonly scale-up DL system that provides fault-tolerance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:06:27 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 20:30:19 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Zhang", "Wei", ""], ["Feng", "Minwei", ""], ["Zheng", "Yunhui", ""], ["Ren", "Yufei", ""], ["Wang", "Yandong", ""], ["Liu", "Ji", ""], ["Liu", "Peng", ""], ["Xiang", "Bing", ""], ["Zhang", "Li", ""], ["Zhou", "Bowen", ""], ["Wang", "Fei", ""]]}, {"id": "1611.06221", "submitter": "Stephan Bongers", "authors": "Stephan Bongers, Patrick Forr\\'e, Jonas Peters, Joris M. Mooij", "title": "Foundations of Structural Causal Models with Cycles and Latent Variables", "comments": "75 pages (including supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural causal models (SCMs), also known as (nonparametric) structural\nequation models (SEMs), are widely used for causal modeling purposes. In\nparticular, acyclic SCMs, also known as recursive SEMs, form a well-studied\nsubclass of SCMs that generalize causal Bayesian networks to allow for latent\nconfounders. In this paper, we investigate SCMs in a more general setting,\nallowing for the presence of both latent confounders and cycles. We show that\nin the presence of cycles, many of the convenient properties of acyclic SCMs do\nnot hold in general: they do not always have a solution; they do not always\ninduce unique observational, interventional and counterfactual distributions; a\nmarginalization does not always exist, and if it exists the marginal model does\nnot always respect the latent projection; they do not always satisfy a Markov\nproperty; and their graphs are not always consistent with their causal\nsemantics. We prove that for SCMs in general each of these properties does hold\nunder certain solvability conditions. Our work generalizes results for SCMs\nwith cycles that were only known for certain special cases so far. We introduce\nthe class of simple SCMs that extends the class of acyclic SCMs to the cyclic\nsetting, while preserving many of the convenient properties of acyclic SCMs.\nWith this paper we aim to provide the foundations for a general theory of\nstatistical causal modeling with SCMs.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:54:03 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 02:15:32 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 16:19:44 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 13:27:13 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 13:58:29 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bongers", "Stephan", ""], ["Forr\u00e9", "Patrick", ""], ["Peters", "Jonas", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1611.06222", "submitter": "Erik Waingarten", "authors": "Alexandr Andoni, Huy L. Nguyen, Aleksandar Nikolov, Ilya Razenshteyn,\n  Erik Waingarten", "title": "Approximate Near Neighbors for General Symmetric Norms", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every symmetric normed space admits an efficient nearest\nneighbor search data structure with doubly-logarithmic approximation.\nSpecifically, for every $n$, $d = n^{o(1)}$, and every $d$-dimensional\nsymmetric norm $\\|\\cdot\\|$, there exists a data structure for\n$\\mathrm{poly}(\\log \\log n)$-approximate nearest neighbor search over\n$\\|\\cdot\\|$ for $n$-point datasets achieving $n^{o(1)}$ query time and\n$n^{1+o(1)}$ space. The main technical ingredient of the algorithm is a\nlow-distortion embedding of a symmetric norm into a low-dimensional iterated\nproduct of top-$k$ norms.\n  We also show that our techniques cannot be extended to general norms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:56:26 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 13:21:13 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nguyen", "Huy L.", ""], ["Nikolov", "Aleksandar", ""], ["Razenshteyn", "Ilya", ""], ["Waingarten", "Erik", ""]]}, {"id": "1611.06241", "submitter": "Maciej Wielgosz", "authors": "Maciej Wielgosz and Andrzej Skocze\\'n and Matej Mertik", "title": "Using LSTM recurrent neural networks for monitoring the LHC\n  superconducting magnets", "comments": null, "journal-ref": null, "doi": "10.1016/j.nima.2017.06.020", "report-no": null, "categories": "physics.ins-det cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superconducting LHC magnets are coupled with an electronic monitoring\nsystem which records and analyses voltage time series reflecting their\nperformance. A currently used system is based on a range of preprogrammed\ntriggers which launches protection procedures when a misbehavior of the magnets\nis detected. All the procedures used in the protection equipment were designed\nand implemented according to known working scenarios of the system and are\nupdated and monitored by human operators.\n  This paper proposes a novel approach to monitoring and fault protection of\nthe Large Hadron Collider (LHC) superconducting magnets which employs\nstate-of-the-art Deep Learning algorithms. Consequently, the authors of the\npaper decided to examine the performance of LSTM recurrent neural networks for\nmodeling of voltage time series of the magnets. In order to address this\nchallenging task different network architectures and hyper-parameters were used\nto achieve the best possible performance of the solution. The regression\nresults were measured in terms of RMSE for different number of future steps and\nhistory length taken into account for the prediction. The best result of\nRMSE=0.00104 was obtained for a network of 128 LSTM cells within the internal\nlayer and 16 steps history buffer.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 21:06:00 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 20:38:36 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Wielgosz", "Maciej", ""], ["Skocze\u0144", "Andrzej", ""], ["Mertik", "Matej", ""]]}, {"id": "1611.06245", "submitter": "Anders S{\\o}gaard Anders S{\\o}gaard", "authors": "Anders S{\\o}gaard", "title": "Spikes as regularizers", "comments": "Computing with Spikes at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a confidence-based single-layer feed-forward learning algorithm\nSPIRAL (Spike Regularized Adaptive Learning) relying on an encoding of\nactivation spikes. We adaptively update a weight vector relying on confidence\nestimates and activation offsets relative to previous activity. We regularize\nupdates proportionally to item-level confidence and weight-specific support,\nloosely inspired by the observation from neurophysiology that high spike rates\nare sometimes accompanied by low temporal precision. Our experiments suggest\nthat the new learning algorithm SPIRAL is more robust and less prone to\noverfitting than both the averaged perceptron and AROW.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 21:09:16 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["S\u00f8gaard", "Anders", ""]]}, {"id": "1611.06256", "submitter": "Iuri Frosio", "authors": "Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, Jan\n  Kautz", "title": "Reinforcement Learning through Asynchronous Advantage Actor-Critic on a\n  GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hybrid CPU/GPU version of the Asynchronous Advantage\nActor-Critic (A3C) algorithm, currently the state-of-the-art method in\nreinforcement learning for various gaming tasks. We analyze its computational\ntraits and concentrate on aspects critical to leveraging the GPU's\ncomputational power. We introduce a system of queues and a dynamic scheduling\nstrategy, potentially helpful for other asynchronous algorithms as well. Our\nhybrid CPU/GPU version of A3C, based on TensorFlow, achieves a significant\nspeed up compared to a CPU implementation; we make it publicly available to\nother researchers at https://github.com/NVlabs/GA3C .\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 21:34:47 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 04:42:18 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 19:12:19 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Babaeizadeh", "Mohammad", ""], ["Frosio", "Iuri", ""], ["Tyree", "Stephen", ""], ["Clemons", "Jason", ""], ["Kautz", "Jan", ""]]}, {"id": "1611.06265", "submitter": "Yi Luo", "authors": "Yi Luo, Zhuo Chen, John R. Hershey, Jonathan Le Roux, Nima Mesgarani", "title": "Deep Clustering and Conventional Networks for Music Separation: Stronger\n  Together", "comments": "Published in ICASSP 2017", "journal-ref": null, "doi": "10.1109/ICASSP.2017.7952118", "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering is the first method to handle general audio separation\nscenarios with multiple sources of the same type and an arbitrary number of\nsources, performing impressively in speaker-independent speech separation\ntasks. However, little is known about its effectiveness in other challenging\nsituations such as music source separation. Contrary to conventional networks\nthat directly estimate the source signals, deep clustering generates an\nembedding for each time-frequency bin, and separates sources by clustering the\nbins in the embedding space. We show that deep clustering outperforms\nconventional networks on a singing voice separation task, in both matched and\nmismatched conditions, even though conventional networks have the advantage of\nend-to-end training for best signal approximation, presumably because its more\nflexible objective engenders better regularization. Since the strengths of deep\nclustering and conventional network architectures appear complementary, we\nexplore combining them in a single hybrid network trained via an approach akin\nto multi-task learning. Remarkably, the combination significantly outperforms\neither of its components.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 22:33:05 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 16:23:58 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Luo", "Yi", ""], ["Chen", "Zhuo", ""], ["Hershey", "John R.", ""], ["Roux", "Jonathan Le", ""], ["Mesgarani", "Nima", ""]]}, {"id": "1611.06306", "submitter": "Jim Jing-Yan Wang", "authors": "Yanbin Wu, Li Wang, Fan Cui, Hongbin Zhai, Baoming Dong, Jim Jing-Yan\n  Wang", "title": "Cross-model convolutional neural network for multiple modality data\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel data representation method of convolutional neural net- work (CNN) is\nproposed in this paper to represent data of different modalities. We learn a\nCNN model for the data of each modality to map the data of differ- ent\nmodalities to a common space, and regularize the new representations in the\ncommon space by a cross-model relevance matrix. We further impose that the\nclass label of data points can also be predicted from the CNN representa- tions\nin the common space. The learning problem is modeled as a minimiza- tion\nproblem, which is solved by an augmented Lagrange method (ALM) with updating\nrules of Alternating direction method of multipliers (ADMM). The experiments\nover benchmark of sequence data of multiple modalities show its advantage.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 05:24:48 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Wu", "Yanbin", ""], ["Wang", "Li", ""], ["Cui", "Fan", ""], ["Zhai", "Hongbin", ""], ["Dong", "Baoming", ""], ["Wang", "Jim Jing-Yan", ""]]}, {"id": "1611.06310", "submitter": "Razvan Pascanu", "authors": "Grzegorz Swirszcz, Wojciech Marian Czarnecki and Razvan Pascanu", "title": "Local minima in training of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a lot of recent interest in trying to characterize the error\nsurface of deep models. This stems from a long standing question. Given that\ndeep networks are highly nonlinear systems optimized by local gradient methods,\nwhy do they not seem to be affected by bad local minima? It is widely believed\nthat training of deep models using gradient methods works so well because the\nerror surface either has no local minima, or if they exist they need to be\nclose in value to the global minimum. It is known that such results hold under\nvery strong assumptions which are not satisfied by real models. In this paper\nwe present examples showing that for such theorem to be true additional\nassumptions on the data, initialization schemes and/or the model classes have\nto be made. We look at the particular case of finite size datasets. We\ndemonstrate that in this scenario one can construct counter-examples (datasets\nor initialization schemes) when the network does become susceptible to bad\nlocal minima over the weight space.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 05:49:22 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 14:51:54 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Swirszcz", "Grzegorz", ""], ["Czarnecki", "Wojciech Marian", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1611.06321", "submitter": "Jose M. Alvarez", "authors": "Jose M Alvarez and Mathieu Salzmann", "title": "Learning the Number of Neurons in Deep Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the number of layers and of neurons in each layer of a deep network\nare typically set manually. While very deep and wide networks have proven\neffective in general, they come at a high memory and computation cost, thus\nmaking them impractical for constrained platforms. These networks, however, are\nknown to have many redundant parameters, and could thus, in principle, be\nreplaced by more compact architectures. In this paper, we introduce an approach\nto automatically determining the number of neurons in each layer of a deep\nnetwork during learning. To this end, we propose to make use of structured\nsparsity during learning. More precisely, we use a group sparsity regularizer\non the parameters of the network, where each group is defined to act on a\nsingle neuron. Starting from an overcomplete network, we show that our approach\ncan reduce the number of parameters by up to 80\\% while retaining or even\nimproving the network accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 07:18:17 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 05:21:29 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 07:18:09 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Alvarez", "Jose M", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "1611.06342", "submitter": "Sungho Shin", "authors": "Sungho Shin, Kyuyeon Hwang, and Wonyong Sung", "title": "Quantized neural network design under weight capacity constraint", "comments": "This paper is accepted at NIPS 2016 workshop on Efficient Methods for\n  Deep Neural Networks (EMDNN). arXiv admin note: text overlap with\n  arXiv:1511.06488", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of deep neural network algorithms for hardware implementation\ncan be lowered either by scaling the number of units or reducing the\nword-length of weights. Both approaches, however, can accompany the performance\ndegradation although many types of research are conducted to relieve this\nproblem. Thus, it is an important question which one, between the network size\nscaling and the weight quantization, is more effective for hardware\noptimization. For this study, the performances of fully-connected deep neural\nnetworks (FCDNNs) and convolutional neural networks (CNNs) are evaluated while\nchanging the network complexity and the word-length of weights. Based on these\nexperiments, we present the effective compression ratio (ECR) to guide the\ntrade-off between the network size and the precision of weights when the\nhardware resource is limited.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 11:21:25 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Shin", "Sungho", ""], ["Hwang", "Kyuyeon", ""], ["Sung", "Wonyong", ""]]}, {"id": "1611.06426", "submitter": "Abbas Kazerouni", "authors": "Abbas Kazerouni, Mohammad Ghavamzadeh, Yasin Abbasi-Yadkori and\n  Benjamin Van Roy", "title": "Conservative Contextual Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is a desirable property that can immensely increase the applicability\nof learning algorithms in real-world decision-making problems. It is much\neasier for a company to deploy an algorithm that is safe, i.e., guaranteed to\nperform at least as well as a baseline. In this paper, we study the issue of\nsafety in contextual linear bandits that have application in many different\nfields including personalized ad recommendation in online marketing. We\nformulate a notion of safety for this class of algorithms. We develop a safe\ncontextual linear bandit algorithm, called conservative linear UCB (CLUCB),\nthat simultaneously minimizes its regret and satisfies the safety constraint,\ni.e., maintains its performance above a fixed percentage of the performance of\na baseline strategy, uniformly over time. We prove an upper-bound on the regret\nof CLUCB and show that it can be decomposed into two terms: 1) an upper-bound\nfor the regret of the standard linear UCB algorithm that grows with the time\nhorizon and 2) a constant (does not grow with the time horizon) term that\naccounts for the loss of being conservative in order to satisfy the safety\nconstraint. We empirically show that our algorithm is safe and validate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 20:36:30 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 01:28:26 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Kazerouni", "Abbas", ""], ["Ghavamzadeh", "Mohammad", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1611.06439", "submitter": "Reza Ebrahimi Atani", "authors": "SamanehSorournejad, Zahra Zojaji, Reza Ebrahimi Atani, Amir Hassan\n  Monadjemi", "title": "A Survey of Credit Card Fraud Detection Techniques: Data and Technique\n  Oriented Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit card plays a very important rule in today's economy. It becomes an\nunavoidable part of household, business and global activities. Although using\ncredit cards provides enormous benefits when used carefully and\nresponsibly,significant credit and financial damages may be caused by\nfraudulent activities. Many techniques have been proposed to confront the\ngrowth in credit card fraud. However, all of these techniques have the same\ngoal of avoiding the credit card fraud; each one has its own drawbacks,\nadvantages and characteristics. In this paper, after investigating difficulties\nof credit card fraud detection, we seek to review the state of the art in\ncredit card fraud detection techniques, data sets and evaluation criteria.The\nadvantages and disadvantages of fraud detection methods are enumerated and\ncompared.Furthermore, a classification of mentioned techniques into two main\nfraud detection approaches, namely, misuses (supervised) and anomaly detection\n(unsupervised) is presented. Again, a classification of techniques is proposed\nbased on capability to process the numerical and categorical data sets.\nDifferent data sets used in literature are then described and grouped into real\nand synthesized data and the effective and common attributes are extracted for\nfurther usage.Moreover, evaluation employed criterions in literature are\ncollected and discussed.Consequently, open issues for credit card fraud\ndetection are explained as guidelines for new researchers.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 22:46:13 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["SamanehSorournejad", "", ""], ["Zojaji", "Zahra", ""], ["Atani", "Reza Ebrahimi", ""], ["Monadjemi", "Amir Hassan", ""]]}, {"id": "1611.06440", "submitter": "Pavlo Molchanov", "authors": "Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, Jan Kautz", "title": "Pruning Convolutional Neural Networks for Resource Efficient Inference", "comments": "17 pages, 14 figures, ICLR 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new formulation for pruning convolutional kernels in neural\nnetworks to enable efficient inference. We interleave greedy criteria-based\npruning with fine-tuning by backpropagation - a computationally efficient\nprocedure that maintains good generalization in the pruned network. We propose\na new criterion based on Taylor expansion that approximates the change in the\ncost function induced by pruning network parameters. We focus on transfer\nlearning, where large pretrained networks are adapted to specialized tasks. The\nproposed criterion demonstrates superior performance compared to other\ncriteria, e.g. the norm of kernel weights or feature map activation, for\npruning large CNNs after adaptation to fine-grained classification tasks\n(Birds-200 and Flowers-102) relaying only on the first order gradient\ninformation. We also show that pruning can lead to more than 10x theoretical\n(5x practical) reduction in adapted 3D-convolutional filters with a small drop\nin accuracy in a recurrent gesture classifier. Finally, we show results for the\nlarge-scale ImageNet dataset to emphasize the flexibility of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 22:48:30 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 19:53:26 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Molchanov", "Pavlo", ""], ["Tyree", "Stephen", ""], ["Karras", "Tero", ""], ["Aila", "Timo", ""], ["Kautz", "Jan", ""]]}, {"id": "1611.06453", "submitter": "Haichen Shen", "authors": "Haichen Shen, Seungyeop Han, Matthai Philipose, Arvind Krishnamurthy", "title": "Fast Video Classification via Adaptive Cascading of Deep Models", "comments": "Accepted at IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances have enabled \"oracle\" classifiers that can classify across\nmany classes and input distributions with high accuracy without retraining.\nHowever, these classifiers are relatively heavyweight, so that applying them to\nclassify video is costly. We show that day-to-day video exhibits highly skewed\nclass distributions over the short term, and that these distributions can be\nclassified by much simpler models. We formulate the problem of detecting the\nshort-term skews online and exploiting models based on it as a new sequential\ndecision making problem dubbed the Online Bandit Problem, and present a new\nalgorithm to solve it. When applied to recognizing faces in TV shows and\nmovies, we realize end-to-end classification speedups of 2.4-7.8x/2.6-11.2x (on\nGPU/CPU) relative to a state-of-the-art convolutional neural network, at\ncompetitive accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 00:21:32 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 02:17:00 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Shen", "Haichen", ""], ["Han", "Seungyeop", ""], ["Philipose", "Matthai", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1611.06455", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Weizhong Yan, Tim Oates", "title": "Time Series Classification from Scratch with Deep Neural Networks: A\n  Strong Baseline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple but strong baseline for time series classification from\nscratch with deep neural networks. Our proposed baseline models are pure\nend-to-end without any heavy preprocessing on the raw data or feature crafting.\nThe proposed Fully Convolutional Network (FCN) achieves premium performance to\nother state-of-the-art approaches and our exploration of the very deep neural\nnetworks with the ResNet structure is also competitive. The global average\npooling in our convolutional model enables the exploitation of the Class\nActivation Map (CAM) to find out the contributing region in the raw data for\nthe specific labels. Our models provides a simple choice for the real world\napplication and a good starting point for the future research. An overall\nanalysis is provided to discuss the generalization capability of our models,\nlearned features, network structures and the classification semantics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 00:34:09 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 02:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 06:39:49 GMT"}, {"version": "v4", "created": "Wed, 14 Dec 2016 06:58:08 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Wang", "Zhiguang", ""], ["Yan", "Weizhong", ""], ["Oates", "Tim", ""]]}, {"id": "1611.06475", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman", "title": "Dealing with Range Anxiety in Mean Estimation via Statistical Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms for estimating the expectation of a given real-valued\nfunction $\\phi:X\\to {\\bf R}$ on a sample drawn randomly from some unknown\ndistribution $D$ over domain $X$, namely ${\\bf E}_{{\\bf x}\\sim D}[\\phi({\\bf\nx})]$. Our algorithms work in two well-studied models of restricted access to\ndata samples. The first one is the statistical query (SQ) model in which an\nalgorithm has access to an SQ oracle for the input distribution $D$ over $X$\ninstead of i.i.d. samples from $D$. Given a query function $\\phi:X \\to [0,1]$,\nthe oracle returns an estimate of ${\\bf E}_{{\\bf x}\\sim D}[\\phi({\\bf x})]$\nwithin some tolerance $\\tau$. The second, is a model in which only a single bit\nis communicated from each sample. In both of these models the error obtained\nusing a naive implementation would scale polynomially with the range of the\nrandom variable $\\phi({\\bf x})$ (which might even be infinite). In contrast,\nwithout restrictions on access to data the expected error scales with the\nstandard deviation of $\\phi({\\bf x})$. Here we give a simple algorithm whose\nerror scales linearly in standard deviation of $\\phi({\\bf x})$ and\nlogarithmically with an upper bound on the second moment of $\\phi({\\bf x})$.\n  As corollaries, we obtain algorithms for high dimensional mean estimation and\nstochastic convex optimization in these models that work in more general\nsettings than previously known solutions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 06:12:43 GMT"}, {"version": "v2", "created": "Sat, 26 Aug 2017 02:25:41 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Feldman", "Vitaly", ""]]}, {"id": "1611.06530", "submitter": "Dingkun Long", "authors": "Dingkun Long, Richong Zhang, Yongyi Mao", "title": "Prototypical Recurrent Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great successes of deep learning, the effectiveness of deep\nneural networks has not been understood at any theoretical depth. This work is\nmotivated by the thrust of developing a deeper understanding of recurrent\nneural networks, particularly LSTM/GRU-like networks. As the highly complex\nstructure of the recurrent unit in LSTM and GRU networks makes them difficult\nto analyze, our methodology in this research theme is to construct an\nalternative recurrent unit that is as simple as possible and yet also captures\nthe key components of LSTM/GRU recurrent units. Such a unit can then be used\nfor the study of recurrent networks and its structural simplicity may allow\neasier analysis. Towards that goal, we take a system-theoretic perspective to\ndesign a new recurrent unit, which we call the prototypical recurrent unit\n(PRU). Not only having minimal complexity, PRU is demonstrated experimentally\nto have comparable performance to GRU and LSTM unit. This establishes PRU\nnetworks as a prototype for future study of LSTM/GRU-like recurrent networks.\nThis paper also studies the memorization abilities of LSTM, GRU and PRU\nnetworks, motivated by the folk belief that such networks possess long-term\nmemory. For this purpose, we design a simple and controllable task, called\n``memorization problem'', where the networks are trained to memorize certain\ntargeted information. We show that the memorization performance of all three\nnetworks depends on the amount of targeted information, the amount of\n``interfering\" information, and the state space dimension of the recurrent\nunit. Experiments are also performed for another controllable task, the adding\nproblem, and similar conclusions are obtained.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 15:39:43 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 18:07:25 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Long", "Dingkun", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""]]}, {"id": "1611.06534", "submitter": "Marc Abeille", "authors": "Marc Abeille, Alessandro Lazaric", "title": "Linear Thompson Sampling Revisited", "comments": null, "journal-ref": null, "doi": "10.1214/154957804100000000", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an alternative proof for the regret of Thompson sampling (\\ts) in\nthe stochastic linear bandit setting. While we obtain a regret bound of order\n$\\widetilde{O}(d^{3/2}\\sqrt{T})$ as in previous results, the proof sheds new\nlight on the functioning of the \\ts. We leverage on the structure of the\nproblem to show how the regret is related to the sensitivity (i.e., the\ngradient) of the objective function and how selecting optimal arms associated\nto \\textit{optimistic} parameters does control it. Thus we show that \\ts can be\nseen as a generic randomized algorithm where the sampling distribution is\ndesigned to have a fixed probability of being optimistic, at the cost of an\nadditional $\\sqrt{d}$ regret factor compared to a UCB-like approach.\nFurthermore, we show that our proof can be readily applied to regularized\nlinear optimization and generalized linear model problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 15:52:41 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 16:50:53 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 16:35:05 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Abeille", "Marc", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1611.06539", "submitter": "Sebastian Vogel", "authors": "Sebastian Vogel, Christoph Schorn, Andre Guntoro, Gerd Ascheid", "title": "Efficient Stochastic Inference of Bitwise Deep Neural Networks", "comments": "6 pages, 3 figures, Workshop on Efficient Methods for Deep Neural\n  Networks at Neural Information Processing Systems Conference 2016, NIPS 2016,\n  EMDNN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently published methods enable training of bitwise neural networks which\nallow reduced representation of down to a single bit per weight. We present a\nmethod that exploits ensemble decisions based on multiple stochastically\nsampled network models to increase performance figures of bitwise neural\nnetworks in terms of classification accuracy at inference. Our experiments with\nthe CIFAR-10 and GTSRB datasets show that the performance of such network\nensembles surpasses the performance of the high-precision base model. With this\ntechnique we achieve 5.81% best classification error on CIFAR-10 test set using\nbitwise networks. Concerning inference on embedded systems we evaluate these\nbitwise networks using a hardware efficient stochastic rounding procedure. Our\nwork contributes to efficient embedded bitwise neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 16:05:07 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Vogel", "Sebastian", ""], ["Schorn", "Christoph", ""], ["Guntoro", "Andre", ""], ["Ascheid", "Gerd", ""]]}, {"id": "1611.06585", "submitter": "Andrew Miller", "authors": "Andrew C. Miller, Nicholas Foti, Ryan P. Adams", "title": "Variational Boosting: Iteratively Refining Posterior Approximations", "comments": "25 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a black-box variational inference method to approximate\nintractable distributions with an increasingly rich approximating class. Our\nmethod, termed variational boosting, iteratively refines an existing\nvariational approximation by solving a sequence of optimization problems,\nallowing the practitioner to trade computation time for accuracy. We show how\nto expand the variational approximating class by incorporating additional\ncovariance structure and by introducing new components to form a mixture. We\napply variational boosting to synthetic and real statistical models, and show\nthat resulting posterior inferences compare favorably to existing posterior\napproximation algorithms in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 20:25:39 GMT"}, {"version": "v2", "created": "Sun, 19 Feb 2017 17:30:28 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Miller", "Andrew C.", ""], ["Foti", "Nicholas", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1611.06624", "submitter": "Masaki Saito", "authors": "Masaki Saito, Eiichi Matsumoto, Shunta Saito", "title": "Temporal Generative Adversarial Nets with Singular Value Clipping", "comments": "to appear in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generative model, Temporal Generative Adversarial\nNets (TGAN), which can learn a semantic representation of unlabeled videos, and\nis capable of generating videos. Unlike existing Generative Adversarial Nets\n(GAN)-based methods that generate videos with a single generator consisting of\n3D deconvolutional layers, our model exploits two different types of\ngenerators: a temporal generator and an image generator. The temporal generator\ntakes a single latent variable as input and outputs a set of latent variables,\neach of which corresponds to an image frame in a video. The image generator\ntransforms a set of such latent variables into a video. To deal with\ninstability in training of GAN with such advanced networks, we adopt a recently\nproposed model, Wasserstein GAN, and propose a novel method to train it stably\nin an end-to-end manner. The experimental results demonstrate the effectiveness\nof our methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 01:10:50 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 01:33:45 GMT"}, {"version": "v3", "created": "Fri, 18 Aug 2017 02:32:16 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Saito", "Masaki", ""], ["Matsumoto", "Eiichi", ""], ["Saito", "Shunta", ""]]}, {"id": "1611.06651", "submitter": "He Yang", "authors": "He Yang, Hengyong Yu and Ge Wang", "title": "Deep Learning for the Classification of Lung Nodules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, as a promising new area of machine learning, has attracted a\nrapidly increasing attention in the field of medical imaging. Compared to the\nconventional machine learning methods, deep learning requires no hand-tuned\nfeature extractor, and has shown a superior performance in many visual object\nrecognition applications. In this study, we develop a deep convolutional neural\nnetwork (CNN) and apply it to thoracic CT images for the classification of lung\nnodules. We present the CNN architecture and classification accuracy for the\noriginal images of lung nodules. In order to understand the features of lung\nnodules, we further construct new datasets, based on the combination of\nartificial geometric nodules and some transformations of the original images,\nas well as a stochastic nodule shape model. It is found that simplistic\ngeometric nodules cannot capture the important features of lung nodules.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 05:12:44 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 21:43:48 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Yang", "He", ""], ["Yu", "Hengyong", ""], ["Wang", "Ge", ""]]}, {"id": "1611.06652", "submitter": "Brian McWilliams", "authors": "Gabriel Krummenacher and Brian McWilliams and Yannic Kilcher and\n  Joachim M. Buhmann and Nicolai Meinshausen", "title": "Scalable Adaptive Stochastic Optimization Using Random Projections", "comments": "To appear in Advances in Neural Information Processing Systems 29\n  (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive stochastic gradient methods such as AdaGrad have gained popularity\nin particular for training deep neural networks. The most commonly used and\nstudied variant maintains a diagonal matrix approximation to second order\ninformation by accumulating past gradients which are used to tune the step size\nadaptively. In certain situations the full-matrix variant of AdaGrad is\nexpected to attain better performance, however in high dimensions it is\ncomputationally impractical. We present Ada-LR and RadaGrad two computationally\nefficient approximations to full-matrix AdaGrad based on randomized\ndimensionality reduction. They are able to capture dependencies between\nfeatures and achieve similar performance to full-matrix AdaGrad but at a much\nsmaller computational cost. We show that the regret of Ada-LR is close to the\nregret of full-matrix AdaGrad which can have an up-to exponentially smaller\ndependence on the dimension than the diagonal variant. Empirically, we show\nthat Ada-LR and RadaGrad perform similarly to full-matrix AdaGrad. On the task\nof training convolutional neural networks as well as recurrent neural networks,\nRadaGrad achieves faster convergence than diagonal AdaGrad.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 05:15:50 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Krummenacher", "Gabriel", ""], ["McWilliams", "Brian", ""], ["Kilcher", "Yannic", ""], ["Buhmann", "Joachim M.", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1611.06670", "submitter": "Biqin Song", "authors": "Yanfang Tao, Peipei Yuan, Biqin Song", "title": "Error analysis of regularized least-square regression with Fredholm\n  kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with Fredholm kernel has attracted increasing attention recently\nsince it can effectively utilize the data information to improve the prediction\nperformance. Despite rapid progress on theoretical and experimental\nevaluations, its generalization analysis has not been explored in learning\ntheory literature. In this paper, we establish the generalization bound of\nleast square regularized regression with Fredholm kernel, which implies that\nthe fast learning rate O(l^{-1}) can be reached under mild capacity conditions.\nSimulated examples show that this Fredholm regression algorithm can achieve the\nsatisfactory prediction performance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 07:03:46 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Tao", "Yanfang", ""], ["Yuan", "Peipei", ""], ["Song", "Biqin", ""]]}, {"id": "1611.06684", "submitter": "Lars Mescheder", "authors": "Lars Mescheder, Sebastian Nowozin and Andreas Geiger", "title": "Probabilistic Duality for Parallel Gibbs Sampling without Graph Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new notion of probabilistic duality for random variables\ninvolving mixture distributions. Using this notion, we show how to implement a\nhighly-parallelizable Gibbs sampler for weakly coupled discrete pairwise\ngraphical models with strictly positive factors that requires almost no\npreprocessing and is easy to implement. Moreover, we show how our method can be\ncombined with blocking to improve mixing. Even though our method leads to\ninferior mixing times compared to a sequential Gibbs sampler, we argue that our\nmethod is still very useful for large dynamic networks, where factors are added\nand removed on a continuous basis, as it is hard to maintain a graph coloring\nin this setup. Similarly, our method is useful for parallelizing Gibbs sampling\nin graphical models that do not allow for graph colorings with a small number\nof colors such as densely connected graphs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 08:57:58 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Mescheder", "Lars", ""], ["Nowozin", "Sebastian", ""], ["Geiger", "Andreas", ""]]}, {"id": "1611.06694", "submitter": "Akshayvarun Subramanya", "authors": "Suraj Srinivas, Akshayvarun Subramanya, R. Venkatesh Babu", "title": "Training Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with lots of parameters are typically used for\nlarge-scale computer vision tasks such as image classification. This is a\nresult of using dense matrix multiplications and convolutions. However, sparse\ncomputations are known to be much more efficient. In this work, we train and\nbuild neural networks which implicitly use sparse computations. We introduce\nadditional gate variables to perform parameter selection and show that this is\nequivalent to using a spike-and-slab prior. We experimentally validate our\nmethod on both small and large networks and achieve state-of-the-art\ncompression results for sparse neural network models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 09:24:24 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Srinivas", "Suraj", ""], ["Subramanya", "Akshayvarun", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1611.06730", "submitter": "Panayotis Mertikopoulos", "authors": "Panayotis Mertikopoulos and Mathias Staudigl", "title": "On the convergence of gradient-like flows with noisy gradient input", "comments": "36 pages, 5 figures; revised proof structure, added numerical case\n  study in Section 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In view of solving convex optimization problems with noisy gradient input, we\nanalyze the asymptotic behavior of gradient-like flows under stochastic\ndisturbances. Specifically, we focus on the widely studied class of mirror\ndescent schemes for convex programs with compact feasible regions, and we\nexamine the dynamics' convergence and concentration properties in the presence\nof noise. In the vanishing noise limit, we show that the dynamics converge to\nthe solution set of the underlying problem (a.s.). Otherwise, when the noise is\npersistent, we show that the dynamics are concentrated around interior\nsolutions in the long run, and they converge to boundary solutions that are\nsufficiently \"sharp\". Finally, we show that a suitably rectified variant of the\nmethod converges irrespective of the magnitude of the noise (or the structure\nof the underlying convex program), and we derive an explicit estimate for its\nrate of convergence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 11:29:40 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 07:32:28 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Mertikopoulos", "Panayotis", ""], ["Staudigl", "Mathias", ""]]}, {"id": "1611.06759", "submitter": "J\\'er\\^ome Tubiana", "authors": "J\\'er\\^ome Tubiana (LPTENS), R\\'emi Monasson (LPTENS)", "title": "Emergence of Compositional Representations in Restricted Boltzmann\n  Machines", "comments": "Supplementary material available at the authors' webpage", "journal-ref": "Phys. Rev. Lett. 118, 138301 (2017)", "doi": "10.1103/PhysRevLett.118.138301", "report-no": null, "categories": "physics.data-an cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting automatically the complex set of features composing real\nhigh-dimensional data is crucial for achieving high performance in\nmachine--learning tasks. Restricted Boltzmann Machines (RBM) are empirically\nknown to be efficient for this purpose, and to be able to generate distributed\nand graded representations of the data. We characterize the structural\nconditions (sparsity of the weights, low effective temperature, nonlinearities\nin the activation functions of hidden units, and adaptation of fields\nmaintaining the activity in the visible layer) allowing RBM to operate in such\na compositional phase. Evidence is provided by the replica analysis of an\nadequate statistical ensemble of random RBMs and by RBM trained on the\nhandwritten digits dataset MNIST.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 12:46:25 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 21:50:02 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Tubiana", "J\u00e9r\u00f4me", "", "LPTENS"], ["Monasson", "R\u00e9mi", "", "LPTENS"]]}, {"id": "1611.06777", "submitter": "Fengfu Li", "authors": "Fengfu Li, Hong Qiao, and Bo Zhang", "title": "Effective Deterministic Initialization for $k$-Means-Like Methods via\n  Local Density Peaks Searching", "comments": "16 pages, 9 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-means clustering algorithm is popular but has the following main\ndrawbacks: 1) the number of clusters, $k$, needs to be provided by the user in\nadvance, 2) it can easily reach local minima with randomly selected initial\ncenters, 3) it is sensitive to outliers, and 4) it can only deal with well\nseparated hyperspherical clusters. In this paper, we propose a Local Density\nPeaks Searching (LDPS) initialization framework to address these issues. The\nLDPS framework includes two basic components: one of them is the local density\nthat characterizes the density distribution of a data set, and the other is the\nlocal distinctiveness index (LDI) which we introduce to characterize how\ndistinctive a data point is compared with its neighbors. Based on these two\ncomponents, we search for the local density peaks which are characterized with\nhigh local densities and high LDIs to deal with 1) and 2). Moreover, we detect\noutliers characterized with low local densities but high LDIs, and exclude them\nout before clustering begins. Finally, we apply the LDPS initialization\nframework to $k$-medoids, which is a variant of $k$-means and chooses data\nsamples as centers, with diverse similarity measures other than the Euclidean\ndistance to fix the last drawback of $k$-means. Combining the LDPS\ninitialization framework with $k$-means and $k$-medoids, we obtain two novel\nclustering methods called LDPS-means and LDPS-medoids, respectively.\nExperiments on synthetic data sets verify the effectiveness of the proposed\nmethods, especially when the ground truth of the cluster number $k$ is large.\nFurther, experiments on several real world data sets, Handwritten Pendigits,\nCoil-20, Coil-100 and Olivetti Face Database, illustrate that our methods give\na superior performance than the analogous approaches on both estimating $k$ and\nunsupervised object categorization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 13:26:37 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Li", "Fengfu", ""], ["Qiao", "Hong", ""], ["Zhang", "Bo", ""]]}, {"id": "1611.06791", "submitter": "Suraj Srinivas", "authors": "Suraj Srinivas, R. Venkatesh Babu", "title": "Generalized Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks often require good regularizers to generalize well.\nDropout is one such regularizer that is widely used among Deep Learning\npractitioners. Recent work has shown that Dropout can also be viewed as\nperforming Approximate Bayesian Inference over the network parameters. In this\nwork, we generalize this notion and introduce a rich family of regularizers\nwhich we call Generalized Dropout. One set of methods in this family, called\nDropout++, is a version of Dropout with trainable parameters. Classical Dropout\nemerges as a special case of this method. Another member of this family selects\nthe width of neural network layers. Experiments show that these methods help in\nimproving generalization performance over Dropout.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 14:06:48 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Srinivas", "Suraj", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1611.06824", "submitter": "Aur\\'elia L\\'eon", "authors": "Aur\\'elia L\\'eon, Ludovic Denoyer", "title": "Options Discovery with Budgeted Reinforcement Learning", "comments": "Under review as a conference paper at IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning hierarchical policies for Reinforcement\nLearning able to discover options, an option corresponding to a sub-policy over\na set of primitive actions. Different models have been proposed during the last\ndecade that usually rely on a predefined set of options. We specifically\naddress the problem of automatically discovering options in decision processes.\nWe describe a new learning model called Budgeted Option Neural Network (BONN)\nable to discover options based on a budgeted learning objective. The BONN model\nis evaluated on different classical RL problems, demonstrating both\nquantitative and qualitative interesting results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 15:05:55 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 17:06:24 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2017 13:12:33 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["L\u00e9on", "Aur\u00e9lia", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1611.06863", "submitter": "Tom Rainforth", "authors": "David Janz, Brooks Paige, Tom Rainforth, Jan-Willem van de Meent,\n  Frank Wood", "title": "Probabilistic structure discovery in time series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for structure discovery in time series data construct\ninterpretable, compositional kernels for Gaussian process regression models.\nWhile the learned Gaussian process model provides posterior mean and variance\nestimates, typically the structure is learned via a greedy optimization\nprocedure. This restricts the space of possible solutions and leads to\nover-confident uncertainty estimates. We introduce a fully Bayesian approach,\ninferring a full posterior over structures, which more reliably captures the\nuncertainty of the model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 16:08:12 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Janz", "David", ""], ["Paige", "Brooks", ""], ["Rainforth", "Tom", ""], ["van de Meent", "Jan-Willem", ""], ["Wood", "Frank", ""]]}, {"id": "1611.06882", "submitter": "Luca de Alfaro", "authors": "Rakshit Agrawal, Luca de Alfaro, Vassilis Polychronopoulos", "title": "Learning From Graph Neighborhoods Using LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report UCSC-SOE-16-17, School of Engineering, University\n  of California, Santa Cruz", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many prediction problems can be phrased as inferences over local\nneighborhoods of graphs. The graph represents the interaction between entities,\nand the neighborhood of each entity contains information that allows the\ninferences or predictions. We present an approach for applying machine learning\ndirectly to such graph neighborhoods, yielding predicitons for graph nodes on\nthe basis of the structure of their local neighborhood and the features of the\nnodes in it. Our approach allows predictions to be learned directly from\nexamples, bypassing the step of creating and tuning an inference model or\nsummarizing the neighborhoods via a fixed set of hand-crafted features. The\napproach is based on a multi-level architecture built from Long Short-Term\nMemory neural nets (LSTMs); the LSTMs learn how to summarize the neighborhood\nfrom data. We demonstrate the effectiveness of the proposed technique on a\nsynthetic example and on real-world data related to crowdsourced grading,\nBitcoin transactions, and Wikipedia edit reversions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 16:25:34 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Agrawal", "Rakshit", ""], ["de Alfaro", "Luca", ""], ["Polychronopoulos", "Vassilis", ""]]}, {"id": "1611.06933", "submitter": "Jacob Eisenstein", "authors": "Jacob Eisenstein", "title": "Unsupervised Learning for Lexicon-Based Classification", "comments": "to appear in AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In lexicon-based classification, documents are assigned labels by comparing\nthe number of words that appear from two opposed lexicons, such as positive and\nnegative sentiment. Creating such words lists is often easier than labeling\ninstances, and they can be debugged by non-experts if classification\nperformance is unsatisfactory. However, there is little analysis or\njustification of this classification heuristic. This paper describes a set of\nassumptions that can be used to derive a probabilistic justification for\nlexicon-based classification, as well as an analysis of its expected accuracy.\nOne key assumption behind lexicon-based classification is that all words in\neach lexicon are equally predictive. This is rarely true in practice, which is\nwhy lexicon-based approaches are usually outperformed by supervised classifiers\nthat learn distinct weights on each word from labeled instances. This paper\nshows that it is possible to learn such weights without labeled data, by\nleveraging co-occurrence statistics across the lexicons. This offers the best\nof both worlds: light supervision in the form of lexicons, and data-driven\nclassification with higher accuracy than traditional word-counting heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 18:30:17 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Eisenstein", "Jacob", ""]]}, {"id": "1611.06950", "submitter": "Jie Mei", "authors": "Jie Mei, Aminul Islam, Yajing Wu, Abidalrahman Moh'd, Evangelos E.\n  Milios", "title": "Statistical Learning for OCR Text Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of Optical Character Recognition (OCR) is crucial to the success\nof subsequent applications used in text analyzing pipeline. Recent models of\nOCR post-processing significantly improve the quality of OCR-generated text,\nbut are still prone to suggest correction candidates from limited observations\nwhile insufficiently accounting for the characteristics of OCR errors. In this\npaper, we show how to enlarge candidate suggestion space by using external\ncorpus and integrating OCR-specific features in a regression approach to\ncorrect OCR-generated errors. The evaluation results show that our model can\ncorrect 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of\nthe OCR-errors (considering the top 3 suggestions), for cases where the\ntheoretical correction upper-bound is 78%.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:00:32 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Mei", "Jie", ""], ["Islam", "Aminul", ""], ["Wu", "Yajing", ""], ["Moh'd", "Abidalrahman", ""], ["Milios", "Evangelos E.", ""]]}, {"id": "1611.06953", "submitter": "Asli Celikyilmaz", "authors": "Tarik Arici and Asli Celikyilmaz", "title": "Associative Adversarial Networks", "comments": "NIPS 2016 Workshop on Adversarial Training", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a higher-level associative memory for learning adversarial\nnetworks. Generative adversarial network (GAN) framework has a discriminator\nand a generator network. The generator (G) maps white noise (z) to data samples\nwhile the discriminator (D) maps data samples to a single scalar. To do so, G\nlearns how to map from high-level representation space to data space, and D\nlearns to do the opposite. We argue that higher-level representation spaces\nneed not necessarily follow a uniform probability distribution. In this work,\nwe use Restricted Boltzmann Machines (RBMs) as a higher-level associative\nmemory and learn the probability distribution for the high-level features\ngenerated by D. The associative memory samples its underlying probability\ndistribution and G learns how to map these samples to data space. The proposed\nassociative adversarial networks (AANs) are generative models in the\nhigher-levels of the learning, and use adversarial non-stochastic models D and\nG for learning the mapping between data and higher-level representation spaces.\nExperiments show the potential of the proposed networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 02:11:40 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Arici", "Tarik", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1611.06972", "submitter": "Jack Gorham", "authors": "Jackson Gorham, Andrew B. Duncan, Sebastian J. Vollmer, and Lester\n  Mackey", "title": "Measuring Sample Quality with Diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein's method for measuring convergence to a continuous target distribution\nrelies on an operator characterizing the target and Stein factor bounds on the\nsolutions of an associated differential equation. While such operators and\nbounds are readily available for a diversity of univariate targets, few\nmultivariate targets have been analyzed. We introduce a new class of\ncharacterizing operators based on Ito diffusions and develop explicit\nmultivariate Stein factor bounds for any target with a fast-coupling Ito\ndiffusion. As example applications, we develop computable and\nconvergence-determining diffusion Stein discrepancies for log-concave,\nheavy-tailed, and multimodal targets and use these quality measures to select\nthe hyperparameters of biased Markov chain Monte Carlo (MCMC) samplers, compare\nrandom and deterministic quadrature rules, and quantify bias-variance tradeoffs\nin approximate MCMC. Our results establish a near-linear relationship between\ndiffusion Stein discrepancies and Wasserstein distances, improving upon past\nwork even for strongly log-concave targets. The exposed relationship between\nStein factors and Markov process coupling may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:47:08 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 19:46:21 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 18:42:43 GMT"}, {"version": "v4", "created": "Wed, 31 Jan 2018 22:47:59 GMT"}, {"version": "v5", "created": "Wed, 21 Feb 2018 01:20:25 GMT"}, {"version": "v6", "created": "Tue, 13 Nov 2018 01:25:12 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Gorham", "Jackson", ""], ["Duncan", "Andrew B.", ""], ["Vollmer", "Sebastian J.", ""], ["Mackey", "Lester", ""]]}, {"id": "1611.06986", "submitter": "Ramon Sanabria", "authors": "Ramon Sanabria, Florian Metze and Fernando De La Torre", "title": "Robust end-to-end deep audiovisual speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is one of the most effective ways of communication among humans. Even\nthough audio is the most common way of transmitting speech, very important\ninformation can be found in other modalities, such as vision. Vision is\nparticularly useful when the acoustic signal is corrupted. Multi-modal speech\nrecognition however has not yet found wide-spread use, mostly because the\ntemporal alignment and fusion of the different information sources is\nchallenging.\n  This paper presents an end-to-end audiovisual speech recognizer (AVSR), based\non recurrent neural networks (RNN) with a connectionist temporal classification\n(CTC) loss function. CTC creates sparse \"peaky\" output activations, and we\nanalyze the differences in the alignments of output targets (phonemes or\nvisemes) between audio-only, video-only, and audio-visual feature\nrepresentations. We present the first such experiments on the large vocabulary\nIBM ViaVoice database, which outperform previously published approaches on\nphone accuracy in clean and noisy conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 20:08:51 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Sanabria", "Ramon", ""], ["Metze", "Florian", ""], ["De La Torre", "Fernando", ""]]}, {"id": "1611.06996", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Itay Hubara, Nir Ailon", "title": "Spatial contrasting for deep unsupervised learning", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks have marked their place over the last few years as the\nbest performing model for various visual tasks. They are, however, most suited\nfor supervised learning from large amounts of labeled data. Previous attempts\nhave been made to use unlabeled data to improve model performance by applying\nunsupervised techniques. These attempts require different architectures and\ntraining methods. In this work we present a novel approach for unsupervised\ntraining of Convolutional networks that is based on contrasting between spatial\nregions within images. This criterion can be employed within conventional\nneural networks and trained using standard techniques such as SGD and\nback-propagation, thus complementing supervised methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 20:24:58 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Hoffer", "Elad", ""], ["Hubara", "Itay", ""], ["Ailon", "Nir", ""]]}, {"id": "1611.07012", "submitter": "Edward Choi", "authors": "Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F. Stewart,\n  Jimeng Sun", "title": "GRAM: Graph-based Attention Model for Healthcare Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods exhibit promising performance for predictive modeling\nin healthcare, but two important challenges remain: -Data insufficiency:Often\nin healthcare predictive modeling, the sample size is insufficient for deep\nlearning methods to achieve satisfactory results. -Interpretation:The\nrepresentations learned by deep learning methods should align with medical\nknowledge. To address these challenges, we propose a GRaph-based Attention\nModel, GRAM that supplements electronic health records (EHR) with hierarchical\ninformation inherent to medical ontologies. Based on the data volume and the\nontology structure, GRAM represents a medical concept as a combination of its\nancestors in the ontology via an attention mechanism. We compared predictive\nperformance (i.e. accuracy, data needs, interpretability) of GRAM to various\nmethods including the recurrent neural network (RNN) in two sequential\ndiagnoses prediction tasks and one heart failure prediction task. Compared to\nthe basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarely\nobserved in the training data and 3% improved area under the ROC curve for\npredicting heart failure using an order of magnitude less training data.\nAdditionally, unlike other methods, the medical concept representations learned\nby GRAM are well aligned with the medical ontology. Finally, GRAM exhibits\nintuitive attention behaviors by adaptively generalizing to higher level\nconcepts when facing data insufficiency at the lower level concepts.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 20:59:22 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 16:51:18 GMT"}, {"version": "v3", "created": "Sat, 1 Apr 2017 22:21:35 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Choi", "Edward", ""], ["Bahadori", "Mohammad Taha", ""], ["Song", "Le", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1611.07054", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl, Nassir Navab, Amin Katouzian", "title": "An Efficient Training Algorithm for Kernel Survival Support Vector\n  Machines", "comments": "ECML PKDD MLLS 2016: 3rd Workshop on Machine Learning in Life\n  Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis is a fundamental tool in medical research to identify\npredictors of adverse events and develop systems for clinical decision support.\nIn order to leverage large amounts of patient data, efficient optimisation\nroutines are paramount. We propose an efficient training algorithm for the\nkernel survival support vector machine (SSVM). We directly optimise the primal\nobjective function and employ truncated Newton optimisation and order statistic\ntrees to significantly lower computational costs compared to previous training\nalgorithms, which require $O(n^4)$ space and $O(p n^6)$ time for datasets with\n$n$ samples and $p$ features. Our results demonstrate that our proposed\noptimisation scheme allows analysing data of a much larger scale with no loss\nin prediction performance. Experiments on synthetic and 5 real-world datasets\nshow that our technique outperforms existing kernel SSVM formulations if the\namount of right censoring is high ($\\geq85\\%$), and performs comparably\notherwise.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:09:33 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Navab", "Nassir", ""], ["Katouzian", "Amin", ""]]}, {"id": "1611.07056", "submitter": "Luca Martino", "authors": "Luca Martino, Victor Elvira, Gustau Camps-Valls", "title": "The Recycling Gibbs Sampler for Efficient Learning", "comments": "The MATLAB code of the numerical examples is provided at\n  http://isp.uv.es/code/RG.zip", "journal-ref": "Digital Signal Processing, Volume 74, 2018", "doi": "10.1016/j.dsp.2017.11.012", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo methods are essential tools for Bayesian inference. Gibbs\nsampling is a well-known Markov chain Monte Carlo (MCMC) algorithm, extensively\nused in signal processing, machine learning, and statistics, employed to draw\nsamples from complicated high-dimensional posterior distributions. The key\npoint for the successful application of the Gibbs sampler is the ability to\ndraw efficiently samples from the full-conditional probability density\nfunctions. Since in the general case this is not possible, in order to speed up\nthe convergence of the chain, it is required to generate auxiliary samples\nwhose information is eventually disregarded. In this work, we show that these\nauxiliary samples can be recycled within the Gibbs estimators, improving their\nefficiency with no extra cost. This novel scheme arises naturally after\npointing out the relationship between the standard Gibbs sampler and the chain\nrule used for sampling purposes. Numerical simulations involving simple and\nreal inference problems confirm the excellent performance of the proposed\nscheme in terms of accuracy and computational efficiency. In particular we give\nempirical evidence of performance in a toy example, inference of Gaussian\nprocesses hyperparameters, and learning dependence graphs through regression.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:13:00 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 14:59:08 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Martino", "Luca", ""], ["Elvira", "Victor", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1611.07078", "submitter": "Felix Leibfried", "authors": "Felix Leibfried, Nate Kushman, Katja Hofmann", "title": "A Deep Learning Approach for Joint Video Frame and Reward Prediction in\n  Atari Games", "comments": "Presented at the ICML 2017 Workshop on Principled Approaches to Deep\n  Learning, Sydney, Australia, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is concerned with identifying reward-maximizing\nbehaviour policies in environments that are initially unknown. State-of-the-art\nreinforcement learning approaches, such as deep Q-networks, are model-free and\nlearn to act effectively across a wide range of environments such as Atari\ngames, but require huge amounts of data. Model-based techniques are more\ndata-efficient, but need to acquire explicit knowledge about the environment.\n  In this paper, we take a step towards using model-based techniques in\nenvironments with a high-dimensional visual state space by demonstrating that\nit is possible to learn system dynamics and the reward structure jointly. Our\ncontribution is to extend a recently developed deep neural network for video\nframe prediction in Atari games to enable reward prediction as well. To this\nend, we phrase a joint optimization problem for minimizing both video frame and\nreward reconstruction loss, and adapt network parameters accordingly. Empirical\nevaluations on five Atari games demonstrate accurate cumulative reward\nprediction of up to 200 frames. We consider these results as opening up\nimportant directions for model-based reinforcement learning in complex,\ninitially unknown environments.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 22:06:23 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 09:00:01 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Leibfried", "Felix", ""], ["Kushman", "Nate", ""], ["Hofmann", "Katja", ""]]}, {"id": "1611.07096", "submitter": "Chong Yang Goh", "authors": "Chong Yang Goh, Patrick Jaillet", "title": "Structured Prediction by Conditional Risk Minimization", "comments": "19 pages, with supplements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general approach for supervised learning with structured output\nspaces, such as combinatorial and polyhedral sets, that is based on minimizing\nestimated conditional risk functions. Given a loss function defined over pairs\nof output labels, we first estimate the conditional risk function by solving a\n(possibly infinite) collection of regularized least squares problems. A\nprediction is made by solving an inference problem that minimizes the estimated\nconditional risk function over the output space. We show that this approach\nenables, in some cases, efficient training and inference without explicitly\nintroducing a convex surrogate for the original loss function, even when it is\ndiscontinuous. Empirical evaluations on real-world and synthetic data sets\ndemonstrate the effectiveness of our method in adapting to a variety of loss\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 23:14:58 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 01:03:51 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Goh", "Chong Yang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1611.07098", "submitter": "Kia Khezeli", "authors": "Kia Khezeli and Eilyan Bitar", "title": "Risk-Sensitive Learning and Pricing for Demand Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting in which an electric power utility seeks to curtail\nits peak electricity demand by offering a fixed group of customers a uniform\nprice for reductions in consumption relative to their predetermined baselines.\nThe underlying demand curve, which describes the aggregate reduction in\nconsumption in response to the offered price, is assumed to be affine and\nsubject to unobservable random shocks. Assuming that both the parameters of the\ndemand curve and the distribution of the random shocks are initially unknown to\nthe utility, we investigate the extent to which the utility might dynamically\nadjust its offered prices to maximize its cumulative risk-sensitive payoff over\na finite number of $T$ days. In order to do so effectively, the utility must\ndesign its pricing policy to balance the tradeoff between the need to learn the\nunknown demand model (exploration) and maximize its payoff (exploitation) over\ntime. In this paper, we propose such a pricing policy, which is shown to\nexhibit an expected payoff loss over $T$ days that is at most\n$O(\\sqrt{T}\\log(T))$, relative to an oracle pricing policy that knows the\nunderlying demand model. Moreover, the proposed pricing policy is shown to\nyield a sequence of prices that converge to the oracle optimal prices in the\nmean square sense.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 23:19:24 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 03:11:45 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 18:55:59 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Khezeli", "Kia", ""], ["Bitar", "Eilyan", ""]]}, {"id": "1611.07115", "submitter": "Sarah Tan", "authors": "Sarah Tan, Matvey Soloviev, Giles Hooker, Martin T. Wells", "title": "Tree Space Prototypes: Another Look at Making Tree Ensembles\n  Interpretable", "comments": "Camera-ready version for ACM-IMS FODS 2020. A short version was\n  presented at NIPS 2016 Workshop on Interpretable Machine Learning for Complex\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of decision trees perform well on many problems, but are not\ninterpretable. In contrast to existing approaches in interpretability that\nfocus on explaining relationships between features and predictions, we propose\nan alternative approach to interpret tree ensemble classifiers by surfacing\nrepresentative points for each class -- prototypes. We introduce a new distance\nfor Gradient Boosted Tree models, and propose new, adaptive prototype selection\nmethods with theoretical guarantees, with the flexibility to choose a different\nnumber of prototypes in each class. We demonstrate our methods on random\nforests and gradient boosted trees, showing that the prototypes can perform as\nwell as or even better than the original tree ensemble when used as a\nnearest-prototype classifier. In a user study, humans were better at predicting\nthe output of a tree ensemble classifier when using prototypes than when using\nShapley values, a popular feature attribution method. Hence, prototypes present\na viable alternative to feature-based explanations for tree ensembles.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 00:53:29 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 22:56:22 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 08:01:26 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tan", "Sarah", ""], ["Soloviev", "Matvey", ""], ["Hooker", "Giles", ""], ["Wells", "Martin T.", ""]]}, {"id": "1611.07119", "submitter": "Chongxuan Li", "authors": "Chongxuan Li and Jun Zhu and Bo Zhang", "title": "Max-Margin Deep Generative Models for (Semi-)Supervised Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1504.06787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models (DGMs) are effective on learning multilayered\nrepresentations of complex data and performing inference of input data by\nexploring the generative ability. However, it is relatively insufficient to\nempower the discriminative ability of DGMs on making accurate predictions. This\npaper presents max-margin deep generative models (mmDGMs) and a\nclass-conditional variant (mmDCGMs), which explore the strongly discriminative\nprinciple of max-margin learning to improve the predictive performance of DGMs\nin both supervised and semi-supervised learning, while retaining the generative\ncapability. In semi-supervised learning, we use the predictions of a max-margin\nclassifier as the missing labels instead of performing full posterior inference\nfor efficiency; we also introduce additional max-margin and label-balance\nregularization terms of unlabeled data for effectiveness. We develop an\nefficient doubly stochastic subgradient algorithm for the piecewise linear\nobjectives in different settings. Empirical results on various datasets\ndemonstrate that: (1) max-margin learning can significantly improve the\nprediction performance of DGMs and meanwhile retain the generative ability; (2)\nin supervised learning, mmDGMs are competitive to the best fully discriminative\nnetworks when employing convolutional neural networks as the generative and\nrecognition models; and (3) in semi-supervised learning, mmDCGMs can perform\nefficient inference and achieve state-of-the-art classification results on\nseveral benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 01:36:29 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Li", "Chongxuan", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1611.07151", "submitter": "Mohammad Motamedi", "authors": "Mohammad Motamedi, Daniel Fong, Soheil Ghiasi", "title": "Fast and Energy-Efficient CNN Inference on IoT Devices", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) exhibit remarkable performance in\nvarious machine learning tasks. As sensor-equipped internet of things (IoT)\ndevices permeate into every aspect of modern life, it is increasingly important\nto run CNN inference, a computationally intensive application, on resource\nconstrained devices. We present a technique for fast and energy-efficient CNN\ninference on mobile SoC platforms, which are projected to be a major player in\nthe IoT space. We propose techniques for efficient parallelization of CNN\ninference targeting mobile GPUs, and explore the underlying tradeoffs.\nExperiments with running Squeezenet on three different mobile devices confirm\nthe effectiveness of our approach. For further study, please refer to the\nproject repository available on our GitHub page:\nhttps://github.com/mtmd/Mobile_ConvNet\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 05:53:22 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Motamedi", "Mohammad", ""], ["Fong", "Daniel", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1611.07174", "submitter": "Zewang Zhang", "authors": "Zewang Zhang, Zheng Sun, Jiaqi Liu, Jingwen Chen, Zhao Huo, Xiao Zhang", "title": "Deep Recurrent Convolutional Neural Network: Improving Performance For\n  Speech Recognition", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning approach has been widely applied in sequence modeling\nproblems. In terms of automatic speech recognition (ASR), its performance has\nsignificantly been improved by increasing large speech corpus and deeper neural\nnetwork. Especially, recurrent neural network and deep convolutional neural\nnetwork have been applied in ASR successfully. Given the arising problem of\ntraining speed, we build a novel deep recurrent convolutional network for\nacoustic modeling and then apply deep residual learning to it. Our experiments\nshow that it has not only faster convergence speed but better recognition\naccuracy over traditional deep convolutional recurrent network. In the\nexperiments, we compare the convergence speed of our novel deep recurrent\nconvolutional networks and traditional deep convolutional recurrent networks.\nWith faster convergence speed, our novel deep recurrent convolutional networks\ncan reach the comparable performance. We further show that applying deep\nresidual learning can boost the convergence speed of our novel deep recurret\nconvolutional networks. Finally, we evaluate all our experimental networks by\nphoneme error rate (PER) with our proposed bidirectional statistical n-gram\nlanguage model. Our evaluation results show that our newly proposed deep\nrecurrent convolutional network applied with deep residual learning can reach\nthe best PER of 17.33\\% with the fastest convergence speed on TIMIT database.\nThe outstanding performance of our novel deep recurrent convolutional neural\nnetwork with deep residual learning indicates that it can be potentially\nadopted in other sequential problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 07:36:21 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2016 04:53:56 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Zhang", "Zewang", ""], ["Sun", "Zheng", ""], ["Liu", "Jiaqi", ""], ["Chen", "Jingwen", ""], ["Huo", "Zhao", ""], ["Zhang", "Xiao", ""]]}, {"id": "1611.07252", "submitter": "Scott Wisdom", "authors": "Scott Wisdom, Thomas Powers, James Pitton, Les Atlas", "title": "Interpretable Recurrent Neural Networks Using Sequential Sparse Recovery", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful and effective for processing\nsequential data. However, RNNs are usually considered \"black box\" models whose\ninternal structure and learned parameters are not interpretable. In this paper,\nwe propose an interpretable RNN based on the sequential iterative\nsoft-thresholding algorithm (SISTA) for solving the sequential sparse recovery\nproblem, which models a sequence of correlated observations with a sequence of\nsparse latent vectors. The architecture of the resulting SISTA-RNN is\nimplicitly defined by the computational structure of SISTA, which results in a\nnovel stacked RNN architecture. Furthermore, the weights of the SISTA-RNN are\nperfectly interpretable as the parameters of a principled statistical model,\nwhich in this case include a sparsifying dictionary, iterative step size, and\nregularization parameters. In addition, on a particular sequential compressive\nsensing task, the SISTA-RNN trains faster and achieves better performance than\nconventional state-of-the-art black box RNNs, including long-short term memory\n(LSTM) RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 11:29:15 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Wisdom", "Scott", ""], ["Powers", "Thomas", ""], ["Pitton", "James", ""], ["Atlas", "Les", ""]]}, {"id": "1611.07270", "submitter": "Pieter-Jan Kindermans", "authors": "Pieter-Jan Kindermans, Kristof Sch\\\"utt, Klaus-Robert M\\\"uller, Sven\n  D\\\"ahne", "title": "Investigating the influence of noise and distractors on the\n  interpretation of neural networks", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding neural networks is becoming increasingly important. Over the\nlast few years different types of visualisation and explanation methods have\nbeen proposed. However, none of them explicitly considered the behaviour in the\npresence of noise and distracting elements. In this work, we will show how\nnoise and distracting dimensions can influence the result of an explanation\nmodel. This gives a new theoretical insights to aid selection of the most\nappropriate explanation model within the deep-Taylor decomposition framework.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 12:23:07 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Kindermans", "Pieter-Jan", ""], ["Sch\u00fctt", "Kristof", ""], ["M\u00fcller", "Klaus-Robert", ""], ["D\u00e4hne", "Sven", ""]]}, {"id": "1611.07305", "submitter": "Nate Veldt", "authors": "Nate Veldt and Anthony Wirth and David F. Gleich", "title": "Correlation Clustering with Low-Rank Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation clustering is a technique for aggregating data based on\nqualitative information about which pairs of objects are labeled 'similar' or\n'dissimilar.' Because the optimization problem is NP-hard, much of the previous\nliterature focuses on finding approximation algorithms. In this paper we\nexplore how to solve the correlation clustering objective exactly when the data\nto be clustered can be represented by a low-rank matrix. We prove in particular\nthat correlation clustering can be solved in polynomial time when the\nunderlying matrix is positive semidefinite with small constant rank, but that\nthe task remains NP-hard in the presence of even one negative eigenvalue. Based\non our theoretical results, we develop an algorithm for efficiently \"solving\"\nlow-rank positive semidefinite correlation clustering by employing a procedure\nfor zonotope vertex enumeration. We demonstrate the effectiveness and speed of\nour algorithm by using it to solve several clustering problems on both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:56:29 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 16:38:09 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Veldt", "Nate", ""], ["Wirth", "Anthony", ""], ["Gleich", "David F.", ""]]}, {"id": "1611.07308", "submitter": "Thomas Kipf", "authors": "Thomas N. Kipf, Max Welling", "title": "Variational Graph Auto-Encoders", "comments": "Bayesian Deep Learning Workshop (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the variational graph auto-encoder (VGAE), a framework for\nunsupervised learning on graph-structured data based on the variational\nauto-encoder (VAE). This model makes use of latent variables and is capable of\nlearning interpretable latent representations for undirected graphs. We\ndemonstrate this model using a graph convolutional network (GCN) encoder and a\nsimple inner product decoder. Our model achieves competitive results on a link\nprediction task in citation networks. In contrast to most existing models for\nunsupervised learning on graph-structured data and link prediction, our model\ncan naturally incorporate node features, which significantly improves\npredictive performance on a number of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 11:37:17 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Kipf", "Thomas N.", ""], ["Welling", "Max", ""]]}, {"id": "1611.07343", "submitter": "Jean-Baptiste Mouret", "authors": "Antoine Cully, Konstantinos Chatzilygeroudis, Federico Allocati,\n  Jean-Baptiste Mouret", "title": "Limbo: A Fast and Flexible Library for Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limbo is an open-source C++11 library for Bayesian optimization which is\ndesigned to be both highly flexible and very fast. It can be used to optimize\nfunctions for which the gradient is unknown, evaluations are expensive, and\nruntime cost matters (e.g., on embedded systems or robots). Benchmarks on\nstandard functions show that Limbo is about 2 times faster than BayesOpt\n(another C++ library) for a similar accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:00:08 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Cully", "Antoine", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Allocati", "Federico", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1611.07422", "submitter": "Jiequn Han", "authors": "Jiequn Han, Weinan E", "title": "Deep Learning Approximation for Stochastic Control Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world stochastic control problems suffer from the \"curse of\ndimensionality\". To overcome this difficulty, we develop a deep learning\napproach that directly solves high-dimensional stochastic control problems\nbased on Monte-Carlo sampling. We approximate the time-dependent controls as\nfeedforward neural networks and stack these networks together through model\ndynamics. The objective function for the control problem plays the role of the\nloss function for the deep neural network. We test this approach using examples\nfrom the areas of optimal trading and energy storage. Our results suggest that\nthe algorithm presented here achieves satisfactory accuracy and at the same\ntime, can handle rather high dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:47:26 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Han", "Jiequn", ""], ["E", "Weinan", ""]]}, {"id": "1611.07429", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bhavya Kailkhura, Prasanna Sattigeri and\n  Karthikeyan Natesan Ramamurthy", "title": "TreeView: Peeking into Deep Neural Networks Via Feature-Space\n  Partitioning", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of highly predictive but opaque deep learning models, it has\nbecome more important than ever to understand and explain the predictions of\nsuch models. Existing approaches define interpretability as the inverse of\ncomplexity and achieve interpretability at the cost of accuracy. This\nintroduces a risk of producing interpretable but misleading explanations. As\nhumans, we are prone to engage in this kind of behavior \\cite{mythos}. In this\npaper, we take a step in the direction of tackling the problem of\ninterpretability without compromising the model accuracy. We propose to build a\nTreeview representation of the complex model via hierarchical partitioning of\nthe feature space, which reveals the iterative rejection of unlikely class\nlabels until the correct association is predicted.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 17:32:59 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Kailkhura", "Bhavya", ""], ["Sattigeri", "Prasanna", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1611.07438", "submitter": "Lu Zhang", "authors": "Lu Zhang (1), Yongkai Wu (1), Xintao Wu (1) ((1) University of\n  Arkansas)", "title": "Achieving non-discrimination in data release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination discovery and prevention/removal are increasingly important\ntasks in data mining. Discrimination discovery aims to unveil discriminatory\npractices on the protected attribute (e.g., gender) by analyzing the dataset of\nhistorical decision records, and discrimination prevention aims to remove\ndiscrimination by modifying the biased data before conducting predictive\nanalysis. In this paper, we show that the key to discrimination discovery and\nprevention is to find the meaningful partitions that can be used to provide\nquantitative evidences for the judgment of discrimination. With the support of\nthe causal graph, we present a graphical condition for identifying a meaningful\npartition. Based on that, we develop a simple criterion for the claim of\nnon-discrimination, and propose discrimination removal algorithms which\naccurately remove discrimination while retaining good data utility. Experiments\nusing real datasets show the effectiveness of our approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 17:55:28 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Zhang", "Lu", ""], ["Wu", "Yongkai", ""], ["Wu", "Xintao", ""]]}, {"id": "1611.07450", "submitter": "Michael Cogswell", "authors": "Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael\n  Cogswell, Devi Parikh, Dhruv Batra", "title": "Grad-CAM: Why did you say that?", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems. This is an extended abstract version of arXiv:1610.02391\n  (CVPR format)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for making Convolutional Neural Network (CNN)-based\nmodels more transparent by visualizing input regions that are 'important' for\npredictions -- or visual explanations. Our approach, called Gradient-weighted\nClass Activation Mapping (Grad-CAM), uses class-specific gradient information\nto localize important regions. These localizations are combined with existing\npixel-space visualizations to create a novel high-resolution and\nclass-discriminative visualization called Guided Grad-CAM. These methods help\nbetter understand CNN-based models, including image captioning and visual\nquestion answering (VQA) models. We evaluate our visual explanations by\nmeasuring their ability to discriminate between classes, to inspire trust in\nhumans, and their correlation with occlusion maps. Grad-CAM provides a new way\nto understand CNN-based models.\n  We have released code, an online demo hosted on CloudCV, and a full version\nof this extended abstract.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 18:34:36 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 16:33:29 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Selvaraju", "Ramprasaath R", ""], ["Das", "Abhishek", ""], ["Vedantam", "Ramakrishna", ""], ["Cogswell", "Michael", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1611.07476", "submitter": "Levent Sagun", "authors": "Levent Sagun, Leon Bottou, Yann LeCun", "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond", "comments": "ICLR submission, 2016 - updated to match the openreview.net version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look at the eigenvalues of the Hessian of a loss function before and after\ntraining. The eigenvalue distribution is seen to be composed of two parts, the\nbulk which is concentrated around zero, and the edges which are scattered away\nfrom zero. We present empirical evidence for the bulk indicating how\nover-parametrized the system is, and for the edges that depend on the input\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 19:24:49 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 13:28:50 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Sagun", "Levent", ""], ["Bottou", "Leon", ""], ["LeCun", "Yann", ""]]}, {"id": "1611.07490", "submitter": "Harshal Maske", "authors": "Harshal Maske, Emily Kieson, Girish Chowdhary, and Charles Abramson", "title": "Can Co-robots Learn to Teach?", "comments": "9 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore beyond existing work on learning from demonstration by asking the\nquestion: Can robots learn to teach?, that is, can a robot autonomously learn\nan instructional policy from expert demonstration and use it to instruct or\ncollaborate with humans in executing complex tasks in uncertain environments?\nIn this paper we pursue a solution to this problem by leveraging the idea that\nhumans often implicitly decompose a higher level task into several subgoals\nwhose execution brings the task closer to completion. We propose Dirichlet\nprocess based non-parametric Inverse Reinforcement Learning (DPMIRL) approach\nfor reward based unsupervised clustering of task space into subgoals. This\napproach is shown to capture the latent subgoals that a human teacher would\nhave utilized to train a novice. The notion of action primitive is introduced\nas the means to communicate instruction policy to humans in the least\ncomplicated manner, and as a computationally efficient tool to segment\ndemonstration data. We evaluate our approach through experiments on hydraulic\nactuated scaled model of an excavator and evaluate and compare different\nteaching strategies utilized by the robot.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 19:56:27 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Maske", "Harshal", ""], ["Kieson", "Emily", ""], ["Chowdhary", "Girish", ""], ["Abramson", "Charles", ""]]}, {"id": "1611.07492", "submitter": "Siddharth Narayanaswamy", "authors": "N. Siddharth and Brooks Paige and Alban Desmaison and Jan-Willem Van\n  de Meent and Frank Wood and Noah D. Goodman and Pushmeet Kohli and Philip\n  H.S. Torr", "title": "Inducing Interpretable Representations with Variational Autoencoders", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for incorporating structured graphical models in the\n\\emph{encoders} of variational autoencoders (VAEs) that allows us to induce\ninterpretable representations through approximate variational inference. This\nallows us to both perform reasoning (e.g. classification) under the structural\nconstraints of a given graphical model, and use deep generative models to deal\nwith messy, high-dimensional domains where it is often difficult to model all\nthe variation. Learning in this framework is carried out end-to-end with a\nvariational objective, applying to both unsupervised and semi-supervised\nschemes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 20:04:59 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["Desmaison", "Alban", ""], ["Van de Meent", "Jan-Willem", ""], ["Wood", "Frank", ""], ["Goodman", "Noah D.", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1611.07507", "submitter": "Karol Gregor", "authors": "Karol Gregor, Danilo Jimenez Rezende, Daan Wierstra", "title": "Variational Intrinsic Control", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new unsupervised reinforcement learning method\nfor discovering the set of intrinsic options available to an agent. This set is\nlearned by maximizing the number of different states an agent can reliably\nreach, as measured by the mutual information between the set of options and\noption termination states. To this end, we instantiate two policy gradient\nbased algorithms, one that creates an explicit embedding space of options and\none that represents options implicitly. The algorithms also provide an explicit\nmeasure of empowerment in a given state that can be used by an empowerment\nmaximizing agent. The algorithm scales well with function approximation and we\ndemonstrate the applicability of the algorithm on a range of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 20:44:39 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Gregor", "Karol", ""], ["Rezende", "Danilo Jimenez", ""], ["Wierstra", "Daan", ""]]}, {"id": "1611.07509", "submitter": "Lu Zhang", "authors": "Lu Zhang (1), Yongkai Wu (1), Xintao Wu (1) ((1) University of\n  Arkansas)", "title": "A causal framework for discovering and removing direct and indirect\n  discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-discrimination is an increasingly important task in data science. In\nthis paper, we investigate the problem of discovering both direct and indirect\ndiscrimination from the historical data, and removing the discriminatory\neffects before the data is used for predictive analysis (e.g., building\nclassifiers). We make use of the causal network to capture the causal structure\nof the data. Then we model direct and indirect discrimination as the\npath-specific effects, which explicitly distinguish the two types of\ndiscrimination as the causal effects transmitted along different paths in the\nnetwork. Based on that, we propose an effective algorithm for discovering\ndirect and indirect discrimination, as well as an algorithm for precisely\nremoving both types of discrimination while retaining good data utility.\nDifferent from previous works, our approaches can ensure that the predictive\nmodels built from the modified data will not incur discrimination in decision\nmaking. Experiments using real datasets show the effectiveness of our\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 20:50:47 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Zhang", "Lu", ""], ["Wu", "Yongkai", ""], ["Wu", "Xintao", ""]]}, {"id": "1611.07567", "submitter": "Marina Vidovic", "authors": "Marina M.-C. Vidovic, Nico G\\\"ornitz, Klaus-Robert M\\\"uller, Marius\n  Kloft", "title": "Feature Importance Measure for Non-linear Learning Algorithms", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex problems may require sophisticated, non-linear learning methods such\nas kernel machines or deep neural networks to achieve state of the art\nprediction accuracies. However, high prediction accuracies are not the only\nobjective to consider when solving problems using machine learning. Instead,\nparticular scientific applications require some explanation of the learned\nprediction function. Unfortunately, most methods do not come with out of the\nbox straight forward interpretation. Even linear prediction functions are not\nstraight forward to explain if features exhibit complex correlation structure.\n  In this paper, we propose the Measure of Feature Importance (MFI). MFI is\ngeneral and can be applied to any arbitrary learning machine (including kernel\nmachines and deep learning). MFI is intrinsically non-linear and can detect\nfeatures that by itself are inconspicuous and only impact the prediction\nfunction through their interaction with other features. Lastly, MFI can be used\nfor both --- model-based feature importance and instance-based feature\nimportance (i.e, measuring the importance of a feature for a particular data\npoint).\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 22:36:31 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Vidovic", "Marina M. -C.", ""], ["G\u00f6rnitz", "Nico", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Kloft", "Marius", ""]]}, {"id": "1611.07571", "submitter": "Nikolay Savinov", "authors": "Nikolay Savinov, Akihito Seki, Lubor Ladicky, Torsten Sattler and Marc\n  Pollefeys", "title": "Quad-networks: unsupervised learning to rank for interest point\n  detection", "comments": "Accepted at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several machine learning tasks require to represent the data using only a\nsparse set of interest points. An ideal detector is able to find the\ncorresponding interest points even if the data undergo a transformation typical\nfor a given domain. Since the task is of high practical interest in computer\nvision, many hand-crafted solutions were proposed. In this paper, we ask a\nfundamental question: can we learn such detectors from scratch? Since it is\noften unclear what points are \"interesting\", human labelling cannot be used to\nfind a truly unbiased solution. Therefore, the task requires an unsupervised\nformulation. We are the first to propose such a formulation: training a neural\nnetwork to rank points in a transformation-invariant manner. Interest points\nare then extracted from the top/bottom quantiles of this ranking. We validate\nour approach on two tasks: standard RGB image interest point detection and\nchallenging cross-modal interest point detection between RGB and depth images.\nWe quantitatively show that our unsupervised method performs better or on-par\nwith baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 22:46:17 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 21:15:18 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Savinov", "Nikolay", ""], ["Seki", "Akihito", ""], ["Ladicky", "Lubor", ""], ["Sattler", "Torsten", ""], ["Pollefeys", "Marc", ""]]}, {"id": "1611.07579", "submitter": "Sameer Singh", "authors": "Sameer Singh and Marco Tulio Ribeiro and Carlos Guestrin", "title": "Programs as Black-Box Explanations", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in model-agnostic explanations of black-box machine learning has\ndemonstrated that interpretability of complex models does not have to come at\nthe cost of accuracy or model flexibility. However, it is not clear what kind\nof explanations, such as linear models, decision trees, and rule lists, are the\nappropriate family to consider, and different tasks and models may benefit from\ndifferent kinds of explanations. Instead of picking a single family of\nrepresentations, in this work we propose to use \"programs\" as model-agnostic\nexplanations. We show that small programs can be expressive yet intuitive as\nexplanations, and generalize over a number of existing interpretable families.\nWe propose a prototype program induction method based on simulated annealing\nthat approximates the local behavior of black-box classifiers around a specific\nprediction using random perturbations. Finally, we present preliminary\napplication on small datasets and show that the generated explanations are\nintuitive and accurate for a number of classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 23:35:03 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Singh", "Sameer", ""], ["Ribeiro", "Marco Tulio", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1611.07588", "submitter": "Ashkan Zeinalzadeh", "authors": "Ashkan Zeinalzadeh, Tom Wenska, Gordon Okimoto", "title": "A Neural Network Model to Classify Liver Cancer Patients Using Data\n  Expansion and Compression", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a neural network model to classify liver cancer patients into\nhigh-risk and low-risk groups using genomic data. Our approach provides a novel\ntechnique to classify big data sets using neural network models. We preprocess\nthe data before training the neural network models. We first expand the data\nusing wavelet analysis. We then compress the wavelet coefficients by mapping\nthem onto a new scaled orthonormal coordinate system. Then the data is used to\ntrain a neural network model that enables us to classify cancer patients into\ntwo different classes of high-risk and low-risk patients. We use the\nleave-one-out approach to build a neural network model. This neural network\nmodel enables us to classify a patient using genomic data as a high-risk or\nlow-risk patient without any information about the survival time of the\npatient. The results from genomic data analysis are compared with survival time\nanalysis. It is shown that the expansion and compression of data using wavelet\nanalysis and singular value decomposition (SVD) is essential to train the\nneural network model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 00:11:41 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 18:02:21 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Zeinalzadeh", "Ashkan", ""], ["Wenska", "Tom", ""], ["Okimoto", "Gordon", ""]]}, {"id": "1611.07627", "submitter": "EPTCS", "authors": "Rajeev Alur (University of Pennsylvania), Dana Fisman (Ben-Gurion\n  University), Rishabh Singh (Microsoft Research, Redmond), Armando\n  Solar-Lezama (Massachusetts Institute of Technology)", "title": "SyGuS-Comp 2016: Results and Analysis", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178. arXiv admin note: text\n  overlap with arXiv:1602.01170", "journal-ref": "EPTCS 229, 2016, pp. 178-202", "doi": "10.4204/EPTCS.229.13", "report-no": null, "categories": "cs.SE cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an\nimplementation f that meets both a semantic constraint given by a logical\nformula $\\varphi$ in a background theory T, and a syntactic constraint given by\na grammar G, which specifies the allowed set of candidate implementations. Such\na synthesis problem can be formally defined in SyGuS-IF, a language that is\nbuilt on top of SMT-LIB.\n  The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to\nfacilitate, bring together and accelerate research and development of efficient\nsolvers for SyGuS by providing a platform for evaluating different synthesis\ntechniques on a comprehensive set of benchmarks. In this year's competition we\nadded a new track devoted to programming by examples. This track consisted of\ntwo categories, one using the theory of bit-vectors and one using the theory of\nstrings. This paper presents and analyses the results of SyGuS-Comp'16.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:17:40 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Alur", "Rajeev", "", "University of Pennsylvania"], ["Fisman", "Dana", "", "Ben-Gurion\n  University"], ["Singh", "Rishabh", "", "Microsoft Research, Redmond"], ["Solar-Lezama", "Armando", "", "Massachusetts Institute of Technology"]]}, {"id": "1611.07634", "submitter": "Yotam Hechtlinger", "authors": "Yotam Hechtlinger", "title": "Interpretation of Prediction Models Using the Input Gradient", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art machine learning algorithms are highly optimized to provide\nthe optimal prediction possible, naturally resulting in complex models. While\nthese models often outperform simpler more interpretable models by order of\nmagnitudes, in terms of understanding the way the model functions, we are often\nfacing a \"black box\".\n  In this paper we suggest a simple method to interpret the behavior of any\npredictive model, both for regression and classification. Given a particular\nmodel, the information required to interpret it can be obtained by studying the\npartial derivatives of the model with respect to the input. We exemplify this\ninsight by interpreting convolutional and multi-layer neural networks in the\nfield of natural language processing.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 04:21:51 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Hechtlinger", "Yotam", ""]]}, {"id": "1611.07659", "submitter": "Zeyi Wen", "authors": "Zeyi Wen, Bin Li, Rao Kotagiri, Jian Chen, Yawen Chen and Rui Zhang", "title": "Improving Efficiency of SVM k-fold Cross-validation by Alpha Seeding", "comments": "9 pages, 2 figures, accepted by AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-fold cross-validation is commonly used to evaluate the effectiveness of\nSVMs with the selected hyper-parameters. It is known that the SVM k-fold\ncross-validation is expensive, since it requires training k SVMs. However,\nlittle work has explored reusing the h-th SVM for training the (h+1)-th SVM for\nimproving the efficiency of k-fold cross-validation. In this paper, we propose\nthree algorithms that reuse the h-th SVM for improving the efficiency of\ntraining the (h+1)-th SVM. Our key idea is to efficiently identify the support\nvectors and to accurately estimate their associated weights (also called alpha\nvalues) of the next SVM by using the previous SVM. Our experimental results\nshow that our algorithms are several times faster than the k-fold\ncross-validation which does not make use of the previously trained SVM.\nMoreover, our algorithms produce the same results (hence same accuracy) as the\nk-fold cross-validation which does not make use of the previously trained SVM.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 06:48:25 GMT"}, {"version": "v2", "created": "Sat, 4 Feb 2017 17:28:38 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Wen", "Zeyi", ""], ["Li", "Bin", ""], ["Kotagiri", "Rao", ""], ["Chen", "Jian", ""], ["Chen", "Yawen", ""], ["Zhang", "Rui", ""]]}, {"id": "1611.07661", "submitter": "Michael Maire", "authors": "Tsung-Wei Ke, Michael Maire, Stella X. Yu", "title": "Multigrid Neural Architectures", "comments": "updated with ImageNet results; to appear at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multigrid extension of convolutional neural networks (CNNs).\nRather than manipulating representations living on a single spatial grid, our\nnetwork layers operate across scale space, on a pyramid of grids. They consume\nmultigrid inputs and produce multigrid outputs; convolutional filters\nthemselves have both within-scale and cross-scale extent. This aspect is\ndistinct from simple multiscale designs, which only process the input at\ndifferent scales. Viewed in terms of information flow, a multigrid network\npasses messages across a spatial pyramid. As a consequence, receptive field\nsize grows exponentially with depth, facilitating rapid integration of context.\nMost critically, multigrid structure enables networks to learn internal\nattention and dynamic routing mechanisms, and use them to accomplish tasks on\nwhich modern CNNs fail.\n  Experiments demonstrate wide-ranging performance advantages of multigrid. On\nCIFAR and ImageNet classification tasks, flipping from a single grid to\nmultigrid within the standard CNN paradigm improves accuracy, while being\ncompute and parameter efficient. Multigrid is independent of other\narchitectural choices; we show synergy in combination with residual\nconnections. Multigrid yields dramatic improvement on a synthetic semantic\nsegmentation dataset. Most strikingly, relatively shallow multigrid networks\ncan learn to directly perform spatial transformation tasks, where, in contrast,\ncurrent CNNs fail. Together, our results suggest that continuous evolution of\nfeatures on a multigrid pyramid is a more powerful alternative to existing CNN\ndesigns on a flat grid.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 06:55:53 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 19:24:33 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Ke", "Tsung-Wei", ""], ["Maire", "Michael", ""], ["Yu", "Stella X.", ""]]}, {"id": "1611.07725", "submitter": "Christoph H. Lampert", "authors": "Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, Christoph\n  H. Lampert", "title": "iCaRL: Incremental Classifier and Representation Learning", "comments": "Accepted paper at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major open problem on the road to artificial intelligence is the\ndevelopment of incrementally learning systems that learn about more and more\nconcepts over time from a stream of data. In this work, we introduce a new\ntraining strategy, iCaRL, that allows learning in such a class-incremental way:\nonly the training data for a small number of classes has to be present at the\nsame time and new classes can be added progressively. iCaRL learns strong\nclassifiers and a data representation simultaneously. This distinguishes it\nfrom earlier works that were fundamentally limited to fixed data\nrepresentations and therefore incompatible with deep learning architectures. We\nshow by experiments on CIFAR-100 and ImageNet ILSVRC 2012 data that iCaRL can\nlearn many classes incrementally over a long period of time where other\nstrategies quickly fail.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 10:24:11 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 16:41:02 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Rebuffi", "Sylvestre-Alvise", ""], ["Kolesnikov", "Alexander", ""], ["Sperl", "Georg", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1611.07743", "submitter": "Gil Keren", "authors": "Gil Keren, Sivan Sabato, Bj\\\"orn Schuller", "title": "Tunable Sensitivity to Large Errors in Neural Network Training", "comments": "The paper is accepted to the AAAI 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans learn a new concept, they might ignore examples that they cannot\nmake sense of at first, and only later focus on such examples, when they are\nmore useful for learning. We propose incorporating this idea of tunable\nsensitivity for hard examples in neural network learning, using a new\ngeneralization of the cross-entropy gradient step, which can be used in place\nof the gradient in any gradient-based training method. The generalized gradient\nis parameterized by a value that controls the sensitivity of the training\nprocess to harder training examples. We tested our method on several benchmark\ndatasets. We propose, and corroborate in our experiments, that the optimal\nlevel of sensitivity to hard example is positively correlated with the depth of\nthe network. Moreover, the test prediction error obtained by our method is\ngenerally lower than that of the vanilla cross-entropy gradient learner. We\ntherefore conclude that tunable sensitivity can be helpful for neural network\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 11:14:01 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Keren", "Gil", ""], ["Sabato", "Sivan", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1611.07781", "submitter": "Pierre-Francois Marteau", "authors": "Pierre-Fran\\c{c}ois Marteau (EXPRESSION), Sylvie Gibet (EXPRESSION),\n  Cl\\'ement Reverdy (EXPRESSION)", "title": "Adaptive Down-Sampling and Dimension Reduction in Time Elastic Kernel\n  Machines for Efficient Recognition of Isolated Gestures", "comments": null, "journal-ref": "Guillet, Fabrice and Pinaud, Bruno and Venturini, Gilles. Advances\n  in Knowledge Discovery and Management: volume 6, Volume (665), Springer\n  International Publishing, pp.39 - 59, 2016, Studies in Computational\n  Intelligence, 978-3-319-45763-5", "doi": "10.1007/978-3-319-45763-5_3", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the scope of gestural action recognition, the size of the feature vector\nrepresenting movements is in general quite large especially when full body\nmovements are considered. Furthermore, this feature vector evolves during the\nmovement performance so that a complete movement is fully represented by a\nmatrix M of size DxT , whose element M i, j represents the value of feature i\nat timestamps j. Many studies have addressed dimensionality reduction\nconsidering only the size of the feature vector lying in R D to reduce both the\nvariability of gestural sequences expressed in the reduced space, and the\ncomputational complexity of their processing. In return, very few of these\nmethods have explicitly addressed the dimensionality reduction along the time\naxis. Yet this is a major issue when considering the use of elastic distances\nwhich are characterized by a quadratic complexity along the time axis. We\npresent in this paper an evaluation of straightforward approaches aiming at\nreducing the dimensionality of the matrix M for each movement, leading to\nconsider both the dimensionality reduction of the feature vector as well as its\nreduction along the time axis. The dimensionality reduction of the feature\nvector is achieved by selecting remarkable joints in the skeleton performing\nthe movement, basically the extremities of the articulatory chains composing\nthe skeleton. The temporal dimen-sionality reduction is achieved using either a\nregular or adaptive down-sampling that seeks to minimize the reconstruction\nerror of the movements. Elastic and Euclidean kernels are then compared through\nsupport vector machine learning. Two data sets 1 that are widely referenced in\nthe domain of human gesture recognition, and quite distinctive in terms of\nquality of motion capture, are used for the experimental assessment of the\nproposed approaches. On these data sets we experimentally show that it is\nfeasible, and possibly desirable, to significantly reduce simultaneously the\nsize of the feature vector and the number of skeleton frames to represent body\nmovements while maintaining a very good recognition rate. The method proves to\ngive satisfactory results at a level currently reached by state-of-the-art\nmethods on these data sets. We experimentally show that the computational\ncomplexity reduction that is obtained makes this approach eligible for\nreal-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 13:18:17 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Marteau", "Pierre-Fran\u00e7ois", "", "EXPRESSION"], ["Gibet", "Sylvie", "", "EXPRESSION"], ["Reverdy", "Cl\u00e9ment", "", "EXPRESSION"]]}, {"id": "1611.07800", "submitter": "Ehsan Abbasnejad M", "authors": "Ehsan Abbasnejad, Anthony Dick, Anton van den Hengel", "title": "Infinite Variational Autoencoder for Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an infinite variational autoencoder (VAE) whose capacity\nadapts to suit the input data. This is achieved using a mixture model where the\nmixing coefficients are modeled by a Dirichlet process, allowing us to\nintegrate over the coefficients when performing inference. Critically, this\nthen allows us to automatically vary the number of autoencoders in the mixture\nbased on the data. Experiments show the flexibility of our method, particularly\nfor semi-supervised learning, where only a small number of training samples are\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 13:59:57 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 01:28:08 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Abbasnejad", "Ehsan", ""], ["Dick", "Anthony", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1611.07897", "submitter": "Zhe Gan", "authors": "Zhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, Lawrence\n  Carin", "title": "Learning Generic Sentence Representations Using Convolutional Neural\n  Networks", "comments": "Accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new encoder-decoder approach to learn distributed sentence\nrepresentations that are applicable to multiple purposes. The model is learned\nby using a convolutional neural network as an encoder to map an input sentence\ninto a continuous vector, and using a long short-term memory recurrent neural\nnetwork as a decoder. Several tasks are considered, including sentence\nreconstruction and future sentence prediction. Further, a hierarchical\nencoder-decoder model is proposed to encode a sentence to predict multiple\nfuture sentences. By training our models on a large collection of novels, we\nobtain a highly generic convolutional sentence encoder that performs well in\npractice. Experimental results on several benchmark datasets, and across a\nbroad range of applications, demonstrate the superiority of the proposed model\nover competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 17:32:23 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 20:48:52 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Gan", "Zhe", ""], ["Pu", "Yunchen", ""], ["Henao", "Ricardo", ""], ["Li", "Chunyuan", ""], ["He", "Xiaodong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.07917", "submitter": "Hengyuan Hu", "authors": "Hengyuan Hu and Lisheng Gao and Quanbin Ma", "title": "Deep Restricted Boltzmann Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a good generative model for image has long been an important topic\nin computer vision and machine learning. Restricted Boltzmann machine (RBM) is\none of such models that is simple but powerful. However, its restricted form\nalso has placed heavy constraints on the models representation power and\nscalability. Many extensions have been invented based on RBM in order to\nproduce deeper architectures with greater power. The most famous ones among\nthem are deep belief network, which stacks multiple layer-wise pretrained RBMs\nto form a hybrid model, and deep Boltzmann machine, which allows connections\nbetween hidden units to form a multi-layer structure. In this paper, we present\na new method to compose RBMs to form a multi-layer network style architecture\nand a training method that trains all layers jointly. We call the resulted\nstructure deep restricted Boltzmann network. We further explore the combination\nof convolutional RBM with the normal fully connected RBM, which is made trivial\nunder our composition framework. Experiments show that our model can generate\ndescent images and outperform the normal RBM significantly in terms of image\nquality and feature quality, without losing much efficiency for training.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 03:57:42 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Hu", "Hengyuan", ""], ["Gao", "Lisheng", ""], ["Ma", "Quanbin", ""]]}, {"id": "1611.08002", "submitter": "Zhe Gan", "authors": "Zhe Gan, Chuang Gan, Xiaodong He, Yunchen Pu, Kenneth Tran, Jianfeng\n  Gao, Lawrence Carin, Li Deng", "title": "Semantic Compositional Networks for Visual Captioning", "comments": "Accepted in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Semantic Compositional Network (SCN) is developed for image captioning, in\nwhich semantic concepts (i.e., tags) are detected from the image, and the\nprobability of each tag is used to compose the parameters in a long short-term\nmemory (LSTM) network. The SCN extends each weight matrix of the LSTM to an\nensemble of tag-dependent weight matrices. The degree to which each member of\nthe ensemble is used to generate an image caption is tied to the\nimage-dependent probability of the corresponding tag. In addition to captioning\nimages, we also extend the SCN to generate captions for video clips. We\nqualitatively analyze semantic composition in SCNs, and quantitatively evaluate\nthe algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text.\nExperimental results show that the proposed method significantly outperforms\nprior state-of-the-art approaches, across multiple evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 21:22:22 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 18:33:51 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Gan", "Zhe", ""], ["Gan", "Chuang", ""], ["He", "Xiaodong", ""], ["Pu", "Yunchen", ""], ["Tran", "Kenneth", ""], ["Gao", "Jianfeng", ""], ["Carin", "Lawrence", ""], ["Deng", "Li", ""]]}, {"id": "1611.08024", "submitter": "Vernon Lawhern", "authors": "Vernon J. Lawhern, Amelia J. Solon, Nicholas R. Waytowich, Stephen M.\n  Gordon, Chou P. Hung, Brent J. Lance", "title": "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer\n  Interfaces", "comments": "30 pages, 10 figures. Added additional feature relevance analyses.\n  Minor change to EEGNet architecture. Source code can be found at\n  https://github.com/vlawhern/arl-eegmodels", "journal-ref": null, "doi": "10.1088/1741-2552/aace8c", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain computer interfaces (BCI) enable direct communication with a computer,\nusing neural activity as the control signal. This neural signal is generally\nchosen from a variety of well-studied electroencephalogram (EEG) signals. For a\ngiven BCI paradigm, feature extractors and classifiers are tailored to the\ndistinct characteristics of its expected EEG control signal, limiting its\napplication to that specific signal. Convolutional Neural Networks (CNNs),\nwhich have been used in computer vision and speech recognition, have\nsuccessfully been applied to EEG-based BCIs; however, they have mainly been\napplied to single BCI paradigms and thus it remains unclear how these\narchitectures generalize to other paradigms. Here, we ask if we can design a\nsingle CNN architecture to accurately classify EEG signals from different BCI\nparadigms, while simultaneously being as compact as possible. In this work we\nintroduce EEGNet, a compact convolutional network for EEG-based BCIs. We\nintroduce the use of depthwise and separable convolutions to construct an\nEEG-specific model which encapsulates well-known EEG feature extraction\nconcepts for BCI. We compare EEGNet to current state-of-the-art approaches\nacross four BCI paradigms: P300 visual-evoked potentials, error-related\nnegativity responses (ERN), movement-related cortical potentials (MRCP), and\nsensory motor rhythms (SMR). We show that EEGNet generalizes across paradigms\nbetter than the reference algorithms when only limited training data is\navailable. We demonstrate three different approaches to visualize the contents\nof a trained EEGNet model to enable interpretation of the learned features. Our\nresults suggest that EEGNet is robust enough to learn a wide variety of\ninterpretable features over a range of BCI tasks, suggesting that the observed\nperformances were not due to artifact or noise sources in the data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 22:36:58 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 16:03:13 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 01:02:21 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 01:14:34 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Lawhern", "Vernon J.", ""], ["Solon", "Amelia J.", ""], ["Waytowich", "Nicholas R.", ""], ["Gordon", "Stephen M.", ""], ["Hung", "Chou P.", ""], ["Lance", "Brent J.", ""]]}, {"id": "1611.08034", "submitter": "Zhe Gan", "authors": "Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence\n  Carin", "title": "Scalable Bayesian Learning of Recurrent Neural Networks for Language\n  Modeling", "comments": "Accepted to ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown promising performance for\nlanguage modeling. However, traditional training of RNNs using back-propagation\nthrough time often suffers from overfitting. One reason for this is that\nstochastic optimization (used for large training sets) does not provide good\nestimates of model uncertainty. This paper leverages recent advances in\nstochastic gradient Markov Chain Monte Carlo (also appropriate for large\ntraining sets) to learn weight uncertainty in RNNs. It yields a principled\nBayesian learning algorithm, adding gradient noise during training (enhancing\nexploration of the model-parameter space) and model averaging when testing.\nExtensive experiments on various RNN models and across a broad range of\napplications demonstrate the superiority of the proposed approach over\nstochastic optimization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 23:40:50 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 15:32:49 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gan", "Zhe", ""], ["Li", "Chunyuan", ""], ["Chen", "Changyou", ""], ["Pu", "Yunchen", ""], ["Su", "Qinliang", ""], ["Carin", "Lawrence", ""]]}, {"id": "1611.08070", "submitter": "Jung-Su Ha", "authors": "Jung-Su Ha and Han-Lim Choi", "title": "Multiscale Inverse Reinforcement Learning using Diffusion Wavelets", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a multiscale framework to solve an inverse reinforcement\nlearning (IRL) problem for continuous-time/state stochastic systems. We take\nadvantage of a diffusion wavelet representation of the associated Markov chain\nto abstract the state space. This not only allows for effectively handling the\nlarge (and geometrically complex) decision space but also provides more\ninterpretable representations of the demonstrated state trajectories and also\nof the resulting policy of IRL. In the proposed framework, the problem is\ndivided into the global and local IRL, where the global approximation of the\noptimal value functions are obtained using coarse features and the local\ndetails are quantified using fine local features. An illustrative numerical\nexample on robot path control in a complex environment is presented to verify\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 05:20:52 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Ha", "Jung-Su", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1611.08083", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha\n  Sohl-Dickstein", "title": "Survey of Expressivity in Deep Neural Networks", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey results on neural network expressivity described in \"On the\nExpressive Power of Deep Neural Networks\". The paper motivates and develops\nthree natural measures of expressiveness, which all display an exponential\ndependence on the depth of the network. In fact, all of these measures are\nrelated to a fourth quantity, trajectory length. This quantity grows\nexponentially in the depth of the network, and is responsible for the depth\nsensitivity observed. These results translate to consequences for networks\nduring and after training. They suggest that parameters earlier in a network\nhave greater influence on its expressive power -- in particular, given a layer,\nits influence on expressivity is determined by the remaining depth of the\nnetwork after that layer. This is verified with experiments on MNIST and\nCIFAR-10. We also explore the effect of training on the input-output map, and\nfind that it trades off between the stability and expressivity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 07:09:24 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Raghu", "Maithra", ""], ["Poole", "Ben", ""], ["Kleinberg", "Jon", ""], ["Ganguli", "Surya", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1611.08108", "submitter": "Jiani Zhang", "authors": "Jiani Zhang, Xingjian Shi, Irwin King and Dit-Yan Yeung", "title": "Dynamic Key-Value Memory Networks for Knowledge Tracing", "comments": "To appear in 26th International Conference on World Wide Web (WWW),\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Tracing (KT) is a task of tracing evolving knowledge state of\nstudents with respect to one or more concepts as they engage in a sequence of\nlearning activities. One important purpose of KT is to personalize the practice\nsequence to help students learn knowledge concepts efficiently. However,\nexisting methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing\neither model knowledge state for each predefined concept separately or fail to\npinpoint exactly which concepts a student is good at or unfamiliar with. To\nsolve these problems, this work introduces a new model called Dynamic Key-Value\nMemory Networks (DKVMN) that can exploit the relationships between underlying\nconcepts and directly output a student's mastery level of each concept. Unlike\nstandard memory-augmented neural networks that facilitate a single memory\nmatrix or two static memory matrices, our model has one static matrix called\nkey, which stores the knowledge concepts and the other dynamic matrix called\nvalue, which stores and updates the mastery levels of corresponding concepts.\nExperiments show that our model consistently outperforms the state-of-the-art\nmodel in a range of KT datasets. Moreover, the DKVMN model can automatically\ndiscover underlying concepts of exercises typically performed by human\nannotations and depict the changing knowledge state of a student.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 09:12:47 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 06:09:27 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Zhang", "Jiani", ""], ["Shi", "Xingjian", ""], ["King", "Irwin", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1611.08191", "submitter": "Wojciech Samek", "authors": "Wojciech Samek, Gr\\'egoire Montavon, Alexander Binder, Sebastian\n  Lapuschkin, Klaus-Robert M\\\"uller", "title": "Interpreting the Predictions of Complex ML Models by Layer-wise\n  Relevance Propagation", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex nonlinear models such as deep neural network (DNNs) have become an\nimportant tool for image classification, speech recognition, natural language\nprocessing, and many other fields of application. These models however lack\ntransparency due to their complex nonlinear structure and to the complex data\ndistributions to which they typically apply. As a result, it is difficult to\nfully characterize what makes these models reach a particular decision for a\ngiven input. This lack of transparency can be a drawback, especially in the\ncontext of sensitive applications such as medical analysis or security. In this\nshort paper, we summarize a recent technique introduced by Bach et al. [1] that\nexplains predictions by decomposing the classification decision of DNN models\nin terms of input variables.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 14:16:12 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Samek", "Wojciech", ""], ["Montavon", "Gr\u00e9goire", ""], ["Binder", "Alexander", ""], ["Lapuschkin", "Sebastian", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1611.08229", "submitter": "Cristian Rusu", "authors": "Cristian Rusu, Nuria Gonzalez-Prelcic, Robert Heath", "title": "Fast Orthonormal Sparsifying Transforms Based on Householder Reflectors", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2612168", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is the task of determining a data-dependent transform\nthat yields a sparse representation of some observed data. The dictionary\nlearning problem is non-convex, and usually solved via computationally complex\niterative algorithms. Furthermore, the resulting transforms obtained generally\nlack structure that permits their fast application to data. To address this\nissue, this paper develops a framework for learning orthonormal dictionaries\nwhich are built from products of a few Householder reflectors. Two algorithms\nare proposed to learn the reflector coefficients: one that considers a\nsequential update of the reflectors and one with a simultaneous update of all\nreflectors that imposes an additional internal orthogonal constraint. The\nproposed methods have low computational complexity and are shown to converge to\nlocal minimum points which can be described in terms of the spectral properties\nof the matrices involved. The resulting dictionaries balance between the\ncomputational complexity and the quality of the sparse representations by\ncontrolling the number of Householder reflectors in their product. Simulations\nof the proposed algorithms are shown in the image processing setting where\nwell-known fast transforms are available for comparisons. The proposed\nalgorithms have favorable reconstruction error and the advantage of a fast\nimplementation relative to the classical, unstructured, dictionaries.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 15:53:59 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Rusu", "Cristian", ""], ["Gonzalez-Prelcic", "Nuria", ""], ["Heath", "Robert", ""]]}, {"id": "1611.08230", "submitter": "Cristian Rusu", "authors": "Cristian Rusu and John Thompson", "title": "Learning Fast Sparsifying Transforms", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2712120", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset, the task of learning a transform that allows sparse\nrepresentations of the data bears the name of dictionary learning. In many\napplications, these learned dictionaries represent the data much better than\nthe static well-known transforms (Fourier, Hadamard etc.). The main downside of\nlearned transforms is that they lack structure and therefore they are not\ncomputationally efficient, unlike their classical counterparts. These posse\nseveral difficulties especially when using power limited hardware such as\nmobile devices, therefore discouraging the application of sparsity techniques\nin such scenarios. In this paper we construct orthogonal and non-orthogonal\ndictionaries that are factorized as a product of a few basic transformations.\nIn the orthogonal case, we solve exactly the dictionary update problem for one\nbasic transformation, which can be viewed as a generalized Givens rotation, and\nthen propose to construct orthogonal dictionaries that are a product of these\ntransformations, guaranteeing their fast manipulation. We also propose a method\nto construct fast square but non-orthogonal dictionaries that are factorized as\na product of few transforms that can be viewed as a further generalization of\nGivens rotations to the non-orthogonal setting. We show how the proposed\ntransforms can balance very well data representation performance and\ncomputational complexity. We also compare with classical fast and learned\ngeneral and orthogonal transforms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 15:57:09 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 13:09:45 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Rusu", "Cristian", ""], ["Thompson", "John", ""]]}, {"id": "1611.08292", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Daniel B. Neill", "title": "Identifying Significant Predictive Bias in Classifiers", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017); earlier\n  version presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel subset scan method to detect if a probabilistic binary\nclassifier has statistically significant bias -- over or under predicting the\nrisk -- for some subgroup, and identify the characteristics of this subgroup.\nThis form of model checking and goodness-of-fit test provides a way to\ninterpretably detect the presence of classifier bias or regions of poor\nclassifier fit. This allows consideration of not just subgroups of a priori\ninterest or small dimensions, but the space of all possible subgroups of\nfeatures. To address the difficulty of considering these exponentially many\npossible subgroups, we use subset scan and parametric bootstrap-based methods.\nExtending this method, we can penalize the complexity of the detected subgroup\nand also identify subgroups with high classification errors. We demonstrate\nthese methods and find interesting results on the COMPAS crime recidivism and\ncredit delinquency data.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 19:30:13 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 14:12:17 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Zhang", "Zhe", ""], ["Neill", "Daniel B.", ""]]}, {"id": "1611.08309", "submitter": "Besmira Nushi", "authors": "Besmira Nushi, Ece Kamar, Eric Horvitz, Donald Kossmann", "title": "On Human Intellect and Machine Failures: Troubleshooting Integrative\n  Machine Learning Systems", "comments": "11 pages, Thirty-First AAAI conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of troubleshooting machine learning systems that rely on\nanalytical pipelines of distinct components. Understanding and fixing errors\nthat arise in such integrative systems is difficult as failures can occur at\nmultiple points in the execution workflow. Moreover, errors can propagate,\nbecome amplified or be suppressed, making blame assignment difficult. We\npropose a human-in-the-loop methodology which leverages human intellect for\ntroubleshooting system failures. The approach simulates potential component\nfixes through human computation tasks and measures the expected improvements in\nthe holistic behavior of the system. The method provides guidance to designers\nabout how they can best improve the system. We demonstrate the effectiveness of\nthe approach on an automated image captioning system that has been pressed into\nreal-world use.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 21:08:41 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Horvitz", "Eric", ""], ["Kossmann", "Donald", ""]]}, {"id": "1611.08321", "submitter": "Junhua Mao", "authors": "Junhua Mao, Jiajing Xu, Yushi Jing, Alan Yuille", "title": "Training and Evaluating Multimodal Word Embeddings with Large-scale Web\n  Annotated Images", "comments": "Appears in NIPS 2016. The datasets introduced in this work will be\n  gradually released on the project page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on training and evaluating effective word embeddings\nwith both text and visual information. More specifically, we introduce a\nlarge-scale dataset with 300 million sentences describing over 40 million\nimages crawled and downloaded from publicly available Pins (i.e. an image with\nsentence descriptions uploaded by users) on Pinterest. This dataset is more\nthan 200 times larger than MS COCO, the standard large-scale image dataset with\nsentence descriptions. In addition, we construct an evaluation dataset to\ndirectly assess the effectiveness of word embeddings in terms of finding\nsemantically similar or related words and phrases. The word/phrase pairs in\nthis evaluation dataset are collected from the click data with millions of\nusers in an image search system, thus contain rich semantic relationships.\nBased on these datasets, we propose and compare several Recurrent Neural\nNetworks (RNNs) based multimodal (text and image) models. Experiments show that\nour model benefits from incorporating the visual information into the word\nembeddings, and a weight sharing strategy is crucial for learning such\nmultimodal embeddings. The project page is:\nhttp://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 23:15:56 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Mao", "Junhua", ""], ["Xu", "Jiajing", ""], ["Jing", "Yushi", ""], ["Yuille", "Alan", ""]]}, {"id": "1611.08331", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Li-Na Wang, Junyu Dong", "title": "An Overview on Data Representation Learning: From Traditional Feature\n  Learning to Recent Deep Learning", "comments": "About 20 pages. Submitted to Journal of Finance and Data Science as\n  an invited paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since about 100 years ago, to learn the intrinsic structure of data, many\nrepresentation learning approaches have been proposed, including both linear\nones and nonlinear ones, supervised ones and unsupervised ones. Particularly,\ndeep architectures are widely applied for representation learning in recent\nyears, and have delivered top results in many tasks, such as image\nclassification, object detection and speech recognition. In this paper, we\nreview the development of data representation learning methods. Specifically,\nwe investigate both traditional feature learning algorithms and\nstate-of-the-art deep learning models. The history of data representation\nlearning is introduced, while available resources (e.g. online course, tutorial\nand book information) and toolboxes are provided. Finally, we conclude this\npaper with remarks and some interesting research directions on data\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 00:53:37 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Wang", "Li-Na", ""], ["Dong", "Junyu", ""]]}, {"id": "1611.08366", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Daoqiang Zhang", "title": "Local Discriminant Hyperalignment for multi-subject fMRI data alignment", "comments": "Published in the Thirty-First AAAI Conference on Artificial\n  Intelligence (AAAI-17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Pattern (MVP) classification can map different cognitive states\nto the brain tasks. One of the main challenges in MVP analysis is validating\nthe generated results across subjects. However, analyzing multi-subject fMRI\ndata requires accurate functional alignments between neuronal activities of\ndifferent subjects, which can rapidly increase the performance and robustness\nof the final results. Hyperalignment (HA) is one of the most effective\nfunctional alignment methods, which can be mathematically formulated by the\nCanonical Correlation Analysis (CCA) methods. Since HA mostly uses the\nunsupervised CCA techniques, its solution may not be optimized for MVP\nanalysis. By incorporating the idea of Local Discriminant Analysis (LDA) into\nCCA, this paper proposes Local Discriminant Hyperalignment (LDHA) as a novel\nsupervised HA method, which can provide better functional alignment for MVP\nanalysis. Indeed, the locality is defined based on the stimuli categories in\nthe train-set, where the correlation between all stimuli in the same category\nwill be maximized and the correlation between distinct categories of stimuli\napproaches to near zero. Experimental studies on multi-subject MVP analysis\nconfirm that the LDHA method achieves superior performance to other\nstate-of-the-art HA algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 07:27:34 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1611.08372", "submitter": "Chen Xu", "authors": "Chen Xu, Zhouchen Lin, Hongbin Zha", "title": "A Unified Convex Surrogate for the Schatten-$p$ Norm", "comments": "The paper is accepted by AAAI-17. We show that multi-factor matrix\n  factorization enjoys superiority over the traditional two-factor case", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Schatten-$p$ norm ($0<p<1$) has been widely used to replace the nuclear\nnorm for better approximating the rank function. However, existing methods are\neither 1) not scalable for large scale problems due to relying on singular\nvalue decomposition (SVD) in every iteration, or 2) specific to some $p$\nvalues, e.g., $1/2$, and $2/3$. In this paper, we show that for any $p$, $p_1$,\nand $p_2 >0$ satisfying $1/p=1/p_1+1/p_2$, there is an equivalence between the\nSchatten-$p$ norm of one matrix and the Schatten-$p_1$ and the Schatten-$p_2$\nnorms of its two factor matrices. We further extend the equivalence to multiple\nfactor matrices and show that all the factor norms can be convex and smooth for\nany $p>0$. In contrast, the original Schatten-$p$ norm for $0<p<1$ is\nnon-convex and non-smooth. As an example we conduct experiments on matrix\ncompletion. To utilize the convexity of the factor matrix norms, we adopt the\naccelerated proximal alternating linearized minimization algorithm and\nestablish its sequence convergence. Experiments on both synthetic and real\ndatasets exhibit its superior performance over the state-of-the-art methods.\nIts speed is also highly competitive.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 08:03:31 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Xu", "Chen", ""], ["Lin", "Zhouchen", ""], ["Zha", "Hongbin", ""]]}, {"id": "1611.08373", "submitter": "Raghav Chalapathy", "authors": "Raghavendra Chalapathy, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "Bidirectional LSTM-CRF for Clinical Concept Extraction", "comments": "This paper \"Bidirectional LSTM-CRF for Clinical Concept Extraction\"\n  is accepted for short paper presentation at Clinical Natural Language\n  Processing Workshop at COLING 2016 Osaka, Japan. December 11, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated extraction of concepts from patient clinical records is an\nessential facilitator of clinical research. For this reason, the 2010 i2b2/VA\nNatural Language Processing Challenges for Clinical Records introduced a\nconcept extraction task aimed at identifying and classifying concepts into\npredefined categories (i.e., treatments, tests and problems). State-of-the-art\nconcept extraction approaches heavily rely on handcrafted features and\ndomain-specific resources which are hard to collect and define. For this\nreason, this paper proposes an alternative, streamlined approach: a recurrent\nneural network (the bidirectional LSTM with CRF decoding) initialized with\ngeneral-purpose, off-the-shelf word embeddings. The experimental results\nachieved on the 2010 i2b2/VA reference corpora using the proposed framework\noutperform all recent methods and ranks closely to the best submission from the\noriginal 2010 i2b2/VA challenge.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 08:11:23 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Chalapathy", "Raghavendra", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1611.08480", "submitter": "Maximilian Alber", "authors": "Maximilian Alber, Julian Zimmert, Urun Dogan, Marius Kloft", "title": "Distributed Optimization of Multi-Class SVMs", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0178161", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of one-vs.-rest SVMs can be parallelized over the number of classes\nin a straight forward way. Given enough computational resources, one-vs.-rest\nSVMs can thus be trained on data involving a large number of classes. The same\ncannot be stated, however, for the so-called all-in-one SVMs, which require\nsolving a quadratic program of size quadratically in the number of classes. We\ndevelop distributed algorithms for two all-in-one SVM formulations (Lee et al.\nand Weston and Watkins) that parallelize the computation evenly over the number\nof classes. This allows us to compare these models to one-vs.-rest SVMs on\nunprecedented scale. The results indicate superior accuracy on text\nclassification data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 15:07:06 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 08:52:10 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Alber", "Maximilian", ""], ["Zimmert", "Julian", ""], ["Dogan", "Urun", ""], ["Kloft", "Marius", ""]]}, {"id": "1611.08483", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan, Edwin Grappin, Quentin Paris", "title": "On the Exponentially Weighted Aggregate with the Laplace Prior", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the statistical behaviour of the Exponentially\nWeighted Aggregate (EWA) in the problem of high-dimensional regression with\nfixed design. Under the assumption that the underlying regression vector is\nsparse, it is reasonable to use the Laplace distribution as a prior. The\nresulting estimator and, specifically, a particular instance of it referred to\nas the Bayesian lasso, was already used in the statistical literature because\nof its computational convenience, even though no thorough mathematical analysis\nof its statistical properties was carried out. The present work fills this gap\nby establishing sharp oracle inequalities for the EWA with the Laplace prior.\nThese inequalities show that if the temperature parameter is small, the EWA\nwith the Laplace prior satisfies the same type of oracle inequality as the\nlasso estimator does, as long as the quality of estimation is measured by the\nprediction loss. Extensions of the proposed methodology to the problem of\nprediction with low-rank matrices are considered.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 15:16:45 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Grappin", "Edwin", ""], ["Paris", "Quentin", ""]]}, {"id": "1611.08568", "submitter": "Rui Shu", "authors": "Rui Shu, Hung H. Bui, Mohammad Ghavamzadeh", "title": "Bottleneck Conditional Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework for training deep generative models for\nhigh-dimensional conditional density estimation. The Bottleneck Conditional\nDensity Estimator (BCDE) is a variant of the conditional variational\nautoencoder (CVAE) that employs layer(s) of stochastic variables as the\nbottleneck between the input $x$ and target $y$, where both are\nhigh-dimensional. Crucially, we propose a new hybrid training method that\nblends the conditional generative model with a joint generative model. Hybrid\nblending is the key to effective training of the BCDE, which avoids overfitting\nand provides a novel mechanism for leveraging unlabeled data. We show that our\nhybrid training procedure enables models to achieve competitive results in the\nMNIST quadrant prediction task in the fully-supervised setting, and sets new\nbenchmarks in the semi-supervised regime for MNIST, SVHN, and CelebA.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 19:42:53 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 08:28:08 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 12:27:01 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Shu", "Rui", ""], ["Bui", "Hung H.", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1611.08618", "submitter": "Yazhou Yang", "authors": "Yazhou Yang, Marco Loog", "title": "A Benchmark and Comparison of Active Learning for Logistic Regression", "comments": "accepted by Pattern Recognition", "journal-ref": "Pattern Recognition 83C (2018) pp. 401-415", "doi": "10.1016/j.patcog.2018.06.004", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression is by far the most widely used classifier in real-world\napplications. In this paper, we benchmark the state-of-the-art active learning\nmethods for logistic regression and discuss and illustrate their underlying\ncharacteristics. Experiments are carried out on three synthetic datasets and 44\nreal-world datasets, providing insight into the behaviors of these active\nlearning methods with respect to the area of the learning curve (which plots\nclassification accuracy as a function of the number of queried examples) and\ntheir computational costs. Surprisingly, one of the earliest and simplest\nsuggested active learning methods, i.e., uncertainty sampling, performs\nexceptionally well overall. Another remarkable finding is that random sampling,\nwhich is the rudimentary baseline to improve upon, is not overwhelmed by\nindividual active learning techniques in many cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 21:33:57 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 12:49:47 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Yang", "Yazhou", ""], ["Loog", "Marco", ""]]}, {"id": "1611.08648", "submitter": "Berkay Celik", "authors": "Z. Berkay Celik, David Lopez-Paz, Patrick McDaniel", "title": "Patient-Driven Privacy Control through Generalized Distillation", "comments": "IEEE Symposium on Privacy-Aware Computing (IEEE PAC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of data analytics into medicine has changed the nature of\npatient treatment. In this, patients are asked to disclose personal information\nsuch as genetic markers, lifestyle habits, and clinical history. This data is\nthen used by statistical models to predict personalized treatments. However,\ndue to privacy concerns, patients often desire to withhold sensitive\ninformation. This self-censorship can impede proper diagnosis and treatment,\nwhich may lead to serious health complications and even death over time. In\nthis paper, we present privacy distillation, a mechanism which allows patients\nto control the type and amount of information they wish to disclose to the\nhealthcare providers for use in statistical models. Meanwhile, it retains the\naccuracy of models that have access to all patient data under a sufficient but\nnot full set of privacy-relevant information. We validate privacy distillation\nusing a corpus of patients prescribed to warfarin for a personalized dosage. We\nuse a deep neural network to implement privacy distillation for training and\nmaking dose predictions. We find that privacy distillation with sufficient\nprivacy-relevant information i) retains accuracy almost as good as having all\npatient data (only 3\\% worse), and ii) is effective at preventing errors that\nintroduce health-related risks (only 3.9\\% worse under- or over-prescriptions).\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 01:47:00 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 23:49:10 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Celik", "Z. Berkay", ""], ["Lopez-Paz", "David", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1611.08655", "submitter": "Vikraman Karunanidhi", "authors": "K.Vikraman", "title": "A Deep Neural Network to identify foreshocks in real time", "comments": "Paper on earthquake prediction based on deep learning approach. 6\n  figures, two tables and 4 pages in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreshock events provide valuable insight to predict imminent major\nearthquakes. However, it is difficult to identify them in real time. In this\npaper, I propose an algorithm based on deep learning to instantaneously\nclassify a seismic waveform as a foreshock, mainshock or an aftershock event\nachieving a high accuracy of 99% in classification. As a result, this is by far\nthe most reliable method to predict major earthquakes that are preceded by\nforeshocks. In addition, I discuss methods to create an earthquake dataset that\nis compatible with deep networks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 04:19:54 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Vikraman", "K.", ""]]}, {"id": "1611.08666", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Guillaume Couly, Cl\\'ement Olalainty", "title": "Training an Interactive Humanoid Robot Using Multimodal Deep\n  Reinforcement Learning", "comments": "NIPS Workshop on Future of Interactive Learning Machines, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training robots to perceive, act and communicate using multiple modalities\nstill represents a challenging problem, particularly if robots are expected to\nlearn efficiently from small sets of example interactions. We describe a\nlearning approach as a step in this direction, where we teach a humanoid robot\nhow to play the game of noughts and crosses. Given that multiple multimodal\nskills can be trained to play this game, we focus our attention to training the\nrobot to perceive the game, and to interact in this game. Our multimodal deep\nreinforcement learning agent perceives multimodal features and exhibits verbal\nand non-verbal actions while playing. Experimental results using simulations\nshow that the robot can learn to win or draw up to 98% of the games. A pilot\ntest of the proposed multimodal system for the targeted game---integrating\nspeech, vision and gestures---reports that reasonable and fluent interactions\ncan be achieved using the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 06:25:08 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Couly", "Guillaume", ""], ["Olalainty", "Cl\u00e9ment", ""]]}, {"id": "1611.08669", "submitter": "Satwik Kottur", "authors": "Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav,\n  Jos\\'e M. F. Moura, Devi Parikh, Dhruv Batra", "title": "Visual Dialog", "comments": "23 pages, 18 figures, CVPR 2017 camera-ready, results on VisDial v0.9\n  dataset, Webpage: http://visualdialog.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of Visual Dialog, which requires an AI agent to hold a\nmeaningful dialog with humans in natural, conversational language about visual\ncontent. Specifically, given an image, a dialog history, and a question about\nthe image, the agent has to ground the question in image, infer context from\nhistory, and answer the question accurately. Visual Dialog is disentangled\nenough from a specific downstream task so as to serve as a general test of\nmachine intelligence, while being grounded in vision enough to allow objective\nevaluation of individual responses and benchmark progress. We develop a novel\ntwo-person chat data-collection protocol to curate a large-scale Visual Dialog\ndataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10\nquestion-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog\nquestion-answer pairs.\n  We introduce a family of neural encoder-decoder models for Visual Dialog with\n3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --\nand 2 decoders (generative and discriminative), which outperform a number of\nsophisticated baselines. We propose a retrieval-based evaluation protocol for\nVisual Dialog where the AI agent is asked to sort a set of candidate answers\nand evaluated on metrics such as mean-reciprocal-rank of human response. We\nquantify gap between machine and human performance on the Visual Dialog task\nvia human studies. Putting it all together, we demonstrate the first 'visual\nchatbot'! Our dataset, code, trained models and visual chatbot are available on\nhttps://visualdialog.org\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 06:39:28 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 02:00:49 GMT"}, {"version": "v3", "created": "Fri, 21 Apr 2017 16:29:55 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 02:10:49 GMT"}, {"version": "v5", "created": "Tue, 1 Aug 2017 22:04:37 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Das", "Abhishek", ""], ["Kottur", "Satwik", ""], ["Gupta", "Khushi", ""], ["Singh", "Avi", ""], ["Yadav", "Deshraj", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1611.08675", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Seunghak Yu, Ashley Williamson, Jacob Carse", "title": "Deep Reinforcement Learning for Multi-Domain Dialogue Systems", "comments": "NIPS Workshop on Deep Reinforcement Learning, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep reinforcement learning methods such as Deep Q-Networks (DQN)\nfor multiple tasks (domains) face scalability problems. We propose a method for\nmulti-domain dialogue policy learning---termed NDQN, and apply it to an\ninformation-seeking spoken dialogue system in the domains of restaurants and\nhotels. Experimental results comparing DQN (baseline) versus NDQN (proposed)\nusing simulations report that our proposed method exhibits better scalability\nand is promising for optimising the behaviour of multi-domain dialogue systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 07:53:22 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Yu", "Seunghak", ""], ["Williamson", "Ashley", ""], ["Carse", "Jacob", ""]]}, {"id": "1611.08699", "submitter": "Colin Brown J", "authors": "Colin J Brown, Ghassan Hamarneh", "title": "Machine Learning on Human Connectome Data from MRI", "comments": "51 pages, 6 figures. To be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional MRI (fMRI) and diffusion MRI (dMRI) are non-invasive imaging\nmodalities that allow in-vivo analysis of a patient's brain network (known as a\nconnectome). Use of these technologies has enabled faster and better diagnoses\nand treatments of neurological disorders and a deeper understanding of the\nhuman brain. Recently, researchers have been exploring the application of\nmachine learning models to connectome data in order to predict clinical\noutcomes and analyze the importance of subnetworks in the brain. Connectome\ndata has unique properties, which present both special challenges and\nopportunities when used for machine learning. The purpose of this work is to\nreview the literature on the topic of applying machine learning models to\nMRI-based connectome data. This field is growing rapidly and now encompasses a\nlarge body of research. To summarize the research done to date, we provide a\ncomparative, structured summary of 77 relevant works, tabulated according to\ndifferent criteria, that represent the majority of the literature on this\ntopic. (We also published a living version of this table online at\nhttp://connectomelearning.cs.sfu.ca that the community can continue to\ncontribute to.) After giving an overview of how connectomes are constructed\nfrom dMRI and fMRI data, we discuss the variety of machine learning tasks that\nhave been explored with connectome data. We then compare the advantages and\ndrawbacks of different machine learning approaches that have been employed,\ndiscussing different feature selection and feature extraction schemes, as well\nas the learning models and regularization penalties themselves. Throughout this\ndiscussion, we focus particularly on how the methods are adapted to the unique\nnature of graphical connectome data. Finally, we conclude by summarizing the\ncurrent state of the art and by outlining what we believe are strategic\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 11:14:22 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Brown", "Colin J", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1611.08733", "submitter": "Jan Jakubuv", "authors": "Jan Jakubuv, Josef Urban", "title": "BliStrTune: Hierarchical Invention of Theorem Proving Strategies", "comments": "Submitted to Certified Programs and Proofs (CPP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inventing targeted proof search strategies for specific problem sets is a\ndifficult task. State-of-the-art automated theorem provers (ATPs) such as E\nallow a large number of user-specified proof search strategies described in a\nrich domain specific language. Several machine learning methods that invent\nstrategies automatically for ATPs were proposed previously. One of them is the\nBlind Strategymaker (BliStr), a system for automated invention of ATP\nstrategies.\n  In this paper we introduce BliStrTune -- a hierarchical extension of BliStr.\nBliStrTune allows exploring much larger space of E strategies by interleaving\nsearch for high-level parameters with their fine-tuning. We use BliStrTune to\ninvent new strategies based also on new clause weight functions targeted at\nproblems from large ITP libraries. We show that the new strategies\nsignificantly improve E's performance in solving problems from the Mizar\nMathematical Library.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 18:48:43 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jakubuv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1611.08737", "submitter": "Shuangfei Zhai", "authors": "Nana Li, Shuangfei Zhai, Zhongfei Zhang, Boying Liu", "title": "Structural Correspondence Learning for Cross-lingual Sentiment\n  Classification with One-to-many Mappings", "comments": "To appear in AAAI 2017. arXiv admin note: text overlap with\n  arXiv:1008.0716 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural correspondence learning (SCL) is an effective method for\ncross-lingual sentiment classification. This approach uses unlabeled documents\nalong with a word translation oracle to automatically induce task specific,\ncross-lingual correspondences. It transfers knowledge through identifying\nimportant features, i.e., pivot features. For simplicity, however, it assumes\nthat the word translation oracle maps each pivot feature in source language to\nexactly only one word in target language. This one-to-one mapping between words\nin different languages is too strict. Also the context is not considered at\nall. In this paper, we propose a cross-lingual SCL based on distributed\nrepresentation of words; it can learn meaningful one-to-many mappings for pivot\nwords using large amounts of monolingual data and a small dictionary. We\nconduct experiments on NLP\\&CC 2013 cross-lingual sentiment analysis dataset,\nemploying English as source language, and Chinese as target language. Our\nmethod does not rely on the parallel corpora and the experimental results show\nthat our approach is more competitive than the state-of-the-art methods in\ncross-lingual sentiment classification.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 20:11:00 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Li", "Nana", ""], ["Zhai", "Shuangfei", ""], ["Zhang", "Zhongfei", ""], ["Liu", "Boying", ""]]}, {"id": "1611.08754", "submitter": "Lex Fridman", "authors": "Lex Fridman, Heishiro Toyoda, Sean Seaman, Bobbie Seppelt, Linda\n  Angell, Joonbum Lee, Bruce Mehler, Bryan Reimer", "title": "What Can Be Predicted from Six Seconds of Driver Glances?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a large dataset of real-world, on-road driving from a 100-car\nnaturalistic study to explore the predictive power of driver glances and,\nspecifically, to answer the following question: what can be predicted about the\nstate of the driver and the state of the driving environment from a 6-second\nsequence of macro-glances? The context-based nature of such glances allows for\napplication of supervised learning to the problem of vision-based gaze\nestimation, making it robust, accurate, and reliable in messy, real-world\nconditions. So, it's valuable to ask whether such macro-glances can be used to\ninfer behavioral, environmental, and demographic variables? We analyze 27\nbinary classification problems based on these variables. The takeaway is that\nglance can be used as part of a multi-sensor real-time system to predict\nradio-tuning, fatigue state, failure to signal, talking, and several\nenvironment variables.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 22:41:51 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Fridman", "Lex", ""], ["Toyoda", "Heishiro", ""], ["Seaman", "Sean", ""], ["Seppelt", "Bobbie", ""], ["Angell", "Linda", ""], ["Lee", "Joonbum", ""], ["Mehler", "Bruce", ""], ["Reimer", "Bryan", ""]]}, {"id": "1611.08903", "submitter": "Martin Schrimpf", "authors": "Martin Schrimpf", "title": "Should I use TensorFlow", "comments": "Seminar Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google's Machine Learning framework TensorFlow was open-sourced in November\n2015 [1] and has since built a growing community around it. TensorFlow is\nsupposed to be flexible for research purposes while also allowing its models to\nbe deployed productively. This work is aimed towards people with experience in\nMachine Learning considering whether they should use TensorFlow in their\nenvironment. Several aspects of the framework important for such a decision are\nexamined, such as the heterogenity, extensibility and its computation graph. A\npure Python implementation of linear classification is compared with an\nimplementation utilizing TensorFlow. I also contrast TensorFlow to other\npopular frameworks with respect to modeling capability, deployment and\nperformance and give a brief description of the current adaption of the\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 20:20:06 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Schrimpf", "Martin", ""]]}, {"id": "1611.08930", "submitter": "Yi Luo", "authors": "Zhuo Chen, Yi Luo, Nima Mesgarani", "title": "Deep attractor network for single-microphone speaker separation", "comments": "2017 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "journal-ref": null, "doi": "10.1109/ICASSP.2017.7952155", "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the overwhelming success of deep learning in various speech\nprocessing tasks, the problem of separating simultaneous speakers in a mixture\nremains challenging. Two major difficulties in such systems are the arbitrary\nsource permutation and unknown number of sources in the mixture. We propose a\nnovel deep learning framework for single channel speech separation by creating\nattractor points in high dimensional embedding space of the acoustic signals\nwhich pull together the time-frequency bins corresponding to each source.\nAttractor points in this study are created by finding the centroids of the\nsources in the embedding space, which are subsequently used to determine the\nsimilarity of each bin in the mixture to each source. The network is then\ntrained to minimize the reconstruction error of each source by optimizing the\nembeddings. The proposed model is different from prior works in that it\nimplements an end-to-end training, and it does not depend on the number of\nsources in the mixture. Two strategies are explored in the test time, K-means\nand fixed attractor points, where the latter requires no post-processing and\ncan be implemented in real-time. We evaluated our system on Wall Street Journal\ndataset and show 5.49\\% improvement over the previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 22:47:23 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 03:15:07 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Chen", "Zhuo", ""], ["Luo", "Yi", ""], ["Mesgarani", "Nima", ""]]}, {"id": "1611.08945", "submitter": "Arvind Neelakantan", "authors": "Arvind Neelakantan, Quoc V. Le, Martin Abadi, Andrew McCallum, Dario\n  Amodei", "title": "Learning a Natural Language Interface with Neural Programmer", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a natural language interface for database tables is a challenging\ntask that involves deep language understanding and multi-step reasoning. The\ntask is often approached by mapping natural language queries to logical forms\nor programs that provide the desired response when executed on the database. To\nour knowledge, this paper presents the first weakly supervised, end-to-end\nneural network model to induce such programs on a real-world dataset. We\nenhance the objective function of Neural Programmer, a neural network with\nbuilt-in discrete operations, and apply it on WikiTableQuestions, a natural\nlanguage question-answering dataset. The model is trained end-to-end with weak\nsupervision of question-answer pairs, and does not require domain-specific\ngrammars, rules, or annotations that are key elements in previous approaches to\nprogram induction. The main experimental result in this paper is that a single\nNeural Programmer model achieves 34.2% accuracy using only 10,000 examples with\nweak supervision. An ensemble of 15 models, with a trivial combination\ntechnique, achieves 37.7% accuracy, which is competitive to the current\nstate-of-the-art accuracy of 37.1% obtained by a traditional natural language\nsemantic parser.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 00:54:34 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:18:14 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2017 14:43:12 GMT"}, {"version": "v4", "created": "Thu, 2 Mar 2017 16:02:00 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Le", "Quoc V.", ""], ["Abadi", "Martin", ""], ["McCallum", "Andrew", ""], ["Amodei", "Dario", ""]]}, {"id": "1611.08998", "submitter": "Seyed Hamid Rezatofighi", "authors": "S. Hamid Rezatofighi, Vijay Kumar B G, Anton Milan, Ehsan Abbasnejad,\n  Anthony Dick, Ian Reid", "title": "DeepSetNet: Predicting Sets with Deep Neural Networks", "comments": "Accepted in IEEE International Conference on Computer Vision (ICCV),\n  Venice, 2017, (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task of set prediction using deep learning. This is\nimportant because the output of many computer vision tasks, including image\ntagging and object detection, are naturally expressed as sets of entities\nrather than vectors. As opposed to a vector, the size of a set is not fixed in\nadvance, and it is invariant to the ordering of entities within it. We define a\nlikelihood for a set distribution and learn its parameters using a deep neural\nnetwork. We also derive a loss for predicting a discrete distribution\ncorresponding to set cardinality. Set prediction is demonstrated on the problem\nof multi-class image classification. Moreover, we show that the proposed\ncardinality loss can also trivially be applied to the tasks of object counting\nand pedestrian detection. Our approach outperforms existing methods in all\nthree cases on standard datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 06:42:56 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 06:18:14 GMT"}, {"version": "v3", "created": "Mon, 12 Dec 2016 01:10:13 GMT"}, {"version": "v4", "created": "Fri, 31 Mar 2017 06:45:52 GMT"}, {"version": "v5", "created": "Fri, 11 Aug 2017 02:52:36 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Rezatofighi", "S. Hamid", ""], ["G", "Vijay Kumar B", ""], ["Milan", "Anton", ""], ["Abbasnejad", "Ehsan", ""], ["Dick", "Anthony", ""], ["Reid", "Ian", ""]]}, {"id": "1611.09180", "submitter": "Quanzeng You", "authors": "Quanzeng You, Ran Pang, Liangliang Cao, Jiebo Luo", "title": "Image Based Appraisal of Real Estate Properties", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TMM.2017.2710804", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate appraisal, which is the process of estimating the price for real\nestate properties, is crucial for both buys and sellers as the basis for\nnegotiation and transaction. Traditionally, the repeat sales model has been\nwidely adopted to estimate real estate price. However, it depends the design\nand calculation of a complex economic related index, which is challenging to\nestimate accurately. Today, real estate brokers provide easy access to detailed\nonline information on real estate properties to their clients. We are\ninterested in estimating the real estate price from these large amounts of\neasily accessed data. In particular, we analyze the prediction power of online\nhouse pictures, which is one of the key factors for online users to make a\npotential visiting decision. The development of robust computer vision\nalgorithms makes the analysis of visual content possible. In this work, we\nemploy a Recurrent Neural Network (RNN) to predict real estate price using the\nstate-of-the-art visual features. The experimental results indicate that our\nmodel outperforms several of other state-of-the-art baseline algorithms in\nterms of both mean absolute error (MAE) and mean absolute percentage error\n(MAPE).\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 15:23:14 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 19:18:27 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["You", "Quanzeng", ""], ["Pang", "Ran", ""], ["Cao", "Liangliang", ""], ["Luo", "Jiebo", ""]]}, {"id": "1611.09194", "submitter": "Pierre-Francois Marteau", "authors": "Pierre-Fran\\c{c}ois Marteau (EXPRESSION)", "title": "Times series averaging and denoising from a probabilistic perspective on\n  time-elastic kernels", "comments": "arXiv admin note: text overlap with arXiv:1505.06897. International\n  Journal of Applied Mathematics and Computer Science, June 2019", "journal-ref": null, "doi": "10.2478/amcs-2019-0028", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the light of regularized dynamic time warping kernels, this paper\nre-considers the concept of time elastic centroid for a setof time series. We\nderive a new algorithm based on a probabilistic interpretation of kernel\nalignment matrices. This algorithm expressesthe averaging process in terms of a\nstochastic alignment automata. It uses an iterative agglomerative heuristic\nmethod for averagingthe aligned samples, while also averaging the times of\noccurrence of the aligned samples. By comparing classification accuracies for45\nheterogeneous time series datasets obtained by first nearest centroid/medoid\nclassifiers we show that: i) centroid-basedapproaches significantly outperform\nmedoid-based approaches, ii) for the considered datasets, our algorithm that\ncombines averagingin the sample space and along the time axes, emerges as the\nmost significantly robust model for time-elastic averaging with apromising\nnoise reduction capability. We also demonstrate its benefit in an isolated\ngesture recognition experiment and its ability tosignificantly reduce the size\nof training instance sets. Finally we highlight its denoising capability using\ndemonstrative synthetic data:we show that it is possible to retrieve, from few\nnoisy instances, a signal whose components are scattered in a wide spectral\nband.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 15:34:30 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 12:41:07 GMT"}, {"version": "v3", "created": "Thu, 22 Dec 2016 11:50:08 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 08:40:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Marteau", "Pierre-Fran\u00e7ois", "", "EXPRESSION"]]}, {"id": "1611.09207", "submitter": "Brian Patton", "authors": "Brian Patton, Yannis Agiomyrgiannakis, Michael Terry, Kevin Wilson,\n  Rif A. Saurous, D. Sculley", "title": "AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech", "comments": "4 pages, 2 figures, 2 tables, NIPS 2016 End-to-end Learning for\n  Speech and Audio Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers of text-to-speech synthesizers (TTS) often make use of human\nraters to assess the quality of synthesized speech. We demonstrate that we can\nmodel human raters' mean opinion scores (MOS) of synthesized speech using a\ndeep recurrent neural network whose inputs consist solely of a raw waveform.\nOur best models provide utterance-level estimates of MOS only moderately\ninferior to sampled human ratings, as shown by Pearson and Spearman\ncorrelations. When multiple utterances are scored and averaged, a scenario\ncommon in synthesizer quality assessment, AutoMOS achieves correlations\napproaching those of human raters. The AutoMOS model has a number of\napplications, such as the ability to explore the parameter space of a speech\nsynthesizer without requiring a human-in-the-loop.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 15:51:25 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Patton", "Brian", ""], ["Agiomyrgiannakis", "Yannis", ""], ["Terry", "Michael", ""], ["Wilson", "Kevin", ""], ["Saurous", "Rif A.", ""], ["Sculley", "D.", ""]]}, {"id": "1611.09226", "submitter": "Michael Figurnov", "authors": "Michael Figurnov, Kirill Struminsky, Dmitry Vetrov", "title": "Robust Variational Inference", "comments": "NIPS 2016 Workshop, Advances in Approximate Bayesian Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is a powerful tool for approximate inference. However,\nit mainly focuses on the evidence lower bound as variational objective and the\ndevelopment of other measures for variational inference is a promising area of\nresearch. This paper proposes a robust modification of evidence and a lower\nbound for the evidence, which is applicable when the majority of the training\nset samples are random noise objects. We provide experiments for variational\nautoencoders to show advantage of the objective over the evidence lower bound\non synthetic datasets obtained by adding uninformative noise objects to MNIST\nand OMNIGLOT. Additionally, for the original MNIST and OMNIGLOT datasets we\nobserve a small improvement over the non-robust evidence lower bound.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 16:28:41 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Figurnov", "Michael", ""], ["Struminsky", "Kirill", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1611.09232", "submitter": "Meshia C\\'edric Oveneke", "authors": "Meshia C\\'edric Oveneke, Mitchel Aliosha-Perez, Yong Zhao, Dongmei\n  Jiang and Hichem Sahli", "title": "Efficient Convolutional Auto-Encoding via Random Convexification and\n  Frequency-Domain Minimization", "comments": "Accepted at NIPS 2016 Workshop on Efficient Methods for Deep Neural\n  Networks (EMDNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The omnipresence of deep learning architectures such as deep convolutional\nneural networks (CNN)s is fueled by the synergistic combination of\never-increasing labeled datasets and specialized hardware. Despite the\nindisputable success, the reliance on huge amounts of labeled data and\nspecialized hardware can be a limiting factor when approaching new\napplications. To help alleviating these limitations, we propose an efficient\nlearning strategy for layer-wise unsupervised training of deep CNNs on\nconventional hardware in acceptable time. Our proposed strategy consists of\nrandomly convexifying the reconstruction contractive auto-encoding (RCAE)\nlearning objective and solving the resulting large-scale convex minimization\nproblem in the frequency domain via coordinate descent (CD). The main\nadvantages of our proposed learning strategy are: (1) single tunable\noptimization parameter; (2) fast and guaranteed convergence; (3) possibilities\nfor full parallelization. Numerical experiments show that our proposed learning\nstrategy scales (in the worst case) linearly with image size, number of filters\nand filter size.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 16:42:11 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Oveneke", "Meshia C\u00e9dric", ""], ["Aliosha-Perez", "Mitchel", ""], ["Zhao", "Yong", ""], ["Jiang", "Dongmei", ""], ["Sahli", "Hichem", ""]]}, {"id": "1611.09288", "submitter": "Tom Sercu", "authors": "Tom Sercu and Vaibhava Goel", "title": "Dense Prediction on Sequences with Time-Dilated Convolutions for Speech\n  Recognition", "comments": "Appeared at NIPS 2016 End-to-end Learning for Speech and Audio\n  Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision pixelwise dense prediction is the task of predicting a\nlabel for each pixel in the image. Convolutional neural networks achieve good\nperformance on this task, while being computationally efficient. In this paper\nwe carry these ideas over to the problem of assigning a sequence of labels to a\nset of speech frames, a task commonly known as framewise classification. We\nshow that dense prediction view of framewise classification offers several\nadvantages and insights, including computational efficiency and the ability to\napply batch normalization. When doing dense prediction we pay specific\nattention to strided pooling in time and introduce an asymmetric dilated\nconvolution, called time-dilated convolution, that allows for efficient and\nelegant implementation of pooling in time. We show results using time-dilated\nconvolutions in a very deep VGG-style CNN with batch normalization on the Hub5\nSwitchboard-2000 benchmark task. With a big n-gram language model, we achieve\n7.7% WER which is the best single model single-pass performance reported so\nfar.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 19:09:58 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 08:27:41 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Sercu", "Tom", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1611.09321", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mohammad Norouzi, Dale Schuurmans", "title": "Improving Policy Gradient by Exploring Under-appreciated Rewards", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel form of policy gradient for model-free\nreinforcement learning (RL) with improved exploration properties. Current\npolicy-based methods use entropy regularization to encourage undirected\nexploration of the reward landscape, which is ineffective in high dimensional\nspaces with sparse rewards. We propose a more directed exploration strategy\nthat promotes exploration of under-appreciated reward regions. An action\nsequence is considered under-appreciated if its log-probability under the\ncurrent policy under-estimates its resulting reward. The proposed exploration\nstrategy is easy to implement, requiring small modifications to an\nimplementation of the REINFORCE algorithm. We evaluate the approach on a set of\nalgorithmic tasks that have long challenged RL methods. Our approach reduces\nhyper-parameter sensitivity and demonstrates significant improvements over\nbaseline methods. Our algorithm successfully solves a benchmark multi-digit\naddition task and generalizes to long sequences. This is, to our knowledge, the\nfirst time that a pure RL method has solved addition using only reward\nfeedback.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:15:55 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 22:35:03 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 22:55:17 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Nachum", "Ofir", ""], ["Norouzi", "Mohammad", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1611.09328", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Adam White, Martha White", "title": "Accelerated Gradient Temporal Difference Learning", "comments": "AAAI Conference on Artificial Intelligence (AAAI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of temporal difference (TD) methods span a spectrum from\ncomputationally frugal linear methods like TD({\\lambda}) to data efficient\nleast squares methods. Least square methods make the best use of available data\ndirectly computing the TD solution and thus do not require tuning a typically\nhighly sensitive learning rate parameter, but require quadratic computation and\nstorage. Recent algorithmic developments have yielded several sub-quadratic\nmethods that use an approximation to the least squares TD solution, but incur\nbias. In this paper, we propose a new family of accelerated gradient TD (ATD)\nmethods that (1) provide similar data efficiency benefits to least-squares\nmethods, at a fraction of the computation and storage (2) significantly reduce\nparameter sensitivity compared to linear TD methods, and (3) are asymptotically\nunbiased. We illustrate these claims with a proof of convergence in expectation\nand experiments on several benchmark domains and a large-scale industrial\nenergy allocation domain.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:33:15 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 22:36:45 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Pan", "Yangchen", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1611.09333", "submitter": "Fredrik Sandin", "authors": "Fredrik Sandin, Sergio Martin-del-Campo", "title": "Dictionary Learning with Equiprobable Matching Pursuit", "comments": "8 pages, 8 figures", "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2017.7965902", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse signal representations based on linear combinations of learned atoms\nhave been used to obtain state-of-the-art results in several practical signal\nprocessing applications. Approximation methods are needed to process\nhigh-dimensional signals in this way because the problem to calculate optimal\natoms for sparse coding is NP-hard. Here we study greedy algorithms for\nunsupervised learning of dictionaries of shift-invariant atoms and propose a\nnew method where each atom is selected with the same probability on average,\nwhich corresponds to the homeostatic regulation of a recurrent convolutional\nneural network. Equiprobable selection can be used with several greedy\nalgorithms for dictionary learning to ensure that all atoms adapt during\ntraining and that no particular atom is more likely to take part in the linear\ncombination on average. We demonstrate via simulation experiments that\ndictionary learning with equiprobable selection results in higher entropy of\nthe sparse representation and lower reconstruction and denoising errors, both\nin the case of ordinary matching pursuit and orthogonal matching pursuit with\nshift-invariant dictionaries. Furthermore, we show that the computational costs\nof the matching pursuits are lower with equiprobable selection, leading to\nfaster and more accurate dictionary learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:38:52 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sandin", "Fredrik", ""], ["Martin-del-Campo", "Sergio", ""]]}, {"id": "1611.09340", "submitter": "Adriana Romero", "authors": "Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain,\n  Alex Auvolat, Etienne Dejoie, Marc-Andr\\'e Legault, Marie-Pierre Dub\\'e,\n  Julie G. Hussin, Yoshua Bengio", "title": "Diet Networks: Thin Parameters for Fat Genomics", "comments": null, "journal-ref": "ICLR 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning tasks such as those involving genomic data often poses a serious\nchallenge: the number of input features can be orders of magnitude larger than\nthe number of training examples, making it difficult to avoid overfitting, even\nwhen using the known regularization techniques. We focus here on tasks in which\nthe input is a description of the genetic variation specific to a patient, the\nsingle nucleotide polymorphisms (SNPs), yielding millions of ternary inputs.\nImproving the ability of deep learning to handle such datasets could have an\nimportant impact in precision medicine, where high-dimensional data regarding a\nparticular patient is used to make predictions of interest. Even though the\namount of data for such tasks is increasing, this mismatch between the number\nof examples and the number of inputs remains a concern. Naive implementations\nof classifier neural networks involve a huge number of free parameters in their\nfirst layer: each input feature is associated with as many parameters as there\nare hidden units. We propose a novel neural network parametrization which\nconsiderably reduces the number of free parameters. It is based on the idea\nthat we can first learn or provide a distributed representation for each input\nfeature (e.g. for each position in the genome where variations are observed),\nand then learn (with another neural network called the parameter prediction\nnetwork) how to map a feature's distributed representation to the vector of\nparameters specific to that feature in the classifier neural network (the\nweights which link the value of the feature to each of the hidden units). We\nshow experimentally on a population stratification task of interest to medical\nstudies that the proposed approach can significantly reduce both the number of\nparameters and the error rate of the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:50:32 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 18:51:52 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 21:09:28 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Romero", "Adriana", ""], ["Carrier", "Pierre Luc", ""], ["Erraqabi", "Akram", ""], ["Sylvain", "Tristan", ""], ["Auvolat", "Alex", ""], ["Dejoie", "Etienne", ""], ["Legault", "Marc-Andr\u00e9", ""], ["Dub\u00e9", "Marie-Pierre", ""], ["Hussin", "Julie G.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1611.09345", "submitter": "Yongxin Yang", "authors": "Yongxin Yang, Timothy M. Hospedales", "title": "Unifying Multi-Domain Multi-Task Learning: Tensor and Neural Network\n  Perspectives", "comments": "Invited book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain learning aims to benefit from simultaneously learning across\nseveral different but related domains. In this chapter, we propose a single\nframework that unifies multi-domain learning (MDL) and the related but better\nstudied area of multi-task learning (MTL). By exploiting the concept of a\n\\emph{semantic descriptor} we show how our framework encompasses various\nclassic and recent MDL/MTL algorithms as special cases with different semantic\ndescriptor encodings. As a second contribution, we present a higher order\ngeneralisation of this framework, capable of simultaneous\nmulti-task-multi-domain learning. This generalisation has two mathematically\nequivalent views in multi-linear algebra and gated neural networks\nrespectively. Moreover, by exploiting the semantic descriptor, it provides\nneural networks the capability of zero-shot learning (ZSL), where a classifier\nis generated for an unseen class without any training data; as well as\nzero-shot domain adaptation (ZSDA), where a model is generated for an unseen\ndomain without any training data. In practice, this framework provides a\npowerful yet easy to implement method that can be flexibly applied to MTL, MDL,\nZSL and ZSDA.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:59:18 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Yang", "Yongxin", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1611.09384", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Neil D. Lawrence, Joshua B. Tenenbaum", "title": "The Emergence of Organizing Structure in Conceptual Representation", "comments": "In press at Cognitive Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both scientists and children make important structural discoveries, yet their\ncomputational underpinnings are not well understood. Structure discovery has\npreviously been formalized as probabilistic inference about the right\nstructural form --- where form could be a tree, ring, chain, grid, etc. [Kemp &\nTenenbaum (2008). The discovery of structural form. PNAS, 105(3), 10687-10692].\nWhile this approach can learn intuitive organizations, including a tree for\nanimals and a ring for the color circle, it assumes a strong inductive bias\nthat considers only these particular forms, and each form is explicitly\nprovided as initial knowledge. Here we introduce a new computational model of\nhow organizing structure can be discovered, utilizing a broad hypothesis space\nwith a preference for sparse connectivity. Given that the inductive bias is\nmore general, the model's initial knowledge shows little qualitative\nresemblance to some of the discoveries it supports. As a consequence, the model\ncan also learn complex structures for domains that lack intuitive description,\nas well as predict human property induction judgments without explicit\nstructural forms. By allowing form to emerge from sparsity, our approach\nclarifies how both the richness and flexibility of human conceptual\norganization can coexist.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 21:13:25 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 00:41:32 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Lake", "Brenden M.", ""], ["Lawrence", "Neil D.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1611.09419", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Vaios Papaspyros, Konstantinos Chatzilygeroudis, Vassilis Vassiliades\n  and Jean-Baptiste Mouret", "title": "Safety-Aware Robot Damage Recovery Using Constrained Bayesian\n  Optimization and Simulated Priors", "comments": "Accepted at the BayesOpt 2016 NIPS workshop, 5 pages, 2 figures, 1\n  algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Intelligent Trial-and-Error (IT&E) algorithm showed\nthat robots can adapt to damage in a matter of a few trials. The success of\nthis algorithm relies on two components: prior knowledge acquired through\nsimulation with an intact robot, and Bayesian optimization (BO) that operates\non-line, on the damaged robot. While IT&E leads to fast damage recovery, it\ndoes not incorporate any safety constraints that prevent the robot from\nattempting harmful behaviors. In this work, we address this limitation by\nreplacing the BO component with a constrained BO procedure. We evaluate our\napproach on a simulated damaged humanoid robot that needs to crawl as fast as\npossible, while performing as few unsafe trials as possible. We compare our new\n\"safety-aware IT&E\" algorithm to IT&E and a multi-objective version of IT&E in\nwhich the safety constraints are dealt as separate objectives. Our results show\nthat our algorithm outperforms the other approaches, both in crawling speed\nwithin the safe regions and number of unsafe trials.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 22:56:24 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 23:28:57 GMT"}, {"version": "v3", "created": "Fri, 2 Dec 2016 09:33:07 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Papaspyros", "Vaios", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Vassiliades", "Vassilis", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1611.09430", "submitter": "Brian Cheung", "authors": "Brian Cheung, Eric Weiss, Bruno Olshausen", "title": "Emergence of foveal image sampling from learning to attend in visual\n  scenes", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a neural attention model with a learnable retinal sampling\nlattice. The model is trained on a visual search task requiring the\nclassification of an object embedded in a visual scene amidst background\ndistractors using the smallest number of fixations. We explore the tiling\nproperties that emerge in the model's retinal sampling lattice after training.\nSpecifically, we show that this lattice resembles the eccentricity dependent\nsampling lattice of the primate retina, with a high resolution region in the\nfovea surrounded by a low resolution periphery. Furthermore, we find conditions\nwhere these emergent properties are amplified or eliminated providing clues to\ntheir function.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:39:20 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 08:26:16 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Cheung", "Brian", ""], ["Weiss", "Eric", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1611.09434", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Justin Gilmer, Jan Chorowski, Jascha\n  Sohl-Dickstein, David Sussillo", "title": "Input Switched Affine Networks: An RNN Architecture Designed for\n  Interpretability", "comments": "ICLR 2107 submission: https://openreview.net/forum?id=H1MjAnqxg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many problem domains where the interpretability of neural network\nmodels is essential for deployment. Here we introduce a recurrent architecture\ncomposed of input-switched affine transformations - in other words an RNN\nwithout any explicit nonlinearities, but with input-dependent recurrent\nweights. This simple form allows the RNN to be analyzed via straightforward\nlinear methods: we can exactly characterize the linear contribution of each\ninput to the model predictions; we can use a change-of-basis to disentangle\ninput, output, and computational hidden unit subspaces; we can fully\nreverse-engineer the architecture's solution to a simple task. Despite this\nease of interpretation, the input switched affine network achieves reasonable\nperformance on a text modeling tasks, and allows greater computational\nefficiency than networks with standard nonlinearities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:48:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 20:29:48 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Gilmer", "Justin", ""], ["Chorowski", "Jan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Sussillo", "David", ""]]}, {"id": "1611.09444", "submitter": "Alden Walker", "authors": "Kevin K. Chen, Anthony Gamst, Alden Walker", "title": "The empirical size of trained neural networks", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ReLU neural networks define piecewise linear functions of their inputs.\nHowever, initializing and training a neural network is very different from\nfitting a linear spline. In this paper, we expand empirically upon previous\ntheoretical work to demonstrate features of trained neural networks. Standard\nnetwork initialization and training produce networks vastly simpler than a\nnaive parameter count would suggest and can impart odd features to the trained\nnetwork. However, we also show the forced simplicity is beneficial and, indeed,\ncritical for the wide success of these networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 00:39:45 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Chen", "Kevin K.", ""], ["Gamst", "Anthony", ""], ["Walker", "Alden", ""]]}, {"id": "1611.09448", "submitter": "Kevin Chen", "authors": "Kevin K. Chen", "title": "The Upper Bound on Knots in Neural Networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with rectified linear unit activations are essentially\nmultivariate linear splines. As such, one of many ways to measure the\n\"complexity\" or \"expressivity\" of a neural network is to count the number of\nknots in the spline model. We study the number of knots in fully-connected\nfeedforward neural networks with rectified linear unit activation functions. We\nintentionally keep the neural networks very simple, so as to make theoretical\nanalyses more approachable. An induction on the number of layers $l$ reveals a\ntight upper bound on the number of knots in $\\mathbb{R} \\to \\mathbb{R}^p$ deep\nneural networks. With $n_i \\gg 1$ neurons in layer $i = 1, \\dots, l$, the upper\nbound is approximately $n_1 \\dots n_l$. We then show that the exact upper bound\nis tight, and we demonstrate the upper bound with an example. The purpose of\nthese analyses is to pave a path for understanding the behavior of general\n$\\mathbb{R}^q \\to \\mathbb{R}^p$ neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 01:07:58 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 02:00:48 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Chen", "Kevin K.", ""]]}, {"id": "1611.09461", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Kuan-Hao Huang, Chih-Wei Chang, Hsuan-Tien Lin", "title": "Cost-Sensitive Reference Pair Encoding for Multi-Label Learning", "comments": "Accepted in 22nd Pacific-Asia Conference on Knowledge Discovery and\n  Data Mining (PAKDD), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-93034-3_12", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label space expansion for multi-label classification (MLC) is a methodology\nthat encodes the original label vectors to higher dimensional codes before\ntraining and decodes the predicted codes back to the label vectors during\ntesting. The methodology has been demonstrated to improve the performance of\nMLC algorithms when coupled with off-the-shelf error-correcting codes for\nencoding and decoding. Nevertheless, such a coding scheme can be complicated to\nimplement, and cannot easily satisfy a common application need of\ncost-sensitive MLC---adapting to different evaluation criteria of interest. In\nthis work, we show that a simpler coding scheme based on the concept of a\nreference pair of label vectors achieves cost-sensitivity more naturally. In\nparticular, our proposed cost-sensitive reference pair encoding (CSRPE)\nalgorithm contains cluster-based encoding, weight-based training and\nvoting-based decoding steps, all utilizing the cost information. Furthermore,\nwe leverage the cost information embedded in the code space of CSRPE to propose\na novel active learning algorithm for cost-sensitive MLC. Extensive\nexperimental results verify that CSRPE performs better than state-of-the-art\nalgorithms across different MLC criteria. The results also demonstrate that the\nCSRPE-backed active learning algorithm is superior to existing algorithms for\nactive MLC, and further justify the usefulness of CSRPE.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 02:41:28 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 07:26:05 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 05:09:59 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Huang", "Kuan-Hao", ""], ["Chang", "Chih-Wei", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1611.09482", "submitter": "Tom Paine", "authors": "Tom Le Paine, Pooya Khorrami, Shiyu Chang, Yang Zhang, Prajit\n  Ramachandran, Mark A. Hasegawa-Johnson, Thomas S. Huang", "title": "Fast Wavenet Generation Algorithm", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient implementation of the Wavenet generation\nprocess called Fast Wavenet. Compared to a naive implementation that has\ncomplexity O(2^L) (L denotes the number of layers in the network), our proposed\napproach removes redundant convolution operations by caching previous\ncalculations, thereby reducing the complexity to O(L) time. Timing experiments\nshow significant advantages of our fast implementation over a naive one. While\nthis method is presented for Wavenet, the same scheme can be applied anytime\none wants to perform autoregressive generation or online prediction using a\nmodel with dilated convolution layers. The code for our method is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 04:16:44 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Paine", "Tom Le", ""], ["Khorrami", "Pooya", ""], ["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Ramachandran", "Prajit", ""], ["Hasegawa-Johnson", "Mark A.", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1611.09510", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Antonio Ortega, Gerard Medioni", "title": "Graph-Based Manifold Frequency Analysis for Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for manifold denoising based on processing in the\ngraph Fourier frequency domain, derived from the spectral decomposition of the\ndiscrete graph Laplacian. Our approach uses the Spectral Graph Wavelet\ntransform in order to per- form non-iterative denoising directly in the graph\nfrequency domain, an approach inspired by conventional wavelet-based signal\ndenoising methods. We theoretically justify our approach, based on the fact\nthat for smooth manifolds the coordinate information energy is localized in the\nlow spectral graph wavelet sub-bands, while the noise affects all frequency\nbands in a similar way. Experimental results show that our proposed manifold\nfrequency denoising (MFD) approach significantly outperforms the state of the\nart denoising meth- ods, and is robust to a wide range of parameter selections,\ne.g., the choice of k nearest neighbor connectivity of the graph.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 06:50:31 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Deutsch", "Shay", ""], ["Ortega", "Antonio", ""], ["Medioni", "Gerard", ""]]}, {"id": "1611.09621", "submitter": "Ankit Singh Rawat", "authors": "Arya Mazumdar and Ankit Singh Rawat", "title": "Associative Memory using Dictionary Learning and Expander Decoding", "comments": "To appear in AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An associative memory is a framework of content-addressable memory that\nstores a collection of message vectors (or a dataset) over a neural network\nwhile enabling a neurally feasible mechanism to recover any message in the\ndataset from its noisy version. Designing an associative memory requires\naddressing two main tasks: 1) learning phase: given a dataset, learn a concise\nrepresentation of the dataset in the form of a graphical model (or a neural\nnetwork), 2) recall phase: given a noisy version of a message vector from the\ndataset, output the correct message vector via a neurally feasible algorithm\nover the network learnt during the learning phase. This paper studies the\nproblem of designing a class of neural associative memories which learns a\nnetwork representation for a large dataset that ensures correction against a\nlarge number of adversarial errors during the recall phase. Specifically, the\nassociative memories designed in this paper can store dataset containing\n$\\exp(n)$ $n$-length message vectors over a network with $O(n)$ nodes and can\ntolerate $\\Omega(\\frac{n}{{\\rm polylog} n})$ adversarial errors. This paper\ncarries out this memory design by mapping the learning phase and recall phase\nto the tasks of dictionary learning with a square dictionary and iterative\nerror correction in an expander code, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 13:27:18 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Mazumdar", "Arya", ""], ["Rawat", "Ankit Singh", ""]]}, {"id": "1611.09630", "submitter": "Jakub Tomczak Ph.D.", "authors": "Jakub M. Tomczak and Max Welling", "title": "Improving Variational Auto-Encoders using Householder Flow", "comments": "A corrected version of the paper submitted to Bayesian Deep Learning\n  Workshop (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAE) are scalable and powerful generative models.\nHowever, the choice of the variational posterior determines tractability and\nflexibility of the VAE. Commonly, latent variables are modeled using the normal\ndistribution with a diagonal covariance matrix. This results in computational\nefficiency but typically it is not flexible enough to match the true posterior\ndistribution. One fashion of enriching the variational posterior distribution\nis application of normalizing flows, i.e., a series of invertible\ntransformations to latent variables with a simple posterior. In this paper, we\nfollow this line of thinking and propose a volume-preserving flow that uses a\nseries of Householder transformations. We show empirically on MNIST dataset and\nhistopathology data that the proposed flow allows to obtain more flexible\nvariational posterior and competitive results comparing to other normalizing\nflows.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 13:49:31 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 12:04:28 GMT"}, {"version": "v3", "created": "Sun, 22 Jan 2017 18:49:14 GMT"}, {"version": "v4", "created": "Fri, 27 Jan 2017 00:36:51 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1611.09726", "submitter": "Michael Blot", "authors": "Michael Blot, David Picard, Matthieu Cord, Nicolas Thome", "title": "Gossip training for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of speeding up the training of convolutional networks.\nHere we study a distributed method adapted to stochastic gradient descent\n(SGD). The parallel optimization setup uses several threads, each applying\nindividual gradient descents on a local variable. We propose a new way to share\ninformation between different threads inspired by gossip algorithms and showing\ngood consensus convergence properties. Our method called GoSGD has the\nadvantage to be fully asynchronous and decentralized. We compared our method to\nthe recent EASGD in \\cite{elastic} on CIFAR-10 show encouraging results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 17:01:31 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Blot", "Michael", ""], ["Picard", "David", ""], ["Cord", "Matthieu", ""], ["Thome", "Nicolas", ""]]}, {"id": "1611.09816", "submitter": "Michael Rabadi", "authors": "Michael Rabadi", "title": "Co-adaptive learning over a countable space", "comments": "6 pages, 1 figure, NIPS 2016 Time Series Workshop", "journal-ref": "In NIPS 2016 Time Series Workshop. Barcelona, Spain", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-adaptation is a special form of on-line learning where an algorithm\n$\\mathcal{A}$ must assist an unknown algorithm $\\mathcal{B}$ to perform some\ntask. This is a general framework and has applications in recommendation\nsystems, search, education, and much more. Today, the most common use of\nco-adaptive algorithms is in brain-computer interfacing (BCI), where algorithms\nhelp patients gain and maintain control over prosthetic devices. While previous\nstudies have shown strong empirical results Kowalski et al. (2013); Orsborn et\nal. (2014) or have been studied in specific examples Merel et al. (2013, 2015),\nthere is no general analysis of the co-adaptive learning problem. Here we will\nstudy the co-adaptive learning problem in the online, closed-loop setting. We\nwill prove that, with high probability, co-adaptive learning is guaranteed to\noutperform learning with a fixed decoder as long as a particular condition is\nmet.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:07:32 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 20:25:36 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Rabadi", "Michael", ""]]}, {"id": "1611.09819", "submitter": "Daniel Harari", "authors": "Daniel Harari, Tao Gao, Nancy Kanwisher, Joshua Tenenbaum, Shimon\n  Ullman", "title": "Measuring and modeling the perception of natural and unconstrained gaze\n  in humans and machines", "comments": "Daniel Harari and Tao Gao contributed equally to this work", "journal-ref": null, "doi": null, "report-no": "Center for Brains, Minds and Machines Memo No. 059", "categories": "q-bio.NC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are remarkably adept at interpreting the gaze direction of other\nindividuals in their surroundings. This skill is at the core of the ability to\nengage in joint visual attention, which is essential for establishing social\ninteractions. How accurate are humans in determining the gaze direction of\nothers in lifelike scenes, when they can move their heads and eyes freely, and\nwhat are the sources of information for the underlying perceptual processes?\nThese questions pose a challenge from both empirical and computational\nperspectives, due to the complexity of the visual input in real-life\nsituations. Here we measure empirically human accuracy in perceiving the gaze\ndirection of others in lifelike scenes, and study computationally the sources\nof information and representations underlying this cognitive capacity. We show\nthat humans perform better in face-to-face conditions compared with recorded\nconditions, and that this advantage is not due to the availability of input\ndynamics. We further show that humans are still performing well when only the\neyes-region is visible, rather than the whole face. We develop a computational\nmodel, which replicates the pattern of human performance, including the finding\nthat the eyes-region contains on its own, the required information for\nestimating both head orientation and direction of gaze. Consistent with\nneurophysiological findings on task-specific face regions in the brain, the\nlearned computational representations reproduce perceptual effects such as the\nWollaston illusion, when trained to estimate direction of gaze, but not when\ntrained to recognize objects or faces.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:11:09 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Harari", "Daniel", ""], ["Gao", "Tao", ""], ["Kanwisher", "Nancy", ""], ["Tenenbaum", "Joshua", ""], ["Ullman", "Shimon", ""]]}, {"id": "1611.09827", "submitter": "John Thickstun", "authors": "John Thickstun, Zaid Harchaoui, Sham Kakade", "title": "Learning Features of Music from Scratch", "comments": "14 pages; camera-ready version; updated experiments and related\n  works; additional MIR metrics (Appendix C)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new large-scale music dataset, MusicNet, to serve as\na source of supervision and evaluation of machine learning methods for music\nresearch. MusicNet consists of hundreds of freely-licensed classical music\nrecordings by 10 composers, written for 11 instruments, together with\ninstrument/note annotations resulting in over 1 million temporal labels on 34\nhours of chamber music performances under various studio and microphone\nconditions.\n  The paper defines a multi-label classification task to predict notes in\nmusical recordings, along with an evaluation protocol, and benchmarks several\nmachine learning architectures for this task: i) learning from spectrogram\nfeatures; ii) end-to-end learning with a neural net; iii) end-to-end learning\nwith a convolutional neural net. These experiments show that end-to-end models\ntrained for note prediction learn frequency selective filters as a low-level\nrepresentation of audio.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:26:00 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 01:13:41 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Thickstun", "John", ""], ["Harchaoui", "Zaid", ""], ["Kakade", "Sham", ""]]}, {"id": "1611.09878", "submitter": "Jian Tang", "authors": "Jian Tang, Meng Qu, and Qiaozhu Mei", "title": "Identity-sensitive Word Embedding through Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most existing word embedding approaches do not distinguish the same words in\ndifferent contexts, therefore ignoring their contextual meanings. As a result,\nthe learned embeddings of these words are usually a mixture of multiple\nmeanings. In this paper, we acknowledge multiple identities of the same word in\ndifferent contexts and learn the \\textbf{identity-sensitive} word embeddings.\nBased on an identity-labeled text corpora, a heterogeneous network of words and\nword identities is constructed to model different-levels of word\nco-occurrences. The heterogeneous network is further embedded into a\nlow-dimensional space through a principled network embedding approach, through\nwhich we are able to obtain the embeddings of words and the embeddings of word\nidentities. We study three different types of word identities including topics,\nsentiments and categories. Experimental results on real-world data sets show\nthat the identity-sensitive word embeddings learned by our approach indeed\ncapture different meanings of words and outperforms competitive methods on\ntasks including text classification and word similarity computation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:12:04 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Tang", "Jian", ""], ["Qu", "Meng", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.09894", "submitter": "Sai Praveen Bangaru", "authors": "Sai Praveen Bangaru, JS Suhas and Balaraman Ravindran", "title": "Exploration for Multi-task Reinforcement Learning with Deep Generative\n  Models", "comments": "9 pages, 5 figures; NIPS Deep Reinforcement Learning Workshop 2016,\n  Barcelona", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in multi-task reinforcement learning is critical in training\nagents to deduce the underlying MDP. Many of the existing exploration\nframeworks such as $E^3$, $R_{max}$, Thompson sampling assume a single\nstationary MDP and are not suitable for system identification in the multi-task\nsetting. We present a novel method to facilitate exploration in multi-task\nreinforcement learning using deep generative models. We supplement our method\nwith a low dimensional energy model to learn the underlying MDP distribution\nand provide a resilient and adaptive exploration signal to the agent. We\nevaluate our method on a new set of environments and provide intuitive\ninterpretation of our results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:32:25 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Bangaru", "Sai Praveen", ""], ["Suhas", "JS", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1611.09897", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Irene Kim, Wolfgang Polonik", "title": "Autism Spectrum Disorder Classification using Graph Kernels on\n  Multidimensional Time Series", "comments": "Under review as a conference paper to BHI '17", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to model time series data from resting state fMRI for\nautism spectrum disorder (ASD) severity classification. We propose to adopt\nkernel machines and employ graph kernels that define a kernel dot product\nbetween two graphs. This enables us to take advantage of spatio-temporal\ninformation to capture the dynamics of the brain network, as opposed to\naggregating them in the spatial or temporal dimension. In addition to the\nconventional similarity graphs, we explore the use of L1 graph using sparse\ncoding, and the persistent homology of time delay embeddings, in the proposed\npipeline for ASD classification. In our experiments on two datasets from the\nABIDE collection, we demonstrate a consistent and significant advantage in\nusing graph kernels over traditional linear or non linear kernels for a variety\nof time series features.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:39:23 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Kim", "Irene", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "1611.09904", "submitter": "Olof Mogren", "authors": "Olof Mogren", "title": "C-RNN-GAN: Continuous recurrent neural networks with adversarial\n  training", "comments": "Accepted to Constructive Machine Learning Workshop (CML) at NIPS 2016\n  in Barcelona, Spain, December 10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generative adversarial networks have been proposed as a way of efficiently\ntraining deep generative neural networks. We propose a generative adversarial\nmodel that works on continuous sequential data, and apply it by training it on\na collection of classical music. We conclude that it generates music that\nsounds better and better as the model is trained, report statistics on\ngenerated music, and let the reader judge the quality by downloading the\ngenerated songs.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:53:09 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Mogren", "Olof", ""]]}, {"id": "1611.09913", "submitter": "Jasmine Collins", "authors": "Jasmine Collins, Jascha Sohl-Dickstein and David Sussillo", "title": "Capacity and Trainability in Recurrent Neural Networks", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two potential bottlenecks on the expressiveness of recurrent neural networks\n(RNNs) are their ability to store information about the task in their\nparameters, and to store information about the input history in their units. We\nshow experimentally that all common RNN architectures achieve nearly the same\nper-task and per-unit capacity bounds with careful training, for a variety of\ntasks and stacking depths. They can store an amount of task information which\nis linear in the number of parameters, and is approximately 5 bits per\nparameter. They can additionally store approximately one real number from their\ninput history per hidden unit. We further find that for several tasks it is the\nper-task parameter capacity bound that determines performance. These results\nsuggest that many previous results comparing RNN architectures are driven\nprimarily by differences in training effectiveness, rather than differences in\ncapacity. Supporting this observation, we compare training difficulty for\nseveral architectures, and show that vanilla RNNs are far more difficult to\ntrain, yet have slightly higher capacity. Finally, we propose two novel RNN\narchitectures, one of which is easier to train than the LSTM or GRU for deeply\nstacked architectures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 22:13:20 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 22:21:44 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 17:39:34 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Collins", "Jasmine", ""], ["Sohl-Dickstein", "Jascha", ""], ["Sussillo", "David", ""]]}, {"id": "1611.09921", "submitter": "Jian Tang", "authors": "Jian Tang, Cheng Li, Ming Zhang, and Qiaozhu Mei", "title": "Less is More: Learning Prominent and Diverse Topics for Data\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical topic models efficiently facilitate the exploration of\nlarge-scale data sets. Many models have been developed and broadly used to\nsummarize the semantic structure in news, science, social media, and digital\nhumanities. However, a common and practical objective in data exploration tasks\nis not to enumerate all existing topics, but to quickly extract representative\nones that broadly cover the content of the corpus, i.e., a few topics that\nserve as a good summary of the data. Most existing topic models fit exactly the\nsame number of topics as a user specifies, which have imposed an unnecessary\nburden to the users who have limited prior knowledge. We instead propose new\nmodels that are able to learn fewer but more representative topics for the\npurpose of data summarization. We propose a reinforced random walk that allows\nprominent topics to absorb tokens from similar and smaller topics, thus\nenhances the diversity among the top topics extracted. With this reinforced\nrandom walk as a general process embedded in classical topic models, we obtain\n\\textit{diverse topic models} that are able to extract the most prominent and\ndiverse topics from data. The inference procedures of these diverse topic\nmodels remain as simple and efficient as the classical models. Experimental\nresults demonstrate that the diverse topic models not only discover topics that\nbetter summarize the data, but also require minimal prior knowledge of the\nusers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 22:24:30 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 02:45:34 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Tang", "Jian", ""], ["Li", "Cheng", ""], ["Zhang", "Ming", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1611.09940", "submitter": "Irwan Bello", "authors": "Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio", "title": "Neural Combinatorial Optimization with Reinforcement Learning", "comments": "Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework to tackle combinatorial optimization problems\nusing neural networks and reinforcement learning. We focus on the traveling\nsalesman problem (TSP) and train a recurrent network that, given a set of city\ncoordinates, predicts a distribution over different city permutations. Using\nnegative tour length as the reward signal, we optimize the parameters of the\nrecurrent network using a policy gradient method. We compare learning the\nnetwork parameters on a set of training graphs against learning them on\nindividual test graphs. Despite the computational expense, without much\nengineering and heuristic designing, Neural Combinatorial Optimization achieves\nclose to optimal results on 2D Euclidean graphs with up to 100 nodes. Applied\nto the KnapSack, another NP-hard problem, the same method obtains optimal\nsolutions for instances with up to 200 items.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 23:22:39 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2016 00:31:39 GMT"}, {"version": "v3", "created": "Thu, 12 Jan 2017 23:55:36 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Bello", "Irwan", ""], ["Pham", "Hieu", ""], ["Le", "Quoc V.", ""], ["Norouzi", "Mohammad", ""], ["Bengio", "Samy", ""]]}, {"id": "1611.09957", "submitter": "Ehsan Amid", "authors": "Ehsan Amid, Nikos Vlassis, Manfred K. Warmuth", "title": "Low-dimensional Data Embedding via Robust Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new method called t-ETE for finding a low-dimensional embedding\nof a set of objects in Euclidean space. We formulate the embedding problem as a\njoint ranking problem over a set of triplets, where each triplet captures the\nrelative similarities between three objects in the set. By exploiting recent\nadvances in robust ranking, t-ETE produces high-quality embeddings even in the\npresence of a significant amount of noise and better preserves local scale than\nknown methods, such as t-STE and t-SNE. In particular, our method produces\nsignificantly better results than t-SNE on signature datasets while also being\nfaster to compute.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 01:03:11 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 21:21:03 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Amid", "Ehsan", ""], ["Vlassis", "Nikos", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1611.09958", "submitter": "Young-Jun Yu", "authors": "Young-jun Yu", "title": "Machine Learning for Dental Image Analysis", "comments": "This study was reviewed and approved by the institutional review\n  board of the Pusan National University Dental Hospital (PNUPH-2015-034)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to study the application of artificial intelligence (AI) to dental\nimaging, we applied AI technology to classify a set of panoramic radiographs\nusing (a) a convolutional neural network (CNN) which is a form of an artificial\nneural network (ANN), (b) representative image cognition algorithms that\nimplement scale-invariant feature transform (SIFT), and (c) histogram of\noriented gradients (HOG).\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 01:17:34 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 11:27:37 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Yu", "Young-jun", ""]]}, {"id": "1611.10017", "submitter": "Gou Koutaki", "authors": "Gou Koutaki, Keiichiro Shirai, Mitsuru Ambai", "title": "Fast Supervised Discrete Hashing and its Analysis", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a learning-based supervised discrete hashing\nmethod. Binary hashing is widely used for large-scale image retrieval as well\nas video and document searches because the compact representation of binary\ncode is essential for data storage and reasonable for query searches using\nbit-operations. The recently proposed Supervised Discrete Hashing (SDH)\nefficiently solves mixed-integer programming problems by alternating\noptimization and the Discrete Cyclic Coordinate descent (DCC) method. We show\nthat the SDH model can be simplified without performance degradation based on\nsome preliminary experiments; we call the approximate model for this the \"Fast\nSDH\" (FSDH) model. We analyze the FSDH model and provide a mathematically exact\nsolution for it. In contrast to SDH, our model does not require an alternating\noptimization algorithm and does not depend on initial values. FSDH is also\neasier to implement than Iterative Quantization (ITQ). Experimental results\ninvolving a large-scale database showed that FSDH outperforms conventional SDH\nin terms of precision, recall, and computation time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 06:35:39 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Koutaki", "Gou", ""], ["Shirai", "Keiichiro", ""], ["Ambai", "Mitsuru", ""]]}, {"id": "1611.10031", "submitter": "Peng Liu", "authors": "Peng Liu, Hui Zhang, and Kie B. Eom", "title": "Active Deep Learning for Classification of Hyperspectral Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active deep learning classification of hyperspectral images is considered in\nthis paper. Deep learning has achieved success in many applications, but\ngood-quality labeled samples are needed to construct a deep learning network.\nIt is expensive getting good labeled samples in hyperspectral images for remote\nsensing applications. An active learning algorithm based on a weighted\nincremental dictionary learning is proposed for such applications. The proposed\nalgorithm selects training samples that maximize two selection criteria, namely\nrepresentative and uncertainty. This algorithm trains a deep network\nefficiently by actively selecting training samples at each iteration. The\nproposed algorithm is applied for the classification of hyperspectral images,\nand compared with other classification algorithms employing active learning. It\nis shown that the proposed algorithm is efficient and effective in classifying\nhyperspectral images.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 07:34:46 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Liu", "Peng", ""], ["Zhang", "Hui", ""], ["Eom", "Kie B.", ""]]}, {"id": "1611.10041", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (PARIETAL), Julien Mairal (LEAR), Ga\\\"el Varoquaux\n  (PARIETAL), Bertrand Thirion (PARIETAL)", "title": "Subsampled online matrix factorization with convergence guarantees", "comments": null, "journal-ref": "9th NIPS Workshop on Optimization for Machine Learning, Dec 2016,\n  Barcelone, Spain", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a matrix factorization algorithm that scales to input matrices\nthat are large in both dimensions (i.e., that contains morethan 1TB of data).\nThe algorithm streams the matrix columns while subsampling them, resulting in\nlow complexity per iteration andreasonable memory footprint. In contrast to\nprevious online matrix factorization methods, our approach relies on\nlow-dimensional statistics from past iterates to control the extra variance\nintroduced by subsampling. We present a convergence analysis that guarantees us\nto reach a stationary point of the problem. Large speed-ups can be obtained\ncompared to previous online algorithms that do not perform subsampling, thanks\nto the feature redundancy that often exists in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 08:10:58 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Mensch", "Arthur", "", "PARIETAL"], ["Mairal", "Julien", "", "LEAR"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"], ["Thirion", "Bertrand", "", "PARIETAL"]]}, {"id": "1611.10052", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Sindhu Padakandla, Chandrashekar L, Priyank Parihar, K\n  Gopinath, Shalabh Bhatnagar", "title": "Performance Tuning of Hadoop MapReduce: A Noisy Gradient Approach", "comments": null, "journal-ref": null, "doi": "10.1109/CLOUD.2017.55", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop MapReduce is a framework for distributed storage and processing of\nlarge datasets that is quite popular in big data analytics. It has various\nconfiguration parameters (knobs) which play an important role in deciding the\nperformance i.e., the execution time of a given big data processing job.\nDefault values of these parameters do not always result in good performance and\nhence it is important to tune them. However, there is inherent difficulty in\ntuning the parameters due to two important reasons - firstly, the parameter\nsearch space is large and secondly, there are cross-parameter interactions.\nHence, there is a need for a dimensionality-free method which can automatically\ntune the configuration parameters by taking into account the cross-parameter\ndependencies. In this paper, we propose a novel Hadoop parameter tuning\nmethodology, based on a noisy gradient algorithm known as the simultaneous\nperturbation stochastic approximation (SPSA). The SPSA algorithm tunes the\nparameters by directly observing the performance of the Hadoop MapReduce\nsystem. The approach followed is independent of parameter dimensions and\nrequires only $2$ observations per iteration while tuning. We demonstrate the\neffectiveness of our methodology in achieving good performance on popular\nHadoop benchmarks namely \\emph{Grep}, \\emph{Bigram}, \\emph{Inverted Index},\n\\emph{Word Co-occurrence} and \\emph{Terasort}. Our method, when tested on a 25\nnode Hadoop cluster shows 66\\% decrease in execution time of Hadoop jobs on an\naverage, when compared to the default configuration. Further, we also observe a\nreduction of 45\\% in execution times, when compared to prior methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 08:52:11 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 09:45:04 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kumar", "Sandeep", ""], ["Padakandla", "Sindhu", ""], ["L", "Chandrashekar", ""], ["Parihar", "Priyank", ""], ["Gopinath", "K", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1611.10176", "submitter": "Shuchang Zhou", "authors": "Qinyao He, He Wen, Shuchang Zhou, Yuxin Wu, Cong Yao, Xinyu Zhou,\n  Yuheng Zou", "title": "Effective Quantization Methods for Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing bit-widths of weights, activations, and gradients of a Neural\nNetwork can shrink its storage size and memory usage, and also allow for faster\ntraining and inference by exploiting bitwise operations. However, previous\nattempts for quantization of RNNs show considerable performance degradation\nwhen using low bit-width weights and activations. In this paper, we propose\nmethods to quantize the structure of gates and interlinks in LSTM and GRU\ncells. In addition, we propose balanced quantization methods for weights to\nfurther reduce performance degradation. Experiments on PTB and IMDB datasets\nconfirm effectiveness of our methods as performances of our models match or\nsurpass the previous state-of-the-art of quantized RNN.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 14:33:08 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["He", "Qinyao", ""], ["Wen", "He", ""], ["Zhou", "Shuchang", ""], ["Wu", "Yuxin", ""], ["Yao", "Cong", ""], ["Zhou", "Xinyu", ""], ["Zou", "Yuheng", ""]]}, {"id": "1611.10215", "submitter": "Gal Dalal", "authors": "Gal Dalal, Elad Gilboa, Shie Mannor, Louis Wehenkel", "title": "Unit Commitment using Nearest Neighbor as a Short-Term Proxy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as\na proxy for quickly approximating outcomes of short-term decisions, to make\ntractable hierarchical long-term assessment and planning for large power\nsystems. Experimental results on updated versions of IEEE-RTS79 and IEEE-RTS96\nshow high accuracy measured on operational cost, achieved in runtimes that are\nlower in several orders of magnitude than the traditional approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 15:24:55 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 19:29:49 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 11:28:55 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Dalal", "Gal", ""], ["Gilboa", "Elad", ""], ["Mannor", "Shie", ""], ["Wehenkel", "Louis", ""]]}, {"id": "1611.10228", "submitter": "Gali Noti", "authors": "Gali Noti, Effi Levi, Yoav Kolumbus and Amit Daniely", "title": "Behavior-Based Machine-Learning: A Hybrid Approach for Predicting Human\n  Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of work in behavioral fields attempts to develop models that\ndescribe the way people, as opposed to rational agents, make decisions. A\nrecent Choice Prediction Competition (2015) challenged researchers to suggest a\nmodel that captures 14 classic choice biases and can predict human decisions\nunder risk and ambiguity. The competition focused on simple decision problems,\nin which human subjects were asked to repeatedly choose between two gamble\noptions.\n  In this paper we present our approach for predicting human decision behavior:\nwe suggest to use machine learning algorithms with features that are based on\nwell-established behavioral theories. The basic idea is that these\npsychological features are essential for the representation of the data and are\nimportant for the success of the learning process. We implement a vanilla model\nin which we train SVM models using behavioral features that rely on the\npsychological properties underlying the competition baseline model. We show\nthat this basic model captures the 14 choice biases and outperforms all the\nother learning-based models in the competition. The preliminary results suggest\nthat such hybrid models can significantly improve the prediction of human\ndecision making, and are a promising direction for future research.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 15:44:57 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Noti", "Gali", ""], ["Levi", "Effi", ""], ["Kolumbus", "Yoav", ""], ["Daniely", "Amit", ""]]}, {"id": "1611.10252", "submitter": "Jingkang Yang", "authors": "Jingkang Yang, Haohan Wang, Jun Zhu, Eric P. Xing", "title": "SeDMiD for Confusion Detection: Uncovering Mind State from Time Series\n  Brain Wave Data", "comments": "11 pages, 2 figures, NIPS 2016 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how brain functions has been an intriguing topic for years.\nWith the recent progress on collecting massive data and developing advanced\ntechnology, people have become interested in addressing the challenge of\ndecoding brain wave data into meaningful mind states, with many machine\nlearning models and algorithms being revisited and developed, especially the\nones that handle time series data because of the nature of brain waves.\nHowever, many of these time series models, like HMM with hidden state in\ndiscrete space or State Space Model with hidden state in continuous space, only\nwork with one source of data and cannot handle different sources of information\nsimultaneously. In this paper, we propose an extension of State Space Model to\nwork with different sources of information together with its learning and\ninference algorithms. We apply this model to decode the mind state of students\nduring lectures based on their brain waves and reach a significant better\nresults compared to traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 18:11:00 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Yang", "Jingkang", ""], ["Wang", "Haohan", ""], ["Zhu", "Jun", ""], ["Xing", "Eric P.", ""]]}, {"id": "1611.10258", "submitter": "Varun Kanade", "authors": "Surbhi Goel, Varun Kanade, Adam Klivans, Justin Thaler", "title": "Reliably Learning the ReLU in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first dimension-efficient algorithms for learning Rectified\nLinear Units (ReLUs), which are functions of the form $\\mathbf{x} \\mapsto\n\\max(0, \\mathbf{w} \\cdot \\mathbf{x})$ with $\\mathbf{w} \\in \\mathbb{S}^{n-1}$.\nOur algorithm works in the challenging Reliable Agnostic learning model of\nKalai, Kanade, and Mansour (2009) where the learner is given access to a\ndistribution $\\cal{D}$ on labeled examples but the labeling may be arbitrary.\nWe construct a hypothesis that simultaneously minimizes the false-positive rate\nand the loss on inputs given positive labels by $\\cal{D}$, for any convex,\nbounded, and Lipschitz loss function.\n  The algorithm runs in polynomial-time (in $n$) with respect to any\ndistribution on $\\mathbb{S}^{n-1}$ (the unit sphere in $n$ dimensions) and for\nany error parameter $\\epsilon = \\Omega(1/\\log n)$ (this yields a PTAS for a\nquestion raised by F. Bach on the complexity of maximizing ReLUs). These\nresults are in contrast to known efficient algorithms for reliably learning\nlinear threshold functions, where $\\epsilon$ must be $\\Omega(1)$ and strong\nassumptions are required on the marginal distribution. We can compose our\nresults to obtain the first set of efficient algorithms for learning\nconstant-depth networks of ReLUs.\n  Our techniques combine kernel methods and polynomial approximations with a\n\"dual-loss\" approach to convex programming. As a byproduct we obtain a number\nof applications including the first set of efficient algorithms for \"convex\npiecewise-linear fitting\" and the first efficient algorithms for noisy\npolynomial reconstruction of low-weight polynomials on the unit sphere.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 16:42:23 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Goel", "Surbhi", ""], ["Kanade", "Varun", ""], ["Klivans", "Adam", ""], ["Thaler", "Justin", ""]]}, {"id": "1611.10283", "submitter": "L.A. Prashanth", "authors": "Aditya Gopalan, L.A. Prashanth, Michael Fu and Steve Marcus", "title": "Weighted bandits or: How bandits learn distorted values that are not\n  expected", "comments": "Longer version of the paper to be published as part of the\n  proceedings of AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by models of human decision making proposed to explain commonly\nobserved deviations from conventional expected value preferences, we formulate\ntwo stochastic multi-armed bandit problems with distorted probabilities on the\ncost distributions: the classic $K$-armed bandit and the linearly parameterized\nbandit. In both settings, we propose algorithms that are inspired by Upper\nConfidence Bound (UCB), incorporate cost distortions, and exhibit sublinear\nregret assuming \\holder continuous weight distortion functions. For the\n$K$-armed setting, we show that the algorithm, called W-UCB, achieves\nproblem-dependent regret $O(L^2 M^2 \\log n/ \\Delta^{\\frac{2}{\\alpha}-1})$,\nwhere $n$ is the number of plays, $\\Delta$ is the gap in distorted expected\nvalue between the best and next best arm, $L$ and $\\alpha$ are the H\\\"{o}lder\nconstants for the distortion function, and $M$ is an upper bound on costs, and\na problem-independent regret bound of\n$O((KL^2M^2)^{\\alpha/2}n^{(2-\\alpha)/2})$. We also present a matching lower\nbound on the regret, showing that the regret of W-UCB is essentially\nunimprovable over the class of H\\\"{o}lder-continuous weight distortions. For\nthe linearly parameterized setting, we develop a new algorithm, a variant of\nthe Optimism in the Face of Uncertainty Linear bandit (OFUL) algorithm called\nWOFUL (Weight-distorted OFUL), and show that it has regret $O(d\\sqrt{n} \\;\n\\mbox{polylog}(n))$ with high probability, for sub-Gaussian cost distributions.\nFinally, numerical examples demonstrate the advantages resulting from using\ndistortion-aware learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 17:37:51 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Gopalan", "Aditya", ""], ["Prashanth", "L. A.", ""], ["Fu", "Michael", ""], ["Marcus", "Steve", ""]]}, {"id": "1611.10305", "submitter": "Qunwei Li", "authors": "Qunwei Li, Bhavya Kailkhura, Jayaraman J. Thiagarajan, Zhenliang\n  Zhang, Pramod K. Varshney", "title": "Influential Node Detection in Implicit Social Networks using Multi-task\n  Gaussian Copula Models", "comments": "NIPS 2016 Workshop, JMLR: Workshop and Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influential node detection is a central research topic in social network\nanalysis. Many existing methods rely on the assumption that the network\nstructure is completely known \\textit{a priori}. However, in many applications,\nnetwork structure is unavailable to explain the underlying information\ndiffusion phenomenon. To address the challenge of information diffusion\nanalysis with incomplete knowledge of network structure, we develop a\nmulti-task low rank linear influence model. By exploiting the relationships\nbetween contagions, our approach can simultaneously predict the volume (i.e.\ntime series prediction) for each contagion (or topic) and automatically\nidentify the most influential nodes for each contagion. The proposed model is\nvalidated using synthetic data and an ISIS twitter dataset. In addition to\nimproving the volume prediction performance significantly, we show that the\nproposed approach can reliably infer the most influential users for specific\ncontagions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 18:46:55 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Li", "Qunwei", ""], ["Kailkhura", "Bhavya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Zhang", "Zhenliang", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1611.10328", "submitter": "Maciej Wielgosz", "authors": "Maciej Wielgosz", "title": "The observer-assisted method for adjusting hyper-parameters in deep\n  learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a concept of a novel method for adjusting\nhyper-parameters in Deep Learning (DL) algorithms. An external agent-observer\nmonitors a performance of a selected Deep Learning algorithm. The observer\nlearns to model the DL algorithm using a series of random experiments.\nConsequently, it may be used for predicting a response of the DL algorithm in\nterms of a selected quality measurement to a set of hyper-parameters. This\nallows to construct an ensemble composed of a series of evaluators which\nconstitute an observer-assisted architecture. The architecture may be used to\ngradually iterate towards to the best achievable quality score in tiny steps\ngoverned by a unit of progress. The algorithm is stopped when the maximum\nnumber of steps is reached or no further progress is made.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 19:37:48 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Wielgosz", "Maciej", ""]]}, {"id": "1611.10338", "submitter": "Reyhane Askari Hemmat", "authors": "Reyhane Askari Hemmat, Abdelhakim Hafid", "title": "SLA Violation Prediction In Cloud Computing: A Machine Learning\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service level agreement (SLA) is an essential part of cloud systems to ensure\nmaximum availability of services for customers. With a violation of SLA, the\nprovider has to pay penalties. In this paper, we explore two machine learning\nmodels: Naive Bayes and Random Forest Classifiers to predict SLA violations.\nSince SLA violations are a rare event in the real world (~0.2 %), the\nclassification task becomes more challenging. In order to overcome these\nchallenges, we use several re-sampling methods. We find that random forests\nwith SMOTE-ENN re-sampling have the best performance among other methods with\nthe accuracy of 99.88 % and F_1 score of 0.9980.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 20:07:34 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Hemmat", "Reyhane Askari", ""], ["Hafid", "Abdelhakim", ""]]}, {"id": "1611.10351", "submitter": "Joris Mooij", "authors": "Joris M. Mooij, Sara Magliacane, Tom Claassen", "title": "Joint Causal Inference from Multiple Contexts", "comments": "Final version, as published by JMLR", "journal-ref": "Journal of Machine Learning Research 21(99):1-108, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gold standard for discovering causal relations is by means of\nexperimentation. Over the last decades, alternative methods have been proposed\nthat can infer causal relations between variables from certain statistical\npatterns in purely observational data. We introduce Joint Causal Inference\n(JCI), a novel approach to causal discovery from multiple data sets from\ndifferent contexts that elegantly unifies both approaches. JCI is a causal\nmodeling framework rather than a specific algorithm, and it can be implemented\nusing any causal discovery algorithm that can take into account certain\nbackground knowledge. JCI can deal with different types of interventions (e.g.,\nperfect, imperfect, stochastic, etc.) in a unified fashion, and does not\nrequire knowledge of intervention targets or types in case of interventional\ndata. We explain how several well-known causal discovery algorithms can be seen\nas addressing special cases of the JCI framework, and we also propose novel\nimplementations that extend existing causal discovery methods for purely\nobservational data to the JCI setting. We evaluate different JCI\nimplementations on synthetic data and on flow cytometry protein expression data\nand conclude that JCI implementations can considerably outperform\nstate-of-the-art causal discovery algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 20:50:33 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 12:43:04 GMT"}, {"version": "v3", "created": "Thu, 29 Mar 2018 21:18:18 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 12:42:55 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2020 12:14:39 GMT"}, {"version": "v6", "created": "Thu, 20 Aug 2020 08:23:07 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mooij", "Joris M.", ""], ["Magliacane", "Sara", ""], ["Claassen", "Tom", ""]]}]