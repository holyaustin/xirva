[{"id": "1107.0434", "submitter": "Adrian Silvescu", "authors": "Adrian Silvescu and Vasant Honavar", "title": "Abstraction Super-structuring Normal Forms: Towards a Theory of\n  Structural Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Induction is the process by which we obtain predictive laws or theories or\nmodels of the world. We consider the structural aspect of induction. We answer\nthe question as to whether we can find a finite and minmalistic set of\noperations on structural elements in terms of which any theory can be\nexpressed. We identify abstraction (grouping similar entities) and\nsuper-structuring (combining topologically e.g., spatio-temporally close\nentities) as the essential structural operations in the induction process. We\nshow that only two more structural operations, namely, reverse abstraction and\nreverse super-structuring (the duals of abstraction and super-structuring\nrespectively) suffice in order to exploit the full power of Turing-equivalent\ngenerative grammars in induction. We explore the implications of this theorem\nwith respect to the nature of hidden variables, radical positivism and the\n2-century old claim of David Hume about the principles of connexion among\nideas.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2011 07:33:51 GMT"}], "update_date": "2011-07-05", "authors_parsed": [["Silvescu", "Adrian", ""], ["Honavar", "Vasant", ""]]}, {"id": "1107.0674", "submitter": "Natalia Janson", "authors": "Natalia B. Janson and Christopher J. Marsden", "title": "\"Memory foam\" approach to unsupervised learning", "comments": "4 pages, 4 figures, and 2 wave files", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternative approach to construct an artificial learning\nsystem, which naturally learns in an unsupervised manner. Its mathematical\nprototype is a dynamical system, which automatically shapes its vector field in\nresponse to the input signal. The vector field converges to a gradient of a\nmulti-dimensional probability density distribution of the input process, taken\nwith negative sign. The most probable patterns are represented by the stable\nfixed points, whose basins of attraction are formed automatically. The\nperformance of this system is illustrated with musical signals.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 16:18:04 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2011 13:09:28 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2015 13:57:56 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Janson", "Natalia B.", ""], ["Marsden", "Christopher J.", ""]]}, {"id": "1107.0789", "submitter": "Lester Mackey", "authors": "Lester Mackey, Ameet Talwalkar, Michael I. Jordan", "title": "Distributed Matrix Completion and Robust Factorization", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If learning methods are to scale to the massive sizes of modern datasets, it\nis essential for the field of machine learning to embrace parallel and\ndistributed computing. Inspired by the recent development of matrix\nfactorization methods with rich theory but poor computational complexity and by\nthe relative ease of mapping matrices onto distributed architectures, we\nintroduce a scalable divide-and-conquer framework for noisy matrix\nfactorization. We present a thorough theoretical analysis of this framework in\nwhich we characterize the statistical errors introduced by the \"divide\" step\nand control their magnitude in the \"conquer\" step, so that the overall\nalgorithm enjoys high-probability estimation guarantees comparable to those of\nits base algorithm. We also present experiments in collaborative filtering and\nvideo background modeling that demonstrate the near-linear to superlinear\nspeed-ups attainable with this approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 06:03:44 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2011 00:59:30 GMT"}, {"version": "v3", "created": "Wed, 21 Sep 2011 01:38:14 GMT"}, {"version": "v4", "created": "Tue, 1 Nov 2011 05:37:48 GMT"}, {"version": "v5", "created": "Fri, 18 May 2012 09:28:27 GMT"}, {"version": "v6", "created": "Tue, 14 Aug 2012 17:33:30 GMT"}, {"version": "v7", "created": "Mon, 28 Oct 2013 06:02:12 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Mackey", "Lester", ""], ["Talwalkar", "Ameet", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1107.0922", "submitter": "Danny Bickson", "authors": "Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos\n  Guestrin", "title": "GraphLab: A Distributed Framework for Machine Learning in the Cloud", "comments": "CMU Tech Report, GraphLab project webpage: http://graphlab.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques are indispensable in a wide range of fields.\nUnfortunately, the exponential increase of dataset sizes are rapidly extending\nthe runtime of sequential algorithms and threatening to slow future progress in\nML. With the promise of affordable large-scale parallel computing, Cloud\nsystems offer a viable platform to resolve the computational challenges in ML.\nHowever, designing and implementing efficient, provably correct distributed ML\nalgorithms is often prohibitively challenging. To enable ML researchers to\neasily and efficiently use parallel systems, we introduced the GraphLab\nabstraction which is designed to represent the computational patterns in ML\nalgorithms while permitting efficient parallel and distributed implementations.\nIn this paper we provide a formal description of the GraphLab parallel\nabstraction and present an efficient distributed implementation. We conduct a\ncomprehensive evaluation of GraphLab on three state-of-the-art ML algorithms\nusing real large-scale data and a 64 node EC2 cluster of 512 processors. We\nfind that GraphLab achieves orders of magnitude performance gains over Hadoop\nwhile performing comparably or superior to hand-tuned MPI implementations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 16:56:53 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Low", "Yucheng", ""], ["Gonzalez", "Joseph", ""], ["Kyrola", "Aapo", ""], ["Bickson", "Danny", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1107.1270", "submitter": "Animashree Anandkumar", "authors": "Animashree Anandkumar, Vincent Y. F. Tan and Alan. S. Willsky", "title": "High-Dimensional Gaussian Graphical Model Selection: Walk Summability\n  and Local Separation Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of high-dimensional Gaussian graphical model\nselection. We identify a set of graphs for which an efficient estimation\nalgorithm exists, and this algorithm is based on thresholding of empirical\nconditional covariances. Under a set of transparent conditions, we establish\nstructural consistency (or sparsistency) for the proposed algorithm, when the\nnumber of samples n=omega(J_{min}^{-2} log p), where p is the number of\nvariables and J_{min} is the minimum (absolute) edge potential of the graphical\nmodel. The sufficient conditions for sparsistency are based on the notion of\nwalk-summability of the model and the presence of sparse local vertex\nseparators in the underlying graph. We also derive novel non-asymptotic\nnecessary conditions on the number of samples required for sparsistency.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2011 22:21:57 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2011 02:43:43 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2012 04:42:39 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Tan", "Vincent Y. F.", ""], ["Willsky", "Alan. S.", ""]]}, {"id": "1107.1283", "submitter": "Daniel Hsu", "authors": "Animashree Anandkumar, Kamalika Chaudhuri, Daniel Hsu, Sham M. Kakade,\n  Le Song, Tong Zhang", "title": "Spectral Methods for Learning Multivariate Latent Tree Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the problem of learning the structure of multivariate\nlinear tree models, which include a variety of directed tree graphical models\nwith continuous, discrete, and mixed latent variables such as linear-Gaussian\nmodels, hidden Markov models, Gaussian mixture models, and Markov evolutionary\ntrees. The setting is one where we only have samples from certain observed\nvariables in the tree, and our goal is to estimate the tree structure (i.e.,\nthe graph of how the underlying hidden variables are connected to each other\nand to the observed variables). We propose the Spectral Recursive Grouping\nalgorithm, an efficient and simple bottom-up procedure for recovering the tree\nstructure from independent samples of the observed variables. Our finite sample\nsize bounds for exact recovery of the tree structure reveal certain natural\ndependencies on underlying statistical and structural properties of the\nunderlying joint distribution. Furthermore, our sample complexity guarantees\nhave no explicit dependence on the dimensionality of the observed variables,\nmaking the algorithm applicable to many high-dimensional settings. At the heart\nof our algorithm is a spectral quartet test for determining the relative\ntopology of a quartet of variables from second-order statistics.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 02:33:31 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 15:42:32 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Chaudhuri", "Kamalika", ""], ["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Song", "Le", ""], ["Zhang", "Tong", ""]]}, {"id": "1107.1322", "submitter": "Gabriel Dulac-Arnold", "authors": "Gabriel Dulac-Arnold, Ludovic Denoyer, Patrick Gallinari", "title": "Text Classification: A Sequential Reading Approach", "comments": "ECIR2011", "journal-ref": "Lecture Notes in Computer Science, 2011, Volume 6611/2011, 411-423", "doi": "10.1007/978-3-642-20161-5_41", "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to model the text classification process as a sequential decision\nprocess. In this process, an agent learns to classify documents into topics\nwhile reading the document sentences sequentially and learns to stop as soon as\nenough information was read for deciding. The proposed algorithm is based on a\nmodelisation of Text Classification as a Markov Decision Process and learns by\nusing Reinforcement Learning. Experiments on four different classical\nmono-label corpora show that the proposed approach performs comparably to\nclassical SVM approaches for large training sets, and better for small training\nsets. In addition, the model automatically adapts its reading process to the\nquantity of training information provided.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 09:09:19 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 07:39:52 GMT"}, {"version": "v3", "created": "Mon, 29 Aug 2011 17:45:53 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dulac-Arnold", "Gabriel", ""], ["Denoyer", "Ludovic", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1107.1358", "submitter": "Omri Weinstein", "authors": "Zohar Karnin, Edo Liberty, Shachar Lovett, Roy Schwartz, Omri\n  Weinstein", "title": "On the Furthest Hyperplane Problem and Maximal Margin Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Furthest Hyperplane Problem (FHP), which is an\nunsupervised counterpart of Support Vector Machines. Given a set of n points in\nRd, the objective is to produce the hyperplane (passing through the origin)\nwhich maximizes the separation margin, that is, the minimal distance between\nthe hyperplane and any input point. To the best of our knowledge, this is the\nfirst paper achieving provable results regarding FHP. We provide both lower and\nupper bounds to this NP-hard problem. First, we give a simple randomized\nalgorithm whose running time is n^O(1/{\\theta}^2) where {\\theta} is the optimal\nseparation margin. We show that its exponential dependency on 1/{\\theta}^2 is\ntight, up to sub-polynomial factors, assuming SAT cannot be solved in\nsub-exponential time. Next, we give an efficient approxima- tion algorithm. For\nany {\\alpha} \\in [0, 1], the algorithm produces a hyperplane whose distance\nfrom at least 1 - 5{\\alpha} fraction of the points is at least {\\alpha} times\nthe optimal separation margin. Finally, we show that FHP does not admit a PTAS\nby presenting a gap preserving reduction from a particular version of the PCP\ntheorem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 11:58:52 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2012 21:40:04 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Karnin", "Zohar", ""], ["Liberty", "Edo", ""], ["Lovett", "Shachar", ""], ["Schwartz", "Roy", ""], ["Weinstein", "Omri", ""]]}, {"id": "1107.1564", "submitter": "Naresh Manwani", "authors": "Naresh Manwani and P. S. Sastry", "title": "Polyceptron: A Polyhedral Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new algorithm for learning polyhedral classifiers\nwhich we call as Polyceptron. It is a Perception like algorithm which updates\nthe parameters only when the current classifier misclassifies any training\ndata. We give both batch and online version of Polyceptron algorithm. Finally\nwe give experimental results to show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 06:26:03 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2013 08:34:52 GMT"}, {"version": "v3", "created": "Wed, 12 Mar 2014 07:08:13 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Manwani", "Naresh", ""], ["Sastry", "P. S.", ""]]}, {"id": "1107.1736", "submitter": "Animashree Anandkumar", "authors": "Animashree Anandkumar, Vincent Y. F. Tan, Furong Huang, Alan S.\n  Willsky", "title": "High-dimensional structure estimation in Ising models: Local separation\n  criterion", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1009 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1346-1375", "doi": "10.1214/12-AOS1009", "report-no": "IMS-AOS-AOS1009", "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of high-dimensional Ising (graphical) model\nselection. We propose a simple algorithm for structure estimation based on the\nthresholding of the empirical conditional variation distances. We introduce a\nnovel criterion for tractable graph families, where this method is efficient,\nbased on the presence of sparse local separators between node pairs in the\nunderlying graph. For such graphs, the proposed algorithm has a sample\ncomplexity of $n=\\Omega(J_{\\min}^{-2}\\log p)$, where $p$ is the number of\nvariables, and $J_{\\min}$ is the minimum (absolute) edge potential in the\nmodel. We also establish nonasymptotic necessary and sufficient conditions for\nstructure estimation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 21:35:48 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2011 02:17:50 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2012 04:37:52 GMT"}, {"version": "v4", "created": "Mon, 20 Aug 2012 05:38:19 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Anandkumar", "Animashree", ""], ["Tan", "Vincent Y. F.", ""], ["Huang", "Furong", ""], ["Willsky", "Alan S.", ""]]}, {"id": "1107.1744", "submitter": "Alekh Agarwal", "authors": "Alekh Agarwal, Dean P. Foster, Daniel Hsu, Sham M. Kakade, Alexander\n  Rakhlin", "title": "Stochastic convex optimization with bandit feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of minimizing a convex, Lipschitz function\n$f$ over a convex, compact set $\\xset$ under a stochastic bandit feedback\nmodel. In this model, the algorithm is allowed to observe noisy realizations of\nthe function value $f(x)$ at any query point $x \\in \\xset$. The quantity of\ninterest is the regret of the algorithm, which is the sum of the function\nvalues at algorithm's query points minus the optimal function value. We\ndemonstrate a generalization of the ellipsoid algorithm that incurs\n$\\otil(\\poly(d)\\sqrt{T})$ regret. Since any algorithm has regret at least\n$\\Omega(\\sqrt{T})$ on this problem, our algorithm is optimal in terms of the\nscaling with $T$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 22:18:05 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2011 06:06:43 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Agarwal", "Alekh", ""], ["Foster", "Dean P.", ""], ["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1107.2021", "submitter": "Sivan Sabato", "authors": "Sivan Sabato and Naftali Tishby", "title": "Multi-Instance Learning with Any Hypothesis Class", "comments": "Fixed typos and added some explanations", "journal-ref": "Journal of Machine Learning Research 13(Oct):1999-3039, 2012", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the supervised learning setting termed Multiple-Instance Learning (MIL),\nthe examples are bags of instances, and the bag label is a function of the\nlabels of its instances. Typically, this function is the Boolean OR. The\nlearner observes a sample of bags and the bag labels, but not the instance\nlabels that determine the bag labels. The learner is then required to emit a\nclassification rule for bags based on the sample. MIL has numerous\napplications, and many heuristic algorithms have been used successfully on this\nproblem, each adapted to specific settings or applications. In this work we\nprovide a unified theoretical analysis for MIL, which holds for any underlying\nhypothesis class, regardless of a specific application or problem domain. We\nshow that the sample complexity of MIL is only poly-logarithmically dependent\non the size of the bag, for any underlying hypothesis class. In addition, we\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\ncan be generated from any efficient non-MIL supervised learning algorithm that\nhandles one-sided error. The computational complexity of the resulting\nalgorithm is only polynomially dependent on the bag size.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2011 13:30:58 GMT"}, {"version": "v2", "created": "Tue, 29 May 2012 05:42:03 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2012 16:38:44 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Sabato", "Sivan", ""], ["Tishby", "Naftali", ""]]}, {"id": "1107.2379", "submitter": "Lev Reyzin", "authors": "Shalev Ben-David, Lev Reyzin", "title": "Data Stability in Clustering: A Closer Look", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model introduced by Bilu and Linial (2010), who study\nproblems for which the optimal clustering does not change when distances are\nperturbed. They show that even when a problem is NP-hard, it is sometimes\npossible to obtain efficient algorithms for instances resilient to certain\nmultiplicative perturbations, e.g. on the order of $O(\\sqrt{n})$ for max-cut\nclustering. Awasthi et al. (2010) consider center-based objectives, and Balcan\nand Liang (2011) analyze the $k$-median and min-sum objectives, giving\nefficient algorithms for instances resilient to certain constant multiplicative\nperturbations.\n  Here, we are motivated by the question of to what extent these assumptions\ncan be relaxed while allowing for efficient algorithms. We show there is little\nroom to improve these results by giving NP-hardness lower bounds for both the\n$k$-median and min-sum objectives. On the other hand, we show that constant\nmultiplicative resilience parameters can be so strong as to make the clustering\nproblem trivial, leaving only a narrow range of resilience parameters for which\nclustering is interesting. We also consider a model of additive perturbations\nand give a correspondence between additive and multiplicative notions of\nstability. Our results provide a close examination of the consequences of\nassuming stability in data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2011 19:27:12 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2011 19:20:42 GMT"}, {"version": "v3", "created": "Mon, 22 Aug 2011 19:04:46 GMT"}, {"version": "v4", "created": "Thu, 3 Nov 2011 15:58:42 GMT"}, {"version": "v5", "created": "Fri, 29 Aug 2014 18:52:16 GMT"}], "update_date": "2014-09-01", "authors_parsed": [["Ben-David", "Shalev", ""], ["Reyzin", "Lev", ""]]}, {"id": "1107.2444", "submitter": "Moritz Hardt", "authors": "Moritz Hardt and Guy N. Rothblum and Rocco A. Servedio", "title": "Private Data Release via Learning Thresholds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers computationally efficient privacy-preserving data\nrelease. We study the task of analyzing a database containing sensitive\ninformation about individual participants. Given a set of statistical queries\non the data, we want to release approximate answers to the queries while also\nguaranteeing differential privacy---protecting each participant's sensitive\ndata.\n  Our focus is on computationally efficient data release algorithms; we seek\nalgorithms whose running time is polynomial, or at least sub-exponential, in\nthe data dimensionality. Our primary contribution is a computationally\nefficient reduction from differentially private data release for a class of\ncounting queries, to learning thresholded sums of predicates from a related\nclass.\n  We instantiate this general reduction with a variety of algorithms for\nlearning thresholds. These instantiations yield several new results for\ndifferentially private data release. As two examples, taking {0,1}^d to be the\ndata domain (of dimension d), we obtain differentially private algorithms for:\n  (*) Releasing all k-way conjunctions. For any given k, the resulting data\nrelease algorithm has bounded error as long as the database is of size at least\nd^{O(\\sqrt{k\\log(k\\log d)})}. The running time is polynomial in the database\nsize.\n  (*) Releasing a (1-\\gamma)-fraction of all parity queries. For any \\gamma\n\\geq \\poly(1/d), the algorithm has bounded error as long as the database is of\nsize at least \\poly(d). The running time is polynomial in the database size.\n  Several other instantiations yield further results for privacy-preserving\ndata release. Of the two results highlighted above, the first learning\nalgorithm uses techniques for representing thresholded sums of predicates as\nlow-degree polynomial threshold functions. The second learning algorithm is\nbased on Jackson's Harmonic Sieve algorithm [Jackson 1997].\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 00:53:23 GMT"}], "update_date": "2011-07-14", "authors_parsed": [["Hardt", "Moritz", ""], ["Rothblum", "Guy N.", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1107.2462", "submitter": "Timothy Rubin", "authors": "Timothy N. Rubin, America Chambers, Padhraic Smyth and Mark Steyvers", "title": "Statistical Topic Models for Multi-Label Document Classification", "comments": "44 Pages (Including Appendices). To be published in: The Machine\n  Learning Journal, special issue on Learning from Multi-Label Data. Version 2\n  corrects some typos, updates some of the notation used in the paper for\n  clarification of some equations, and incorporates several relatively minor\n  changes to the text throughout the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches to multi-label document classification have to\ndate largely relied on discriminative modeling techniques such as support\nvector machines. A drawback of these approaches is that performance rapidly\ndrops off as the total number of labels and the number of labels per document\nincrease. This problem is amplified when the label frequencies exhibit the type\nof highly skewed distributions that are often observed in real-world datasets.\nIn this paper we investigate a class of generative statistical topic models for\nmulti-label documents that associate individual word tokens with different\nlabels. We investigate the advantages of this approach relative to\ndiscriminative models, particularly with respect to classification problems\ninvolving large numbers of relatively rare labels. We compare the performance\nof generative and discriminative approaches on document labeling tasks ranging\nfrom datasets with several thousand labels to datasets with tens of labels. The\nexperimental results indicate that probabilistic generative models can achieve\ncompetitive multi-label classification performance compared to discriminative\nmethods, and have advantages for datasets with many labels and skewed label\nfrequencies.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 04:28:32 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2011 04:24:38 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Rubin", "Timothy N.", ""], ["Chambers", "America", ""], ["Smyth", "Padhraic", ""], ["Steyvers", "Mark", ""]]}, {"id": "1107.2487", "submitter": "Anil Aswani", "authors": "Anil Aswani, Humberto Gonzalez, S. Shankar Sastry, Claire Tomlin", "title": "Provably Safe and Robust Learning-Based Model Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controller design faces a trade-off between robustness and performance, and\nthe reliability of linear controllers has caused many practitioners to focus on\nthe former. However, there is renewed interest in improving system performance\nto deal with growing energy constraints. This paper describes a learning-based\nmodel predictive control (LBMPC) scheme that provides deterministic guarantees\non robustness, while statistical identification tools are used to identify\nricher models of the system in order to improve performance; the benefits of\nthis framework are that it handles state and input constraints, optimizes\nsystem performance with respect to a cost function, and can be designed to use\na wide variety of parametric or nonparametric statistical tools. The main\ninsight of LBMPC is that safety and performance can be decoupled under\nreasonable conditions in an optimization framework by maintaining two models of\nthe system. The first is an approximate model with bounds on its uncertainty,\nand the second model is updated by statistical methods. LBMPC improves\nperformance by choosing inputs that minimize a cost subject to the learned\ndynamics, and it ensures safety and robustness by checking whether these same\ninputs keep the approximate model stable when it is subject to uncertainty.\nFurthermore, we show that if the system is sufficiently excited, then the LBMPC\ncontrol action probabilistically converges to that of an MPC computed using the\ntrue dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 08:34:50 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2012 00:13:11 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["Aswani", "Anil", ""], ["Gonzalez", "Humberto", ""], ["Sastry", "S. Shankar", ""], ["Tomlin", "Claire", ""]]}, {"id": "1107.2490", "submitter": "Wei Xu", "authors": "Wei Xu", "title": "Towards Optimal One Pass Large Scale Learning with Averaged Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For large scale learning problems, it is desirable if we can obtain the\noptimal model parameters by going through the data in only one pass. Polyak and\nJuditsky (1992) showed that asymptotically the test performance of the simple\naverage of the parameters obtained by stochastic gradient descent (SGD) is as\ngood as that of the parameters which minimize the empirical cost. However, to\nour knowledge, despite its optimal asymptotic convergence rate, averaged SGD\n(ASGD) received little attention in recent research on large scale learning.\nOne possible reason is that it may take a prohibitively large number of\ntraining samples for ASGD to reach its asymptotic region for most real\nproblems. In this paper, we present a finite sample analysis for the method of\nPolyak and Juditsky (1992). Our analysis shows that it indeed usually takes a\nhuge number of samples for ASGD to reach its asymptotic region for improperly\nchosen learning rate. More importantly, based on our analysis, we propose a\nsimple way to properly set learning rate so that it takes a reasonable amount\nof data for ASGD to reach its asymptotic region. We compare ASGD using our\nproposed learning rate with other well known algorithms for training large\nscale linear classifiers. The experiments clearly show the superiority of ASGD.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 08:57:29 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2011 06:43:31 GMT"}], "update_date": "2011-12-23", "authors_parsed": [["Xu", "Wei", ""]]}, {"id": "1107.2700", "submitter": "Ilias Diakonikolas", "authors": "Constantinos Daskalakis, Ilias Diakonikolas, Rocco A. Servedio", "title": "Learning $k$-Modal Distributions via Testing", "comments": "28 pages, full version of SODA'12 paper, to appear in Theory of\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-modal probability distribution over the discrete domain $\\{1,...,n\\}$\nis one whose histogram has at most $k$ \"peaks\" and \"valleys.\" Such\ndistributions are natural generalizations of monotone ($k=0$) and unimodal\n($k=1$) probability distributions, which have been intensively studied in\nprobability theory and statistics.\n  In this paper we consider the problem of \\emph{learning} (i.e., performing\ndensity estimation of) an unknown $k$-modal distribution with respect to the\n$L_1$ distance. The learning algorithm is given access to independent samples\ndrawn from an unknown $k$-modal distribution $p$, and it must output a\nhypothesis distribution $\\widehat{p}$ such that with high probability the total\nvariation distance between $p$ and $\\widehat{p}$ is at most $\\epsilon.$ Our\nmain goal is to obtain \\emph{computationally efficient} algorithms for this\nproblem that use (close to) an information-theoretically optimal number of\nsamples.\n  We give an efficient algorithm for this problem that runs in time\n$\\mathrm{poly}(k,\\log(n),1/\\epsilon)$. For $k \\leq \\tilde{O}(\\log n)$, the\nnumber of samples used by our algorithm is very close (within an\n$\\tilde{O}(\\log(1/\\epsilon))$ factor) to being information-theoretically\noptimal. Prior to this work computationally efficient algorithms were known\nonly for the cases $k=0,1$ \\cite{Birge:87b,Birge:97}.\n  A novel feature of our approach is that our learning algorithm crucially uses\na new algorithm for \\emph{property testing of probability distributions} as a\nkey subroutine. The learning algorithm uses the property tester to efficiently\ndecompose the $k$-modal distribution into $k$ (near-)monotone distributions,\nwhich are easier to learn.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 23:26:53 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2011 06:05:19 GMT"}, {"version": "v3", "created": "Sun, 14 Sep 2014 21:20:37 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1107.2702", "submitter": "Ilias Diakonikolas", "authors": "Constantinos Daskalakis, Ilias Diakonikolas, Rocco A. Servedio", "title": "Learning Poisson Binomial Distributions", "comments": "Revised full version. Improved sample complexity bound of O~(1/eps^2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a basic problem in unsupervised learning: learning an unknown\n\\emph{Poisson Binomial Distribution}. A Poisson Binomial Distribution (PBD)\nover $\\{0,1,\\dots,n\\}$ is the distribution of a sum of $n$ independent\nBernoulli random variables which may have arbitrary, potentially non-equal,\nexpectations. These distributions were first studied by S. Poisson in 1837\n\\cite{Poisson:37} and are a natural $n$-parameter generalization of the\nfamiliar Binomial Distribution. Surprisingly, prior to our work this basic\nlearning problem was poorly understood, and known results for it were far from\noptimal.\n  We essentially settle the complexity of the learning problem for this basic\nclass of distributions. As our first main result we give a highly efficient\nalgorithm which learns to $\\eps$-accuracy (with respect to the total variation\ndistance) using $\\tilde{O}(1/\\eps^3)$ samples \\emph{independent of $n$}. The\nrunning time of the algorithm is \\emph{quasilinear} in the size of its input\ndata, i.e., $\\tilde{O}(\\log(n)/\\eps^3)$ bit-operations. (Observe that each draw\nfrom the distribution is a $\\log(n)$-bit string.) Our second main result is a\n{\\em proper} learning algorithm that learns to $\\eps$-accuracy using\n$\\tilde{O}(1/\\eps^2)$ samples, and runs in time $(1/\\eps)^{\\poly (\\log\n(1/\\eps))} \\cdot \\log n$. This is nearly optimal, since any algorithm {for this\nproblem} must use $\\Omega(1/\\eps^2)$ samples. We also give positive and\nnegative results for some extensions of this learning problem to weighted sums\nof independent Bernoulli random variables.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 23:30:39 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2011 06:03:55 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2013 17:37:52 GMT"}, {"version": "v4", "created": "Tue, 17 Feb 2015 01:45:53 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1107.2807", "submitter": "Boris Flach", "authors": "Boris Flach and Dmitrij Schlesinger", "title": "Modelling Distributed Shape Priors by Gibbs Random Fields of Second\n  Order", "comments": "17 pages, 8 figures", "journal-ref": "Control Systems and Computers, (2) 2011, pp 14-24", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the potential of Gibbs Random Fields for shape prior modelling. We\nshow that the expressive power of second order GRFs is already sufficient to\nexpress simple shapes and spatial relations between them simultaneously. This\nallows to model and recognise complex shapes as spatial compositions of simpler\nparts.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2011 12:51:10 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["Flach", "Boris", ""], ["Schlesinger", "Dmitrij", ""]]}, {"id": "1107.3059", "submitter": "Amin Karbasi", "authors": "Amin Karbasi, Stratis Ioannidis, Laurent Massoulie", "title": "From Small-World Networks to Comparison-Based Search", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT cs.SI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of content search through comparisons has recently received\nconsiderable attention. In short, a user searching for a target object\nnavigates through a database in the following manner: the user is asked to\nselect the object most similar to her target from a small list of objects. A\nnew object list is then presented to the user based on her earlier selection.\nThis process is repeated until the target is included in the list presented, at\nwhich point the search terminates. This problem is known to be strongly related\nto the small-world network design problem.\n  However, contrary to prior work, which focuses on cases where objects in the\ndatabase are equally popular, we consider here the case where the demand for\nobjects may be heterogeneous. We show that, under heterogeneous demand, the\nsmall-world network design problem is NP-hard. Given the above negative result,\nwe propose a novel mechanism for small-world design and provide an upper bound\non its performance under heterogeneous demand. The above mechanism has a\nnatural equivalent in the context of content search through comparisons, and we\nestablish both an upper bound and a lower bound for the performance of this\nmechanism. These bounds are intuitively appealing, as they depend on the\nentropy of the demand as well as its doubling constant, a quantity capturing\nthe topology of the set of target objects. They also illustrate interesting\nconnections between comparison-based search to classic results from information\ntheory. Finally, we propose an adaptive learning algorithm for content search\nthat meets the performance guarantees achieved by the above mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2011 12:47:02 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 19:44:00 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2014 07:03:28 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Karbasi", "Amin", ""], ["Ioannidis", "Stratis", ""], ["Massoulie", "Laurent", ""]]}, {"id": "1107.3090", "submitter": "Nikos Vlassis", "authors": "Nikos Vlassis, Michael L. Littman, David Barber", "title": "On the Computational Complexity of Stochastic Controller Optimization in\n  POMDPs", "comments": "Corrected error in the proof of Theorem 2, and revised Section 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem of finding an optimal stochastic 'blind' controller\nin a Markov decision process is an NP-hard problem. The corresponding decision\nproblem is NP-hard, in PSPACE, and SQRT-SUM-hard, hence placing it in NP would\nimply breakthroughs in long-standing open problems in computer science. Our\nresult establishes that the more general problem of stochastic controller\noptimization in POMDPs is also NP-hard. Nonetheless, we outline a special case\nthat is convex and admits efficient global solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2011 15:33:15 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2012 13:54:42 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Vlassis", "Nikos", ""], ["Littman", "Michael L.", ""], ["Barber", "David", ""]]}, {"id": "1107.3133", "submitter": "JooSeuk Kim", "authors": "JooSeuk Kim and Clayton D. Scott", "title": "Robust Kernel Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for nonparametric density estimation that exhibits\nrobustness to contamination of the training sample. This method achieves\nrobustness by combining a traditional kernel density estimator (KDE) with ideas\nfrom classical $M$-estimation. We interpret the KDE based on a radial, positive\nsemi-definite kernel as a sample mean in the associated reproducing kernel\nHilbert space. Since the sample mean is sensitive to outliers, we estimate it\nrobustly via $M$-estimation, yielding a robust kernel density estimator (RKDE).\n  An RKDE can be computed efficiently via a kernelized iteratively re-weighted\nleast squares (IRWLS) algorithm. Necessary and sufficient conditions are given\nfor kernelized IRWLS to converge to the global minimizer of the $M$-estimator\nobjective function. The robustness of the RKDE is demonstrated with a\nrepresenter theorem, the influence function, and experimental results for\ndensity estimation and anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2011 19:05:48 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2011 03:18:45 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Kim", "JooSeuk", ""], ["Scott", "Clayton D.", ""]]}, {"id": "1107.3258", "submitter": "Ali Jalali", "authors": "Ali Jalali and Chris Johnson and Pradeep Ravikumar", "title": "On Learning Discrete Graphical Models Using Greedy Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of learning the structure of a pairwise\ngraphical model from samples in a high-dimensional setting. Our first main\nresult studies the sparsistency, or consistency in sparsity pattern recovery,\nproperties of a forward-backward greedy algorithm as applied to general\nstatistical models. As a special case, we then apply this algorithm to learn\nthe structure of a discrete graphical model via neighborhood estimation. As a\ncorollary of our general result, we derive sufficient conditions on the number\nof samples n, the maximum node-degree d and the problem size p, as well as\nother conditions on the model parameters, so that the algorithm recovers all\nthe edges with high probability. Our result guarantees graph selection for\nsamples scaling as n = Omega(d^2 log(p)), in contrast to existing\nconvex-optimization based algorithms that require a sample complexity of\n\\Omega(d^3 log(p)). Further, the greedy algorithm only requires a restricted\nstrong convexity condition which is typically milder than irrepresentability\nassumptions. We corroborate these results using numerical simulations at the\nend.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2011 22:04:13 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Jalali", "Ali", ""], ["Johnson", "Chris", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1107.3407", "submitter": "Jean-Philippe M\\'etivier", "authors": "Patrice Boizumault, Bruno Cr\\'emilleux, Mehdi Khiari, Samir Loudni,\n  and Jean-Philippe M\\'etivier", "title": "Discovering Knowledge using a Constraint-based Language", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "DPA-11201", "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Discovering pattern sets or global patterns is an attractive issue from the\npattern mining community in order to provide useful information. By combining\nlocal patterns satisfying a joint meaning, this approach produces patterns of\nhigher level and thus more useful for the data analyst than the usual local\npatterns, while reducing the number of patterns. In parallel, recent works\ninvestigating relationships between data mining and constraint programming (CP)\nshow that the CP paradigm is a nice framework to model and mine such patterns\nin a declarative and generic way. We present a constraint-based language which\nenables us to define queries addressing patterns sets and global patterns. The\nusefulness of such a declarative approach is highlighted by several examples\ncoming from the clustering based on associations. This language has been\nimplemented in the CP framework.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2011 12:01:28 GMT"}], "update_date": "2011-07-19", "authors_parsed": [["Boizumault", "Patrice", ""], ["Cr\u00e9milleux", "Bruno", ""], ["Khiari", "Mehdi", ""], ["Loudni", "Samir", ""], ["M\u00e9tivier", "Jean-Philippe", ""]]}, {"id": "1107.3600", "submitter": "Oliver Kramer Oliver Kramer", "authors": "Oliver Kramer", "title": "Unsupervised K-Nearest Neighbor Regression", "comments": "4 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific disciplines structures in high-dimensional data have to be\nfound, e.g., in stellar spectra, in genome data, or in face recognition tasks.\nIn this work we present a novel approach to non-linear dimensionality\nreduction. It is based on fitting K-nearest neighbor regression to the\nunsupervised regression framework for learning of low-dimensional manifolds.\nSimilar to related approaches that are mostly based on kernel methods,\nunsupervised K-nearest neighbor (UNN) regression optimizes latent variables\nw.r.t. the data space reconstruction error employing the K-nearest neighbor\nheuristic. The problem of optimizing latent neighborhoods is difficult to\nsolve, but the UNN formulation allows the design of efficient strategies that\niteratively embed latent points to fixed neighborhood topologies. UNN is well\nappropriate for sorting of high-dimensional data. The iterative variants are\nanalyzed experimentally.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2011 00:48:41 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 10:02:43 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Kramer", "Oliver", ""]]}, {"id": "1107.3823", "submitter": "Nicolas Le Roux", "authors": "Nicolas Heess (Informatics), Nicolas Le Roux (INRIA Paris -\n  Rocquencourt), John Winn", "title": "Weakly Supervised Learning of Foreground-Background Segmentation using\n  Masked RBMs", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (2011)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of the Restricted Boltzmann Machine (RBM) that allows\nthe joint shape and appearance of foreground objects in cluttered images to be\nmodeled independently of the background. We present a learning scheme that\nlearns this representation directly from cluttered images with only very weak\nsupervision. The model generates plausible samples and performs\nforeground-background segmentation. We demonstrate that representing foreground\nobjects independently of the background can be beneficial in recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2011 19:43:10 GMT"}], "update_date": "2011-07-20", "authors_parsed": [["Heess", "Nicolas", "", "Informatics"], ["Roux", "Nicolas Le", "", "INRIA Paris -\n  Rocquencourt"], ["Winn", "John", ""]]}, {"id": "1107.4042", "submitter": "Cem Tekin", "authors": "Cem Tekin, Mingyan Liu", "title": "Optimal Adaptive Learning in Uncontrolled Restless Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of learning the optimal policy for\nuncontrolled restless bandit problems. In an uncontrolled restless bandit\nproblem, there is a finite set of arms, each of which when pulled yields a\npositive reward. There is a player who sequentially selects one of the arms at\neach time step. The goal of the player is to maximize its undiscounted reward\nover a time horizon T. The reward process of each arm is a finite state Markov\nchain, whose transition probabilities are unknown by the player. State\ntransitions of each arm is independent of the selection of the player. We\npropose a learning algorithm with logarithmic regret uniformly over time with\nrespect to the optimal finite horizon policy. Our results extend the optimal\nadaptive learning of MDPs to POMDPs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 17:33:43 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2012 05:06:22 GMT"}, {"version": "v3", "created": "Thu, 29 Jan 2015 10:15:00 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Tekin", "Cem", ""], ["Liu", "Mingyan", ""]]}, {"id": "1107.4080", "submitter": "Karthik Sridharan Karthik Sridharan", "authors": "Nathan Srebro, Karthik Sridharan, Ambuj Tewari", "title": "On the Universality of Online Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for a general class of convex online learning problems, Mirror\nDescent can always achieve a (nearly) optimal regret guarantee.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 19:34:00 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Srebro", "Nathan", ""], ["Sridharan", "Karthik", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1107.4153", "submitter": "Cem Tekin", "authors": "Cem Tekin, Mingyan Liu", "title": "Performance and Convergence of Multi-user Online Learning", "comments": null, "journal-ref": "in Proceedings of GAMENETS 2011", "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of allocating multiple users to a set of wireless\nchannels in a decentralized manner when the channel quali- ties are\ntime-varying and unknown to the users, and accessing the same channel by\nmultiple users leads to reduced quality due to interference. In such a setting\nthe users not only need to learn the inherent channel quality and at the same\ntime the best allocations of users to channels so as to maximize the social\nwelfare. Assuming that the users adopt a certain online learning algorithm, we\ninvestigate under what conditions the socially optimal allocation is\nachievable. In particular we examine the effect of different levels of\nknowledge the users may have and the amount of communications and cooperation.\nThe general conclusion is that when the cooperation of users decreases and the\nuncertainty about channel payoffs increases it becomes harder to achieve the\nsocially opti- mal allocation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2011 04:15:25 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Tekin", "Cem", ""], ["Liu", "Mingyan", ""]]}, {"id": "1107.4573", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "Analogy perception applied to seven tests of word comprehension", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": "Journal of Experimental & Theoretical Artificial Intelligence\n  (JETAI), 2011, Volume 23, Issue 3, pages 343-362", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that analogy is the core of cognition. In AI research,\nalgorithms for analogy are often limited by the need for hand-coded high-level\nrepresentations as input. An alternative approach is to use high-level\nperception, in which high-level representations are automatically generated\nfrom raw data. Analogy perception is the process of recognizing analogies using\nhigh-level perception. We present PairClass, an algorithm for analogy\nperception that recognizes lexical proportional analogies using representations\nthat are automatically generated from a large corpus of raw textual data. A\nproportional analogy is an analogy of the form A:B::C:D, meaning \"A is to B as\nC is to D\". A lexical proportional analogy is a proportional analogy with\nwords, such as carpenter:wood::mason:stone. PairClass represents the semantic\nrelations between two words using a high-dimensional feature vector, in which\nthe elements are based on frequencies of patterns in the corpus. PairClass\nrecognizes analogies by applying standard supervised machine learning\ntechniques to the feature vectors. We show how seven different tests of word\ncomprehension can be framed as problems of analogy perception and we then apply\nPairClass to the seven resulting sets of analogy perception problems. We\nachieve competitive results on all seven tests. This is the first time a\nuniform approach has handled such a range of tests of word comprehension.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2011 16:54:11 GMT"}], "update_date": "2011-07-25", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}, {"id": "1107.4606", "submitter": "Michael Fairbank Mr", "authors": "Michael Fairbank and Eduardo Alonso", "title": "The Divergence of Reinforcement Learning Algorithms with Value-Iteration\n  and Function Approximation", "comments": "8 pages, 4 figures. In Proceedings of the IEEE International Joint\n  Conference on Neural Networks, June 2012, Brisbane (IEEE IJCNN 2012), pp.\n  3070--3077", "journal-ref": "In Proceedings of the IEEE International Joint Conference on\n  Neural Networks, June 2012, Brisbane (IEEE IJCNN 2012), pp. 3070--3077", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives specific divergence examples of value-iteration for several\nmajor Reinforcement Learning and Adaptive Dynamic Programming algorithms, when\nusing a function approximator for the value function. These divergence examples\ndiffer from previous divergence examples in the literature, in that they are\napplicable for a greedy policy, i.e. in a \"value iteration\" scenario. Perhaps\nsurprisingly, with a greedy policy, it is also possible to get divergence for\nthe algorithms TD(1) and Sarsa(1). In addition to these divergences, we also\nachieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and\nGDHP.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2011 13:05:48 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2012 18:08:07 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Fairbank", "Michael", ""], ["Alonso", "Eduardo", ""]]}, {"id": "1107.4966", "submitter": "Lilyana Mihalkova", "authors": "Lilyana Mihalkova and Lise Getoor", "title": "Lifted Graphical Models: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a survey of work on lifted graphical models. We review\na general form for a lifted graphical model, a par-factor graph, and show how a\nnumber of existing statistical relational representations map to this\nformalism. We discuss inference algorithms, including lifted inference\nalgorithms, that efficiently compute the answers to probabilistic queries. We\nalso review work in learning lifted graphical models from data. It is our\nbelief that the need for statistical relational models (whether it goes by that\nname or another) will grow in the coming decades, as we are inundated with data\nwhich is a mix of structured and unstructured, with entities and relations\nextracted in a noisy manner from text, and with the need to reason effectively\nwith this data. We hope that this synthesis of ideas from many different\nresearch groups will provide an accessible starting point for new researchers\nin this expanding field.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 14:56:18 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2011 17:27:04 GMT"}], "update_date": "2011-08-29", "authors_parsed": [["Mihalkova", "Lilyana", ""], ["Getoor", "Lise", ""]]}, {"id": "1107.4967", "submitter": "Domenico Corapi Domenico Corapi", "authors": "Domenico Corapi, Alessandra Russo, Marina De Vos, Julian Padget, Ken\n  Satoh", "title": "Normative design using inductive learning", "comments": "Theory and Practice of Logic Programming, 27th Int'l. Conference on\n  Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a use-case-driven iterative design methodology for\nnormative frameworks, also called virtual institutions, which are used to\ngovern open systems. Our computational model represents the normative framework\nas a logic program under answer set semantics (ASP). By means of an inductive\nlogic programming approach, implemented using ASP, it is possible to synthesise\nnew rules and revise the existing ones. The learning mechanism is guided by the\ndesigner who describes the desired properties of the framework through use\ncases, comprising (i) event traces that capture possible scenarios, and (ii) a\nstate that describes the desired outcome. The learning process then proposes\nadditional rules, or changes to current rules, to satisfy the constraints\nexpressed in the use cases. Thus, the contribution of this paper is a process\nfor the elaboration and revision of a normative framework by means of a\nsemi-automatic and iterative process driven from specifications of\n(un)desirable behaviour. The process integrates a novel and general methodology\nfor theory revision based on ASP.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2011 15:01:50 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Corapi", "Domenico", ""], ["Russo", "Alessandra", ""], ["De Vos", "Marina", ""], ["Padget", "Julian", ""], ["Satoh", "Ken", ""]]}, {"id": "1107.5236", "submitter": "Wael Emara", "authors": "Wael Emara and Mehmed Kantardzic", "title": "Submodular Optimization for Efficient Semi-supervised Support Vector\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a quadratic programming approximation of the\nSemi-Supervised Support Vector Machine (S3VM) problem, namely approximate\nQP-S3VM, that can be efficiently solved using off the shelf optimization\npackages. We prove that this approximate formulation establishes a relation\nbetween the low density separation and the graph-based models of\nsemi-supervised learning (SSL) which is important to develop a unifying\nframework for semi-supervised learning methods. Furthermore, we propose the\nnovel idea of representing SSL problems as submodular set functions and use\nefficient submodular optimization algorithms to solve them. Using this new idea\nwe develop a representation of the approximate QP-S3VM as a maximization of a\nsubmodular set function which makes it possible to optimize using efficient\ngreedy algorithms. We demonstrate that the proposed methods are accurate and\nprovide significant improvement in time complexity over the state of the art in\nthe literature.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2011 15:11:10 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2011 17:42:35 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Emara", "Wael", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1107.5349", "submitter": "Luca Pinello", "authors": "Luca Pinello", "title": "Multi Layer Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents a new methodology to analyze one-dimensional signals\ntrough a new approach called Multi Layer Analysis, for short MLA. It also\nprovides some new insights on the relationship between one-dimensional signals\nprocessed by MLA and tree kernels, test of randomness and signal processing\ntechniques. The MLA approach has a wide range of application to the fields of\npattern discovery and matching, computational biology and many other areas of\ncomputer science and signal processing. This thesis includes also some\napplications of this approach to real problems in biology and seismology.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2011 22:29:35 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Pinello", "Luca", ""]]}, {"id": "1107.5520", "submitter": "Marcus Hutter", "authors": "Peter Sunehag and Marcus Hutter", "title": "Axioms for Rational Reinforcement Learning", "comments": "16 LaTeX pages", "journal-ref": "Proc. 22nd International Conf. on Algorithmic Learning Theory\n  (ALT-2011) pages 338-352", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a formal, simple and intuitive theory of rational decision making\nincluding sequential decisions that affect the environment. The theory has a\ngeometric flavor, which makes the arguments easy to visualize and understand.\nOur theory is for complete decision makers, which means that they have a\ncomplete set of preferences. Our main result shows that a complete rational\ndecision maker implicitly has a probabilistic model of the environment. We have\na countable version of this result that brings light on the issue of countable\nvs finite additivity by showing how it depends on the geometry of the space\nwhich we have preferences over. This is achieved through fruitfully connecting\nrationality with the Hahn-Banach Theorem. The theory presented here can be\nviewed as a formalization and extension of the betting odds approach to\nprobability of Ramsey and De Finetti.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 16:29:06 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Sunehag", "Peter", ""], ["Hutter", "Marcus", ""]]}, {"id": "1107.5531", "submitter": "Marcus Hutter", "authors": "Tor Lattimore and Marcus Hutter and Vaibhav Gavane", "title": "Universal Prediction of Selected Bits", "comments": "17 LaTeX pages", "journal-ref": "Proc. 22nd International Conf. on Algorithmic Learning Theory\n  (ALT-2011) pages 262-276", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning tasks can be viewed as sequence prediction problems. For\nexample, online classification can be converted to sequence prediction with the\nsequence being pairs of input/target data and where the goal is to correctly\npredict the target data given input data and previous input/target pairs.\nSolomonoff induction is known to solve the general sequence prediction problem,\nbut only if the entire sequence is sampled from a computable distribution. In\nthe case of classification and discriminative learning though, only the targets\nneed be structured (given the inputs). We show that the normalised version of\nSolomonoff induction can still be used in this case, and more generally that it\ncan detect any recursive sub-pattern (regularity) within an otherwise\ncompletely unstructured sequence. It is also shown that the unnormalised\nversion can fail to predict very simple recursive sub-patterns.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 16:44:41 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Lattimore", "Tor", ""], ["Hutter", "Marcus", ""], ["Gavane", "Vaibhav", ""]]}, {"id": "1107.5537", "submitter": "Marcus Hutter", "authors": "Tor Lattimore and Marcus Hutter", "title": "Asymptotically Optimal Agents", "comments": "21 LaTeX pages", "journal-ref": "Proc. 22nd International Conf. on Algorithmic Learning Theory\n  (ALT-2011) pages 368-382", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial general intelligence aims to create agents capable of learning to\nsolve arbitrary interesting problems. We define two versions of asymptotic\noptimality and prove that no agent can satisfy the strong version while in some\ncases, depending on discounting, there does exist a non-computable weak\nasymptotically optimal agent.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 16:51:48 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Lattimore", "Tor", ""], ["Hutter", "Marcus", ""]]}, {"id": "1107.5671", "submitter": "Max Ostrowski", "authors": "Max Ostrowski and Torsten Schaub and Markus Durzinsky and Wolfgang\n  Marwan and Annegret Wagler", "title": "Automatic Network Reconstruction using ASP", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 27th Int'l. Conference\n  on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, pages\n  749-766, 2011", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building biological models by inferring functional dependencies from\nexperimental data is an im- portant issue in Molecular Biology. To relieve the\nbiologist from this traditionally manual process, various approaches have been\nproposed to increase the degree of automation. However, available ap- proaches\noften yield a single model only, rely on specific assumptions, and/or use\ndedicated, heuris- tic algorithms that are intolerant to changing circumstances\nor requirements in the view of the rapid progress made in Biotechnology. Our\naim is to provide a declarative solution to the problem by ap- peal to Answer\nSet Programming (ASP) overcoming these difficulties. We build upon an existing\napproach to Automatic Network Reconstruction proposed by part of the authors.\nThis approach has firm mathematical foundations and is well suited for ASP due\nto its combinatorial flavor providing a characterization of all models\nexplaining a set of experiments. The usage of ASP has several ben- efits over\nthe existing heuristic algorithms. First, it is declarative and thus\ntransparent for biological experts. Second, it is elaboration tolerant and thus\nallows for an easy exploration and incorporation of biological constraints.\nThird, it allows for exploring the entire space of possible models. Finally,\nour approach offers an excellent performance, matching existing,\nspecial-purpose systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 10:36:30 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Ostrowski", "Max", ""], ["Schaub", "Torsten", ""], ["Durzinsky", "Markus", ""], ["Marwan", "Wolfgang", ""], ["Wagler", "Annegret", ""]]}]