[{"id": "1803.00001", "submitter": "Ngom Papa", "authors": "Mactar Ndaw, Macoumba Ndour, Papa Ngom", "title": "The Alpha-Beta-Symetric Divergence and their Positive Definite Kernel", "comments": "1o pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the field of Hilbertian metrics and positive definit\n(pd) kernels on probability measures, they have a real interest in kernel\nmethods. Firstly we will make a study based on the Alpha-Beta-divergence to\nhave a Hilbercan metric by proposing an improvement of this divergence by\nconstructing it so that its is symmetrical the Alpha-Beta-Symmetric-divergence\n(ABS-divergence) and also do some studies on these properties but also propose\nthe kernels associated with this divergence. Secondly we will do mumerical\nstudies incorporating all proposed metrics/kernels into support vector machine\n(SVM). Finally we presented a algorithm for image classification by using our\ndivergence.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 18:10:26 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 22:19:15 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Ndaw", "Mactar", ""], ["Ndour", "Macoumba", ""], ["Ngom", "Papa", ""]]}, {"id": "1803.00008", "submitter": "Gautam Kamath", "authors": "Jayadev Acharya, Gautam Kamath, Ziteng Sun, Huanyu Zhang", "title": "INSPECTRE: Privately Estimating the Unseen", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop differentially private methods for estimating various\ndistributional properties. Given a sample from a discrete distribution $p$,\nsome functional $f$, and accuracy and privacy parameters $\\alpha$ and\n$\\varepsilon$, the goal is to estimate $f(p)$ up to accuracy $\\alpha$, while\nmaintaining $\\varepsilon$-differential privacy of the sample.\n  We prove almost-tight bounds on the sample size required for this problem for\nseveral functionals of interest, including support size, support coverage, and\nentropy. We show that the cost of privacy is negligible in a variety of\nsettings, both theoretically and experimentally. Our methods are based on a\nsensitivity analysis of several state-of-the-art methods for estimating these\nproperties with sublinear sample complexities.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 19:00:00 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Acharya", "Jayadev", ""], ["Kamath", "Gautam", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "1803.00055", "submitter": "Ryan Marcus", "authors": "Ryan Marcus, Olga Papaemmanouil", "title": "Deep Reinforcement Learning for Join Order Enumeration", "comments": null, "journal-ref": "aiDM@SIGMOD 2018 Proceedings of the First International Workshop\n  on Exploiting Artificial Intelligence Techniques for Data Management", "doi": "10.1145/3211954.3211957", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Join order selection plays a significant role in query performance. However,\nmodern query optimizers typically employ static join enumeration algorithms\nthat do not receive any feedback about the quality of the resulting plan.\nHence, optimizers often repeatedly choose the same bad plan, as they do not\nhave a mechanism for \"learning from their mistakes\". In this paper, we argue\nthat existing deep reinforcement learning techniques can be applied to address\nthis challenge. These techniques, powered by artificial neural networks, can\nautomatically improve decision making by incorporating feedback from their\nsuccesses and failures. Towards this goal, we present ReJOIN, a\nproof-of-concept join enumerator, and present preliminary results indicating\nthat ReJOIN can match or outperform the PostgreSQL optimizer in terms of plan\nquality and join enumeration efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 20:00:33 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 21:09:45 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Marcus", "Ryan", ""], ["Papaemmanouil", "Olga", ""]]}, {"id": "1803.00057", "submitter": "Boyang Li", "authors": "Pelin Dogan, Boyang Li, Leonid Sigal, Markus Gross", "title": "A Neural Multi-sequence Alignment TeCHnique (NeuMATCH)", "comments": "Accepted at CVPR 2018 (Spotlight). arXiv file includes the paper and\n  the supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alignment of heterogeneous sequential data (video to text) is an\nimportant and challenging problem. Standard techniques for this task, including\nDynamic Time Warping (DTW) and Conditional Random Fields (CRFs), suffer from\ninherent drawbacks. Mainly, the Markov assumption implies that, given the\nimmediate past, future alignment decisions are independent of further history.\nThe separation between similarity computation and alignment decision also\nprevents end-to-end training. In this paper, we propose an end-to-end neural\narchitecture where alignment actions are implemented as moving data between\nstacks of Long Short-term Memory (LSTM) blocks. This flexible architecture\nsupports a large variety of alignment tasks, including one-to-one, one-to-many,\nskipping unmatched elements, and (with extensions) non-monotonic alignment.\nExtensive experiments on semi-synthetic and real datasets show that our\nalgorithm outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 06:51:01 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 20:51:32 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Dogan", "Pelin", ""], ["Li", "Boyang", ""], ["Sigal", "Leonid", ""], ["Gross", "Markus", ""]]}, {"id": "1803.00067", "submitter": "Alan Mackey", "authors": "Alan Mackey, Xiyang Luo, Elad Eban", "title": "Constrained Classification and Ranking via Quantiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most machine learning applications, classification accuracy is not the\nprimary metric of interest. Binary classifiers which face class imbalance are\noften evaluated by the $F_\\beta$ score, area under the precision-recall curve,\nPrecision at K, and more. The maximization of many of these metrics can be\nexpressed as a constrained optimization problem, where the constraint is a\nfunction of the classifier's predictions.\n  In this paper we propose a novel framework for learning with constraints that\ncan be expressed as a predicted positive rate (or negative rate) on a subset of\nthe training data. We explicitly model the threshold at which a classifier must\noperate to satisfy the constraint, yielding a surrogate loss function which\navoids the complexity of constrained optimization. The method is model-agnostic\nand only marginally more expensive than minimization of the unconstrained loss.\nExperiments on a variety of benchmarks show competitive performance relative to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 20:23:10 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mackey", "Alan", ""], ["Luo", "Xiyang", ""], ["Eban", "Elad", ""]]}, {"id": "1803.00092", "submitter": "Markus Haltmeier", "authors": "Housen Li, Johannes Schwab, Stephan Antholzer, Markus Haltmeier", "title": "NETT: Solving Inverse Problems with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a function or high-dimensional parameter vector from indirect\nmeasurements is a central task in various scientific areas. Several methods for\nsolving such inverse problems are well developed and well understood. Recently,\nnovel algorithms using deep learning and neural networks for inverse problems\nappeared. While still in their infancy, these techniques show astonishing\nperformance for applications like low-dose CT or various sparse data problems.\nHowever, there are few theoretical results for deep learning in inverse\nproblems. In this paper, we establish a complete convergence analysis for the\nproposed NETT (Network Tikhonov) approach to inverse problems. NETT considers\ndata consistent solutions having small value of a regularizer defined by a\ntrained neural network. We derive well-posedness results and quantitative error\nestimates, and propose a possible strategy for training the regularizer. Our\ntheoretical results and framework are different from any previous work using\nneural networks for solving inverse problems. A possible data driven\nregularizer is proposed. Numerical results are presented for a tomographic\nsparse data problem, which demonstrate good performance of NETT even for\nunknowns of different type from the training data. To derive the convergence\nand convergence rates results we introduce a new framework based on the\nabsolute Bregman distance generalizing the standard Bregman distance from the\nconvex to the non-convex case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:23:22 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 10:39:04 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 17:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Li", "Housen", ""], ["Schwab", "Johannes", ""], ["Antholzer", "Stephan", ""], ["Haltmeier", "Markus", ""]]}, {"id": "1803.00094", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein", "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision\n  Regions", "comments": "Accepted at ICML 2018. Added discussion for non-pyramidal networks\n  and ReLU activation function", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature the important role of depth in deep learning has\nbeen emphasized. In this paper we argue that sufficient width of a feedforward\nnetwork is equally important by answering the simple question under which\nconditions the decision regions of a neural network are connected. It turns out\nthat for a class of activation functions including leaky ReLU, neural networks\nhaving a pyramidal structure, that is no layer has more hidden units than the\ninput dimension, produce necessarily connected decision regions. This implies\nthat a sufficiently wide hidden layer is necessary to guarantee that the\nnetwork can produce disconnected decision regions. We discuss the implications\nof this result for the construction of neural networks, in particular the\nrelation to the problem of adversarial manipulation of classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:28:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 10:47:26 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 09:14:57 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1803.00101", "submitter": "Vladimir Feinberg", "authors": "Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael I. Jordan, Joseph E.\n  Gonzalez, Sergey Levine", "title": "Model-Based Value Estimation for Efficient Model-Free Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent model-free reinforcement learning algorithms have proposed\nincorporating learned dynamics models as a source of additional data with the\nintention of reducing sample complexity. Such methods hold the promise of\nincorporating imagined data coupled with a notion of model uncertainty to\naccelerate the learning of continuous control tasks. Unfortunately, they rely\non heuristics that limit usage of the dynamics model. We present model-based\nvalue expansion, which controls for uncertainty in the model by only allowing\nimagination to fixed depth. By enabling wider use of learned dynamics models\nwithin a model-free reinforcement learning algorithm, we improve value\nestimation, which, in turn, reduces the sample complexity of learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:43:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Feinberg", "Vladimir", ""], ["Wan", "Alvin", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.00111", "submitter": "Karen Sun", "authors": "Shane Mooney, Karen Sun, Eric Bomgardner", "title": "Predicting Recall Probability to Adaptively Prioritize Study", "comments": "From the NIPS 2017 Teaching Machines workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Students have a limited time to study and are typically ineffective at\nallocating study time. Machine-directed study strategies that identify which\nitems need reinforcement and dictate the spacing of repetition have been shown\nto help students optimize mastery (Mozer & Lindsey 2017). The large volume of\nresearch on this matter is typically conducted in constructed experimental\nsettings with fixed instruction, content, and scheduling; in contrast, we aim\nto develop methods that can address any demographic, subject matter, or study\nschedule. We show two methods that model item-specific recall probability for\nuse in a discrepancy-reduction instruction strategy. The first model predicts\nitem recall probability using a multiple logistic regression (MLR) model based\non previous answer correctness and temporal spacing of study. Prompted by\nliterature suggesting that forgetting is better modeled by the power law than\nan exponential decay (Wickelgren 1974), we compare the MLR approach with a\nRecurrent Power Law (RPL) model which adaptively fits a forgetting curve. We\nthen discuss the performance of these models against study datasets comprised\nof millions of answers and show that the RPL approach is more accurate and\nflexible than the MLR model. Finally, we give an overview of promising future\napproaches to knowledge modeling.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:14:38 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mooney", "Shane", ""], ["Sun", "Karen", ""], ["Bomgardner", "Eric", ""]]}, {"id": "1803.00113", "submitter": "Jeffrey Regier", "authors": "Jeffrey Regier, Andrew C. Miller, David Schlegel, Ryan P. Adams, Jon\n  D. McAuliffe, and Prabhat", "title": "Approximate Inference for Constructing Astronomical Catalogs from Images", "comments": "accepted to the Annals of Applied Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, fully generative model for constructing astronomical\ncatalogs from optical telescope image sets. Each pixel intensity is treated as\na random variable with parameters that depend on the latent properties of stars\nand galaxies. These latent properties are themselves modeled as random. We\ncompare two procedures for posterior inference. One procedure is based on\nMarkov chain Monte Carlo (MCMC) while the other is based on variational\ninference (VI). The MCMC procedure excels at quantifying uncertainty, while the\nVI procedure is 1000 times faster. On a supercomputer, the VI procedure\nefficiently uses 665,000 CPU cores to construct an astronomical catalog from 50\nterabytes of images in 14.6 minutes, demonstrating the scaling characteristics\nnecessary to construct catalogs for upcoming astronomical surveys.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:15:48 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 19:35:56 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 03:23:29 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Regier", "Jeffrey", ""], ["Miller", "Andrew C.", ""], ["Schlegel", "David", ""], ["Adams", "Ryan P.", ""], ["McAuliffe", "Jon D.", ""], ["Prabhat", "", ""]]}, {"id": "1803.00114", "submitter": "James Sharpnack", "authors": "Liwei Wu, Cho-Jui Hsieh, James Sharpnack", "title": "SQL-Rank: A Listwise Approach to Collaborative Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a listwise approach for constructing user-specific\nrankings in recommendation systems in a collaborative fashion. We contrast the\nlistwise approach to previous pointwise and pairwise approaches, which are\nbased on treating either each rating or each pairwise comparison as an\nindependent instance respectively. By extending the work of (Cao et al. 2007),\nwe cast listwise collaborative ranking as maximum likelihood under a\npermutation model which applies probability mass to permutations based on a low\nrank latent score matrix. We present a novel algorithm called SQL-Rank, which\ncan accommodate ties and missing data and can run in linear time. We develop a\ntheoretical framework for analyzing listwise ranking methods based on a novel\nrepresentation theory for the permutation model. Applying this framework to\ncollaborative ranking, we derive asymptotic statistical rates as the number of\nusers and items grow together. We conclude by demonstrating that our SQL-Rank\nmethod often outperforms current state-of-the-art algorithms for implicit\nfeedback such as Weighted-MF and BPR and achieve favorable results when\ncompared to explicit feedback algorithms such as matrix factorization and\ncollaborative ranking.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:26:43 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:19:57 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 22:22:55 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wu", "Liwei", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1803.00116", "submitter": "Benito van der Zander", "authors": "Benito van der Zander (1), Maciej Li\\'skiewicz (1), Johannes Textor\n  (2) ((1) Institute for Theoretical Computer Science, Universit\\\"at zu\n  L\\\"ubeck, Germany, (2) Institute for Computing and Information Sciences,\n  Radboud University Nijmegen, Nijmegen, The Netherlands)", "title": "Separators and Adjustment Sets in Causal Graphs: Complete Criteria and\n  an Algorithmic Framework", "comments": "52 pages, 20 figures, 12 tables", "journal-ref": "Artificial Intelligence 270 (2019) 1-40", "doi": "10.1016/j.artint.2018.12.006", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principled reasoning about the identifiability of causal effects from\nnon-experimental data is an important application of graphical causal models.\nThis paper focuses on effects that are identifiable by covariate adjustment, a\ncommonly used estimation approach. We present an algorithmic framework for\nefficiently testing, constructing, and enumerating $m$-separators in ancestral\ngraphs (AGs), a class of graphical causal models that can represent uncertainty\nabout the presence of latent confounders. Furthermore, we prove a reduction\nfrom causal effect identification by covariate adjustment to $m$-separation in\na subgraph for directed acyclic graphs (DAGs) and maximal ancestral graphs\n(MAGs). Jointly, these results yield constructive criteria that characterize\nall adjustment sets as well as all minimal and minimum adjustment sets for\nidentification of a desired causal effect with multivariate exposures and\noutcomes in the presence of latent confounding. Our results extend several\nexisting solutions for special cases of these problems. Our efficient\nalgorithms allowed us to empirically quantify the identifiability gap between\ncovariate adjustment and the do-calculus in random DAGs and MAGs, covering a\nwide range of scenarios. Implementations of our algorithms are provided in the\nR package dagitty.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:28:08 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 15:42:44 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 16:33:53 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["van der Zander", "Benito", ""], ["Li\u015bkiewicz", "Maciej", ""], ["Textor", "Johannes", ""]]}, {"id": "1803.00144", "submitter": "Trieu Trinh", "authors": "Trieu H. Trinh, Andrew M. Dai, Minh-Thang Luong, Quoc V. Le", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in training recurrent neural networks (RNNs),\ncapturing long-term dependencies in sequences remains a fundamental challenge.\nMost approaches use backpropagation through time (BPTT), which is difficult to\nscale to very long sequences. This paper proposes a simple method that improves\nthe ability to capture long term dependencies in RNNs by adding an unsupervised\nauxiliary loss to the original objective. This auxiliary loss forces RNNs to\neither reconstruct previous events or predict next events in a sequence, making\ntruncated backpropagation feasible for long sequences and also improving full\nBPTT. We evaluate our method on a variety of settings, including pixel-by-pixel\nimage classification with sequence lengths up to 16\\,000, and a real document\nclassification benchmark. Our results highlight good performance and resource\nefficiency of this approach over competitive baselines, including other\nrecurrent models and a comparable sized Transformer. Further analyses reveal\nbeneficial effects of the auxiliary loss on optimization and regularization, as\nwell as extreme cases where there is little to no backpropagation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 00:28:07 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:49:15 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 08:35:57 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Trinh", "Trieu H.", ""], ["Dai", "Andrew M.", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "1803.00149", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Deep Learning for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep learning techniques for econometrics,\nspecifically for causal inference and for estimating individual as well as\naverage treatment effects. The contribution of this paper is twofold: 1. For\ngeneralized neighbor matching to estimate individual and average treatment\neffects, we analyze the use of autoencoders for dimensionality reduction while\nmaintaining the local neighborhood structure among the data points in the\nembedding space. This deep learning based technique is shown to perform better\nthan simple k nearest neighbor matching for estimating treatment effects,\nespecially when the data points have several features/covariates but reside in\na low dimensional manifold in high dimensional space. We also observe better\nperformance than manifold learning methods for neighbor matching. 2. Propensity\nscore matching is one specific and popular way to perform matching in order to\nestimate average and individual treatment effects. We propose the use of deep\nneural networks (DNNs) for propensity score matching, and present a network\ncalled PropensityNet for this. This is a generalization of the logistic\nregression technique traditionally used to estimate propensity scores and we\nshow empirically that DNNs perform better than logistic regression at\npropensity score matching. Code for both methods will be made available shortly\non Github at: https://github.com/vikas84bf\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:01:16 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1803.00156", "submitter": "Eric Korman", "authors": "Eric O. Korman", "title": "Autoencoding topology", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning a manifold structure on a dataset is framed in terms\nof a generative model, to which we use ideas behind autoencoders (namely\nadversarial/Wasserstein autoencoders) to fit deep neural networks. From a\nmachine learning perspective, the resulting structure, an atlas of a manifold,\nmay be viewed as a combination of dimensionality reduction and \"fuzzy\"\nclustering.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:35:27 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Korman", "Eric O.", ""]]}, {"id": "1803.00158", "submitter": "Guihua Wen", "authors": "Li Huihui and Wen Guihua", "title": "Modeling reverse thinking for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human inertial thinking schemes can be formed through learning, which are\nthen applied to quickly solve similar problems later. However, when problems\nare significantly different, inertial thinking generally presents the solutions\nthat are definitely imperfect. In such cases, people will apply creative\nthinking, such as reverse thinking, to solve problems. Similarly, machine\nlearning methods also form inertial thinking schemes through learning the\nknowledge from a large amount of data. However, when the testing data are\nvastly difference, the formed inertial thinking schemes will inevitably\ngenerate errors. This kind of inertial thinking is called illusion inertial\nthinking. Because all machine learning methods do not consider illusion\ninertial thinking, in this paper we propose a new method that uses reverse\nthinking to correct illusion inertial thinking, which increases the\ngeneralization ability of machine learning methods. Experimental results on\nbenchmark datasets are used to validate the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:45:30 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Huihui", "Li", ""], ["Guihua", "Wen", ""]]}, {"id": "1803.00162", "submitter": "Weixun Wang", "authors": "Weixun Wang, Jianye Hao, Yixi Wang, Matthew Taylor", "title": "Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent\n  Reinforcement Learning Approach", "comments": "13 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Iterated Prisoner's Dilemma has guided research on social dilemmas for\ndecades. However, it distinguishes between only two atomic actions: cooperate\nand defect. In real-world prisoner's dilemmas, these choices are temporally\nextended and different strategies may correspond to sequences of actions,\nreflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma\n(SPD) game to better capture the aforementioned characteristics. In this work,\nwe propose a deep multiagent reinforcement learning approach that investigates\nthe evolution of mutual cooperation in SPD games. Our approach consists of two\nphases. The first phase is offline: it synthesizes policies with different\ncooperation degrees and then trains a cooperation degree detection network. The\nsecond phase is online: an agent adaptively selects its policy based on the\ndetected degree of opponent cooperation. The effectiveness of our approach is\ndemonstrated in two representative SPD 2D games: the Apple-Pear game and the\nFruit Gathering game. Experimental results show that our strategy can avoid\nbeing exploited by exploitative opponents and achieve cooperation with\ncooperative opponents.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:53:52 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Wang", "Weixun", ""], ["Hao", "Jianye", ""], ["Wang", "Yixi", ""], ["Taylor", "Matthew", ""]]}, {"id": "1803.00183", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Yiming Ying", "title": "Learning with Correntropy-induced Losses for Regression with Mixture of\n  Symmetric Stable Noise", "comments": null, "journal-ref": null, "doi": "10.1016/j.acha.2019.09.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, correntropy and its applications in machine learning have\nbeen drawing continuous attention owing to its merits in dealing with\nnon-Gaussian noise and outliers. However, theoretical understanding of\ncorrentropy, especially in the statistical learning context, is still limited.\nIn this study, within the statistical learning framework, we investigate\ncorrentropy based regression in the presence of non-Gaussian noise or outliers.\nMotivated by the practical way of generating non-Gaussian noise or outliers, we\nintroduce mixture of symmetric stable noise, which include Gaussian noise,\nCauchy noise, and their mixture as special cases, to model non-Gaussian noise\nor outliers. We demonstrate that under the mixture of symmetric stable noise\nassumption, correntropy based regression can learn the conditional mean\nfunction or the conditional median function well without resorting to the\nfinite-variance or even the finite first-order moment condition on the noise.\nIn particular, for the above two cases, we establish asymptotic optimal\nlearning rates for correntropy based regression estimators that are\nasymptotically of type $\\mathcal{O}(n^{-1})$. These results justify the\neffectiveness of the correntropy based regression estimators in dealing with\noutliers as well as non-Gaussian noise. We believe that the present study\ncompletes our understanding towards correntropy based regression from a\nstatistical learning viewpoint, and may also shed some light on robust\nstatistical learning for regression.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:01:54 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 01:13:10 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2018 01:20:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 01:47:58 GMT"}, {"version": "v5", "created": "Thu, 5 Sep 2019 03:27:09 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Feng", "Yunlong", ""], ["Ying", "Yiming", ""]]}, {"id": "1803.00184", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou", "title": "Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble of neural networks is known to be more robust and accurate than\nan individual network, however usually with linearly-increased cost in both\ntraining and testing. In this work, we propose a two-stage method to learn\nSparse Structured Ensembles (SSEs) for neural networks. In the first stage, we\nrun SG-MCMC with group sparse priors to draw an ensemble of samples from the\nposterior distribution of network parameters. In the second stage, we apply\nweight-pruning to each sampled network and then perform retraining over the\nremained connections. In this way of learning SSEs with SG-MCMC and pruning, we\nnot only achieve high prediction accuracy since SG-MCMC enhances exploration of\nthe model-parameter space, but also reduce memory and computation cost\nsignificantly in both training and testing of NN ensembles. This is thoroughly\nevaluated in the experiments of learning SSE ensembles of both FNNs and LSTMs.\nFor example, in LSTM based language modeling (LM), we obtain 21% relative\nreduction in LM perplexity by learning a SSE of 4 large LSTM models, which has\nonly 30% of model parameters and 70% of computations in total, as compared to\nthe baseline large LSTM LM. To the best of our knowledge, this work represents\nthe first methodology and empirical study of integrating SG-MCMC, group sparse\nprior and network pruning together for learning NN ensembles.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:03:53 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 09:43:05 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 08:28:20 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""]]}, {"id": "1803.00186", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Nicolas Boumal, Prateek Jain, Praneeth\n  Netrapalli", "title": "Smoothed analysis for low-rank solutions to semidefinite programs in\n  quadratic penalty form", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programs (SDP) are important in learning and combinatorial\noptimization with numerous applications. In pursuit of low-rank solutions and\nlow complexity algorithms, we consider the Burer--Monteiro factorization\napproach for solving SDPs. We show that all approximate local optima are global\noptima for the penalty formulation of appropriately rank-constrained SDPs as\nlong as the number of constraints scales sub-quadratically with the desired\nrank of the optimal solution. Our result is based on a simple penalty function\nformulation of the rank-constrained SDP along with a smoothed analysis to avoid\nworst-case cost matrices. We particularize our results to two applications,\nnamely, Max-Cut and matrix completion.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:11:11 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Boumal", "Nicolas", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1803.00195", "submitter": "Jingfeng Wu", "authors": "Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, Jinwen Ma", "title": "The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of\n  Escaping from Sharp Minima and Regularization Effects", "comments": "ICML 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the behavior of stochastic gradient descent (SGD) in the\ncontext of deep neural networks has raised lots of concerns recently. Along\nthis line, we study a general form of gradient based optimization dynamics with\nunbiased noise, which unifies SGD and standard Langevin dynamics. Through\ninvestigating this general optimization dynamics, we analyze the behavior of\nSGD on escaping from minima and its regularization effects. A novel indicator\nis derived to characterize the efficiency of escaping from minima through\nmeasuring the alignment of noise covariance and the curvature of loss function.\nBased on this indicator, two conditions are established to show which type of\nnoise structure is superior to isotropic noise in term of escaping efficiency.\nWe further show that the anisotropic noise in SGD satisfies the two conditions,\nand thus helps to escape from sharp and poor minima effectively, towards more\nstable and flat minima that typically generalize well. We systematically design\nvarious experiments to verify the benefits of the anisotropic noise, compared\nwith full gradient descent plus isotropic diffusion (i.e. Langevin dynamics).\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:46:36 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 10:19:15 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 08:16:16 GMT"}, {"version": "v4", "created": "Mon, 21 May 2018 15:01:58 GMT"}, {"version": "v5", "created": "Mon, 10 Jun 2019 05:19:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhu", "Zhanxing", ""], ["Wu", "Jingfeng", ""], ["Yu", "Bing", ""], ["Wu", "Lei", ""], ["Ma", "Jinwen", ""]]}, {"id": "1803.00196", "submitter": "Roberto Calandra", "authors": "Brian Yang, Grant Wang, Roberto Calandra, Daniel Contreras, Sergey\n  Levine and Kristofer Pister", "title": "Learning Flexible and Reusable Locomotion Primitives for a Microrobot", "comments": "8 pages. Accepted at RAL+ICRA2018", "journal-ref": null, "doi": "10.1109/LRA.2018.2806083", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of gaits for robot locomotion can be a daunting process which\nrequires significant expert knowledge and engineering. This process is even\nmore challenging for robots that do not have an accurate physical model, such\nas compliant or micro-scale robots. Data-driven gait optimization provides an\nautomated alternative to analytical gait design. In this paper, we propose a\nnovel approach to efficiently learn a wide range of locomotion tasks with\nwalking robots. This approach formalizes locomotion as a contextual policy\nsearch task to collect data, and subsequently uses that data to learn\nmulti-objective locomotion primitives that can be used for planning. As a\nproof-of-concept we consider a simulated hexapod modeled after a recently\ndeveloped microrobot, and we thoroughly evaluate the performance of this\nmicrorobot on different tasks and gaits. Our results validate the proposed\ncontroller and learning scheme on single and multi-objective locomotion tasks.\nMoreover, the experimental simulations show that without any prior knowledge\nabout the robot used (e.g., dynamics model), our approach is capable of\nlearning locomotion primitives within 250 trials and subsequently using them to\nsuccessfully navigate through a maze.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:48:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Yang", "Brian", ""], ["Wang", "Grant", ""], ["Calandra", "Roberto", ""], ["Contreras", "Daniel", ""], ["Levine", "Sergey", ""], ["Pister", "Kristofer", ""]]}, {"id": "1803.00204", "submitter": "Chen Wang", "authors": "Chen Wang, Xiaomei Yang, Shaomin Fei, Kai Zhou, Xiaofeng Gong, Miao\n  Du, Ruisen Luo", "title": "Scalar Quantization as Sparse Least Square Optimization", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": "10.1109/TPAMI.2019.2952096", "report-no": null, "categories": "cs.LG cs.AI cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantization can be used to form new vectors/matrices with shared values\nclose to the original. In recent years, the popularity of scalar quantization\nfor value-sharing applications has been soaring as it has been found huge\nutilities in reducing the complexity of neural networks. Existing\nclustering-based quantization techniques, while being well-developed, have\nmultiple drawbacks including the dependency of the random seed, empty or\nout-of-the-range clusters, and high time complexity for a large number of\nclusters. To overcome these problems, in this paper, the problem of scalar\nquantization is examined from a new perspective, namely sparse least square\noptimization. Specifically, inspired by the property of sparse least square\nregression, several quantization algorithms based on $l_1$ least square are\nproposed. In addition, similar schemes with $l_1 + l_2$ and $l_0$\nregularization are proposed. Furthermore, to compute quantization results with\na given amount of values/clusters, this paper designed an iterative method and\na clustering-based method, and both of them are built on sparse least square.\nThe paper shows that the latter method is mathematically equivalent to an\nimproved version of k-means clustering-based quantization algorithm, although\nthe two algorithms originated from different intuitions. The algorithms\nproposed were tested with three types of data and their computational\nperformances, including information loss, time consumption, and the\ndistribution of the values of the sparse vectors, were compared and analyzed.\nThe paper offers a new perspective to probe the area of quantization, and the\nalgorithms proposed can outperform existing methods especially under some\nbit-width reduction scenarios, when the required post-quantization resolution\n(number of values) is not significantly lower than the original number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:07:40 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 16:24:26 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:32:25 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 04:12:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Chen", ""], ["Yang", "Xiaomei", ""], ["Fei", "Shaomin", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Du", "Miao", ""], ["Luo", "Ruisen", ""]]}, {"id": "1803.00212", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler, Philip Schniter, Ashok Veeraraghavan, Richard\n  G. Baraniuk", "title": "prDeep: Robust Phase Retrieval with a Flexible Deep Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase retrieval algorithms have become an important component in many modern\ncomputational imaging systems. For instance, in the context of ptychography and\nspeckle correlation imaging, they enable imaging past the diffraction limit and\nthrough scattering media, respectively. Unfortunately, traditional phase\nretrieval algorithms struggle in the presence of noise. Progress has been made\nrecently on more robust algorithms using signal priors, but at the expense of\nlimiting the range of supported measurement models (e.g., to Gaussian or coded\ndiffraction patterns). In this work we leverage the regularization-by-denoising\nframework and a convolutional neural network denoiser to create prDeep, a new\nphase retrieval algorithm that is both robust and broadly applicable. We test\nand validate prDeep in simulation to demonstrate that it is robust to noise and\ncan handle a variety of system models.\n  A MatConvNet implementation of prDeep is available at\nhttps://github.com/ricedsp/prDeep.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:56:54 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 18:12:34 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Schniter", "Philip", ""], ["Veeraraghavan", "Ashok", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1803.00218", "submitter": "Ichiro Takeuchi Prof.", "authors": "Hiroyuki Hanada, Toshiyuki Takada, Jun Sakuma and Ichiro Takeuchi", "title": "Interval-based Prediction Uncertainty Bound Computation in Learning with\n  Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of machine learning with missing values is common in many areas.\nA simple approach is to first construct a dataset without missing values simply\nby discarding instances with missing entries or by imputing a fixed value for\neach missing entry, and then train a prediction model with the new dataset. A\ndrawback of this naive approach is that the uncertainty in the missing entries\nis not properly incorporated in the prediction. In order to evaluate prediction\nuncertainty, the multiple imputation (MI) approach has been studied, but the\nperformance of MI is sensitive to the choice of the probabilistic model of the\ntrue values in the missing entries, and the computational cost of MI is high\nbecause multiple models must be trained. In this paper, we propose an\nalternative approach called the Interval-based Prediction Uncertainty Bounding\n(IPUB) method. The IPUB method represents the uncertainties due to missing\nentries as intervals, and efficiently computes the lower and upper bounds of\nthe prediction results when all possible training sets constructed by imputing\narbitrary values in the intervals are considered. The IPUB method can be\napplied to a wide class of convex learning algorithms including penalized\nleast-squares regression, support vector machine (SVM), and logistic\nregression. We demonstrate the advantages of the IPUB method by comparing it\nwith an existing method in numerical experiment with benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 05:31:38 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Hanada", "Hiroyuki", ""], ["Takada", "Toshiyuki", ""], ["Sakuma", "Jun", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1803.00225", "submitter": "Tim Tsz-Kit Lau", "authors": "Jinshan Zeng, Tim Tsz-Kit Lau, Shaobo Lin, Yuan Yao", "title": "Global Convergence of Block Coordinate Descent in Deep Learning", "comments": "27 pages, 2 figures", "journal-ref": "Proceeding of the 36th International Conference on Machine\n  Learning (ICML), 2019", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has aroused extensive attention due to its great empirical\nsuccess. The efficiency of the block coordinate descent (BCD) methods has been\nrecently demonstrated in deep neural network (DNN) training. However,\ntheoretical studies on their convergence properties are limited due to the\nhighly nonconvex nature of DNN training. In this paper, we aim at providing a\ngeneral methodology for provable convergence guarantees for this type of\nmethods. In particular, for most of the commonly used DNN training models\ninvolving both two- and three-splitting schemes, we establish the global\nconvergence to a critical point at a rate of ${\\cal O}(1/k)$, where $k$ is the\nnumber of iterations. The results extend to general loss functions which have\nLipschitz continuous gradients and deep residual networks (ResNets). Our key\ndevelopment adds several new elements to the Kurdyka-{\\L}ojasiewicz inequality\nframework that enables us to carry out the global convergence analysis of BCD\nin the general scenario of deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:11:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 08:46:46 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 07:47:35 GMT"}, {"version": "v4", "created": "Sun, 12 May 2019 12:24:53 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zeng", "Jinshan", ""], ["Lau", "Tim Tsz-Kit", ""], ["Lin", "Shaobo", ""], ["Yao", "Yuan", ""]]}, {"id": "1803.00227", "submitter": "Asit Mishra", "authors": "Asit Mishra and Debbie Marr", "title": "WRPN & Apprentice: Methods for Training and Inference using\n  Low-Precision Numerics", "comments": "Tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today's high performance deep learning architectures involve large models\nwith numerous parameters. Low precision numerics has emerged as a popular\ntechnique to reduce both the compute and memory requirements of these large\nmodels. However, lowering precision often leads to accuracy degradation. We\ndescribe three schemes whereby one can both train and do efficient inference\nusing low precision numerics without hurting accuracy. Finally, we describe an\nefficient hardware accelerator that can take advantage of the proposed low\nprecision numerics.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:22:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mishra", "Asit", ""], ["Marr", "Debbie", ""]]}, {"id": "1803.00232", "submitter": "Alexandre Thiery", "authors": "Sripad Krishna Devalla, Prajwal K. Renukanand, Bharathwaj K. Sreedhar,\n  Shamira Perera, Jean-Martial Mari, Khai Sing Chin, Tin A. Tun, Nicholas G.\n  Strouthidis, Tin Aung, Alexandre H. Thiery, Michael J. A. Girard", "title": "DRUNET: A Dilated-Residual U-Net Deep Learning Network to Digitally\n  Stain Optic Nerve Head Tissues in Optical Coherence Tomography Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that the neural and connective tissues of the optic nerve head (ONH)\nexhibit complex morphological changes with the development and progression of\nglaucoma, their simultaneous isolation from optical coherence tomography (OCT)\nimages may be of great interest for the clinical diagnosis and management of\nthis pathology. A deep learning algorithm was designed and trained to digitally\nstain (i.e. highlight) 6 ONH tissue layers by capturing both the local (tissue\ntexture) and contextual information (spatial arrangement of tissues). The\noverall dice coefficient (mean of all tissues) was $0.91 \\pm 0.05$ when\nassessed against manual segmentations performed by an expert observer. We offer\nhere a robust segmentation framework that could be extended for the automated\nparametric study of the ONH tissues.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:37:30 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Devalla", "Sripad Krishna", ""], ["Renukanand", "Prajwal K.", ""], ["Sreedhar", "Bharathwaj K.", ""], ["Perera", "Shamira", ""], ["Mari", "Jean-Martial", ""], ["Chin", "Khai Sing", ""], ["Tun", "Tin A.", ""], ["Strouthidis", "Nicholas G.", ""], ["Aung", "Tin", ""], ["Thiery", "Alexandre H.", ""], ["Girard", "Michael J. A.", ""]]}, {"id": "1803.00250", "submitter": "Alain Rakotomamonjy", "authors": "Alain Rakotomamonjy (LITIS), Abraham Traor\\'e (LITIS), Maxime Berar\n  (LITIS), R\\'emi Flamary (OCA), Nicolas Courty (OBELIX, PANAMA)", "title": "Distance Measure Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distance-based discriminative framework for learning\nwith probability distributions. Instead of using kernel mean embeddings or\ngeneralized radial basis kernels, we introduce embeddings based on\ndissimilarity of distributions to some reference distributions denoted as\ntemplates. Our framework extends the theory of similarity of Balcan et al.\n(2008) to the population distribution case and we show that, for some learning\nproblems, some dissimilarity on distribution achieves low-error linear decision\nfunctions with high probability. Our key result is to prove that the theory\nalso holds for empirical distributions. Algorithmically, the proposed approach\nconsists in computing a mapping based on pairwise dissimilarity where learning\na linear decision function is amenable. Our experimental results show that the\nWasserstein distance embedding performs better than kernel mean embeddings and\ncomputing Wasserstein distance is far more tractable than estimating pairwise\nKullback-Leibler divergence of empirical distributions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 08:51:01 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 14:40:56 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 13:54:10 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Rakotomamonjy", "Alain", "", "LITIS"], ["Traor\u00e9", "Abraham", "", "LITIS"], ["Berar", "Maxime", "", "LITIS"], ["Flamary", "R\u00e9mi", "", "OCA"], ["Courty", "Nicolas", "", "OBELIX, PANAMA"]]}, {"id": "1803.00276", "submitter": "Faicel Chamroukhi", "authors": "Faicel Chamroukhi, Hien D. Nguyen", "title": "Model-Based Clustering and Classification of Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of complex data analysis is a central topic of modern statistical\nscience and learning systems and is becoming of broader interest with the\nincreasing prevalence of high-dimensional data. The challenge is to develop\nstatistical models and autonomous algorithms that are able to acquire knowledge\nfrom raw data for exploratory analysis, which can be achieved through\nclustering techniques or to make predictions of future data via classification\n(i.e., discriminant analysis) techniques. Latent data models, including mixture\nmodel-based approaches are one of the most popular and successful approaches in\nboth the unsupervised context (i.e., clustering) and the supervised one (i.e,\nclassification or discrimination). Although traditionally tools of multivariate\nanalysis, they are growing in popularity when considered in the framework of\nfunctional data analysis (FDA). FDA is the data analysis paradigm in which the\nindividual data units are functions (e.g., curves, surfaces), rather than\nsimple vectors. In many areas of application, the analyzed data are indeed\noften available in the form of discretized values of functions or curves (e.g.,\ntime series, waveforms) and surfaces (e.g., 2d-images, spatio-temporal data).\nThis functional aspect of the data adds additional difficulties compared to the\ncase of a classical multivariate (non-functional) data analysis. We review and\npresent approaches for model-based clustering and classification of functional\ndata. We derive well-established statistical models along with efficient\nalgorithmic tools to address problems regarding the clustering and the\nclassification of these high-dimensional data, including their heterogeneity,\nmissing information, and dynamical hidden structure. The presented models and\nalgorithms are illustrated on real-world functional data analysis problems from\nseveral application area.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 10:02:13 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 04:03:28 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chamroukhi", "Faicel", ""], ["Nguyen", "Hien D.", ""]]}, {"id": "1803.00310", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Gavin Brown", "title": "Minimax rates for cost-sensitive learning on manifolds with approximate\n  nearest neighbours", "comments": "Published in ALT 2017", "journal-ref": "Algorithmic Learning Theory 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximate nearest neighbour method for cost-sensitive\nclassification on low-dimensional manifolds embedded within a high-dimensional\nfeature space. We determine the minimax learning rates for distributions on a\nsmooth manifold, in a cost-sensitive setting. This generalises a classic result\nof Audibert and Tsybakov. Building upon recent work of Chaudhuri and Dasgupta\nwe prove that these minimax rates are attained by the approximate nearest\nneighbour algorithm, where neighbours are computed in a randomly projected\nlow-dimensional space. In addition, we give a bound on the number of dimensions\nrequired for the projection which depends solely upon the reach and dimension\nof the manifold, combined with the regularity of the marginal.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 11:26:34 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Brown", "Gavin", ""]]}, {"id": "1803.00314", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Gavin Brown", "title": "Diversity and degrees of freedom in regression ensembles", "comments": "Neurocomputing 2018", "journal-ref": "Neurocomputing 2018", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods are a cornerstone of modern machine learning. The\nperformance of an ensemble depends crucially upon the level of diversity\nbetween its constituent learners. This paper establishes a connection between\ndiversity and degrees of freedom (i.e. the capacity of the model), showing that\ndiversity may be viewed as a form of inverse regularisation. This is achieved\nby focusing on a previously published algorithm Negative Correlation Learning\n(NCL), in which model diversity is explicitly encouraged through a diversity\npenalty term in the loss function. We provide an exact formula for the\neffective degrees of freedom in an NCL ensemble with fixed basis functions,\nshowing that it is a continuous, convex and monotonically increasing function\nof the diversity parameter. We demonstrate a connection to Tikhonov\nregularisation and show that, with an appropriately chosen diversity parameter,\nan NCL ensemble can always outperform the unregularised ensemble in the\npresence of noise. We demonstrate the practical utility of our approach by\nderiving a method to efficiently tune the diversity parameter. Finally, we use\na Monte-Carlo estimator to extend the connection between diversity and degrees\nof freedom to ensembles of deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 11:38:49 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Brown", "Gavin", ""]]}, {"id": "1803.00316", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Joe Mellor, Gavin Brown", "title": "The K-Nearest Neighbour UCB algorithm for multi-armed bandits with\n  covariates", "comments": "To be presented at ALT 2018", "journal-ref": "Algorithmic Learning Theory 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and explore the k-Nearest Neighbour UCB algorithm\nfor multi-armed bandits with covariates. We focus on a setting where the\ncovariates are supported on a metric space of low intrinsic dimension, such as\na manifold embedded within a high dimensional ambient feature space. The\nalgorithm is conceptually simple and straightforward to implement. The\nk-Nearest Neighbour UCB algorithm does not require prior knowledge of the\neither the intrinsic dimension of the marginal distribution or the time\nhorizon. We prove a regret bound for the k-Nearest Neighbour UCB algorithm\nwhich is minimax optimal up to logarithmic factors. In particular, the\nalgorithm automatically takes advantage of both low intrinsic dimensionality of\nthe marginal distribution over the covariates and low noise in the data,\nexpressed as a margin condition. In addition, focusing on the case of bounded\nrewards, we give corresponding regret bounds for the k-Nearest Neighbour KL-UCB\nalgorithm, which is an analogue of the KL-UCB algorithm adapted to the setting\nof multi-armed bandits with covariates. Finally, we present empirical results\nwhich demonstrate the ability of both the k-Nearest Neighbour UCB and k-Nearest\nNeighbour KL-UCB to take advantage of situations where the data is supported on\nan unknown sub-manifold of a high-dimensional feature space.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 11:41:13 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Mellor", "Joe", ""], ["Brown", "Gavin", ""]]}, {"id": "1803.00397", "submitter": "Evgeny Burnaev", "authors": "Alexey Trekin and German Novikov and Georgy Potapov and Vladimir\n  Ignatiev and Evgeny Burnaev", "title": "Satellite imagery analysis for operational damage assessment in\n  Emergency situations", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When major disaster occurs the questions are raised how to estimate the\ndamage in time to support the decision making process and relief efforts by\nlocal authorities or humanitarian teams. In this paper we consider the use of\nMachine Learning and Computer Vision on remote sensing imagery to improve time\nefficiency of assessment of damaged buildings in disaster affected area. We\npropose a general workflow that can be useful in various disaster management\napplications, and demonstrate the use of the proposed workflow for the\nassessment of the damage caused by the wildfires in California in 2017.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 08:04:25 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Trekin", "Alexey", ""], ["Novikov", "German", ""], ["Potapov", "Georgy", ""], ["Ignatiev", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1803.00399", "submitter": "Siming Yan", "authors": "Siming Yan, Feng Shi, Yuhua Chen, Damini Dey, Sang-Eun Lee, Hyuk-Jae\n  Chang, Debiao Li, Yibin Xie", "title": "Calcium Removal From Cardiac CT Images Using Deep Convolutional Neural\n  Network", "comments": "Accepted by ISBI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronary calcium causes beam hardening and blooming artifacts on cardiac\ncomputed tomography angiography (CTA) images, which lead to overestimation of\nlumen stenosis and reduction of diagnostic specificity. To properly remove\ncoronary calcification and restore arterial lumen precisely, we propose a\nmachine learning-based method with a multi-step inpainting process. We\ndeveloped a new network configuration, Dense-Unet, to achieve optimal\nperformance with low computational cost. Results after the calcium removal\nprocess were validated by comparing with gold-standard X-ray angiography. Our\nresults demonstrated that removing coronary calcification from images with the\nproposed approach was feasible, and may potentially improve the diagnostic\naccuracy of CTA.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:10:34 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Yan", "Siming", ""], ["Shi", "Feng", ""], ["Chen", "Yuhua", ""], ["Dey", "Damini", ""], ["Lee", "Sang-Eun", ""], ["Chang", "Hyuk-Jae", ""], ["Li", "Debiao", ""], ["Xie", "Yibin", ""]]}, {"id": "1803.00404", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Deep Defense: Training DNNs with Improved Adversarial Robustness", "comments": "Accepted by NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the efficacy on a variety of computer vision tasks, deep neural\nnetworks (DNNs) are vulnerable to adversarial attacks, limiting their\napplications in security-critical systems. Recent works have shown the\npossibility of generating imperceptibly perturbed image inputs (a.k.a.,\nadversarial examples) to fool well-trained DNN classifiers into making\narbitrary predictions. To address this problem, we propose a training recipe\nnamed \"deep defense\". Our core idea is to integrate an adversarial\nperturbation-based regularizer into the classification objective, such that the\nobtained models learn to resist potential attacks, directly and precisely. The\nwhole optimization problem is solved just like training a recursive network.\nExperimental results demonstrate that our method outperforms training with\nadversarial/Parseval regularizations by large margins on various datasets\n(including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code\nand models for reproducing our results are available at\nhttps://github.com/ZiangYan/deepdefense.pytorch\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 05:02:59 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 01:59:20 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 01:53:51 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1803.00420", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, James Cheng", "title": "Tractable and Scalable Schatten Quasi-Norm Approximations for Rank\n  Minimization", "comments": "26 pages, 7 figures, AISTATS 2016. arXiv admin note: text overlap\n  with arXiv:1606.01245", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 03:29:33 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""]]}, {"id": "1803.00443", "submitter": "Suraj Srinivas", "authors": "Suraj Srinivas, Francois Fleuret", "title": "Knowledge Transfer with Jacobian Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical distillation methods transfer representations from a \"teacher\"\nneural network to a \"student\" network by matching their output activations.\nRecent methods also match the Jacobians, or the gradient of output activations\nwith the input. However, this involves making some ad hoc decisions, in\nparticular, the choice of the loss function.\n  In this paper, we first establish an equivalence between Jacobian matching\nand distillation with input noise, from which we derive appropriate loss\nfunctions for Jacobian matching. We then rely on this analysis to apply\nJacobian matching to transfer learning by establishing equivalence of a recent\ntransfer learning procedure to distillation.\n  We then show experimentally on standard image datasets that Jacobian-based\npenalties improve distillation, robustness to noisy inputs, and transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:31:26 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Srinivas", "Suraj", ""], ["Fleuret", "Francois", ""]]}, {"id": "1803.00444", "submitter": "Adrian \\v{S}o\\v{s}i\\'c", "authors": "Adrian \\v{S}o\\v{s}i\\'c, Elmar Rueckert, Jan Peters, Abdelhak M.\n  Zoubir, Heinz Koeppl", "title": "Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal\n  Modeling", "comments": "45 pages, 14 figures; ### Version 3 ### published in the Journal of\n  Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of inverse reinforcement learning (IRL) have led to\nsophisticated inference frameworks that relax the original modeling assumption\nof observing an agent behavior that reflects only a single intention. Instead\nof learning a global behavioral model, recent IRL methods divide the\ndemonstration data into parts, to account for the fact that different\ntrajectories may correspond to different intentions, e.g., because they were\ngenerated by different domain experts. In this work, we go one step further:\nusing the intuitive concept of subgoals, we build upon the premise that even a\nsingle trajectory can be explained more efficiently locally within a certain\ncontext than globally, enabling a more compact representation of the observed\nbehavior. Based on this assumption, we build an implicit intentional model of\nthe agent's goals to forecast its behavior in unobserved situations. The result\nis an integrated Bayesian prediction framework that significantly outperforms\nexisting IRL solutions and provides smooth policy estimates consistent with the\nexpert's plan. Most notably, our framework naturally handles situations where\nthe intentions of the agent change over time and classical IRL algorithms fail.\nIn addition, due to its probabilistic nature, the model can be\nstraightforwardly applied in active learning scenarios to guide the\ndemonstration process of the expert.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:31:28 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 16:30:20 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 10:52:08 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["\u0160o\u0161i\u0107", "Adrian", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""], ["Zoubir", "Abdelhak M.", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1803.00446", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Elena Demidova, Stefan Dietze", "title": "Inferring Missing Categorical Information in Noisy and Sparse Web Markup", "comments": null, "journal-ref": "Proceedings of The Web Conference 2018, 27th edition of the former\n  WWW conference", "doi": "10.1145/3178876.3186028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded markup of Web pages has seen widespread adoption throughout the past\nyears driven by standards such as RDFa and Microdata and initiatives such as\nschema.org, where recent studies show an adoption by 39% of all Web pages\nalready in 2016. While this constitutes an important information source for\ntasks such as Web search, Web page classification or knowledge graph\naugmentation, individual markup nodes are usually sparsely described and often\nlack essential information. For instance, from 26 million nodes describing\nevents within the Common Crawl in 2016, 59% of nodes provide less than six\nstatements and only 257,000 nodes (0.96%) are typed with more specific event\nsubtypes. Nevertheless, given the scale and diversity of Web markup data, nodes\nthat provide missing information can be obtained from the Web in large\nquantities, in particular for categorical properties. Such data constitutes\npotential training data for inferring missing information to significantly\naugment sparsely described nodes. In this work, we introduce a supervised\napproach for inferring missing categorical properties in Web markup. Our\nexperiments, conducted on properties of events and movies, show a performance\nof 79% and 83% F1 score correspondingly, significantly outperforming existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:33:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Demidova", "Elena", ""], ["Dietze", "Stefan", ""]]}, {"id": "1803.00491", "submitter": "Pedro Mercado", "authors": "Pedro Mercado (1), Antoine Gautier (1), Francesco Tudisco (2) and\n  Matthias Hein (1) ((1) Saarland University, (2) University of Strathclyde)", "title": "The Power Mean Laplacian for Multilayer Graph Clustering", "comments": "19 pages, 3 figures. Accepted in Artificial Intelligence and\n  Statistics (AISTATS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer graphs encode different kind of interactions between the same set\nof entities. When one wants to cluster such a multilayer graph, the natural\nquestion arises how one should merge the information different layers. We\nintroduce in this paper a one-parameter family of matrix power means for\nmerging the Laplacians from different layers and analyze it in expectation in\nthe stochastic block model. We show that this family allows to recover ground\ntruth clusters under different settings and verify this in real world data.\nWhile computing the matrix power mean can be very expensive for large graphs,\nwe introduce a numerical scheme to efficiently compute its eigenvectors for the\ncase of large sparse graphs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 16:43:01 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mercado", "Pedro", "", "Saarland University"], ["Gautier", "Antoine", "", "Saarland University"], ["Tudisco", "Francesco", "", "University of Strathclyde"], ["Hein", "Matthias", "", "Saarland University"]]}, {"id": "1803.00500", "submitter": "Tom Lorimer", "authors": "Tom Lorimer, Karlis Kanders, Ruedi Stoop", "title": "Natural data structure extracted from neighborhood-similarity graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2018.12.033", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Big' high-dimensional data are commonly analyzed in low-dimensions, after\nperforming a dimensionality-reduction step that inherently distorts the data\nstructure. For the same purpose, clustering methods are also often used. These\nmethods also introduce a bias, either by starting from the assumption of a\nparticular geometric form of the clusters, or by using iterative schemes to\nenhance cluster contours, with uncontrollable consequences. The goal of data\nanalysis should, however, be to encode and detect structural data features at\nall scales and densities simultaneously, without assuming a parametric form of\ndata point distances, or modifying them. We propose a novel approach that\ndirectly encodes data point neighborhood similarities as a sparse graph. Our\nnon-iterative framework permits a transparent interpretation of data, without\naltering the original data dimension and metric. Several natural and synthetic\ndata applications demonstrate the efficacy of our novel approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:06:46 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Lorimer", "Tom", ""], ["Kanders", "Karlis", ""], ["Stoop", "Ruedi", ""]]}, {"id": "1803.00502", "submitter": "Zi Yin", "authors": "Zi Yin", "title": "Understand Functionality and Dimensionality of Vector Embeddings: the\n  Distributional Hypothesis, the Pairwise Inner Product Loss and Its\n  Bias-Variance Trade-off", "comments": "40 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector embedding is a foundational building block of many deep learning\nmodels, especially in natural language processing. In this paper, we present a\ntheoretical framework for understanding the effect of dimensionality on vector\nembeddings. We observe that the distributional hypothesis, a governing\nprinciple of statistical semantics, requires a natural unitary-invariance for\nvector embeddings. Motivated by the unitary-invariance observation, we propose\nthe Pairwise Inner Product (PIP) loss, a unitary-invariant metric on the\nsimilarity between two embeddings. We demonstrate that the PIP loss captures\nthe difference in functionality between embeddings, and that the PIP loss is\ntightly connect with two basic properties of vector embeddings, namely\nsimilarity and compositionality. By formulating the embedding training process\nas matrix factorization with noise, we reveal a fundamental bias-variance\ntrade-off between the signal spectrum and noise power in the dimensionality\nselection process. This bias-variance trade-off sheds light on many empirical\nobservations which have not been thoroughly explained, for example the\nexistence of an optimal dimensionality. Moreover, we discover two new results\nabout vector embeddings, namely their robustness against over-parametrization\nand their forward stability. The bias-variance trade-off of the PIP loss\nexplicitly answers the fundamental open problem of dimensionality selection for\nvector embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 17:02:17 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 01:41:59 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 17:46:36 GMT"}, {"version": "v4", "created": "Mon, 21 May 2018 05:13:02 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Yin", "Zi", ""]]}, {"id": "1803.00530", "submitter": "Buse Atli", "authors": "Buse Gul Atli, Alexander Jung", "title": "Online Feature Ranking for Intrusion Detection Systems", "comments": "Feature selection, streaming data, SVM, SGD, intrusion detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current approaches to the design of intrusion detection systems apply\nfeature selection in a static, non-adaptive fashion. These methods often\nneglect the dynamic nature of network data which requires to use adaptive\nfeature selection techniques. In this paper, we present a simple technique\nbased on incremental learning of support vector machines in order to rank the\nfeatures in real time within a streaming model for network data. Some\nillustrative numerical experiments with two popular benchmark datasets show\nthat our approach allows to adapt to the changes in normal network behaviour\nand novel attack patterns which have not been experienced before.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 17:51:48 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 11:12:15 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Atli", "Buse Gul", ""], ["Jung", "Alexander", ""]]}, {"id": "1803.00546", "submitter": "Evangelos Michelioudakis", "authors": "Evangelos Michelioudakis and Alexander Artikis and Georgios Paliouras", "title": "Semi-Supervised Online Structure Learning for Composite Event\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-019-05780-8", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online structure learning approaches, such as those stemming from Statistical\nRelational Learning, enable the discovery of complex relations in noisy data\nstreams. However, these methods assume the existence of fully-labelled training\ndata, which is unrealistic for most real-world applications. We present a novel\napproach for completing the supervision of a semi-supervised structure learning\ntask. We incorporate graph-cut minimisation, a technique that derives labels\nfor unlabelled data, based on their distance to their labelled counterparts. In\norder to adapt graph-cut minimisation to first order logic, we employ a\nsuitable structural distance for measuring the distance between sets of logical\natoms. The labelling process is achieved online (single-pass) by means of a\ncaching mechanism and the Hoeffding bound, a statistical tool to approximate\nglobally-optimal decisions from locally-optimal ones. We evaluate our approach\non the task of composite event recognition by using a benchmark dataset for\nhuman activity recognition, as well as a real dataset for maritime monitoring.\nThe evaluation suggests that our approach can effectively complete the missing\nlabels and eventually, improve the accuracy of the underlying structure\nlearning system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 18:31:07 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 09:13:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Michelioudakis", "Evangelos", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1803.00590", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Nan Jiang, Alekh Agarwal, Miroslav Dud\\'ik, Yisong Yue,\n  Hal Daum\\'e III", "title": "Hierarchical Imitation and Reinforcement Learning", "comments": "Proceedings of the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to effectively leverage expert feedback to learn sequential\ndecision-making policies. We focus on problems with sparse rewards and long\ntime horizons, which typically pose significant challenges in reinforcement\nlearning. We propose an algorithmic framework, called hierarchical guidance,\nthat leverages the hierarchical structure of the underlying problem to\nintegrate different modes of expert interaction. Our framework can incorporate\ndifferent combinations of imitation learning (IL) and reinforcement learning\n(RL) at different levels, leading to dramatic reductions in both expert effort\nand cost of exploration. Using long-horizon benchmarks, including Montezuma's\nRevenge, we demonstrate that our approach can learn significantly faster than\nhierarchical RL, and be significantly more label-efficient than standard IL. We\nalso theoretically analyze labeling cost for certain instantiations of our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 19:12:27 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 08:41:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Yue", "Yisong", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1803.00606", "submitter": "Christoph Dann", "authors": "Christoph Dann, Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John\n  Langford, Robert E. Schapire", "title": "On Oracle-Efficient PAC RL with Rich Observations", "comments": "appeared at NeurIPS 18; full paper including appendix; updated style\n  file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational tractability of PAC reinforcement learning with\nrich observations. We present new provably sample-efficient algorithms for\nenvironments with deterministic hidden state dynamics and stochastic rich\nobservations. These methods operate in an oracle model of computation --\naccessing policy and value function classes exclusively through standard\noptimization primitives -- and therefore represent computationally efficient\nalternatives to prior algorithms that require enumeration. With stochastic\nhidden state dynamics, we prove that the only known sample-efficient algorithm,\nOLIVE, cannot be implemented in the oracle model. We also present several\nexamples that illustrate fundamental challenges of tractable PAC reinforcement\nlearning in such general settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 20:08:06 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 03:06:36 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 16:20:44 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 19:37:24 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Dann", "Christoph", ""], ["Jiang", "Nan", ""], ["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Langford", "John", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1803.00651", "submitter": "Praneeth Narayanamurthy", "authors": "Namrata Vaswani and Praneeth Narayanamurthy", "title": "Static and Dynamic Robust PCA and Matrix Completion: A Review", "comments": "To appear in Proceedings of the IEEE, Special Issue on Rethinking PCA\n  for Modern Datasets. arXiv admin note: text overlap with arXiv:1711.09492", "journal-ref": "Proceedings of the IEEE ( Volume: 106, Issue: 8, Aug. 2018 )", "doi": "10.1109/JPROC.2018.2844126", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Components Analysis (PCA) is one of the most widely used dimension\nreduction techniques. Robust PCA (RPCA) refers to the problem of PCA when the\ndata may be corrupted by outliers. Recent work by Cand{\\`e}s, Wright, Li, and\nMa defined RPCA as a problem of decomposing a given data matrix into the sum of\na low-rank matrix (true data) and a sparse matrix (outliers). The column space\nof the low-rank matrix then gives the PCA solution. This simple definition has\nlead to a large amount of interesting new work on provably correct, fast, and\npractical solutions to RPCA. More recently, the dynamic (time-varying) version\nof the RPCA problem has been studied and a series of provably correct, fast,\nand memory efficient tracking solutions have been proposed. Dynamic RPCA (or\nrobust subspace tracking) is the problem of tracking data lying in a (slowly)\nchanging subspace while being robust to sparse outliers. This article provides\nan exhaustive review of the last decade of literature on RPCA and its dynamic\ncounterpart (robust subspace tracking), along with describing their theoretical\nguarantees, discussing the pros and cons of various approaches, and providing\nempirical comparisons of performance and speed.\n  A brief overview of the (low-rank) matrix completion literature is also\nprovided (the focus is on works not discussed in other recent reviews). This\nrefers to the problem of completing a low-rank matrix when only a subset of its\nentries are observed. It can be interpreted as a simpler special case of RPCA\nin which the indices of the outlier corrupted entries are known.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:48:53 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 21:25:01 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Vaswani", "Namrata", ""], ["Narayanamurthy", "Praneeth", ""]]}, {"id": "1803.00653", "submitter": "Alexey Dosovitskiy", "authors": "Nikolay Savinov, Alexey Dosovitskiy, Vladlen Koltun", "title": "Semi-parametric Topological Memory for Navigation", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2018. Project website at https://sites.google.com/view/SPTM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new memory architecture for navigation in previously unseen\nenvironments, inspired by landmark-based navigation in animals. The proposed\nsemi-parametric topological memory (SPTM) consists of a (non-parametric) graph\nwith nodes corresponding to locations in the environment and a (parametric)\ndeep network capable of retrieving nodes from the graph based on observations.\nThe graph stores no metric information, only connectivity of locations\ncorresponding to the nodes. We use SPTM as a planning module in a navigation\nsystem. Given only 5 minutes of footage of a previously unseen maze, an\nSPTM-based navigation agent can build a topological map of the environment and\nuse it to confidently navigate towards goals. The average success rate of the\nSPTM agent in goal-directed navigation across test environments is higher than\nthe best-performing baseline by a factor of three. A video of the agent is\navailable at https://youtu.be/vRF7f4lhswo\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:50:35 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Savinov", "Nikolay", ""], ["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.00657", "submitter": "Dacheng Tao", "authors": "Chaoyue Wang, Chang Xu, Xin Yao, Dacheng Tao", "title": "Evolutionary Generative Adversarial Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have been effective for learning\ngenerative models for real-world data. However, existing GANs (GAN and its\nvariants) tend to suffer from training problems such as instability and mode\ncollapse. In this paper, we propose a novel GAN framework called evolutionary\ngenerative adversarial networks (E-GAN) for stable GAN training and improved\ngenerative performance. Unlike existing GANs, which employ a pre-defined\nadversarial objective function alternately training a generator and a\ndiscriminator, we utilize different adversarial training objectives as mutation\noperations and evolve a population of generators to adapt to the environment\n(i.e., the discriminator). We also utilize an evaluation mechanism to measure\nthe quality and diversity of generated samples, such that only well-performing\ngenerator(s) are preserved and used for further training. In this way, E-GAN\novercomes the limitations of an individual adversarial training objective and\nalways preserves the best offspring, contributing to progress in and the\nsuccess of GANs. Experiments on several datasets demonstrate that E-GAN\nachieves convincing generative performance and reduces the training problems\ninherent in existing GANs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 23:15:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Wang", "Chaoyue", ""], ["Xu", "Chang", ""], ["Yao", "Xin", ""], ["Tao", "Dacheng", ""]]}, {"id": "1803.00676", "submitter": "Mengye Ren", "authors": "Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin\n  Swersky, Joshua B. Tenenbaum, Hugo Larochelle, Richard S. Zemel", "title": "Meta-Learning for Semi-Supervised Few-Shot Classification", "comments": "Published as a conference paper at ICLR 2018. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot classification, we are interested in learning algorithms that\ntrain a classifier from only a handful of labeled examples. Recent progress in\nfew-shot classification has featured meta-learning, in which a parameterized\nmodel for a learning algorithm is defined and trained on episodes representing\ndifferent classification problems, each with a small labeled training set and\nits corresponding test set. In this work, we advance this few-shot\nclassification paradigm towards a scenario where unlabeled examples are also\navailable within each episode. We consider two situations: one where all\nunlabeled examples are assumed to belong to the same set of classes as the\nlabeled examples of the episode, as well as the more challenging situation\nwhere examples from other distractor classes are also provided. To address this\nparadigm, we propose novel extensions of Prototypical Networks (Snell et al.,\n2017) that are augmented with the ability to use unlabeled examples when\nproducing prototypes. These models are trained in an end-to-end way on\nepisodes, to learn to leverage the unlabeled examples successfully. We evaluate\nthese methods on versions of the Omniglot and miniImageNet benchmarks, adapted\nto this new framework augmented with unlabeled examples. We also propose a new\nsplit of ImageNet, consisting of a large set of classes, with a hierarchical\nstructure. Our experiments confirm that our Prototypical Networks can learn to\nimprove their predictions due to unlabeled examples, much like a\nsemi-supervised algorithm would.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 01:07:49 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Ren", "Mengye", ""], ["Triantafillou", "Eleni", ""], ["Ravi", "Sachin", ""], ["Snell", "Jake", ""], ["Swersky", "Kevin", ""], ["Tenenbaum", "Joshua B.", ""], ["Larochelle", "Hugo", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1803.00679", "submitter": "Ke Wang", "authors": "Sean O'Rourke and Van Vu and Ke Wang", "title": "Random perturbation and matrix sparsification and completion", "comments": "20 pages. Conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss general perturbation inequalities when the perturbation is random.\nAs applications, we obtain several new results concerning two important\nproblems: matrix sparsification and matrix completion.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 01:27:58 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["O'Rourke", "Sean", ""], ["Vu", "Van", ""], ["Wang", "Ke", ""]]}, {"id": "1803.00684", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Harvey Wu, Warren Mo, Ishanu Chattopadhyay, Hod Lipson", "title": "Autostacker: A Compositional Evolutionary Learning System", "comments": "Submitted to GECCO 2018 and currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automatic machine learning (AutoML) modeling architecture\ncalled Autostacker, which combines an innovative hierarchical stacking\narchitecture and an Evolutionary Algorithm (EA) to perform efficient parameter\nsearch. Neither prior domain knowledge about the data nor feature preprocessing\nis needed. Using EA, Autostacker quickly evolves candidate pipelines with high\npredictive accuracy. These pipelines can be used as is or as a starting point\nfor human experts to build on. Autostacker finds innovative combinations and\nstructures of machine learning models, rather than selecting a single model and\noptimizing its hyperparameters. Compared with other AutoML systems on fifteen\ndatasets, Autostacker achieves state-of-art or competitive performance both in\nterms of test accuracy and time cost.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 02:02:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chen", "Boyuan", ""], ["Wu", "Harvey", ""], ["Mo", "Warren", ""], ["Chattopadhyay", "Ishanu", ""], ["Lipson", "Hod", ""]]}, {"id": "1803.00702", "submitter": "Emad Grais", "authors": "Emad M. Grais, Dominic Ward, and Mark D. Plumbley", "title": "Raw Multi-Channel Audio Source Separation using Multi-Resolution\n  Convolutional Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised multi-channel audio source separation requires extracting useful\nspectral, temporal, and spatial features from the mixed signals. The success of\nmany existing systems is therefore largely dependent on the choice of features\nused for training. In this work, we introduce a novel multi-channel,\nmulti-resolution convolutional auto-encoder neural network that works on raw\ntime-domain signals to determine appropriate multi-resolution features for\nseparating the singing-voice from stereo music. Our experimental results show\nthat the proposed method can achieve multi-channel audio source separation\nwithout the need for hand-crafted features or any pre- or post-processing.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 03:47:47 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Grais", "Emad M.", ""], ["Ward", "Dominic", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1803.00710", "submitter": "Da Qing", "authors": "Yujing Hu, Qing Da, Anxiang Zeng, Yang Yu and Yinghui Xu", "title": "Reinforcement Learning to Rank in E-Commerce Search Engine:\n  Formalization, Analysis, and Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce platforms such as Amazon and TaoBao, ranking items in a search\nsession is a typical multi-step decision-making problem. Learning to rank (LTR)\nmethods have been widely applied to ranking problems. However, such methods\noften consider different ranking steps in a session to be independent, which\nconversely may be highly correlated to each other. For better utilizing the\ncorrelation between different ranking steps, in this paper, we propose to use\nreinforcement learning (RL) to learn an optimal ranking policy which maximizes\nthe expected accumulative rewards in a search session. Firstly, we formally\ndefine the concept of search session Markov decision process (SSMDP) to\nformulate the multi-step ranking problem. Secondly, we analyze the property of\nSSMDP and theoretically prove the necessity of maximizing accumulative rewards.\nLastly, we propose a novel policy gradient algorithm for learning an optimal\nranking policy, which is able to deal with the problem of high reward variance\nand unbalanced reward distribution of an SSMDP. Experiments are conducted in\nsimulation and TaoBao search engine. The results demonstrate that our algorithm\nperforms much better than online LTR methods, with more than 40% and 30% growth\nof total transaction amount in the simulation and the real application,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 03:57:45 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 02:31:36 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 11:24:58 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Hu", "Yujing", ""], ["Da", "Qing", ""], ["Zeng", "Anxiang", ""], ["Yu", "Yang", ""], ["Xu", "Yinghui", ""]]}, {"id": "1803.00744", "submitter": "Dev Goyal", "authors": "Dev Goyal, Zeeshan Syed, Jenna Wiens", "title": "Clinically Meaningful Comparisons Over Time: An Approach to Measuring\n  Patient Similarity based on Subsequence Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal patient data has the potential to improve clinical risk\nstratification models for disease. However, chronic diseases that progress\nslowly over time are often heterogeneous in their clinical presentation.\nPatients may progress through disease stages at varying rates. This leads to\npathophysiological misalignment over time, making it difficult to consistently\ncompare patients in a clinically meaningful way. Furthermore, patients present\nclinically for the first time at different stages of disease. This eliminates\nthe possibility of simply aligning patients based on their initial\npresentation. Finally, patient data may be sampled at different rates due to\ndifferences in schedules or missed visits. To address these challenges, we\npropose a robust measure of patient similarity based on subsequence alignment.\nCompared to global alignment techniques that do not account for\npathophysiological misalignment, focusing on the most relevant subsequences\nallows for an accurate measure of similarity between patients. We demonstrate\nthe utility of our approach in settings where longitudinal data, while useful,\nare limited and lack a clear temporal alignment for comparison. Applied to the\ntask of stratifying patients for risk of progression to probable Alzheimer's\nDisease, our approach outperforms models that use only snapshot data (AUROC of\n0.839 vs. 0.812) and models that use global alignment techniques (AUROC of\n0.822). Our results support the hypothesis that patients' trajectories are\nuseful for quantifying inter-patient similarities and that using subsequence\nmatching and can help account for heterogeneity and misalignment in\nlongitudinal data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 07:43:27 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Goyal", "Dev", ""], ["Syed", "Zeeshan", ""], ["Wiens", "Jenna", ""]]}, {"id": "1803.00754", "submitter": "Kai-Lang Yao", "authors": "Kai-Lang Yao, Wu-Jun Li, Jianbo Yang and Xinyan Lu", "title": "Convolutional Geometric Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric matrix completion (GMC) has been proposed for recommendation by\nintegrating the relationship (link) graphs among users/items into matrix\ncompletion (MC). Traditional GMC methods typically adopt graph regularization\nto impose smoothness priors for MC. Recently, geometric deep learning on graphs\n(GDLG) is proposed to solve the GMC problem, showing better performance than\nexisting GMC methods including traditional graph regularization based methods.\nTo the best of our knowledge, there exists only one GDLG method for GMC, which\nis called RMGCNN. RMGCNN combines graph convolutional network (GCN) and\nrecurrent neural network (RNN) together for GMC. In the original work of\nRMGCNN, RMGCNN demonstrates better performance than pure GCN-based method. In\nthis paper, we propose a new GMC method, called convolutional geometric matrix\ncompletion (CGMC), for recommendation with graphs among users/items. CGMC is a\npure GCN-based method with a newly designed graph convolutional network.\nExperimental results on real datasets show that CGMC can outperform other\nstate-of-the-art methods including RMGCNN in terms of both accuracy and speed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 08:30:44 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 06:49:54 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yao", "Kai-Lang", ""], ["Li", "Wu-Jun", ""], ["Yang", "Jianbo", ""], ["Lu", "Xinyan", ""]]}, {"id": "1803.00781", "submitter": "Alexandre P\\'er\\'e", "authors": "Alexandre P\\'er\\'e, S\\'ebastien Forestier, Olivier Sigaud, Pierre-Yves\n  Oudeyer", "title": "Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrinsically motivated goal exploration algorithms enable machines to\ndiscover repertoires of policies that produce a diversity of effects in complex\nenvironments. These exploration algorithms have been shown to allow real world\nrobots to acquire skills such as tool use in high-dimensional continuous state\nand action spaces. However, they have so far assumed that self-generated goals\nare sampled in a specifically engineered feature space, limiting their\nautonomy. In this work, we propose to use deep representation learning\nalgorithms to learn an adequate goal space. This is a developmental 2-stage\napproach: first, in a perceptual learning stage, deep learning algorithms use\npassive raw sensor observations of world changes to learn a corresponding\nlatent space; then goal exploration happens in a second stage by sampling goals\nin this latent space. We present experiments where a simulated robot arm\ninteracts with an object, and we show that exploration algorithms using such\nlearned representations can match the performance obtained using engineered\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 09:45:53 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 09:32:30 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 18:30:41 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["P\u00e9r\u00e9", "Alexandre", ""], ["Forestier", "S\u00e9bastien", ""], ["Sigaud", "Olivier", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1803.00810", "submitter": "Dominik Janzing", "authors": "Dominik Janzing and Bernhard Schoelkopf", "title": "Detecting non-causal artifacts in multivariate linear regression models", "comments": "7 figures, latex", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear models where $d$ potential causes $X_1,...,X_d$ are\ncorrelated with one target quantity $Y$ and propose a method to infer whether\nthe association is causal or whether it is an artifact caused by overfitting or\nhidden common causes. We employ the idea that in the former case the vector of\nregression coefficients has 'generic' orientation relative to the covariance\nmatrix $\\Sigma_{XX}$ of $X$. Using an ICA based model for confounding, we show\nthat both confounding and overfitting yield regression vectors that concentrate\nmainly in the space of low eigenvalues of $\\Sigma_{XX}$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 11:17:27 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Janzing", "Dominik", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1803.00816", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z\\\"ugner, Stephan\n  G\\\"unnemann", "title": "NetGAN: Generating Graphs via Random Walks", "comments": "ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), Stockholm, Sweden, pp. 609-618", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NetGAN - the first implicit generative model for graphs able to\nmimic real-world networks. We pose the problem of graph generation as learning\nthe distribution of biased random walks over the input graph. The proposed\nmodel is based on a stochastic neural network that generates discrete output\nsamples and is trained using the Wasserstein GAN objective. NetGAN is able to\nproduce graphs that exhibit well-known network patterns without explicitly\nspecifying them in the model definition. At the same time, our model exhibits\nstrong generalization properties, as highlighted by its competitive link\nprediction performance, despite not being trained specifically for this task.\nBeing the first approach to combine both of these desirable properties, NetGAN\nopens exciting avenues for further research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 11:49:32 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 13:18:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["Shchur", "Oleksandr", ""], ["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1803.00830", "submitter": "Ziliang Chen", "authors": "Ruijia Xu, Ziliang Chen, Wangmeng Zuo, Junjie Yan, Liang Lin", "title": "Deep Cocktail Network: Multi-source Unsupervised Domain Adaptation with\n  Category Shift", "comments": "Accepted for publication in Conference on Computer Vision and Pattern\n  Recognition(CVPR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) conventionally assumes labeled source\nsamples coming from a single underlying source distribution. Whereas in\npractical scenario, labeled data are typically collected from diverse sources.\nThe multiple sources are different not only from the target but also from each\nother, thus, domain adaptater should not be modeled in the same way. Moreover,\nthose sources may not completely share their categories, which further brings a\nnew transfer challenge called category shift. In this paper, we propose a deep\ncocktail network (DCTN) to battle the domain and category shifts among multiple\nsources. Motivated by the theoretical results in \\cite{mansour2009domain}, the\ntarget distribution can be represented as the weighted combination of source\ndistributions, and, the multi-source unsupervised domain adaptation via DCTN is\nthen performed as two alternating steps: i) It deploys multi-way adversarial\nlearning to minimize the discrepancy between the target and each of the\nmultiple source domains, which also obtains the source-specific perplexity\nscores to denote the possibilities that a target sample belongs to different\nsource domains. ii) The multi-source category classifiers are integrated with\nthe perplexity scores to classify target sample, and the pseudo-labeled target\nsamples together with source samples are utilized to update the multi-source\ncategory classifier and the feature extractor. We evaluate DCTN in three domain\nadaptation benchmarks, which clearly demonstrate the superiority of our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 12:58:51 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Xu", "Ruijia", ""], ["Chen", "Ziliang", ""], ["Zuo", "Wangmeng", ""], ["Yan", "Junjie", ""], ["Lin", "Liang", ""]]}, {"id": "1803.00838", "submitter": "Piotr Bialas", "authors": "P. Bialas, D. Nemeth, E. Richter-W\\k{a}s", "title": "A multi-instance deep neural network classifier: application to Higgs\n  boson CP measurement", "comments": "7 pages, 6 figures (fixed some misprints)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE hep-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties of a classifier applied to the measurements of the\nCP state of the Higgs boson in $H\\rightarrow\\tau\\tau$ decays. The problem is\nframed as binary classifier applied to individual instances. Then the prior\nknowledge that the instances belong to the same class is used to define the\nmulti-instance classifier. Its final score is calculated as multiplication of\nsingle instance scores for a given series of instances. In the paper we discuss\nproperties of such classifier, notably its dependence on the number of\ninstances in the series. This classifier exhibits very strong random dependence\non the number of epochs used for training and requires careful tuning of the\nclassification threshold. We derive formula for this optimal threshold.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 13:13:04 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 15:41:46 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Bialas", "P.", ""], ["Nemeth", "D.", ""], ["Richter-W\u0105s", "E.", ""]]}, {"id": "1803.00841", "submitter": "Rong Zhu", "authors": "Rong Zhu", "title": "Gradient-based Sampling: An Adaptive Importance Sampling for\n  Least-squares", "comments": null, "journal-ref": "30th Conference on Neural Information Processing Systems (NIPS\n  2016), Barcelona, Spain", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data analysis, random sampling is an efficient and widely-used\nstrategy to overcome the computational difficulties brought by large sample\nsize. In previous studies, researchers conducted random sampling which is\naccording to the input data but independent on the response variable, however\nthe response variable may also be informative for sampling. In this paper we\npropose an adaptive sampling called the gradient-based sampling which is\ndependent on both the input data and the output for fast solving of\nleast-square (LS) problems. We draw the data points by random sampling from the\nfull data according to their gradient values. This sampling is computationally\nsaving, since the running time of computing the sampling probabilities is\nreduced to O(nd) where n is the full sample size and d is the dimension of the\ninput. Theoretically, we establish an error bound analysis of the general\nimportance sampling with respect to LS solution from full data. The result\nestablishes an improved performance of the use of our gradient- based sampling.\nSynthetic and real data sets are used to empirically argue that the\ngradient-based sampling has an obvious advantage over existing sampling methods\nfrom two aspects of statistical efficiency and computational saving.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 13:34:09 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Zhu", "Rong", ""]]}, {"id": "1803.00854", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "A more globally accurate dimensionality reduction method using triplets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first show that the commonly used dimensionality reduction (DR) methods\nsuch as t-SNE and LargeVis poorly capture the global structure of the data in\nthe low dimensional embedding. We show this via a number of tests for the DR\nmethods that can be easily applied by any practitioner to the dataset at hand.\nSurprisingly enough, t-SNE performs the best w.r.t. the commonly used measures\nthat reward the local neighborhood accuracy such as precision-recall while\nhaving the worst performance in our tests for global structure. We then\ncontrast the performance of these two DR method against our new method called\nTriMap. The main idea behind TriMap is to capture higher orders of structure\nwith triplet information (instead of pairwise information used by t-SNE and\nLargeVis), and to minimize a robust loss function for satisfying the chosen\ntriplets. We provide compelling experimental evidence on large natural datasets\nfor the clear advantage of the TriMap DR results. As LargeVis, TriMap scales\nlinearly with the number of data points.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:35:02 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1803.00879", "submitter": "Gareth Conduit", "authors": "B.D. Conduit, N.G. Jones, H.J. Stone, G.J. Conduit", "title": "Probabilistic design of a molybdenum-base alloy using a neural network", "comments": null, "journal-ref": "Scripta Materialia 146, 82 (2018)", "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An artificial intelligence tool is exploited to discover and characterize a\nnew molybdenum-base alloy that is the most likely to simultaneously satisfy\ntargets of cost, phase stability, precipitate content, yield stress, and\nhardness. Experimental testing demonstrates that the proposed alloy fulfils the\ncomputational predictions, and furthermore the physical properties exceed those\nof other commercially available Mo-base alloys for forging-die applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:11:49 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Conduit", "B. D.", ""], ["Jones", "N. G.", ""], ["Stone", "H. J.", ""], ["Conduit", "G. J.", ""]]}, {"id": "1803.00885", "submitter": "Felix Draxler", "authors": "Felix Draxler, Kambis Veschgini, Manfred Salmhofer, Fred A. Hamprecht", "title": "Essentially No Barriers in Neural Network Energy Landscape", "comments": "In Proceedings of 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1308-1317, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training neural networks involves finding minima of a high-dimensional\nnon-convex loss function. Knowledge of the structure of this energy landscape\nis sparse. Relaxing from linear interpolations, we construct continuous paths\nbetween minima of recent neural network architectures on CIFAR10 and CIFAR100.\nSurprisingly, the paths are essentially flat in both the training and test\nlandscapes. This implies that neural networks have enough capacity for\nstructural changes, or that these changes are small between minima. Also, each\nminimum has at least one vanishing Hessian eigenvalue in addition to those\nresulting from trivial invariance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:22:10 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 21:59:03 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 17:45:05 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 14:55:25 GMT"}, {"version": "v5", "created": "Fri, 22 Feb 2019 11:20:22 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Draxler", "Felix", ""], ["Veschgini", "Kambis", ""], ["Salmhofer", "Manfred", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1803.00886", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Dong Wang, Yixiang Chen, Ying Shi, Zhiyuan Tang and Thomas\n  Fang Zheng", "title": "Deep factorization for speech signal", "comments": "Accepted by ICASSP 2018. arXiv admin note: substantial text overlap\n  with arXiv:1706.01777", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various informative factors mixed in speech signals, leading to great\ndifficulty when decoding any of the factors. An intuitive idea is to factorize\neach speech frame into individual informative factors, though it turns out to\nbe highly difficult. Recently, we found that speaker traits, which were assumed\nto be long-term distributional properties, are actually short-time patterns,\nand can be learned by a carefully designed deep neural network (DNN). This\ndiscovery motivated a cascade deep factorization (CDF) framework that will be\npresented in this paper. The proposed framework infers speech factors in a\nsequential way, where factors previously inferred are used as conditional\nvariables when inferring other factors. We will show that this approach can\neffectively factorize speech signals, and using these factors, the original\nspeech spectrum can be recovered with a high accuracy. This factorization and\nreconstruction approach provides potential values for many speech processing\ntasks, e.g., speaker recognition and emotion recognition, as will be\ndemonstrated in the paper.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 12:45:16 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Chen", "Yixiang", ""], ["Shi", "Ying", ""], ["Tang", "Zhiyuan", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1803.00897", "submitter": "Patrick Glauner", "authors": "Patrick Glauner, Petko Valtchev, Radu State", "title": "Impact of Biases in Big Data", "comments": null, "journal-ref": "Proceedings of the 26th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2018)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying paradigm of big data-driven machine learning reflects the\ndesire of deriving better conclusions from simply analyzing more data, without\nthe necessity of looking at theory and models. Is having simply more data\nalways helpful? In 1936, The Literary Digest collected 2.3M filled in\nquestionnaires to predict the outcome of that year's US presidential election.\nThe outcome of this big data prediction proved to be entirely wrong, whereas\nGeorge Gallup only needed 3K handpicked people to make an accurate prediction.\nGenerally, biases occur in machine learning whenever the distributions of\ntraining set and test set are different. In this work, we provide a review of\ndifferent sorts of biases in (big) data sets in machine learning. We provide\ndefinitions and discussions of the most commonly appearing biases in machine\nlearning: class imbalance and covariate shift. We also show how these biases\ncan be quantified and corrected. This work is an introductory text for both\nresearchers and practitioners to become more aware of this topic and thus to\nderive more reliable models for their learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:35:18 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Glauner", "Patrick", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""]]}, {"id": "1803.00909", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun, Yixuan Li, R. Srikant", "title": "Understanding the Loss Surface of Neural Networks for Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely conjectured that the reason that training algorithms for neural\nnetworks are successful because all local minima lead to similar performance,\nfor example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,\n2014). Performance is typically measured in terms of two metrics: training\nperformance and generalization performance. Here we focus on the training\nperformance of single-layered neural networks for binary classification, and\nprovide conditions under which the training error is zero at all local minima\nof a smooth hinge loss function. Our conditions are roughly in the following\nform: the neurons have to be strictly convex and the surrogate loss function\nshould be a smooth version of hinge loss. We also provide counterexamples to\nshow that when the loss function is replaced with quadratic loss or logistic\nloss, the result may not hold.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:13:38 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:20:37 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Li", "Yixuan", ""], ["Srikant", "R.", ""]]}, {"id": "1803.00916", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi, Walid Saad", "title": "Deep Learning for Signal Authentication and Security in Massive Internet\n  of Things Systems", "comments": "16 pages, 15 figures. arXiv admin note: text overlap with\n  arXiv:1711.01306", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure signal authentication is arguably one of the most challenging problems\nin the Internet of Things (IoT) environment, due to the large-scale nature of\nthe system and its susceptibility to man-in-the-middle and eavesdropping\nattacks. In this paper, a novel deep learning method is proposed for dynamic\nauthentication of IoT signals to detect cyber attacks. The proposed learning\nframework, based on a long short-term memory (LSTM) structure, enables the IoT\ndevices (IoTDs) to extract a set of stochastic features from their generated\nsignal and dynamically watermark these features into the signal. This method\nenables the cloud, which collects signals from the IoT devices, to effectively\nauthenticate the reliability of the signals. Moreover, in massive IoT\nscenarios, since the cloud cannot authenticate all the IoTDs simultaneously due\nto computational limitations, a game-theoretic framework is proposed to improve\nthe cloud's decision making process by predicting vulnerable IoTDs. The\nmixed-strategy Nash equilibrium (MSNE) for this game is derived and the\nuniqueness of the expected utility at the equilibrium is proven. In the massive\nIoT system, due to a large set of available actions for the cloud, it is shown\nthat analytically deriving the MSNE is challenging and, thus, a learning\nalgorithm proposed that converges to the MSNE. Moreover, in order to cope with\nthe incomplete information case in which the cloud cannot access the state of\nthe unauthenticated IoTDs, a deep reinforcement learning algorithm is proposed\nto dynamically predict the state of unauthenticated IoTDs and allow the cloud\nto decide on which IoTDs to authenticate. Simulation results show that, with an\nattack detection delay of under 1 second the messages can be transmitted from\nIoT devices with an almost 100% reliability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:07:13 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 05:07:58 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "1803.00933", "submitter": "Daniel Horgan", "authors": "Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo\n  Hessel, Hado van Hasselt and David Silver", "title": "Distributed Prioritized Experience Replay", "comments": "Accepted to International Conference on Learning Representations 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed architecture for deep reinforcement learning at\nscale, that enables agents to learn effectively from orders of magnitude more\ndata than previously possible. The algorithm decouples acting from learning:\nthe actors interact with their own instances of the environment by selecting\nactions according to a shared neural network, and accumulate the resulting\nexperience in a shared experience replay memory; the learner replays samples of\nexperience and updates the neural network. The architecture relies on\nprioritized experience replay to focus only on the most significant data\ngenerated by the actors. Our architecture substantially improves the state of\nthe art on the Arcade Learning Environment, achieving better final performance\nin a fraction of the wall-clock training time.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 16:21:46 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Horgan", "Dan", ""], ["Quan", "John", ""], ["Budden", "David", ""], ["Barth-Maron", "Gabriel", ""], ["Hessel", "Matteo", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""]]}, {"id": "1803.00942", "submitter": "Angelos Katharopoulos", "authors": "Angelos Katharopoulos and Fran\\c{c}ois Fleuret", "title": "Not All Samples Are Created Equal: Deep Learning with Importance\n  Sampling", "comments": "Accepted at ICML 2018 (short oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network training spends most of the computation on examples that\nare properly handled, and could be ignored. We propose to mitigate this\nphenomenon with a principled importance sampling scheme that focuses\ncomputation on \"informative\" examples, and reduces the variance of the\nstochastic gradients during training. Our contribution is twofold: first, we\nderive a tractable upper bound to the per-sample gradient norm, and second we\nderive an estimator of the variance reduction achieved with importance\nsampling, which enables us to switch it on when it will result in an actual\nspeedup. The resulting scheme can be used by changing a few lines of code in a\nstandard SGD procedure, and we demonstrate experimentally, on image\nclassification, CNN fine-tuning, and RNN training, that for a fixed wall-clock\ntime budget, it provides a reduction of the train losses of up to an order of\nmagnitude and a relative improvement of test errors between 5% and 17%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 16:40:43 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 20:03:25 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 10:19:29 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Katharopoulos", "Angelos", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "1803.00967", "submitter": "Zi Wang", "authors": "Zi Wang and Caelan Reed Garrett and Leslie Pack Kaelbling and Tom\\'as\n  Lozano-P\\'erez", "title": "Active model learning and diverse action sampling for task and motion\n  planning", "comments": "Proceedings of the 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), Madrid, Spain.\n  https://www.youtube.com/playlist?list=PLoWhBFPMfSzDbc8CYelsbHZa1d3uz-W_c", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to augment the basic abilities of a robot by\nlearning to use new sensorimotor primitives to enable the solution of complex\nlong-horizon problems. Solving long-horizon problems in complex domains\nrequires flexible generative planning that can combine primitive abilities in\nnovel combinations to solve problems as they arise in the world. In order to\nplan to combine primitive actions, we must have models of the preconditions and\neffects of those actions: under what circumstances will executing this\nprimitive achieve some particular effect in the world?\n  We use, and develop novel improvements on, state-of-the-art methods for\nactive learning and sampling. We use Gaussian process methods for learning the\nconditions of operator effectiveness from small numbers of expensive training\nexamples collected by experimentation on a robot. We develop adaptive sampling\nmethods for generating diverse elements of continuous sets (such as robot\nconfigurations and object poses) during planning for solving a new task, so\nthat planning is as efficient as possible. We demonstrate these methods in an\nintegrated system, combining newly learned models with an efficient\ncontinuous-space robot task and motion planner to learn to solve long horizon\nproblems more efficiently than was previously possible.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 17:40:18 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 16:08:00 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Zi", ""], ["Garrett", "Caelan Reed", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1803.00992", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Andrea Paudice, Luis Mu\\~noz-Gonz\\'alez, Emil C. Lupu", "title": "Label Sanitization against Label Flipping Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems rely on data collected in the wild from\nuntrusted sources, exposing the learning algorithms to data poisoning.\nAttackers can inject malicious data in the training dataset to subvert the\nlearning process, compromising the performance of the algorithm producing\nerrors in a targeted or an indiscriminate way. Label flipping attacks are a\nspecial case of data poisoning, where the attacker can control the labels\nassigned to a fraction of the training points. Even if the capabilities of the\nattacker are constrained, these attacks have been shown to be effective to\nsignificantly degrade the performance of the system. In this paper we propose\nan efficient algorithm to perform optimal label flipping poisoning attacks and\na mechanism to detect and relabel suspicious data points, mitigating the effect\nof such poisoning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 18:43:22 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:26:48 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Paudice", "Andrea", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1803.01013", "submitter": "Tyler Maunu", "authors": "Gilad Lerman, Tyler Maunu", "title": "An Overview of Robust Subspace Recovery", "comments": "31 pages, 5 figures, 3 tables", "journal-ref": "Proceedings of the IEEE 106 (2018) 1380-1410", "doi": "10.1109/JPROC.2018.2853141", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will serve as an introduction to the body of work on robust\nsubspace recovery. Robust subspace recovery involves finding an underlying\nlow-dimensional subspace in a dataset that is possibly corrupted with outliers.\nWhile this problem is easy to state, it has been difficult to develop optimal\nalgorithms due to its underlying nonconvexity. This work emphasizes advantages\nand disadvantages of proposed approaches and unsolved problems in the area.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:16:07 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 00:08:44 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Lerman", "Gilad", ""], ["Maunu", "Tyler", ""]]}, {"id": "1803.01024", "submitter": "Besim Bilalli", "authors": "Besim Bilalli and Alberto Abell\\'o and Tom\\`as Aluja-Banet and Robert\n  Wrembel", "title": "PRESISTANT: Learning based assistant for data pre-processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data pre-processing is one of the most time consuming and relevant steps in a\ndata analysis process (e.g., classification task). A given data pre-processing\noperator (e.g., transformation) can have positive, negative or zero impact on\nthe final result of the analysis. Expert users have the required knowledge to\nfind the right pre-processing operators. However, when it comes to non-experts,\nthey are overwhelmed by the amount of pre-processing operators and it is\nchallenging for them to find operators that would positively impact their\nanalysis (e.g., increase the predictive accuracy of a classifier). Existing\nsolutions either assume that users have expert knowledge, or they recommend\npre-processing operators that are only \"syntactically\" applicable to a dataset,\nwithout taking into account their impact on the final analysis. In this work,\nwe aim at providing assistance to non-expert users by recommending data\npre-processing operators that are ranked according to their impact on the final\nanalysis. We developed a tool PRESISTANT, that uses Random Forests to learn the\nimpact of pre-processing operators on the performance (e.g., predictive\naccuracy) of 5 different classification algorithms, such as J48, Naive Bayes,\nPART, Logistic Regression, and Nearest Neighbor. Extensive evaluations on the\nrecommendations provided by our tool, show that PRESISTANT can effectively help\nnon-experts in order to achieve improved results in their analytical tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:50:30 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Bilalli", "Besim", ""], ["Abell\u00f3", "Alberto", ""], ["Aluja-Banet", "Tom\u00e0s", ""], ["Wrembel", "Robert", ""]]}, {"id": "1803.01043", "submitter": "Mitch Hill", "authors": "Mitch Hill, Erik Nijkamp, Song-Chun Zhu", "title": "Building a Telescope to Look Into High-Dimensional Image Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image pattern can be represented by a probability distribution whose\ndensity is concentrated on different low-dimensional subspaces in the\nhigh-dimensional image space. Such probability densities have an astronomical\nnumber of local modes corresponding to typical pattern appearances. Related\ngroups of modes can join to form macroscopic image basins that represent\npattern concepts. Recent works use neural networks that capture high-order\nimage statistics to learn Gibbs models capable of synthesizing realistic images\nof many patterns. However, characterizing a learned probability density to\nuncover the Hopfield memories of the model, encoded by the structure of the\nlocal modes, remains an open challenge. In this work, we present novel\ncomputational experiments that map and visualize the local mode structure of\nGibbs densities. Efficient mapping requires identifying the global basins\nwithout enumerating the countless modes. Inspired by Grenander's jump-diffusion\nmethod, we propose a new MCMC tool called Attraction-Diffusion (AD) that can\ncapture the macroscopic structure of highly non-convex densities by measuring\nmetastability of local modes. AD involves altering the target density with a\nmagnetization potential penalizing distance from a known mode and running an\nMCMC sample of the altered density to measure the stability of the initial\nchain state. Using a low-dimensional generator network to facilitate\nexploration, we map image spaces with up to 12,288 dimensions (64 $\\times$ 64\npixels in RGB). Our work shows: (1) AD can efficiently map highly non-convex\nprobability densities, (2) metastable regions of pattern probability densities\ncontain coherent groups of images, and (3) the perceptibility of differences\nbetween training images influences the metastability of image basins.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 21:09:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Hill", "Mitch", ""], ["Nijkamp", "Erik", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1803.01045", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, He Ma, Graham Taylor, Kristin Branson", "title": "Quantitatively Evaluating GANs With Divergences Proposed for Training", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been extremely effective in\napproximating complex distributions of high-dimensional, input data samples,\nand substantial progress has been made in understanding and improving GAN\nperformance in terms of both theory and application. However, we currently lack\nquantitative methods for model assessment. Because of this, while many GAN\nvariants are being proposed, we have relatively little understanding of their\nrelative abilities. In this paper, we evaluate the performance of various types\nof GANs using divergence and distance functions typically used only for\ntraining. We observe consistency across the various proposed metrics and,\ninterestingly, the test-time metrics do not favour networks that use the same\ntraining-time criterion. We also compare the proposed metrics to human\nperceptual scores.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 21:18:36 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 13:34:44 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Ma", "He", ""], ["Taylor", "Graham", ""], ["Branson", "Kristin", ""]]}, {"id": "1803.01066", "submitter": "Ian Manchester", "authors": "Jack Umenberger and Ian R. Manchester", "title": "Specialized Interior Point Algorithm for Stable Nonlinear System\n  Identification", "comments": "accepted to IEEE Transactions on Automatic Control", "journal-ref": null, "doi": "10.1109/TAC.2018.2867358", "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of nonlinear dynamic models from data poses many challenges,\nincluding model instability and non-convexity of long-term simulation fidelity.\nRecently Lagrangian relaxation has been proposed as a method to approximate\nsimulation fidelity and guarantee stability via semidefinite programming (SDP),\nhowever the resulting SDPs have large dimension, limiting their utility in\npractical problems. In this paper we develop a path-following interior point\nalgorithm that takes advantage of special structure in the problem and reduces\ncomputational complexity from cubic to linear growth with the length of the\ndata set. The new algorithm enables empirical comparisons to established\nmethods including Nonlinear ARX, and we demonstrate superior generalization to\nnew data. We also explore the \"regularizing\" effect of stability constraints as\nan alternative to regressor subset selection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 22:57:06 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Umenberger", "Jack", ""], ["Manchester", "Ian R.", ""]]}, {"id": "1803.01088", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Alekh Agarwal, Miroslav Dud\\'ik, Haipeng Luo, Robert\n  E. Schapire", "title": "Practical Contextual Bandits with Regression Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in contextual bandits is to design general-purpose\nalgorithms that are both practically useful and theoretically well-founded. We\npresent a new technique that has the empirical and computational advantages of\nrealizability-based approaches combined with the flexibility of agnostic\nmethods. Our algorithms leverage the availability of a regression oracle for\nthe value-function class, a more realistic and reasonable oracle than the\nclassification oracles over policies typically assumed by agnostic methods. Our\napproach generalizes both UCB and LinUCB to far more expressive possible model\nclasses and achieves low regret under certain distributional assumptions. In an\nextensive empirical evaluation, compared to both realizability-based and\nagnostic baselines, we find that our approach typically gives comparable or\nsuperior results.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 01:50:35 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Foster", "Dylan J.", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Luo", "Haipeng", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1803.01113", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Gauri Joshi, Soumyadip Ghosh, Parijat Dube, Priya\n  Nagpurkar", "title": "Slow and Stale Gradients Can Win the Race: Error-Runtime Trade-offs in\n  Distributed SGD", "comments": "Single Column Version, 33 pages, 14 figures, Accepted at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Stochastic Gradient Descent (SGD) when run in a synchronous\nmanner, suffers from delays in waiting for the slowest learners (stragglers).\nAsynchronous methods can alleviate stragglers, but cause gradient staleness\nthat can adversely affect convergence. In this work we present a novel\ntheoretical characterization of the speed-up offered by asynchronous methods by\nanalyzing the trade-off between the error in the trained model and the actual\ntraining runtime (wallclock time). The novelty in our work is that our runtime\nanalysis considers random straggler delays, which helps us design and compare\ndistributed SGD algorithms that strike a balance between stragglers and\nstaleness. We also present a new convergence analysis of asynchronous SGD\nvariants without bounded or exponential delay assumptions, and a novel learning\nrate schedule to compensate for gradient staleness.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 06:17:18 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 19:47:57 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 23:30:45 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Joshi", "Gauri", ""], ["Ghosh", "Soumyadip", ""], ["Dube", "Parijat", ""], ["Nagpurkar", "Priya", ""]]}, {"id": "1803.01128", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Jinfeng Yi, Pin-Yu Chen, Huan Zhang, Cho-Jui Hsieh", "title": "Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crafting adversarial examples has become an important technique to evaluate\nthe robustness of deep neural networks (DNNs). However, most existing works\nfocus on attacking the image classification problem since its input space is\ncontinuous and output space is finite.\n  In this paper, we study the much more challenging problem of crafting\nadversarial examples for sequence-to-sequence (seq2seq) models, whose inputs\nare discrete text strings and outputs have an almost infinite number of\npossibilities. To address the challenges caused by the discrete input space, we\npropose a projected gradient method combined with group lasso and gradient\nregularization. To handle the almost infinite output space, we design some\nnovel loss functions to conduct non-overlapping attack and targeted keyword\nattack. We apply our algorithm to machine translation and text summarization\ntasks, and verify the effectiveness of the proposed algorithm: by changing less\nthan 3 words, we can make seq2seq model to produce desired outputs with high\nsuccess rates. On the other hand, we recognize that, compared with the\nwell-evaluated CNN-based classifiers, seq2seq models are intrinsically more\nrobust to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 08:51:00 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 17:47:37 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 19:59:25 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Cheng", "Minhao", ""], ["Yi", "Jinfeng", ""], ["Chen", "Pin-Yu", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1803.01129", "submitter": "Matthias M\\\"uller", "authors": "Guohao Li, Matthias M\\\"uller, Vincent Casser, Neil Smith, Dominik L.\n  Michels, Bernard Ghanem", "title": "OIL: Observational Imitation Learning", "comments": "Accepted at RSS'19. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored the problem of autonomous navigation by imitating a\nteacher and learning an end-to-end policy, which directly predicts controls\nfrom raw images. However, these approaches tend to be sensitive to mistakes by\nthe teacher and do not scale well to other environments or vehicles. To this\nend, we propose Observational Imitation Learning (OIL), a novel imitation\nlearning variant that supports online training and automatic selection of\noptimal behavior by observing multiple imperfect teachers. We apply our\nproposed methodology to the challenging problems of autonomous driving and UAV\nracing. For both tasks, we utilize the Sim4CV simulator that enables the\ngeneration of large amounts of synthetic training data and also allows for\nonline learning and evaluation. We train a perception network to predict\nwaypoints from raw image data and use OIL to train another network to predict\ncontrols from these waypoints. Extensive experiments demonstrate that our\ntrained network outperforms its teachers, conventional imitation learning (IL)\nand reinforcement learning (RL) baselines and even humans in simulation. The\nproject website is available at https://sites.google.com/kaust.edu.sa/oil/ and\na video at https://youtu.be/_rhq8a0qgeg\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 09:17:42 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 12:55:18 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 11:24:12 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Li", "Guohao", ""], ["M\u00fcller", "Matthias", ""], ["Casser", "Vincent", ""], ["Smith", "Neil", ""], ["Michels", "Dominik L.", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1803.01199", "submitter": "Yuri G. Gordienko", "authors": "Sergii Stirenko, Yuriy Kochura, Oleg Alienin, Oleksandr Rokovyi, Peng\n  Gang, Wei Zeng, and Yuri Gordienko", "title": "Chest X-Ray Analysis of Tuberculosis by Deep Learning with Segmentation\n  and Augmentation", "comments": "6 pages, 11 figures, 1 table", "journal-ref": "2018 IEEE 38th International Conference on Electronics and\n  Nanotechnology (ELNANO), Kiev, 2018, pp. 422-428", "doi": "10.1109/ELNANO.2018.8477564", "report-no": null, "categories": "cs.LG cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of chest X-ray (CXR) analysis of 2D images to get the\nstatistically reliable predictions (availability of tuberculosis) by\ncomputer-aided diagnosis (CADx) on the basis of deep learning are presented.\nThey demonstrate the efficiency of lung segmentation, lossless and lossy data\naugmentation for CADx of tuberculosis by deep convolutional neural network\n(CNN) applied to the small and not well-balanced dataset even. CNN demonstrates\nability to train (despite overfitting) on the pre-processed dataset obtained\nafter lung segmentation in contrast to the original not-segmented dataset.\nLossless data augmentation of the segmented dataset leads to the lowest\nvalidation loss (without overfitting) and nearly the same accuracy (within the\nlimits of standard deviation) in comparison to the original and other\npre-processed datasets after lossy data augmentation. The additional limited\nlossy data augmentation results in the lower validation loss, but with a\ndecrease of the validation accuracy. In conclusion, besides the more complex\ndeep CNNs and bigger datasets, the better progress of CADx for the small and\nnot well-balanced datasets even could be obtained by better segmentation, data\naugmentation, dataset stratification, and exclusion of non-evident outliers.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 16:42:19 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Stirenko", "Sergii", ""], ["Kochura", "Yuriy", ""], ["Alienin", "Oleg", ""], ["Rokovyi", "Oleksandr", ""], ["Gang", "Peng", ""], ["Zeng", "Wei", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1803.01203", "submitter": "Shaobo Han", "authors": "Shaobo Han and David B. Dunson", "title": "Multiresolution Tensor Decomposition for Multiple Spatial Passing\n  Networks", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is motivated by soccer positional passing networks collected\nacross multiple games. We refer to these data as replicated spatial passing\nnetworks---to accurately model such data it is necessary to take into account\nthe spatial positions of the passer and receiver for each passing event. This\nspatial registration and replicates that occur across games represent key\ndifferences with usual social network data. As a key step before investigating\nhow the passing dynamics influence team performance, we focus on developing\nmethods for summarizing different team's passing strategies. Our proposed\napproach relies on a novel multiresolution data representation framework and\nPoisson nonnegative block term decomposition model, which automatically\nproduces coarse-to-fine low-rank network motifs. The proposed methods are\napplied to detailed passing record data collected from the 2014 FIFA World Cup.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 16:57:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Han", "Shaobo", ""], ["Dunson", "David B.", ""]]}, {"id": "1803.01206", "submitter": "Simon Du", "authors": "Simon S. Du and Jason D. Lee", "title": "On the Power of Over-parametrization in Neural Networks with Quadratic\n  Activation", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new theoretical insights on why over-parametrization is effective\nin learning neural networks. For a $k$ hidden node shallow network with\nquadratic activation and $n$ training data points, we show as long as $ k \\ge\n\\sqrt{2n}$, over-parametrization enables local search algorithms to find a\n\\emph{globally} optimal solution for general smooth and convex loss functions.\nFurther, despite that the number of parameters may exceed the sample size,\nusing theory of Rademacher complexity, we show with weight decay, the solution\nalso generalizes well if the data is sampled from a regular distribution such\nas Gaussian. To prove when $k\\ge \\sqrt{2n}$, the loss function has benign\nlandscape properties, we adopt an idea from smoothed analysis, which may have\nother applications in studying loss surfaces of neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 17:37:57 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 23:59:37 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""]]}, {"id": "1803.01216", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Karsten Kahl and Hanno Gottschalk", "title": "Deep Bayesian Active Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications the process of generating label information is expensive\nand time consuming. We present a new method that combines active and\nsemi-supervised deep learning to achieve high generalization performance from a\ndeep convolutional neural network with as few known labels as possible. In a\nsetting where a small amount of labeled data as well as a large amount of\nunlabeled data is available, our method first learns the labeled data set. This\ninitialization is followed by an expectation maximization algorithm, where\nfurther training reduces classification entropy on the unlabeled data by\ntargeting a low entropy fit which is consistent with the labeled data. In\naddition the algorithm asks at a specified frequency an oracle for labels of\ndata with entropy above a certain entropy quantile. Using this active learning\ncomponent we obtain an agile labeling process that achieves high accuracy, but\nrequires only a small amount of known labels. For the MNIST dataset we report\nan error rate of 2.06% using only 300 labels and 1.06% for 1000 labels. These\nresults are obtained without employing any special network architecture or data\naugmentation.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 19:13:40 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Rottmann", "Matthias", ""], ["Kahl", "Karsten", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1803.01229", "submitter": "Maayan Frid-Adar", "authors": "Maayan Frid-Adar, Idit Diamant, Eyal Klang, Michal Amitai, Jacob\n  Goldberger, Hayit Greenspan", "title": "GAN-based Synthetic Medical Image Augmentation for increased CNN\n  Performance in Liver Lesion Classification", "comments": "Preprint submitted to Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2018.09.013", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods, and in particular convolutional neural networks\n(CNNs), have led to an enormous breakthrough in a wide range of computer vision\ntasks, primarily by using large-scale annotated datasets. However, obtaining\nsuch datasets in the medical domain remains a challenge. In this paper, we\npresent methods for generating synthetic medical images using recently\npresented deep learning Generative Adversarial Networks (GANs). Furthermore, we\nshow that generated medical images can be used for synthetic data augmentation,\nand improve the performance of CNN for medical image classification. Our novel\nmethod is demonstrated on a limited dataset of computed tomography (CT) images\nof 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We first\nexploit GAN architectures for synthesizing high quality liver lesion ROIs. Then\nwe present a novel scheme for liver lesion classification using CNN. Finally,\nwe train the CNN using classic data augmentation and our synthetic data\naugmentation and compare performance. In addition, we explore the quality of\nour synthesized examples using visualization and expert assessment. The\nclassification performance using only classic data augmentation yielded 78.6%\nsensitivity and 88.4% specificity. By adding the synthetic data augmentation\nthe results increased to 85.7% sensitivity and 92.4% specificity. We believe\nthat this approach to synthetic data augmentation can generalize to other\nmedical classification applications and thus support radiologists' efforts to\nimprove diagnosis.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 20:20:38 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Frid-Adar", "Maayan", ""], ["Diamant", "Idit", ""], ["Klang", "Eyal", ""], ["Amitai", "Michal", ""], ["Goldberger", "Jacob", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1803.01233", "submitter": "Quanquan Gu", "authors": "Xiao Zhang and Simon S. Du and Quanquan Gu", "title": "Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase\n  Procrustes Flow", "comments": "35 pages, 3 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the inductive matrix completion problem that aims to recover a\nrank-$r$ matrix with ambient dimension $d$ given $n$ features as the side prior\ninformation. The goal is to make use of the known $n$ features to reduce sample\nand computational complexities. We present and analyze a new gradient-based\nnon-convex optimization algorithm that converges to the true underlying matrix\nat a linear rate with sample complexity only linearly depending on $n$ and\nlogarithmically depending on $d$. To the best of our knowledge, all previous\nalgorithms either have a quadratic dependency on the number of features in\nsample complexity or a sub-linear computational convergence rate. In addition,\nwe provide experiments on both synthetic and real world data to demonstrate the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 20:42:29 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Zhang", "Xiao", ""], ["Du", "Simon S.", ""], ["Gu", "Quanquan", ""]]}, {"id": "1803.01254", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Xianfeng Tang, Hua Wei, Guanjie Zheng, Zhenhui Li", "title": "Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for\n  Traffic Prediction", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction has drawn increasing attention in AI research field due to\nthe increasing availability of large-scale traffic data and its importance in\nthe real world. For example, an accurate taxi demand prediction can assist taxi\ncompanies in pre-allocating taxis. The key challenge of traffic prediction lies\nin how to model the complex spatial dependencies and temporal dynamics.\nAlthough both factors have been considered in modeling, existing works make\nstrong assumptions about spatial dependence and temporal dynamics, i.e.,\nspatial dependence is stationary in time, and temporal dynamics is strictly\nperiodical. However, in practice, the spatial dependence could be dynamic\n(i.e., changing from time to time), and the temporal dynamics could have some\nperturbation from one period to another period. In this paper, we make two\nimportant observations: (1) the spatial dependencies between locations are\ndynamic; and (2) the temporal dependency follows daily and weekly pattern but\nit is not strictly periodic for its dynamic temporal shifting. To address these\ntwo issues, we propose a novel Spatial-Temporal Dynamic Network (STDN), in\nwhich a flow gating mechanism is introduced to learn the dynamic similarity\nbetween locations, and a periodically shifted attention mechanism is designed\nto handle long-term periodic temporal shifting. To the best of our knowledge,\nthis is the first work that tackles both issues in a unified framework. Our\nexperimental results on real-world traffic datasets verify the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 22:38:56 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 23:45:42 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Yao", "Huaxiu", ""], ["Tang", "Xianfeng", ""], ["Wei", "Hua", ""], ["Zheng", "Guanjie", ""], ["Li", "Zhenhui", ""]]}, {"id": "1803.01257", "submitter": "Xiao Fu", "authors": "Xiao Fu and Kejun Huang and Nicholas D. Sidiropoulos and Wing-Kin Ma", "title": "Nonnegative Matrix Factorization for Signal and Data Analytics:\n  Identifiability, Algorithms, and Applications", "comments": "accepted version, IEEE Signal Processing Magazine; supplementary\n  materials added. Some minor revisions implemented", "journal-ref": null, "doi": "10.1109/MSP.2018.2877582", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has become a workhorse for signal and\ndata analytics, triggered by its model parsimony and interpretability. Perhaps\na bit surprisingly, the understanding to its model identifiability---the major\nreason behind the interpretability in many applications such as topic mining\nand hyperspectral imaging---had been rather limited until recent years.\nBeginning from the 2010s, the identifiability research of NMF has progressed\nconsiderably: Many interesting and important results have been discovered by\nthe signal processing (SP) and machine learning (ML) communities. NMF\nidentifiability has a great impact on many aspects in practice, such as\nill-posed formulation avoidance and performance-guaranteed algorithm design. On\nthe other hand, there is no tutorial paper that introduces NMF from an\nidentifiability viewpoint. In this paper, we aim at filling this gap by\noffering a comprehensive and deep tutorial on model identifiability of NMF as\nwell as the connections to algorithms and applications. This tutorial will help\nresearchers and graduate students grasp the essence and insights of NMF,\nthereby avoiding typical `pitfalls' that are often times due to unidentifiable\nNMF formulations. This paper will also help practitioners pick/design suitable\nfactorization tools for their own problems.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 22:48:14 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 05:49:47 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 16:45:48 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 18:41:45 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Fu", "Xiao", ""], ["Huang", "Kejun", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Ma", "Wing-Kin", ""]]}, {"id": "1803.01271", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks\n  for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most deep learning practitioners, sequence modeling is synonymous with\nrecurrent networks. Yet recent results indicate that convolutional\narchitectures can outperform recurrent networks on tasks such as audio\nsynthesis and machine translation. Given a new sequence modeling task or\ndataset, which architecture should one use? We conduct a systematic evaluation\nof generic convolutional and recurrent architectures for sequence modeling. The\nmodels are evaluated across a broad range of standard tasks that are commonly\nused to benchmark recurrent networks. Our results indicate that a simple\nconvolutional architecture outperforms canonical recurrent networks such as\nLSTMs across a diverse range of tasks and datasets, while demonstrating longer\neffective memory. We conclude that the common association between sequence\nmodeling and recurrent networks should be reconsidered, and convolutional\nnetworks should be regarded as a natural starting point for sequence modeling\ntasks. To assist related work, we have made code available at\nhttp://github.com/locuslab/TCN .\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 00:20:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 14:32:38 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.01273", "submitter": "Yang Song", "authors": "Yang Song, Jiaming Song, and Stefano Ermon", "title": "Accelerating Natural Gradient with Higher-Order Invariance", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appealing property of the natural gradient is that it is invariant to\narbitrary differentiable reparameterizations of the model. However, this\ninvariance property requires infinitesimal steps and is lost in practical\nimplementations with small but finite step sizes. In this paper, we study\ninvariance properties from a combined perspective of Riemannian geometry and\nnumerical differential equation solving. We define the order of invariance of a\nnumerical method to be its convergence order to an invariant solution. We\npropose to use higher-order integrators and geodesic corrections to obtain more\ninvariant optimization trajectories. We prove the numerical convergence\nproperties of geodesic corrected updates and show that they can be as\ncomputationally efficient as plain natural gradient. Experimentally, we\ndemonstrate that invariance leads to faster optimization and our techniques\nimprove on traditional natural gradient in deep neural network training and\nnatural policy gradient for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 00:25:09 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 21:29:51 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Song", "Yang", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.01299", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Shuji Hao", "title": "An Optimal Control Approach to Deep Learning and Applications to\n  Discrete-Weight Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is formulated as a discrete-time optimal control problem. This\nallows one to characterize necessary conditions for optimality and develop\ntraining algorithms that do not rely on gradients with respect to the trainable\nparameters. In particular, we introduce the discrete-time method of successive\napproximations (MSA), which is based on the Pontryagin's maximum principle, for\ntraining neural networks. A rigorous error estimate for the discrete MSA is\nobtained, which sheds light on its dynamics and the means to stabilize the\nalgorithm. The developed methods are applied to train, in a rather principled\nway, neural networks with weights that are constrained to take values in a\ndiscrete set. We obtain competitive performance and interestingly, very sparse\nweights in the case of ternary networks, which may be useful in model\ndeployment in low-memory devices.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 04:37:49 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 08:40:52 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Li", "Qianxiao", ""], ["Hao", "Shuji", ""]]}, {"id": "1803.01302", "submitter": "Yuancheng Zhu", "authors": "Yuancheng Zhu and John Lafferty", "title": "Distributed Nonparametric Regression under Communication Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of nonparametric estimation of a smooth\nfunction with data distributed across multiple machines. We assume an\nindependent sample from a white noise model is collected at each machine, and\nan estimator of the underlying true function needs to be constructed at a\ncentral machine. We place limits on the number of bits that each machine can\nuse to transmit information to the central machine. Our results give both\nasymptotic lower bounds and matching upper bounds on the statistical risk under\nvarious settings. We identify three regimes, depending on the relationship\namong the number of machines, the size of the data available at each machine,\nand the communication budget. When the communication budget is small, the\nstatistical risk depends solely on this communication bottleneck, regardless of\nthe sample size. In the regime where the communication budget is large, the\nclassic minimax risk in the non-distributed estimation setting is recovered. In\nan intermediate regime, the statistical risk depends on both the sample size\nand the communication budget.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 05:15:10 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 15:27:50 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Zhu", "Yuancheng", ""], ["Lafferty", "John", ""]]}, {"id": "1803.01316", "submitter": "Johannes F\\\"urnkranz", "authors": "Johannes F\\\"urnkranz, Tom\\'a\\v{s} Kliegr, Heiko Paulheim", "title": "On Cognitive Preferences and the Plausibility of Rule-based Models", "comments": "V4: Another rewrite of section on interpretability to clarify focus\n  on plausibility and relation to interpretability, comprehensibility, and\n  justifiability", "journal-ref": "Machine Learning 109(4):853-898, 2020", "doi": "10.1007/s10994-019-05856-5", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is conventional wisdom in machine learning and data mining that logical\nmodels such as rule sets are more interpretable than other models, and that\namong such rule-based models, simpler models are more interpretable than more\ncomplex ones. In this position paper, we question this latter assumption by\nfocusing on one particular aspect of interpretability, namely the plausibility\nof models. Roughly speaking, we equate the plausibility of a model with the\nlikeliness that a user accepts it as an explanation for a prediction. In\nparticular, we argue that, all other things being equal, longer explanations\nmay be more convincing than shorter ones, and that the predominant bias for\nshorter models, which is typically necessary for learning powerful\ndiscriminative models, may not be suitable when it comes to user acceptance of\nthe learned models. To that end, we first recapitulate evidence for and against\nthis postulate, and then report the results of an evaluation in a\ncrowd-sourcing study based on about 3.000 judgments. The results do not reveal\na strong preference for simple rules, whereas we can observe a weak preference\nfor longer rules in some domains. We then relate these results to well-known\ncognitive biases such as the conjunction fallacy, the representative heuristic,\nor the recogition heuristic, and investigate their relation to rule length and\nplausibility.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 08:26:43 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 14:03:06 GMT"}, {"version": "v3", "created": "Sat, 18 Aug 2018 15:02:51 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 08:37:58 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["F\u00fcrnkranz", "Johannes", ""], ["Kliegr", "Tom\u00e1\u0161", ""], ["Paulheim", "Heiko", ""]]}, {"id": "1803.01347", "submitter": "Brahim Khalil Abid", "authors": "Brahim Khalil Abid and Robert M. Gower", "title": "Greedy stochastic algorithms for entropy-regularized optimal transport\n  problems", "comments": "17 pages, 3 figures, AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) distances are finding evermore applications in machine\nlearning and computer vision, but their wide spread use in larger-scale\nproblems is impeded by their high computational cost. In this work we develop a\nfamily of fast and practical stochastic algorithms for solving the optimal\ntransport problem with an entropic penalization. This work extends the recently\ndeveloped Greenkhorn algorithm, in the sense that, the Greenkhorn algorithm is\na limiting case of this family. We also provide a simple and general\nconvergence theorem for all algorithms in the class, with rates that match the\nbest known rates of Greenkorn and the Sinkhorn algorithm, and conclude with\nnumerical experiments that show under what regime of penalization the new\nstochastic methods are faster than the aforementioned methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 12:32:11 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Abid", "Brahim Khalil", ""], ["Gower", "Robert M.", ""]]}, {"id": "1803.01349", "submitter": "Sotirios Chatzis", "authors": "Harris Partaourides and Sotirios P. Chatzis", "title": "Deep Network Regularization via Bayesian Inference of Synaptic\n  Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) often require good regularizers to generalize\nwell. Currently, state-of-the-art DNN regularization techniques consist in\nrandomly dropping units and/or connections on each iteration of the training\nalgorithm. Dropout and DropConnect are characteristic examples of such\nregularizers, that are widely popular among practitioners. However, a drawback\nof such approaches consists in the fact that their postulated probability of\nrandom unit/connection omission is a constant that must be heuristically\nselected based on the obtained performance in some validation set. To alleviate\nthis burden, in this paper we regard the DNN regularization problem from a\nBayesian inference perspective: We impose a sparsity-inducing prior over the\nnetwork synaptic weights, where the sparsity is induced by a set of\nBernoulli-distributed binary variables with Beta (hyper-)priors over their\nprior parameters. This way, we eventually allow for marginalizing over the DNN\nsynaptic connectivity for output generation, thus giving rise to an effective,\nheuristics-free, network regularization scheme. We perform Bayesian inference\nfor the resulting hierarchical model by means of an efficient Black-Box\nVariational inference scheme. We exhibit the advantages of our method over\nexisting approaches by conducting an extensive experimental evaluation using\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 12:41:34 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Partaourides", "Harris", ""], ["Chatzis", "Sotirios P.", ""]]}, {"id": "1803.01364", "submitter": "Arief Koesdwiady", "authors": "Arief Koesdwiady and Fakhri Karray", "title": "SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary\n  Time Series Prediction", "comments": "submitted to IEEE Trans Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical approach for detecting non-stationarity in\ntime series prediction. This method is called SAFE and works by monitoring the\nevolution of the spectral contents of time series through a distance function.\nThis method is designed to work in combination with state-of-the-art machine\nlearning methods in real time by informing the online predictors to perform\nnecessary adaptation when a non-stationarity presents. We also propose an\nalgorithm to proportionally include some past data in the adaption process to\novercome the Catastrophic Forgetting problem. To validate our hypothesis and\ntest the effectiveness of our approach, we present comprehensive experiments in\ndifferent elements of the approach involving artificial and real-world\ndatasets. The experiments show that the proposed method is able to\nsignificantly save computational resources in term of processor or GPU cycles\nwhile maintaining high prediction performances.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 14:55:33 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:39:25 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Koesdwiady", "Arief", ""], ["Karray", "Fakhri", ""]]}, {"id": "1803.01365", "submitter": "Arief Koesdwiady", "authors": "Arief Koesdwiady, and Fakhri Karray", "title": "New Results on Multi-Step Traffic Flow Prediction", "comments": "submitted to IEEE Trans on ITS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its simplest form, the traffic flow prediction problem is restricted to\npredicting a single time-step into the future. Multi-step traffic flow\nprediction extends this set-up to the case where predicting multiple time-steps\ninto the future based on some finite history is of interest. This problem is\nsignificantly more difficult than its single-step variant and is known to\nsuffer from degradation in predictions as the time step increases. In this\npaper, two approaches to improve multi-step traffic flow prediction performance\nin recursive and multi-output settings are introduced. In particular, a model\nthat allows recursive prediction approaches to take into account the temporal\ncontext in term of time-step index when making predictions is introduced. In\naddition, a conditional generative adversarial network-based data augmentation\nmethod is proposed to improve prediction performance in the multi-output\nsetting. The experiments on a real-world traffic flow dataset show that the two\nmethods improve on multi-step traffic flow prediction in recursive and\nmulti-output settings, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 14:59:55 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:35:10 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Koesdwiady", "Arief", ""], ["Karray", "Fakhri", ""]]}, {"id": "1803.01370", "submitter": "Ching-pei Lee", "authors": "Ching-pei Lee, Cong Han Lim, Stephen J. Wright", "title": "A Distributed Quasi-Newton Algorithm for Empirical Risk Minimization\n  with Nonsmooth Regularization", "comments": "In the proceedings of The 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining, 2018", "journal-ref": null, "doi": "10.1145/3219819.3220075", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a communication- and computation-efficient distributed\noptimization algorithm using second-order information for solving ERM problems\nwith a nonsmooth regularization term. Current second-order and quasi-Newton\nmethods for this problem either do not work well in the distributed setting or\nwork only for specific regularizers. Our algorithm uses successive quadratic\napproximations, and we describe how to maintain an approximation of the Hessian\nand solve subproblems efficiently in a distributed manner. The proposed method\nenjoys global linear convergence for a broad range of non-strongly convex\nproblems that includes the most commonly used ERMs, thus requiring lower\ncommunication complexity. It also converges on non-convex problems, so has the\npotential to be used on applications such as deep learning. Initial\ncomputational results on convex problems demonstrate that our method\nsignificantly improves on communication cost and running time over the current\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 15:37:46 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 06:46:12 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lee", "Ching-pei", ""], ["Lim", "Cong Han", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1803.01420", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Ohad Shamir", "title": "Detecting Correlations with Little Memory and Communication", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2018. Changes: Added a comparison to Raz [2016]; Corrected typos; Added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying correlations in multivariate data, under\ninformation constraints: Either on the amount of memory that can be used by the\nalgorithm, or the amount of communication when the data is distributed across\nseveral machines. We prove a tight trade-off between the memory/communication\ncomplexity and the sample complexity, implying (for example) that to detect\npairwise correlations with optimal sample complexity, the number of required\nmemory/communication bits is at least quadratic in the dimension. Our results\nsubstantially improve those of Shamir [2014], which studied a similar question\nin a much more restricted setting. To the best of our knowledge, these are the\nfirst provable sample/memory/communication trade-offs for a practical\nestimation problem, using standard distributions, and in the natural regime\nwhere the memory/communication budget is larger than the size of a single data\npoint. To derive our theorems, we prove a new information-theoretic result,\nwhich may be relevant for studying other information-constrained learning\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 20:57:42 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 15:14:43 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Dagan", "Yuval", ""], ["Shamir", "Ohad", ""]]}, {"id": "1803.01422", "submitter": "Bryon Aragam", "authors": "Xun Zheng, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing", "title": "DAGs with NO TEARS: Continuous Optimization for Structure Learning", "comments": "22 pages, 8 figures, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the structure of directed acyclic graphs (DAGs, also known as\nBayesian networks) is a challenging problem since the search space of DAGs is\ncombinatorial and scales superexponentially with the number of nodes. Existing\napproaches rely on various local heuristics for enforcing the acyclicity\nconstraint. In this paper, we introduce a fundamentally different strategy: We\nformulate the structure learning problem as a purely \\emph{continuous}\noptimization problem over real matrices that avoids this combinatorial\nconstraint entirely. This is achieved by a novel characterization of acyclicity\nthat is not only smooth but also exact. The resulting problem can be\nefficiently solved by standard numerical algorithms, which also makes\nimplementation effortless. The proposed method outperforms existing ones,\nwithout imposing any structural assumptions on the graph such as bounded\ntreewidth or in-degree. Code implementing the proposed algorithm is open-source\nand publicly available at https://github.com/xunzheng/notears.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 21:09:13 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 01:29:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zheng", "Xun", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1803.01440", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu, Rahul Mazumder, Zhen Zhu, Hossein Vahabi", "title": "Hierarchical Modeling and Shrinkage for User Session Length Prediction\n  in Media Streaming", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important metric of users' satisfaction and engagement within on-line\nstreaming services is the user session length, i.e. the amount of time they\nspend on a service continuously without interruption. Being able to predict\nthis value directly benefits the recommendation and ad pacing contexts in music\nand video streaming services. Recent research has shown that predicting the\nexact amount of time spent is highly nontrivial due to many external factors\nfor which a user can end a session, and the lack of predictive covariates. Most\nof the other related literature on duration based user engagement has focused\non dwell time for websites, for search and display ads, mainly for post-click\nsatisfaction prediction or ad ranking.\n  In this work we present a novel framework inspired by hierarchical Bayesian\nmodeling to predict, at the moment of login, the amount of time a user will\nspend in the streaming service. The time spent by a user on a platform depends\nupon user-specific latent variables which are learned via hierarchical\nshrinkage. Our framework enjoys theoretical guarantees and naturally\nincorporates flexible parametric/nonparametric models on the covariates,\nincluding models robust to outliers. Our proposal is found to outperform\nstate-of- the-art estimators in terms of efficiency and predictive performance\non real world public and private datasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 23:39:43 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 22:29:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Dedieu", "Antoine", ""], ["Mazumder", "Rahul", ""], ["Zhu", "Zhen", ""], ["Vahabi", "Hossein", ""]]}, {"id": "1803.01442", "submitter": "Guneet Dhillon", "authors": "Guneet S. Dhillon, Kamyar Azizzadenesheli, Zachary C. Lipton, Jeremy\n  Bernstein, Jean Kossaifi, Aran Khanna, Anima Anandkumar", "title": "Stochastic Activation Pruning for Robust Adversarial Defense", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to adversarial examples. Carefully\nchosen perturbations to real images, while imperceptible to humans, induce\nmisclassification and threaten the reliability of deep learning systems in the\nwild. To guard against adversarial examples, we take inspiration from game\ntheory and cast the problem as a minimax zero-sum game between the adversary\nand the model. In general, for such games, the optimal strategy for both\nplayers requires a stochastic policy, also known as a mixed strategy. In this\nlight, we propose Stochastic Activation Pruning (SAP), a mixed strategy for\nadversarial defense. SAP prunes a random subset of activations (preferentially\npruning those with smaller magnitude) and scales up the survivors to\ncompensate. We can apply SAP to pretrained networks, including adversarially\ntrained models, without fine-tuning, providing robustness against adversarial\nexamples. Experiments demonstrate that SAP confers robustness against attacks,\nincreasing accuracy and preserving calibration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 00:17:05 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Dhillon", "Guneet S.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Lipton", "Zachary C.", ""], ["Bernstein", "Jeremy", ""], ["Kossaifi", "Jean", ""], ["Khanna", "Aran", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1803.01449", "submitter": "Sohil Shah", "authors": "Sohil Atul Shah and Vladlen Koltun", "title": "Deep Continuous Clustering", "comments": "The code is available at http://github.com/shahsohil/DCC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering high-dimensional datasets is hard because interpoint distances\nbecome less informative in high-dimensional spaces. We present a clustering\nalgorithm that performs nonlinear dimensionality reduction and clustering\njointly. The data is embedded into a lower-dimensional space by a deep\nautoencoder. The autoencoder is optimized as part of the clustering process.\nThe resulting network produces clustered data. The presented approach does not\nrely on prior knowledge of the number of ground-truth clusters. Joint nonlinear\ndimensionality reduction and clustering are formulated as optimization of a\nglobal continuous objective. We thus avoid discrete reconfigurations of the\nobjective that characterize prior clustering algorithms. Experiments on\ndatasets from multiple domains demonstrate that the presented algorithm\noutperforms state-of-the-art clustering schemes, including recent methods that\nuse deep networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 01:15:38 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Shah", "Sohil Atul", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.01465", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Wei Li, Sujian Li, Wenjie Li, Xuancheng Ren", "title": "Query and Output: Generating Words by Querying Distributed Word\n  Representations for Paraphrase Generation", "comments": "arXiv admin note: text overlap with arXiv:1710.02318", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent approaches use the sequence-to-sequence model for paraphrase\ngeneration. The existing sequence-to-sequence model tends to memorize the words\nand the patterns in the training dataset instead of learning the meaning of the\nwords. Therefore, the generated sentences are often grammatically correct but\nsemantically improper. In this work, we introduce a novel model based on the\nencoder-decoder framework, called Word Embedding Attention Network (WEAN). Our\nproposed model generates the words by querying distributed word representations\n(i.e. neural word embeddings), hoping to capturing the meaning of the according\nwords. Following previous work, we evaluate our model on two\nparaphrase-oriented tasks, namely text simplification and short text\nabstractive summarization. Experimental results show that our model outperforms\nthe sequence-to-sequence baseline by the BLEU score of 6.3 and 5.5 on two\nEnglish text simplification datasets, and the ROUGE-2 F1 score of 5.7 on a\nChinese summarization dataset. Moreover, our model achieves state-of-the-art\nperformances on these three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 02:44:42 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 08:44:47 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2018 05:58:59 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Li", "Wei", ""], ["Li", "Sujian", ""], ["Li", "Wenjie", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1803.01485", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, Markus D. Solbach, John K. Tsotsos", "title": "Totally Looks Like - How Humans Compare, Compared to Machines", "comments": "ACCV 2018. Project website:\n  https://sites.google.com/view/totally-looks-like-dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual judgment of image similarity by humans relies on rich internal\nrepresentations ranging from low-level features to high-level concepts, scene\nproperties and even cultural associations. However, existing methods and\ndatasets attempting to explain perceived similarity use stimuli which arguably\ndo not cover the full breadth of factors that affect human similarity\njudgments, even those geared toward this goal. We introduce a new dataset\ndubbed Totally-Looks-Like (TLL) after a popular entertainment website, which\ncontains images paired by humans as being visually similar. The dataset\ncontains 6016 image-pairs from the wild, shedding light upon a rich and diverse\nset of criteria employed by human beings. We conduct experiments to try to\nreproduce the pairings via features extracted from state-of-the-art deep\nconvolutional neural networks, as well as additional human experiments to\nverify the consistency of the collected data. Though we create conditions to\nartificially make the matching task increasingly easier, we show that\nmachine-extracted representations perform very poorly in terms of reproducing\nthe matching selected by humans. We discuss and analyze these results,\nsuggesting future directions for improvement of learned image representations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 03:43:20 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 20:07:19 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 18:31:00 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Solbach", "Markus D.", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1803.01489", "submitter": "Ahmed Hefny", "authors": "Ahmed Hefny, Zita Marinho, Wen Sun, Siddhartha Srinivasa, Geoffrey\n  Gordon", "title": "Recurrent Predictive State Policy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent\narchitecture that brings insights from predictive state representations to\nreinforcement learning in partially observable environments. Predictive state\npolicy networks consist of a recursive filter, which keeps track of a belief\nabout the state of the environment, and a reactive policy that directly maps\nbeliefs to actions, to maximize the cumulative reward. The recursive filter\nleverages predictive state representations (PSRs) (Rosencrantz and Gordon,\n2004; Sun et al., 2016) by modeling predictive state-- a prediction of the\ndistribution of future observations conditioned on history and future actions.\nThis representation gives rise to a rich class of statistically consistent\nalgorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive\nstate serves as an equivalent representation of a belief state. Therefore, the\npolicy component of the RPSP-network can be purely reactive, simplifying\ntraining while still allowing optimal behaviour. Moreover, we use the PSR\ninterpretation during training as well, by incorporating prediction error in\nthe loss function. The entire network (recursive filter and reactive policy) is\nstill differentiable and can be trained using gradient based methods. We\noptimize our policy using a combination of policy gradient based on rewards\n(Williams, 1992) and gradient descent based on prediction error. We show the\nefficacy of RPSP-networks under partial observability on a set of robotic\ncontrol tasks from OpenAI Gym. We empirically show that RPSP-networks perform\nwell compared with memory-preserving networks such as GRUs, as well as finite\nmemory models, being the overall best performing method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 03:59:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Hefny", "Ahmed", ""], ["Marinho", "Zita", ""], ["Sun", "Wen", ""], ["Srinivasa", "Siddhartha", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1803.01498", "submitter": "Dong Yin", "authors": "Dong Yin, Yudong Chen, Kannan Ramchandran, Peter Bartlett", "title": "Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale distributed learning, security issues have become increasingly\nimportant. Particularly in a decentralized environment, some computing units\nmay behave abnormally, or even exhibit Byzantine failures -- arbitrary and\npotentially adversarial behavior. In this paper, we develop distributed\nlearning algorithms that are provably robust against such failures, with a\nfocus on achieving optimal statistical performance. A main result of this work\nis a sharp analysis of two robust distributed gradient descent algorithms based\non median and trimmed mean operations, respectively. We prove statistical error\nrates for three kinds of population loss functions: strongly convex,\nnon-strongly convex, and smooth non-convex. In particular, these algorithms are\nshown to achieve order-optimal statistical error rates for strongly convex\nlosses. To achieve better communication efficiency, we further propose a\nmedian-based distributed algorithm that is provably robust, and uses only one\ncommunication round. For strongly convex quadratic loss, we show that this\nalgorithm achieves the same optimal error rate as the robust distributed\ngradient descent algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 05:04:17 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:34:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Yin", "Dong", ""], ["Chen", "Yudong", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1803.01500", "submitter": "Youngjin Kim", "authors": "Youngjin Kim, Minjung Kim, Gunhee Kim", "title": "Memorization Precedes Generation: Learning Unsupervised GANs with Memory\n  Networks", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to address two issues that commonly occur during\ntraining of unsupervised GANs. First, since GANs use only a continuous latent\ndistribution to embed multiple classes or clusters of data, they often do not\ncorrectly handle the structural discontinuity between disparate classes in a\nlatent space. Second, discriminators of GANs easily forget about past generated\nsamples by generators, incurring instability during adversarial training. We\nargue that these two infamous problems of unsupervised GAN training can be\nlargely alleviated by a learnable memory network to which both generators and\ndiscriminators can access. Generators can effectively learn representation of\ntraining samples to understand underlying cluster distributions of data, which\nease the structure discontinuity problem. At the same time, discriminators can\nbetter memorize clusters of previously generated samples, which mitigate the\nforgetting problem. We propose a novel end-to-end GAN model named memoryGAN,\nwhich involves a memory network that is unsupervisedly trainable and integrable\nto many existing GAN models. With evaluations on multiple datasets such as\nFashion-MNIST, CelebA, CIFAR10, and Chairs, we show that our model is\nprobabilistically interpretable, and generates realistic image samples of high\nvisual fidelity. The memoryGAN also achieves the state-of-the-art inception\nscores over unsupervised GAN models on the CIFAR10 dataset, without any\noptimization tricks and weaker divergences.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 05:17:42 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 02:47:12 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kim", "Youngjin", ""], ["Kim", "Minjung", ""], ["Kim", "Gunhee", ""]]}, {"id": "1803.01526", "submitter": "Avi Caciularu", "authors": "Avi Caciularu, David Burshtein", "title": "Blind Channel Equalization using Variational Autoencoders", "comments": "Accepted to ICC workshop, Promises and Challenges of Machine Learning\n  in Communication Networks (ML4COM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new maximum likelihood estimation approach for blind channel equalization,\nusing variational autoencoders (VAEs), is introduced. Significant and\nconsistent improvements in the error rate of the reconstructed symbols,\ncompared to constant modulus equalizers, are demonstrated. In fact, for the\nchannels that were examined, the performance of the new VAE blind channel\nequalizer was close to the performance of a nonblind adaptive linear minimum\nmean square error equalizer. The new equalization method enables a\nsignificantly lower latency channel acquisition compared to the constant\nmodulus algorithm (CMA). The VAE uses a convolutional neural network with two\nlayers and a very small number of free parameters. Although the computational\ncomplexity of the new equalizer is higher compared to CMA, it is still\nreasonable, and the number of free parameters to estimate is small.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 07:28:51 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Caciularu", "Avi", ""], ["Burshtein", "David", ""]]}, {"id": "1803.01541", "submitter": "Xiang Wei", "authors": "Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, Liqiang Wang", "title": "Improving the Improved Training of Wasserstein GANs: A Consistency Term\n  and Its Dual Effect", "comments": "Accepted as a conference paper in International Conference on\n  Learning Representation(ICLR). Xiang Wei and Boqing Gong contributed equally\n  in this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being impactful on a variety of problems and applications, the\ngenerative adversarial nets (GANs) are remarkably difficult to train. This\nissue is formally analyzed by \\cite{arjovsky2017towards}, who also propose an\nalternative direction to avoid the caveats in the minmax two-player training of\nGANs. The corresponding algorithm, called Wasserstein GAN (WGAN), hinges on the\n1-Lipschitz continuity of the discriminator. In this paper, we propose a novel\napproach to enforcing the Lipschitz continuity in the training procedure of\nWGANs. Our approach seamlessly connects WGAN with one of the recent\nsemi-supervised learning methods. As a result, it gives rise to not only better\nphoto-realistic samples than the previous methods but also state-of-the-art\nsemi-supervised learning results. In particular, our approach gives rise to the\ninception score of more than 5.0 with only 1,000 CIFAR-10 images and is the\nfirst that exceeds the accuracy of 90% on the CIFAR-10 dataset using only 4,000\nlabeled images, to the best of our knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:00:39 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Wei", "Xiang", ""], ["Gong", "Boqing", ""], ["Liu", "Zixia", ""], ["Lu", "Wei", ""], ["Wang", "Liqiang", ""]]}, {"id": "1803.01548", "submitter": "Jason Altschuler", "authors": "Jason Altschuler and Kunal Talwar", "title": "Online learning over a finite action set with limited switching", "comments": "Extended abstract to appear in the proceedings of the 2018 Conference\n  on Learning Theory (COLT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the value of switching actions in the Prediction From\nExperts (PFE) problem and Adversarial Multi-Armed Bandits (MAB) problem. First,\nwe revisit the well-studied and practically motivated setting of PFE with\nswitching costs. Many algorithms are known to achieve the minimax optimal order\nof $O(\\sqrt{T \\log n})$ in expectation for both regret and number of switches,\nwhere $T$ is the number of iterations and $n$ the number of actions. However,\nno high probability (h.p.) guarantees are known. Our main technical\ncontribution is the first algorithms which with h.p. achieve this optimal order\nfor both regret and switches. This settles an open problem of [Devroye et al.,\n2015], and directly implies the first h.p. guarantees for several problems of\ninterest.\n  Next, to investigate the value of switching actions at a more granular level,\nwe introduce the setting of switching budgets, in which algorithms are limited\nto $S \\leq T$ switches between actions. This entails a limited number of free\nswitches, in contrast to the unlimited number of expensive switches in the\nswitching cost setting. Using the above result and several reductions, we unify\nprevious work and completely characterize the complexity of this switching\nbudget setting up to small polylogarithmic factors: for both PFE and MAB, for\nall switching budgets $S \\leq T$, and for both expectation and h.p. guarantees.\nFor PFE, we show the optimal rate is $\\tilde{\\Theta}(\\sqrt{T\\log n})$ for $S =\n\\Omega(\\sqrt{T\\log n})$, and $\\min(\\tilde{\\Theta}(\\tfrac{T\\log n}{S}), T)$ for\n$S = O(\\sqrt{T \\log n})$. Interestingly, the bandit setting does not exhibit\nsuch a phase transition; instead we show the minimax rate decays steadily as\n$\\min(\\tilde{\\Theta}(\\tfrac{T\\sqrt{n}}{\\sqrt{S}}), T)$ for all ranges of $S\n\\leq T$. These results recover and generalize the known minimax rates for the\n(arbitrary) switching cost setting.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:13:18 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 21:24:06 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Altschuler", "Jason", ""], ["Talwar", "Kunal", ""]]}, {"id": "1803.01562", "submitter": "Hossein Rajabzadeh", "authors": "Hossein Rajabzadeh, Mansoor Zolghadri Jahromi, Mohammad Sadegh Zare,\n  Mostafa Fakhrahmad", "title": "Local Distance Metric Learning for Nearest Neighbor Algorithm", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning is a successful way to enhance the performance of\nthe nearest neighbor classifier. In most cases, however, the distribution of\ndata does not obey a regular form and may change in different parts of the\nfeature space. Regarding that, this paper proposes a novel local distance\nmetric learning method, namely Local Mahalanobis Distance Learning (LMDL), in\norder to enhance the performance of the nearest neighbor classifier. LMDL\nconsiders the neighborhood influence and learns multiple distance metrics for a\nreduced set of input samples. The reduced set is called as prototypes which try\nto preserve local discriminative information as much as possible. The proposed\nLMDL can be kernelized very easily, which is significantly desirable in the\ncase of highly nonlinear data. The quality as well as the efficiency of the\nproposed method assesses through a set of different experiments on various\ndatasets and the obtained results show that LDML as well as the kernelized\nversion is superior to the other related state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:45:47 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 20:21:22 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Rajabzadeh", "Hossein", ""], ["Jahromi", "Mansoor Zolghadri", ""], ["Zare", "Mohammad Sadegh", ""], ["Fakhrahmad", "Mostafa", ""]]}, {"id": "1803.01570", "submitter": "Rohit Babbar", "authors": "Rohit Babbar, Bernhard Sch\\\"olkopf", "title": "Adversarial Extreme Multi-label Classification", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal in extreme multi-label classification is to learn a classifier which\ncan assign a small subset of relevant labels to an instance from an extremely\nlarge set of target labels. Datasets in extreme classification exhibit a long\ntail of labels which have small number of positive training instances. In this\nwork, we pose the learning task in extreme classification with large number of\ntail-labels as learning in the presence of adversarial perturbations. This view\nmotivates a robust optimization framework and equivalence to a corresponding\nregularized objective.\n  Under the proposed robustness framework, we demonstrate efficacy of Hamming\nloss for tail-label detection in extreme classification. The equivalent\nregularized objective, in combination with proximal gradient based\noptimization, performs better than state-of-the-art methods on propensity\nscored versions of precision@k and nDCG@k(upto 20% relative improvement over\nPFastreXML - a leading tree-based approach and 60% relative improvement over\nSLEEC - a leading label-embedding approach). Furthermore, we also highlight the\nsub-optimality of a sparse solver in a widely used package for large-scale\nlinear classification, which is interesting in its own right. We also\ninvestigate the spectral properties of label graphs for providing novel\ninsights towards understanding the conditions governing the performance of\nHamming loss based one-vs-rest scheme vis-\\`a-vis label embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:30:46 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Babbar", "Rohit", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1803.01575", "submitter": "Michiel Stock", "authors": "Michiel Stock, Tapio Pahikkala, Antti Airola, Bernard De Baets, Willem\n  Waegeman", "title": "A Comparative Study of Pairwise Learning Methods based on Kernel Ridge\n  Regression", "comments": "arXiv admin note: text overlap with arXiv:1606.04275", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems can be formulated as predicting labels for a\npair of objects. Problems of that kind are often referred to as pairwise\nlearning, dyadic prediction or network inference problems. During the last\ndecade kernel methods have played a dominant role in pairwise learning. They\nstill obtain a state-of-the-art predictive performance, but a theoretical\nanalysis of their behavior has been underexplored in the machine learning\nliterature.\n  In this work we review and unify existing kernel-based algorithms that are\ncommonly used in different pairwise learning settings, ranging from matrix\nfiltering to zero-shot learning. To this end, we focus on closed-form efficient\ninstantiations of Kronecker kernel ridge regression. We show that independent\ntask kernel ridge regression, two-step kernel ridge regression and a linear\nmatrix filter arise naturally as a special case of Kronecker kernel ridge\nregression, implying that all these methods implicitly minimize a squared loss.\nIn addition, we analyze universality, consistency and spectral filtering\nproperties. Our theoretical results provide valuable insights in assessing the\nadvantages and limitations of existing pairwise learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:49:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Stock", "Michiel", ""], ["Pahikkala", "Tapio", ""], ["Airola", "Antti", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "1803.01588", "submitter": "Risi Kondor", "authors": "Risi Kondor", "title": "N-body Networks: a Covariant Hierarchical Neural Network Architecture\n  for Learning Atomic Potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe N-body networks, a neural network architecture for learning the\nbehavior and properties of complex many body physical systems. Our specific\napplication is to learn atomic potential energy surfaces for use in molecular\ndynamics simulations. Our architecture is novel in that (a) it is based on a\nhierarchical decomposition of the many body system into subsytems, (b) the\nactivations of the network correspond to the internal state of each subsystem,\n(c) the \"neurons\" in the network are constructed explicitly so as to guarantee\nthat each of the activations is covariant to rotations, (d) the neurons operate\nentirely in Fourier space, and the nonlinearities are realized by tensor\nproducts followed by Clebsch-Gordan decompositions. As part of the description\nof our network, we give a characterization of what way the weights of the\nnetwork may interact with the activations so as to ensure that the covariance\nproperty is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 10:17:01 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Kondor", "Risi", ""]]}, {"id": "1803.01626", "submitter": "M. Sadegh Talebi", "authors": "Mohammad Sadegh Talebi and Odalric-Ambrym Maillard", "title": "Variance-Aware Regret Bounds for Undiscounted Reinforcement Learning in\n  MDPs", "comments": "To appear in Proceedings of the 29th International Conference on\n  Algorithmic Learning Theory (ALT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of reinforcement learning in an unknown and discrete Markov\nDecision Process (MDP) under the average-reward criterion is considered, when\nthe learner interacts with the system in a single stream of observations,\nstarting from an initial state without any reset. We revisit the minimax lower\nbound for that problem by making appear the local variance of the bias function\nin place of the diameter of the MDP. Furthermore, we provide a novel analysis\nof the KL-UCRL algorithm establishing a high-probability regret bound scaling\nas $\\widetilde {\\mathcal O}\\Bigl({\\textstyle \\sqrt{S\\sum_{s,a}{\\bf\nV}^\\star_{s,a}T}}\\Big)$ for this algorithm for ergodic MDPs, where $S$ denotes\nthe number of states and where ${\\bf V}^\\star_{s,a}$ is the variance of the\nbias function with respect to the next-state distribution following action $a$\nin state $s$. The resulting bound improves upon the best previously known\nregret bound $\\widetilde {\\mathcal O}(DS\\sqrt{AT})$ for that algorithm, where\n$A$ and $D$ respectively denote the maximum number of actions (per state) and\nthe diameter of MDP. We finally compare the leading terms of the two bounds in\nsome benchmark MDPs indicating that the derived bound can provide an order of\nmagnitude improvement in some cases. Our analysis leverages novel variations of\nthe transportation lemma combined with Kullback-Leibler concentration\ninequalities, that we believe to be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 12:23:42 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Talebi", "Mohammad Sadegh", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "1803.01682", "submitter": "Ray Jiang", "authors": "Ray Jiang, Sven Gowal, Timothy A. Mann, Danilo J. Rezende", "title": "Beyond Greedy Ranking: Slate Optimization via List-CVAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional solution to the recommendation problem greedily ranks\nindividual document candidates by prediction scores. However, this method fails\nto optimize the slate as a whole, and hence, often struggles to capture biases\ncaused by the page layout and document interdepedencies. The slate\nrecommendation problem aims to directly find the optimally ordered subset of\ndocuments (i.e. slates) that best serve users' interests. Solving this problem\nis hard due to the combinatorial explosion in all combinations of document\ncandidates and their display positions on the page. Therefore we propose a\nparadigm shift from the traditional viewpoint of solving a ranking problem to a\ndirect slate generation framework. In this paper, we introduce List Conditional\nVariational Auto-Encoders (List-CVAE), which learns the joint distribution of\ndocuments on the slate conditioned on user responses, and directly generates\nfull slates. Experiments on simulated and real-world data show that List-CVAE\noutperforms popular comparable ranking methods consistently on various scales\nof documents corpora.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 14:40:56 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 22:46:30 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 11:12:49 GMT"}, {"version": "v4", "created": "Wed, 23 May 2018 09:08:19 GMT"}, {"version": "v5", "created": "Thu, 24 May 2018 10:29:00 GMT"}, {"version": "v6", "created": "Sat, 23 Feb 2019 13:56:39 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jiang", "Ray", ""], ["Gowal", "Sven", ""], ["Mann", "Timothy A.", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "1803.01686", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, C.-C. Jay Kuo", "title": "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent\n  Neural Network", "comments": "github repo: https://github.com/yuanhangsu/ELSTM-DBRNN", "journal-ref": "Neurocomputing 356 (2019): 151-161", "doi": "10.1016/j.neucom.2019.04.044", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first analyze the memory behavior in three recurrent neural\nnetworks (RNN) cells; namely, the simple RNN (SRN), the long short-term memory\n(LSTM) and the gated recurrent unit (GRU), where the memory is defined as a\nfunction that maps previous elements in a sequence to the current output. Our\nstudy shows that all three of them suffer rapid memory decay. Then, to\nalleviate this effect, we introduce trainable scaling factors that act like an\nattention mechanism to adjust memory decay adaptively. The new design is called\nthe extended LSTM (ELSTM). Finally, to design a system that is robust to\nprevious erroneous predictions, we propose a dependent bidirectional recurrent\nneural network (DBRNN). Extensive experiments are conducted on different\nlanguage tasks to demonstrate the superiority of the proposed ELSTM and DBRNN\nsolutions. The ELTSM has achieved up to 30% increase in the labeled attachment\nscore (LAS) as compared to LSTM and GRU in the dependency parsing (DP) task.\nOur models also outperform other state-of-the-art models such as bi-attention\nand convolutional sequence to sequence (convseq2seq) by close to 10% in the\nLAS. The code is released as an open source\n(https://github.com/yuanhangsu/ELSTM-DBRNN)\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:47:13 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 05:43:49 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 04:30:02 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 23:26:31 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 21:39:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Su", "Yuanhang", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1803.01719", "submitter": "Boris Hanin", "authors": "Boris Hanin, David Rolnick", "title": "How to Start Training: The Effect of Initialization and Architecture", "comments": "Final Version, 16p, Accepted NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and study two common failure modes for early training in deep\nReLU nets. For each we give a rigorous proof of when it occurs and how to avoid\nit, for fully connected and residual architectures. The first failure mode,\nexploding/vanishing mean activation length, can be avoided by initializing\nweights from a symmetric distribution with variance 2/fan-in and, for ResNets,\nby correctly weighting the residual modules. We prove that the second failure\nmode, exponentially large variance of activation length, never occurs in\nresidual nets once the first failure mode is avoided. In contrast, for fully\nconnected nets, we prove that this failure mode can happen and is avoided by\nkeeping constant the sum of the reciprocals of layer widths. We demonstrate\nempirically the effectiveness of our theoretical results in predicting when\nnetworks are able to start training. In particular, we note that many popular\ninitializations fail our criteria, whereas correct initialization and\narchitecture allows much deeper networks to be trained.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:17:50 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 13:37:00 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 14:52:46 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hanin", "Boris", ""], ["Rolnick", "David", ""]]}, {"id": "1803.01768", "submitter": "Wei Hu", "authors": "Sanjeev Arora, Wei Hu, Pravesh K. Kothari", "title": "An Analysis of the t-SNE Algorithm for Data Visualization", "comments": "In Conference on Learning Theory (COLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A first line of attack in exploratory data analysis is data visualization,\ni.e., generating a 2-dimensional representation of data that makes clusters of\nsimilar points visually identifiable. Standard Johnson-Lindenstrauss\ndimensionality reduction does not produce data visualizations. The t-SNE\nheuristic of van der Maaten and Hinton, which is based on non-convex\noptimization, has become the de facto standard for visualization in a wide\nrange of applications.\n  This work gives a formal framework for the problem of data visualization -\nfinding a 2-dimensional embedding of clusterable data that correctly separates\nindividual clusters to make them visually identifiable. We then give a rigorous\nanalysis of the performance of t-SNE under a natural, deterministic condition\non the \"ground-truth\" clusters (similar to conditions assumed in earlier\nanalyses of clustering) in the underlying data. These are the first provable\nguarantees on t-SNE for constructing good data visualizations.\n  We show that our deterministic condition is satisfied by considerably general\nprobabilistic generative models for clusterable data such as mixtures of\nwell-separated log-concave distributions. Finally, we give theoretical evidence\nthat t-SNE provably succeeds in partially recovering cluster structure even\nwhen the above deterministic condition is not met.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 16:48:58 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 19:27:28 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Arora", "Sanjeev", ""], ["Hu", "Wei", ""], ["Kothari", "Pravesh K.", ""]]}, {"id": "1803.01777", "submitter": "Peter Englert", "authors": "Peter Englert and Marc Toussaint", "title": "Kinematic Morphing Networks for Manipulation Skill Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer of a robot skill between different geometric environments is\nnon-trivial since a wide variety of environments exists, sensor observations as\nwell as robot motions are high-dimensional, and the environment might only be\npartially observed. We consider the problem of extracting a low-dimensional\ndescription of the manipulated environment in form of a kinematic model. This\nallows us to transfer a skill by defining a policy on a prototype model and\nmorphing the observed environment to this prototype. A deep neural network is\nused to map depth image observations of the environment to morphing parameter,\nwhich include transformation and configuration parameters of the prototype\nmodel. Using the concatenation property of affine transformations and the\nability to convert point clouds to depth images allows to apply the network in\nan iterative manner. The network is trained on data generated in a simulator\nand on augmented data that is created by using network predictions. The\nalgorithm is evaluated on different tasks, where it is shown that iterative\npredictions lead to a higher accuracy than one-step predictions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:10:46 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Englert", "Peter", ""], ["Toussaint", "Marc", ""]]}, {"id": "1803.01785", "submitter": "Sebastian Tschiatschek", "authors": "Sebastian Tschiatschek, Aytunc Sahin, Andreas Krause", "title": "Differentiable Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning of submodular functions from data. These functions are\nimportant in machine learning and have a wide range of applications, e.g. data\nsummarization, feature selection and active learning. Despite their\ncombinatorial nature, submodular functions can be maximized approximately with\nstrong theoretical guarantees in polynomial time. Typically, learning the\nsubmodular function and optimization of that function are treated separately,\ni.e. the function is first learned using a proxy objective and subsequently\nmaximized. In contrast, we show how to perform learning and optimization\njointly. By interpreting the output of greedy maximization algorithms as\ndistributions over sequences of items and smoothening these distributions, we\nobtain a differentiable objective. In this way, we can differentiate through\nthe maximization algorithms and optimize the model to work well with the\noptimization algorithm. We theoretically characterize the error made by our\napproach, yielding insights into the tradeoff of smoothness and accuracy. We\ndemonstrate the effectiveness of our approach for jointly learning and\noptimizing on synthetic maximum cut data, and on real world applications such\nas product recommendation and image collection summarization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:16:22 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 20:06:50 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Tschiatschek", "Sebastian", ""], ["Sahin", "Aytunc", ""], ["Krause", "Andreas", ""]]}, {"id": "1803.01798", "submitter": "Xintao Wu", "authors": "Panpan Zheng and Shuhan Yuan and Xintao Wu and Jun Li and Aidong Lu", "title": "One-Class Adversarial Nets for Fraud Detection", "comments": "Update Fig 2, add Fig 7, and add references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online applications, such as online social networks or knowledge bases,\nare often attacked by malicious users who commit different types of actions\nsuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most\nof the fraud detection approaches require a training dataset that contains\nrecords of both benign and malicious users. However, in practice, there are\noften no or very few records of malicious users. In this paper, we develop\none-class adversarial nets (OCAN) for fraud detection using training data with\nonly benign users. OCAN first uses LSTM-Autoencoder to learn the\nrepresentations of benign users from their sequences of online activities. It\nthen detects malicious users by training a discriminator with a complementary\nGAN model that is different from the regular GAN model. Experimental results\nshow that our OCAN outperforms the state-of-the-art one-class classification\nmodels and achieves comparable performance with the latest multi-source LSTM\nmodel that requires both benign and malicious users in the training phase.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:40:24 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 19:56:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Li", "Jun", ""], ["Lu", "Aidong", ""]]}, {"id": "1803.01814", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Ron Banner, Itay Golan, Daniel Soudry", "title": "Norm matters: efficient and accurate normalization schemes in deep\n  networks", "comments": "http://papers.nips.cc/paper/7485-norm-matters-efficient-and-accurate-normalization-schemes-in-deep-networks", "journal-ref": "NeurIPS2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, Batch-Normalization has been commonly used in deep\nnetworks, allowing faster training and high performance for a wide variety of\napplications. However, the reasons behind its merits remained unanswered, with\nseveral shortcomings that hindered its use for certain tasks. In this work, we\npresent a novel view on the purpose and function of normalization methods and\nweight-decay, as tools to decouple weights' norm from the underlying optimized\nobjective. This property highlights the connection between practices such as\nnormalization, weight decay and learning-rate adjustments. We suggest several\nalternatives to the widely used $L^2$ batch-norm, using normalization in $L^1$\nand $L^\\infty$ spaces that can substantially improve numerical stability in\nlow-precision implementations as well as provide computational and memory\nbenefits. We demonstrate that such methods enable the first batch-norm\nalternative to work for half-precision implementations. Finally, we suggest a\nmodification to weight-normalization, which improves its performance on\nlarge-scale tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:16:43 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 13:37:48 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 13:01:44 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Hoffer", "Elad", ""], ["Banner", "Ron", ""], ["Golan", "Itay", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.01833", "submitter": "Guillaume Martinet", "authors": "Samory Kpotufe, Guillaume Martinet", "title": "Marginal Singularity, and the Benefits of Labels in Covariate-Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new minimax results that concisely capture the relative benefits\nof source and target labeled data, under covariate-shift. Namely, we show that\nthe benefits of target labels are controlled by a transfer-exponent $\\gamma$\nthat encodes how singular Q is locally w.r.t. P, and interestingly allows\nsituations where transfer did not seem possible under previous insights. In\nfact, our new minimax analysis - in terms of $\\gamma$ - reveals a continuum of\nregimes ranging from situations where target labels have little benefit, to\nregimes where target labels dramatically improve classification. We then show\nthat a recently proposed semi-supervised procedure can be extended to adapt to\nunknown $\\gamma$, and therefore requests labels only when beneficial, while\nachieving minimax transfer rates.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:52:08 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 17:31:45 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 04:57:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kpotufe", "Samory", ""], ["Martinet", "Guillaume", ""]]}, {"id": "1803.01834", "submitter": "Alexander Ororbia II", "authors": "Alexander G. Ororbia, Ankur Mali, Daniel Kifer, and C. Lee Giles", "title": "Conducting Credit Assignment by Aligning Local Representations", "comments": "Full document revision/overhaul, new results/analyses, new diagrams,\n  addition of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using back-propagation and its variants to train deep networks is often\nproblematic for new users. Issues such as exploding gradients, vanishing\ngradients, and high sensitivity to weight initialization strategies often make\nnetworks difficult to train, especially when users are experimenting with new\narchitectures. Here, we present Local Representation Alignment (LRA), a\ntraining procedure that is much less sensitive to bad initializations, does not\nrequire modifications to the network architecture, and can be adapted to\nnetworks with highly nonlinear and discrete-valued activation functions.\nFurthermore, we show that one variation of LRA can start with a null\ninitialization of network weights and still successfully train networks with a\nwide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and\nothers that may draw their inspiration from biology.\n  A comprehensive set of experiments on MNIST and the much harder Fashion MNIST\ndata sets show that LRA can be used to train networks robustly and effectively,\nsucceeding even when back-propagation fails and outperforming other alternative\nlearning algorithms, such as target propagation and feedback alignment.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:54:02 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 21:10:27 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "1803.01837", "submitter": "Chen-Hsuan Lin", "authors": "Chen-Hsuan Lin, Ersin Yumer, Oliver Wang, Eli Shechtman, Simon Lucey", "title": "ST-GAN: Spatial Transformer Generative Adversarial Networks for Image\n  Compositing", "comments": "Accepted to CVPR 2018 (website & code:\n  https://chenhsuanlin.bitbucket.io/spatial-transformer-GAN/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding realistic geometric corrections to a\nforeground object such that it appears natural when composited into a\nbackground image. To achieve this, we propose a novel Generative Adversarial\nNetwork (GAN) architecture that utilizes Spatial Transformer Networks (STNs) as\nthe generator, which we call Spatial Transformer GANs (ST-GANs). ST-GANs seek\nimage realism by operating in the geometric warp parameter space. In\nparticular, we exploit an iterative STN warping scheme and propose a sequential\ntraining strategy that achieves better results compared to naive training of a\nsingle generator. One of the key advantages of ST-GAN is its applicability to\nhigh-resolution images indirectly since the predicted warp parameters are\ntransferable between reference frames. We demonstrate our approach in two\napplications: (1) visualizing how indoor furniture (e.g. from product images)\nmight be perceived in a room, (2) hallucinating how accessories like glasses\nwould look when matched with real portraits.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 18:59:01 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Lin", "Chen-Hsuan", ""], ["Yumer", "Ersin", ""], ["Wang", "Oliver", ""], ["Shechtman", "Eli", ""], ["Lucey", "Simon", ""]]}, {"id": "1803.01840", "submitter": "Kyriacos Shiarlis Mr", "authors": "Kyriacos Shiarlis, Markus Wulfmeier, Sasha Salter, Shimon Whiteson,\n  Ingmar Posner", "title": "TACO: Learning Task Decomposition via Temporal Alignment for Control", "comments": "12 Pages. Published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many advanced Learning from Demonstration (LfD) methods consider the\ndecomposition of complex, real-world tasks into simpler sub-tasks. By reusing\nthe corresponding sub-policies within and between tasks, they provide training\ndata for each policy from different high-level tasks and compose them to\nperform novel ones. Existing approaches to modular LfD focus either on learning\na single high-level task or depend on domain knowledge and temporal\nsegmentation. In contrast, we propose a weakly supervised, domain-agnostic\napproach based on task sketches, which include only the sequence of sub-tasks\nperformed in each demonstration. Our approach simultaneously aligns the\nsketches with the observed demonstrations and learns the required sub-policies.\nThis improves generalisation in comparison to separate optimisation procedures.\nWe evaluate the approach on multiple domains, including a simulated 3D robot\narm control task using purely image-based observations. The results show that\nour approach performs commensurately with fully supervised approaches, while\nrequiring significantly less annotation effort.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:26:16 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 09:07:40 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Shiarlis", "Kyriacos", ""], ["Wulfmeier", "Markus", ""], ["Salter", "Sasha", ""], ["Whiteson", "Shimon", ""], ["Posner", "Ingmar", ""]]}, {"id": "1803.01843", "submitter": "Mojtaba Barzegari", "authors": "Mojtaba Barzegari, Bahman Vahidi, Mohammad Reza Safarinejad, Marzieh\n  Hashemipour", "title": "Pathological Analysis of Stress Urinary Incontinence in Females using\n  Artificial Neural Networks", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: To mathematically investigate urethral pressure and influencing\nparameters of stress urinary incontinence (SUI) in women, with focus on the\nclinical aspects of the mathematical modeling.\n  Method: Several patients' data are extracted from UPP and urodynamic\ndocuments and their relation and affinities are modeled using an artificial\nneural network (ANN) model. The studied parameter is urethral pressure as a\nfunction of two variables: the age of the patient and the position in which the\npressure was measured across the urethra (normalized length).\n  Results: The ANN-generated surface, showing the relation between the chosen\nparameters and the urethral pressure in the studied patients, is more efficient\nthan the surface generated by conventional mathematical methods for clinical\nanalysis, with multi-sample analysis being obtained. For example, in elderly\npeople, there are many low-pressure zones throughout the urethra length,\nindicating that there is more incontinence in old age.\n  Conclusion: The predictions of urethral pressure made by the trained neural\nnetwork model in relation to the studied effective parameters can be used to\nbuild a medical assistance system in order to help clinicians diagnose urinary\nincontinence problems more efficiently.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 15:05:51 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Barzegari", "Mojtaba", ""], ["Vahidi", "Bahman", ""], ["Safarinejad", "Mohammad Reza", ""], ["Hashemipour", "Marzieh", ""]]}, {"id": "1803.01848", "submitter": "Yu Shi", "authors": "Yu Shi and Huan Gui and Qi Zhu and Lance Kaplan and Jiawei Han", "title": "AspEm: Embedding Learning by Aspects in Heterogeneous Information\n  Networks", "comments": "11 pages including additional supplementary materials. In Proceedings\n  of the 2018 SIAM International Conference on Data Mining, San Diego,\n  California, USA, SIAM, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information networks (HINs) are ubiquitous in real-world\napplications. Due to the heterogeneity in HINs, the typed edges may not fully\nalign with each other. In order to capture the semantic subtlety, we propose\nthe concept of aspects with each aspect being a unit representing one\nunderlying semantic facet. Meanwhile, network embedding has emerged as a\npowerful method for learning network representation, where the learned\nembedding can be used as features in various downstream applications.\nTherefore, we are motivated to propose a novel embedding learning\nframework---AspEm---to preserve the semantic information in HINs based on\nmultiple aspects. Instead of preserving information of the network in one\nsemantic space, AspEm encapsulates information regarding each aspect\nindividually. In order to select aspects for embedding purpose, we further\ndevise a solution for AspEm based on dataset-wide statistics. To corroborate\nthe efficacy of AspEm, we conducted experiments on two real-words datasets with\ntwo types of applications---classification and link prediction. Experiment\nresults demonstrate that AspEm can outperform baseline network embedding\nlearning methods by considering multiple aspects, where the aspects can be\nselected from the given HIN in an unsupervised manner.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:17:38 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Shi", "Yu", ""], ["Gui", "Huan", ""], ["Zhu", "Qi", ""], ["Kaplan", "Lance", ""], ["Han", "Jiawei", ""]]}, {"id": "1803.01901", "submitter": "Xintao Wu", "authors": "Yongkai Wu and Lu Zhang and Xintao Wu", "title": "On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 19:53:40 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1803.01905", "submitter": "Mor Shpigel Nacson", "authors": "Mor Shpigel Nacson, Jason D. Lee, Suriya Gunasekar, Pedro H. P.\n  Savarese, Nathan Srebro, Daniel Soudry", "title": "Convergence of Gradient Descent on Separable Data", "comments": "AISTATS Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a detailed study on the implicit bias of gradient descent when\noptimizing loss functions with strictly monotone tails, such as the logistic\nloss, over separable datasets. We look at two basic questions: (a) what are the\nconditions on the tail of the loss function under which gradient descent\nconverges in the direction of the $L_2$ maximum-margin separator? (b) how does\nthe rate of margin convergence depend on the tail of the loss function and the\nchoice of the step size? We show that for a large family of super-polynomial\ntailed losses, gradient descent iterates on linear networks of any depth\nconverge in the direction of $L_2$ maximum-margin solution, while this does not\nhold for losses with heavier tails. Within this family, for simple linear\nmodels we show that the optimal rates with fixed step size is indeed obtained\nfor the commonly used exponentially tailed losses such as logistic loss.\nHowever, with a fixed step size the optimal convergence rate is extremely slow\nas $1/\\log(t)$, as also proved in Soudry et al. (2018). For linear models with\nexponential loss, we further prove that the convergence rate could be improved\nto $\\log (t) /\\sqrt{t}$ by using aggressive step sizes that compensates for the\nrapidly vanishing gradients. Numerical results suggest this method might be\nuseful for deep networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 20:03:46 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 11:55:53 GMT"}, {"version": "v3", "created": "Sun, 24 Mar 2019 09:56:50 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nacson", "Mor Shpigel", ""], ["Lee", "Jason D.", ""], ["Gunasekar", "Suriya", ""], ["Savarese", "Pedro H. P.", ""], ["Srebro", "Nathan", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.01927", "submitter": "Alpha Albert Lee", "authors": "Yao Zhang, Andrew M. Saxe, Madhu S. Advani, Alpha A. Lee", "title": "Energy-entropy competition and the effectiveness of stochastic gradient\n  descent in machine learning", "comments": null, "journal-ref": null, "doi": "10.1080/00268976.2018.1483535", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding parameters that minimise a loss function is at the core of many\nmachine learning methods. The Stochastic Gradient Descent algorithm is widely\nused and delivers state of the art results for many problems. Nonetheless,\nStochastic Gradient Descent typically cannot find the global minimum, thus its\nempirical effectiveness is hitherto mysterious. We derive a correspondence\nbetween parameter inference and free energy minimisation in statistical\nphysics. The degree of undersampling plays the role of temperature. Analogous\nto the energy-entropy competition in statistical physics, wide but shallow\nminima can be optimal if the system is undersampled, as is typical in many\napplications. Moreover, we show that the stochasticity in the algorithm has a\nnon-trivial correlation structure which systematically biases it towards wide\nminima. We illustrate our argument with two prototypical models: image\nclassification using deep learning, and a linear neural network where we can\nanalytically reveal the relationship between entropy and out-of-sample error.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:12:04 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Zhang", "Yao", ""], ["Saxe", "Andrew M.", ""], ["Advani", "Madhu S.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "1803.01960", "submitter": "Giancarlo Fissore", "authors": "Aur\\'elien Decelle, Giancarlo Fissore, Cyril Furtlehner", "title": "Thermodynamics of Restricted Boltzmann Machines and related learning\n  dynamics", "comments": "35 pages, 9 figures", "journal-ref": "Decelle, A., Fissore, G. & Furtlehner, C. J Stat Phys (2018)", "doi": "10.1007/s10955-018-2105-y", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the thermodynamic properties of a Restricted Boltzmann Machine\n(RBM), a simple energy-based generative model used in the context of\nunsupervised learning. Assuming the information content of this model to be\nmainly reflected by the spectral properties of its weight matrix $W$, we try to\nmake a realistic analysis by averaging over an appropriate statistical ensemble\nof RBMs.\n  First, a phase diagram is derived. Otherwise similar to that of the\nSherrington- Kirkpatrick (SK) model with ferromagnetic couplings, the RBM's\nphase diagram presents a ferromagnetic phase which may or may not be of\ncompositional type depending on the kurtosis of the distribution of the\ncomponents of the singular vectors of $W$.\n  Subsequently, the learning dynamics of the RBM is studied in the\nthermodynamic limit. A \"typical\" learning trajectory is shown to solve an\neffective dynamical equation, based on the aforementioned ensemble average and\nexplicitly involving order parameters obtained from the thermodynamic analysis.\nIn particular, this let us show how the evolution of the dominant singular\nvalues of $W$, and thus of the unstable modes, is driven by the input data. At\nthe beginning of the training, in which the RBM is found to operate in the\nlinear regime, the unstable modes reflect the dominant covariance modes of the\ndata. In the non-linear regime, instead, the selected modes interact and\neventually impose a matching of the order parameters to their empirical\ncounterparts estimated from the data.\n  Finally, we illustrate our considerations by performing experiments on both\nartificial and real data, showing in particular how the RBM operates in the\nferromagnetic compositional phase.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 23:46:27 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 17:48:37 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["Fissore", "Giancarlo", ""], ["Furtlehner", "Cyril", ""]]}, {"id": "1803.01968", "submitter": "Theja Tulabandhula", "authors": "Debjyoti Saharoy and Theja Tulabandhula", "title": "An Online Algorithm for Learning Buyer Behavior under Realistic Pricing\n  Restrictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new efficient online algorithm to learn the parameters governing\nthe purchasing behavior of a utility maximizing buyer, who responds to prices,\nin a repeated interaction setting. The key feature of our algorithm is that it\ncan learn even non-linear buyer utility while working with arbitrary price\nconstraints that the seller may impose. This overcomes a major shortcoming of\nprevious approaches, which use unrealistic prices to learn these parameters\nmaking them unsuitable in practice.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 00:48:02 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Saharoy", "Debjyoti", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1803.01980", "submitter": "Luke Pfister", "authors": "Luke Pfister, Yoram Bresler", "title": "Learning Filter Bank Sparsifying Transforms", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2883021", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is said to follow the transform (or analysis) sparsity model if it\nbecomes sparse when acted on by a linear operator called a sparsifying\ntransform. Several algorithms have been designed to learn such a transform\ndirectly from data, and data-adaptive sparsifying transforms have demonstrated\nexcellent performance in signal restoration tasks. Sparsifying transforms are\ntypically learned using small sub-regions of data called patches, but these\nalgorithms often ignore redundant information shared between neighboring\npatches.\n  We show that many existing transform and analysis sparse representations can\nbe viewed as filter banks, thus linking the local properties of patch-based\nmodel to the global properties of a convolutional model. We propose a new\ntransform learning framework where the sparsifying transform is an undecimated\nperfect reconstruction filter bank. Unlike previous transform learning\nalgorithms, the filter length can be chosen independently of the number of\nfilter bank channels. Numerical results indicate filter bank sparsifying\ntransforms outperform existing patch-based transform learning for image\ndenoising while benefiting from additional flexibility in the design process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:35:01 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Pfister", "Luke", ""], ["Bresler", "Yoram", ""]]}, {"id": "1803.02007", "submitter": "Kapil Katyal", "authors": "Kapil Katyal, Katie Popek, Chris Paxton, Joseph Moore, Kevin Wolfe,\n  Philippe Burlina, and Gregory D. Hager", "title": "Occupancy Map Prediction Using Generative and Fully Convolutional\n  Networks for Vehicle Navigation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast, collision-free motion through unknown environments remains a\nchallenging problem for robotic systems. In these situations, the robot's\nability to reason about its future motion is often severely limited by sensor\nfield of view (FOV). By contrast, biological systems routinely make decisions\nby taking into consideration what might exist beyond their FOV based on prior\nexperience. In this paper, we present an approach for predicting occupancy map\nrepresentations of sensor data for future robot motions using deep neural\nnetworks. We evaluate several deep network architectures, including purely\ngenerative and adversarial models. Testing on both simulated and real\nenvironments we demonstrated performance both qualitatively and quantitatively,\nwith SSIM similarity measure up to 0.899. We showed that it is possible to make\npredictions about occupied space beyond the physical robot's FOV from simulated\ntraining data. In the future, this method will allow robots to navigate through\nunknown environments in a faster, safer manner.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 04:01:37 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Katyal", "Kapil", ""], ["Popek", "Katie", ""], ["Paxton", "Chris", ""], ["Moore", "Joseph", ""], ["Wolfe", "Kevin", ""], ["Burlina", "Philippe", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1803.02021", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Mengye Ren, Renjie Liao, Roger Grosse", "title": "Understanding Short-Horizon Bias in Stochastic Meta-Optimization", "comments": "17 pages, 8 figures; To appear in ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Careful tuning of the learning rate, or even schedules thereof, can be\ncrucial to effective neural net training. There has been much recent interest\nin gradient-based meta-optimization, where one tunes hyperparameters, or even\nlearns an optimizer, in order to minimize the expected loss when the training\nprocedure is unrolled. But because the training procedure must be unrolled\nthousands of times, the meta-objective must be defined with an\norders-of-magnitude shorter time horizon than is typical for neural net\ntraining. We show that such short-horizon meta-objectives cause a serious bias\ntowards small step sizes, an effect we term short-horizon bias. We introduce a\ntoy problem, a noisy quadratic cost function, on which we analyze short-horizon\nbias by deriving and comparing the optimal schedules for short and long time\nhorizons. We then run meta-optimization experiments (both offline and online)\non standard benchmark datasets, showing that meta-optimization chooses too\nsmall a learning rate by multiple orders of magnitude, even when run with a\nmoderately long time horizon (100 steps) typical of work in the area. We\nbelieve short-horizon bias is a fundamental problem that needs to be addressed\nif meta-optimization is to scale to practical neural net training regimes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:01:37 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wu", "Yuhuai", ""], ["Ren", "Mengye", ""], ["Liao", "Renjie", ""], ["Grosse", "Roger", ""]]}, {"id": "1803.02042", "submitter": "Biau Gerard", "authors": "G\\'erard Biau (1), Beno\\^it Cadre (2), Laurent Rouv\\`i\\`ere (2) ((1)\n  LPSM UMR 8001, (2) IRMAR)", "title": "Accelerated Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient tree boosting is a prediction algorithm that sequentially produces a\nmodel in the form of linear combinations of decision trees, by solving an\ninfinite-dimensional optimization problem. We combine gradient boosting and\nNesterov's accelerated descent to design a new algorithm, which we call AGB\n(for Accelerated Gradient Boosting). Substantial numerical evidence is provided\non both synthetic and real-life data sets to assess the excellent performance\nof the method in a large variety of prediction problems. It is empirically\nshown that AGB is much less sensitive to the shrinkage parameter and outputs\npredictors that are considerably more sparse in the number of trees, while\nretaining the exceptional performance of gradient boosting.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:23:17 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Biau", "G\u00e9rard", ""], ["Cadre", "Beno\u00eet", ""], ["Rouv\u00ec\u00e8re", "Laurent", ""]]}, {"id": "1803.02043", "submitter": "Savitha Ramasamy", "authors": "Savitha Ramasamy, Kanagasabai Rajaraman, Pavitra Krishnaswamy, Vijay\n  Chandrasekhar", "title": "Online Deep Learning: Growing RBM on the fly", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm for Restricted Boltzmann\nMachines (RBM), namely, the Online Generative Discriminative Restricted\nBoltzmann Machine (OGD-RBM), that provides the ability to build and adapt the\nnetwork architecture of RBM according to the statistics of streaming data. The\nOGD-RBM is trained in two phases: (1) an online generative phase for\nunsupervised feature representation at the hidden layer and (2) a\ndiscriminative phase for classification. The online generative training begins\nwith zero neurons in the hidden layer, adds and updates the neurons to adapt to\nstatistics of streaming data in a single pass unsupervised manner, resulting in\na feature representation best suited to the data. The discriminative phase is\nbased on stochastic gradient descent and associates the represented features to\nthe class labels. We demonstrate the OGD-RBM on a set of multi-category and\nbinary classification problems for data sets having varying degrees of\nclass-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST\ndataset to characterize the network evolution. We demonstrate that the online\ngenerative phase converges to a stable, concise network architecture, wherein\nindividual neurons are inherently discriminative to the class labels despite\nunsupervised training. We then benchmark OGD-RBM performance to other machine\nlearning, neural network and ClassRBM techniques for credit scoring\napplications using 3 public non-stationary two-class credit datasets with\nvarying degrees of class-imbalance. We report that OGD-RBM improves accuracy by\n2.5-3% over batch learning techniques while requiring at least 24%-70% fewer\nneurons and fewer training samples. This online generative training approach\ncan be extended greedily to multiple layers for training Deep Belief Networks\nin non-stationary data mining applications without the need for a priori fixed\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:24:21 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ramasamy", "Savitha", ""], ["Rajaraman", "Kanagasabai", ""], ["Krishnaswamy", "Pavitra", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1803.02057", "submitter": "Jatavallabhula Krishna Murthy", "authors": "Junaid Ahmed Ansari, Sarthak Sharma, Anshuman Majumdar, J. Krishna\n  Murthy, and K. Madhava Krishna", "title": "The Earth ain't Flat: Monocular Reconstruction of Vehicles on Steep and\n  Graded Roads from a Moving Camera", "comments": "Submitted to IROS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate localization of other traffic participants is a vital task in\nautonomous driving systems. State-of-the-art systems employ a combination of\nsensing modalities such as RGB cameras and LiDARs for localizing traffic\nparticipants, but most such demonstrations have been confined to plain roads.\nWe demonstrate, to the best of our knowledge, the first results for monocular\nobject localization and shape estimation on surfaces that do not share the same\nplane with the moving monocular camera. We approximate road surfaces by local\nplanar patches and use semantic cues from vehicles in the scene to initialize a\nlocal bundle-adjustment like procedure that simultaneously estimates the pose\nand shape of the vehicles, and the orientation of the local ground plane on\nwhich the vehicle stands as well. We evaluate the proposed approach on the\nKITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations.\nThe proposed approach significantly improves the state-of-the-art for monocular\nobject localization on arbitrarily-shaped roads.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 08:28:18 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ansari", "Junaid Ahmed", ""], ["Sharma", "Sarthak", ""], ["Majumdar", "Anshuman", ""], ["Murthy", "J. Krishna", ""], ["Krishna", "K. Madhava", ""]]}, {"id": "1803.02077", "submitter": "Roey Mechrez", "authors": "Roey Mechrez, Itamar Talmi, Lihi Zelnik-Manor", "title": "The Contextual Loss for Image Transformation with Non-Aligned Data", "comments": "ECCV Oral. Paper web page:\n  http://cgm.technion.ac.il/Computer-Graphics-Multimedia/Software/contextual/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward CNNs trained for image transformation problems rely on loss\nfunctions that measure the similarity between the generated image and a target\nimage. Most of the common loss functions assume that these images are spatially\naligned and compare pixels at corresponding locations. However, for many tasks,\naligned training pairs of images will not be available. We present an\nalternative loss function that does not require alignment, thus providing an\neffective and simple solution for a new space of problems. Our loss is based on\nboth context and semantics -- it compares regions with similar semantic\nmeaning, while considering the context of the entire image. Hence, for example,\nwhen transferring the style of one face to another, it will translate\neyes-to-eyes and mouth-to-mouth. Our code can be found at\nhttps://www.github.com/roimehrez/contextualLoss\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 09:43:25 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:11:15 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 13:08:09 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 09:58:50 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Mechrez", "Roey", ""], ["Talmi", "Itamar", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "1803.02099", "submitter": "Shengdong Du", "authors": "Shengdong Du, Tianrui Li, Xun Gong and Shi-Jinn Horng", "title": "A Hybrid Method for Traffic Flow Forecasting Using Multimodal Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow forecasting has been regarded as a key problem of intelligent\ntransport systems. In this work, we propose a hybrid multimodal deep learning\nmethod for short-term traffic flow forecasting, which can jointly and\nadaptively learn the spatial-temporal correlation features and long temporal\ninterdependence of multi-modality traffic data by an attention auxiliary\nmultimodal deep learning architecture. According to the highly nonlinear\ncharacteristics of multi-modality traffic data, the base module of our method\nconsists of one-dimensional Convolutional Neural Networks (1D CNN) and Gated\nRecurrent Units (GRU) with the attention mechanism. The former is to capture\nthe local trend features and the latter is to capture the long temporal\ndependencies. Then, we design a hybrid multimodal deep learning framework\n(HMDLF) for fusing share representation features of different modality traffic\ndata by multiple CNN-GRU-Attention modules. The experimental results indicate\nthat the proposed multimodal deep learning model is capable of dealing with\ncomplex nonlinear urban traffic flow forecasting with satisfying accuracy and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:39:47 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 09:44:49 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 10:42:38 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 13:08:11 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Du", "Shengdong", ""], ["Li", "Tianrui", ""], ["Gong", "Xun", ""], ["Horng", "Shi-Jinn", ""]]}, {"id": "1803.02108", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Jorn W.T. Peters, Taco S. Cohen, Max Welling", "title": "HexaConv", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Convolutional Neural Networks stems in large part from\ntheir ability to exploit the translation invariance that is inherent in many\nlearning problems. Recently, it was shown that CNNs can exploit other\ninvariances, such as rotation invariance, by using group convolutions instead\nof planar convolutions. However, for reasons of performance and ease of\nimplementation, it has been necessary to limit the group convolution to\ntransformations that can be applied to the filters without interpolation. Thus,\nfor images with square pixels, only integer translations, rotations by\nmultiples of 90 degrees, and reflections are admissible.\n  Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal\ntiling of the plane has a 6-fold rotational symmetry. In this paper we show how\none can efficiently implement planar convolution and group convolution over\nhexagonal lattices, by re-using existing highly optimized convolution routines.\nWe find that, due to the reduced anisotropy of hexagonal filters, planar\nHexaConv provides better accuracy than planar convolution with square filters,\ngiven a fixed parameter budget. Furthermore, we find that the increased degree\nof symmetry of the hexagonal grid increases the effectiveness of group\nconvolutions, by allowing for more parameter sharing. We show that our method\nsignificantly outperforms conventional CNNs on the AID aerial scene\nclassification dataset, even outperforming ImageNet pre-trained models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 11:05:39 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Peters", "Jorn W. T.", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "1803.02194", "submitter": "Kan Ren", "authors": "Kan Ren, Weinan Zhang, Ke Chang, Yifei Rong, Yong Yu, Jun Wang", "title": "Bidding Machine: Learning to Bid for Directly Optimizing Profits in\n  Display Advertising", "comments": "18 pages, 10 figures, Final version published in IEEE Transactions on\n  Knowledge and Data Engineering (TKDE), URL:\n  http://ieeexplore.ieee.org/document/8115218/", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, Volume: 30,\n  Issue: 4, Year: 2018, Pages: 645-659", "doi": "10.1109/TKDE.2017.2775228", "report-no": null, "categories": "cs.GT cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time bidding (RTB) based display advertising has become one of the key\ntechnological advances in computational advertising. RTB enables advertisers to\nbuy individual ad impressions via an auction in real-time and facilitates the\nevaluation and the bidding of individual impressions across multiple\nadvertisers. In RTB, the advertisers face three main challenges when optimizing\ntheir bidding strategies, namely (i) estimating the utility (e.g., conversions,\nclicks) of the ad impression, (ii) forecasting the market value (thus the cost)\nof the given ad impression, and (iii) deciding the optimal bid for the given\nauction based on the first two. Previous solutions assume the first two are\nsolved before addressing the bid optimization problem. However, these\nchallenges are strongly correlated and dealing with any individual problem\nindependently may not be globally optimal. In this paper, we propose Bidding\nMachine, a comprehensive learning to bid framework, which consists of three\noptimizers dealing with each challenge above, and as a whole, jointly optimizes\nthese three parts. We show that such a joint optimization would largely\nincrease the campaign effectiveness and the profit. From the learning\nperspective, we show that the bidding machine can be updated smoothly with both\noffline periodical batch or online sequential training schemes. Our extensive\noffline empirical study and online A/B testing verify the high effectiveness of\nthe proposed bidding machine.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:28:32 GMT"}, {"version": "v2", "created": "Sun, 11 Mar 2018 02:25:32 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Chang", "Ke", ""], ["Rong", "Yifei", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1803.02218", "submitter": "Shuai Jiang", "authors": "Shuai Jiang, Kan Li and Richard Yida Xu", "title": "Relative Pairwise Relationship Constrained Non-negative Matrix\n  Factorisation", "comments": "13 pages, 10 figures", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, vol. 31, no.\n  8, pp. 1595-1609, 1 Aug. 2019", "doi": "10.1109/TKDE.2018.2859223", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative Matrix Factorisation (NMF) has been extensively used in machine\nlearning and data analytics applications. Most existing variations of NMF only\nconsider how each row/column vector of factorised matrices should be shaped,\nand ignore the relationship among pairwise rows or columns. In many cases, such\npairwise relationship enables better factorisation, for example, image\nclustering and recommender systems. In this paper, we propose an algorithm\nnamed, Relative Pairwise Relationship constrained Non-negative Matrix\nFactorisation (RPR-NMF), which places constraints over relative pairwise\ndistances amongst features by imposing penalties in a triplet form. Two\ndistance measures, squared Euclidean distance and Symmetric divergence, are\nused, and exponential and hinge loss penalties are adopted for the two measures\nrespectively. It is well known that the so-called \"multiplicative update rules\"\nresult in a much faster convergence than gradient descend for matrix\nfactorisation. However, applying such update rules to RPR-NMF and also proving\nits convergence is not straightforward. Thus, we use reasonable approximations\nto relax the complexity brought by the penalties, which are practically\nverified. Experiments on both synthetic datasets and real datasets demonstrate\nthat our algorithms have advantages on gaining close approximation, satisfying\na high proportion of expected constraints, and achieving superior performance\ncompared with other algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 07:56:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jiang", "Shuai", ""], ["Li", "Kan", ""], ["Xu", "Richard Yida", ""]]}, {"id": "1803.02222", "submitter": "Xi Fang", "authors": "Xi Fang, Zengmao Wang, Xinyao Tang, Chen Wu", "title": "Multi-class Active Learning: A Hybrid Informative and Representative\n  Criterion Inspired Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling each instance in a large dataset is extremely labor- and time-\nconsuming . One way to alleviate this problem is active learning, which aims to\nwhich discover the most valuable instances for labeling to construct a powerful\nclassifier. Considering both informativeness and representativeness provides a\npromising way to design a practical active learning. However, most existing\nactive learning methods select instances favoring either informativeness or\nrepresentativeness. Meanwhile, many are designed based on the binary class, so\nthat they may present suboptimal solutions on the datasets with multiple\nclasses. In this paper, a hybrid informative and representative criterion based\nmulti-class active learning approach is proposed. We combine the informative\ninformativeness and representativeness into one formula, which can be solved\nunder a unified framework. The informativeness is measured by the margin\nminimum while the representative information is measured by the maximum mean\ndiscrepancy. By minimizing the upper bound for the true risk, we generalize the\nempirical risk minimization principle to the active learning setting.\nSimultaneously, our proposed method makes full use of the label information,\nand the proposed active learning is designed based on multiple classes. So the\nproposed method is not suitable to the binary class but also the multiple\nclasses. We conduct our experiments on twelve benchmark UCI data sets, and the\nexperimental results demonstrate that the proposed method performs better than\nsome state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 14:32:15 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Fang", "Xi", ""], ["Wang", "Zengmao", ""], ["Tang", "Xinyao", ""], ["Wu", "Chen", ""]]}, {"id": "1803.02242", "submitter": "Stefan Zernetsch", "authors": "Stefan Zernetsch, Viktor Kress, Bernhard Sick and Konrad Doll", "title": "Early Start Intention Detection of Cyclists Using Motion History Images\n  and a Deep Residual Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a novel approach to detect starting motions of\ncyclists in real world traffic scenarios based on Motion History Images (MHIs).\nThe method uses a deep Convolutional Neural Network (CNN) with a residual\nnetwork architecture (ResNet), which is commonly used in image classification\nand detection tasks. By combining MHIs with a ResNet classifier and performing\na frame by frame classification of the MHIs, we are able to detect starting\nmotions in image sequences. The detection is performed using a wide angle\nstereo camera system at an urban intersection. We compare our algorithm to an\nexisting method to detect movement transitions of pedestrians that uses MHIs in\ncombination with a Histograms of Oriented Gradients (HOG) like descriptor and a\nSupport Vector Machine (SVM), which we adapted to cyclists. To train and\nevaluate the methods a dataset containing MHIs of 394 cyclist starting motions\nwas created. The results show that both methods can be used to detect starting\nmotions of cyclists. Using the SVM approach, we were able to safely detect\nstarting motions 0.506 s on average after the bicycle starts moving with an\nF1-score of 97.7%. The ResNet approach achieved an F1-score of 100% at an\naverage detection time of 0.144 s. The ResNet approach outperformed the SVM\napproach in both robustness against false positive detections and detection\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:12:27 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Zernetsch", "Stefan", ""], ["Kress", "Viktor", ""], ["Sick", "Bernhard", ""], ["Doll", "Konrad", ""]]}, {"id": "1803.02247", "submitter": "Fernando Gama", "authors": "Fernando Gama, Antonio G. Marques, Alejandro Ribeiro, Geert Leus", "title": "MIMO Graph Filters for Convolutional Neural Networks", "comments": "Submitted to 19th IEEE International Workshop on Signal Processing\n  Advances in Wireless Communications (SPAWC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superior performance and ease of implementation have fostered the adoption of\nConvolutional Neural Networks (CNNs) for a wide array of inference and\nreconstruction tasks. CNNs implement three basic blocks: convolution, pooling\nand pointwise nonlinearity. Since the two first operations are well-defined\nonly on regular-structured data such as audio or images, application of CNNs to\ncontemporary datasets where the information is defined in irregular domains is\nchallenging. This paper investigates CNNs architectures to operate on signals\nwhose support can be modeled using a graph. Architectures that replace the\nregular convolution with a so-called linear shift-invariant graph filter have\nbeen recently proposed. This paper goes one step further and, under the\nframework of multiple-input multiple-output (MIMO) graph filters, imposes\nadditional structure on the adopted graph filters, to obtain three new (more\nparsimonious) architectures. The proposed architectures result in a lower\nnumber of model parameters, reducing the computational complexity, facilitating\nthe training, and mitigating the risk of overfitting. Simulations show that the\nproposed simpler architectures achieve similar performance as more complex\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:18:56 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Ribeiro", "Alejandro", ""], ["Leus", "Geert", ""]]}, {"id": "1803.02251", "submitter": "Monica Visintin", "authors": "Giulio Franzese and Monica Visintin", "title": "Deep Information Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel classifier with a tree structure, designed using\ninformation theory concepts. This Information Network is made of information\nnodes, that compress the input data, and multiplexers, that connect two or more\ninput nodes to an output node. Each information node is trained, independently\nof the others, to minimize a local cost function that minimizes the mutual\ninformation between its input and output with the constraint of keeping a given\nmutual information between its output and the target (information bottleneck).\nWe show that the system is able to provide good results in terms of accuracy,\nwhile it shows many advantages in terms of modularity and reduced complexity.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:24:41 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Franzese", "Giulio", ""], ["Visintin", "Monica", ""]]}, {"id": "1803.02310", "submitter": "Youngjun Cho", "authors": "Youngjun Cho, Nadia Bianchi-Berthouze, Nicolai Marquardt and Simon J.\n  Julier", "title": "Deep Thermal Imaging: Proximate Material Type Recognition in the Wild\n  through Deep Learning of Spatial Surface Temperature Patterns", "comments": "Proceedings of the 2018 CHI Conference on Human Factors in Computing\n  Systems", "journal-ref": null, "doi": "10.1145/3173574.3173576", "report-no": null, "categories": "cs.CV cond-mat.mtrl-sci cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Thermal Imaging, a new approach for close-range automatic\nrecognition of materials to enhance the understanding of people and ubiquitous\ntechnologies of their proximal environment. Our approach uses a low-cost mobile\nthermal camera integrated into a smartphone to capture thermal textures. A deep\nneural network classifies these textures into material types. This approach\nworks effectively without the need for ambient light sources or direct contact\nwith materials. Furthermore, the use of a deep learning network removes the\nneed to handcraft the set of features for different materials. We evaluated the\nperformance of the system by training it to recognise 32 material types in both\nindoor and outdoor environments. Our approach produced recognition accuracies\nabove 98% in 14,860 images of 15 indoor materials and above 89% in 26,584\nimages of 17 outdoor materials. We conclude by discussing its potentials for\nreal-time use in HCI applications and future directions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 17:29:08 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Cho", "Youngjun", ""], ["Bianchi-Berthouze", "Nadia", ""], ["Marquardt", "Nicolai", ""], ["Julier", "Simon J.", ""]]}, {"id": "1803.02312", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Lin Yang, Mengdi Wang, Tuo Zhao", "title": "Dimensionality Reduction for Stationary Time Series via Stochastic\n  Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization naturally arises in machine learning. Efficient\nalgorithms with provable guarantees, however, are still largely missing, when\nthe objective function is nonconvex and the data points are dependent. This\npaper studies this fundamental challenge through a streaming PCA problem for\nstationary time series data. Specifically, our goal is to estimate the\nprinciple component of time series data with respect to the covariance matrix\nof the stationary distribution. Computationally, we propose a variant of Oja's\nalgorithm combined with downsampling to control the bias of the stochastic\ngradient caused by the data dependency. Theoretically, we quantify the\nuncertainty of our proposed stochastic algorithm based on diffusion\napproximations. This allows us to prove the asymptotic rate of convergence and\nfurther implies near optimal asymptotic sample complexity. Numerical\nexperiments are provided to support our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 17:38:03 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 17:37:35 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 17:54:14 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2018 16:47:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chen", "Minshuo", ""], ["Yang", "Lin", ""], ["Wang", "Mengdi", ""], ["Zhao", "Tuo", ""]]}, {"id": "1803.02323", "submitter": "Steven Young M", "authors": "Steven Young, Tamer Abdou, and Ayse Bener", "title": "Deep Super Learner: A Deep Ensemble for Classification Problems", "comments": "12 pages, 3 figures, accepted to the 31st Canadian Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become very popular for tasks such as predictive modeling\nand pattern recognition in handling big data. Deep learning is a powerful\nmachine learning method that extracts lower level features and feeds them\nforward for the next layer to identify higher level features that improve\nperformance. However, deep neural networks have drawbacks, which include many\nhyper-parameters and infinite architectures, opaqueness into results, and\nrelatively slower convergence on smaller datasets. While traditional machine\nlearning algorithms can address these drawbacks, they are not typically capable\nof the performance levels achieved by deep neural networks. To improve\nperformance, ensemble methods are used to combine multiple base learners. Super\nlearning is an ensemble that finds the optimal combination of diverse learning\nalgorithms. This paper proposes deep super learning as an approach which\nachieves log loss and accuracy results competitive to deep neural networks\nwhile employing traditional machine learning algorithms in a hierarchical\nstructure. The deep super learner is flexible, adaptable, and easy to train\nwith good performance across different tasks using identical hyper-parameter\nvalues. Using traditional machine learning requires fewer hyper-parameters,\nallows transparency into results, and has relatively fast convergence on\nsmaller datasets. Experimental results show that the deep super learner has\nsuperior performance compared to the individual base learners, single-layer\nensembles, and in some cases deep neural networks. Performance of the deep\nsuper learner may further be improved with task-specific tuning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:19:55 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Young", "Steven", ""], ["Abdou", "Tamer", ""], ["Bener", "Ayse", ""]]}, {"id": "1803.02329", "submitter": "Kevin Swersky", "authors": "Milad Hashemi, Kevin Swersky, Jamie A. Smith, Grant Ayers, Heiner\n  Litz, Jichuan Chang, Christos Kozyrakis, Parthasarathy Ranganathan", "title": "Learning Memory Access Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion in workload complexity and the recent slow-down in Moore's law\nscaling call for new approaches towards efficient computing. Researchers are\nnow beginning to use recent advances in machine learning in software\noptimizations, augmenting or replacing traditional heuristics and data\nstructures. However, the space of machine learning for computer hardware\narchitecture is only lightly explored. In this paper, we demonstrate the\npotential of deep learning to address the von Neumann bottleneck of memory\nperformance. We focus on the critical problem of learning memory access\npatterns, with the goal of constructing accurate and efficient memory\nprefetchers. We relate contemporary prefetching strategies to n-gram models in\nnatural language processing, and show how recurrent neural networks can serve\nas a drop-in replacement. On a suite of challenging benchmark datasets, we find\nthat neural networks consistently demonstrate superior performance in terms of\nprecision and recall. This work represents the first step towards practical\nneural-network based prefetching, and opens a wide range of exciting directions\nfor machine learning in computer architecture research.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:41:04 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hashemi", "Milad", ""], ["Swersky", "Kevin", ""], ["Smith", "Jamie A.", ""], ["Ayers", "Grant", ""], ["Litz", "Heiner", ""], ["Chang", "Jichuan", ""], ["Kozyrakis", "Christos", ""], ["Ranganathan", "Parthasarathy", ""]]}, {"id": "1803.02348", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mohammad Norouzi, George Tucker, Dale Schuurmans", "title": "Smoothed Action Value Functions for Learning Gaussian Policies", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-action value functions (i.e., Q-values) are ubiquitous in reinforcement\nlearning (RL), giving rise to popular algorithms such as SARSA and Q-learning.\nWe propose a new notion of action value defined by a Gaussian smoothed version\nof the expected Q-value. We show that such smoothed Q-values still satisfy a\nBellman equation, making them learnable from experience sampled from an\nenvironment. Moreover, the gradients of expected reward with respect to the\nmean and covariance of a parameterized Gaussian policy can be recovered from\nthe gradient and Hessian of the smoothed Q-value function. Based on these\nrelationships, we develop new algorithms for training a Gaussian policy\ndirectly from a learned smoothed Q-value approximator. The approach is\nadditionally amenable to proximal optimization by augmenting the objective with\na penalty on KL-divergence from a previous policy. We find that the ability to\nlearn both a mean and covariance during training leads to significantly\nimproved results on standard continuous control benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 04:58:20 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:56:38 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 17:07:23 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Nachum", "Ofir", ""], ["Norouzi", "Mohammad", ""], ["Tucker", "George", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1803.02388", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Ofer Dekel, and Lin Xiao", "title": "Learning SMaLL Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning technique for training small\nresource-constrained predictors. Our algorithm, the Sparse Multiprototype\nLinear Learner (SMaLL), is inspired by the classic machine learning problem of\nlearning $k$-DNF Boolean formulae. We present a formal derivation of our\nalgorithm and demonstrate the benefits of our approach with a detailed\nempirical study.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:16:08 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Garg", "Vikas K.", ""], ["Dekel", "Ofer", ""], ["Xiao", "Lin", ""]]}, {"id": "1803.02395", "submitter": "Manish Nair", "authors": "Chase Roberts and Manish Nair", "title": "Arbitrary Discrete Sequence Anomaly Detection with Zero Boundary LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a simple mathematical definition and new neural architecture for\nfinding anomalies within discrete sequence datasets. Our model comprises of a\nmodified LSTM autoencoder and an array of One-Class SVMs. The LSTM takes in\nelements from a sequence and creates context vectors that are used to predict\nthe probability distribution of the following element. These context vectors\nare then used to train an array of One-Class SVMs. These SVMs are used to\ndetermine an outlier boundary in context space.We show that our method is\nconsistently more stable and also outperforms standard LSTM and sliding window\nanomaly detection systems on two generated datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:28:38 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Roberts", "Chase", ""], ["Nair", "Manish", ""]]}, {"id": "1803.02398", "submitter": "David Koes", "authors": "Joshua Hochuli, Alec Helbling, Tamar Skaist, Matthew Ragoza, David\n  Ryan Koes", "title": "Visualizing Convolutional Neural Network Protein-Ligand Scoring", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmgm.2018.06.005", "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-ligand scoring is an important step in a structure-based drug design\npipeline. Selecting a correct binding pose and predicting the binding affinity\nof a protein-ligand complex enables effective virtual screening. Machine\nlearning techniques can make use of the increasing amounts of structural data\nthat are becoming publicly available. Convolutional neural network (CNN)\nscoring functions in particular have shown promise in pose selection and\naffinity prediction for protein-ligand complexes. Neural networks are known for\nbeing difficult to interpret. Understanding the decisions of a particular\nnetwork can help tune parameters and training data to maximize performance.\nVisualization of neural networks helps decompose complex scoring functions into\npictures that are more easily parsed by humans. Here we present three methods\nfor visualizing how individual protein-ligand complexes are interpreted by 3D\nconvolutional neural networks. We also present a visualization of the\nconvolutional filters and their weights. We describe how the intuition provided\nby these visualizations aids in network design.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:40:51 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hochuli", "Joshua", ""], ["Helbling", "Alec", ""], ["Skaist", "Tamar", ""], ["Ragoza", "Matthew", ""], ["Koes", "David Ryan", ""]]}, {"id": "1803.02400", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Chenglong Wang, Rishabh Singh, Wen-tau Yih, Xiaodong He", "title": "Natural Language to Structured Query Generation via Meta-Learning", "comments": "in NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional supervised training, a model is trained to fit all the\ntraining examples. However, having a monolithic model may not always be the\nbest strategy, as examples could vary widely. In this work, we explore a\ndifferent learning protocol that treats each example as a unique pseudo-task,\nby reducing the original learning problem to a few-shot meta-learning scenario\nwith the help of a domain-dependent relevance function. When evaluated on the\nWikiSQL dataset, our approach leads to faster convergence and achieves\n1.1%-5.4% absolute accuracy gains over the non-meta-learning counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 05:26:28 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 22:27:18 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 22:32:38 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 21:40:45 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Huang", "Po-Sen", ""], ["Wang", "Chenglong", ""], ["Singh", "Rishabh", ""], ["Yih", "Wen-tau", ""], ["He", "Xiaodong", ""]]}, {"id": "1803.02421", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Masked Conditional Neural Networks for Audio Classification", "comments": "Restricted BoltzmannMachine, RBM, Conditional Restricted Boltzmann\n  Machine, CRBM, Music Information Retrieval, MIR, Conditional Neural Network,\n  CLNN, Masked Conditional Neural Network, MCLNN, Deep Neural Network", "journal-ref": "International Conference on Artificial Neural Networks (ICANN)\n  Year: 2017", "doi": "10.1007/978-3-319-68612-7_40", "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL\nNeural Network (MCLNN) designed for temporal signal recognition. The CLNN takes\ninto consideration the temporal nature of the sound signal and the MCLNN\nextends upon the CLNN through a binary mask to preserve the spatial locality of\nthe features and allows an automated exploration of the features combination\nanalogous to hand-crafting the most relevant features for the recognition task.\nMCLNN has achieved competitive recognition accuracies on the GTZAN and the\nISMIR2004 music datasets that surpass several state-of-the-art neural network\nbased architectures and hand-crafted methods applied on both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 20:54:00 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 10:56:33 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1803.02453", "submitter": "Miroslav Dud\\'ik", "authors": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\\'ik, John Langford,\n  Hanna Wallach", "title": "A Reductions Approach to Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic approach for achieving fairness in a binary\nclassification setting. While we focus on two well-known quantitative\ndefinitions of fairness, our approach encompasses many other previously studied\ndefinitions as special cases. The key idea is to reduce fair classification to\na sequence of cost-sensitive classification problems, whose solutions yield a\nrandomized classifier with the lowest (empirical) error subject to the desired\nconstraints. We introduce two reductions that work for any representation of\nthe cost-sensitive classifier and compare favorably to prior baselines on a\nvariety of data sets, while overcoming several of their disadvantages.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 22:39:58 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 20:21:32 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 15:06:37 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Agarwal", "Alekh", ""], ["Beygelzimer", "Alina", ""], ["Dud\u00edk", "Miroslav", ""], ["Langford", "John", ""], ["Wallach", "Hanna", ""]]}, {"id": "1803.02458", "submitter": "Seojin Bang", "authors": "Seojin Bang, Yaoliang Yu and Wei Wu", "title": "Robust Multiple Kernel k-means Clustering using Min-Max Optimization", "comments": "R package is available at https://github.com/SeojinBang/MKKC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple kernel learning is a type of multiview learning that combines\ndifferent data modalities by capturing view-specific patterns using kernels.\nAlthough supervised multiple kernel learning has been extensively studied,\nuntil recently, only a few unsupervised approaches have been proposed. In the\nmeanwhile, adversarial learning has recently received much attention. Many\nworks have been proposed to defend against adversarial examples. However,\nlittle is known about the effect of adversarial perturbation in the context of\nmultiview learning, and even less in the unsupervised case. In this study, we\nshow that adversarial features added to a view can make the existing approaches\nwith the min-max formulation in multiple kernel clustering yield unfavorable\nclusters. To address this problem and inspired by recent works in adversarial\nlearning, we propose a multiple kernel clustering method with the min-max\nframework that aims to be robust to such adversarial perturbation. We evaluate\nthe robustness of our method on simulation data under different types of\nadversarial perturbations and show that it outperforms several compared\nexisting methods. In the real data analysis, We demonstrate the utility of our\nmethod on a real-world problem.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 22:44:39 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 04:50:57 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bang", "Seojin", ""], ["Yu", "Yaoliang", ""], ["Wu", "Wei", ""]]}, {"id": "1803.02493", "submitter": "Gao Tang", "authors": "Gao Tang and Kris Hauser", "title": "Discontinuity-Sensitive Optimal Control Learning by Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a discontinuity-sensitive approach to learn the solutions\nof parametric optimal control problems with high accuracy. Many tasks, ranging\nfrom model predictive control to reinforcement learning, may be solved by\nlearning optimal solutions as a function of problem parameters. However,\nnonconvexity, discrete homotopy classes, and control switching cause\ndiscontinuity in the parameter-solution mapping, thus making learning difficult\nfor traditional continuous function approximators. A mixture of experts (MoE)\nmodel composed of a classifier and several regressors is proposed to address\nsuch an issue. The optimal trajectories of different parameters are clustered\nsuch that in each cluster the trajectories are continuous function of problem\nparameters. Numerical examples on benchmark problems show that training the\nclassifier and regressors individually outperforms joint training of MoE. With\nsuitably chosen clusters, this approach not only achieves lower prediction\nerror with less training data and fewer model parameters, but also leads to\ndramatic improvements in the reliability of trajectory tracking compared to\ntraditional universal function approximation models (e.g., neural networks).\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 01:21:57 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 15:31:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tang", "Gao", ""], ["Hauser", "Kris", ""]]}, {"id": "1803.02504", "submitter": "Bowen Wu", "authors": "Bowen Wu, Zhangling Chen, Jun Wang, Huaming Wu", "title": "Exponential Discriminative Metric Embedding in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the remarkable success achieved by the Convolutional Neural Networks\n(CNNs) in object recognition recently, deep learning is being widely used in\nthe computer vision community. Deep Metric Learning (DML), integrating deep\nlearning with conventional metric learning, has set new records in many fields,\nespecially in classification task. In this paper, we propose a replicable DML\nmethod, called Include and Exclude (IE) loss, to force the distance between a\nsample and its designated class center away from the mean distance of this\nsample to other class centers with a large margin in the exponential feature\nprojection space. With the supervision of IE loss, we can train CNNs to enhance\nthe intra-class compactness and inter-class separability, leading to great\nimprovements on several public datasets ranging from object recognition to face\nverification. We conduct a comparative study of our algorithm with several\ntypical DML methods on three kinds of networks with different capacity.\nExtensive experiments on three object recognition datasets and two face\nrecognition datasets demonstrate that IE loss is always superior to other\nmainstream DML methods and approach the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 02:39:34 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Wu", "Bowen", ""], ["Chen", "Zhangling", ""], ["Wang", "Jun", ""], ["Wu", "Huaming", ""]]}, {"id": "1803.02517", "submitter": "Elizabeth Hou", "authors": "Elizabeth Hou, Alfred O. Hero", "title": "Sequential Maximum Margin Classifiers for Partially Labeled Data", "comments": null, "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data is not collected as one batch, but\nsequentially over time, and often it is not possible or desirable to wait until\nthe data is completely gathered before analyzing it. Thus, we propose a\nframework to sequentially update a maximum margin classifier by taking\nadvantage of the Maximum Entropy Discrimination principle. Our maximum margin\nclassifier allows for a kernel representation to represent large numbers of\nfeatures and can also be regularized with respect to a smooth sub-manifold,\nallowing it to incorporate unlabeled observations. We compare the performance\nof our classifier to its non-sequential equivalents in both simulated and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 03:55:18 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Hou", "Elizabeth", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1803.02544", "submitter": "Chengliang Yang", "authors": "Chengliang Yang, Anand Rangarajan, Sanjay Ranka", "title": "Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification", "comments": "Accepted by 2018 American Medical Informatics Association Annual\n  Symposium (AMIA2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:07:39 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 01:29:14 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 00:28:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yang", "Chengliang", ""], ["Rangarajan", "Anand", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1803.02551", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Extracting Domain Invariant Features by Unsupervised Learning for Robust\n  Automatic Speech Recognition", "comments": "accepted by 2018 International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition (ASR) systems can be\nsignificantly compromised by previously unseen conditions, which is typically\ndue to a mismatch between training and testing distributions. In this paper, we\naddress robustness by studying domain invariant features, such that domain\ninformation becomes transparent to ASR systems, resolving the mismatch problem.\nSpecifically, we investigate a recent model, called the Factorized Hierarchical\nVariational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and\nsegment-level attributes into different latent variables without supervision.\nWe argue that the set of latent variables that contain segment-level\ninformation is our desired domain invariant feature for ASR. Experiments are\nconducted on Aurora-4 and CHiME-4, which demonstrate 41% and 27% absolute word\nerror rate reductions respectively on mismatched domains.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:30:36 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1803.02553", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Eduardo Pavez, Antonio Ortega", "title": "Graph Learning from Filtered Signals: Graph System and Diffusion Kernel\n  Identification", "comments": "Submitted to IEEE Trans. on Signal and Information Processing over\n  Networks (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel graph signal processing framework for building\ngraph-based models from classes of filtered signals. In our framework,\ngraph-based modeling is formulated as a graph system identification problem,\nwhere the goal is to learn a weighted graph (a graph Laplacian matrix) and a\ngraph-based filter (a function of graph Laplacian matrices). In order to solve\nthe proposed problem, an algorithm is developed to jointly identify a graph and\na graph-based filter (GBF) from multiple signal/data observations. Our\nalgorithm is valid under the assumption that GBFs are one-to-one functions. The\nproposed approach can be applied to learn diffusion (heat) kernels, which are\npopular in various fields for modeling diffusion processes. In addition, for\nspecific choices of graph-based filters, the proposed problem reduces to a\ngraph Laplacian estimation problem. Our experimental results demonstrate that\nthe proposed algorithm outperforms the current state-of-the-art methods. We\nalso implement our framework on a real climate dataset for modeling of\ntemperature signals.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:37:44 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Pavez", "Eduardo", ""], ["Ortega", "Antonio", ""]]}, {"id": "1803.02596", "submitter": "Yu-Xiang Wang", "authors": "Yu-Xiang Wang", "title": "Revisiting differentially private linear regression: optimal and\n  adaptive prediction & estimation in unbounded domain", "comments": "Uncertainty in Artificial Intelligence (UAI-2018), Monterey, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of linear regression under a differential privacy\nconstraint. By consolidating existing pieces in the literature, we clarify the\ncorrect dependence of the feature, label and coefficient domains in the\noptimization error and estimation error, hence revealing the delicate price of\ndifferential privacy in statistical estimation and statistical learning.\nMoreover, we propose simple modifications of two existing DP algorithms: (a)\nposterior sampling, (b) sufficient statistics perturbation, and show that they\ncan be upgraded into **adaptive** algorithms that are able to exploit\ndata-dependent quantities and behave nearly optimally **for every instance**.\nExtensive experiments are conducted on both simulated data and real data, which\nconclude that both AdaOPS and AdaSSP outperform the existing techniques on\nnearly all 36 data sets that we test on.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:03:36 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 10:56:30 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Yu-Xiang", ""]]}, {"id": "1803.02603", "submitter": "Ieva Kazlauskaite", "authors": "Ieva Kazlauskaite, Carl Henrik Ek, Neill D. F. Campbell", "title": "Gaussian Process Latent Variable Alignment Learning", "comments": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019 (13 pages, 11 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model that can automatically learn alignments between\nhigh-dimensional data in an unsupervised manner. Our proposed method casts\nalignment learning in a framework where both alignment and data are modelled\nsimultaneously. Further, we automatically infer groupings of different types of\nsequences within the same dataset. We derive a probabilistic model built on\nnon-parametric priors that allows for flexible warps while at the same time\nproviding means to specify interpretable constraints. We demonstrate the\nefficacy of our approach with superior quantitative performance to the\nstate-of-the-art approaches and provide examples to illustrate the versatility\nof our model in automatic inference of sequence groupings, absent from previous\napproaches, as well as easy specification of high level priors for different\nmodalities of data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:30:05 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 09:41:10 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 12:52:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kazlauskaite", "Ieva", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1803.02661", "submitter": "Haim Avron", "authors": "Liron Mor-Yosef and Haim Avron", "title": "Sketching for Principal Component Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component regression (PCR) is a useful method for regularizing\nlinear regression. Although conceptually simple, straightforward\nimplementations of PCR have high computational costs and so are inappropriate\nwhen learning with large scale data. In this paper, we propose efficient\nalgorithms for computing approximate PCR solutions that are, on one hand, high\nquality approximations to the true PCR solutions (when viewed as minimizer of a\nconstrained optimization problem), and on the other hand entertain rigorous\nrisk bounds (when viewed as statistical estimators). In particular, we propose\nan input sparsity time algorithms for approximate PCR. We also consider\ncomputing an approximate PCR in the streaming model, and kernel PCR. Empirical\nresults demonstrate the excellent performance of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 14:09:10 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 07:45:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Mor-Yosef", "Liron", ""], ["Avron", "Haim", ""]]}, {"id": "1803.02665", "submitter": "Taras Kucherenko", "authors": "Taras Kucherenko, Jonas Beskow, Hedvig Kjellstr\\\"om", "title": "A Neural Network Approach to Missing Marker Reconstruction in Human\n  Motion Capture", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical motion capture systems have become a widely used technology in\nvarious fields, such as augmented reality, robotics, movie production, etc.\nSuch systems use a large number of cameras to triangulate the position of\noptical markers.The marker positions are estimated with high accuracy. However,\nespecially when tracking articulated bodies, a fraction of the markers in each\ntimestep is missing from the reconstruction. In this paper, we propose to use a\nneural network approach to learn how human motion is temporally and spatially\ncorrelated, and reconstruct missing markers positions through this model. We\nexperiment with two different models, one LSTM-based and one time-window-based.\nBoth methods produce state-of-the-art results, while working online, as opposed\nto most of the alternative methods, which require the complete sequence to be\nknown. The implementation is publicly available at\nhttps://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction .\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 14:16:59 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 12:38:13 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 17:13:14 GMT"}, {"version": "v4", "created": "Tue, 25 Sep 2018 09:00:03 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Kucherenko", "Taras", ""], ["Beskow", "Jonas", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "1803.02780", "submitter": "Andrea Gesmundo", "authors": "Catherine Wong, Neil Houlsby, Yifeng Lu, Andrea Gesmundo", "title": "Transfer Learning with Neural AutoML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce the computational cost of Neural AutoML with transfer learning.\nAutoML relieves human effort by automating the design of ML algorithms. Neural\nAutoML has become popular for the design of deep learning architectures,\nhowever, this method has a high computation cost. To address this we propose\nTransfer Neural AutoML that uses knowledge from prior tasks to speed up network\ndesign. We extend RL-based architecture search methods to support parallel\ntraining on multiple tasks and then transfer the search strategy to new tasks.\nOn language and image classification tasks, Transfer Neural AutoML reduces\nconvergence time over single-task training by over an order of magnitude on\nmany tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:31:02 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 12:47:17 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2018 09:55:18 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 07:53:41 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 15:43:20 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wong", "Catherine", ""], ["Houlsby", "Neil", ""], ["Lu", "Yifeng", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1803.02781", "submitter": "Sukrut Rao", "authors": "Vaibhav B Sinha, Sukrut Rao, Vineeth N Balasubramanian", "title": "Fast Dawid-Skene: A Fast Vote Aggregation Scheme for Sentiment\n  Classification", "comments": "8 pages, 5 tables, 1 figure, KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems can now be effectively solved using supervised\nmachine learning. A major roadblock is often the lack of an adequate quantity\nof labeled data for training. A possible solution is to assign the task of\nlabeling data to a crowd, and then infer the true label using aggregation\nmethods. A well-known approach for aggregation is the Dawid-Skene (DS)\nalgorithm, which is based on the principle of Expectation-Maximization (EM). We\npropose a new simple, yet effective, EM-based algorithm, which can be\ninterpreted as a `hard' version of DS, that allows much faster convergence\nwhile maintaining similar accuracy in aggregation. We show the use of this\nalgorithm as a quick and effective technique for online, real-time sentiment\nannotation. We also prove that our algorithm converges to the estimated labels\nat a linear rate. Our experiments on standard datasets show a significant\nspeedup in time taken for aggregation - upto $\\sim$8x over Dawid-Skene and\n$\\sim$6x over other fast EM methods, at competitive accuracy performance. The\ncode for the implementation of the algorithms can be found at\nhttps://github.com/GoodDeeds/Fast-Dawid-Skene\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:31:20 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 15:13:52 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 20:22:38 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sinha", "Vaibhav B", ""], ["Rao", "Sukrut", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1803.02782", "submitter": "Kajsa M{\\o}llersen", "authors": "Kajsa M{\\o}llersen, Jon Yngve Hardeberg, Fred Godtliebsen", "title": "A bag-to-class divergence approach to multiple-instance learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-instance (MI) learning, each object (bag) consists of multiple\nfeature vectors (instances), and is most commonly regarded as a set of points\nin a multidimensional space. A different viewpoint is that the instances are\nrealisations of random vectors with corresponding probability distribution, and\nthat a bag is the distribution, not the realisations. In MI classification,\neach bag in the training set has a class label, but the instances are\nunlabelled. By introducing the probability distribution space to bag-level\nclassification problems, dissimilarities between probability distributions\n(divergences) can be applied. The bag-to-bag Kullback-Leibler information is\nasymptotically the best classifier, but the typical sparseness of MI training\nsets is an obstacle. We introduce bag-to-class divergence to MI learning,\nemphasising the hierarchical nature of the random vectors that makes bags from\nthe same class different. We propose two properties for bag-to-class\ndivergences, and an additional property for sparse training sets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:33:29 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 23:39:08 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["M\u00f8llersen", "Kajsa", ""], ["Hardeberg", "Jon Yngve", ""], ["Godtliebsen", "Fred", ""]]}, {"id": "1803.02811", "submitter": "Adam Stooke", "authors": "Adam Stooke and Pieter Abbeel", "title": "Accelerated Methods for Deep Reinforcement Learning", "comments": "v2: -Added game performance statistics summary for algorithm scaling\n  across full Atari game set. -Added full set of learning curves (appendix).\n  -Fixed images to remove phantom borders. -Streamlined some discussion, moved\n  some details to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved many recent successes, yet\nexperiment turn-around time remains a key bottleneck in research and in\npractice. We investigate how to optimize existing deep RL algorithms for modern\ncomputers, specifically for a combination of CPUs and GPUs. We confirm that\nboth policy gradient and Q-value learning algorithms can be adapted to learn\nusing many parallel simulator instances. We further find it possible to train\nusing batch sizes considerably larger than are standard, without negatively\naffecting sample complexity or final performance. We leverage these facts to\nbuild a unified framework for parallelization that dramatically hastens\nexperiments in both classes of algorithm. All neural network computations use\nGPUs, accelerating both data collection and training. Our results include using\nan entire DGX-1 to learn successful strategies in Atari games in mere minutes,\nusing both synchronous and asynchronous algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:39:12 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 20:48:11 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Stooke", "Adam", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.02815", "submitter": "Gautam Kamath", "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Jacob\n  Steinhardt, Alistair Stewart", "title": "Sever: A Robust Meta-Algorithm for Stochastic Optimization", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensions, most machine learning methods are brittle to even a small\nfraction of structured outliers. To address this, we introduce a new\nmeta-algorithm that can take in a base learner such as least squares or\nstochastic gradient descent, and harden the learner to be resistant to\noutliers. Our method, Sever, possesses strong theoretical guarantees yet is\nalso highly scalable -- beyond running the base learner itself, it only\nrequires computing the top singular vector of a certain $n \\times d$ matrix. We\napply Sever on a drug design dataset and a spam classification dataset, and\nfind that in both cases it has substantially greater robustness than several\nbaselines. On the spam dataset, with $1\\%$ corruptions, we achieved $7.4\\%$\ntest error, compared to $13.4\\%-20.5\\%$ for the baselines, and $3\\%$ error on\nthe uncorrupted dataset. Similarly, on the drug design dataset, with $10\\%$\ncorruptions, we achieved $1.42$ mean-squared error test error, compared to\n$1.51$-$2.33$ for the baselines, and $1.23$ error on the uncorrupted dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:47:48 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:51:06 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kamath", "Gautam", ""], ["Kane", "Daniel M.", ""], ["Li", "Jerry", ""], ["Steinhardt", "Jacob", ""], ["Stewart", "Alistair", ""]]}, {"id": "1803.02855", "submitter": "Daniel Russo", "authors": "Daniel Russo and Benjamin Van Roy", "title": "Satisficing in Time-Sensitive Bandit Learning", "comments": "This submission largely supersedes earlier work in arXiv:1704.09028", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the recent literature on bandit learning focuses on algorithms that\naim to converge on an optimal action. One shortcoming is that this orientation\ndoes not account for time sensitivity, which can play a crucial role when\nlearning an optimal action requires much more information than near-optimal\nones. Indeed, popular approaches such as upper-confidence-bound methods and\nThompson sampling can fare poorly in such situations. We consider instead\nlearning a satisficing action, which is near-optimal while requiring less\ninformation, and propose satisficing Thompson sampling, an algorithm that\nserves this purpose. We establish a general bound on expected discounted regret\nand study the application of satisficing Thompson sampling to linear and\ninfinite-armed bandits, demonstrating arbitrarily large benefits over Thompson\nsampling. We also discuss the relation between the notion of satisficing and\nthe theory of rate distortion, which offers guidance on the selection of\nsatisficing actions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:41:44 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 19:23:18 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Russo", "Daniel", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1803.02865", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Rachel Ward and L\\'eon Bottou", "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "comments": "10 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 20:30:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 20:31:14 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1803.02879", "submitter": "Devon Graham Mr", "authors": "Jason Hartford, Devon R Graham, Kevin Leyton-Brown, Siamak Ravanbakhsh", "title": "Deep Models of Interactions Across Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use deep learning to model interactions across two or more sets of\nobjects, such as user-movie ratings, protein-drug bindings, or ternary\nuser-item-tag interactions. The canonical representation of such interactions\nis a matrix (or a higher-dimensional tensor) with an exchangeability property:\nthe encoding's meaning is not changed by permuting rows or columns. We argue\nthat models should hence be Permutation Equivariant (PE): constrained to make\nthe same predictions across such permutations. We present a parameter-sharing\nscheme and prove that it could not be made any more expressive without\nviolating PE. This scheme yields three benefits. First, we demonstrate\nstate-of-the-art performance on multiple matrix completion benchmarks. Second,\nour models require a number of parameters independent of the numbers of\nobjects, and thus scale well to large datasets. Third, models can be queried\nabout new objects that were not available at training time, but for which\ninteractions have since been observed. In experiments, our models achieved\nsurprisingly good generalization performance on this matrix extrapolation task,\nboth within domains (e.g., new users and new movies drawn from the same\ndistribution used for training) and even across domains (e.g., predicting music\nratings after training on movies).\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 21:18:25 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 22:43:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Hartford", "Jason", ""], ["Graham", "Devon R", ""], ["Leyton-Brown", "Kevin", ""], ["Ravanbakhsh", "Siamak", ""]]}, {"id": "1803.02893", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee", "title": "An efficient framework for learning sentence representations", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a simple and efficient framework for learning\nsentence representations from unlabelled data. Drawing inspiration from the\ndistributional hypothesis and recent work on learning sentence representations,\nwe reformulate the problem of predicting the context in which a sentence\nappears as a classification problem. Given a sentence and its context, a\nclassifier distinguishes context sentences from other contrastive sentences\nbased on their vector representations. This allows us to efficiently learn\ndifferent types of encoding functions, and we show that the model learns\nhigh-quality sentence representations. We demonstrate that our sentence\nrepresentations outperform state-of-the-art unsupervised and supervised\nrepresentation learning methods on several downstream NLP tasks that involve\nunderstanding sentence semantics while achieving an order of magnitude speedup\nin training time.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 22:02:10 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""]]}, {"id": "1803.02922", "submitter": "Partha Mitra", "authors": "Partha P Mitra", "title": "Fast Convergence for Stochastic and Distributed Gradient Descent in the\n  Interpolation Limit", "comments": "Accepted for presentation in EUSIPCO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern supervised learning techniques, particularly those using deep nets,\ninvolve fitting high dimensional labelled data sets with functions containing\nvery large numbers of parameters. Much of this work is empirical. Interesting\nphenomena have been observed that require theoretical explanations; however the\nnon-convexity of the loss functions complicates the analysis. Recently it has\nbeen proposed that the success of these techniques rests partly in the\neffectiveness of the simple stochastic gradient descent algorithm in the so\ncalled interpolation limit in which all labels are fit perfectly. This analysis\nis made possible since the SGD algorithm reduces to a stochastic linear system\nnear the interpolating minimum of the loss function. Here we exploit this\ninsight by presenting and analyzing a new distributed algorithm for gradient\ndescent, also in the interpolating limit. The distributed SGD algorithm\npresented in the paper corresponds to gradient descent applied to a simple\npenalized distributed loss function, $L({\\bf w}_1,...,{\\bf w}_n) = \\Sigma_i\nl_i({\\bf w}_i) + \\mu \\sum_{<i,j>}|{\\bf w}_i-{\\bf w}_j|^2$. Here each node holds\nonly one sample, and its own parameter vector. The notation $<i,j>$ denotes\nedges of a connected graph defining the links between nodes. It is shown that\nthis distributed algorithm converges linearly (ie the error reduces\nexponentially with iteration number), with a rate\n$1-\\frac{\\eta}{n}\\lambda_{min}(H)<R<1$ where $\\lambda_{min}(H)$ is the smallest\nnonzero eigenvalue of the sample covariance or the Hessian H. In contrast with\nprevious usage of similar penalty functions to enforce consensus between nodes,\nin the interpolating limit it is not required to take the penalty parameter to\ninfinity for consensus to occur. The analysis further reinforces the utility of\nthe interpolation limit in the theoretical treatment of modern machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 00:19:11 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 05:40:57 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 03:42:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mitra", "Partha P", ""]]}, {"id": "1803.02940", "submitter": "Ian Fox", "authors": "Jiaxuan Wang, Ian Fox, Jonathan Skaza, Nick Linck, Satinder Singh,\n  Jenna Wiens", "title": "The Advantage of Doubling: A Deep Reinforcement Learning Approach to\n  Studying the Double Team in the NBA", "comments": "Accepted to MIT Sloan Sports Analytics 2018. First two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the 2017 NBA playoffs, Celtics coach Brad Stevens was faced with a\ndifficult decision when defending against the Cavaliers: \"Do you double and\nrisk giving up easy shots, or stay at home and do the best you can?\" It's a\ntough call, but finding a good defensive strategy that effectively incorporates\ndoubling can make all the difference in the NBA. In this paper, we analyze\ndouble teaming in the NBA, quantifying the trade-off between risk and reward.\nUsing player trajectory data pertaining to over 643,000 possessions, we\nidentified when the ball handler was double teamed. Given these data and the\ncorresponding outcome (i.e., was the defense successful), we used deep\nreinforcement learning to estimate the quality of the defensive actions. We\npresent qualitative and quantitative results summarizing our learned defensive\nstrategy for defending. We show that our policy value estimates are predictive\nof points per possession and win percentage. Overall, the proposed framework\nrepresents a step toward a more comprehensive understanding of defensive\nstrategies in the NBA.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 02:08:49 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Wang", "Jiaxuan", ""], ["Fox", "Ian", ""], ["Skaza", "Jonathan", ""], ["Linck", "Nick", ""], ["Singh", "Satinder", ""], ["Wiens", "Jenna", ""]]}, {"id": "1803.02956", "submitter": "Brendan McCane", "authors": "Brendan McCane and Lech Szymanski", "title": "Some Approximation Bounds for Deep Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce new bounds on the approximation of functions in\ndeep networks and in doing so introduce some new deep network architectures for\nfunction approximation. These results give some theoretical insight into the\nsuccess of autoencoders and ResNets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 04:01:56 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["McCane", "Brendan", ""], ["Szymanski", "Lech", ""]]}, {"id": "1803.02965", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Peter Vamplew, Saeid Nahavandi,\n  Richard Dazeley, Chee Peng Lim", "title": "A Multi-Objective Deep Reinforcement Learning Framework", "comments": "21 pages", "journal-ref": "Engineering Applications of Artificial Intelligence, 2020", "doi": "10.1016/j.engappai.2020.103915", "report-no": "Volume 96, November 2020, 103915", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new scalable multi-objective deep reinforcement\nlearning (MODRL) framework based on deep Q-networks. We develop a\nhigh-performance MODRL framework that supports both single-policy and\nmulti-policy strategies, as well as both linear and non-linear approaches to\naction selection. The experimental results on two benchmark problems\n(two-objective deep sea treasure environment and three-objective Mountain Car\nproblem) indicate that the proposed framework is able to find the\nPareto-optimal solutions effectively. The proposed framework is generic and\nhighly modularized, which allows the integration of different deep\nreinforcement learning algorithms in different complex problem domains. This\ntherefore overcomes many disadvantages involved with standard multi-objective\nreinforcement learning methods in the current literature. The proposed\nframework acts as a testbed platform that accelerates the development of MODRL\nfor solving increasingly complicated multi-objective problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 04:50:21 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 17:20:52 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 16:04:41 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Vamplew", "Peter", ""], ["Nahavandi", "Saeid", ""], ["Dazeley", "Richard", ""], ["Lim", "Chee Peng", ""]]}, {"id": "1803.02991", "submitter": "Yingzhen Li", "authors": "Yingzhen Li, Stephan Mandt", "title": "Disentangled Sequential Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a VAE architecture for encoding and generating high dimensional\nsequential data, such as video or audio. Our deep generative model learns a\nlatent representation of the data which is split into a static and dynamic\npart, allowing us to approximately disentangle latent time-dependent features\n(dynamics) from features which are preserved over time (content). This\narchitecture gives us partial control over generating content and dynamics by\nconditioning on either one of these sets of features. In our experiments on\nartificially generated cartoon video clips and voice recordings, we show that\nwe can convert the content of a given sequence into another one by such content\nswapping. For audio, this allows us to convert a male speaker into a female\nspeaker and vice versa, while for video we can separately manipulate shapes and\ndynamics. Furthermore, we give empirical evidence for the hypothesis that\nstochastic RNNs as latent state models are more efficient at compressing and\ngenerating long sequences than deterministic ones, which may be relevant for\napplications in video compression.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 07:42:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 17:18:55 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Li", "Yingzhen", ""], ["Mandt", "Stephan", ""]]}, {"id": "1803.02999", "submitter": "John Schulman", "authors": "Alex Nichol, Joshua Achiam, John Schulman", "title": "On First-Order Meta-Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers meta-learning problems, where there is a distribution of\ntasks, and we would like to obtain an agent that performs well (i.e., learns\nquickly) when presented with a previously unseen task sampled from this\ndistribution. We analyze a family of algorithms for learning a parameter\ninitialization that can be fine-tuned quickly on a new task, using only\nfirst-order derivatives for the meta-learning updates. This family includes and\ngeneralizes first-order MAML, an approximation to MAML obtained by ignoring\nsecond-order derivatives. It also includes Reptile, a new algorithm that we\nintroduce here, which works by repeatedly sampling a task, training on it, and\nmoving the initialization towards the trained weights on that task. We expand\non the results from Finn et al. showing that first-order meta-learning\nalgorithms perform well on some well-established benchmarks for few-shot\nclassification, and we provide theoretical analysis aimed at understanding why\nthese algorithms work.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 08:29:38 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 19:00:28 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 16:11:14 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Nichol", "Alex", ""], ["Achiam", "Joshua", ""], ["Schulman", "John", ""]]}, {"id": "1803.03018", "submitter": "Heishiro Kanagawa", "authors": "Heishiro Kanagawa, Hayato Kobayashi, Nobuyuki Shimizu, Yukihiro Tagami\n  and Taiji Suzuki", "title": "Cross-domain Recommendation via Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of users in certain services could be a clue that can be used to\ninfer their preferences and may be used to make recommendations for other\nservices they have never used. However, the cross-domain relationships between\nitems and user consumption patterns are not simple, especially when there are\nfew or no common users and items across domains. To address this problem, we\npropose a content-based cross-domain recommendation method for cold-start users\nthat does not require user- and item- overlap. We formulate recommendation as\nextreme multi-class classification where labels (items) corresponding to the\nusers are predicted. With this formulation, the problem is reduced to a domain\nadaptation setting, in which a classifier trained in the source domain is\nadapted to the target domain. For this, we construct a neural network that\ncombines an architecture for domain adaptation, Domain Separation Network, with\na denoising autoencoder for item representation. We assess the performance of\nour approach in experiments on a pair of data sets collected from movie and\nnews services of Yahoo! JAPAN and show that our approach outperforms several\nbaseline methods including a cross-domain collaborative filtering method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 09:43:04 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Kanagawa", "Heishiro", ""], ["Kobayashi", "Hayato", ""], ["Shimizu", "Nobuyuki", ""], ["Tagami", "Yukihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1803.03039", "submitter": "Gareth Conduit", "authors": "B.D. Conduit, N.G. Jones, H.J. Stone, and G.J. Conduit", "title": "Design of a nickel-base superalloy using a neural network", "comments": null, "journal-ref": "Materials & Design 131, 358 (2017)", "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new computational tool has been developed to model, discover, and optimize\nnew alloys that simultaneously satisfy up to eleven physical criteria. An\nartificial neural network is trained from pre-existing materials data that\nenables the prediction of individual material properties both as a function of\ncomposition and heat treatment routine, which allows it to optimize the\nmaterial properties to search for the material with properties most likely to\nexceed a target criteria. We design a new polycrystalline nickel-base\nsuperalloy with the optimal combination of cost, density, gamma' phase content\nand solvus, phase stability, fatigue life, yield stress, ultimate tensile\nstrength, stress rupture, oxidation resistance, and tensile elongation.\nExperimental data demonstrates that the proposed alloy fulfills the\ncomputational predictions, possessing multiple physical properties,\nparticularly oxidation resistance and yield stress, that exceed existing\ncommercially available alloys.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 11:04:58 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Conduit", "B. D.", ""], ["Jones", "N. G.", ""], ["Stone", "H. J.", ""], ["Conduit", "G. J.", ""]]}, {"id": "1803.03145", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, Tamoghna Roy, Nathan West, Benjamin C. Hilburn", "title": "Physical Layer Communications System Design Over-the-Air Using\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method for synthesizing new physical layer\nmodulation and coding schemes for communications systems using a learning-based\napproach which does not require an analytic model of the impairments in the\nchannel. It extends prior work published on the channel autoencoder to consider\nthe case where the channel response is not known or can not be easily modeled\nin a closed form analytic expression. By adopting an adversarial approach for\nchannel response approximation and information encoding, we can jointly learn a\ngood solution to both tasks over a wide range of channel environments. We\ndescribe the operation of the proposed adversarial system, share results for\nits training and validation over-the-air, and discuss implications and future\nwork in the area.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:08:46 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["Roy", "Tamoghna", ""], ["West", "Nathan", ""], ["Hilburn", "Benjamin C.", ""]]}, {"id": "1803.03148", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Generating Artificial Data for Private Deep Learning", "comments": "Privacy-Enhancing Artificial Intelligence and Language Technologies,\n  AAAI Spring Symposium Series, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose generating artificial data that retain statistical\nproperties of real data as the means of providing privacy with respect to the\noriginal dataset. We use generative adversarial network to draw\nprivacy-preserving artificial data samples and derive an empirical method to\nassess the risk of information disclosure in a differential-privacy-like way.\nOur experiments show that we are able to generate artificial data of high\nquality and successfully train and validate machine learning models on this\ndata while limiting potential privacy loss.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:22:37 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 20:27:22 GMT"}, {"version": "v3", "created": "Sun, 28 Apr 2019 17:04:59 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1803.03155", "submitter": "Deborah Cohen", "authors": "Deborah Cohen, Amit Daniely, Amir Globerson, Gal Elidan", "title": "Learning Rules-First Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex classifiers may exhibit \"embarassing\" failures in cases where humans\ncan easily provide a justified classification. Avoiding such failures is\nobviously of key importance. In this work, we focus on one such setting, where\na label is perfectly predictable if the input contains certain features, or\nrules, and otherwise it is predictable by a linear classifier. We define a\nhypothesis class that captures this notion and determine its sample complexity.\nWe also give evidence that efficient algorithms cannot achieve this sample\ncomplexity. We then derive a simple and efficient algorithm and show that its\nsample complexity is close to optimal, among efficient algorithms. Experiments\non synthetic and sentiment analysis data demonstrate the efficacy of the\nmethod, both in terms of accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:32:49 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 15:45:01 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 14:48:14 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 13:44:55 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Cohen", "Deborah", ""], ["Daniely", "Amit", ""], ["Globerson", "Amir", ""], ["Elidan", "Gal", ""]]}, {"id": "1803.03185", "submitter": "Wen-Hao Chiang", "authors": "Wen-Hao Chiang, Li Shen, Lang Li and Xia Ning", "title": "Drug Recommendation toward Safe Polypharmacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reactions (ADRs) induced from high-order drug-drug interactions\n(DDIs) due to polypharmacy represent a significant public health problem. In\nthis paper, we formally formulate the to-avoid and safe (with respect to ADRs)\ndrug recommendation problems when multiple drugs have been taken\nsimultaneously. We develop a joint model with a recommendation component and an\nADR label prediction component to recommend for a prescription a set of\nto-avoid drugs that will induce ADRs if taken together with the prescription.\nWe also develop real drug-drug interaction datasets and corresponding\nevaluation protocols. Our experimental results on real datasets demonstrate the\nstrong performance of the joint model compared to other baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:22:26 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Chiang", "Wen-Hao", ""], ["Shen", "Li", ""], ["Li", "Lang", ""], ["Ning", "Xia", ""]]}, {"id": "1803.03191", "submitter": "Trisha Lawrence Ms.", "authors": "Trisha Lawrence", "title": "A Bayesian and Machine Learning approach to estimating Influence Model\n  parameters for IM-RO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The rise of Online Social Networks (OSNs) has caused an insurmountable amount\nof interest from advertisers and researchers seeking to monopolize on its\nfeatures. Researchers aim to develop strategies for determining how information\nis propagated among users within an OSN that is captured by diffusion or\ninfluence models. We consider the influence models for the IM-RO problem, a\nnovel formulation to the Influence Maximization (IM) problem based on\nimplementing Stochastic Dynamic Programming (SDP). In contrast to existing\napproaches involving influence spread and the theory of submodular functions,\nthe SDP method focuses on optimizing clicks and ultimately revenue to\nadvertisers in OSNs. Existing approaches to influence maximization have been\nactively researched over the past decade, with applications to multiple fields,\nhowever, our approach is a more practical variant to the original IM problem.\nIn this paper, we provide an analysis on the influence models of the IM-RO\nproblem by conducting experiments on synthetic and real-world datasets. We\npropose a Bayesian and Machine Learning approach for estimating the parameters\nof the influence models for the (Influence Maximization- Revenue Optimization)\nIM-RO problem. We present a Bayesian hierarchical model and implement the\nwell-known Naive Bayes classifier (NBC), Decision Trees classifier (DTC) and\nRandom Forest classifier (RFC) on three real-world datasets. Compared to\nprevious approaches to estimating influence model parameters, our strategy has\nthe great advantage of being directly implementable in standard software\npackages such as WinBUGS/OpenBUGS/JAGS and Apache Spark. We demonstrate the\nefficiency and usability of our methods in terms of spreading information and\ngenerating revenue for advertisers in the context of OSNs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:33:09 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Lawrence", "Trisha", ""]]}, {"id": "1803.03234", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "Improving Optimization for Models With Continuous Symmetry Breaking", "comments": "In the proceedings of International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), in PMLR 80:423-432", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many loss functions in representation learning are invariant under a\ncontinuous symmetry transformation. For example, the loss function of word\nembeddings (Mikolov et al., 2013) remains unchanged if we simultaneously rotate\nall word and context embedding vectors. We show that representation learning\nmodels for time series possess an approximate continuous symmetry that leads to\nslow convergence of gradient descent. We propose a new optimization algorithm\nthat speeds up convergence using ideas from gauge theory in physics. Our\nalgorithm leads to orders of magnitude faster convergence and to more\ninterpretable representations, as we show for dynamic extensions of matrix\nfactorization and word embedding models. We further present an example\napplication of our proposed algorithm that translates modern words into their\nhistoric equivalents.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:07:40 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 21:28:34 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 18:29:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "1803.03239", "submitter": "Michael P. Kim", "authors": "Michael P. Kim and Omer Reingold and Guy N. Rothblum", "title": "Fairness Through Computationally-Bounded Awareness", "comments": "Appears at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fair classification within the versatile framework of\nDwork et al. [ITCS '12], which assumes the existence of a metric that measures\nsimilarity between pairs of individuals. Unlike earlier work, we do not assume\nthat the entire metric is known to the learning algorithm; instead, the learner\ncan query this arbitrary metric a bounded number of times. We propose a new\nnotion of fairness called metric multifairness and show how to achieve this\nnotion in our setting. Metric multifairness is parameterized by a similarity\nmetric $d$ on pairs of individuals to classify and a rich collection ${\\cal C}$\nof (possibly overlapping) \"comparison sets\" over pairs of individuals. At a\nhigh level, metric multifairness guarantees that similar subpopulations are\ntreated similarly, as long as these subpopulations are identified within the\nclass ${\\cal C}$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:23:17 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 18:23:37 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kim", "Michael P.", ""], ["Reingold", "Omer", ""], ["Rothblum", "Guy N.", ""]]}, {"id": "1803.03241", "submitter": "Pravesh K Kothari", "authors": "Adam Klivans and Pravesh K. Kothari and Raghu Meka", "title": "Efficient Algorithms for Outlier-Robust Regression", "comments": "27 pages. Appeared in COLT 2018. This update removes Lemma 6.2 that\n  erroneously claimed an information-theoretic lower bound on error rate as a\n  function of fraction of outliers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time algorithm for performing linear or\npolynomial regression resilient to adversarial corruptions in both examples and\nlabels.\n  Given a sufficiently large (polynomial-size) training set drawn i.i.d. from\ndistribution D and subsequently corrupted on some fraction of points, our\nalgorithm outputs a linear function whose squared error is close to the squared\nerror of the best-fitting linear function with respect to D, assuming that the\nmarginal distribution of D over the input space is \\emph{certifiably\nhypercontractive}. This natural property is satisfied by many well-studied\ndistributions such as Gaussian, strongly log-concave distributions and, uniform\ndistribution on the hypercube among others. We also give a simple statistical\nlower bound showing that some distributional assumption is necessary to succeed\nin this setting.\n  These results are the first of their kind and were not known to be even\ninformation-theoretically possible prior to our work.\n  Our approach is based on the sum-of-squares (SoS) method and is inspired by\nthe recent applications of the method for parameter recovery problems in\nunsupervised learning. Our algorithm can be seen as a natural convex relaxation\nof the following conceptually simple non-convex optimization problem: find a\nlinear function and a large subset of the input corrupted sample such that the\nleast squares loss of the function over the subset is minimized over all\npossible large subsets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:30:31 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 04:04:29 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 15:42:45 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Klivans", "Adam", ""], ["Kothari", "Pravesh K.", ""], ["Meka", "Raghu", ""]]}, {"id": "1803.03242", "submitter": "Gal Yona", "authors": "Guy N. Rothblum and Gal Yona", "title": "Probably Approximately Metric-Fair Learning", "comments": "Published in International Conference on Machine Learning (ICML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seminal work of Dwork {\\em et al.} [ITCS 2012] introduced a metric-based\nnotion of individual fairness. Given a task-specific similarity metric, their\nnotion required that every pair of similar individuals should be treated\nsimilarly. In the context of machine learning, however, individual fairness\ndoes not generalize from a training set to the underlying population. We show\nthat this can lead to computational intractability even for simple\nfair-learning tasks.\n  With this motivation in mind, we introduce and study a relaxed notion of {\\em\napproximate metric-fairness}: for a random pair of individuals sampled from the\npopulation, with all but a small probability of error, if they are similar then\nthey should be treated similarly. We formalize the goal of achieving\napproximate metric-fairness simultaneously with best-possible accuracy as\nProbably Approximately Correct and Fair (PACF) Learning. We show that\napproximate metric-fairness {\\em does} generalize, and leverage these\ngeneralization guarantees to construct polynomial-time PACF learning algorithms\nfor the classes of linear and logistic predictors.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:35:08 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 07:01:34 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Rothblum", "Guy N.", ""], ["Yona", "Gal", ""]]}, {"id": "1803.03254", "submitter": "Noriaki HIrose", "authors": "Noriaki Hirose, Amir Sadeghian, Marynel V\\'azquez, Patrick Goebel, and\n  Silvio Savarese", "title": "GONet: A Semi-Supervised Deep Learning Approach For Traversability\n  Estimation", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present semi-supervised deep learning approaches for traversability\nestimation from fisheye images. Our method, GONet, and the proposed extensions\nleverage Generative Adversarial Networks (GANs) to effectively predict whether\nthe area seen in the input image(s) is safe for a robot to traverse. These\nmethods are trained with many positive images of traversable places, but just a\nsmall set of negative images depicting blocked and unsafe areas. This makes the\nproposed methods practical. Positive examples can be collected easily by simply\noperating a robot through traversable spaces, while obtaining negative examples\nis time consuming, costly, and potentially dangerous. Through extensive\nexperiments and several demonstrations, we show that the proposed\ntraversability estimation approaches are robust and can generalize to unseen\nscenarios. Further, we demonstrate that our methods are memory efficient and\nfast, allowing for real-time operation on a mobile robot with single or stereo\nfisheye cameras. As part of our contributions, we open-source two new datasets\nfor traversability estimation. These datasets are composed of approximately 24h\nof videos from more than 25 indoor environments. Our methods outperform\nbaseline approaches for traversability estimation on these new datasets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:52:03 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Hirose", "Noriaki", ""], ["Sadeghian", "Amir", ""], ["V\u00e1zquez", "Marynel", ""], ["Goebel", "Patrick", ""], ["Savarese", "Silvio", ""]]}, {"id": "1803.03288", "submitter": "Sayed Hadi Hashemi", "authors": "Sayed Hadi Hashemi, Sangeetha Abdu Jyothi, Roy H. Campbell", "title": "TicTac: Accelerating Distributed Deep Learning with Communication\n  Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep learning systems rely on iterative distributed training\nto tackle the increasing complexity of models and input data. The iteration\ntime in these communication-heavy systems depends on the computation time,\ncommunication time and the extent of overlap of computation and communication.\n  In this work, we identify a shortcoming in systems with graph representation\nfor computation, such as TensorFlow and PyTorch, that result in high variance\nin iteration time --- random order of received parameters across workers. We\ndevelop a system, TicTac, to improve the iteration time by fixing this issue in\ndistributed deep learning with Parameter Servers while guaranteeing\nnear-optimal overlap of communication and computation. TicTac identifies and\nenforces an order of network transfers which improves the iteration time using\nprioritization. Our system is implemented over TensorFlow and requires no\nchanges to the model or developer inputs. TicTac improves the throughput by up\nto $37.7\\%$ in inference and $19.2\\%$ in training, while also reducing\nstraggler effect by up to $2.3\\times$. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 20:03:51 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 00:38:36 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Hashemi", "Sayed Hadi", ""], ["Jyothi", "Sangeetha Abdu", ""], ["Campbell", "Roy H.", ""]]}, {"id": "1803.03289", "submitter": "Yuhui Xu", "authors": "Yuhui Xu, Yongzhuang Wang, Aojun Zhou, Weiyao Lin, Hongkai Xiong", "title": "Deep Neural Network Compression with Single and Multiple Level\n  Quantization", "comments": "Published in AAAI18. Code is available at\n  https://github.com/yuhuixu1993/SLQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is an effective solution to compress deep neural\nnetworks for practical usage. Existing network quantization methods cannot\nsufficiently exploit the depth information to generate low-bit compressed\nnetwork. In this paper, we propose two novel network quantization approaches,\nsingle-level network quantization (SLQ) for high-bit quantization and\nmulti-level network quantization (MLQ) for extremely low-bit quantization\n(ternary).We are the first to consider the network quantization from both width\nand depth level. In the width level, parameters are divided into two parts: one\nfor quantization and the other for re-training to eliminate the quantization\nloss. SLQ leverages the distribution of the parameters to improve the width\nlevel. In the depth level, we introduce incremental layer compensation to\nquantize layers iteratively which decreases the quantization loss in each\niteration. The proposed approaches are validated with extensive experiments\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:47:52 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 08:29:21 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Xu", "Yuhui", ""], ["Wang", "Yongzhuang", ""], ["Zhou", "Aojun", ""], ["Lin", "Weiyao", ""], ["Xiong", "Hongkai", ""]]}, {"id": "1803.03319", "submitter": "Itay Evron", "authors": "Itay Evron, Edward Moroshko, Koby Crammer", "title": "Efficient Loss-Based Decoding on Graphs For Extreme Classification", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (2018),\n  7232-7243", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In extreme classification problems, learning algorithms are required to map\ninstances to labels from an extremely large label set. We build on a recent\nextreme classification framework with logarithmic time and space, and on a\ngeneral approach for error correcting output coding (ECOC) with loss-based\ndecoding, and introduce a flexible and efficient approach accompanied by\ntheoretical bounds. Our framework employs output codes induced by graphs, for\nwhich we show how to perform efficient loss-based decoding to potentially\nimprove accuracy. In addition, our framework offers a tradeoff between\naccuracy, model size and prediction time. We show how to find the sweet spot of\nthis tradeoff using only the training data. Our experimental study demonstrates\nthe validity of our assumptions and claims, and shows that our method is\ncompetitive with state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 21:54:19 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 07:06:23 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Evron", "Itay", ""], ["Moroshko", "Edward", ""], ["Crammer", "Koby", ""]]}, {"id": "1803.03324", "submitter": "Yujia Li", "authors": "Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, Peter Battaglia", "title": "Learning Deep Generative Models of Graphs", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are fundamental data structures which concisely capture the relational\nstructure in many important real-world domains, such as knowledge graphs,\nphysical and social interactions, language, and chemistry. Here we introduce a\npowerful new approach for learning generative models over graphs, which can\ncapture both their structure and attributes. Our approach uses graph neural\nnetworks to express probabilistic dependencies among a graph's nodes and edges,\nand can, in principle, learn distributions over any arbitrary graph. In a\nseries of experiments our results show that once trained, our models can\ngenerate good quality samples of both synthetic graphs as well as real\nmolecular graphs, both unconditionally and conditioned on data. Compared to\nbaselines that do not use graph-structured representations, our models often\nperform far better. We also explore key challenges of learning generative\nmodels of graphs, such as how to handle symmetries and ordering of elements\nduring the graph generation process, and offer possible solutions. Our work is\nthe first and most general approach for learning generative models over\narbitrary graphs, and opens new directions for moving away from restrictions of\nvector- and sequence-like knowledge representations, toward more expressive and\nflexible relational data structures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 22:20:00 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Li", "Yujia", ""], ["Vinyals", "Oriol", ""], ["Dyer", "Chris", ""], ["Pascanu", "Razvan", ""], ["Battaglia", "Peter", ""]]}, {"id": "1803.03376", "submitter": "Lifu Tu", "authors": "Lifu Tu, Kevin Gimpel", "title": "Learning Approximate Inference Networks for Structured Prediction", "comments": "accepted by ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use\nneural network architectures to define energy functions that can capture\narbitrary dependencies among parts of structured outputs. Prior work used\ngradient descent for inference, relaxing the structured output to a set of\ncontinuous variables and then optimizing the energy with respect to them. We\nreplace this use of gradient descent with a neural network trained to\napproximate structured argmax inference. This \"inference network\" outputs\ncontinuous values that we treat as the output structure. We develop\nlarge-margin training criteria for joint training of the structured energy\nfunction and inference network. On multi-label classification we report\nspeed-ups of 10-60x compared to (Belanger et al, 2017) while also improving\naccuracy. For sequence labeling with simple structured energies, our approach\nperforms comparably to exact inference while being much faster at test time. We\nthen demonstrate improved accuracy by augmenting the energy with a \"label\nlanguage model\" that scores entire output label sequences, showing it can\nimprove handling of long-distance dependencies in part-of-speech tagging.\nFinally, we show how inference networks can replace dynamic programming for\ntest-time inference in conditional random fields, suggestive for their general\nuse for fast inference in structured settings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:50:24 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Tu", "Lifu", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1803.03382", "submitter": "Aurko Roy", "authors": "{\\L}ukasz Kaiser, Aurko Roy, Ashish Vaswani, Niki Parmar, Samy Bengio,\n  Jakob Uszkoreit, Noam Shazeer", "title": "Fast Decoding in Sequence Models using Discrete Latent Variables", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive sequence models based on deep neural networks, such as RNNs,\nWavenet and the Transformer attain state-of-the-art results on many tasks.\nHowever, they are difficult to parallelize and are thus slow at processing long\nsequences. RNNs lack parallelism both during training and decoding, while\narchitectures like WaveNet and Transformer are much more parallelizable during\ntraining, yet still operate sequentially during decoding.\n  Inspired by [arxiv:1711.00937], we present a method to extend sequence models\nusing discrete latent variables that makes decoding much more parallelizable.\nWe first auto-encode the target sequence into a shorter sequence of discrete\nlatent variables, which at inference time is generated autoregressively, and\nfinally decode the output sequence from this shorter latent sequence in\nparallel. To this end, we introduce a novel method for constructing a sequence\nof discrete latent variables and compare it with previously introduced methods.\nFinally, we evaluate our model end-to-end on the task of neural machine\ntranslation, where it is an order of magnitude faster at decoding than\ncomparable autoregressive models. While lower in BLEU than purely\nautoregressive models, our model achieves higher scores than previously\nproposed non-autoregressive translation models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 04:39:35 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 16:50:28 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 03:55:38 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2018 04:49:31 GMT"}, {"version": "v5", "created": "Sun, 29 Apr 2018 02:51:26 GMT"}, {"version": "v6", "created": "Thu, 7 Jun 2018 21:48:19 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Kaiser", "\u0141ukasz", ""], ["Roy", "Aurko", ""], ["Vaswani", "Ashish", ""], ["Parmar", "Niki", ""], ["Bengio", "Samy", ""], ["Uszkoreit", "Jakob", ""], ["Shazeer", "Noam", ""]]}, {"id": "1803.03383", "submitter": "Christopher De Sa", "authors": "Christopher De Sa, Megan Leszczynski, Jian Zhang, Alana Marzoev,\n  Christopher R. Aberger, Kunle Olukotun, Christopher R\\'e", "title": "High-Accuracy Low-Precision Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision computation is often used to lower the time and energy cost of\nmachine learning, and recently hardware accelerators have been developed to\nsupport it. Still, it has been used primarily for inference - not training.\nPrevious low-precision training algorithms suffered from a fundamental\ntradeoff: as the number of bits of precision is lowered, quantization noise is\nadded to the model, which limits statistical accuracy. To address this issue,\nwe describe a simple low-precision stochastic gradient descent variant called\nHALP. HALP converges at the same theoretical rate as full-precision algorithms\ndespite the noise introduced by using low precision throughout execution. The\nkey idea is to use SVRG to reduce gradient variance, and to combine this with a\nnovel technique called bit centering to reduce quantization error. We show that\non the CPU, HALP can run up to $4 \\times$ faster than full-precision SVRG and\ncan match its convergence trajectory. We implemented HALP in TensorQuant, and\nshow that it exceeds the validation performance of plain low-precision SGD on\ntwo deep learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 04:50:27 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["De Sa", "Christopher", ""], ["Leszczynski", "Megan", ""], ["Zhang", "Jian", ""], ["Marzoev", "Alana", ""], ["Aberger", "Christopher R.", ""], ["Olukotun", "Kunle", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1803.03467", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing\n  Xie, Minyi Guo", "title": "RippleNet: Propagating User Preferences on the Knowledge Graph for\n  Recommender Systems", "comments": "CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271739", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the sparsity and cold start problem of collaborative filtering,\nresearchers usually make use of side information, such as social networks or\nitem attributes, to improve recommendation performance. This paper considers\nthe knowledge graph as the source of side information. To address the\nlimitations of existing embedding-based and path-based methods for\nknowledge-graph-aware recommendation, we propose Ripple Network, an end-to-end\nframework that naturally incorporates the knowledge graph into recommender\nsystems. Similar to actual ripples propagating on the surface of water, Ripple\nNetwork stimulates the propagation of user preferences over the set of\nknowledge entities by automatically and iteratively extending a user's\npotential interests along links in the knowledge graph. The multiple \"ripples\"\nactivated by a user's historically clicked items are thus superposed to form\nthe preference distribution of the user with respect to a candidate item, which\ncould be used for predicting the final clicking probability. Through extensive\nexperiments on real-world datasets, we demonstrate that Ripple Network achieves\nsubstantial gains in a variety of scenarios, including movie, book and news\nrecommendation, over several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:12:01 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 12:15:17 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:28:32 GMT"}, {"version": "v4", "created": "Sat, 25 Aug 2018 05:52:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Jialin", ""], ["Zhao", "Miao", ""], ["Li", "Wenjie", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1803.03481", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, and Tetsunari\n  Inamura", "title": "Improved and Scalable Online Learning of Spatial Concepts and Language\n  Models with Mapping", "comments": "Accepted to Autonomous Robots (24 January 2020)", "journal-ref": null, "doi": "10.1007/s10514-020-09905-0", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm, called SpCoSLAM 2.0, for\nspatial concepts and lexical acquisition with high accuracy and scalability.\nPreviously, we proposed SpCoSLAM as an online learning algorithm based on\nunsupervised Bayesian probabilistic model that integrates multimodal place\ncategorization, lexical acquisition, and SLAM. However, our original algorithm\nhad limited estimation accuracy owing to the influence of the early stages of\nlearning, and increased computational complexity with added training data.\nTherefore, we introduce techniques such as fixed-lag rejuvenation to reduce the\ncalculation time while maintaining an accuracy higher than that of the original\nalgorithm. The results show that, in terms of estimation accuracy, the proposed\nalgorithm exceeds the original algorithm and is comparable to batch learning.\nIn addition, the calculation time of the proposed algorithm does not depend on\nthe amount of training data and becomes constant for each step of the scalable\nalgorithm. Our approach will contribute to the realization of long-term spatial\nlanguage interactions between humans and robots.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:06:04 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 07:36:32 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 12:17:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Taniguchi", "Akira", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1803.03503", "submitter": "Shao-Bo Lin", "authors": "Charles K. Chui, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Construction of neural networks for realization of localized deep\n  learning", "comments": "22pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of deep learning has recently attracted users of machine learning\nfrom various disciplines, including: medical diagnosis and bioinformatics,\nfinancial market analysis and online advertisement, speech and handwriting\nrecognition, computer vision and natural language processing, time series\nforecasting, and search engines. However, theoretical development of deep\nlearning is still at its infancy. The objective of this paper is to introduce a\ndeep neural network (also called deep-net) approach to localized manifold\nlearning, with each hidden layer endowed with a specific learning task. For the\npurpose of illustrations, we only focus on deep-nets with three hidden layers,\nwith the first layer for dimensionality reduction, the second layer for bias\nreduction, and the third layer for variance reduction. A feedback component\nalso designed to eliminate outliers. The main theoretical result in this paper\nis the order $\\mathcal O\\left(m^{-2s/(2s+d)}\\right)$ of approximation of the\nregression function with regularity $s$, in terms of the number $m$ of sample\npoints, where the (unknown) manifold dimension $d$ replaces the dimension $D$\nof the sampling (Euclidean) space for shallow nets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 13:28:01 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Chui", "Charles K.", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1803.03544", "submitter": "Marco Melis", "authors": "Marco Melis, Davide Maiorca, Battista Biggio, Giorgio Giacinto and\n  Fabio Roli", "title": "Explaining Black-box Android Malware Detection", "comments": "Published on the Proceedings of 26th European Signal Processing\n  Conference (EUSIPCO '18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models have been recently used for detecting malicious\nAndroid applications, reporting impressive performances on benchmark datasets,\neven when trained only on features statically extracted from the application,\nsuch as system calls and permissions. However, recent findings have highlighted\nthe fragility of such in-vitro evaluations with benchmark datasets, showing\nthat very few changes to the content of Android malware may suffice to evade\ndetection. How can we thus trust that a malware detector performing well on\nbenchmark data will continue to do so when deployed in an operating\nenvironment? To mitigate this issue, the most popular Android malware detectors\nuse linear, explainable machine-learning models to easily identify the most\ninfluential features contributing to each decision. In this work, we generalize\nthis approach to any black-box machine- learning model, by leveraging a\ngradient-based approach to identify the most influential local features. This\nenables using nonlinear models to potentially increase accuracy without\nsacrificing interpretability of decisions. Our approach also highlights the\nglobal characteristics learned by the model to discriminate between benign and\nmalware applications. Finally, as shown by our empirical analysis on a popular\nAndroid malware detection task, it also helps identifying potential\nvulnerabilities of linear and nonlinear models against adversarial\nmanipulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 14:56:36 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:19:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Melis", "Marco", ""], ["Maiorca", "Davide", ""], ["Biggio", "Battista", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1803.03607", "submitter": "Emilio Rafael Balda", "authors": "Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar", "title": "On Generation of Adversarial Examples using Convex Programming", "comments": "Best Student Paper Award in ASILOMAR 2018", "journal-ref": "ASILOMAR 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that deep learning architectures tend to make erroneous\ndecisions with high reliability for particularly designed adversarial\ninstances. In this work, we show that the perturbation analysis of these\narchitectures provides a framework for generating adversarial instances by\nconvex programming which, for classification tasks, is able to recover variants\nof existing non-adaptive adversarial methods. The proposed framework can be\nused for the design of adversarial noise under various desirable constraints\nand different types of networks. Moreover, this framework is capable of\nexplaining various existing adversarial methods and can be used to derive new\nalgorithms as well. We make use of these results to obtain novel algorithms.\nThe experiments show the competitive performance of the obtained solutions, in\nterms of fooling ratio, when benchmarked with well-known adversarial methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 17:24:45 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 11:32:36 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 08:33:19 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 22:14:52 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Balda", "Emilio Rafael", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1803.03623", "submitter": "Cong Feng", "authors": "Cong Feng and Jie Zhang", "title": "Hourly-Similarity Based Solar Forecasting Using Multi-Model Machine\n  Learning Blending", "comments": "2018 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing penetration of solar power into power systems,\nforecasting becomes critical in power system operations. In this paper, an\nhourly-similarity (HS) based method is developed for 1-hour-ahead (1HA) global\nhorizontal irradiance (GHI) forecasting. This developed method utilizes diurnal\npatterns, statistical distinctions between different hours, and hourly\nsimilarities in solar data to improve the forecasting accuracy. The HS-based\nmethod is built by training multiple two-layer multi-model forecasting\nframework (MMFF) models independently with the same-hour subsets. The final\noptimal model is a combination of MMFF models with the best-performed blending\nalgorithm at every hour. At the forecasting stage, the most suitable model is\nselected to perform the forecasting subtask of a certain hour. The HS-based\nmethod is validated by 1-year data with six solar features collected by the\nNational Renewable Energy Laboratory (NREL). Results show that the HS-based\nmethod outperforms the non-HS (all-in-one) method significantly with the same\nMMFF architecture, wherein the optimal HS- based method outperforms the best\nall-in-one method by 10.94% and 7.74% based on the normalized mean absolute\nerror and normalized root mean square error, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:17:52 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Feng", "Cong", ""], ["Zhang", "Jie", ""]]}, {"id": "1803.03635", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and Michael Carbin", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "comments": "ICLR camera ready", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning techniques can reduce the parameter counts of trained\nnetworks by over 90%, decreasing storage requirements and improving\ncomputational performance of inference without compromising accuracy. However,\ncontemporary experience is that the sparse architectures produced by pruning\nare difficult to train from the start, which would similarly improve training\nperformance.\n  We find that a standard pruning technique naturally uncovers subnetworks\nwhose initializations made them capable of training effectively. Based on these\nresults, we articulate the \"lottery ticket hypothesis:\" dense,\nrandomly-initialized, feed-forward networks contain subnetworks (\"winning\ntickets\") that - when trained in isolation - reach test accuracy comparable to\nthe original network in a similar number of iterations. The winning tickets we\nfind have won the initialization lottery: their connections have initial\nweights that make training particularly effective.\n  We present an algorithm to identify winning tickets and a series of\nexperiments that support the lottery ticket hypothesis and the importance of\nthese fortuitous initializations. We consistently find winning tickets that are\nless than 10-20% of the size of several fully-connected and convolutional\nfeed-forward architectures for MNIST and CIFAR10. Above this size, the winning\ntickets that we find learn faster than the original network and reach higher\ntest accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:51:28 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 19:58:09 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 19:46:47 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 20:03:01 GMT"}, {"version": "v5", "created": "Mon, 4 Mar 2019 15:51:11 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Frankle", "Jonathan", ""], ["Carbin", "Michael", ""]]}, {"id": "1803.03639", "submitter": "Nesime Tatbul", "authors": "Nesime Tatbul, Tae Jun Lee, Stan Zdonik, Mejbah Alam, Justin\n  Gottschlich", "title": "Precision and Recall for Time Series", "comments": "11 pages, 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical anomaly detection is principally concerned with point-based\nanomalies, those anomalies that occur at a single point in time. Yet, many\nreal-world anomalies are range-based, meaning they occur over a period of time.\nMotivated by this observation, we present a new mathematical model to evaluate\nthe accuracy of time series classification algorithms. Our model expands the\nwell-known Precision and Recall metrics to measure ranges, while simultaneously\nenabling customization support for domain-specific preferences.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 21:49:38 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 02:20:01 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 19:48:46 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Tatbul", "Nesime", ""], ["Lee", "Tae Jun", ""], ["Zdonik", "Stan", ""], ["Alam", "Mejbah", ""], ["Gottschlich", "Justin", ""]]}, {"id": "1803.03642", "submitter": "Abhinav Valada", "authors": "Abhinav Valada and Noha Radwan and Wolfram Burgard", "title": "Deep Auxiliary Learning for Visual Localization and Odometry", "comments": "Accepted for ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization is an indispensable component of a robot's autonomy stack that\nenables it to determine where it is in the environment, essentially making it a\nprecursor for any action execution or planning. Although convolutional neural\nnetworks have shown promising results for visual localization, they are still\ngrossly outperformed by state-of-the-art local feature-based techniques. In\nthis work, we propose VLocNet, a new convolutional neural network architecture\nfor 6-DoF global pose regression and odometry estimation from consecutive\nmonocular images. Our multitask model incorporates hard parameter sharing, thus\nbeing compact and enabling real-time inference, in addition to being end-to-end\ntrainable. We propose a novel loss function that utilizes auxiliary learning to\nleverage relative pose information during training, thereby constraining the\nsearch space to obtain consistent pose estimates. We evaluate our proposed\nVLocNet on indoor as well as outdoor datasets and show that even our single\ntask model exceeds the performance of state-of-the-art deep architectures for\nglobal localization, while achieving competitive performance for visual\nodometry estimation. Furthermore, we present extensive experimental evaluations\nutilizing our proposed Geometric Consistency Loss that show the effectiveness\nof multitask learning and demonstrate that our model is the first deep learning\ntechnique to be on par with, and in some cases outperforms state-of-the-art\nSIFT-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:56:57 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Valada", "Abhinav", ""], ["Radwan", "Noha", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1803.03665", "submitter": "Duncan Blythe", "authors": "Duncan Blythe and Alan Akbik and Roland Vollgraf", "title": "Syntax-Aware Language Modeling with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) are typically trained using only lexical\nfeatures, such as surface forms of words. In this paper, we argue this deprives\nthe LM of crucial syntactic signals that can be detected at high confidence\nusing existing parsers. We present a simple but highly effective approach for\ntraining neural LMs using both lexical and syntactic information, and a novel\napproach for applying such LMs to unparsed text using sequential Monte Carlo\nsampling. In experiments on a range of corpora and corpus sizes, we show our\napproach consistently outperforms standard lexical LMs in character-level\nlanguage modeling; on the other hand, for word-level models the models are on a\npar with standard language models. These results indicate potential for\nexpanding LMs beyond lexical surface features to higher-level NLP features for\ncharacter-level models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 14:47:24 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Blythe", "Duncan", ""], ["Akbik", "Alan", ""], ["Vollgraf", "Roland", ""]]}, {"id": "1803.03666", "submitter": "Chi-Ken Lu", "authors": "Chi-Ken Lu, Scott Cheng-Hsin Yang, Patrick Shafto", "title": "Standing Wave Decomposition Gaussian Process", "comments": "10 pages, 8 figures; updated version includes a modified introduction\n  and a new discussion on time complexity of our approximated GP method. New\n  references are added. Simulation package will be announced later; updated\n  with discussion of validity of perturbation treatment of Eq. (25) with added\n  Fig. 6 as evidence; simulation code at https://github.com/CoDaS-Lab/LG-SWD-GP", "journal-ref": "Phys. Rev. E 98, 032303 (2018)", "doi": "10.1103/PhysRevE.98.032303", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Standing Wave Decomposition (SWD) approximation to Gaussian\nProcess regression (GP). GP involves a costly matrix inversion operation, which\nlimits applicability to large data analysis. For an input space that can be\napproximated by a grid and when correlations among data are short-ranged, the\nkernel matrix inversion can be replaced by analytic diagonalization using the\nSWD. We show that this approach applies to uni- and multi-dimensional input\ndata, extends to include longer-range correlations, and the grid can be in a\nlatent space and used as inducing points. Through simulations, we show that our\napproximate method applied to the squared exponential kernel outperforms\nexisting methods in predictive accuracy per unit time in the regime where data\nare plentiful. Our SWD-GP is recommended for regression analyses where there is\na relatively large amount of data and/or there are constraints on computation\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:26:11 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 15:56:06 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 16:37:59 GMT"}, {"version": "v4", "created": "Mon, 17 Sep 2018 15:41:39 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Lu", "Chi-Ken", ""], ["Yang", "Scott Cheng-Hsin", ""], ["Shafto", "Patrick", ""]]}, {"id": "1803.03672", "submitter": "Amin  Khajehnejad", "authors": "Amin Khajehnejad and Shima Hajimirza", "title": "Competitive Machine Learning: Best Theoretical Prediction vs\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is often used in competitive scenarios: Participants learn\nand fit static models, and those models compete in a shared platform. The\ncommon assumption is that in order to win a competition one has to have the\nbest predictive model, i.e., the model with the smallest out-sample error. Is\nthat necessarily true? Does the best theoretical predictive model for a target\nalways yield the best reward in a competition? If not, can one take the best\nmodel and purposefully change it into a theoretically inferior model which in\npractice results in a higher competitive edge? How does that modification look\nlike? And finally, if all participants modify their prediction models towards\nthe best practical performance, who benefits the most? players with inferior\nmodels, or those with theoretical superiority? The main theme of this paper is\nto raise these important questions and propose a theoretical model to answer\nthem. We consider a study case where two linear predictive models compete over\na shared target. The model with the closest estimate gets the whole reward,\nwhich is equal to the absolute value of the target. We characterize the reward\nfunction of each model, and using a basic game theoretic approach, demonstrate\nthat the inferior competitor can significantly improve his performance by\nchoosing optimal model coefficients that are different from the best\ntheoretical prediction. This is a preliminary study that emphasizes the fact\nthat in many applications where predictive machine learning is at the service\nof competition, much can be gained from practical (back-testing) optimization\nof the model compared to static prediction improvement.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:42:54 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Khajehnejad", "Amin", ""], ["Hajimirza", "Shima", ""]]}, {"id": "1803.03674", "submitter": "Mohammadreza Mohaghegh Neyshabouri", "authors": "Mohammadreza Mohaghegh Neyshabouri, Suleyman Serdar Kozat", "title": "Sequential Outlier Detection based on Incremental Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online outlier detection algorithm to detect outliers in a\nsequentially observed data stream. For this purpose, we use a two-stage\nfiltering and hedging approach. In the first stage, we construct a multi-modal\nprobability density function to model the normal samples. In the second stage,\ngiven a new observation, we label it as an anomaly if the value of\naforementioned density function is below a specified threshold at the newly\nobserved point. In order to construct our multi-modal density function, we use\nan incremental decision tree to construct a set of subspaces of the observation\nspace. We train a single component density function of the exponential family\nusing the observations, which fall inside each subspace represented on the\ntree. These single component density functions are then adaptively combined to\nproduce our multi-modal density function, which is shown to achieve the\nperformance of the best convex combination of the density functions defined on\nthe subspaces. As we observe more samples, our tree grows and produces more\nsubspaces. As a result, our modeling power increases in time, while mitigating\noverfitting issues. In order to choose our threshold level to label the\nobservations, we use an adaptive thresholding scheme. We show that our adaptive\nthreshold level achieves the performance of the optimal pre-fixed threshold\nlevel, which knows the observation labels in hindsight. Our algorithm provides\nsignificant performance improvements over the state of the art in our wide set\nof experiments involving both synthetic as well as real data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 19:48:13 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Neyshabouri", "Mohammadreza Mohaghegh", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "1803.03684", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer", "title": "Scoring Formulation for Multi-Condition Joint PLDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint PLDA model, is a generalization of PLDA where the nuisance variable\nis no longer considered independent across samples, but potentially shared\n(tied) across samples that correspond to the same nuisance condition. The\noriginal work considered a single nuisance condition, deriving the EM and\nscoring formulas for this scenario. In this document, we show how to obtain\nlikelihood ratios for scoring when multiple nuisance conditions are allowed in\nthe model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:29:18 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Ferrer", "Luciana", ""]]}, {"id": "1803.03719", "submitter": "Pooyan Fazli", "authors": "Mahmoud Hamandi, Mike D'Arcy, and Pooyan Fazli", "title": "DeepMoTIon: Learning to Navigate Like Humans", "comments": "7 pages, In Proceedings of the IEEE International Conference on Robot\n  and Human Interactive Communication, RO-MAN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel human-aware navigation approach, where the robot learns to\nmimic humans to navigate safely in crowds. The presented model, referred to as\nDeepMoTIon, is trained with pedestrian surveillance data to predict human\nvelocity in the environment. The robot processes LiDAR scans via the trained\nnetwork to navigate to the target location. We conduct extensive experiments to\nassess the components of our network and prove their necessity to imitate\nhumans. Our experiments show that DeepMoTIion outperforms all the benchmarks in\nterms of human imitation, achieving a 24% reduction in time series-based path\ndeviation over the next best approach. In addition, while many other approaches\noften failed to reach the target, our method reached the target in 100% of the\ntest cases while complying with social norms and ensuring human safety.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 23:36:38 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 09:36:46 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 23:48:46 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Hamandi", "Mahmoud", ""], ["D'Arcy", "Mike", ""], ["Fazli", "Pooyan", ""]]}, {"id": "1803.03735", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran K. Thekumparampil, Chong Wang, Sewoong Oh, Li-Jia Li", "title": "Attention-based Graph Neural Network for Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently popularized graph neural networks achieve the state-of-the-art\naccuracy on a number of standard benchmark datasets for graph-based\nsemi-supervised learning, improving significantly over existing approaches.\nThese architectures alternate between a propagation layer that aggregates the\nhidden states of the local neighborhood and a fully-connected layer. Perhaps\nsurprisingly, we show that a linear model, that removes all the intermediate\nfully-connected layers, is still able to achieve a performance comparable to\nthe state-of-the-art models. This significantly reduces the number of\nparameters, which is critical for semi-supervised learning where number of\nlabeled examples are small. This in turn allows a room for designing more\ninnovative propagation layers. Based on this insight, we propose a novel graph\nneural network that removes all the intermediate fully-connected layers, and\nreplaces the propagation layers with attention mechanisms that respect the\nstructure of the graph. The attention mechanism allows us to learn a dynamic\nand adaptive local summary of the neighborhood to achieve more accurate\npredictions. In a number of experiments on benchmark citation networks\ndatasets, we demonstrate that our approach outperforms competing methods. By\nexamining the attention weights among neighbors, we show that our model\nprovides some interesting insights on how neighbors influence each other.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 02:01:35 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Thekumparampil", "Kiran K.", ""], ["Wang", "Chong", ""], ["Oh", "Sewoong", ""], ["Li", "Li-Jia", ""]]}, {"id": "1803.03756", "submitter": "Lili Zhang", "authors": "Lili Zhang, Jennifer Priestley and Xuelei Ni", "title": "Influence of the Event Rate on Discrimination Abilities of Bankruptcy\n  Prediction Models", "comments": null, "journal-ref": "International Journal of Database Management Systems. 2018\n  February 10(1): 1-14", "doi": "10.5121/ijdms.2018.10101", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In bankruptcy prediction, the proportion of events is very low, which is\noften oversampled to eliminate this bias. In this paper, we study the influence\nof the event rate on discrimination abilities of bankruptcy prediction models.\nFirst the statistical association and significance of public records and\nfirmographics indicators with the bankruptcy were explored. Then the event rate\nwas oversampled from 0.12% to 10%, 20%, 30%, 40%, and 50%, respectively. Seven\nmodels were developed, including Logistic Regression, Decision Tree, Random\nForest, Gradient Boosting, Support Vector Machine, Bayesian Network, and Neural\nNetwork. Under different event rates, models were comprehensively evaluated and\ncompared based on Kolmogorov-Smirnov Statistic, accuracy, F1 score, Type I\nerror, Type II error, and ROC curve on the hold-out dataset with their best\nprobability cut-offs. Results show that Bayesian Network is the most\ninsensitive to the event rate, while Support Vector Machine is the most\nsensitive.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 04:51:31 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zhang", "Lili", ""], ["Priestley", "Jennifer", ""], ["Ni", "Xuelei", ""]]}, {"id": "1803.03759", "submitter": "Sanjay Krishna Gouda", "authors": "Sanjay Krishna Gouda, Salil Kanetkar, David Harrison and Manfred K\n  Warmuth", "title": "Speech Recognition: Keyword Spotting Through Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of identifying voice commands has always been a challenge due to\nthe presence of noise and variability in speed, pitch, etc. We will compare the\nefficacies of several neural network architectures for the speech recognition\nproblem. In particular, we will build a model to determine whether a one second\naudio clip contains a particular word (out of a set of 10), an unknown word, or\nsilence. The models to be implemented are a CNN recommended by the Tensorflow\nSpeech Recognition tutorial, a low-latency CNN, and an adversarially trained\nCNN. The result is a demonstration of how to convert a problem in audio\nrecognition to the better-studied domain of image classification, where the\npowerful techniques of convolutional neural networks are fully developed.\nAdditionally, we demonstrate the applicability of the technique of Virtual\nAdversarial Training (VAT) to this problem domain, functioning as a powerful\nregularizer with promising potential future applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 05:16:18 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:10:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gouda", "Sanjay Krishna", ""], ["Kanetkar", "Salil", ""], ["Harrison", "David", ""], ["Warmuth", "Manfred K", ""]]}, {"id": "1803.03769", "submitter": "Siong Thye Goh", "authors": "Siong Thye Goh, Cynthia Rudin", "title": "A Minimax Surrogate Loss Approach to Conditional Difference Estimation", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning approach to estimate personalized treatment\neffects in the classical potential outcomes framework with binary outcomes. To\novercome the problem that both treatment and control outcomes for the same unit\nare required for supervised learning, we propose surrogate loss functions that\nincorporate both treatment and control data. The new surrogates yield tighter\nbounds than the sum of losses for treatment and control groups. A specific\nchoice of loss function, namely a type of hinge loss, yields a minimax support\nvector machine formulation. The resulting optimization problem requires the\nsolution to only a single convex optimization problem, incorporating both\ntreatment and control units, and it enables the kernel trick to be used to\nhandle nonlinear (also non-parametric) estimation. Statistical learning bounds\nare also presented for the framework, and experimental results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 07:01:52 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 03:36:42 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Goh", "Siong Thye", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1803.03772", "submitter": "Shao-Bo Lin", "authors": "Shao-Bo Lin", "title": "Generalization and Expressivity for Deep Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the rapid development of deep learning in practice, the\ntheoretical explanations for its success become urgent. Generalization and\nexpressivity are two widely used measurements to quantify theoretical behaviors\nof deep learning. The expressivity focuses on finding functions expressible by\ndeep nets but cannot be approximated by shallow nets with the similar number of\nneurons. It usually implies the large capacity. The generalization aims at\nderiving fast learning rate for deep nets. It usually requires small capacity\nto reduce the variance. Different from previous studies on deep learning,\npursuing either expressivity or generalization, we take both factors into\naccount to explore the theoretical advantages of deep nets. For this purpose,\nwe construct a deep net with two hidden layers possessing excellent\nexpressivity in terms of localized and sparse approximation. Then, utilizing\nthe well known covering number to measure the capacity, we find that deep nets\npossess excellent expressive power (measured by localized and sparse\napproximation) without enlarging the capacity of shallow nets. As a\nconsequence, we derive near optimal learning rates for implementing empirical\nrisk minimization (ERM) on the constructed deep nets. These results\ntheoretically exhibit the advantage of deep nets from learning theory\nviewpoints.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 07:41:25 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 13:53:06 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lin", "Shao-Bo", ""]]}, {"id": "1803.03800", "submitter": "Pramod Kompalli", "authors": "Srayanta Mukherjee, Devashish Shankar, Atin Ghosh, Nilam Tathawadekar,\n  Pramod Kompalli, Sunita Sarawagi, Krishnendu Chaudhury", "title": "ARMDN: Associative and Recurrent Mixture Density Networks for eRetail\n  Demand Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate demand forecasts can help on-line retail organizations better plan\ntheir supply-chain processes. The challenge, however, is the large number of\nassociative factors that result in large, non-stationary shifts in demand,\nwhich traditional time series and regression approaches fail to model. In this\npaper, we propose a Neural Network architecture called AR-MDN, that\nsimultaneously models associative factors, time-series trends and the variance\nin the demand. We first identify several causal features and use a combination\nof feature embeddings, MLP and LSTM to represent them. We then model the output\ndensity as a learned mixture of Gaussian distributions. The AR-MDN can be\ntrained end-to-end without the need for additional supervision. We experiment\non a dataset of an year's worth of data over tens-of-thousands of products from\nFlipkart. The proposed architecture yields a significant improvement in\nforecasting accuracy when compared with existing alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 12:45:11 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 04:49:15 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mukherjee", "Srayanta", ""], ["Shankar", "Devashish", ""], ["Ghosh", "Atin", ""], ["Tathawadekar", "Nilam", ""], ["Kompalli", "Pramod", ""], ["Sarawagi", "Sunita", ""], ["Chaudhury", "Krishnendu", ""]]}, {"id": "1803.03807", "submitter": "Tomer Golomb", "authors": "Tomer Golomb, Yisroel Mirsky and Yuval Elovici", "title": "CIoTA: Collaborative IoT Anomaly Detection via Blockchain", "comments": "Appears in the workshop on Decentralized IoT Security and Standards\n  (DISS) of the Network and Distributed Systems Security Symposium (NDSS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their rapid growth and deployment, Internet of things (IoT) devices\nhave become a central aspect of our daily lives. However, they tend to have\nmany vulnerabilities which can be exploited by an attacker. Unsupervised\ntechniques, such as anomaly detection, can help us secure the IoT devices.\nHowever, an anomaly detection model must be trained for a long time in order to\ncapture all benign behaviors. This approach is vulnerable to adversarial\nattacks since all observations are assumed to be benign while training the\nanomaly detection model.\n  In this paper, we propose CIoTA, a lightweight framework that utilizes the\nblockchain concept to perform distributed and collaborative anomaly detection\nfor devices with limited resources. CIoTA uses blockchain to incrementally\nupdate a trusted anomaly detection model via self-attestation and consensus\namong IoT devices. We evaluate CIoTA on our own distributed IoT simulation\nplatform, which consists of 48 Raspberry Pis, to demonstrate CIoTA's ability to\nenhance the security of each device and the security of the network as a whole.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 13:53:19 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 19:09:08 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Golomb", "Tomer", ""], ["Mirsky", "Yisroel", ""], ["Elovici", "Yuval", ""]]}, {"id": "1803.03831", "submitter": "Anne Morvan", "authors": "Rafael Pinot, Anne Morvan, Florian Yger, C\\'edric Gouy-Pailler, Jamal\n  Atif", "title": "Graph-based Clustering under Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first differentially private clustering method\nfor arbitrary-shaped node clusters in a graph. This algorithm takes as input\nonly an approximate Minimum Spanning Tree (MST) $\\mathcal{T}$ released under\nweight differential privacy constraints from the graph. Then, the underlying\nnonconvex clustering partition is successfully recovered from cutting optimal\ncuts on $\\mathcal{T}$. As opposed to existing methods, our algorithm is\ntheoretically well-motivated. Experiments support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 16:26:47 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pinot", "Rafael", ""], ["Morvan", "Anne", ""], ["Yger", "Florian", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1803.03833", "submitter": "Pan Li", "authors": "Pan Li and Olgica Milenkovic", "title": "Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral\n  Clustering", "comments": "A short version of this paper is presented in ICML 2018. This version\n  includes the definition of a sequence of eigenvalues for 1-Laplacian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce submodular hypergraphs, a family of hypergraphs that have\ndifferent submodular weights associated with different cuts of hyperedges.\nSubmodular hypergraphs arise in clustering applications in which higher-order\nstructures carry relevant information. For such hypergraphs, we define the\nnotion of p-Laplacians and derive corresponding nodal domain theorems and k-way\nCheeger inequalities. We conclude with the description of algorithms for\ncomputing the spectra of 1- and 2-Laplacians that constitute the basis of new\nspectral hypergraph clustering methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 16:42:05 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 19:36:36 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 23:45:45 GMT"}, {"version": "v4", "created": "Thu, 11 Oct 2018 16:17:55 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Li", "Pan", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1803.03835", "submitter": "S. M. Ali Eslami", "authors": "Simon Schmitt, Jonathan J. Hudson, Augustin Zidek, Simon Osindero,\n  Carl Doersch, Wojciech M. Czarnecki, Joel Z. Leibo, Heinrich Kuttler, Andrew\n  Zisserman, Karen Simonyan, S. M. Ali Eslami", "title": "Kickstarting Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for using previously-trained 'teacher' agents to\nkickstart the training of a new 'student' agent. To this end, we leverage ideas\nfrom policy distillation and population based training. Our method places no\nconstraints on the architecture of the teacher or student agents, and it\nregulates itself to allow the students to surpass their teachers in\nperformance. We show that, on a challenging and computationally-intensive\nmulti-task benchmark (DMLab-30), kickstarted training improves the data\nefficiency of new agents, making it significantly easier to iterate on their\ndesign. We also show that the same kickstarting pipeline can allow a single\nstudent agent to leverage multiple 'expert' teachers which specialize on\nindividual tasks. In this setting kickstarting yields surprisingly large gains,\nwith the kickstarted agent matching the performance of an agent trained from\nscratch in almost 10x fewer steps, and surpassing its final performance by 42\npercent. Kickstarting is conceptually simple and can easily be incorporated\ninto reinforcement learning experiments.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 16:45:00 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Schmitt", "Simon", ""], ["Hudson", "Jonathan J.", ""], ["Zidek", "Augustin", ""], ["Osindero", "Simon", ""], ["Doersch", "Carl", ""], ["Czarnecki", "Wojciech M.", ""], ["Leibo", "Joel Z.", ""], ["Kuttler", "Heinrich", ""], ["Zisserman", "Andrew", ""], ["Simonyan", "Karen", ""], ["Eslami", "S. M. Ali", ""]]}, {"id": "1803.03851", "submitter": "Pan Li", "authors": "Pan Li and Olgica Milenkovic", "title": "Revisiting Decomposable Submodular Function Minimization with Incidence\n  Relations", "comments": "A part of this work will be presented in NIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to decomposable submodular function minimization\n(DSFM) that exploits incidence relations. Incidence relations describe which\nvariables effectively influence the component functions, and when properly\nutilized, they allow for improving the convergence rates of DSFM solvers. Our\nmain results include the precise parametrization of the DSFM problem based on\nincidence relations, the development of new scalable alternative projections\nand parallel coordinate descent methods and an accompanying rigorous analysis\nof their convergence rates.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 18:40:07 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 07:37:50 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 22:35:05 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Li", "Pan", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1803.03870", "submitter": "Stephan Zheng", "authors": "Sumanth Dathathri, Stephan Zheng, Tianwei Yin, Richard M. Murray,\n  Yisong Yue", "title": "Detecting Adversarial Examples via Neural Fingerprinting", "comments": "First 2 authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which\ndramatically alter model output using small input changes. We propose Neural\nFingerprinting, a simple, yet effective method to detect adversarial examples\nby verifying whether model behavior is consistent with a set of secret\nfingerprints, inspired by the use of biometric and cryptographic signatures.\nThe benefits of our method are that 1) it is fast, 2) it is prohibitively\nexpensive for an attacker to reverse-engineer which fingerprints were used, and\n3) it does not assume knowledge of the adversary. In this work, we pose a\nformal framework to analyze fingerprints under various threat models, and\ncharacterize Neural Fingerprinting for linear models. For complex neural\nnetworks, we empirically demonstrate that Neural Fingerprinting significantly\nimproves on state-of-the-art detection mechanisms by detecting the strongest\nknown adversarial attacks with 98-100% AUC-ROC scores on the MNIST, CIFAR-10\nand MiniImagenet (20 classes) datasets. In particular, the detection accuracy\nof Neural Fingerprinting generalizes well to unseen test-data under various\nblack- and whitebox threat models, and is robust over a wide range of\nhyperparameters and choices of fingerprints.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 00:37:41 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 04:19:50 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 23:46:00 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Dathathri", "Sumanth", ""], ["Zheng", "Stephan", ""], ["Yin", "Tianwei", ""], ["Murray", "Richard M.", ""], ["Yue", "Yisong", ""]]}, {"id": "1803.03877", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz and Robert Sabourin and George D. C. Cavalcanti", "title": "On dynamic ensemble selection and data preprocessing for multi-class\n  imbalance learning", "comments": "Proceedings of the ICPRAI 2018 pp. 189-194", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-imbalance refers to classification problems in which many more\ninstances are available for certain classes than for others. Such imbalanced\ndatasets require special attention because traditional classifiers generally\nfavor the majority class which has a large number of instances. Ensemble of\nclassifiers have been reported to yield promising results. However, the\nmajority of ensemble methods applied too imbalanced learning are static ones.\nMoreover, they only deal with binary imbalanced problems. Hence, this paper\npresents an empirical analysis of dynamic selection techniques and data\npreprocessing methods for dealing with multi-class imbalanced problems. We\nconsidered five variations of preprocessing methods and four dynamic selection\nmethods. Our experiments conducted on 26 multi-class imbalanced problems show\nthat the dynamic ensemble improves the F-measure and the G-mean as compared to\nthe static ensemble. Moreover, data preprocessing plays an important role in\nsuch cases.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 01:46:31 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 15:52:59 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1803.03880", "submitter": "Soorya Gopalakrishnan", "authors": "Soorya Gopalakrishnan, Zhinus Marzi, Upamanyu Madhow, Ramtin Pedarsani", "title": "Combating Adversarial Attacks Using Sparse Representations", "comments": "Accepted at ICLR Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks (DNNs). In this paper, we make\nthe case that sparse representations of the input data are a crucial tool for\ncombating such attacks. For linear classifiers, we show that a sparsifying\nfront end is provably effective against $\\ell_{\\infty}$-bounded attacks,\nreducing output distortion due to the attack by a factor of roughly $K / N$\nwhere $N$ is the data dimension and $K$ is the sparsity level. We then extend\nthis concept to DNNs, showing that a \"locally linear\" model can be used to\ndevelop a theoretical foundation for crafting attacks and defenses.\nExperimental results for the MNIST dataset show the efficacy of the proposed\nsparsifying front end.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 02:02:46 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 10:36:47 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 17:16:53 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Gopalakrishnan", "Soorya", ""], ["Marzi", "Zhinus", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1803.03903", "submitter": "Kurt Riedel", "authors": "Kurt S. Riedel", "title": "Piecewise Convex Function Estimation and Model Selection", "comments": "arXiv admin note: text overlap with arXiv:1803.03901", "journal-ref": "Approximation Theory Viii - Volume 1: Approximation And\n  Interpolation edited by Chui Charles K, Schumaker Larry L 1995 by World\n  Scientific Publishing", "doi": null, "report-no": null, "categories": "stat.ME cs.LG eess.SP math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given noisy data, function estimation is considered when the unknown function\nis known apriori to consist of a small number of regions where the function is\neither convex or concave. When the regions are known apriori, the estimate is\nreduced to a finite dimensional convex optimization in the dual space. When the\nnumber of regions is unknown, the model selection problem is to determine the\nnumber of convexity change points. We use a pilot estimator based on the\nexpected number of false inflection points.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 04:45:57 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Riedel", "Kurt S.", ""]]}, {"id": "1803.03910", "submitter": "Li Zeng", "authors": "Li Zeng, Zhaolong Yu, Hongyu Zhao", "title": "A pathway-based kernel boosting method for sample classification using\n  genomic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of cancer genomic data has long suffered \"the curse of\ndimensionality\". Sample sizes for most cancer genomic studies are a few\nhundreds at most while there are tens of thousands of genomic features studied.\nVarious methods have been proposed to leverage prior biological knowledge, such\nas pathways, to more effectively analyze cancer genomic data. Most of the\nmethods focus on testing marginal significance of the associations between\npathways and clinical phenotypes. They can identify relevant pathways, but do\nnot involve predictive modeling. In this article, we propose a Pathway-based\nKernel Boosting (PKB) method for integrating gene pathway information for\nsample classification, where we use kernel functions calculated from each\npathway as base learners and learn the weights through iterative optimization\nof the classification loss function. We apply PKB and several competing methods\nto three cancer studies with pathological and clinical information, including\ntumor grade, stage, tumor sites, and metastasis status. Our results show that\nPKB outperforms other methods, and identifies pathways relevant to the outcome\nvariables.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 05:50:35 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zeng", "Li", ""], ["Yu", "Zhaolong", ""], ["Zhao", "Hongyu", ""]]}, {"id": "1803.03916", "submitter": "Xiang Gao", "authors": "Xiang Gao", "title": "Deep reinforcement learning for time series: playing idealized trading\n  games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-learning is investigated as an end-to-end solution to estimate the\noptimal strategies for acting on time series input. Experiments are conducted\non two idealized trading games. 1) Univariate: the only input is a wave-like\nprice time series, and 2) Bivariate: the input includes a random stepwise price\ntime series and a noisy signal time series, which is positively correlated with\nfuture price changes. The Univariate game tests whether the agent can capture\nthe underlying dynamics, and the Bivariate game tests whether the agent can\nutilize the hidden relation among the inputs. Stacked Gated Recurrent Unit\n(GRU), Long Short-Term Memory (LSTM) units, Convolutional Neural Network (CNN),\nand multi-layer perceptron (MLP) are used to model Q values. For both games,\nall agents successfully find a profitable strategy. The GRU-based agents show\nbest overall performance in the Univariate game, while the MLP-based agents\noutperform others in the Bivariate game.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 06:56:29 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Gao", "Xiang", ""]]}, {"id": "1803.03919", "submitter": "Yingxiang Yang", "authors": "Yingxiang Yang, Adams Wei Yu, Zhaoran Wang and Tuo Zhao", "title": "Detecting Nonlinear Causality in Multivariate Time Series with Sparse\n  Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric method for detecting nonlinear causal relationship\nwithin a set of multidimensional discrete time series, by using sparse additive\nmodels (SpAMs). We show that, when the input to the SpAM is a $\\beta$-mixing\ntime series, the model can be fitted by first approximating each unknown\nfunction with a linear combination of a set of B-spline bases, and then solving\na group-lasso-type optimization problem with nonconvex regularization.\nTheoretically, we characterize the oracle statistical properties of the\nproposed sparse estimator in function estimation and model selection.\nNumerically, we propose an efficient pathwise iterative shrinkage thresholding\nalgorithm (PISTA), which tames the nonconvexity and guarantees linear\nconvergence towards the desired sparse estimator with high probability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 07:46:24 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 04:24:14 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Yang", "Yingxiang", ""], ["Yu", "Adams Wei", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "1803.03965", "submitter": "Pan Li", "authors": "Pan Li and Qiang Liu and Wentao Zhao and Dongxu Wang and Siqi Wang", "title": "BEBP: An Poisoning Method Against Machine Learning Based IDSs", "comments": "7 pages,5figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data era, machine learning is one of fundamental techniques in\nintrusion detection systems (IDSs). However, practical IDSs generally update\ntheir decision module by feeding new data then retraining learning models in a\nperiodical way. Hence, some attacks that comprise the data for training or\ntesting classifiers significantly challenge the detecting capability of machine\nlearning-based IDSs. Poisoning attack, which is one of the most recognized\nsecurity threats towards machine learning-based IDSs, injects some adversarial\nsamples into the training phase, inducing data drifting of training data and a\nsignificant performance decrease of target IDSs over testing data. In this\npaper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel\npoisoning method that attack against several machine learning algorithms used\nin IDSs. Specifically, we propose a boundary pattern detection algorithm to\nefficiently generate the points that are near to abnormal data but considered\nto be normal ones by current classifiers. Then, we introduce a Batch-EPD\nBoundary Pattern (BEBP) detection algorithm to overcome the limitation of the\nnumber of edge pattern points generated by EPD and to obtain more useful\nadversarial samples. Based on BEBP, we further present a moderate but effective\npoisoning method called chronic poisoning attack. Extensive experiments on\nsynthetic and three real network data sets demonstrate the performance of the\nproposed poisoning method against several well-known machine learning\nalgorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 14:15:50 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Li", "Pan", ""], ["Liu", "Qiang", ""], ["Zhao", "Wentao", ""], ["Wang", "Dongxu", ""], ["Wang", "Siqi", ""]]}, {"id": "1803.04008", "submitter": "Tanner Fiez", "authors": "Tanner Fiez and Shreyas Sekar and Lillian J. Ratliff", "title": "Multi-Armed Bandits for Correlated Markovian Environments with Smoothed\n  Reward Feedback", "comments": "Significant revision of prior version including deeper discussion of\n  related work, gap-independent regret bounds, and regret bounds for discounted\n  rewards", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-armed bandit problem in a dynamic environment where arm\nrewards evolve in a correlated fashion according to a Markov chain. Different\nthan much of the work on related problems, in our formulation a learning\nalgorithm does not have access to either a priori information or observations\nof the state of the Markov chain and only observes smoothed reward feedback\nfollowing time intervals we refer to as epochs. We demonstrate that existing\nmethods such as UCB and $\\varepsilon$-greedy can suffer linear regret in such\nan environment. Employing mixing-time bounds on Markov chains, we develop\nalgorithms called EpochUCB and EpochGreedy that draw inspiration from the\naforementioned methods, yet which admit sublinear regret guarantees for the\nproblem formulation. Our proposed algorithms proceed in epochs in which an arm\nis played repeatedly for a number of iterations that grows linearly as a\nfunction of the number of times an arm has been played in the past. We analyze\nthese algorithms under two types of smoothed reward feedback at the end of each\nepoch: a reward that is the discount-average of the discounted rewards within\nan epoch, and a reward that is the time-average of the rewards within an epoch.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 18:44:50 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 22:03:13 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Fiez", "Tanner", ""], ["Sekar", "Shreyas", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "1803.04015", "submitter": "Cem Tekin", "authors": "Eralp Tur\\u{g}ay and Doruk \\\"Oner and Cem Tekin", "title": "Multi-objective Contextual Bandit Problem with Similarity Information", "comments": "The 21st International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the multi-objective contextual bandit problem with\nsimilarity information. This problem extends the classical contextual bandit\nproblem with similarity information by introducing multiple and possibly\nconflicting objectives. Since the best arm in each objective can be different\ngiven the context, learning the best arm based on a single objective can\njeopardize the rewards obtained from the other objectives. In order to evaluate\nthe performance of the learner in this setup, we use a performance metric\ncalled the contextual Pareto regret. Essentially, the contextual Pareto regret\nis the sum of the distances of the arms chosen by the learner to the context\ndependent Pareto front. For this problem, we develop a new online learning\nalgorithm called Pareto Contextual Zooming (PCZ), which exploits the idea of\ncontextual zooming to learn the arms that are close to the Pareto front for\neach observed context by adaptively partitioning the joint context-arm set\naccording to the observed rewards and locations of the context-arm pairs\nselected in the past. Then, we prove that PCZ achieves $\\tilde O\n(T^{(1+d_p)/(2+d_p)})$ Pareto regret where $d_p$ is the Pareto zooming\ndimension that depends on the size of the set of near-optimal context-arm\npairs. Moreover, we show that this regret bound is nearly optimal by providing\nan almost matching $\\Omega (T^{(1+d_p)/(2+d_p)})$ lower bound.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 19:04:12 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Tur\u011fay", "Eralp", ""], ["\u00d6ner", "Doruk", ""], ["Tekin", "Cem", ""]]}, {"id": "1803.04019", "submitter": "Yifeng Jiang", "authors": "Yifeng Jiang, Jiazheng Sun, C. Karen Liu", "title": "Data-Augmented Contact Model for Rigid Body Simulation", "comments": "7 pages, 7 figures. Submitted to ICRA 2019. Added video attachment\n  with full 3D experiments: https://youtu.be/AKSD8TabDV8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately modeling contact behaviors for real-world, near-rigid materials\nremains a grand challenge for existing rigid-body physics simulators. This\npaper introduces a data-augmented contact model that incorporates analytical\nsolutions with observed data to predict the 3D contact impulse which could\nresult in rigid bodies bouncing, sliding or spinning in all directions. Our\nmethod enhances the expressiveness of the standard Coulomb contact model by\nlearning the contact behaviors from the observed data, while preserving the\nfundamental contact constraints whenever possible. For example, a classifier is\ntrained to approximate the transitions between static and dynamic frictions,\nwhile non-penetration constraint during collision is enforced analytically. Our\nmethod computes the aggregated effect of contact for the entire rigid body,\ninstead of predicting the contact force for each contact point individually,\nremoving the exponential decline in accuracy as the number of contact points\nincreases.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 19:20:15 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 01:15:14 GMT"}, {"version": "v3", "created": "Sun, 23 Sep 2018 03:05:45 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Jiang", "Yifeng", ""], ["Sun", "Jiazheng", ""], ["Liu", "C. Karen", ""]]}, {"id": "1803.04035", "submitter": "Richard Nock", "authors": "Richard Nock and Stephen Hardy and Wilko Henecka and Hamish Ivey-Law\n  and Giorgio Patrini and Guillaume Smith and Brian Thorne", "title": "Entity Resolution and Federated Learning get a Federated Resolution", "comments": "arXiv admin note: text overlap with arXiv:1711.10677", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider two data providers, each maintaining records of different feature\nsets about common entities. They aim to learn a linear model over the whole set\nof features. This problem of federated learning over vertically partitioned\ndata includes a crucial upstream issue: entity resolution, i.e. finding the\ncorrespondence between the rows of the datasets. It is well known that entity\nresolution, just like learning, is mistake-prone in the real world. Despite the\nimportance of the problem, there has been no formal assessment of how errors in\nentity resolution impact learning.\n  In this paper, we provide a thorough answer to this question, answering how\noptimal classifiers, empirical losses, margins and generalisation abilities are\naffected. While our answer spans a wide set of losses --- going beyond proper,\nconvex, or classification calibrated ---, it brings simple practical arguments\nto upgrade entity resolution as a preprocessing step to learning. One of these\nsuggests that entity resolution should be aimed at controlling or minimizing\nthe number of matching errors between examples of distinct classes. In our\nexperiments, we modify a simple token-based entity resolution algorithm so that\nit indeed aims at avoiding matching rows belonging to different classes, and\nperform experiments in the setting where entity resolution relies on noisy\ndata, which is very relevant to real world domains. Notably, our approach\ncovers the case where one peer \\textit{does not} have classes, or a noisy\nrecord of classes. Experiments display that using the class information during\nentity resolution can buy significant uplift for learning at little expense\nfrom the complexity standpoint.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 20:53:18 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 21:46:12 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Nock", "Richard", ""], ["Hardy", "Stephen", ""], ["Henecka", "Wilko", ""], ["Ivey-Law", "Hamish", ""], ["Patrini", "Giorgio", ""], ["Smith", "Guillaume", ""], ["Thorne", "Brian", ""]]}, {"id": "1803.04037", "submitter": "Glib Kechyn", "authors": "Glib Kechyn, Lucius Yu, Yangguang Zang, Svyatoslav Kechyn", "title": "Sales forecasting using WaveNet within the framework of the Kaggle\n  competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We took part in the Corporacion Favorita Grocery Sales Forecasting\ncompetition hosted on Kaggle and achieved the 2nd place. In this abstract\npaper, we present an overall analysis and solution to the underlying\nmachine-learning problem based on time series data, where major challenges are\nidentified and corresponding preliminary methods are proposed. Our approach is\nbased on the adaptation of dilated convolutional neural network for time series\nforecasting. By applying this technique iteratively to batches of n examples, a\nbig amount of time series data can be eventually processed with a decent speed\nand accuracy. We hope this paper could serve, to some extent, as a review and\nguideline of the time series forecasting benchmark, inspiring further attempts\nand researches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 20:59:35 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kechyn", "Glib", ""], ["Yu", "Lucius", ""], ["Zang", "Yangguang", ""], ["Kechyn", "Svyatoslav", ""]]}, {"id": "1803.04039", "submitter": "Cem Tekin", "authors": "Doruk \\\"Oner and Altu\\u{g} Karakurt and Atilla Ery{\\i}lmaz and Cem\n  Tekin", "title": "Combinatorial Multi-Objective Multi-Armed Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the COmbinatorial Multi-Objective Multi-Armed\nBandit (COMO-MAB) problem that captures the challenges of combinatorial and\nmulti-objective online learning simultaneously. In this setting, the goal of\nthe learner is to choose an action at each time, whose reward vector is a\nlinear combination of the reward vectors of the arms in the action, to learn\nthe set of super Pareto optimal actions, which includes the Pareto optimal\nactions and actions that become Pareto optimal after adding an arbitrary small\npositive number to their expected reward vectors. We define the Pareto regret\nperformance metric and propose a fair learning algorithm whose Pareto regret is\n$O(N L^3 \\log T)$, where $T$ is the time horizon, $N$ is the number of arms and\n$L$ is the maximum number of arms in an action. We show that COMO-MAB has a\nwide range of applications, including recommending bundles of items to users\nand network routing, and focus on a resource-allocation application for\nmulti-user communication in the presence of multidimensional performance\nmetrics, where we show that our algorithm outperforms existing MAB algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 21:06:52 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["\u00d6ner", "Doruk", ""], ["Karakurt", "Altu\u011f", ""], ["Ery\u0131lmaz", "Atilla", ""], ["Tekin", "Cem", ""]]}, {"id": "1803.04042", "submitter": "Kai Xu", "authors": "Kai Xu, Dae Hoon Park, Chang Yi and Charles Sutton", "title": "Interpreting Deep Classifier by Visual Distillation of Dark Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting black box classifiers, such as deep networks, allows an analyst\nto validate a classifier before it is deployed in a high-stakes setting. A\nnatural idea is to visualize the deep network's representations, so as to \"see\nwhat the network sees\". In this paper, we demonstrate that standard dimension\nreduction methods in this setting can yield uninformative or even misleading\nvisualizations. Instead, we present DarkSight, which visually summarizes the\npredictions of a classifier in a way inspired by notion of dark knowledge.\nDarkSight embeds the data points into a low-dimensional space such that it is\neasy to compress the deep classifier into a simpler one, essentially combining\nmodel compression and dimension reduction. We compare DarkSight against t-SNE\nboth qualitatively and quantitatively, demonstrating that DarkSight\nvisualizations are more informative. Our method additionally yields a new\nconfidence measure based on dark knowledge by quantifying how unusual a given\nvector of predictions is.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 21:17:05 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Xu", "Kai", ""], ["Park", "Dae Hoon", ""], ["Yi", "Chang", ""], ["Sutton", "Charles", ""]]}, {"id": "1803.04051", "submitter": "Rakshit Trivedi", "authors": "Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, Hongyuan Zha", "title": "Representation Learning over Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we effectively encode evolving information over dynamic graphs into\nlow-dimensional representations? In this paper, we propose DyRep, an inductive\ndeep representation learning framework that learns a set of functions to\nefficiently produce low-dimensional node embeddings that evolves over time. The\nlearned embeddings drive the dynamics of two key processes namely,\ncommunication and association between nodes in dynamic graphs. These processes\nexhibit complex nonlinear dynamics that evolve at different time scales and\nsubsequently contribute to the update of node embeddings. We employ a\ntime-scale dependent multivariate point process model to capture these\ndynamics. We devise an efficient unsupervised learning procedure and\ndemonstrate that our approach significantly outperforms representative\nbaselines on two real-world datasets for the problem of dynamic link prediction\nand event time prediction.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 22:00:33 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 19:27:29 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Trivedi", "Rakshit", ""], ["Farajtabar", "Mehrdad", ""], ["Biswal", "Prasenjeet", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1803.04062", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "Pseudo-task Augmentation: From Deep Multitask Learning to Intratask\n  Sharing---and Back", "comments": "Published as a conference paper at ICML 2018; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multitask learning boosts performance by sharing learned structure\nacross related tasks. This paper adapts ideas from deep multitask learning to\nthe setting where only a single task is available. The method is formalized as\npseudo-task augmentation, in which models are trained with multiple decoders\nfor each task. Pseudo-tasks simulate the effect of training towards\nclosely-related tasks drawn from the same universe. In a suite of experiments,\npseudo-task augmentation is shown to improve performance on single-task\nlearning problems. When combined with multitask learning, further improvements\nare achieved, including state-of-the-art performance on the CelebA dataset,\nshowing that pseudo-task augmentation and multitask learning have complementary\nvalue. All in all, pseudo-task augmentation is a broadly applicable and\nefficient way to boost performance in deep learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 23:06:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:28:34 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.04084", "submitter": "Yun-Jhong Wu", "authors": "Yun-Jhong Wu, Elizaveta Levina, Ji Zhu", "title": "Link prediction for egocentrically sampled networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in networks is typically accomplished by estimating or\nranking the probabilities of edges for all pairs of nodes. In practice,\nespecially for social networks, the data are often collected by egocentric\nsampling, which means selecting a subset of nodes and recording all of their\nedges. This sampling mechanism requires different prediction tools than the\ntypical assumption of links missing at random. We propose a new computationally\nefficient link prediction algorithm for egocentrically sampled networks, which\nestimates the underlying probability matrix by estimating its row space. For\nnetworks created by sampling rows, our method outperforms many popular link\nprediction and graphon estimation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 01:37:53 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Wu", "Yun-Jhong", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1803.04087", "submitter": "Adarsh Barik", "authors": "Adarsh Barik, Jean Honorio", "title": "Learning discrete Bayesian networks in polynomial time and sample\n  complexity", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of structure learning for Bayesian\nnetworks in which nodes take discrete values. The problem is NP-hard in general\nbut we show that under certain conditions we can recover the true structure of\na Bayesian network with sufficient number of samples. We develop a mathematical\nmodel which does not assume any specific conditional probability distributions\nfor the nodes. We use a primal-dual witness construction to prove that, under\nsome technical conditions on the interaction between node pairs, we can do\nexact recovery of the parents and children of a node by performing group\nl_12-regularized multivariate regression. Thus, we recover the true Bayesian\nnetwork structure. If degree of a node is bounded then the sample complexity of\nour proposed approach grows logarithmically with respect to the number of nodes\nin the Bayesian network. Furthermore, our method runs in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 01:49:39 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 04:30:05 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 20:58:55 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "1803.04186", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Alireza M. Javid, and Saikat Chatterjee", "title": "R3Net: Random Weights, Rectifier Linear Units and Robustness for\n  Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a neural network architecture with randomized features, a\nsign-splitter, followed by rectified linear units (ReLU). We prove that our\narchitecture exhibits robustness to the input perturbation: the output feature\nof the neural network exhibits a Lipschitz continuity in terms of the input\nperturbation. We further show that the network output exhibits a discrimination\nability that inputs that are not arbitrarily close generate output vectors\nwhich maintain distance between each other obeying a certain lower bound. This\nensures that two different inputs remain discriminable while contracting the\ndistance in the output feature space.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:04:17 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Javid", "Alireza M.", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1803.04189", "submitter": "Samuli Laine", "authors": "Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero\n  Karras, Miika Aittala, Timo Aila", "title": "Noise2Noise: Learning Image Restoration without Clean Data", "comments": "Added link to official implementation and updated MRI results to\n  match it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply basic statistical reasoning to signal reconstruction by machine\nlearning -- learning to map corrupted observations to clean signals -- with a\nsimple and powerful conclusion: it is possible to learn to restore images by\nonly looking at corrupted examples, at performance at and sometimes exceeding\ntraining using clean data, without explicit image priors or likelihood models\nof the corruption. In practice, we show that a single model learns photographic\nnoise removal, denoising synthetic Monte Carlo images, and reconstruction of\nundersampled MRI scans -- all corrupted by different processes -- based on\nnoisy data only.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:07:58 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 12:08:44 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 10:29:23 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lehtinen", "Jaakko", ""], ["Munkberg", "Jacob", ""], ["Hasselgren", "Jon", ""], ["Laine", "Samuli", ""], ["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Aila", "Timo", ""]]}, {"id": "1803.04193", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Extreme Learning Machine for Graph Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we improve extreme learning machines for regression tasks\nusing a graph signal processing based regularization. We assume that the target\nsignal for prediction or regression is a graph signal. With this assumption, we\nuse the regularization to enforce that the output of an extreme learning\nmachine is smooth over a given graph. Simulation results with real data confirm\nthat such regularization helps significantly when the available training data\nis limited in size and corrupted by noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:12:48 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.04196", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Multi-kernel Regression For Graph Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a multi-kernel based regression method for graph signal processing\nwhere the target signal is assumed to be smooth over a graph. In multi-kernel\nregression, an effective kernel function is expressed as a linear combination\nof many basis kernel functions. We estimate the linear weights to learn the\neffective kernel function by appropriate regularization based on graph\nsmoothness. We show that the resulting optimization problem is shown to be\nconvex and pro- pose an accelerated projected gradient descent based solution.\nSimulation results using real-world graph signals show efficiency of the\nmulti-kernel based approach over a standard kernel based approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:20:07 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.04204", "submitter": "Akshay Krishnamurthy", "authors": "Akshay Krishnamurthy, Zhiwei Steven Wu, Vasilis Syrgkanis", "title": "Semiparametric Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies semiparametric contextual bandits, a generalization of the\nlinear stochastic bandit problem where the reward for an action is modeled as a\nlinear function of known action features confounded by an non-linear\naction-independent term. We design new algorithms that achieve\n$\\tilde{O}(d\\sqrt{T})$ regret over $T$ rounds, when the linear function is\n$d$-dimensional, which matches the best known bounds for the simpler\nunconfounded case and improves on a recent result of Greenewald et al. (2017).\nVia an empirical evaluation, we show that our algorithms outperform prior\napproaches when there are non-linear confounding effects on the rewards.\nTechnically, our algorithms use a new reward estimator inspired by\ndoubly-robust approaches and our proofs require new concentration inequalities\nfor self-normalized martingales.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:39:20 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 11:04:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Wu", "Zhiwei Steven", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1803.04209", "submitter": "Michael Teng", "authors": "Michael Teng and Frank Wood", "title": "High Throughput Synchronous Distributed Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, high-throughput, synchronous, distributed, data-parallel,\nstochastic-gradient-descent learning algorithm. This algorithm uses amortized\ninference in a compute-cluster-specific, deep, generative, dynamical model to\nperform joint posterior predictive inference of the mini-batch gradient\ncomputation times of all worker-nodes in a parallel computing cluster. We show\nthat a synchronous parameter server can, by utilizing such a model, choose an\noptimal cutoff time beyond which mini-batch gradient messages from slow workers\nare ignored that maximizes overall mini-batch gradient computations per second.\nIn keeping with earlier findings we observe that, under realistic conditions,\neagerly discarding the mini-batch gradient computations of stragglers not only\nincreases throughput but actually increases the overall rate of convergence as\na function of wall-clock time by virtue of eliminating idleness. The principal\nnovel contribution and finding of this work goes beyond this by demonstrating\nthat using the predicted run-times from a generative model of cluster worker\nperformance to dynamically adjust the cutoff improves substantially over the\nstatic-cutoff prior art, leading to, among other things, significantly reduced\ndeep neural net training times on large computer clusters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 11:51:38 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Teng", "Michael", ""], ["Wood", "Frank", ""]]}, {"id": "1803.04223", "submitter": "Jie Yang", "authors": "Jie Yang, Thomas Drake, Andreas Damianou, Yoelle Maarek", "title": "Leveraging Crowdsourcing Data For Deep Active Learning - An Application:\n  Learning Intents in Alexa", "comments": null, "journal-ref": null, "doi": "10.1145/3178876.3186033", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a generic Bayesian framework that enables any deep\nlearning model to actively learn from targeted crowds. Our framework inherits\nfrom recent advances in Bayesian deep learning, and extends existing work by\nconsidering the targeted crowdsourcing approach, where multiple annotators with\nunknown expertise contribute an uncontrolled amount (often limited) of\nannotations. Our framework leverages the low-rank structure in annotations to\nlearn individual annotator expertise, which then helps to infer the true labels\nfrom noisy and sparse annotations. It provides a unified Bayesian model to\nsimultaneously infer the true labels and train the deep learning model in order\nto reach an optimal learning efficacy. Finally, our framework exploits the\nuncertainty of the deep learning model during prediction as well as the\nannotators' estimated expertise to minimize the number of required annotations\nand annotators for optimally training the deep learning model.\n  We evaluate the effectiveness of our framework for intent classification in\nAlexa (Amazon's personal assistant), using both synthetic and real-world\ndatasets. Experiments show that our framework can accurately learn annotator\nexpertise, infer true labels, and effectively reduce the amount of annotations\nin model training as compared to state-of-the-art approaches. We further\ndiscuss the potential of our proposed framework in bridging machine learning\nand crowdsourcing towards improved human-in-the-loop systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 12:43:41 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Yang", "Jie", ""], ["Drake", "Thomas", ""], ["Damianou", "Andreas", ""], ["Maarek", "Yoelle", ""]]}, {"id": "1803.04239", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "FeTa: A DCA Pruning Algorithm with Generalization Error Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent DNN pruning algorithms have succeeded in reducing the number of\nparameters in fully connected layers, often with little or no drop in\nclassification accuracy. However, most of the existing pruning schemes either\nhave to be applied during training or require a costly retraining procedure\nafter pruning to regain classification accuracy. We start by proposing a cheap\npruning algorithm for fully connected DNN layers based on difference of convex\nfunctions (DC) optimisation, that requires little or no retraining. We then\nprovide a theoretical analysis for the growth in the Generalization Error (GE)\nof a DNN for the case of bounded perturbations to the hidden layers, of which\nweight pruning is a special case. Our pruning method is orders of magnitude\nfaster than competing approaches, while our theoretical analysis sheds light to\npreviously observed problems in DNN pruning. Experiments on commnon feedforward\nneural networks validate our results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 13:19:33 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1803.04262", "submitter": "Marco Valtorta", "authors": "Mohammad Ali Javidian and Marco Valtorta", "title": "On the Properties of MVR Chain Graphs", "comments": "Extended version of a paper submitted to a conference. arXiv admin\n  note: text overlap with arXiv:0906.2098 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depending on the interpretation of the type of edges, a chain graph can\nrepresent different relations between variables and thereby independence\nmodels. Three interpretations, known by the acronyms LWF, MVR, and AMP, are\nprevalent. Multivariate regression chain graphs (MVR CGs) were introduced by\nCox and Wermuth in 1993. We review Markov properties for MVR chain graphs and\npropose an alternative global and local Markov property for them. Except for\npairwise Markov properties, we show that for MVR chain graphs all Markov\nproperties in the literature are equivalent for semi-graphoids. We derive a new\nfactorization formula for MVR chain graphs which is more explicit than and\ndifferent from the proposed factorizations for MVR chain graphs in the\nliterature. Finally, we provide a summary table comparing different features of\nLWF, AMP, and MVR chain graphs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 00:39:19 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 00:11:45 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 19:13:29 GMT"}, {"version": "v4", "created": "Tue, 24 Apr 2018 22:26:02 GMT"}, {"version": "v5", "created": "Wed, 18 Jul 2018 19:50:09 GMT"}, {"version": "v6", "created": "Wed, 1 Aug 2018 19:05:16 GMT"}, {"version": "v7", "created": "Mon, 11 Feb 2019 22:01:36 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""]]}, {"id": "1803.04271", "submitter": "Charis Lanaras", "authors": "Charis Lanaras, Jos\\'e Bioucas-Dias, Silvano Galliani, Emmanuel\n  Baltsavias, Konrad Schindler", "title": "Super-resolution of Sentinel-2 images: Learning a globally applicable\n  deep neural network", "comments": "19 pages, 11 figures", "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing, 146 (2018),\n  pp. 305-319", "doi": "10.1016/j.isprsjprs.2018.09.018", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Sentinel-2 satellite mission delivers multi-spectral imagery with 13\nspectral bands, acquired at three different spatial resolutions. The aim of\nthis research is to super-resolve the lower-resolution (20 m and 60 m Ground\nSampling Distance - GSD) bands to 10 m GSD, so as to obtain a complete data\ncube at the maximal sensor resolution. We employ a state-of-the-art\nconvolutional neural network (CNN) to perform end-to-end upsampling, which is\ntrained with data at lower resolution, i.e., from 40->20 m, respectively\n360->60 m GSD. In this way, one has access to a virtually infinite amount of\ntraining data, by downsampling real Sentinel-2 images. We use data sampled\nglobally over a wide range of geographical locations, to obtain a network that\ngeneralises across different climate zones and land-cover types, and can\nsuper-resolve arbitrary Sentinel-2 images without the need of retraining. In\nquantitative evaluations (at lower scale, where ground truth is available), our\nnetwork, which we call DSen2, outperforms the best competing approach by almost\n50% in RMSE, while better preserving the spectral characteristics. It also\ndelivers visually convincing results at the full 10 m GSD. The code is\navailable at https://github.com/lanha/DSen2\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 14:15:07 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 15:54:43 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Lanaras", "Charis", ""], ["Bioucas-Dias", "Jos\u00e9", ""], ["Galliani", "Silvano", ""], ["Baltsavias", "Emmanuel", ""], ["Schindler", "Konrad", ""]]}, {"id": "1803.04300", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Christian Bauckhage, Kristian Kersting", "title": "Neural Conditional Gradients", "comments": "arXiv admin note: text overlap with arXiv:1610.05120 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The move from hand-designed to learned optimizers in machine learning has\nbeen quite successful for gradient-based and -free optimizers. When facing a\nconstrained problem, however, maintaining feasibility typically requires a\nprojection step, which might be computationally expensive and not\ndifferentiable. We show how the design of projection-free convex optimization\nalgorithms can be cast as a learning problem based on Frank-Wolfe Networks:\nrecurrent networks implementing the Frank-Wolfe algorithm aka. conditional\ngradients. This allows them to learn to exploit structure when, e.g.,\noptimizing over rank-1 matrices. Our LSTM-learned optimizers outperform\nhand-designed as well learned but unconstrained ones. We demonstrate this for\ntraining support vector machines and softmax classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:10:45 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 08:41:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Schramowski", "Patrick", ""], ["Bauckhage", "Christian", ""], ["Kersting", "Kristian", ""]]}, {"id": "1803.04304", "submitter": "Ankit Singh Rawat", "authors": "Arya Mazumdar, Ankit Singh Rawat", "title": "Representation Learning and Recovery in the ReLU Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified linear units, or ReLUs, have become the preferred activation\nfunction for artificial neural networks. In this paper we consider two basic\nlearning problems assuming that the underlying data follow a generative model\nbased on a ReLU-network -- a neural network with ReLU activations. As a\nprimarily theoretical study, we limit ourselves to a single-layer network. The\nfirst problem we study corresponds to dictionary-learning in the presence of\nnonlinearity (modeled by the ReLU functions). Given a set of observation\nvectors $\\mathbf{y}^i \\in \\mathbb{R}^d, i =1, 2, \\dots , n$, we aim to recover\n$d\\times k$ matrix $A$ and the latent vectors $\\{\\mathbf{c}^i\\} \\subset\n\\mathbb{R}^k$ under the model $\\mathbf{y}^i = \\mathrm{ReLU}(A\\mathbf{c}^i\n+\\mathbf{b})$, where $\\mathbf{b}\\in \\mathbb{R}^d$ is a random bias. We show\nthat it is possible to recover the column space of $A$ within an error of\n$O(d)$ (in Frobenius norm) under certain conditions on the probability\ndistribution of $\\mathbf{b}$.\n  The second problem we consider is that of robust recovery of the signal in\nthe presence of outliers, i.e., large but sparse noise. In this setting we are\ninterested in recovering the latent vector $\\mathbf{c}$ from its noisy\nnonlinear sketches of the form $\\mathbf{v} = \\mathrm{ReLU}(A\\mathbf{c}) +\n\\mathbf{e}+\\mathbf{w}$, where $\\mathbf{e} \\in \\mathbb{R}^d$ denotes the\noutliers with sparsity $s$ and $\\mathbf{w} \\in \\mathbb{R}^d$ denote the dense\nbut small noise. This line of work has recently been studied (Soltanolkotabi,\n2017) without the presence of outliers. For this problem, we show that a\ngeneralized LASSO algorithm is able to recover the signal $\\mathbf{c} \\in\n\\mathbb{R}^k$ within an $\\ell_2$ error of $O(\\sqrt{\\frac{(k+s)\\log d}{d}})$\nwhen $A$ is a random Gaussian matrix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:17:14 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Mazumdar", "Arya", ""], ["Rawat", "Ankit Singh", ""]]}, {"id": "1803.04307", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Vitaly Feldman, Saharon Rosset, and Nathan Srebro", "title": "The Everlasting Database: Statistical Validity at a Fair Price", "comments": "22 pages, accepted to NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of handling adaptivity in data analysis, intentional or not,\npermeates a variety of fields, including test-set overfitting in ML challenges\nand the accumulation of invalid scientific discoveries. We propose a mechanism\nfor answering an arbitrarily long sequence of potentially adaptive statistical\nqueries, by charging a price for each query and using the proceeds to collect\nadditional samples. Crucially, we guarantee statistical validity without any\nassumptions on how the queries are generated. We also ensure with high\nprobability that the cost for $M$ non-adaptive queries is $O(\\log M)$, while\nthe cost to a potentially adaptive user who makes $M$ queries that do not\ndepend on any others is $O(\\sqrt{M})$.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:22:55 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 15:49:00 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 15:29:05 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Woodworth", "Blake", ""], ["Feldman", "Vitaly", ""], ["Rosset", "Saharon", ""], ["Srebro", "Nathan", ""]]}, {"id": "1803.04311", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang, Paul Patras, Hamed Haddadi", "title": "Deep Learning in Mobile and Wireless Networking: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid uptake of mobile devices and the rising popularity of mobile\napplications and services pose unprecedented demands on mobile and wireless\nnetworking infrastructure. Upcoming 5G systems are evolving to support\nexploding mobile traffic volumes, agile management of network resource to\nmaximize user experience, and extraction of fine-grained real-time analytics.\nFulfilling these tasks is challenging, as mobile environments are increasingly\ncomplex, heterogeneous, and evolving. One potential solution is to resort to\nadvanced machine learning techniques to help managing the rise in data volumes\nand algorithm-driven applications. The recent success of deep learning\nunderpins new and powerful tools that tackle problems in this space.\n  In this paper we bridge the gap between deep learning and mobile and wireless\nnetworking research, by presenting a comprehensive survey of the crossovers\nbetween the two areas. We first briefly introduce essential background and\nstate-of-the-art in deep learning techniques with potential applications to\nnetworking. We then discuss several techniques and platforms that facilitate\nthe efficient deployment of deep learning onto mobile systems. Subsequently, we\nprovide an encyclopedic review of mobile and wireless networking research based\non deep learning, which we categorize by different domains. Drawing from our\nexperience, we discuss how to tailor deep learning to mobile environments. We\ncomplete this survey by pinpointing current challenges and open future\ndirections for research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 15:30:04 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 16:08:08 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 12:54:32 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Patras", "Paul", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1803.04357", "submitter": "Cem Subakan", "authors": "Cem Subakan, Oluwasanmi Koyejo, Paris Smaragdis", "title": "Learning the Base Distribution in Implicit Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular generative model learning methods such as Generative Adversarial\nNetworks (GANs), and Variational Autoencoders (VAE) enforce the latent\nrepresentation to follow simple distributions such as isotropic Gaussian. In\nthis paper, we argue that learning a complicated distribution over the latent\nspace of an auto-encoder enables more accurate modeling of complicated data\ndistributions. Based on this observation, we propose a two stage optimization\nprocedure which maximizes an approximate implicit density model. We\nexperimentally verify that our method outperforms GANs and VAEs on two image\ndatasets (MNIST, CELEB-A). We also show that our approach is amenable to\nlearning generative model for sequential data, by learning to generate speech\nand music.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:24:33 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 22:40:35 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Subakan", "Cem", ""], ["Koyejo", "Oluwasanmi", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1803.04371", "submitter": "Junhong Lin", "authors": "Junhong Lin and Volkan Cevher", "title": "Optimal Rates of Sketched-regularized Algorithms for Least-Squares\n  Regression over Hilbert Spaces", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate regularized algorithms combining with projection for\nleast-squares regression problem over a Hilbert space, covering nonparametric\nregression over a reproducing kernel Hilbert space. We prove convergence\nresults with respect to variants of norms, under a capacity assumption on the\nhypothesis space and a regularity condition on the target function. As a\nresult, we obtain optimal rates for regularized algorithms with randomized\nsketches, provided that the sketch dimension is proportional to the effective\ndimension up to a logarithmic factor. As a byproduct, we obtain similar results\nfor Nystr\\\"{o}m regularized algorithms. Our results are the first ones with\noptimal, distribution-dependent rates that do not have any saturation effect\nfor sketched/Nystr\\\"{o}m regularized algorithms, considering both the\nattainable and non-attainable cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:57:48 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 15:14:52 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Lin", "Junhong", ""], ["Cevher", "Volkan", ""]]}, {"id": "1803.04383", "submitter": "Lydia T. Liu", "authors": "Lydia T. Liu, Sarah Dean, Esther Rolf, Max Simchowitz, Moritz Hardt", "title": "Delayed Impact of Fair Machine Learning", "comments": "37 pages, 6 figures", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:3150-3158, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in machine learning has predominantly been studied in static\nclassification settings without concern for how decisions change the underlying\npopulation over time. Conventional wisdom suggests that fairness criteria\npromote the long-term well-being of those groups they aim to protect.\n  We study how static fairness criteria interact with temporal indicators of\nwell-being, such as long-term improvement, stagnation, and decline in a\nvariable of interest. We demonstrate that even in a one-step feedback model,\ncommon fairness criteria in general do not promote improvement over time, and\nmay in fact cause harm in cases where an unconstrained objective would not.\n  We completely characterize the delayed impact of three standard criteria,\ncontrasting the regimes in which these exhibit qualitatively different\nbehavior. In addition, we find that a natural form of measurement error\nbroadens the regime in which fairness criteria perform favorably.\n  Our results highlight the importance of measurement and temporal modeling in\nthe evaluation of fairness criteria, suggesting a range of new challenges and\ntrade-offs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 17:20:56 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 20:34:16 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Liu", "Lydia T.", ""], ["Dean", "Sarah", ""], ["Rolf", "Esther", ""], ["Simchowitz", "Max", ""], ["Hardt", "Moritz", ""]]}, {"id": "1803.04386", "submitter": "Paul Vicol", "authors": "Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Tran, Roger Grosse", "title": "Flipout: Efficient Pseudo-Independent Weight Perturbations on\n  Mini-Batches", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic neural net weights are used in a variety of contexts, including\nregularization, Bayesian neural nets, exploration in reinforcement learning,\nand evolution strategies. Unfortunately, due to the large number of weights,\nall the examples in a mini-batch typically share the same weight perturbation,\nthereby limiting the variance reduction effect of large mini-batches. We\nintroduce flipout, an efficient method for decorrelating the gradients within a\nmini-batch by implicitly sampling pseudo-independent weight perturbations for\neach example. Empirically, flipout achieves the ideal linear variance reduction\nfor fully connected networks, convolutional networks, and RNNs. We find\nsignificant speedups in training neural networks with multiplicative Gaussian\nperturbations. We show that flipout is effective at regularizing LSTMs, and\noutperforms previous methods. Flipout also enables us to vectorize evolution\nstrategies: in our experiments, a single GPU with flipout can handle the same\nthroughput as at least 40 CPU cores using existing methods, equivalent to a\nfactor-of-4 cost reduction on Amazon Web Services.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 17:25:21 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 17:56:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Wen", "Yeming", ""], ["Vicol", "Paul", ""], ["Ba", "Jimmy", ""], ["Tran", "Dustin", ""], ["Grosse", "Roger", ""]]}, {"id": "1803.04431", "submitter": "Zilong Tan", "authors": "Zilong Tan, Kimberly Roche, Xiang Zhou, Sayan Mukherjee", "title": "Scalable Algorithms for Learning High-Dimensional Linear Mixed Models", "comments": null, "journal-ref": "Proceedings of the Thirty Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed models (LMMs) are used extensively to model dependecies of\nobservations in linear regression and are used extensively in many application\nareas. Parameter estimation for LMMs can be computationally prohibitive on big\ndata. State-of-the-art learning algorithms require computational complexity\nwhich depends at least linearly on the dimension $p$ of the covariates, and\noften use heuristics that do not offer theoretical guarantees. We present\nscalable algorithms for learning high-dimensional LMMs with sublinear\ncomputational complexity dependence on $p$. Key to our approach are novel dual\nestimators which use only kernel functions of the data, and fast computational\ntechniques based on the subsampled randomized Hadamard transform. We provide\ntheoretical guarantees for our learning algorithms, demonstrating the\nrobustness of parameter estimation. Finally, we complement the theory with\nexperiments on large synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:07:40 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Tan", "Zilong", ""], ["Roche", "Kimberly", ""], ["Zhou", "Xiang", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1803.04439", "submitter": "Aditya Rawal", "authors": "Aditya Rawal and Risto Miikkulainen", "title": "From Nodes to Networks: Evolving Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated recurrent networks such as those composed of Long Short-Term Memory\n(LSTM) nodes have recently been used to improve state of the art in many\nsequential processing tasks such as speech recognition and machine translation.\nHowever, the basic structure of the LSTM node is essentially the same as when\nit was first conceived 25 years ago. Recently, evolutionary and reinforcement\nlearning mechanisms have been employed to create new variations of this\nstructure. This paper proposes a new method, evolution of a tree-based encoding\nof the gated memory nodes, and shows that it makes it possible to explore new\nvariations more effectively than other methods. The method discovers nodes with\nmultiple recurrent paths and multiple memory cells, which lead to significant\nimprovement in the standard language modeling benchmark task. The paper also\nshows how the search process can be speeded up by training an LSTM network to\nestimate performance of candidate structures, and by encouraging exploration of\nnovel solutions. Thus, evolutionary design of complex neural network structures\npromises to improve performance of deep learning architectures beyond human\nability to do so.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:24:07 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 21:41:18 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Rawal", "Aditya", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.04459", "submitter": "Rayyan Ahmad Khan", "authors": "Rayyan Ahmad Khan, Rana Ali Amjad, Martin Kleinsteuber", "title": "Extended Affinity Propagation: Global Discovery and Local Insights", "comments": "Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new clustering algorithm, Extended Affinity Propagation, based\non pairwise similarities. Extended Affinity Propagation is developed by\nmodifying Affinity Propagation such that the desirable features of Affinity\nPropagation, e.g., exemplars, reasonable computational complexity and no need\nto specify number of clusters, are preserved while the shortcomings, e.g., the\nlack of global structure discovery, that limit the applicability of Affinity\nPropagation are overcome. Extended Affinity Propagation succeeds not only in\nachieving this goal but can also provide various additional insights into the\ninternal structure of the individual clusters, e.g., refined confidence values,\nrelative cluster densities and local cluster strength in different regions of a\ncluster, which are valuable for an analyst. We briefly discuss how these\ninsights can help in easily tuning the hyperparameters. We also illustrate\nthese desirable features and the performance of Extended Affinity Propagation\non various synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:56:38 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 18:43:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Khan", "Rayyan Ahmad", ""], ["Amjad", "Rana Ali", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1803.04464", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Hamid Javadi", "title": "False Discovery Rate Control via Debiased Lasso", "comments": "accepted for publication in the Electronic Journal of statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of variable selection in high-dimensional statistical\nmodels where the goal is to report a set of variables, out of many predictors\n$X_1, \\dotsc, X_p$, that are relevant to a response of interest. For linear\nhigh-dimensional model, where the number of parameters exceeds the number of\nsamples $(p>n)$, we propose a procedure for variables selection and prove that\nit controls the \"directional\" false discovery rate (FDR) below a pre-assigned\nsignificance level $q\\in [0,1]$. We further analyze the statistical power of\nour framework and show that for designs with subgaussian rows and a common\nprecision matrix $\\Omega\\in\\mathbb{R}^{p\\times p}$, if the minimum nonzero\nparameter $\\theta_{\\min}$ satisfies $$\\sqrt{n} \\theta_{\\min} - \\sigma\n\\sqrt{2(\\max_{i\\in [p]}\\Omega_{ii})\\log\\left(\\frac{2p}{qs_0}\\right)} \\to\n\\infty\\,,$$ then this procedure achieves asymptotic power one. Our framework is\nbuilt upon the debiasing approach and assumes the standard condition $s_0 =\no(\\sqrt{n}/(\\log p)^2)$, where $s_0$ indicates the number of true positives\namong the $p$ features. Notably, this framework achieves exact directional FDR\ncontrol without any assumption on the amplitude of unknown regression\nparameters, and does not require any knowledge of the distribution of\ncovariates or the noise level. We test our method in synthetic and real data\nexperiments to assess its performance and to corroborate our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:03:33 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 06:14:48 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Javanmard", "Adel", ""], ["Javadi", "Hamid", ""]]}, {"id": "1803.04465", "submitter": "Evan N. Feinberg", "authors": "Evan N. Feinberg, Debnil Sur, Zhenqin Wu, Brooke E. Husic, Huanghao\n  Mai, Yang Li, Saisai Sun, Jianyi Yang, Bharath Ramsundar, and Vijay S. Pande", "title": "PotentialNet for Molecular Property Prediction", "comments": "13 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arc of drug discovery entails a multiparameter optimization problem\nspanning vast length scales. They key parameters range from solubility\n(angstroms) to protein-ligand binding (nanometers) to in vivo toxicity\n(meters). Through feature learning---instead of feature engineering---deep\nneural networks promise to outperform both traditional physics-based and\nknowledge-based machine learning models for predicting molecular properties\npertinent to drug discovery. To this end, we present the PotentialNet family of\ngraph convolutions. These models are specifically designed for and achieve\nstate-of-the-art performance for protein-ligand binding affinity. We further\nvalidate these deep neural networks by setting new standards of performance in\nseveral ligand-based tasks. In parallel, we introduce a new metric, the\nRegression Enrichment Factor $EF_\\chi^{(R)}$, to measure the early enrichment\nof computational models for chemical data. Finally, we introduce a\ncross-validation strategy based on structural homology clustering that can more\naccurately measure model generalizability, which crucially distinguishes the\naims of machine learning for drug discovery from standard machine learning\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:06:03 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 19:20:13 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Feinberg", "Evan N.", ""], ["Sur", "Debnil", ""], ["Wu", "Zhenqin", ""], ["Husic", "Brooke E.", ""], ["Mai", "Huanghao", ""], ["Li", "Yang", ""], ["Sun", "Saisai", ""], ["Yang", "Jianyi", ""], ["Ramsundar", "Bharath", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.04475", "submitter": "Enrico Camporeale", "authors": "Enrico Camporeale", "title": "Accuracy-Reliability Cost Function for Empirical Variance Estimation", "comments": "under review for ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of assigning uncertainties to\nsingle-point predictions. We introduce a cost function that encodes the\ntrade-off between accuracy and reliability in probabilistic forecast. We derive\nanalytic formula for the case of forecasts of continuous scalar variables\nexpressed in terms of Gaussian distributions. The Accuracy-Reliability cost\nfunction can be used to empirically estimate the variance in heteroskedastic\nregression problems (input dependent noise), by solving a two-objective\noptimization problem. The simple philosophy behind this strategy is that\npredictions based on the estimated variances should be both accurate and\nreliable (i.e. statistical consistent with observations). We show several\nexamples with synthetic data, where the underlying hidden noise function can be\naccurately recovered, both in one and multi-dimensional problems. The practical\nimplementation of the method has been done using a Neural Network and, in the\none-dimensional case, with a simple polynomial fit.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:24:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Camporeale", "Enrico", ""]]}, {"id": "1803.04478", "submitter": "David Lattanzi", "authors": "Achyuthan Jootoo, David Lattanzi", "title": "Bridge type classification: supervised learning on a modified NBI\n  dataset", "comments": "Preprint of paper published in ASCE Journal of Computing\n  (https://ascelibrary.org/doi/full/10.1061/(ASCE)CP.1943-5487.0000712). 6\n  figures and 8 tables, provided at end of document", "journal-ref": "Journal of Computing in Civil Engineering 31.6 (2017): 04017063", "doi": "10.1061/(ASCE)CP.1943-5487.0000712", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key phase in the bridge design process is the selection of the structural\nsystem. Due to budget and time constraints, engineers typically rely on\nengineering judgment and prior experience when selecting a structural system,\noften considering a limited range of design alternatives. The objective of this\nstudy was to explore the suitability of supervised machine learning as a\npreliminary design aid that provides guidance to engineers with regards to the\nstatistically optimal bridge type to choose, ultimately improving the\nlikelihood of optimized design, design standardization, and reduced maintenance\ncosts. In order to devise this supervised learning system, data for over\n600,000 bridges from the National Bridge Inventory database were analyzed. Key\nattributes for determining the bridge structure type were identified through\nthree feature selection techniques. Potentially useful attributes like seismic\nintensity and historic data on the cost of materials (steel and concrete) were\nthen added from the US Geological Survey (USGS) database and Engineering News\nRecord. Decision tree, Bayes network and Support Vector Machines were used for\npredicting the bridge design type. Due to state-to-state variations in material\navailability, material costs, and design codes, supervised learning models\nbased on the complete data set did not yield favorable results. Supervised\nlearning models were then trained and tested using 10-fold cross validation on\ndata for each state. Inclusion of seismic data improved the model performance\nnoticeably. The data was then resampled to reduce the bias of the models\ntowards more common design types, and the supervised learning models thus\nconstructed showed further improvements in performance. The average recall and\nprecision for the state models was 88.6% and 88.0% using Decision Trees, 84.0%\nand 83.7% using Bayesian Networks, and 80.8% and 75.6% using SVM.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 16:33:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Jootoo", "Achyuthan", ""], ["Lattanzi", "David", ""]]}, {"id": "1803.04489", "submitter": "Sean Billings", "authors": "Sean Billings", "title": "Probabilistic and Regularized Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the recently proposed Graph Convolutional Network\narchitecture proposed in (Kipf & Welling, 2016) The key points of their work is\nsummarized and their results are reproduced. Graph regularization and\nalternative graph convolution approaches are explored. I find that explicit\ngraph regularization was correctly rejected by (Kipf & Welling, 2016). I\nattempt to improve the performance of GCN by approximating a k-step transition\nmatrix in place of the normalized graph laplacian, but I fail to find positive\nresults. Nonetheless, the performance of several configurations of this GCN\nvariation is shown for the Cora, Citeseer, and Pubmed datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:47:16 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Billings", "Sean", ""]]}, {"id": "1803.04494", "submitter": "Sean Billings", "authors": "Sean Billings", "title": "Gradient Augmented Information Retrieval with Autoencoders and Semantic\n  Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will explore the use of autoencoders for semantic hashing in the\ncontext of Information Retrieval. This paper will summarize how to efficiently\ntrain an autoencoder in order to create meaningful and low-dimensional\nencodings of data. This paper will demonstrate how computing and storing the\nclosest encodings to an input query can help speed up search time and improve\nthe quality of our search results. The novel contributions of this paper\ninvolve using the representation of the data learned by an auto-encoder in\norder to augment our search query in various ways. I present and evaluate the\nnew gradient search augmentation (GSA) approach, as well as the more well-known\npseudo-relevance-feedback (PRF) adjustment. I find that GSA helps to improve\nthe performance of the TF-IDF based information retrieval system, and PRF\ncombined with GSA works best overall for the systems compared in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:49:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Billings", "Sean", ""]]}, {"id": "1803.04497", "submitter": "Onur Ozdemir", "authors": "Jacob A. Harer, Louis Y. Kim, Rebecca L. Russell, Onur Ozdemir,\n  Leonard R. Kosta, Akshay Rangamani, Lei H. Hamilton, Gabriel I. Centeno,\n  Jonathan R. Key, Paul M. Ellingwood, Erik Antelman, Alan Mackay, Marc W.\n  McConley, Jeffrey M. Opper, Peter Chin, Tomo Lazovich", "title": "Automated software vulnerability detection with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thousands of security vulnerabilities are discovered in production software\neach year, either reported publicly to the Common Vulnerabilities and Exposures\ndatabase or discovered internally in proprietary code. Vulnerabilities often\nmanifest themselves in subtle ways that are not obvious to code reviewers or\nthe developers themselves. With the wealth of open source code available for\nanalysis, there is an opportunity to learn the patterns of bugs that can lead\nto security vulnerabilities directly from data. In this paper, we present a\ndata-driven approach to vulnerability detection using machine learning,\nspecifically applied to C and C++ programs. We first compile a large dataset of\nhundreds of thousands of open-source functions labeled with the outputs of a\nstatic analyzer. We then compare methods applied directly to source code with\nmethods applied to artifacts extracted from the build process, finding that\nsource-based models perform better. We also compare the application of deep\nneural network models with more traditional models such as random forests and\nfind the best performance comes from combining features learned by deep models\nwith tree-based models. Ultimately, our highest performing model achieves an\narea under the precision-recall curve of 0.49 and an area under the ROC curve\nof 0.87.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 13:00:05 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 13:27:12 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Harer", "Jacob A.", ""], ["Kim", "Louis Y.", ""], ["Russell", "Rebecca L.", ""], ["Ozdemir", "Onur", ""], ["Kosta", "Leonard R.", ""], ["Rangamani", "Akshay", ""], ["Hamilton", "Lei H.", ""], ["Centeno", "Gabriel I.", ""], ["Key", "Jonathan R.", ""], ["Ellingwood", "Paul M.", ""], ["Antelman", "Erik", ""], ["Mackay", "Alan", ""], ["McConley", "Marc W.", ""], ["Opper", "Jeffrey M.", ""], ["Chin", "Peter", ""], ["Lazovich", "Tomo", ""]]}, {"id": "1803.04566", "submitter": "Nicholas Waytowich", "authors": "Nicholas R. Waytowich, Vernon Lawhern, Javier O. Garcia, Jennifer\n  Cummings, Josef Faller, Paul Sajda, Jean M. Vettel", "title": "Compact Convolutional Neural Networks for Classification of Asynchronous\n  Steady-state Visual Evoked Potentials", "comments": "Accepted for publication at the Journal of Neural Engineering", "journal-ref": null, "doi": "10.1088/1741-2552/aae5d8", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-State Visual Evoked Potentials (SSVEPs) are neural oscillations from\nthe parietal and occipital regions of the brain that are evoked from flickering\nvisual stimuli. SSVEPs are robust signals measurable in the\nelectroencephalogram (EEG) and are commonly used in brain-computer interfaces\n(BCIs). However, methods for high-accuracy decoding of SSVEPs usually require\nhand-crafted approaches that leverage domain-specific knowledge of the stimulus\nsignals, such as specific temporal frequencies in the visual stimuli and their\nrelative spatial arrangement. When this knowledge is unavailable, such as when\nSSVEP signals are acquired asynchronously, such approaches tend to fail. In\nthis paper, we show how a compact convolutional neural network (Compact-CNN),\nwhich only requires raw EEG signals for automatic feature extraction, can be\nused to decode signals from a 12-class SSVEP dataset without the need for any\ndomain-specific knowledge or calibration data. We report across subject mean\naccuracy of approximately 80% (chance being 8.3%) and show this is\nsubstantially better than current state-of-the-art hand-crafted approaches\nusing canonical correlation analysis (CCA) and Combined-CCA. Furthermore, we\nanalyze our Compact-CNN to examine the underlying feature representation,\ndiscovering that the deep learner extracts additional phase and amplitude\nrelated features associated with the structure of the dataset. We discuss how\nour Compact-CNN shows promise for BCI applications that allow users to freely\ngaze/attend to any stimulus at any time (e.g., asynchronous BCI) as well as\nprovides a method for analyzing SSVEP signals in a way that might augment our\nunderstanding about the basic processing in the visual cortex.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:03:44 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 16:53:26 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Waytowich", "Nicholas R.", ""], ["Lawhern", "Vernon", ""], ["Garcia", "Javier O.", ""], ["Cummings", "Jennifer", ""], ["Faller", "Josef", ""], ["Sajda", "Paul", ""], ["Vettel", "Jean M.", ""]]}, {"id": "1803.04572", "submitter": "Ardavan Afshar", "authors": "Ardavan Afshar, Ioakeim Perros, Evangelos E. Papalexakis, Elizabeth\n  Searles, Joyce Ho, Jimeng Sun", "title": "COPA: Constrained PARAFAC2 for Sparse & Large Datasets", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PARAFAC2 has demonstrated success in modeling irregular tensors, where the\ntensor dimensions vary across one of the modes. An example scenario is modeling\ntreatments across a set of patients with the varying number of medical\nencounters over time. Despite recent improvements on unconstrained PARAFAC2,\nits model factors are usually dense and sensitive to noise which limits their\ninterpretability. As a result, the following open challenges remain: a) various\nmodeling constraints, such as temporal smoothness, sparsity and non-negativity,\nare needed to be imposed for interpretable temporal modeling and b) a scalable\napproach is required to support those constraints efficiently for large\ndatasets. To tackle these challenges, we propose a {\\it CO}nstrained {\\it\nPA}RAFAC2 (COPA) method, which carefully incorporates optimization constraints\nsuch as temporal smoothness, sparsity, and non-negativity in the resulting\nfactors. To efficiently support all those constraints, COPA adopts a hybrid\noptimization framework using alternating optimization and alternating direction\nmethod of multiplier (AO-ADMM). As evaluated on large electronic health record\n(EHR) datasets with hundreds of thousands of patients, COPA achieves\nsignificant speedups (up to 36 times faster) over prior PARAFAC2 approaches\nthat only attempt to handle a subset of the constraints that COPA enables.\nOverall, our method outperforms all the baselines attempting to handle a subset\nof the constraints in terms of speed, while achieving the same level of\naccuracy. Through a case study on temporal phenotyping of medically complex\nchildren, we demonstrate how the constraints imposed by COPA reveal concise\nphenotypes and meaningful temporal profiles of patients. The clinical\ninterpretation of both the phenotypes and the temporal profiles was confirmed\nby a medical expert.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:27:06 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 19:52:28 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Afshar", "Ardavan", ""], ["Perros", "Ioakeim", ""], ["Papalexakis", "Evangelos E.", ""], ["Searles", "Elizabeth", ""], ["Ho", "Joyce", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.04579", "submitter": "Ankur Taly", "authors": "Pramod Kaushik Mudrakarta, Ankur Taly, Mukund Sundararajan, Kedar\n  Dhamdhere", "title": "It was the training data pruning too!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the current best model (KDG) for question answering on tabular data\nevaluated over the WikiTableQuestions dataset. Previous ablation studies\nperformed against this model attributed the model's performance to certain\naspects of its architecture. In this paper, we find that the model's\nperformance also crucially depends on a certain pruning of the data used to\ntrain the model. Disabling the pruning step drops the accuracy of the model\nfrom 43.3% to 36.3%. The large impact on the performance of the KDG model\nsuggests that the pruning may be a useful pre-processing step in training other\nsemantic parsers as well.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 23:59:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Taly", "Ankur", ""], ["Sundararajan", "Mukund", ""], ["Dhamdhere", "Kedar", ""]]}, {"id": "1803.04623", "submitter": "Siwei Wang", "authors": "Siwei Wang, Wei Chen", "title": "Thompson Sampling for Combinatorial Semi-Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the application of the Thompson sampling (TS) methodology to the\nstochastic combinatorial multi-armed bandit (CMAB) framework. We analyze the\nstandard TS algorithm for the general CMAB, and obtain the first\ndistribution-dependent regret bound of $O(mK_{\\max}\\log T / \\Delta_{\\min})$,\nwhere $m$ is the number of arms, $K_{\\max}$ is the size of the largest super\narm, $T$ is the time horizon, and $\\Delta_{\\min}$ is the minimum gap between\nthe expected reward of the optimal solution and any non-optimal solution. We\nalso show that one cannot directly replace the exact offline oracle with an\napproximation oracle in TS algorithm for even the classical MAB problem. Then\nwe expand the analysis to two special cases: the linear reward case and the\nmatroid bandit case. When the reward function is linear, the regret of the TS\nalgorithm achieves a better bound $O(m\\log K_{\\max}\\log T / \\Delta_{\\min})$.\nFor matroid bandit, we could remove the independence assumption across arms and\nachieve a regret upper bound that matches the lower bound for the matroid case.\nFinally, we use some experiments to show the comparison between regrets of TS\nand other existing algorithms like CUCB and ESCB.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 05:08:47 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 08:28:56 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 07:55:18 GMT"}, {"version": "v4", "created": "Sun, 10 Jan 2021 10:15:30 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Wang", "Siwei", ""], ["Chen", "Wei", ""]]}, {"id": "1803.04663", "submitter": "Tomoya Sakai", "authors": "Masayoshi Hayashi, Tomoya Sakai, Masashi Sugiyama", "title": "Binary Matrix Completion Using Unobserved Entries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matrix completion problem, which aims to recover a complete matrix from its\npartial observations, is one of the important problems in the machine learning\nfield and has been studied actively. However, there is a discrepancy between\nthe mainstream problem setting, which assumes continuous-valued observations,\nand some practical applications such as recommendation systems and SNS link\npredictions where observations take discrete or even binary values. To cope\nwith this problem, Davenport et al. (2014) proposed a binary matrix completion\n(BMC) problem, where observations are quantized into binary values. Hsieh et\nal. (2015) proposed a PU (Positive and Unlabeled) matrix completion problem,\nwhich is an extension of the BMC problem. This problem targets the setting\nwhere we cannot observe negative values, such as SNS link predictions. In the\nconstruction of their method for this setting, they introduced a methodology of\nthe classification problem, regarding each matrix entry as a sample. Their\nrisk, which defines losses over unobserved entries as well, indicates the\npossibility of the use of unobserved entries. In this paper, motivated by a\nsemi-supervised classification method recently proposed by Sakai et al. (2017),\nwe develop a method for the BMC problem which can use all of positive,\nnegative, and unobserved entries, by combining the risks of Davenport et al.\n(2014) and Hsieh et al. (2015). To the best of our knowledge, this is the first\nBMC method which exploits all kinds of matrix entries. We experimentally show\nthat an appropriate mixture of risks improves the performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 07:26:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Hayashi", "Masayoshi", ""], ["Sakai", "Tomoya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1803.04665", "submitter": "Emilie Kaufmann", "authors": "Maryam Aziz, Jesse Anderton, Emilie Kaufmann (SEQUEL, CNRS, CRIStAL),\n  Javed Aslam", "title": "Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of near-optimal arm identification in the fixed\nconfidence setting of the infinitely armed bandit problem when nothing is known\nabout the arm reservoir distribution. We (1) introduce a PAC-like framework\nwithin which to derive and cast results; (2) derive a sample complexity lower\nbound for near-optimal arm identification; (3) propose an algorithm that\nidentifies a nearly-optimal arm with high probability and derive an upper bound\non its sample complexity which is within a log factor of our lower bound; and\n(4) discuss whether our log^2(1/delta) dependence is inescapable for\n\"two-phase\" (select arms first, identify the best later) algorithms in the\ninfinite setting. This work permits the application of bandit models to a\nbroader class of problems where fewer assumptions hold.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 07:36:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Aziz", "Maryam", "", "SEQUEL, CNRS, CRIStAL"], ["Anderton", "Jesse", "", "SEQUEL, CNRS, CRIStAL"], ["Kaufmann", "Emilie", "", "SEQUEL, CNRS, CRIStAL"], ["Aslam", "Javed", ""]]}, {"id": "1803.04674", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour", "title": "Hierarchical Reinforcement Learning: Approximating Optimal Discounted\n  TSP Using Local Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide theoretical guarantees for reward decomposition in\ndeterministic MDPs. Reward decomposition is a special case of Hierarchical\nReinforcement Learning, that allows one to learn many policies in parallel and\ncombine them into a composite solution. Our approach builds on mapping this\nproblem into a Reward Discounted Traveling Salesman Problem, and then deriving\napproximate solutions for it. In particular, we focus on approximate solutions\nthat are local, i.e., solutions that only observe information about the current\nstate. Local policies are easy to implement and do not require substantial\ncomputational resources as they do not perform planning. While local\ndeterministic policies, like Nearest Neighbor, are being used in practice for\nhierarchical reinforcement learning, we propose three stochastic policies that\nguarantee better performance than any deterministic policy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:13:11 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zahavy", "Tom", ""], ["Hasidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1803.04706", "submitter": "Olivier Sigaud", "authors": "Olivier Sigaud and Freek Stulp", "title": "Policy Search in Continuous Action Domains: an Overview", "comments": "Accepted in the Neural Networks Journal (Volume 113, May 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous action policy search is currently the focus of intensive research,\ndriven both by the recent success of deep reinforcement learning algorithms and\nthe emergence of competitors based on evolutionary algorithms. In this paper,\nwe present a broad survey of policy search methods, providing a unified\nperspective on very different approaches, including also Bayesian Optimization\nand directed exploration methods. The main message of this overview is in the\nrelationship between the families of methods, but we also outline some factors\nunderlying sample efficiency properties of the various approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 09:57:42 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:36:16 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 14:26:30 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 15:55:52 GMT"}, {"version": "v5", "created": "Thu, 13 Jun 2019 11:39:06 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Sigaud", "Olivier", ""], ["Stulp", "Freek", ""]]}, {"id": "1803.04715", "submitter": "Nghi Bui", "authors": "Nghi D. Q. Bui, Lingxiao Jiang", "title": "Hierarchical Learning of Cross-Language Mappings through Distributed\n  Vector Representations for Code", "comments": "Accepted at ICSE'18", "journal-ref": null, "doi": "10.1145/3183399.3183427", "report-no": null, "categories": "cs.LG cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating a program written in one programming language to another can be\nuseful for software development tasks that need functionality implementations\nin different languages. Although past studies have considered this problem,\nthey may be either specific to the language grammars, or specific to certain\nkinds of code elements (e.g., tokens, phrases, API uses). This paper proposes a\nnew approach to automatically learn cross-language representations for various\nkinds of structural code elements that may be used for program translation. Our\nkey idea is two folded: First, we normalize and enrich code token streams with\nadditional structural and semantic information, and train cross-language vector\nrepresentations for the tokens (a.k.a. shared embeddings based on word2vec, a\nneural-network-based technique for producing word embeddings; Second,\nhierarchically from bottom up, we construct shared embeddings for code elements\nof higher levels of granularity (e.g., expressions, statements, methods) from\nthe embeddings for their constituents, and then build mappings among code\nelements across languages based on similarities among embeddings.\n  Our preliminary evaluations on about 40,000 Java and C# source files from 9\nsoftware projects show that our approach can automatically learn shared\nembeddings for various code elements in different languages and identify their\ncross-language mappings with reasonable Mean Average Precision scores. When\ncompared with an existing tool for mapping library API methods, our approach\nidentifies many more mappings accurately. The mapping results and code can be\naccessed at\nhttps://github.com/bdqnghi/hierarchical-programming-language-mapping. We\nbelieve that our idea for learning cross-language vector representations with\ncode structural information can be a useful step towards automated program\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 10:30:55 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "1803.04742", "submitter": "Anton Tsitsulin", "authors": "Anton Tsitsulin, Davide Mottin, Panagiotis Karras, Emmanuel M\\\"uller", "title": "VERSE: Versatile Graph Embeddings from Similarity Measures", "comments": "In WWW 2018: The Web Conference. 10 pages, 5 figures", "journal-ref": null, "doi": "10.1145/3178876.3186120", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Embedding a web-scale information network into a low-dimensional vector space\nfacilitates tasks such as link prediction, classification, and visualization.\nPast research has addressed the problem of extracting such embeddings by\nadopting methods from words to graphs, without defining a clearly\ncomprehensible graph-related objective. Yet, as we show, the objectives used in\npast works implicitly utilize similarity measures among graph nodes.\n  In this paper, we carry the similarity orientation of previous works to its\nlogical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple,\nversatile, and memory-efficient method that derives graph embeddings explicitly\ncalibrated to preserve the distributions of a selected vertex-to-vertex\nsimilarity measure. VERSE learns such embeddings by training a single-layer\nneural network. While its default, scalable version does so via sampling\nsimilarity information, we also develop a variant using the full information\nper vertex. Our experimental study on standard benchmarks and real-world\ndatasets demonstrates that VERSE, instantiated with diverse similarity\nmeasures, outperforms state-of-the-art methods in terms of precision and recall\nin major data mining tasks and supersedes them in time and space efficiency,\nwhile the scalable sampling-based variant achieves equally good results as the\nnon-scalable full variant.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 12:05:58 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Tsitsulin", "Anton", ""], ["Mottin", "Davide", ""], ["Karras", "Panagiotis", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "1803.04765", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel", "title": "Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) enable innovative applications of machine\nlearning like image recognition, machine translation, or malware detection.\nHowever, deep learning is often criticized for its lack of robustness in\nadversarial settings (e.g., vulnerability to adversarial inputs) and general\ninability to rationalize its predictions. In this work, we exploit the\nstructure of deep learning to enable new learning-based inference and decision\nstrategies that achieve desirable properties such as robustness and\ninterpretability. We take a first step in this direction and introduce the Deep\nk-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest\nneighbors algorithm with representations of the data learned by each layer of\nthe DNN: a test input is compared to its neighboring training points according\nto the distance that separates them in the representations. We show the labels\nof these neighboring points afford confidence estimates for inputs outside the\nmodel's training manifold, including on malicious inputs like adversarial\nexamples--and therein provides protections against inputs that are outside the\nmodels understanding. This is because the nearest neighbors can be used to\nestimate the nonconformity of, i.e., the lack of support for, a prediction in\nthe training data. The neighbors also constitute human-interpretable\nexplanations of predictions. We evaluate the DkNN algorithm on several\ndatasets, and show the confidence estimates accurately identify inputs outside\nthe model, and that the explanations provided by nearest neighbors are\nintuitive and useful in understanding model failures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 13:02:13 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1803.04779", "submitter": "Jaideep Pathak", "authors": "Jaideep Pathak, Alexander Wikner, Rebeckah Fussell, Sarthak Chandra,\n  Brian Hunt, Michelle Girvan, Edward Ott", "title": "Hybrid Forecasting of Chaotic Processes: Using Machine Learning in\n  Conjunction with a Knowledge-Based Model", "comments": null, "journal-ref": null, "doi": "10.1063/1.5028373", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model-based approach to forecasting chaotic dynamical systems utilizes\nknowledge of the physical processes governing the dynamics to build an\napproximate mathematical model of the system. In contrast, machine learning\ntechniques have demonstrated promising results for forecasting chaotic systems\npurely from past time series measurements of system state variables (training\ndata), without prior knowledge of the system dynamics. The motivation for this\npaper is the potential of machine learning for filling in the gaps in our\nunderlying mechanistic knowledge that cause widely-used knowledge-based models\nto be inaccurate. Thus we here propose a general method that leverages the\nadvantages of these two approaches by combining a knowledge-based model and a\nmachine learning technique to build a hybrid forecasting scheme. Potential\napplications for such an approach are numerous (e.g., improving weather\nforecasting). We demonstrate and test the utility of this approach using a\nparticular illustrative version of a machine learning known as reservoir\ncomputing, and we apply the resulting hybrid forecaster to a low-dimensional\nchaotic system, as well as to a high-dimensional spatiotemporal chaotic system.\nThese tests yield extremely promising results in that our hybrid technique is\nable to accurately predict for a much longer period of time than either its\nmachine-learning component or its model-based component alone.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 21:02:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Pathak", "Jaideep", ""], ["Wikner", "Alexander", ""], ["Fussell", "Rebeckah", ""], ["Chandra", "Sarthak", ""], ["Hunt", "Brian", ""], ["Girvan", "Michelle", ""], ["Ott", "Edward", ""]]}, {"id": "1803.04792", "submitter": "Youcheng Sun", "authors": "Youcheng Sun and Xiaowei Huang and Daniel Kroening and James Sharp and\n  Matthew Hill and Rob Ashmore", "title": "Testing Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have a wide range of applications, and software\nemploying them must be thoroughly tested, especially in safety-critical\ndomains. However, traditional software test coverage metrics cannot be applied\ndirectly to DNNs. In this paper, inspired by the MC/DC coverage criterion, we\npropose a family of four novel test criteria that are tailored to structural\nfeatures of DNNs and their semantics. We validate the criteria by demonstrating\nthat the generated test inputs guided via our proposed coverage criteria are\nable to capture undesired behaviours in a DNN. Test cases are generated using a\nsymbolic approach and a gradient-based heuristic search. By comparing them with\nexisting methods, we show that our criteria achieve a balance between their\nability to find bugs (proxied using adversarial examples) and the computational\ncost of test case generation. Our experiments are conducted on state-of-the-art\nDNNs obtained using popular open source datasets, including MNIST, CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 23:19:13 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 17:53:58 GMT"}, {"version": "v3", "created": "Sun, 18 Mar 2018 23:40:19 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 16:49:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Sun", "Youcheng", ""], ["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""], ["Sharp", "James", ""], ["Hill", "Matthew", ""], ["Ashmore", "Rob", ""]]}, {"id": "1803.04813", "submitter": "Saptarshi Das", "authors": "Daya Shankar Pandey, Saptarshi Das, Indranil Pan, James J. Leahy,\n  Witold Kwapinski", "title": "Artificial neural network based modelling approach for municipal solid\n  waste gasification in a fluidized bed reactor", "comments": "34 pages, 11 figures", "journal-ref": "Waste Management (Elsevier), Volume 58, December 2016, Pages\n  202-213", "doi": "10.1016/j.wasman.2016.08.023", "report-no": null, "categories": "cs.LG cs.CE cs.NE physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, multi-layer feed forward neural networks are used to predict\nthe lower heating value of gas (LHV), lower heating value of gasification\nproducts including tars and entrained char (LHVp) and syngas yield during\ngasification of municipal solid waste (MSW) during gasification in a fluidized\nbed reactor. These artificial neural networks (ANNs) with different\narchitectures are trained using the Levenberg-Marquardt (LM) back-propagation\nalgorithm and a cross validation is also performed to ensure that the results\ngeneralise to other unseen datasets. A rigorous study is carried out on\noptimally choosing the number of hidden layers, number of neurons in the hidden\nlayer and activation function in a network using multiple Monte Carlo runs.\nNine input and three output parameters are used to train and test various\nneural network architectures in both multiple output and single output\nprediction paradigms using the available experimental datasets. The model\nselection procedure is carried out to ascertain the best network architecture\nin terms of predictive accuracy. The simulation results show that the ANN based\nmethodology is a viable alternative which can be used to predict the\nperformance of a fluidized bed gasifier.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 21:50:22 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Pandey", "Daya Shankar", ""], ["Das", "Saptarshi", ""], ["Pan", "Indranil", ""], ["Leahy", "James J.", ""], ["Kwapinski", "Witold", ""]]}, {"id": "1803.04818", "submitter": "Michael Barz", "authors": "Jan Zacharias and Michael Barz and Daniel Sonntag", "title": "A Survey on Deep Learning Toolkits and Libraries for Intelligent User\n  Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper provides an overview of prominent deep learning toolkits and, in\nparticular, reports on recent publications that contributed open source\nsoftware for implementing tasks that are common in intelligent user interfaces\n(IUI). We provide a scientific reference for researchers and software engineers\nwho plan to utilise deep learning techniques within their IUI research and\ndevelopment projects.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:07:40 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 08:32:02 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Zacharias", "Jan", ""], ["Barz", "Michael", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1803.04825", "submitter": "Raphael Hauser A", "authors": "Reka Kovacs, Oktay Gunluk, Raphael Hauser", "title": "Low-Rank Boolean Matrix Approximation by Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximations of data matrices are an important dimensionality\nreduction tool in machine learning and regression analysis. We consider the\ncase of categorical variables, where it can be formulated as the problem of\nfinding low-rank approximations to Boolean matrices. In this paper we give what\nis to the best of our knowledge the first integer programming formulation that\nrelies on only polynomially many variables and constraints, we discuss how to\nsolve it computationally and report numerical tests on synthetic and real-world\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:17:00 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Kovacs", "Reka", ""], ["Gunluk", "Oktay", ""], ["Hauser", "Raphael", ""]]}, {"id": "1803.04831", "submitter": "Shuai Li", "authors": "Shuai Li, Wanqing Li, Chris Cook, Ce Zhu, Yanbo Gao", "title": "Independently Recurrent Neural Network (IndRNN): Building A Longer and\n  Deeper RNN", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been widely used for processing\nsequential data. However, RNNs are commonly difficult to train due to the\nwell-known gradient vanishing and exploding problems and hard to learn\nlong-term patterns. Long short-term memory (LSTM) and gated recurrent unit\n(GRU) were developed to address these problems, but the use of hyperbolic\ntangent and the sigmoid action functions results in gradient decay over layers.\nConsequently, construction of an efficiently trainable deep network is\nchallenging. In addition, all the neurons in an RNN layer are entangled\ntogether and their behaviour is hard to interpret. To address these problems, a\nnew type of RNN, referred to as independently recurrent neural network\n(IndRNN), is proposed in this paper, where neurons in the same layer are\nindependent of each other and they are connected across layers. We have shown\nthat an IndRNN can be easily regulated to prevent the gradient exploding and\nvanishing problems while allowing the network to learn long-term dependencies.\nMoreover, an IndRNN can work with non-saturated activation functions such as\nrelu (rectified linear unit) and be still trained robustly. Multiple IndRNNs\ncan be stacked to construct a network that is deeper than the existing RNNs.\nExperimental results have shown that the proposed IndRNN is able to process\nvery long sequences (over 5000 time steps), can be used to construct very deep\nnetworks (21 layers used in the experiment) and still be trained robustly.\nBetter performances have been achieved on various tasks by using IndRNNs\ncompared with the traditional RNN and LSTM. The code is available at\nhttps://github.com/Sunnydreamrain/IndRNN_Theano_Lasagne.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:27:42 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 04:46:08 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 11:54:28 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Shuai", ""], ["Li", "Wanqing", ""], ["Cook", "Chris", ""], ["Zhu", "Ce", ""], ["Gao", "Yanbo", ""]]}, {"id": "1803.04837", "submitter": "Luchen Liu", "authors": "Luchen Liu, Jianhao Shen, Ming Zhang, Zichang Wang and Jian Tang", "title": "Learning the Joint Representation of Heterogeneous Temporal Events for\n  Clinical Endpoint Prediction", "comments": "8 pages, this paper has been accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of a large amount of electronic health records (EHR)\nprovides huge opportunities to improve health care service by mining these\ndata. One important application is clinical endpoint prediction, which aims to\npredict whether a disease, a symptom or an abnormal lab test will happen in the\nfuture according to patients' history records. This paper develops deep\nlearning techniques for clinical endpoint prediction, which are effective in\nmany practical applications. However, the problem is very challenging since\npatients' history records contain multiple heterogeneous temporal events such\nas lab tests, diagnosis, and drug administrations. The visiting patterns of\ndifferent types of events vary significantly, and there exist complex nonlinear\nrelationships between different events. In this paper, we propose a novel model\nfor learning the joint representation of heterogeneous temporal events. The\nmodel adds a new gate to control the visiting rates of different events which\neffectively models the irregular patterns of different events and their\nnonlinear correlations. Experiment results with real-world clinical data on the\ntasks of predicting death and abnormal lab tests prove the effectiveness of our\nproposed approach over competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:32:38 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 21:56:32 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 12:12:48 GMT"}, {"version": "v4", "created": "Sat, 17 Nov 2018 06:20:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Liu", "Luchen", ""], ["Shen", "Jianhao", ""], ["Zhang", "Ming", ""], ["Wang", "Zichang", ""], ["Tang", "Jian", ""]]}, {"id": "1803.04848", "submitter": "Esther Derman", "authors": "Esther Derman, Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor", "title": "Soft-Robust Actor-Critic Policy-Gradient", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust Reinforcement Learning aims to derive optimal behavior that accounts\nfor model uncertainty in dynamical systems. However, previous studies have\nshown that by considering the worst case scenario, robust policies can be\noverly conservative. Our soft-robust framework is an attempt to overcome this\nissue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm\n(SR-AC). It learns an optimal policy with respect to a distribution over an\nuncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show the convergence of SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 09:43:20 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 06:01:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Derman", "Esther", ""], ["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Mannor", "Shie", ""]]}, {"id": "1803.04866", "submitter": "Gaurav Gupta", "authors": "Gaurav Gupta, Sergio Pequito, Paul Bogdan", "title": "Dealing with Unknown Unknowns: Identification and Selection of Minimal\n  Sensing for Fractional Dynamics with Unknown Inputs", "comments": "7 pages, 4 figures, ACC-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on analysis and design of time-varying complex networks\nhaving fractional order dynamics. These systems are key in modeling the complex\ndynamical processes arising in several natural and man made systems. Notably,\nexamples include neurophysiological signals such as electroencephalogram (EEG)\nthat captures the variation in potential fields, and blood oxygenation level\ndependent (BOLD) signal, which serves as a proxy for neuronal activity.\nNotwithstanding, the complex networks originated by locally measuring EEG and\nBOLD are often treated as isolated networks and do not capture the dependency\nfrom external stimuli, e.g., originated in subcortical structures such as the\nthalamus and the brain stem. Therefore, we propose a paradigm-shift towards the\nanalysis of such complex networks under unknown unknowns (i.e., excitations).\nConsequently, the main contributions of the present paper are threefold: (i) we\npresent an alternating scheme that enables to determine the best estimate of\nthe model parameters and unknown stimuli; (ii) we provide necessary and\nsufficient conditions to ensure that it is possible to retrieve the state and\nunknown stimuli; and (iii) upon these conditions we determine a small subset of\nvariables that need to be measured to ensure that both state and input can be\nrecovered, while establishing sub-optimality guarantees with respect to the\nsmallest possible subset. Finally, we present several pedagogical examples of\nthe main results using real data collected from an EEG wearable device.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 20:40:56 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 21:08:56 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Gupta", "Gaurav", ""], ["Pequito", "Sergio", ""], ["Bogdan", "Paul", ""]]}, {"id": "1803.04926", "submitter": "Sebastian Schulze", "authors": "Sebastian Schulze and Owain Evans", "title": "Active Reinforcement Learning with Monte-Carlo Tree Search", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Reinforcement Learning (ARL) is a twist on RL where the agent observes\nreward information only if it pays a cost. This subtle change makes exploration\nsubstantially more challenging. Powerful principles in RL like optimism,\nThompson sampling, and random exploration do not help with ARL. We relate ARL\nin tabular environments to Bayes-Adaptive MDPs. We provide an ARL algorithm\nusing Monte-Carlo Tree Search that is asymptotically Bayes optimal.\nExperimentally, this algorithm is near-optimal on small Bandit problems and\nMDPs. On larger MDPs it outperforms a Q-learner augmented with specialised\nheuristics for ARL. By analysing exploration behaviour in detail, we uncover\nobstacles to scaling up simulation-based algorithms for ARL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:35:25 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 18:44:11 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 16:11:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Schulze", "Sebastian", ""], ["Evans", "Owain", ""]]}, {"id": "1803.04964", "submitter": "Pan Wei", "authors": "Archit Harsh, John E. Ball, Pan Wei", "title": "Onion-Peeling Outlier Detection in 2-D data Sets", "comments": "6 pages, 4 figures, journal paper", "journal-ref": "International Journal of Computer Application, Vol.139 (3),\n  pp.26-31, April, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Outlier Detection is a critical and cardinal research task due its array of\napplications in variety of domains ranging from data mining, clustering,\nstatistical analysis, fraud detection, network intrusion detection and\ndiagnosis of diseases etc. Over the last few decades, distance-based outlier\ndetection algorithms have gained significant reputation as a viable alternative\nto the more traditional statistical approaches due to their scalable,\nnon-parametric and simple implementation. In this paper, we present a modified\nonion peeling (Convex hull) genetic algorithm to detect outliers in a Gaussian\n2-D point data set. We present three different scenarios of outlier detection\nusing a) Euclidean Distance Metric b) Standardized Euclidean Distance Metric\nand c) Mahalanobis Distance Metric. Finally, we analyze the performance and\nevaluate the results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 22:37:14 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Harsh", "Archit", ""], ["Ball", "John E.", ""], ["Wei", "Pan", ""]]}, {"id": "1803.04967", "submitter": "Aaron Tuor", "authors": "Andy Brown, Aaron Tuor, Brian Hutchinson, Nicole Nichols", "title": "Recurrent Neural Network Attention Mechanisms for Interpretable System\n  Log Anomaly Detection", "comments": "Submitted to the First Workshop On Machine Learning for Computer\n  Systems, ACM HPDC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently demonstrated state-of-the art performance on key\ntasks related to the maintenance of computer systems, such as intrusion\ndetection, denial of service attack detection, hardware and software system\nfailures, and malware detection. In these contexts, model interpretability is\nvital for administrator and analyst to trust and act on the automated analysis\nof machine learning models. Deep learning methods have been criticized as black\nbox oracles which allow limited insight into decision factors. In this work we\nseek to \"bridge the gap\" between the impressive performance of deep learning\nmodels and the need for interpretable model introspection. To this end we\npresent recurrent neural network (RNN) language models augmented with attention\nfor anomaly detection in system logs. Our methods are generally applicable to\nany computer system and logging source.\n  By incorporating attention variants into our RNN language models we create\nopportunities for model introspection and analysis without sacrificing\nstate-of-the art performance.\n  We demonstrate model performance and illustrate model interpretability on an\nintrusion detection task using the Los Alamos National Laboratory (LANL) cyber\nsecurity dataset, reporting upward of 0.99 area under the receiver operator\ncharacteristic curve despite being trained only on a single day's worth of\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:09:20 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Brown", "Andy", ""], ["Tuor", "Aaron", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""]]}, {"id": "1803.05011", "submitter": "Yingying Zhu", "authors": "Yingying Zhu, Mert R. Sabuncu", "title": "A Probabilistic Disease Progression Model for Predicting Future Clinical\n  Outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of predicting the course of a\nprogressive disease, such as cancer or Alzheimer's. Progressive diseases often\nstart with mild symptoms that might precede a diagnosis, and each patient\nfollows their own trajectory. Patient trajectories exhibit wild variability,\nwhich can be associated with many factors such as genotype, age, or sex. An\nadditional layer of complexity is that, in real life, the amount and type of\ndata available for each patient can differ significantly. For example, for one\npatient we might have no prior history, whereas for another patient we might\nhave detailed clinical assessments obtained at multiple prior time-points. This\npaper presents a probabilistic model that can handle multiple modalities\n(including images and clinical assessments) and variable patient histories with\nirregular timings and missing entries, to predict clinical scores at future\ntime-points. We use a sigmoidal function to model latent disease progression,\nwhich gives rise to clinical observations in our generative model. We\nimplemented an approximate Bayesian inference strategy on the proposed model to\nestimate the parameters on data from a large population of subjects.\nFurthermore, the Bayesian framework enables the model to automatically\nfine-tune its predictions based on historical observations that might be\navailable on the test subject. We applied our method to a longitudinal\nAlzheimer's disease dataset with more than 3000 subjects [23] and present a\ndetailed empirical analysis of prediction performance under different\nscenarios, with comparisons against several benchmarks. We also demonstrate how\nthe proposed model can be interrogated to glean insights about temporal\ndynamics in Alzheimer's disease.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 19:05:08 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zhu", "Yingying", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1803.05026", "submitter": "Vaneet Aggarwal", "authors": "Wenqi Wang and Vaneet Aggarwal and Shuchin Aeron", "title": "Principal Component Analysis with Tensor Train Subspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor train is a hierarchical tensor network structure that helps alleviate\nthe curse of dimensionality by parameterizing large-scale multidimensional data\nvia a set of network of low-rank tensors. Associated with such a construction\nis a notion of Tensor Train subspace and in this paper we propose a TT-PCA\nalgorithm for estimating this structured subspace from the given data. By\nmaintaining low rank tensor structure, TT-PCA is more robust to noise comparing\nwith PCA or Tucker-PCA. This is borne out numerically by testing the proposed\napproach on the Extended YaleFace Dataset B.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 19:58:46 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Wang", "Wenqi", ""], ["Aggarwal", "Vaneet", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1803.05044", "submitter": "Tianbing Xu", "authors": "Tianbing Xu, Qiang Liu, Liang Zhao, Jian Peng", "title": "Learning to Explore with Meta-Policy Gradient", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of off-policy learning, including deep Q-learning and deep\ndeterministic policy gradient (DDPG), critically depends on the choice of the\nexploration policy. Existing exploration methods are mostly based on adding\nnoise to the on-going actor policy and can only explore \\emph{local} regions\nclose to what the actor policy dictates. In this work, we develop a simple\nmeta-policy gradient algorithm that allows us to adaptively learn the\nexploration policy in DDPG. Our algorithm allows us to train flexible\nexploration behaviors that are independent of the actor policy, yielding a\n\\emph{global exploration} that significantly speeds up the learning process.\nWith an extensive study, we show that our method significantly improves the\nsample-efficiency of DDPG on a variety of reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:04:17 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 00:02:21 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Xu", "Tianbing", ""], ["Liu", "Qiang", ""], ["Zhao", "Liang", ""], ["Peng", "Jian", ""]]}, {"id": "1803.05045", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou", "title": "Analysis of Nonautonomous Adversarial Systems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks are used to generate images but still their\nconvergence properties are not well understood. There have been a few studies\nwho intended to investigate the stability properties of GANs as a dynamical\nsystem. This short writing can be seen in that direction. Among the proposed\nmethods for stabilizing training of GANs, {\\ss}-GAN was the first who proposed\na complete annealing strategy to change high-level conditions of the GAN\nobjective. In this note, we show by a simple example how annealing strategy\nworks in GANs. The theoretical analysis is supported by simple simulations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:06:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Mehrjou", "Arash", ""]]}, {"id": "1803.05070", "submitter": "Sugumar Murugesan", "authors": "Ashok Sundaresan, Sugumar Murugesan, Sean Davis, Karthik Kappaganthu,\n  ZhongYi Jin, Divya Jain, Anurag Maunder", "title": "A Multi-Modal Approach to Infer Image Affect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group affect or emotion in an image of people can be inferred by\nextracting features about both the people in the picture and the overall makeup\nof the scene. The state-of-the-art on this problem investigates a combination\nof facial features, scene extraction and even audio tonality. This paper\ncombines three additional modalities, namely, human pose, text-based tagging\nand CNN extracted features / predictions. To the best of our knowledge, this is\nthe first time all of the modalities were extracted using deep neural networks.\nWe evaluate the performance of our approach against baselines and identify\ninsights throughout this paper.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 23:07:45 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Sundaresan", "Ashok", ""], ["Murugesan", "Sugumar", ""], ["Davis", "Sean", ""], ["Kappaganthu", "Karthik", ""], ["Jin", "ZhongYi", ""], ["Jain", "Divya", ""], ["Maunder", "Anurag", ""]]}, {"id": "1803.05101", "submitter": "Raef Bassily", "authors": "Raef Bassily, Om Thakkar, Abhradeep Thakurta", "title": "Model-Agnostic Private Learning via Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design differentially private learning algorithms that are agnostic to the\nlearning model. Our algorithms are interactive in nature, i.e., instead of\noutputting a model based on the training data, they provide predictions for a\nset of $m$ feature vectors that arrive online. We show that, for the feature\nvectors on which an ensemble of models (trained on random disjoint subsets of a\ndataset) makes consistent predictions, there is almost no-cost of privacy in\ngenerating accurate predictions for those feature vectors. To that end, we\nprovide a novel coupling of the distance to instability framework with the\nsparse vector technique. We provide algorithms with formal privacy and utility\nguarantees for both binary/multi-class classification, and soft-label\nclassification. For binary classification in the standard (agnostic) PAC model,\nwe show how to bootstrap from our privately generated predictions to construct\na computationally efficient private learner that outputs a final accurate\nhypothesis. Our construction - to the best of our knowledge - is the first\ncomputationally efficient construction for a label-private learner. We prove\nsample complexity upper bounds for this setting. As in non-private sample\ncomplexity bounds, the only relevant property of the given concept class is its\nVC dimension. For soft-label classification, our techniques are based on\nexploiting the stability properties of traditional learning algorithms, like\nstochastic gradient descent (SGD). We provide a new technique to boost the\naverage-case stability properties of learning algorithms to strong (worst-case)\nstability properties, and then exploit them to obtain private classification\nalgorithms. In the process, we also show that a large class of SGD methods\nsatisfy average-case stability properties, in contrast to a smaller class of\nSGD methods that are uniformly stable as shown in prior work.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:09:15 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Bassily", "Raef", ""], ["Thakkar", "Om", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1803.05105", "submitter": "Liangyue Li", "authors": "Muge Li, Liangyue Li, and Feiping Nie", "title": "Ranking with Adaptive Neighbors", "comments": "published at Tsinghua Science and Technology 22(6), 2017", "journal-ref": null, "doi": "10.23919/TST.2017.8195354", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving the most similar objects in a large-scale database for a given\nquery is a fundamental building block in many application domains, ranging from\nweb searches, visual, cross media, and document retrievals. State-of-the-art\napproaches have mainly focused on capturing the underlying geometry of the data\nmanifolds. Graph-based approaches, in particular, define various diffusion\nprocesses on weighted data graphs. Despite success, these approaches rely on\nfixed-weight graphs, making ranking sensitive to the input affinity matrix. In\nthis study, we propose a new ranking algorithm that simultaneously learns the\ndata affinity matrix and the ranking scores. The proposed optimization\nformulation assigns adaptive neighbors to each point in the data based on the\nlocal connectivity, and the smoothness constraint assigns similar ranking\nscores to similar data points. We develop a novel and efficient algorithm to\nsolve the optimization problem. Evaluations using synthetic and real datasets\nsuggest that the proposed algorithm can outperform the existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:23:11 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Li", "Muge", ""], ["Li", "Liangyue", ""], ["Nie", "Feiping", ""]]}, {"id": "1803.05123", "submitter": "Derui Derek Wang", "authors": "Derek Wang, Chaoran Li, Sheng Wen, Surya Nepal, Yang Xiang", "title": "Defending against Adversarial Attack towards Deep Neural Networks via\n  Collaborative Multi-task Training", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples which contain human-imperceptible perturbations. A series of defending\nmethods, either proactive defence or reactive defence, have been proposed in\nthe recent years. However, most of the methods can only handle specific\nattacks. For example, proactive defending methods are invalid against grey-box\nor white-box attacks, while reactive defending methods are challenged by\nlow-distortion adversarial examples or transferring adversarial examples. This\nbecomes a critical problem since a defender usually does not have the type of\nthe attack as a priori knowledge. Moreover, existing two-pronged defences\n(e.g., MagNet), which take advantages of both proactive and reactive methods,\nhave been reported as broken under transferring attacks. To address this\nproblem, this paper proposed a novel defensive framework based on collaborative\nmulti-task training, aiming at providing defence for different types of\nattacks. The proposed defence first encodes training labels into label pairs\nand counters black-box attacks leveraging adversarial training supervised by\nthe encoded label pairs. The defence further constructs a detector to identify\nand reject high-confidence adversarial examples that bypass the black-box\ndefence. In addition, the proposed collaborative architecture can prevent\nadversaries from finding valid adversarial examples when the defence strategy\nis exposed. In the experiments, we evaluated our defence against four\nstate-of-the-art attacks on $MNIST$ and $CIFAR10$ datasets. The results showed\nthat our defending method achieved up to $96.3\\%$ classification accuracy on\nblack-box adversarial examples, and detected up to $98.7\\%$ of the high\nconfidence adversarial examples. It only decreased the model accuracy on benign\nexample classification by $2.1\\%$ for the $CIFAR10$ dataset.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 03:41:18 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 15:41:43 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 03:31:25 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 06:01:08 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Wang", "Derek", ""], ["Li", "Chaoran", ""], ["Wen", "Sheng", ""], ["Nepal", "Surya", ""], ["Xiang", "Yang", ""]]}, {"id": "1803.05159", "submitter": "Stanislaw Gorlow", "authors": "Pedro J. Villasana T. and Stanislaw Gorlow and Arvind T. Hariraman", "title": "Multiplicative Updates for Convolutional NMF Under $\\beta$-Divergence", "comments": null, "journal-ref": "Optim Lett (2019)", "doi": "10.1007/s11590-019-01434-9", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we generalize the convolutional NMF by taking the\n$\\beta$-divergence as the contrast function and present the correct\nmultiplicative updates for its factors in closed form. The new updates unify\nthe $\\beta$-NMF and the convolutional NMF. We state why almost all of the\nexisting updates are inexact and approximative w.r.t. the convolutional data\nmodel. We show that our updates are stable and that their convergence\nperformance is consistent across the most common values of $\\beta$.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 08:11:07 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 14:55:30 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["T.", "Pedro J. Villasana", ""], ["Gorlow", "Stanislaw", ""], ["Hariraman", "Arvind T.", ""]]}, {"id": "1803.05170", "submitter": "Jianxun Lian", "authors": "Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie,\n  Guangzhong Sun", "title": "xDeepFM: Combining Explicit and Implicit Feature Interactions for\n  Recommender Systems", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3219819.3220023", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial features are essential for the success of many commercial\nmodels. Manually crafting these features usually comes with high cost due to\nthe variety, volume and velocity of raw data in web-scale systems.\nFactorization based models, which measure interactions in terms of vector\nproduct, can learn patterns of combinatorial features automatically and\ngeneralize to unseen features as well. With the great success of deep neural\nnetworks (DNNs) in various fields, recently researchers have proposed several\nDNN-based factorization model to learn both low- and high-order feature\ninteractions. Despite the powerful ability of learning an arbitrary function\nfrom data, plain DNNs generate feature interactions implicitly and at the\nbit-wise level. In this paper, we propose a novel Compressed Interaction\nNetwork (CIN), which aims to generate feature interactions in an explicit\nfashion and at the vector-wise level. We show that the CIN share some\nfunctionalities with convolutional neural networks (CNNs) and recurrent neural\nnetworks (RNNs). We further combine a CIN and a classical DNN into one unified\nmodel, and named this new model eXtreme Deep Factorization Machine (xDeepFM).\nOn one hand, the xDeepFM is able to learn certain bounded-degree feature\ninteractions explicitly; on the other hand, it can learn arbitrary low- and\nhigh-order feature interactions implicitly. We conduct comprehensive\nexperiments on three real-world datasets. Our results demonstrate that xDeepFM\noutperforms state-of-the-art models. We have released the source code of\nxDeepFM at \\url{https://github.com/Leavingseason/xDeepFM}.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:13:16 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 07:37:35 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 15:00:27 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lian", "Jianxun", ""], ["Zhou", "Xiaohuan", ""], ["Zhang", "Fuzheng", ""], ["Chen", "Zhongxia", ""], ["Xie", "Xing", ""], ["Sun", "Guangzhong", ""]]}, {"id": "1803.05181", "submitter": "Rizwan Ahmed Khan", "authors": "Muhammad Shoaib Jaliawala, Rizwan Ahmed Khan", "title": "Can Autism be Catered with Artificial Intelligence-Assisted Intervention\n  Technology? A Literature Review", "comments": null, "journal-ref": "Artificial Intelligence Review 2019", "doi": "10.1007/s10462-019-09686-8", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an extensive literature review of technology based\nintervention methodologies for individuals facing Autism Spectrum Disorder\n(ASD). Reviewed methodologies include: contemporary Computer Aided Systems\n(CAS), Computer Vision Assisted Technologies (CVAT) and Virtual Reality (VR) or\nArtificial Intelligence (AI)-Assisted interventions. The research over the past\ndecade has provided enough demonstrations that individuals with ASD have a\nstrong interest in technology based interventions, which are useful in both,\nclinical settings as well as at home and classrooms. Despite showing great\npromise, research in developing an advanced technology based intervention that\nis clinically quantitative for ASD is minimal. Moreover, the clinicians are\ngenerally not convinced about the potential of the technology based\ninterventions due to non-empirical nature of published results. A major reason\nbehind this lack of acceptability is that a vast majority of studies on\ndistinct intervention methodologies do not follow any specific standard or\nresearch design. We conclude from our findings that there remains a gap between\nthe research community of computer science, psychology and neuroscience to\ndevelop an AI assisted intervention technology for individuals suffering from\nASD. Following the development of a standardized AI based intervention\ntechnology, a database needs to be developed, to devise effective AI\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:56:39 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 04:37:12 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 18:54:34 GMT"}, {"version": "v4", "created": "Fri, 23 Nov 2018 05:15:02 GMT"}, {"version": "v5", "created": "Sat, 19 Jan 2019 16:16:32 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Jaliawala", "Muhammad Shoaib", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "1803.05206", "submitter": "Xiaopeng Li", "authors": "Xiaopeng Li, Zhourong Chen, Leonard K. M. Poon, Nevin L. Zhang", "title": "Learning Latent Superstructures in Variational Autoencoders for Deep\n  Multidimensional Clustering", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a variant of variational autoencoders where there is a\nsuperstructure of discrete latent variables on top of the latent features. In\ngeneral, our superstructure is a tree structure of multiple super latent\nvariables and it is automatically learned from data. When there is only one\nlatent variable in the superstructure, our model reduces to one that assumes\nthe latent features to be generated from a Gaussian mixture model. We call our\nmodel the latent tree variational autoencoder (LTVAE). Whereas previous deep\nlearning methods for clustering produce only one partition of data, LTVAE\nproduces multiple partitions of data, each being given by one super latent\nvariable. This is desirable because high dimensional data usually have many\ndifferent natural facets and can be meaningfully partitioned in multiple ways.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 11:20:38 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 03:16:54 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 07:44:14 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Li", "Xiaopeng", ""], ["Chen", "Zhourong", ""], ["Poon", "Leonard K. M.", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1803.05209", "submitter": "Xiaopeng Li", "authors": "Xiaopeng Li, Zhourong Chen, Nevin L. Zhang", "title": "Building Sparse Deep Feedforward Networks using Tree Receptive Fields", "comments": "International Joint Conference on Artificial Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse connectivity is an important factor behind the success of\nconvolutional neural networks and recurrent neural networks. In this paper, we\nconsider the problem of learning sparse connectivity for feedforward neural\nnetworks (FNNs). The key idea is that a unit should be connected to a small\nnumber of units at the next level below that are strongly correlated. We use\nChow-Liu's algorithm to learn a tree-structured probabilistic model for the\nunits at the current level, use the tree to identify subsets of units that are\nstrongly correlated, and introduce a new unit with receptive field over the\nsubsets. The procedure is repeated on the new units to build multiple layers of\nhidden units. The resulting model is called a TRF-net. Empirical results show\nthat, when compared to dense FNNs, TRF-net achieves better or comparable\nclassification performance with much fewer parameters and sparser structures.\nThey are also more interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 11:27:15 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 07:44:28 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Li", "Xiaopeng", ""], ["Chen", "Zhourong", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1803.05252", "submitter": "Gonzalo G. de Polavieja", "authors": "Fernando Martin-Maroto and Gonzalo G. de Polavieja", "title": "Algebraic Machine Learning", "comments": "In v2 Figures 10 and 12 are images (v1 used latex commands), so all\n  queens on board are now visible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.AC math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms use error function minimization to fit a large\nset of parameters in a preexisting model. However, error minimization\neventually leads to a memorization of the training dataset, losing the ability\nto generalize to other datasets. To achieve generalization something else is\nneeded, for example a regularization method or stopping the training when error\nin a validation dataset is minimal. Here we propose a different approach to\nlearning and generalization that is parameter-free, fully discrete and that\ndoes not use function minimization. We use the training data to find an\nalgebraic representation with minimal size and maximal freedom, explicitly\nexpressed as a product of irreducible components. This algebraic representation\nis shown to directly generalize, giving high accuracy in test data, more so the\nsmaller the representation. We prove that the number of generalizing\nrepresentations can be very large and the algebra only needs to find one. We\nalso derive and test a relationship between compression and error rate. We give\nresults for a simple problem solved step by step, hand-written character\nrecognition, and the Queens Completion problem as an example of unsupervised\nlearning. As an alternative to statistical learning, algebraic learning may\noffer advantages in combining bottom-up and top-down information, formal\nconcept derivation from data and large-scale parallelization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 13:09:35 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 13:13:24 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Martin-Maroto", "Fernando", ""], ["de Polavieja", "Gonzalo G.", ""]]}, {"id": "1803.05262", "submitter": "William Woof", "authors": "William Woof and Ke Chen", "title": "Learning to Play General Video-Games via an Object Embedding Network", "comments": "To appear in IEEE CIG2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has proven to be an effective tool for\ncreating general video-game AI. However most current DRL video-game agents\nlearn end-to-end from the video-output of the game, which is superfluous for\nmany applications and creates a number of additional problems. More\nimportantly, directly working on pixel-based raw video data is substantially\ndistinct from what a human player does.In this paper, we present a novel method\nwhich enables DRL agents to learn directly from object information. This is\nobtained via use of an object embedding network (OEN) that compresses a set of\nobject feature vectors of different lengths into a single fixed-length unified\nfeature vector representing the current game-state and fulfills the DRL\nsimultaneously. We evaluate our OEN-based DRL agent by comparing to several\nstate-of-the-art approaches on a selection of games from the GVG-AI\nCompetition. Experimental results suggest that our object-based DRL agent\nyields performance comparable to that of those approaches used in our\ncomparative study.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 13:26:44 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 11:25:06 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Woof", "William", ""], ["Chen", "Ke", ""]]}, {"id": "1803.05288", "submitter": "Elif Vural", "authors": "Mehmet Pilanci, Elif Vural", "title": "Domain Adaptation on Graphs by Learning Aligned Graph Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in semi-supervised learning with graph models is that the\nclass label function varies smoothly on the data graph, resulting in the rather\nstrict prior that the label function has low-frequency content. Meanwhile, in\nmany classification problems, the label function may vary abruptly in certain\ngraph regions, resulting in high-frequency components. Although the\nsemi-supervised estimation of class labels is an ill-posed problem in general,\nin several applications it is possible to find a source graph on which the\nlabel function has similar frequency content to that on the target graph where\nthe actual classification problem is defined. In this paper, we propose a\nmethod for domain adaptation on graphs motivated by these observations. Our\nalgorithm is based on learning the spectrum of the label function in a source\ngraph with many labeled nodes, and transferring the information of the spectrum\nto the target graph with fewer labeled nodes. While the frequency content of\nthe class label function can be identified through the graph Fourier transform,\nit is not easy to transfer the Fourier coefficients directly between the two\ngraphs, since no one-to-one match exists between the Fourier basis vectors of\nindependently constructed graphs in the domain adaptation setting. We solve\nthis problem by learning a transformation between the Fourier bases of the two\ngraphs that flexibly ``aligns'' them. The unknown class label function on the\ntarget graph is then reconstructed such that its spectrum matches that on the\nsource graph while also ensuring the consistency with the available labels. The\nproposed method is tested in the classification of image, online product\nreview, and social network data sets. Comparative experiments suggest that the\nproposed algorithm performs better than recent domain adaptation methods in the\nliterature in most settings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 14:04:04 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 11:30:59 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 15:38:55 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Pilanci", "Mehmet", ""], ["Vural", "Elif", ""]]}, {"id": "1803.05307", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Oleg Kudashev, Vadim Schemelinin, Ivan Kremnev and\n  Galina Lavrentyeva", "title": "Deep CNN based feature extractor for text-prompted speaker recognition", "comments": "Submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 10:59:24 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Novoselov", "Sergey", ""], ["Kudashev", "Oleg", ""], ["Schemelinin", "Vadim", ""], ["Kremnev", "Ivan", ""], ["Lavrentyeva", "Galina", ""]]}, {"id": "1803.05337", "submitter": "Micha\\\"el Defferrard", "authors": "Micha\\\"el Defferrard, Sharada P. Mohanty, Sean F. Carroll, Marcel\n  Salath\\'e", "title": "Learning to Recognize Musical Genre from Audio", "comments": "submitted to WWW'18 after challenge round-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We here summarize our experience running a challenge with open data for\nmusical genre recognition. Those notes motivate the task and the challenge\ndesign, show some statistics about the submissions, and present the results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:58:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Defferrard", "Micha\u00ebl", ""], ["Mohanty", "Sharada P.", ""], ["Carroll", "Sean F.", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "1803.05339", "submitter": "Yilong Yang", "authors": "Run Han, Yilong Yang, Xiaoshan Li, Defang Ouyang", "title": "Predicting Oral Disintegrating Tablet Formulations by Neural Network\n  Techniques", "comments": "This is a post-peer-review, pre-copyedit version of an article\n  published in Asian Journal of Pharmaceutical Sciences. The final\n  authenticated version is available online at:\n  https://doi.org/10.1016/j.ajps.2018.01.003", "journal-ref": null, "doi": "10.1016/j.ajps.2018.01.003", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oral Disintegrating Tablets (ODTs) is a novel dosage form that can be\ndissolved on the tongue within 3min or less especially for geriatric and\npediatric patients. Current ODT formulation studies usually rely on the\npersonal experience of pharmaceutical experts and trial-and-error in the\nlaboratory, which is inefficient and time-consuming. The aim of current\nresearch was to establish the prediction model of ODT formulations with direct\ncompression process by Artificial Neural Network (ANN) and Deep Neural Network\n(DNN) techniques. 145 formulation data were extracted from Web of Science. All\ndata sets were divided into three parts: training set (105 data), validation\nset (20) and testing set (20). ANN and DNN were compared for the prediction of\nthe disintegrating time. The accuracy of the ANN model has reached 85.60%,\n80.00% and 75.00% on the training set, validation set and testing set\nrespectively, whereas that of the DNN model was 85.60%, 85.00% and 80.00%,\nrespectively. Compared with the ANN, DNN showed the better prediction for ODT\nformulations. It is the first time that deep neural network with the improved\ndataset selection algorithm is applied to formulation prediction on small data.\nThe proposed predictive approach could evaluate the critical parameters about\nquality control of formulation, and guide research and process development. The\nimplementation of this prediction model could effectively reduce drug product\ndevelopment timeline and material usage, and proactively facilitate the\ndevelopment of a robust drug product.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:05:11 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Han", "Run", ""], ["Yang", "Yilong", ""], ["Li", "Xiaoshan", ""], ["Ouyang", "Defang", ""]]}, {"id": "1803.05340", "submitter": "Lucas Lamata", "authors": "F. Albarr\\'an-Arriagada, J. C. Retamal, E. Solano, L. Lamata", "title": "Measurement-based adaptation protocol with quantum reinforcement\n  learning", "comments": null, "journal-ref": "Phys. Rev. A 98, 042315 (2018)", "doi": "10.1103/PhysRevA.98.042315", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning employs dynamical algorithms that mimic the human capacity\nto learn, where the reinforcement learning ones are among the most similar to\nhumans in this respect. On the other hand, adaptability is an essential aspect\nto perform any task efficiently in a changing environment, and it is\nfundamental for many purposes, such as natural selection. Here, we propose an\nalgorithm based on successive measurements to adapt one quantum state to a\nreference unknown state, in the sense of achieving maximum overlap. The\nprotocol naturally provides many identical copies of the reference state, such\nthat in each measurement iteration more information about it is obtained. In\nour protocol, we consider a system composed of three parts, the \"environment\"\nsystem, which provides the reference state copies; the register, which is an\nauxiliary subsystem that interacts with the environment to acquire information\nfrom it; and the agent, which corresponds to the quantum state that is adapted\nby digital feedback with input corresponding to the outcome of the measurements\non the register. With this proposal we can achieve an average fidelity between\nthe environment and the agent of more than $90\\% $ with less than $30$\niterations of the protocol. In addition, we extend the formalism to $ d\n$-dimensional states, reaching an average fidelity of around $80\\% $ in less\nthan $400$ iterations for $d=$ 11, for a variety of genuinely quantum and\nsemiclassical states. This work paves the way for the development of quantum\nreinforcement learning protocols using quantum data and for the future\ndeployment of semi-autonomous quantum systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:06:11 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 06:01:22 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Albarr\u00e1n-Arriagada", "F.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""], ["Lamata", "L.", ""]]}, {"id": "1803.05389", "submitter": "Edith Cohen", "authors": "Eliav Buchnik and Edith Cohen and Avinatan Hassidim and Yossi Matias", "title": "Self-Similar Epochs: Value in Arrangement", "comments": "13 pages, published in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of machine learning models is commonly performed through\nstochastic gradient updates on randomly ordered training examples. This\npractice means that sub-epochs comprise of independent random samples of the\ntraining data that may not preserve informative structure present in the full\ndata. We hypothesize that the training can be more effective with {\\em\nself-similar} arrangements that potentially allow each epoch to provide\nbenefits of multiple ones. We study this for \"matrix factorization\" -- the\ncommon task of learning metric embeddings of entities such as queries, videos,\nor words from example pairwise associations. We construct arrangements that\npreserve the weighted Jaccard similarities of rows and columns and\nexperimentally observe training acceleration of 3\\%-37\\% on synthetic and\nrecommendation datasets. Principled arrangements of training examples emerge as\na novel and potentially powerful enhancement to SGD that merits further\nexploration.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:38:14 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 00:38:27 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 08:55:55 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Buchnik", "Eliav", ""], ["Cohen", "Edith", ""], ["Hassidim", "Avinatan", ""], ["Matias", "Yossi", ""]]}, {"id": "1803.05391", "submitter": "Zheng Zhan", "authors": "Yanzhi Wang, Zheng Zhan, Jiayu Li, Jian Tang, Bo Yuan, Liang Zhao,\n  Wujie Wen, Siyue Wang and Xue Lin", "title": "On the Universal Approximation Property and Equivalence of Stochastic\n  Computing-based Neural Networks and Binary Neural Networks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale deep neural networks are both memory intensive and\ncomputation-intensive, thereby posing stringent requirements on the computing\nplatforms. Hardware accelerations of deep neural networks have been extensively\ninvestigated in both industry and academia. Specific forms of binary neural\nnetworks (BNNs) and stochastic computing based neural networks (SCNNs) are\nparticularly appealing to hardware implementations since they can be\nimplemented almost entirely with binary operations. Despite the obvious\nadvantages in hardware implementation, these approximate computing techniques\nare questioned by researchers in terms of accuracy and universal applicability.\nAlso it is important to understand the relative pros and cons of SCNNs and BNNs\nin theory and in actual hardware implementations. In order to address these\nconcerns, in this paper we prove that the \"ideal\" SCNNs and BNNs satisfy the\nuniversal approximation property with probability 1 (due to the stochastic\nbehavior). The proof is conducted by first proving the property for SCNNs from\nthe strong law of large numbers, and then using SCNNs as a \"bridge\" to prove\nfor BNNs. Based on the universal approximation property, we further prove that\nSCNNs and BNNs exhibit the same energy complexity. In other words, they have\nthe same asymptotic energy consumption with the growing of network size. We\nalso provide a detailed analysis of the pros and cons of SCNNs and BNNs for\nhardware implementations and conclude that SCNNs are more suitable for\nhardware.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:40:42 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 17:22:31 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Yanzhi", ""], ["Zhan", "Zheng", ""], ["Li", "Jiayu", ""], ["Tang", "Jian", ""], ["Yuan", "Bo", ""], ["Zhao", "Liang", ""], ["Wen", "Wujie", ""], ["Wang", "Siyue", ""], ["Lin", "Xue", ""]]}, {"id": "1803.05397", "submitter": "Can Karakus", "authors": "Can Karakus, Yifan Sun, Suhas Diggavi, Wotao Yin", "title": "Redundancy Techniques for Straggler Mitigation in Distributed\n  Optimization and Learning", "comments": "39 pages, 14 figures. Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of distributed optimization and learning systems is bottlenecked\nby \"straggler\" nodes and slow communication links, which significantly delay\ncomputation. We propose a distributed optimization framework where the dataset\nis \"encoded\" to have an over-complete representation with built-in redundancy,\nand the straggling nodes in the system are dynamically left out of the\ncomputation at every iteration, whose loss is compensated by the embedded\nredundancy. We show that oblivious application of several popular optimization\nalgorithms on encoded data, including gradient descent, L-BFGS, proximal\ngradient under data parallelism, and coordinate descent under model\nparallelism, converge to either approximate or exact solutions of the original\nproblem when stragglers are treated as erasures. These convergence results are\ndeterministic, i.e., they establish sample path convergence for arbitrary\nsequences of delay patterns or distributions on the nodes, and are independent\nof the tail behavior of the delay distribution. We demonstrate that equiangular\ntight frames have desirable properties as encoding matrices, and propose\nefficient mechanisms for encoding large-scale data. We implement the proposed\ntechnique on Amazon EC2 clusters, and demonstrate its performance over several\nlearning problems, including matrix factorization, LASSO, ridge regression and\nlogistic regression, and compare the proposed method with uncoded,\nasynchronous, and data replication strategies.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:48:08 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Karakus", "Can", ""], ["Sun", "Yifan", ""], ["Diggavi", "Suhas", ""], ["Yin", "Wotao", ""]]}, {"id": "1803.05402", "submitter": "Jack Harmer PhD", "authors": "Jack Harmer, Linus Gissl\\'en, Jorge del Val, Henrik Holst, Joakim\n  Bergdahl, Tom Olsson, Kristoffer Sj\\\"o\\\"o, Magnus Nordin", "title": "Imitation Learning with Concurrent Actions in 3D Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a novel deep reinforcement learning architecture\nthat allows multiple actions to be selected at every time-step in an efficient\nmanner. Multi-action policies allow complex behaviours to be learnt that would\notherwise be hard to achieve when using single action selection techniques. We\nuse both imitation learning and temporal difference (TD) reinforcement learning\n(RL) to provide a 4x improvement in training time and 2.5x improvement in\nperformance over single action selection TD RL. We demonstrate the capabilities\nof this network using a complex in-house 3D game. Mimicking the behavior of the\nexpert teacher significantly improves world state exploration and allows the\nagents vision system to be trained more rapidly than TD RL alone. This initial\ntraining technique kick-starts TD learning and the agent quickly learns to\nsurpass the capabilities of the expert.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:59:17 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 17:35:18 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 20:48:42 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 10:12:40 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 12:16:17 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Harmer", "Jack", ""], ["Gissl\u00e9n", "Linus", ""], ["del Val", "Jorge", ""], ["Holst", "Henrik", ""], ["Bergdahl", "Joakim", ""], ["Olsson", "Tom", ""], ["Sj\u00f6\u00f6", "Kristoffer", ""], ["Nordin", "Magnus", ""]]}, {"id": "1803.05407", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov,\n  Andrew Gordon Wilson", "title": "Averaging Weights Leads to Wider Optima and Better Generalization", "comments": "Appears at the Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much flatter solutions than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 17:09:27 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 08:49:15 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 14:18:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Izmailov", "Pavel", ""], ["Podoprikhin", "Dmitrii", ""], ["Garipov", "Timur", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1803.05419", "submitter": "John Alexander Harston", "authors": "Thomas Teh, Chaiyawan Auepanwiriyakul, John Alexander Harston, A. Aldo\n  Faisal", "title": "Generalised Structural CNNs (SCNNs) for time series data with arbitrary\n  graph topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning methods, specifically convolutional neural networks (CNNs),\nhave seen a lot of success in the domain of image-based data, where the data\noffers a clearly structured topology in the regular lattice of pixels. This\n4-neighbourhood topological simplicity makes the application of convolutional\nmasks straightforward for time series data, such as video applications, but\nmany high-dimensional time series data are not organised in regular lattices,\nand instead values may have adjacency relationships with non-trivial\ntopologies, such as small-world networks or trees. In our application case,\nhuman kinematics, it is currently unclear how to generalise convolutional\nkernels in a principled manner. Therefore we define and implement here a\nframework for general graph-structured CNNs for time series analysis. Our\nalgorithm automatically builds convolutional layers using the specified\nadjacency matrix of the data dimensions and convolutional masks that scale with\nthe hop distance. In the limit of a lattice-topology our method produces the\nwell-known image convolutional masks. We test our method first on synthetic\ndata of arbitrarily-connected graphs and human hand motion capture data, where\nthe hand is represented by a tree capturing the mechanical dependencies of the\njoints. We are able to demonstrate, amongst other things, that inclusion of the\ngraph structure of the data dimensions improves model prediction significantly,\nwhen compared against a benchmark CNN model with only time convolution layers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 17:39:11 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 17:23:12 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Teh", "Thomas", ""], ["Auepanwiriyakul", "Chaiyawan", ""], ["Harston", "John Alexander", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1803.05428", "submitter": "Adam Roberts", "authors": "Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, Douglas Eck", "title": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in\n  Music", "comments": "ICML Camera Ready Version (w/ fixed typos)", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) has proven to be an effective model for\nproducing semantically meaningful latent representations for natural data.\nHowever, it has thus far seen limited application to sequential data, and, as\nwe demonstrate, existing recurrent VAE models have difficulty modeling\nsequences with long-term structure. To address this issue, we propose the use\nof a hierarchical decoder, which first outputs embeddings for subsequences of\nthe input and then uses these embeddings to generate each subsequence\nindependently. This structure encourages the model to utilize its latent code,\nthereby avoiding the \"posterior collapse\" problem, which remains an issue for\nrecurrent VAEs. We apply this architecture to modeling sequences of musical\nnotes and find that it exhibits dramatically better sampling, interpolation,\nand reconstruction performance than a \"flat\" baseline model. An implementation\nof our \"MusicVAE\" is available online at http://g.co/magenta/musicvae-code.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:14:46 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 03:51:30 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 18:26:14 GMT"}, {"version": "v4", "created": "Mon, 30 Jul 2018 20:53:57 GMT"}, {"version": "v5", "created": "Mon, 11 Nov 2019 12:38:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Roberts", "Adam", ""], ["Engel", "Jesse", ""], ["Raffel", "Colin", ""], ["Hawthorne", "Curtis", ""], ["Eck", "Douglas", ""]]}, {"id": "1803.05473", "submitter": "Ioakeim Perros", "authors": "Ioakeim Perros, Evangelos E. Papalexakis, Haesun Park, Richard Vuduc,\n  Xiaowei Yan, Christopher Defilippi, Walter F. Stewart, Jimeng Sun", "title": "SUSTain: Scalable Unsupervised Scoring for Tensors and its Application\n  to Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method, which we call SUSTain, that extends\nreal-valued matrix and tensor factorizations to data where values are integers.\nSuch data are common when the values correspond to event counts or ordinal\nmeasures. The conventional approach is to treat integer data as real, and then\napply real-valued factorizations. However, doing so fails to preserve important\ncharacteristics of the original data, thereby making it hard to interpret the\nresults. Instead, our approach extracts factor values from integer datasets as\nscores that are constrained to take values from a small integer set. These\nscores are easy to interpret: a score of zero indicates no feature contribution\nand higher scores indicate distinct levels of feature importance.\n  At its core, SUSTain relies on: a) a problem partitioning into\ninteger-constrained subproblems, so that they can be optimally solved in an\nefficient manner; and b) organizing the order of the subproblems' solution, to\npromote reuse of shared intermediate results. We propose two variants,\nSUSTain_M and SUSTain_T, to handle both matrix and tensor inputs, respectively.\nWe evaluate SUSTain against several state-of-the-art baselines on both\nsynthetic and real Electronic Health Record (EHR) datasets. Comparing to those\nbaselines, SUSTain shows either significantly better fit or orders of magnitude\nspeedups that achieve a comparable fit (up to 425X faster). We apply SUSTain to\nEHR datasets to extract patient phenotypes (i.e., clinically meaningful patient\nclusters). Furthermore, 87% of them were validated as clinically meaningful\nphenotypes related to heart failure by a cardiologist.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:53:56 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Perros", "Ioakeim", ""], ["Papalexakis", "Evangelos E.", ""], ["Park", "Haesun", ""], ["Vuduc", "Richard", ""], ["Yan", "Xiaowei", ""], ["Defilippi", "Christopher", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.05554", "submitter": "Raj Agrawal", "authors": "Raj Agrawal and Tamara Broderick and Caroline Uhler", "title": "Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models", "comments": "Proceedings of the 30th International Conference on Machine Learning.\n  2018, to appear. 16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Bayesian network (BN) from data can be useful for decision-making\nor discovering causal relationships. However, traditional methods often fail in\nmodern applications, which exhibit a larger number of observed variables than\ndata points. The resulting uncertainty about the underlying network as well as\nthe desire to incorporate prior information recommend a Bayesian approach to\nlearning the BN, but the highly combinatorial structure of BNs poses a striking\nchallenge for inference. The current state-of-the-art methods such as order\nMCMC are faster than previous methods but prevent the use of many natural\nstructural priors and still have running time exponential in the maximum\nindegree of the true directed acyclic graph (DAG) of the BN. We here propose an\nalternative posterior approximation based on the observation that, if we\nincorporate empirical conditional independence tests, we can focus on a\nhigh-probability DAG associated with each order of the vertices. We show that\nour method allows the desired flexibility in prior specification, removes\ntiming dependence on the maximum indegree and yields provably good posterior\napproximations; in addition, we show that it achieves superior accuracy,\nscalability, and sampler mixing on several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 00:53:25 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 23:44:43 GMT"}, {"version": "v3", "created": "Sun, 24 Jun 2018 15:52:36 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Agrawal", "Raj", ""], ["Broderick", "Tamara", ""], ["Uhler", "Caroline", ""]]}, {"id": "1803.05573", "submitter": "Tim Salimans", "authors": "Tim Salimans, Han Zhang, Alec Radford, Dimitris Metaxas", "title": "Improving GANs Using Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Transport GAN (OT-GAN), a variant of generative\nadversarial nets minimizing a new metric measuring the distance between the\ngenerator distribution and the data distribution. This metric, which we call\nmini-batch energy distance, combines optimal transport in primal form with an\nenergy distance defined in an adversarially learned feature space, resulting in\na highly discriminative distance function with unbiased mini-batch gradients.\nExperimentally we show OT-GAN to be highly stable when trained with large\nmini-batches, and we present state-of-the-art results on several popular\nbenchmark problems for image generation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 02:34:46 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Salimans", "Tim", ""], ["Zhang", "Han", ""], ["Radford", "Alec", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1803.05591", "submitter": "Rahul Kidambi", "authors": "Rahul Kidambi, Praneeth Netrapalli, Prateek Jain and Sham M. Kakade", "title": "On the insufficiency of existing momentum schemes for Stochastic\n  Optimization", "comments": "28 pages, 10 figures. Updated acknowledgements. Appeared as an oral\n  presentation at International Conference on Learning Representations (ICLR),\n  2018. Code implementing the ASGD method can be found at\n  https://github.com/rahulkidambi/AccSGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum based stochastic gradient methods such as heavy ball (HB) and\nNesterov's accelerated gradient descent (NAG) method are widely used in\npractice for training deep networks and other supervised learning models, as\nthey often provide significant improvements over stochastic gradient descent\n(SGD). Rigorously speaking, \"fast gradient\" methods have provable improvements\nover gradient descent only for the deterministic case, where the gradients are\nexact. In the stochastic case, the popular explanations for their wide\napplicability is that when these fast gradient methods are applied in the\nstochastic case, they partially mimic their exact gradient counterparts,\nresulting in some practical gain. This work provides a counterpoint to this\nbelief by proving that there exist simple problem instances where these methods\ncannot outperform SGD despite the best setting of its parameters. These\nnegative problem instances are, in an informal sense, generic; they do not look\nlike carefully constructed pathological instances. These results suggest (along\nwith empirical evidence) that HB or NAG's practical performance gains are a\nby-product of mini-batching.\n  Furthermore, this work provides a viable (and provable) alternative, which,\non the same set of problem instances, significantly improves over HB, NAG, and\nSGD's performance. This algorithm, referred to as Accelerated Stochastic\nGradient Descent (ASGD), is a simple to implement stochastic algorithm, based\non a relatively less popular variant of Nesterov's Acceleration. Extensive\nempirical results in this paper show that ASGD has performance gains over HB,\nNAG, and SGD.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 05:09:51 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 18:18:05 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Kidambi", "Rahul", ""], ["Netrapalli", "Praneeth", ""], ["Jain", "Prateek", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1803.05598", "submitter": "Hossein Mobahi", "authors": "Gamaleldin F. Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan,\n  Samy Bengio", "title": "Large Margin Deep Networks for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formulation of deep learning that aims at producing a large\nmargin classifier. The notion of margin, minimum distance to a decision\nboundary, has served as the foundation of several theoretically profound and\nempirically successful results for both classification and regression tasks.\nHowever, most large margin algorithms are applicable only to shallow models\nwith a preset feature representation; and conventional margin methods for\nneural networks only enforce margin at the output layer. Such methods are\ntherefore not well suited for deep networks.\n  In this work, we propose a novel loss function to impose a margin on any\nchosen set of layers of a deep network (including input and hidden layers). Our\nformulation allows choosing any norm on the metric measuring the margin. We\ndemonstrate that the decision boundary obtained by our loss has nice properties\ncompared to standard classification loss functions. Specifically, we show\nimproved empirical results on the MNIST, CIFAR-10 and ImageNet datasets on\nmultiple tasks: generalization from small training sets, corrupted labels, and\nrobustness against adversarial perturbations. The resulting loss is general and\ncomplementary to existing data augmentation (such as random/adversarial input\ntransform) and regularization techniques (such as weight decay, dropout, and\nbatch norm).\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 05:33:13 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 01:36:40 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Krishnan", "Dilip", ""], ["Mobahi", "Hossein", ""], ["Regan", "Kevin", ""], ["Bengio", "Samy", ""]]}, {"id": "1803.05605", "submitter": "Vinay Praneeth Boda", "authors": "Vinay Praneeth Boda", "title": "Reconstructing Gaussian sources by spatial sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a Gaussian memoryless multiple source with $m$ components with joint\nprobability distribution known only to lie in a given class of distributions. A\nsubset of $k \\leq m$ components are sampled and compressed with the objective\nof reconstructing all the $m$ components within a specified level of distortion\nunder a mean-squared error criterion. In Bayesian and nonBayesian settings, the\nnotion of universal sampling rate distortion function for Gaussian sources is\nintroduced to capture the optimal tradeoffs among sampling, compression rate\nand distortion level. Single-letter characterizations are provided for the\nuniversal sampling rate distortion function. Our achievability proofs highlight\nthe following structural property: it is optimal to compress and reconstruct\nfirst the sampled components of the GMMS alone, and then form estimates for the\nunsampled components based on the former.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 05:58:37 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Boda", "Vinay Praneeth", ""]]}, {"id": "1803.05621", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Gong-Duo Zhang, Ming-Wei Li, Wu-Jun Li", "title": "Proximal SCOPE for Distributed Sparse Learning: Better Data Partition\n  Implies Faster Convergence Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed sparse learning with a cluster of multiple machines has attracted\nmuch attention in machine learning, especially for large-scale applications\nwith high-dimensional data. One popular way to implement sparse learning is to\nuse $L_1$ regularization. In this paper, we propose a novel method, called\nproximal \\mbox{SCOPE}~(\\mbox{pSCOPE}), for distributed sparse learning with\n$L_1$ regularization. pSCOPE is based on a \\underline{c}ooperative\n\\underline{a}utonomous \\underline{l}ocal \\underline{l}earning~(\\mbox{CALL})\nframework. In the \\mbox{CALL} framework of \\mbox{pSCOPE}, we find that the data\npartition affects the convergence of the learning procedure, and subsequently\nwe define a metric to measure the goodness of a data partition. Based on the\ndefined metric, we theoretically prove that pSCOPE is convergent with a linear\nconvergence rate if the data partition is good enough. We also prove that\nbetter data partition implies faster convergence rate. Furthermore, pSCOPE is\nalso communication efficient. Experimental results on real data sets show that\npSCOPE can outperform other state-of-the-art distributed methods for sparse\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 07:38:50 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 16:34:29 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Zhang", "Gong-Duo", ""], ["Li", "Ming-Wei", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1803.05649", "submitter": "Jakub Tomczak Ph.D.", "authors": "Rianne van den Berg and Leonard Hasenclever and Jakub M. Tomczak and\n  Max Welling", "title": "Sylvester Normalizing Flows for Variational Inference", "comments": "Published at UAI 2018, 12 pages, 3 figures, code at:\n  https://github.com/riannevdberg/sylvester-flows", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference relies on flexible approximate posterior distributions.\nNormalizing flows provide a general recipe to construct flexible variational\nposteriors. We introduce Sylvester normalizing flows, which can be seen as a\ngeneralization of planar flows. Sylvester normalizing flows remove the\nwell-known single-unit bottleneck from planar flows, making a single\ntransformation much more flexible. We compare the performance of Sylvester\nnormalizing flows against planar flows and inverse autoregressive flows and\ndemonstrate that they compare favorably on several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:15:14 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 18:36:23 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Berg", "Rianne van den", ""], ["Hasenclever", "Leonard", ""], ["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1803.05657", "submitter": "Lei Zhou", "authors": "Lei Zhou, Xiao Bai, Xianglong Liu, Jun Zhou and Hancock Edwin", "title": "Fast Subspace Clustering Based on the Kronecker Product", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a useful technique for many computer vision\napplications in which the intrinsic dimension of high-dimensional data is often\nsmaller than the ambient dimension. Spectral clustering, as one of the main\napproaches to subspace clustering, often takes on a sparse representation or a\nlow-rank representation to learn a block diagonal self-representation matrix\nfor subspace generation. However, existing methods require solving a large\nscale convex optimization problem with a large set of data, with computational\ncomplexity reaches O(N^3) for N data points. Therefore, the efficiency and\nscalability of traditional spectral clustering methods can not be guaranteed\nfor large scale datasets. In this paper, we propose a subspace clustering model\nbased on the Kronecker product. Due to the property that the Kronecker product\nof a block diagonal matrix with any other matrix is still a block diagonal\nmatrix, we can efficiently learn the representation matrix which is formed by\nthe Kronecker product of k smaller matrices. By doing so, our model\nsignificantly reduces the computational complexity to O(kN^{3/k}). Furthermore,\nour model is general in nature, and can be adapted to different regularization\nbased subspace clustering methods. Experimental results on two public datasets\nshow that our model significantly improves the efficiency compared with several\nstate-of-the-art methods. Moreover, we have conducted experiments on synthetic\ndata to verify the scalability of our model for large scale datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:31:44 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Zhou", "Lei", ""], ["Bai", "Xiao", ""], ["Liu", "Xianglong", ""], ["Zhou", "Jun", ""], ["Edwin", "Hancock", ""]]}, {"id": "1803.05675", "submitter": "Panagiotis Meletis", "authors": "Panagiotis Meletis, Gijs Dubbelman", "title": "Training of Convolutional Networks on Multiple Heterogeneous Datasets\n  for Street Scene Semantic Segmentation", "comments": "IEEE Intelligent Vehicles 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convolutional network with hierarchical classifiers for\nper-pixel semantic segmentation, which is able to be trained on multiple,\nheterogeneous datasets and exploit their semantic hierarchy. Our network is the\nfirst to be simultaneously trained on three different datasets from the\nintelligent vehicles domain, i.e. Cityscapes, GTSDB and Mapillary Vistas, and\nis able to handle different semantic level-of-detail, class imbalances, and\ndifferent annotation types, i.e. dense per-pixel and sparse bounding-box\nlabels. We assess our hierarchical approach, by comparing against flat,\nnon-hierarchical classifiers and we show improvements in mean pixel accuracy of\n13.0% for Cityscapes classes and 2.4% for Vistas classes and 32.3% for GTSDB\nclasses. Our implementation achieves inference rates of 17 fps at a resolution\nof 520x706 for 108 classes running on a GPU.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 10:24:43 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 14:04:13 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Meletis", "Panagiotis", ""], ["Dubbelman", "Gijs", ""]]}, {"id": "1803.05752", "submitter": "Weihao Yuan", "authors": "Weihao Yuan, Johannes A. Stork, Danica Kragic, Michael Y. Wang and\n  Kaiyu Hang", "title": "Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement\n  Learning", "comments": "2018 International Conference on Robotics and Automation", "journal-ref": null, "doi": "10.1109/ICRA.2018.8462863", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rearranging objects on a tabletop surface by means of nonprehensile\nmanipulation is a task which requires skillful interaction with the physical\nworld. Usually, this is achieved by precisely modeling physical properties of\nthe objects, robot, and the environment for explicit planning. In contrast, as\nexplicitly modeling the physical environment is not always feasible and\ninvolves various uncertainties, we learn a nonprehensile rearrangement strategy\nwith deep reinforcement learning based on only visual feedback. For this, we\nmodel the task with rewards and train a deep Q-network. Our potential\nfield-based heuristic exploration strategy reduces the amount of collisions\nwhich lead to suboptimal outcomes and we actively balance the training set to\navoid bias towards poor examples. Our training process leads to quicker\nlearning and better performance on the task as compared to uniform exploration\nand standard experience replay. We demonstrate empirical evidence from\nsimulation that our method leads to a success rate of 85%, show that our system\ncan cope with sudden changes of the environment, and compare our performance\nwith human level performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:00:24 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Yuan", "Weihao", ""], ["Stork", "Johannes A.", ""], ["Kragic", "Danica", ""], ["Wang", "Michael Y.", ""], ["Hang", "Kaiyu", ""]]}, {"id": "1803.05768", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Jesse Davis, Steven Schockaert", "title": "PAC-Reasoning in Relational Domains", "comments": "Longer version of paper appearing in UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting plausible missing facts in relational\ndata, given a set of imperfect logical rules. In particular, our aim is to\nprovide bounds on the (expected) number of incorrect inferences that are made\nin this way. Since for classical inference it is in general impossible to bound\nthis number in a non-trivial way, we consider two inference relations that\nweaken, but remain close in spirit to classical inference.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:20:06 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 11:59:27 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 13:37:05 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Davis", "Jesse", ""], ["Schockaert", "Steven", ""]]}, {"id": "1803.05776", "submitter": "Arun Venkitaraman", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\\\"andel", "title": "Gaussian Processes Over Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Gaussian processes for signals over graphs (GPG) using the apriori\nknowledge that the target vectors lie over a graph. We incorporate this\ninformation using a graph- Laplacian based regularization which enforces the\ntarget vectors to have a specific profile in terms of graph Fourier transform\ncoeffcients, for example lowpass or bandpass graph signals. We discuss how the\nregularization affects the mean and the variance in the prediction output. In\nparticular, we prove that the predictive variance of the GPG is strictly\nsmaller than the conventional Gaussian process (GP) for any non-trivial graph.\nWe validate our concepts by application to various real-world graph signals.\nOur experiments show that the performance of the GPG is superior to GP for\nsmall training data sizes and under noisy training.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:27:49 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 10:30:30 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""], ["H\u00e4ndel", "Peter", ""]]}, {"id": "1803.05796", "submitter": "Karlson Pfannschmidt", "authors": "Karlson Pfannschmidt, Pritha Gupta, Eyke H\\\"ullermeier", "title": "Deep Architectures for Learning Context-dependent Ranking Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object ranking is an important problem in the realm of preference learning.\nOn the basis of training data in the form of a set of rankings of objects,\nwhich are typically represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects.\nCurrent approaches commonly focus on ranking by scoring, i.e., on learning an\nunderlying latent utility function that seeks to capture the inherent utility\nof each object. These approaches, however, are not able to take possible\neffects of context-dependence into account, where context-dependence means that\nthe utility or usefulness of an object may also depend on what other objects\nare available as alternatives. In this paper, we formalize the problem of\ncontext-dependent ranking and present two general approaches based on two\nnatural representations of context-dependent ranking functions. Both approaches\nare instantiated by means of appropriate neural network architectures, which\nare evaluated on suitable benchmark task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:14:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 16:44:26 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pfannschmidt", "Karlson", ""], ["Gupta", "Pritha", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1803.05814", "submitter": "Vitaly Kuznetsov", "authors": "Vitaly Kuznetsov and Mehryar Mohri", "title": "Theory and Algorithms for Forecasting Time Series", "comments": "An extended abstract has appeared in (Kuznetsov and Mohri, 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present data-dependent learning bounds for the general scenario of\nnon-stationary non-mixing stochastic processes. Our learning guarantees are\nexpressed in terms of a data-dependent measure of sequential complexity and a\ndiscrepancy measure that can be estimated from data under some mild\nassumptions. We also also provide novel analysis of stable time series\nforecasting algorithm using this new notion of discrepancy that we introduce.\nWe use our learning bounds to devise new algorithms for non-stationary time\nseries forecasting for which we report some preliminary experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:37:40 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Kuznetsov", "Vitaly", ""], ["Mohri", "Mehryar", ""]]}, {"id": "1803.05827", "submitter": "Chu Wang", "authors": "Chu Wang, Babak Samari, Kaleem Siddiqi", "title": "Local Spectral Graph Convolution for Point Set Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature learning on point clouds has shown great promise, with the\nintroduction of effective and generalizable deep learning frameworks such as\npointnet++. Thus far, however, point features have been abstracted in an\nindependent and isolated manner, ignoring the relative layout of neighboring\npoints as well as their features. In the present article, we propose to\novercome this limitation by using spectral graph convolution on a local graph,\ncombined with a novel graph pooling strategy. In our approach, graph\nconvolution is carried out on a nearest neighbor graph constructed from a\npoint's neighborhood, such that features are jointly learned. We replace the\nstandard max pooling step with a recursive clustering and pooling strategy,\ndevised to aggregate information from within clusters of nodes that are close\nto one another in their spectral coordinates, leading to richer overall feature\ndescriptors. Through extensive experiments on diverse datasets, we show a\nconsistent demonstrable advantage for the tasks of both point set\nclassification and segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 16:00:50 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Wang", "Chu", ""], ["Samari", "Babak", ""], ["Siddiqi", "Kaleem", ""]]}, {"id": "1803.05847", "submitter": "Lingxiao Wei", "authors": "Lingxiao Wei, Bo Luo, Yu Li, Yannan Liu and Qiang Xu", "title": "I Know What You See: Power Side-Channel Attack on Convolutional Neural\n  Network Accelerators", "comments": null, "journal-ref": null, "doi": "10.1145/3274694.3274696", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become the de-facto computational paradigm for various\nkinds of perception problems, including many privacy-sensitive applications\nsuch as online medical image analysis. No doubt to say, the data privacy of\nthese deep learning systems is a serious concern. Different from previous\nresearch focusing on exploiting privacy leakage from deep learning models, in\nthis paper, we present the first attack on the implementation of deep learning\nmodels. To be specific, we perform the attack on an FPGA-based convolutional\nneural network accelerator and we manage to recover the input image from the\ncollected power traces without knowing the detailed parameters in the neural\nnetwork. For the MNIST dataset, our power side-channel attack is able to\nachieve up to 89% recognition accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 11:35:14 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 15:11:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wei", "Lingxiao", ""], ["Luo", "Bo", ""], ["Li", "Yu", ""], ["Liu", "Yannan", ""], ["Xu", "Qiang", ""]]}, {"id": "1803.05848", "submitter": "Zhiyang Liu", "authors": "Zhiyang Liu, Chen Cao, Shuxue Ding, Tong Han, Hong Wu, Sheng Liu", "title": "Towards Clinical Diagnosis: Automated Stroke Lesion Segmentation on\n  Multimodal MR Image Using Convolutional Neural Network", "comments": "submitted to Neuroimage: Clinical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The patient with ischemic stroke can benefit most from the earliest possible\ndefinitive diagnosis. While the high quality medical resources are quite scarce\nacross the globe, an automated diagnostic tool is expected in analyzing the\nmagnetic resonance (MR) images to provide reference in clinical diagnosis. In\nthis paper, we propose a deep learning method to automatically segment ischemic\nstroke lesions from multi-modal MR images. By using atrous convolution and\nglobal convolution network, our proposed residual-structured fully\nconvolutional network (Res-FCN) is able to capture features from large\nreceptive fields. The network architecture is validated on a large dataset of\n212 clinically acquired multi-modal MR images, which is shown to achieve a mean\ndice coefficient of 0.645 with a mean number of false negative lesions of\n1.515. The false negatives can reach a value that close to a common medical\nimage doctor, making it exceptive for a real clinical application.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 14:27:41 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Liu", "Zhiyang", ""], ["Cao", "Chen", ""], ["Ding", "Shuxue", ""], ["Han", "Tong", ""], ["Wu", "Hong", ""], ["Liu", "Sheng", ""]]}, {"id": "1803.05867", "submitter": "Daniel Emaasit", "authors": "Daniel Emaasit, Matthew Johnson", "title": "Capturing Structure Implicitly from Time-Series having Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific fields such as insider-threat detection and highway-safety\nplanning often lack sufficient amounts of time-series data to estimate\nstatistical models for the purpose of scientific discovery. Moreover, the\navailable limited data are quite noisy. This presents a major challenge when\nestimating time-series models that are robust to overfitting and have\nwell-calibrated uncertainty estimates. Most of the current literature in these\nfields involve visualizing the time-series for noticeable structure and hard\ncoding them into pre-specified parametric functions. This approach is\nassociated with two limitations. First, given that such trends may not be\neasily noticeable in small data, it is difficult to explicitly incorporate\nexpressive structure into the models during formulation. Second, it is\ndifficult to know $\\textit{a priori}$ the most appropriate functional form to\nuse. To address these limitations, a nonparametric Bayesian approach was\nproposed to implicitly capture hidden structure from time series having limited\ndata. The proposed model, a Gaussian process with a spectral mixture kernel,\nprecludes the need to pre-specify a functional form and hard code trends, is\nrobust to overfitting and has well-calibrated uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:03:04 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Emaasit", "Daniel", ""], ["Johnson", "Matthew", ""]]}, {"id": "1803.05871", "submitter": "Fengyi Tang", "authors": "Jiayu Zhou, Fengyi Tang, He Zhu, Ning Nan, Ziheng Zhou", "title": "Distributed Data Vending on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in blockchain technologies have provided exciting\nopportunities for decentralized applications. Specifically, blockchain-based\nsmart contracts enable credible transactions without authorized third parties.\nThe attractive properties of smart contracts facilitate distributed data\nvending, allowing for proprietary data to be securely exchanged on a\nblockchain. Distributed data vending can transform domains such as healthcare\nby encouraging data distribution from owners and enabling large-scale data\naggregation. However, one key challenge in distributed data vending is the\ntrade-off dilemma between the effectiveness of data retrieval, and the leakage\nrisk from indexing the data. In this paper, we propose a framework for\ndistributed data vending through a combination of data embedding and similarity\nlearning. We illustrate our framework through a practical scenario of\ndistributing and aggregating electronic medical records on a blockchain.\nExtensive empirical results demonstrate the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:10:16 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 03:55:35 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zhou", "Jiayu", ""], ["Tang", "Fengyi", ""], ["Zhu", "He", ""], ["Nan", "Ning", ""], ["Zhou", "Ziheng", ""]]}, {"id": "1803.05880", "submitter": "Jeffrey Daily", "authors": "Jeff Daily, Abhinav Vishnu, Charles Siegel, Thomas Warfel, Vinay\n  Amatya", "title": "GossipGraD: Scalable Deep Learning using Gossip Communication based\n  Asynchronous Gradient Descent", "comments": "13 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present GossipGraD - a gossip communication protocol based\nStochastic Gradient Descent (SGD) algorithm for scaling Deep Learning (DL)\nalgorithms on large-scale systems. The salient features of GossipGraD are: 1)\nreduction in overall communication complexity from {\\Theta}(log(p)) for p\ncompute nodes in well-studied SGD to O(1), 2) model diffusion such that compute\nnodes exchange their updates (gradients) indirectly after every log(p) steps,\n3) rotation of communication partners for facilitating direct diffusion of\ngradients, 4) asynchronous distributed shuffle of samples during the\nfeedforward phase in SGD to prevent over-fitting, 5) asynchronous communication\nof gradients for further reducing the communication cost of SGD and GossipGraD.\nWe implement GossipGraD for GPU and CPU clusters and use NVIDIA GPUs (Pascal\nP100) connected with InfiniBand, and Intel Knights Landing (KNL) connected with\nAries network. We evaluate GossipGraD using well-studied dataset ImageNet-1K\n(~250GB), and widely studied neural network topologies such as GoogLeNet and\nResNet50 (current winner of ImageNet Large Scale Visualization Research\nChallenge (ILSVRC)). Our performance evaluation using both KNL and Pascal GPUs\nindicates that GossipGraD can achieve perfect efficiency for these datasets and\ntheir associated neural network topologies. Specifically, for ResNet50,\nGossipGraD is able to achieve ~100% compute efficiency using 128 NVIDIA Pascal\nP100 GPUs - while matching the top-1 classification accuracy published in\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:32:16 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Daily", "Jeff", ""], ["Vishnu", "Abhinav", ""], ["Siegel", "Charles", ""], ["Warfel", "Thomas", ""], ["Amatya", "Vinay", ""]]}, {"id": "1803.05900", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris, Alexandros Kouris, Christos-Savvas Bouganis", "title": "Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey\n  and Future Directions", "comments": "Accepted for publication at the ACM Computing Surveys (CSUR) journal,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, Convolutional Neural Networks (CNNs) have demonstrated\nstate-of-the-art performance in various Artificial Intelligence tasks. To\naccelerate the experimentation and development of CNNs, several software\nframeworks have been released, primarily targeting power-hungry CPUs and GPUs.\nIn this context, reconfigurable hardware in the form of FPGAs constitutes a\npotential alternative platform that can be integrated in the existing deep\nlearning ecosystem to provide a tunable balance between performance, power\nconsumption and programmability. In this paper, a survey of the existing\nCNN-to-FPGA toolflows is presented, comprising a comparative study of their key\ncharacteristics which include the supported applications, architectural\nchoices, design space exploration methods and achieved performance. Moreover,\nmajor challenges and objectives introduced by the latest trends in CNN\nalgorithmic research are identified and presented. Finally, a uniform\nevaluation methodology is proposed, aiming at the comprehensive, complete and\nin-depth evaluation of CNN-to-FPGA toolflows.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 17:58:19 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Kouris", "Alexandros", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1803.05976", "submitter": "Alejandro Mottini", "authors": "Alejandro Mottini, Rodrigo Acuna-Agost", "title": "Deep Choice Model Using Pointer Networks for Airline Itinerary\n  Prediction", "comments": null, "journal-ref": "KDD 2017, Proceedings of the 23rd ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining, Pages 1575-1583", "doi": "10.1145/3097983.3098005", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel providers such as airlines and on-line travel agents are becoming more\nand more interested in understanding how passengers choose among alternative\nitineraries when searching for flights. This knowledge helps them better\ndisplay and adapt their offer, taking into account market conditions and\ncustomer needs. Some common applications are not only filtering and sorting\nalternatives, but also changing certain attributes in real-time (e.g., changing\nthe price). In this paper, we concentrate with the problem of modeling air\npassenger choices of flight itineraries. This problem has historically been\ntackled using classical Discrete Choice Modelling techniques. Traditional\nstatistical approaches, in particular the Multinomial Logit model (MNL), is\nwidely used in industrial applications due to its simplicity and general good\nperformance. However, MNL models present several shortcomings and assumptions\nthat might not hold in real applications. To overcome these difficulties, we\npresent a new choice model based on Pointer Networks. Given an input sequence,\nthis type of deep neural architecture combines Recurrent Neural Networks with\nthe Attention Mechanism to learn the conditional probability of an output whose\nvalues correspond to positions in an input sequence. Therefore, given a\nsequence of different alternatives presented to a customer, the model can learn\nto point to the one most likely to be chosen by the customer. The proposed\nmethod was evaluated on a real dataset that combines on-line user search logs\nand airline flight bookings. Experimental results show that the proposed model\noutperforms the traditional MNL model on several metrics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 19:55:56 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mottini", "Alejandro", ""], ["Acuna-Agost", "Rodrigo", ""]]}, {"id": "1803.05985", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena Cukic, David Pokrajac, Miodrag Stokic, slobodan Simic, Vlada\n  Radivojevic and Milos Ljubisavljevic", "title": "EEG machine learning with Higuchi fractal dimension and Sample Entropy\n  as features for successful detection of depression", "comments": "34 pages, 4 Figures, 2 tables", "journal-ref": "Cognitive Neurodynamics Springer Nature March 2020", "doi": "10.1007/s11571-020-09581-x", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable diagnosis of depressive disorder is essential for both optimal\ntreatment and prevention of fatal outcomes. In this study, we aimed to\nelucidate the effectiveness of two non-linear measures, Higuchi Fractal\nDimension (HFD) and Sample Entropy (SampEn), in detecting depressive disorders\nwhen applied on EEG. HFD and SampEn of EEG signals were used as features for\nseven machine learning algorithms including Multilayer Perceptron, Logistic\nRegression, Support Vector Machines with the linear and polynomial kernel,\nDecision Tree, Random Forest, and Naive Bayes classifier, discriminating EEG\nbetween healthy control subjects and patients diagnosed with depression. We\nconfirmed earlier observations that both non-linear measures can discriminate\nEEG signals of patients from healthy control subjects. The results suggest that\ngood classification is possible even with a small number of principal\ncomponents. Average accuracy among classifiers ranged from 90.24% to 97.56%.\nAmong the two measures, SampEn had better performance. Using HFD and SampEn and\na variety of machine learning techniques we can accurately discriminate\npatients diagnosed with depression vs controls which can serve as a highly\nsensitive, clinically relevant marker for the diagnosis of depressive\ndisorders.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 20:13:38 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cukic", "Milena", ""], ["Pokrajac", "David", ""], ["Stokic", "Miodrag", ""], ["Simic", "slobodan", ""], ["Radivojevic", "Vlada", ""], ["Ljubisavljevic", "Milos", ""]]}, {"id": "1803.05999", "submitter": "Hadi Daneshmand", "authors": "Hadi Daneshmand, Jonas Kohler, Aurelien Lucchi, Thomas Hofmann", "title": "Escaping Saddles with Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the variance of stochastic gradients along negative curvature\ndirections in certain non-convex machine learning models and show that\nstochastic gradients exhibit a strong component along these directions.\nFurthermore, we show that - contrary to the case of isotropic noise - this\nvariance is proportional to the magnitude of the corresponding eigenvalues and\nnot decreasing in the dimensionality. Based upon this observation we propose a\nnew assumption under which we show that the injection of explicit, isotropic\nnoise usually applied to make gradient descent escape saddle points can\nsuccessfully be replaced by a simple SGD step. Additionally - and under the\nsame condition - we derive the first convergence rate for plain SGD to a\nsecond-order stationary point in a number of iterations that is independent of\nthe problem dimension.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 20:48:06 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 16:18:17 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Kohler", "Jonas", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1803.06024", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alex Dikopoltsev, Oren Cohen, Shie Mannor and Mordechai\n  Segev", "title": "Deep Learning Reconstruction of Ultra-Short Pulses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-short laser pulses with femtosecond to attosecond pulse duration are\nthe shortest systematic events humans can create. Characterization (amplitude\nand phase) of these pulses is a key ingredient in ultrafast science, e.g.,\nexploring chemical reactions and electronic phase transitions. Here, we propose\nand demonstrate, numerically and experimentally, the first deep neural network\ntechnique to reconstruct ultra-short optical pulses. We anticipate that this\napproach will extend the range of ultrashort laser pulses that can be\ncharacterized, e.g., enabling to diagnose very weak attosecond pulses.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 22:37:31 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zahavy", "Tom", ""], ["Dikopoltsev", "Alex", ""], ["Cohen", "Oren", ""], ["Mannor", "Shie", ""], ["Segev", "Mordechai", ""]]}, {"id": "1803.06058", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, Jacob R. Gardner, Kilian Q. Weinberger, Andrew Gordon\n  Wilson", "title": "Constant-Time Predictive Distributions for Gaussian Processes", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most compelling features of Gaussian process (GP) regression is\nits ability to provide well-calibrated posterior distributions. Recent advances\nin inducing point methods have sped up GP marginal likelihood and posterior\nmean computations, leaving posterior covariance estimation and sampling as the\nremaining computational bottlenecks. In this paper we address these\nshortcomings by using the Lanczos algorithm to rapidly approximate the\npredictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs\nVariance Estimates), substantially improves time and space complexity. In our\nexperiments, LOVE computes covariances up to 2,000 times faster and draws\nsamples 18,000 times faster than existing methods, all without sacrificing\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 02:31:45 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 17:49:21 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 20:25:05 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 16:39:16 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1803.06071", "submitter": "Hongzhi Wang", "authors": "Zhixin Qi, Hongzhi Wang, Jianzhong Li, Hong Gao", "title": "Impacts of Dirty Data: and Experimental Evaluation", "comments": "22 pages, 192 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality issues have attracted widespread attention due to the negative\nimpacts of dirty data on data mining and machine learning results. The\nrelationship between data quality and the accuracy of results could be applied\non the selection of the appropriate algorithm with the consideration of data\nquality and the determination of the data share to clean. However, rare\nresearch has focused on exploring such relationship. Motivated by this, this\npaper conducts an experimental comparison for the effects of missing,\ninconsistent and conflicting data on classification and clustering algorithms.\nBased on the experimental findings, we provide guidelines for algorithm\nselection and data cleaning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 04:23:00 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:48:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Qi", "Zhixin", ""], ["Wang", "Hongzhi", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1803.06084", "submitter": "Tri Dao", "authors": "Tri Dao, Albert Gu, Alexander J. Ratner, Virginia Smith, Christopher\n  De Sa, Christopher R\\'e", "title": "A Kernel Theory of Modern Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation, a technique in which a training set is expanded with\nclass-preserving transformations, is ubiquitous in modern machine learning\npipelines. In this paper, we seek to establish a theoretical framework for\nunderstanding data augmentation. We approach this from two directions: First,\nwe provide a general model of augmentation as a Markov process, and show that\nkernels appear naturally with respect to this model, even when we do not employ\nkernel classification. Next, we analyze more directly the effect of\naugmentation on kernel classifiers, showing that data augmentation can be\napproximated by first-order feature averaging and second-order variance\nregularization components. These frameworks both serve to illustrate the ways\nin which data augmentation affects the downstream learning model, and the\nresulting analyses provide novel connections between prior work in invariant\nkernels, tangent propagation, and robust optimization. Finally, we provide\nseveral proof-of-concept applications showing that our theory can be useful for\naccelerating machine learning workflows, such as reducing the amount of\ncomputation needed to train using augmented data, and predicting the utility of\na transformation prior to training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 06:05:32 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 17:58:12 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Dao", "Tri", ""], ["Gu", "Albert", ""], ["Ratner", "Alexander J.", ""], ["Smith", "Virginia", ""], ["De Sa", "Christopher", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1803.06092", "submitter": "Guangyu Robert Yang", "authors": "Guangyu Robert Yang, Igor Ganichev, Xiao-Jing Wang, Jonathon Shlens,\n  David Sussillo", "title": "A Dataset and Architecture for Visual Reasoning with a Working Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vexing problem in artificial intelligence is reasoning about events that\noccur in complex, changing visual stimuli such as in video analysis or game\nplay. Inspired by a rich tradition of visual reasoning and memory in cognitive\npsychology and neuroscience, we developed an artificial, configurable visual\nquestion and answer dataset (COG) to parallel experiments in humans and\nanimals. COG is much simpler than the general problem of video analysis, yet it\naddresses many of the problems relating to visual and logical reasoning and\nmemory -- problems that remain challenging for modern deep learning\narchitectures. We additionally propose a deep learning architecture that\nperforms competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as\neasy settings of the COG dataset. However, several settings of COG result in\ndatasets that are progressively more challenging to learn. After training, the\nnetwork can zero-shot generalize to many new tasks. Preliminary analyses of the\nnetwork architectures trained on COG demonstrate that the network accomplishes\nthe task in a manner interpretable to humans.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 06:53:45 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 14:12:49 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Yang", "Guangyu Robert", ""], ["Ganichev", "Igor", ""], ["Wang", "Xiao-Jing", ""], ["Shlens", "Jonathon", ""], ["Sussillo", "David", ""]]}, {"id": "1803.06111", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Vulnerability of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 08:52:04 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.06120", "submitter": "Zhourong Chen", "authors": "Zhourong Chen, Xiaopeng Li, Nevin L. Zhang", "title": "Learning Sparse Deep Feedforward Networks via Tree Skeleton Expansion", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the popularity of deep learning, structure learning for deep models\nremains a relatively under-explored area. In contrast, structure learning has\nbeen studied extensively for probabilistic graphical models (PGMs). In\nparticular, an efficient algorithm has been developed for learning a class of\ntree-structured PGMs called hierarchical latent tree models (HLTMs), where\nthere is a layer of observed variables at the bottom and multiple layers of\nlatent variables on top. In this paper, we propose a simple method for learning\nthe structures of feedforward neural networks (FNNs) based on HLTMs. The idea\nis to expand the connections in the tree skeletons from HLTMs and to use the\nresulting structures for FNNs. An important characteristic of FNN structures\nlearned this way is that they are sparse. We present extensive empirical\nresults to show that, compared with standard FNNs tuned-manually, sparse FNNs\nlearned by our method achieve better or comparable classification performance\nwith much fewer parameters. They are also more interpretable.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 09:22:47 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Chen", "Zhourong", ""], ["Li", "Xiaopeng", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1803.06174", "submitter": "Michael Veale", "authors": "Michael Veale, Reuben Binns and Max Van Kleek", "title": "Some HCI Priorities for GDPR-Compliant Machine Learning", "comments": "8 pages, 0 figures, The General Data Protection Regulation: An\n  Opportunity for the CHI Community? (CHI-GDPR 2018), Workshop at ACM CHI'18,\n  22 April 2018, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 11:40:33 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Veale", "Michael", ""], ["Binns", "Reuben", ""], ["Van Kleek", "Max", ""]]}, {"id": "1803.06234", "submitter": "Koujin Takeda", "authors": "Ryota Kawasumi, Koujin Takeda", "title": "Approximate Method of Variational Bayesian Matrix\n  Factorization/Completion with Sparse Prior", "comments": "22 pages, 4 figures, part of this work was presented in IEEE\n  International Workshop on Machine Learning for Signal Processing (2017)", "journal-ref": "J. Stat. Mech. (2018) 053404", "doi": "10.1088/1742-5468/aabc7d", "report-no": null, "categories": "eess.SP cond-mat.dis-nn cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive analytical expression of matrix factorization/completion solution\nby variational Bayes method, under the assumption that observed matrix is\noriginally the product of low-rank dense and sparse matrices with additive\nnoise. We assume the prior of sparse matrix is Laplace distribution by taking\nmatrix sparsity into consideration. Then we use several approximations for\nderivation of matrix factorization/completion solution. By our solution, we\nalso numerically evaluate the performance of sparse matrix reconstruction in\nmatrix factorization, and completion of missing matrix element in matrix\ncompletion.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 13:54:23 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kawasumi", "Ryota", ""], ["Takeda", "Koujin", ""]]}, {"id": "1803.06236", "submitter": "Junqiu Wu", "authors": "Ke Liu, Xiangyan Sun, Lei Jia, Jun Ma, Haoming Xing, Junqiu Wu, Hua\n  Gao, Yax Sun, Florian Boulnois, and Jie Fan", "title": "Chemi-net: a graph convolutional network for accurate drug property\n  prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Absorption, distribution, metabolism, and excretion (ADME) studies are\ncritical for drug discovery. Conventionally, these tasks, together with other\nchemical property predictions, rely on domain-specific feature descriptors, or\nfingerprints. Following the recent success of neural networks, we developed\nChemi-Net, a completely data-driven, domain knowledge-free, deep learning\nmethod for ADME property prediction. To compare the relative performance of\nChemi-Net with Cubist, one of the popular machine learning programs used by\nAmgen, a large-scale ADME property prediction study was performed on-site at\nAmgen. The results showed that our deep neural network method improved current\nmethods by a large margin. We foresee that the significantly increased accuracy\nof ADME prediction seen with Chemi-Net over Cubist will greatly accelerate drug\ndiscovery.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 13:57:18 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 08:25:50 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Liu", "Ke", ""], ["Sun", "Xiangyan", ""], ["Jia", "Lei", ""], ["Ma", "Jun", ""], ["Xing", "Haoming", ""], ["Wu", "Junqiu", ""], ["Gao", "Hua", ""], ["Sun", "Yax", ""], ["Boulnois", "Florian", ""], ["Fan", "Jie", ""]]}, {"id": "1803.06272", "submitter": "Renjie Liao", "authors": "Renjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander L. Gaunt,\n  Raquel Urtasun, Richard Zemel", "title": "Graph Partition Neural Networks for Semi-Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present graph partition neural networks (GPNN), an extension of graph\nneural networks (GNNs) able to handle extremely large graphs. GPNNs alternate\nbetween locally propagating information between nodes in small subgraphs and\nglobally propagating information between the subgraphs. To efficiently\npartition graphs, we experiment with several partitioning algorithms and also\npropose a novel variant for fast processing of large scale graphs. We\nextensively test our model on a variety of semi-supervised node classification\ntasks. Experimental results indicate that GPNNs are either superior or\ncomparable to state-of-the-art methods on a wide variety of datasets for\ngraph-based semi-supervised classification. We also show that GPNNs can achieve\nsimilar performance as standard GNNs with fewer propagation steps.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 15:34:06 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Liao", "Renjie", ""], ["Brockschmidt", "Marc", ""], ["Tarlow", "Daniel", ""], ["Gaunt", "Alexander L.", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1803.06305", "submitter": "Zhe Li", "authors": "Shuo Wang, Zhe Li, Caiwen Ding, Bo Yuan, Yanzhi Wang, Qinru Qiu, Yun\n  Liang", "title": "C-LSTM: Enabling Efficient LSTM using Structured Compression Techniques\n  on FPGAs", "comments": "Proceedings of the 2018 ACM/SIGDA International Symposium on\n  Field-Programmable Gate Arrays", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant accuracy improvement has been achieved for acoustic\nrecognition systems by increasing the model size of Long Short-Term Memory\n(LSTM) networks. Unfortunately, the ever-increasing size of LSTM model leads to\ninefficient designs on FPGAs due to the limited on-chip resources. The previous\nwork proposes to use a pruning based compression technique to reduce the model\nsize and thus speedups the inference on FPGAs. However, the random nature of\nthe pruning technique transforms the dense matrices of the model to highly\nunstructured sparse ones, which leads to unbalanced computation and irregular\nmemory accesses and thus hurts the overall performance and energy efficiency.\n  In contrast, we propose to use a structured compression technique which could\nnot only reduce the LSTM model size but also eliminate the irregularities of\ncomputation and memory accesses. This approach employs block-circulant instead\nof sparse matrices to compress weight matrices and reduces the storage\nrequirement from $\\mathcal{O}(k^2)$ to $\\mathcal{O}(k)$. Fast Fourier Transform\nalgorithm is utilized to further accelerate the inference by reducing the\ncomputational complexity from $\\mathcal{O}(k^2)$ to\n$\\mathcal{O}(k\\text{log}k)$. The datapath and activation functions are\nquantized as 16-bit to improve the resource utilization. More importantly, we\npropose a comprehensive framework called C-LSTM to automatically optimize and\nimplement a wide range of LSTM variants on FPGAs. According to the experimental\nresults, C-LSTM achieves up to 18.8X and 33.5X gains for performance and energy\nefficiency compared with the state-of-the-art LSTM implementation under the\nsame experimental setup, and the accuracy degradation is very small.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:19:37 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Shuo", ""], ["Li", "Zhe", ""], ["Ding", "Caiwen", ""], ["Yuan", "Bo", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""], ["Liang", "Yun", ""]]}, {"id": "1803.06333", "submitter": "Celestine D\\\"unner", "authors": "Celestine D\\\"unner, Thomas Parnell, Dimitrios Sarigiannis, Nikolas\n  Ioannou, Andreea Anghel, Gummadi Ravi, Madhusudanan Kandasamy, Haralampos\n  Pozidis", "title": "Snap ML: A Hierarchical Framework for Machine Learning", "comments": "in Proceedings of the Thirty-Second Conference on Neural Information\n  Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new software framework for fast training of generalized linear\nmodels. The framework, named Snap Machine Learning (Snap ML), combines recent\nadvances in machine learning systems and algorithms in a nested manner to\nreflect the hierarchical architecture of modern computing systems. We prove\ntheoretically that such a hierarchical system can accelerate training in\ndistributed environments where intra-node communication is cheaper than\ninter-node communication. Additionally, we provide a review of the\nimplementation of Snap ML in terms of GPU acceleration, pipelining,\ncommunication patterns and software architecture, highlighting aspects that\nwere critical for achieving high performance. We evaluate the performance of\nSnap ML in both single-node and multi-node environments, quantifying the\nbenefit of the hierarchical scheme and the data streaming functionality, and\ncomparing with other widely-used machine learning software frameworks. Finally,\nwe present a logistic regression benchmark on the Criteo Terabyte Click Logs\ndataset and show that Snap ML achieves the same test loss an order of magnitude\nfaster than any of the previously reported results, including those obtained\nusing TensorFlow and scikit-learn.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:37:12 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:30:36 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 17:17:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""], ["Sarigiannis", "Dimitrios", ""], ["Ioannou", "Nikolas", ""], ["Anghel", "Andreea", ""], ["Ravi", "Gummadi", ""], ["Kandasamy", "Madhusudanan", ""], ["Pozidis", "Haralampos", ""]]}, {"id": "1803.06373", "submitter": "Harini Kannan", "authors": "Harini Kannan, Alexey Kurakin, Ian Goodfellow", "title": "Adversarial Logit Pairing", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop improved techniques for defending against\nadversarial examples at scale. First, we implement the state of the art version\nof adversarial training at unprecedented scale on ImageNet and investigate\nwhether it remains effective in this setting - an important open scientific\nquestion (Athalye et al., 2018). Next, we introduce enhanced defenses using a\ntechnique we call logit pairing, a method that encourages logits for pairs of\nexamples to be similar. When applied to clean examples and their adversarial\ncounterparts, logit pairing improves accuracy on adversarial examples over\nvanilla adversarial training; we also find that logit pairing on clean examples\nonly is competitive with adversarial training in terms of accuracy on two\ndatasets. Finally, we show that adversarial logit pairing achieves the state of\nthe art defense on ImageNet against PGD white box attacks, with an accuracy\nimprovement from 1.5% to 27.9%. Adversarial logit pairing also successfully\ndamages the current state of the art defense against black box attacks on\nImageNet (Tramer et al., 2018), dropping its accuracy from 66.6% to 47.1%. With\nthis new accuracy drop, adversarial logit pairing ties with Tramer et al.(2018)\nfor the state of the art on black box attacks on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 19:03:45 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Kannan", "Harini", ""], ["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1803.06386", "submitter": "Akbar Siami Namin", "authors": "Sima Siami-Namini and Akbar Siami Namin", "title": "Forecasting Economics and Financial Time Series: ARIMA vs. LSTM", "comments": "19 pages, 2 figures, 1 diagram, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting time series data is an important subject in economics, business,\nand finance. Traditionally, there are several techniques to effectively\nforecast the next lag of time series data such as univariate Autoregressive\n(AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and\nmore notably Autoregressive Integrated Moving Average (ARIMA) with its many\nvariations. In particular, ARIMA model has demonstrated its outperformance in\nprecision and accuracy of predicting the next lags of time series. With the\nrecent advancement in computational power of computers and more importantly\ndeveloping more advanced machine learning algorithms and approaches such as\ndeep learning, new algorithms are developed to forecast time series data. The\nresearch question investigated in this article is that whether and how the\nnewly developed deep learning-based algorithms for forecasting time series\ndata, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional\nalgorithms. The empirical studies conducted and reported in this article show\nthat deep learning-based algorithms such as LSTM outperform traditional-based\nalgorithms such as ARIMA model. More specifically, the average reduction in\nerror rates obtained by LSTM is between 84 - 87 percent when compared to ARIMA\nindicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that\nthe number of training times, known as \"epoch\" in deep learning, has no effect\non the performance of the trained forecast model and it exhibits a truly random\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:01:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Siami-Namini", "Sima", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1803.06390", "submitter": "Marina Sokolova", "authors": "Marina Sokolova, Victoria Bobicev", "title": "Corpus Statistics in Text Classification of Online Data", "comments": "12 pages, 6 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation of Machine Learning (ML) from a boutique science to a\ngenerally accepted technology has increased importance of reproduction and\ntransportability of ML studies. In the current work, we investigate how corpus\ncharacteristics of textual data sets correspond to text classification results.\nWe work with two data sets gathered from sub-forums of an online health-related\nforum. Our empirical results are obtained for a multi-class sentiment analysis\napplication.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:19:56 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Sokolova", "Marina", ""], ["Bobicev", "Victoria", ""]]}, {"id": "1803.06396", "submitter": "Renjie Liao", "authors": "Renjie Liao, Yuwen Xiong, Ethan Fetaya, Lisa Zhang, KiJung Yoon, Xaq\n  Pitkow, Raquel Urtasun, Richard Zemel", "title": "Reviving and Improving Recurrent Back-Propagation", "comments": "International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the recurrent back-propagation (RBP) algorithm,\ndiscuss the conditions under which it applies as well as how to satisfy them in\ndeep neural networks. We show that RBP can be unstable and propose two variants\nbased on conjugate gradient on the normal equations (CG-RBP) and Neumann series\n(Neumann-RBP). We further investigate the relationship between Neumann-RBP and\nback propagation through time (BPTT) and its truncated version (TBPTT). Our\nNeumann-RBP has the same time complexity as TBPTT but only requires constant\nmemory, whereas TBPTT's memory cost scales linearly with the number of\ntruncation steps. We examine all RBP variants along with BPTT and TBPTT in\nthree different application domains: associative memory with continuous\nHopfield networks, document classification in citation networks using graph\nneural networks and hyperparameter optimization for fully connected networks.\nAll experiments demonstrate that RBPs, especially the Neumann-RBP variant, are\nefficient and effective for optimizing convergent recurrent neural networks.\nCode is released at: \\url{https://github.com/lrjconan/RBP}.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:57:36 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 17:03:55 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 03:15:02 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 03:12:40 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Fetaya", "Ethan", ""], ["Zhang", "Lisa", ""], ["Yoon", "KiJung", ""], ["Pitkow", "Xaq", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1803.06407", "submitter": "Calvin Murdock", "authors": "Calvin Murdock, Ming-Fang Chang, Simon Lucey", "title": "Deep Component Analysis via Alternating Direction Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a lack of theoretical understanding, deep neural networks have\nachieved unparalleled performance in a wide range of applications. On the other\nhand, shallow representation learning with component analysis is associated\nwith rich intuition and theory, but smaller capacity often limits its\nusefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA),\nan expressive multilayer model formulation that enforces hierarchical structure\nthrough constraints on latent variables in each layer. For inference, we\npropose a differentiable optimization algorithm implemented using recurrent\nAlternating Direction Neural Networks (ADNNs) that enable parameter learning\nusing standard backpropagation. By interpreting feed-forward networks as\nsingle-iteration approximations of inference in our model, we provide both a\nnovel theoretical perspective for understanding them and a practical technique\nfor constraining predictions with prior knowledge. Experimentally, we\ndemonstrate performance improvements on a variety of tasks, including\nsingle-image depth prediction with sparse output constraints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 21:40:02 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Murdock", "Calvin", ""], ["Chang", "Ming-Fang", ""], ["Lucey", "Simon", ""]]}, {"id": "1803.06442", "submitter": "Edward Parker", "authors": "Gavin Hartnett and Edward Parker and Edward Geist", "title": "Replica Symmetry Breaking in Bipartite Spin Glasses and Neural Networks", "comments": "33 pages, 14 figures", "journal-ref": "Phys. Rev. E 98, 022116 (2018)", "doi": "10.1103/PhysRevE.98.022116", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some interesting recent advances in the theoretical understanding of neural\nnetworks have been informed by results from the physics of disordered many-body\nsystems. Motivated by these findings, this work uses the replica technique to\nstudy the mathematically tractable bipartite Sherrington-Kirkpatrick (SK) spin\nglass model, which is formally similar to a Restricted Boltzmann Machine (RBM)\nneural network. The bipartite SK model has been previously studied assuming\nreplica symmetry; here this assumption is relaxed and a replica symmetry\nbreaking analysis is performed. The bipartite SK model is found to have many\nfeatures in common with Parisi's solution of the original, unipartite SK model,\nincluding the existence of a multitude of pure states which are related in a\nhierarchical, ultrametric fashion. As an application of this analysis, the\noptimal cost for a graph partitioning problem is shown to be simply related to\nthe ground state energy of the bipartite SK model. As a second application,\nempirical investigations reveal that the Gibbs sampled outputs of an RBM\ntrained on the MNIST data set are more ultrametrically distributed than the\ninput data itself.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 01:47:57 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 16:21:39 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 03:19:20 GMT"}, {"version": "v4", "created": "Thu, 16 Aug 2018 02:38:06 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Hartnett", "Gavin", ""], ["Parker", "Edward", ""], ["Geist", "Edward", ""]]}, {"id": "1803.06443", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Shaoduo Gan, Ce Zhang, Tong Zhang, Ji Liu", "title": "Communication Compression for Decentralized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing distributed learning systems is an art of balancing between\ncomputation and communication. There have been two lines of research that try\nto deal with slower networks: {\\em communication compression} for low bandwidth\nnetworks, and {\\em decentralization} for high latency networks. In this paper,\nWe explore a natural question: {\\em can the combination of both techniques lead\nto a system that is robust to both bandwidth and latency?}\n  Although the system implication of such combination is trivial, the\nunderlying theoretical principle and algorithm design is challenging: unlike\ncentralized algorithms, simply compressing exchanged information, even in an\nunbiased stochastic way, within the decentralized network would accumulate the\nerror and fail to converge. In this paper, we develop a framework of\ncompressed, decentralized training and propose two different strategies, which\nwe call {\\em extrapolation compression} and {\\em difference compression}. We\nanalyze both algorithms and prove both converge at the rate of $O(1/\\sqrt{nT})$\nwhere $n$ is the number of workers and $T$ is the number of iterations,\nmatching the convergence rate for full precision, centralized training. We\nvalidate our algorithms and find that our proposed algorithm outperforms the\nbest of merely decentralized and merely quantized algorithm significantly for\nnetworks with {\\em both} high latency and low bandwidth.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 01:51:09 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 00:15:49 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 23:10:01 GMT"}, {"version": "v4", "created": "Mon, 31 Dec 2018 21:20:01 GMT"}, {"version": "v5", "created": "Thu, 31 Jan 2019 20:20:32 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Tang", "Hanlin", ""], ["Gan", "Shaoduo", ""], ["Zhang", "Ce", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06449", "submitter": "Hannah Wayment-Steele", "authors": "Hannah K. Wayment-Steele and Vijay S. Pande", "title": "Note: Variational Encoding of Protein Dynamics Benefits from Maximizing\n  Latent Autocorrelation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep Variational Auto-Encoder (VAE) frameworks become more widely used for\nmodeling biomolecular simulation data, we emphasize the capability of the VAE\narchitecture to concurrently maximize the timescale of the latent space while\ninferring a reduced coordinate, which assists in finding slow processes as\naccording to the variational approach to conformational dynamics. We\nadditionally provide evidence that the VDE framework (Hern\\'andez et al.,\n2017), which uses this autocorrelation loss along with a time-lagged\nreconstruction loss, obtains a variationally optimized latent coordinate in\ncomparison with related loss functions. We thus recommend leveraging the\nautocorrelation of the latent space while training neural network models of\nbiomolecular simulation data to better represent slow processes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 03:27:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wayment-Steele", "Hannah K.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.06453", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Tuan Dinh, Vishnu Lokhande, Vikas Singh", "title": "Constrained Deep Learning using Conditional Gradient and Applications in\n  Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of results have recently demonstrated the benefits of incorporating\nvarious constraints when training deep architectures in vision and machine\nlearning. The advantages range from guarantees for statistical generalization\nto better accuracy to compression. But support for general constraints within\nwidely used libraries remains scarce and their broader deployment within many\napplications that can benefit from them remains under-explored. Part of the\nreason is that Stochastic gradient descent (SGD), the workhorse for training\ndeep neural networks, does not natively deal with constraints with global scope\nvery well. In this paper, we revisit a classical first order scheme from\nnumerical optimization, Conditional Gradients (CG), that has, thus far had\nlimited applicability in training deep models. We show via rigorous analysis\nhow various constraints can be naturally handled by modifications of this\nalgorithm. We provide convergence guarantees and show a suite of immediate\nbenefits that are possible -- from training ResNets with fewer layers but\nbetter accuracy simply by substituting in our version of CG to faster training\nof GANs with 50% fewer epochs in image inpainting applications to provably\nbetter generalization guarantees using efficiently implementable forms of\nrecently proposed regularizers.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 03:59:34 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Dinh", "Tuan", ""], ["Lokhande", "Vishnu", ""], ["Singh", "Vikas", ""]]}, {"id": "1803.06459", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zheng Xu, Zsolt Kira, Jiawei Huang", "title": "Learning to Cluster for Proposal-Free Instance Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposed a novel learning objective to train a deep neural network\nto perform end-to-end image pixel clustering. We applied the approach to\ninstance segmentation, which is at the intersection of image semantic\nsegmentation and object detection. We utilize the most fundamental property of\ninstance labeling -- the pairwise relationship between pixels -- as the\nsupervision to formulate the learning objective, then apply it to train a fully\nconvolutional network (FCN) for learning to perform pixel-wise clustering. The\nresulting clusters can be used as the instance labeling directly. To support\nlabeling of an unlimited number of instance, we further formulate ideas from\ngraph coloring theory into the proposed learning objective. The evaluation on\nthe Cityscapes dataset demonstrates strong performance and therefore proof of\nthe concept. Moreover, our approach won the second place in the lane detection\ncompetition of 2017 CVPR Autonomous Driving Challenge, and was the top\nperformer without using external data.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 04:35:21 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Xu", "Zheng", ""], ["Kira", "Zsolt", ""], ["Huang", "Jiawei", ""]]}, {"id": "1803.06510", "submitter": "Yingjie Fei", "authors": "Yingjie Fei and Yudong Chen", "title": "Hidden Integrality of SDP Relaxation for Sub-Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the discrete clustering structures\nunder Sub-Gaussian Mixture Models. Our main results establish a hidden\nintegrality property of a semidefinite programming (SDP) relaxation for this\nproblem: while the optimal solutions to the SDP are not integer-valued in\ngeneral, their estimation errors can be upper bounded in terms of the error of\nan idealized integer program. The error of the integer program, and hence that\nof the SDP, are further shown to decay exponentially in the signal-to-noise\nratio. To the best of our knowledge, this is the first exponentially decaying\nerror bound for convex relaxations of mixture models, and our results reveal\nthe \"global-to-local\" mechanism that drives the performance of the SDP\nrelaxation.\n  A corollary of our results shows that in certain regimes the SDP solutions\nare in fact integral and exact, improving on existing exact recovery results\nfor convex relaxations. More generally, our results establish sufficient\nconditions for the SDP to correctly recover the cluster memberships of\n$(1-\\delta)$ fraction of the points for any $\\delta\\in(0,1)$. As a special\ncase, we show that under the $d$-dimensional Stochastic Ball Model, SDP\nachieves non-trivial (sometimes exact) recovery when the center separation is\nas small as $\\sqrt{1/d}$, which complements previous exact recovery results\nthat require constant separation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 14:11:13 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Fei", "Yingjie", ""], ["Chen", "Yudong", ""]]}, {"id": "1803.06520", "submitter": "Alberto Calderone Dr.", "authors": "Alberto Calderone, Gianni Cesareni", "title": "Analysis of Triplet Motifs in Biological Signed Oriented Graphs Suggests\n  a Relationship Between Fine Topology and Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Networks in different domains are characterized by similar global\ncharacteristics while differing in local structures. To further extend this\nconcept, we investigated network regularities on a fine scale in order to\nexamine the functional impact of recurring motifs in signed oriented biological\nnetworks. In this work we generalize to signaling net works some considerations\nmade on feedback and feed forward loops and extend them by adding a close\nscrutiny of Linear Triplets, which have not yet been investigate in detail.\nResults: We studied the role of triplets, either open or closed (Loops or\nlinear events) by enumerating them in different biological signaling networks\nand by comparing their significance profiles. We compared different data\nsources and investigated the fine topology of protein networks representing\ncausal relationships based on transcriptional control, phosphorylation,\nubiquitination and binding. Not only were we able to generalize findings that\nhave already been reported but we also highlighted a connection between\nrelative motif abundance and node function. Furthermore, by analyzing for the\nfirst time Linear Triplets, we highlighted the relative importance of nodes\nsitting in specific positions in closed signaling triplets. Finally, we tried\nto apply machine learning to show that a combination of motifs features can be\nused to derive node function. Availability: The triplets counter used for this\nwork is available as a Cytoscape App and as a standalone command line Java\napplication. http://apps.cytoscape.org/apps/counttriplets Keywords: Graph\ntheory, graph analysis, graph topology, machine learning, cytoscape\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 15:26:02 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 15:15:18 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2019 11:36:24 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 20:31:01 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Calderone", "Alberto", ""], ["Cesareni", "Gianni", ""]]}, {"id": "1803.06521", "submitter": "Sitan Chen", "authors": "Sitan Chen, Ankur Moitra", "title": "Beyond the Low-Degree Algorithm: Mixtures of Subcubes and Their\n  Applications", "comments": "62 pages; to appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning mixtures of $k$ subcubes over\n$\\{0,1\\}^n$, which contains many classic learning theory problems as a special\ncase (and is itself a special case of others). We give a surprising $n^{O(\\log\nk)}$-time learning algorithm based on higher-order multilinear moments. It is\nnot possible to learn the parameters because the same distribution can be\nrepresented by quite different models. Instead, we develop a framework for\nreasoning about how multilinear moments can pinpoint essential features of the\nmixture, like the number of components.\n  We also give applications of our algorithm to learning decision trees with\nstochastic transitions (which also capture interesting scenarios where the\ntransitions are deterministic but there are latent variables). Using our\nalgorithm for learning mixtures of subcubes, we can approximate the Bayes\noptimal classifier within additive error $\\epsilon$ on $k$-leaf decision trees\nwith at most $s$ stochastic transitions on any root-to-leaf path in $n^{O(s +\n\\log k)}\\cdot\\text{poly}(1/\\epsilon)$ time. In this stochastic setting, the\nclassic Occam algorithms for learning decision trees with zero stochastic\ntransitions break down, while the low-degree algorithm of Linial et al.\ninherently has a quasipolynomial dependence on $1/\\epsilon$.\n  In contrast, as we will show, mixtures of $k$ subcubes are uniquely\ndetermined by their degree $2 \\log k$ moments and hence provide a useful\nabstraction for simultaneously achieving the polynomial dependence on\n$1/\\epsilon$ of the classic Occam algorithms for decision trees and the\nflexibility of the low-degree algorithm in being able to accommodate stochastic\ntransitions. Using our multilinear moment techniques, we also give the first\nimproved upper and lower bounds since the work of Feldman et al. for the\nrelated but harder problem of learning mixtures of binary product\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 15:26:04 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 17:43:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Chen", "Sitan", ""], ["Moitra", "Ankur", ""]]}, {"id": "1803.06523", "submitter": "Damek Davis", "authors": "Damek Davis and Dmitriy Drusvyatskiy", "title": "Stochastic model-based minimization of weakly convex functions", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a family of algorithms that successively sample and minimize\nsimple stochastic models of the objective function. We show that under\nreasonable conditions on approximation quality and regularity of the models,\nany such algorithm drives a natural stationarity measure to zero at the rate\n$O(k^{-1/4})$. As a consequence, we obtain the first complexity guarantees for\nthe stochastic proximal point, proximal subgradient, and regularized\nGauss-Newton methods for minimizing compositions of convex functions with\nsmooth maps. The guiding principle, underlying the complexity guarantees, is\nthat all algorithms under consideration can be interpreted as approximate\ndescent methods on an implicit smoothing of the problem, given by the Moreau\nenvelope. Specializing to classical circumstances, we obtain the long-sought\nconvergence rate of the stochastic projected gradient method, without batching,\nfor minimizing a smooth function on a closed convex set.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 15:38:20 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 20:14:26 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 21:35:36 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1803.06561", "submitter": "Chen Yu", "authors": "Chen Yu, Bojan Karlas, Jie Zhong, Ce Zhang, Ji Liu", "title": "AutoML from Service Provider's Perspective: Multi-device, Multi-tenant\n  Model Selection with GP-EI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AutoML has become a popular service that is provided by most leading cloud\nservice providers today. In this paper, we focus on the AutoML problem from the\n\\emph{service provider's perspective}, motivated by the following practical\nconsideration: When an AutoML service needs to serve {\\em multiple users} with\n{\\em multiple devices} at the same time, how can we allocate these devices to\nusers in an efficient way? We focus on GP-EI, one of the most popular\nalgorithms for automatic model selection and hyperparameter tuning, used by\nsystems such as Google Vizer. The technical contribution of this paper is the\nfirst multi-device, multi-tenant algorithm for GP-EI that is aware of\n\\emph{multiple} computation devices and multiple users sharing the same set of\ncomputation devices. Theoretically, given $N$ users and $M$ devices, we obtain\na regret bound of $O((\\text{\\bf {MIU}}(T,K) + M)\\frac{N^2}{M})$, where\n$\\text{\\bf {MIU}}(T,K)$ refers to the maximal incremental uncertainty up to\ntime $T$ for the covariance matrix $K$. Empirically, we evaluate our algorithm\non two applications of automatic model selection, and show that our algorithm\nsignificantly outperforms the strategy of serving users independently.\nMoreover, when multiple computation devices are available, we achieve\nnear-linear speedup when the number of users is much larger than the number of\ndevices.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:56:18 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 01:02:26 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 02:59:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yu", "Chen", ""], ["Karlas", "Bojan", ""], ["Zhong", "Jie", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06567", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy (Dj) Dvijotham, Robert Stanforth, Sven Gowal, Timothy\n  Mann, Pushmeet Kohli", "title": "A Dual Approach to Scalable Verification of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of formally verifying desirable properties\nof neural networks, i.e., obtaining provable guarantees that neural networks\nsatisfy specifications relating their inputs and outputs (robustness to bounded\nnorm adversarial perturbations, for example). Most previous work on this topic\nwas limited in its applicability by the size of the network, network\narchitecture and the complexity of properties to be verified. In contrast, our\nframework applies to a general class of activation functions and specifications\non neural network inputs and outputs. We formulate verification as an\noptimization problem (seeking to find the largest violation of the\nspecification) and solve a Lagrangian relaxation of the optimization problem to\nobtain an upper bound on the worst case violation of the specification being\nverified. Our approach is anytime i.e. it can be stopped at any time and a\nvalid bound on the maximum violation can be obtained. We develop specialized\nverification algorithms with provable tightness guarantees under special\nassumptions and demonstrate the practical significance of our general\nverification approach on a variety of verification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 20:13:28 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 17:41:19 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Stanforth", "Robert", ""], ["Gowal", "Sven", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1803.06585", "submitter": "Yibo Lin", "authors": "Jiong Zhang, Yibo Lin, Zhao Song, Inderjit S. Dhillon", "title": "Learning Long Term Dependencies via Fourier Recurrent Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a known fact that training recurrent neural networks for tasks that\nhave long term dependencies is challenging. One of the main reasons is the\nvanishing or exploding gradient problem, which prevents gradient information\nfrom propagating to early layers. In this paper we propose a simple recurrent\narchitecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradients\nthat arise in its training while giving us stronger expressive power.\nSpecifically, FRU summarizes the hidden states $h^{(t)}$ along the temporal\ndimension with Fourier basis functions. This allows gradients to easily reach\nany layer due to FRU's residual learning structure and the global support of\ntrigonometric functions. We show that FRU has gradient lower and upper bounds\nindependent of temporal dimension. We also show the strong expressivity of\nsparse Fourier basis, from which FRU obtains its strong expressive power. Our\nexperimental study also demonstrates that with fewer parameters the proposed\narchitecture outperforms other recurrent architectures on many tasks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 23:06:31 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Zhang", "Jiong", ""], ["Lin", "Yibo", ""], ["Song", "Zhao", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1803.06586", "submitter": "Christopher Tosh", "authors": "Christopher Tosh, Sanjoy Dasgupta", "title": "Structural query-by-committee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a framework that unifies many different interactive\nlearning tasks. We present a generalization of the {\\it query-by-committee}\nactive learning algorithm for this setting, and we study its consistency and\nrate of convergence, both theoretically and empirically, with and without\nnoise.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 23:39:57 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Tosh", "Christopher", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1803.06589", "submitter": "Reza Sadeghi", "authors": "Reza Sadeghi, Tanvi Banerjee, William Romine", "title": "Early hospital mortality prediction using vital signals", "comments": "11 pages, 5 figures, preprint of accepted paper in IEEE&ACM CHASE\n  2018 and published in Smart Health journal", "journal-ref": "Smart Health 9-10 (2018) 265-274", "doi": "10.1016/j.smhl.2018.07.001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early hospital mortality prediction is critical as intensivists strive to\nmake efficient medical decisions about the severely ill patients staying in\nintensive care units. As a result, various methods have been developed to\naddress this problem based on clinical records. However, some of the laboratory\ntest results are time-consuming and need to be processed. In this paper, we\npropose a novel method to predict mortality using features extracted from the\nheart signals of patients within the first hour of ICU admission. In order to\npredict the risk, quantitative features have been computed based on the heart\nrate signals of ICU patients. Each signal is described in terms of 12\nstatistical and signal-based features. The extracted features are fed into\neight classifiers: decision tree, linear discriminant, logistic regression,\nsupport vector machine (SVM), random forest, boosted trees, Gaussian SVM, and\nK-nearest neighborhood (K-NN). To derive insight into the performance of the\nproposed method, several experiments have been conducted using the well-known\nclinical dataset named Medical Information Mart for Intensive Care III\n(MIMIC-III). The experimental results demonstrate the capability of the\nproposed method in terms of precision, recall, F1-score, and area under the\nreceiver operating characteristic curve (AUC). The decision tree classifier\nsatisfies both accuracy and interpretability better than the other classifiers,\nproducing an F1-score and AUC equal to 0.91 and 0.93, respectively. It\nindicates that heart rate signals can be used for predicting mortality in\npatients in the ICU, achieving a comparable performance with existing\npredictions that rely on high dimensional features from clinical records which\nneed to be processed and may contain missing information.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 00:35:42 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 06:06:50 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Sadeghi", "Reza", ""], ["Banerjee", "Tanvi", ""], ["Romine", "William", ""]]}, {"id": "1803.06604", "submitter": "Haichuan Yang", "authors": "Ke Ren, Haichuan Yang, Yu Zhao, Mingshan Xue, Hongyu Miao, Shuai\n  Huang, Ji Liu", "title": "A Robust AUC Maximization Framework with Simultaneous Outlier Detection\n  and Feature Selection for Positive-Unlabeled Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The positive-unlabeled (PU) classification is a common scenario in real-world\napplications such as healthcare, text classification, and bioinformatics, in\nwhich we only observe a few samples labeled as \"positive\" together with a large\nvolume of \"unlabeled\" samples that may contain both positive and negative\nsamples. Building robust classifier for the PU problem is very challenging,\nespecially for complex data where the negative samples overwhelm and mislabeled\nsamples or corrupted features exist. To address these three issues, we propose\na robust learning framework that unifies AUC maximization (a robust metric for\nbiased labels), outlier detection (for excluding wrong labels), and feature\nselection (for excluding corrupted features). The generalization error bounds\nare provided for the proposed model that give valuable insight into the\ntheoretical performance of the method and lead to useful practical guidance,\ne.g., to train a model, we find that the included unlabeled samples are\nsufficient as long as the sample size is comparable to the number of positive\nsamples in the training process. Empirical comparisons and two real-world\napplications on surgical site infection (SSI) and EEG seizure detection are\nalso conducted to show the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 05:09:53 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Ren", "Ke", ""], ["Yang", "Haichuan", ""], ["Zhao", "Yu", ""], ["Xue", "Mingshan", ""], ["Miao", "Hongyu", ""], ["Huang", "Shuai", ""], ["Liu", "Ji", ""]]}, {"id": "1803.06622", "submitter": "Christopher Kim", "authors": "Christopher Kim and Carson Chow", "title": "Learning recurrent dynamics in spiking networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking activity of neurons engaged in learning and performing a task show\ncomplex spatiotemporal dynamics. While the output of recurrent network models\ncan learn to perform various tasks, the possible range of recurrent dynamics\nthat emerge after learning remains unknown. Here we show that modifying the\nrecurrent connectivity with a recursive least squares algorithm provides\nsufficient flexibility for synaptic and spiking rate dynamics of spiking\nnetworks to produce a wide range of spatiotemporal activity. We apply the\ntraining method to learn arbitrary firing patterns, stabilize irregular spiking\nactivity of a balanced network, and reproduce the heterogeneous spiking rate\npatterns of cortical neurons engaged in motor planning and movement. We\nidentify sufficient conditions for successful learning, characterize two types\nof learning errors, and assess the network capacity. Our findings show that\nsynaptically-coupled recurrent spiking networks possess a vast computational\ncapability that can support the diverse activity patterns in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 07:51:19 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 14:13:37 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kim", "Christopher", ""], ["Chow", "Carson", ""]]}, {"id": "1803.06643", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "The Web as a Knowledge-base for Answering Complex Questions", "comments": "accepted as a long paper at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions is a time-consuming activity for humans that\nrequires reasoning and integration of information. Recent work on reading\ncomprehension made headway in answering simple questions, but tackling complex\nquestions is still an ongoing research challenge. Conversely, semantic parsers\nhave been successful at handling compositionality, but only when the\ninformation resides in a target knowledge-base. In this paper, we present a\nnovel framework for answering broad and complex questions, assuming answering\nsimple questions is possible using a search engine and a reading comprehension\nmodel. We propose to decompose complex questions into a sequence of simple\nquestions, and compute the final answer from the sequence of answers. To\nillustrate the viability of our approach, we create a new dataset of complex\nquestions, ComplexWebQuestions, and present a model that decomposes questions\nand interacts with the web to compute an answer. We empirically demonstrate\nthat question decomposition improves performance from 20.8 precision@1 to 27.5\nprecision@1 on this new dataset.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 11:28:12 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1803.06727", "submitter": "Evgeny Burnaev", "authors": "Alexander Korotin and Vladimir V'yugin and Evgeny Burnaev", "title": "Aggregating Strategies for Long-term Forecasting", "comments": "20 pages, 4 figures", "journal-ref": "PMLR 91:63-82, 2018", "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article is devoted to investigating the application of aggregating\nalgorithms to the problem of the long-term forecasting. We examine the classic\naggregating algorithms based on the exponential reweighing. For the general\nVovk's aggregating algorithm we provide its generalization for the long-term\nforecasting. For the special basic case of Vovk's algorithm we provide its two\nmodifications for the long-term forecasting. The first one is theoretically\nclose to an optimal algorithm and is based on replication of independent\ncopies. It provides the time-independent regret bound with respect to the best\nexpert in the pool. The second one is not optimal but is more practical and has\n$O(\\sqrt{T})$ regret bound, where $T$ is the length of the game.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 20:04:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Korotin", "Alexander", ""], ["V'yugin", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1803.06762", "submitter": "Majd Latah", "authors": "Majd Latah, Levent Toker", "title": "Towards an Efficient Anomaly-Based Intrusion Detection for\n  Software-Defined Networks", "comments": "This manuscript has been accepted for publication in IET Networks,\n  2018", "journal-ref": "https://digital-library.theiet.org/content/journals/10.1049/iet-net.2018.5080", "doi": "10.1049/iet-net.2018.5080", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Software-defined networking (SDN) is a new paradigm that allows developing\nmore flexible network applications. SDN controller, which represents a\ncentralized controlling point, is responsible for running various network\napplications as well as maintaining different network services and\nfunctionalities. Choosing an efficient intrusion detection system helps in\nreducing the overhead of the running controller and creates a more secure\nnetwork. In this study, we investigate the performance of the well-known\nanomaly-based intrusion detection approaches in terms of accuracy, false alarm\nrate, precision, recall, f1-measure, area under ROC curve, execution time and\nMc Nemar's test. Precisely, we focus on supervised machine-learning approaches\nwhere we use the following classifiers: Decision Trees (DT), Extreme Learning\nMachine (ELM), Naive Bayes (NB), Linear Discriminant Analysis (LDA), Neural\nNetworks (NN), Support Vector Machines (SVM), Random Forest (RT), K\nNearest-Neighbour (KNN), AdaBoost, RUSBoost, LogitBoost and BaggingTrees where\nwe employ the well-known NSL-KDD benchmark dataset to compare the performance\nof each one of these classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 23:06:20 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 05:57:41 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Latah", "Majd", ""], ["Toker", "Levent", ""]]}, {"id": "1803.06773", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Vitchyr Pong, Aurick Zhou, Murtaza Dalal, Pieter\n  Abbeel, Sergey Levine", "title": "Composable Deep Reinforcement Learning for Robotic Manipulation", "comments": "Videos: https://sites.google.com/view/composing-real-world-policies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 01:17:16 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Pong", "Vitchyr", ""], ["Zhou", "Aurick", ""], ["Dalal", "Murtaza", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.06852", "submitter": "Furui Liu", "authors": "Furui Liu, Laiwan Chan", "title": "Confounder Detection in High Dimensional Linear Models using First\n  Moments of Spectral Measures", "comments": "Accepted at Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01099", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the confounder detection problem in the linear model,\nwhere the target variable $Y$ is predicted using its $n$ potential causes\n$X_n=(x_1,...,x_n)^T$. Based on an assumption of rotation invariant generating\nprocess of the model, recent study shows that the spectral measure induced by\nthe regression coefficient vector with respect to the covariance matrix of\n$X_n$ is close to a uniform measure in purely causal cases, but it differs from\na uniform measure characteristically in the presence of a scalar confounder.\nThen, analyzing spectral measure pattern could help to detect confounding. In\nthis paper, we propose to use the first moment of the spectral measure for\nconfounder detection. We calculate the first moment of the regression vector\ninduced spectral measure, and compare it with the first moment of a uniform\nspectral measure, both defined with respect to the covariance matrix of $X_n$.\nThe two moments coincide in non-confounding cases, and differ from each other\nin the presence of confounding. This statistical causal-confounding asymmetry\ncan be used for confounder detection. Without the need of analyzing the\nspectral measure pattern, our method does avoid the difficulty of metric choice\nand multiple parameter optimization. Experiments on synthetic and real data\nshow the performance of this method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 10:00:47 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 14:23:57 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Furui", ""], ["Chan", "Laiwan", ""]]}, {"id": "1803.06898", "submitter": "Yaniv Shachor", "authors": "Yaniv Shachor, Hayit Greenspan, Jacob Goldberger", "title": "A Mixture of Views Network with Applications to the Classification of\n  Breast Microcalcifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine data fusion methods for multi-view data\nclassification. We present a decision concept which explicitly takes into\naccount the input multi-view structure, where for each case there is a\ndifferent subset of relevant views. This data fusion concept, which we dub\nMixture of Views, is implemented by a special purpose neural network\narchitecture. It is demonstrated on the task of classifying breast\nmicrocalcifications as benign or malignant based on CC and MLO mammography\nviews. The single view decisions are combined by a data-driven decision,\naccording to the relevance of each view in a given case, into a global\ndecision. The method is evaluated on a large multi-view dataset extracted from\nthe standardized digital database for screening mammography (DDSM). The\nexperimental results show that our method outperforms previously suggested\nfusion methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 13:11:10 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Shachor", "Yaniv", ""], ["Greenspan", "Hayit", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1803.06905", "submitter": "Hongyu Zhu", "authors": "Hongyu Zhu, Mohamed Akrout, Bojian Zheng, Andrew Pelegris, Amar\n  Phanishayee, Bianca Schroeder, and Gennady Pekhimenko", "title": "TBD: Benchmarking and Analyzing Deep Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent popularity of deep neural networks (DNNs) has generated a lot of\nresearch interest in performing DNN-related computation efficiently. However,\nthe primary focus is usually very narrow and limited to (i) inference -- i.e.\nhow to efficiently execute already trained models and (ii) image classification\nnetworks as the primary benchmark for evaluation.\n  Our primary goal in this work is to break this myopic view by (i) proposing a\nnew benchmark for DNN training, called TBD (TBD is short for Training Benchmark\nfor DNNs), that uses a representative set of DNN models that cover a wide range\nof machine learning applications: image classification, machine translation,\nspeech recognition, object detection, adversarial networks, reinforcement\nlearning, and (ii) by performing an extensive performance analysis of training\nthese different applications on three major deep learning frameworks\n(TensorFlow, MXNet, CNTK) across different hardware configurations (single-GPU,\nmulti-GPU, and multi-machine). TBD currently covers six major application\ndomains and eight different state-of-the-art models.\n  We present a new toolchain for performance analysis for these models that\ncombines the targeted usage of existing performance analysis tools, careful\nselection of new and existing metrics and methodologies to analyze the results,\nand utilization of domain specific characteristics of DNN training. We also\nbuild a new set of tools for memory profiling in all three major frameworks;\nmuch needed tools that can finally shed some light on precisely how much memory\nis consumed by different data structures (weights, activations, gradients,\nworkspace) in DNN training. By using our tools and methodologies, we make\nseveral important observations and recommendations on where the future research\nand optimization of DNN training should be focused.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 05:16:06 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 01:21:40 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zhu", "Hongyu", ""], ["Akrout", "Mohamed", ""], ["Zheng", "Bojian", ""], ["Pelegris", "Andrew", ""], ["Phanishayee", "Amar", ""], ["Schroeder", "Bianca", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1803.06913", "submitter": "Anirban Nag", "authors": "Anirban Nag, Ali Shafiee, Rajeev Balasubramonian, Vivek Srikumar and\n  Naveen Muralimanohar", "title": "Newton: Gravitating Towards the Physical Limits of Crossbar Acceleration", "comments": "13 pages with Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have designed accelerators for Convolutional Neural\nNetworks (CNNs). While digital accelerators have relied on near data\nprocessing, analog accelerators have further reduced data movement by\nperforming in-situ computation. Recent works take advantage of highly parallel\nanalog in-situ computation in memristor crossbars to accelerate the many\nvector-matrix multiplication operations in CNNs. However, these in-situ\naccelerators have two significant short-comings that we address in this work.\nFirst, the ADCs account for a large fraction of chip power and area. Second,\nthese accelerators adopt a homogeneous design where every resource is\nprovisioned for the worst case. By addressing both problems, the new\narchitecture, Newton, moves closer to achieving optimal energy-per-neuron for\ncrossbar accelerators.\n  We introduce multiple new techniques that apply at different levels of the\ntile hierarchy. Two of the techniques leverage heterogeneity: one adapts ADC\nprecision based on the requirements of every sub-computation (with zero impact\non accuracy), and the other designs tiles customized for convolutions or\nclassifiers. Two other techniques rely on divide-and-conquer numeric algorithms\nto reduce computations and ADC pressure. Finally, we place constraints on how a\nworkload is mapped to tiles, thus helping reduce resource provisioning in\ntiles. For a wide range of CNN dataflows and structures, Newton achieves a 77%\ndecrease in power, 51% improvement in energy efficiency, and 2.2x higher\nthroughput/area, relative to the state-of-the-art ISAAC accelerator.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 05:06:57 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Nag", "Anirban", ""], ["Shafiee", "Ali", ""], ["Balasubramonian", "Rajeev", ""], ["Srikumar", "Vivek", ""], ["Muralimanohar", "Naveen", ""]]}, {"id": "1803.06952", "submitter": "Silvia-Laura Pintea", "authors": "Silvia L. Pintea, and Jan C. van Gemert, and Arnold W. M. Smeulders", "title": "Asymmetric kernel in Gaussian Processes for learning target variance", "comments": "Accepted in Pattern Recognition Letters, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work incorporates the multi-modality of the data distribution into a\nGaussian Process regression model. We approach the problem from a\ndiscriminative perspective by learning, jointly over the training data, the\ntarget space variance in the neighborhood of a certain sample through metric\nlearning. We start by using data centers rather than all training samples.\nSubsequently, each center selects an individualized kernel metric. This enables\neach center to adjust the kernel space in its vicinity in correspondence with\nthe topology of the targets --- a multi-modal approach. We additionally add\ndescriptiveness by allowing each center to learn a precision matrix. We\ndemonstrate empirically the reliability of the model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:34:35 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Pintea", "Silvia L.", ""], ["van Gemert", "Jan C.", ""], ["Smeulders", "Arnold W. M.", ""]]}, {"id": "1803.06959", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, David G.T. Barrett, Neil C. Rabinowitz, Matthew\n  Botvinick", "title": "On the importance of single directions for generalization", "comments": "ICLR 2018 conference paper; added additional methodological details", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:42:19 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 10:03:34 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 10:48:45 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:55:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Morcos", "Ari S.", ""], ["Barrett", "David G. T.", ""], ["Rabinowitz", "Neil C.", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1803.06969", "submitter": "Marco Baity-Jesi", "authors": "M. Baity-Jesi, L. Sagun, M. Geiger, S. Spigler, G. Ben Arous, C.\n  Cammarota, Y. LeCun, M. Wyart, G. Biroli", "title": "Comparing Dynamics: Deep Neural Networks versus Glassy Systems", "comments": "10 pages, 5 figures. Version accepted at ICML 2018", "journal-ref": "PMLR 80:324-333, 2018; Republication with DOI (cite this one): J.\n  Stat. Mech. (2019) 124013", "doi": "10.1088/1742-5468/ab3281", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze numerically the training dynamics of deep neural networks (DNN) by\nusing methods developed in statistical physics of glassy systems. The two main\nissues we address are (1) the complexity of the loss landscape and of the\ndynamics within it, and (2) to what extent DNNs share similarities with glassy\nsystems. Our findings, obtained for different architectures and datasets,\nsuggest that during the training process the dynamics slows down because of an\nincreasingly large number of flat directions. At large times, when the loss is\napproaching zero, the system diffuses at the bottom of the landscape. Despite\nsome similarities with the dynamics of mean-field glassy systems, in\nparticular, the absence of barrier crossing, we find distinctive dynamical\nbehaviors in the two cases, showing that the statistical properties of the\ncorresponding loss and energy landscapes are different. In contrast, when the\nnetwork is under-parametrized we observe a typical glassy behavior, thus\nsuggesting the existence of different phases depending on whether the network\nis under-parametrized or over-parametrized.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:59:01 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 10:46:06 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Baity-Jesi", "M.", ""], ["Sagun", "L.", ""], ["Geiger", "M.", ""], ["Spigler", "S.", ""], ["Arous", "G. Ben", ""], ["Cammarota", "C.", ""], ["LeCun", "Y.", ""], ["Wyart", "M.", ""], ["Biroli", "G.", ""]]}, {"id": "1803.06971", "submitter": "Lilian Besson", "authors": "Lilian Besson (IETR), Emilie Kaufmann (SEQUEL, CNRS)", "title": "What Doubling Tricks Can and Can't Do for Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online reinforcement learning algorithm is anytime if it does not need to\nknow in advance the horizon T of the experiment. A well-known technique to\nobtain an anytime algorithm from any non-anytime algorithm is the \"Doubling\nTrick\". In the context of adversarial or stochastic multi-armed bandits, the\nperformance of an algorithm is measured by its regret, and we study two\nfamilies of sequences of growing horizons (geometric and exponential) to\ngeneralize previously known results that certain doubling tricks can be used to\nconserve certain regret bounds. In a broad setting, we prove that a geometric\ndoubling trick can be used to conserve (minimax) bounds in $R\\_T = O(\\sqrt{T})$\nbut cannot conserve (distribution-dependent) bounds in $R\\_T = O(\\log T)$. We\ngive insights as to why exponential doubling tricks may be better, as they\nconserve bounds in $R\\_T = O(\\log T)$, and are close to conserving bounds in\n$R\\_T = O(\\sqrt{T})$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:02:15 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Besson", "Lilian", "", "IETR"], ["Kaufmann", "Emilie", "", "SEQUEL, CNRS"]]}, {"id": "1803.06975", "submitter": "Octavian Suciu", "authors": "Octavian Suciu, Radu M\\u{a}rginean, Yi\\u{g}itcan Kaya, Hal Daum\\'e\n  III, Tudor Dumitra\\c{s}", "title": "Technical Report: When Does Machine Learning FAIL? Generalized\n  Transferability for Evasion and Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results suggest that attacks against supervised machine learning\nsystems are quite effective, while defenses are easily bypassed by new attacks.\nHowever, the specifications for machine learning systems currently lack precise\nadversary definitions, and the existing attacks make diverse, potentially\nunrealistic assumptions about the strength of the adversary who launches them.\nWe propose the FAIL attacker model, which describes the adversary's knowledge\nand control along four dimensions. Our model allows us to consider a wide range\nof weaker adversaries who have limited control and incomplete knowledge of the\nfeatures, learning algorithms and training instances utilized. To evaluate the\nutility of the FAIL model, we consider the problem of conducting targeted\npoisoning attacks in a realistic setting: the crafted poison samples must have\nclean labels, must be individually and collectively inconspicuous, and must\nexhibit a generalized form of transferability, defined by the FAIL model. By\ntaking these constraints into account, we design StingRay, a targeted poisoning\nattack that is practical against 4 machine learning applications, which use 3\ndifferent learning algorithms, and can bypass 2 existing defenses. Conversely,\nwe show that a prior evasion attack is less effective under generalized\ntransferability. Such attack evaluations, under the FAIL adversary model, may\nalso suggest promising directions for future defenses.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:02:52 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 16:32:49 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Suciu", "Octavian", ""], ["M\u0103rginean", "Radu", ""], ["Kaya", "Yi\u011fitcan", ""], ["Daum\u00e9", "Hal", "III"], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1803.06978", "submitter": "Cihang Xie", "authors": "Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou\n  Ren, Alan Yuille", "title": "Improving Transferability of Adversarial Examples with Input Diversity", "comments": "CVPR 2019, code is available at:\n  https://github.com/cihangxie/DI-2-FGSM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though CNNs have achieved the state-of-the-art performance on various vision\ntasks, they are vulnerable to adversarial examples --- crafted by adding\nhuman-imperceptible perturbations to clean images. However, most of the\nexisting adversarial attacks only achieve relatively low success rates under\nthe challenging black-box setting, where the attackers have no knowledge of the\nmodel structure and parameters. To this end, we propose to improve the\ntransferability of adversarial examples by creating diverse input patterns.\nInstead of only using the original images to generate adversarial examples, our\nmethod applies random transformations to the input images at each iteration.\nExtensive experiments on ImageNet show that the proposed attack method can\ngenerate adversarial examples that transfer much better to different networks\nthan existing baselines. By evaluating our method against top defense solutions\nand official baselines from NIPS 2017 adversarial competition, the enhanced\nattack reaches an average success rate of 73.0%, which outperforms the top-1\nattack submission in the NIPS competition by a large margin of 6.6%. We hope\nthat our proposed attack strategy can serve as a strong benchmark baseline for\nevaluating the robustness of networks to adversaries and the effectiveness of\ndifferent defense methods in the future. Code is available at\nhttps://github.com/cihangxie/DI-2-FGSM.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:07:51 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 00:15:38 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 02:29:17 GMT"}, {"version": "v4", "created": "Sat, 1 Jun 2019 17:12:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Xie", "Cihang", ""], ["Zhang", "Zhishuai", ""], ["Zhou", "Yuyin", ""], ["Bai", "Song", ""], ["Wang", "Jianyu", ""], ["Ren", "Zhou", ""], ["Yuille", "Alan", ""]]}, {"id": "1803.06989", "submitter": "Stefan Steinerberger", "authors": "George C. Linderman, Stefan Steinerberger", "title": "Numerical Integration on Graphs: where to sample and how to weigh", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E,w)$ be a finite, connected graph with weighted edges. We are\ninterested in the problem of finding a subset $W \\subset V$ of vertices and\nweights $a_w$ such that $$ \\frac{1}{|V|}\\sum_{v \\in V}^{}{f(v)} \\sim \\sum_{w\n\\in W}{a_w f(w)}$$ for functions $f:V \\rightarrow \\mathbb{R}$ that are `smooth'\nwith respect to the geometry of the graph. The main application are problems\nwhere $f$ is known to somehow depend on the underlying graph but is expensive\nto evaluate on even a single vertex. We prove an inequality showing that the\nintegration problem can be rewritten as a geometric problem (`the optimal\npacking of heat balls'). We discuss how one would construct approximate\nsolutions of the heat ball packing problem; numerical examples demonstrate the\nefficiency of the method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:27:59 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Linderman", "George C.", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1803.06992", "submitter": "Elena Facco", "authors": "Elena Facco, Maria d'Errico, Alex Rodriguez, Alessandro Laio", "title": "Estimating the intrinsic dimension of datasets by a minimal neighborhood\n  information", "comments": "Scientific Reports 2017", "journal-ref": null, "doi": "10.1038/s41598-017-11873-y", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing large volumes of high-dimensional data is an issue of fundamental\nimportance in data science, molecular simulations and beyond. Several\napproaches work on the assumption that the important content of a dataset\nbelongs to a manifold whose Intrinsic Dimension (ID) is much lower than the\ncrude large number of coordinates. Such manifold is generally twisted and\ncurved, in addition points on it will be non-uniformly distributed: two factors\nthat make the identification of the ID and its exploitation really hard. Here\nwe propose a new ID estimator using only the distance of the first and the\nsecond nearest neighbor of each point in the sample. This extreme minimality\nenables us to reduce the effects of curvature, of density variation, and the\nresulting computational cost. The ID estimator is theoretically exact in\nuniformly distributed datasets, and provides consistent measures in general.\nWhen used in combination with block analysis, it allows discriminating the\nrelevant dimensions as a function of the block size. This allows estimating the\nID even when the data lie on a manifold perturbed by a high-dimensional noise,\na situation often encountered in real world data sets. We demonstrate the\nusefulness of the approach on molecular simulations and image analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 15:31:41 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Facco", "Elena", ""], ["d'Errico", "Maria", ""], ["Rodriguez", "Alex", ""], ["Laio", "Alessandro", ""]]}, {"id": "1803.07043", "submitter": "Patrick Johnstone", "authors": "Patrick R. Johnstone and Jonathan Eckstein", "title": "Projective Splitting with Forward Steps: Asynchronous and\n  Block-Iterative Operator Splitting", "comments": "New numerical experiments on a large-scale rare feature selection\n  problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the classical problem of finding a zero of a sum\nof maximal monotone operators. For the projective splitting framework recently\nproposed by Combettes and Eckstein, we show how to replace the fundamental\nsubproblem calculation using a backward step with one based on two forward\nsteps. The resulting algorithms have the same kind of coordination procedure\nand can be implemented in the same block-iterative and highly flexible manner,\nbut may perform backward steps on some operators and forward steps on others.\nPrior algorithms in the projective splitting family have used only backward\nsteps. Forward steps can be used for any Lipschitz-continuous operators\nprovided the stepsize is bounded by the inverse of the Lipschitz constant. If\nthe Lipschitz constant is unknown, a simple backtracking linesearch procedure\nmay be used. For affine operators, the stepsize can be chosen adaptively\nwithout knowledge of the Lipschitz constant and without any additional forward\nsteps. We close the paper by empirically studying the performance of several\nkinds of splitting algorithms on a large-scale rare feature selection problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:15:43 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 00:00:57 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 14:50:18 GMT"}, {"version": "v4", "created": "Sat, 23 Jun 2018 18:46:27 GMT"}, {"version": "v5", "created": "Fri, 20 Jul 2018 20:35:36 GMT"}, {"version": "v6", "created": "Wed, 8 Aug 2018 18:14:49 GMT"}, {"version": "v7", "created": "Thu, 20 Aug 2020 19:01:39 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Johnstone", "Patrick R.", ""], ["Eckstein", "Jonathan", ""]]}, {"id": "1803.07055", "submitter": "Horia Mania", "authors": "Horia Mania, Aurelia Guy, Benjamin Recht", "title": "Simple random search provides a competitive approach to reinforcement\n  learning", "comments": "22 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:35:14 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mania", "Horia", ""], ["Guy", "Aurelia", ""], ["Recht", "Benjamin", ""]]}, {"id": "1803.07067", "submitter": "Ashique Rupam Mahmood", "authors": "A. Rupam Mahmood, Dmytro Korenkevych, Brent J. Komer, James Bergstra", "title": "Setting up a Reinforcement Learning Task with a Real-World Robot", "comments": "Submitted to 2018 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:59:05 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mahmood", "A. Rupam", ""], ["Korenkevych", "Dmytro", ""], ["Komer", "Brent J.", ""], ["Bergstra", "James", ""]]}, {"id": "1803.07068", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, Ji Liu", "title": "D$^2$: Decentralized Training over Decentralized Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training a machine learning model using multiple workers, each of which\ncollects data from their own data sources, it would be most useful when the\ndata collected from different workers can be {\\em unique} and {\\em different}.\nIronically, recent analysis of decentralized parallel stochastic gradient\ndescent (D-PSGD) relies on the assumption that the data hosted on different\nworkers are {\\em not too different}. In this paper, we ask the question: {\\em\nCan we design a decentralized parallel stochastic gradient descent algorithm\nthat is less sensitive to the data variance across workers?} In this paper, we\npresent D$^2$, a novel decentralized parallel stochastic gradient descent\nalgorithm designed for large data variance \\xr{among workers} (imprecisely,\n\"decentralized\" data). The core of D$^2$ is a variance blackuction extension of\nthe standard D-PSGD algorithm, which improves the convergence rate from\n$O\\left({\\sigma \\over \\sqrt{nT}} + {(n\\zeta^2)^{\\frac{1}{3}} \\over\nT^{2/3}}\\right)$ to $O\\left({\\sigma \\over \\sqrt{nT}}\\right)$ where $\\zeta^{2}$\ndenotes the variance among data on different workers. As a result, D$^2$ is\nrobust to data variance among workers. We empirically evaluated D$^2$ on image\nclassification tasks where each worker has access to only the data of a limited\nset of labels, and find that D$^2$ significantly outperforms D-PSGD.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:59:11 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 00:13:16 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Yan", "Ming", ""], ["Zhang", "Ce", ""], ["Liu", "Ji", ""]]}, {"id": "1803.07102", "submitter": "Felipe Tobar", "authors": "Gonzalo Rios and Felipe Tobar", "title": "Learning non-Gaussian Time Series using the Box-Cox Gaussian Process", "comments": "Accepted at IEEE IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are Bayesian nonparametric generative models that\nprovide interpretability of hyperparameters, admit closed-form expressions for\ntraining and inference, and are able to accurately represent uncertainty. To\nmodel general non-Gaussian data with complex correlation structure, GPs can be\npaired with an expressive covariance kernel and then fed into a nonlinear\ntransformation (or warping). However, overparametrising the kernel and the\nwarping is known to, respectively, hinder gradient-based training and make the\npredictions computationally expensive. We remedy this issue by (i) training the\nmodel using derivative-free global-optimisation techniques so as to find\nmeaningful maxima of the model likelihood, and (ii) proposing a warping\nfunction based on the celebrated Box-Cox transformation that requires minimal\nnumerical approximations---unlike existing warped GP models. We validate the\nproposed approach by first showing that predictions can be computed\nanalytically, and then on a learning, reconstruction and forecasting experiment\nusing real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 18:21:34 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Rios", "Gonzalo", ""], ["Tobar", "Felipe", ""]]}, {"id": "1803.07133", "submitter": "Sidi Lu", "authors": "Sidi Lu, Yaoming Zhu, Weinan Zhang, Jun Wang, Yong Yu", "title": "Neural Text Generation: Past, Present and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic survey on recent development of neural text\ngeneration models. Specifically, we start from recurrent neural network\nlanguage models with the traditional maximum likelihood estimation training\nscheme and point out its shortcoming for text generation. We thus introduce the\nrecently proposed methods for text generation based on reinforcement learning,\nre-parametrization tricks and generative adversarial nets (GAN) techniques. We\ncompare different properties of these models and the corresponding techniques\nto handle their common problems such as gradient vanishing and generation\ndiversity. Finally, we conduct a benchmarking experiment with different types\nof neural text generation models on two well-known datasets and discuss the\nempirical results along with the aforementioned model properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 07:54:30 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Lu", "Sidi", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1803.07164", "submitter": "Vasilis Syrgkanis", "authors": "Greg Lewis, Vasilis Syrgkanis", "title": "Adversarial Generalized Method of Moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.GT cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an approach for learning deep neural net representations of models\ndescribed via conditional moment restrictions. Conditional moment restrictions\nare widely used, as they are the language by which social scientists describe\nthe assumptions they make to enable causal inference. We formulate the problem\nof estimating the underling model as a zero-sum game between a modeler and an\nadversary and apply adversarial training. Our approach is similar in nature to\nGenerative Adversarial Networks (GAN), though here the modeler is learning a\nrepresentation of a function that satisfies a continuum of moment conditions\nand the adversary is identifying violating moments. We outline ways of\nconstructing effective adversaries in practice, including kernels centered by\nk-means clustering, and random forests. We examine the practical performance of\nour approach in the setting of non-parametric instrumental variable regression.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 21:02:51 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 13:27:54 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1803.07192", "submitter": "Raunak Dey", "authors": "Raunak Dey, Zhongjie Lu, Yi Hong", "title": "Diagnostic Classification Of Lung Nodules Using 3D Neural Networks", "comments": "Accepted for publication in IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2018 Copyright c 2018 IEEE", "journal-ref": null, "doi": "10.1109/ISBI.2018.8363687", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is the leading cause of cancer-related death worldwide. Early\ndiagnosis of pulmonary nodules in Computed Tomography (CT) chest scans provides\nan opportunity for designing effective treatment and making financial and care\nplans. In this paper, we consider the problem of diagnostic classification\nbetween benign and malignant lung nodules in CT images, which aims to learn a\ndirect mapping from 3D images to class labels. To achieve this goal, four\ntwo-pathway Convolutional Neural Networks (CNN) are proposed, including a basic\n3D CNN, a novel multi-output network, a 3D DenseNet, and an augmented 3D\nDenseNet with multi-outputs. These four networks are evaluated on the public\nLIDC-IDRI dataset and outperform most existing methods. In particular, the 3D\nmulti-output DenseNet (MoDenseNet) achieves the state-of-the-art classification\naccuracy on the task of end-to-end lung nodule diagnosis. In addition, the\nnetworks pretrained on the LIDC-IDRI dataset can be further extended to handle\nsmaller datasets using transfer learning. This is demonstrated on our dataset\nwith encouraging prediction accuracy in lung nodule classification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 23:02:37 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Dey", "Raunak", ""], ["Lu", "Zhongjie", ""], ["Hong", "Yi", ""]]}, {"id": "1803.07200", "submitter": "Hamid Khodabandehlou", "authors": "Hamid Khodabandehlou and M. Sami Fadali", "title": "Training Recurrent Neural Networks as a Constraint Satisfaction Problem", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new approach for training artificial neural networks\nusing techniques for solving the constraint satisfaction problem (CSP). The\nquotient gradient system (QGS) is a trajectory-based method for solving the\nCSP. This study converts the training set of a neural network into a CSP and\nuses the QGS to find its solutions. The QGS finds the global minimum of the\noptimization problem by tracking trajectories of a nonlinear dynamical system\nand does not stop at a local minimum of the optimization problem. Lyapunov\ntheory is used to prove the asymptotic stability of the solutions with and\nwithout the presence of measurement errors. Numerical examples illustrate the\neffectiveness of the proposed methodology and compare it to a genetic algorithm\nand error backpropagation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 00:12:26 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 17:56:14 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 18:26:29 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2018 01:20:13 GMT"}, {"version": "v5", "created": "Tue, 17 Apr 2018 00:31:40 GMT"}, {"version": "v6", "created": "Sun, 6 May 2018 22:21:51 GMT"}, {"version": "v7", "created": "Mon, 14 May 2018 05:14:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Khodabandehlou", "Hamid", ""], ["Fadali", "M. Sami", ""]]}, {"id": "1803.07225", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Ga\\\"etan Hadjeres", "title": "Monte Carlo Information Geometry: The dually flat case", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential families and mixture families are parametric probability models\nthat can be geometrically studied as smooth statistical manifolds with respect\nto any statistical divergence like the Kullback-Leibler (KL) divergence or the\nHellinger divergence. When equipping a statistical manifold with the KL\ndivergence, the induced manifold structure is dually flat, and the KL\ndivergence between distributions amounts to an equivalent Bregman divergence on\ntheir corresponding parameters. In practice, the corresponding Bregman\ngenerators of mixture/exponential families require to perform definite integral\ncalculus that can either be too time-consuming (for exponentially large\ndiscrete support case) or even do not admit closed-form formula (for continuous\nsupport case). In these cases, the dually flat construction remains theoretical\nand cannot be used by information-geometric algorithms. To bypass this problem,\nwe consider performing stochastic Monte Carlo (MC) estimation of those\nintegral-based mixture/exponential family Bregman generators. We show that,\nunder natural assumptions, these MC generators are almost surely Bregman\ngenerators. We define a series of dually flat information geometries, termed\nMonte Carlo Information Geometries, that increasingly-finely approximate the\nuntractable geometry. The advantage of this MCIG is that it allows a practical\nuse of the Bregman algorithmic toolbox on a wide range of probability\ndistribution families. We demonstrate our approach with a clustering task on a\nmixture family manifold.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 02:39:37 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Nielsen", "Frank", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1803.07246", "submitter": "Cathy Wu", "authors": "Cathy Wu, Aravind Rajeswaran, Yan Duan, Vikash Kumar, Alexandre M\n  Bayen, Sham Kakade, Igor Mordatch, Pieter Abbeel", "title": "Variance Reduction for Policy Gradient with Action-Dependent Factorized\n  Baselines", "comments": "Accepted to ICLR 2018, Oral (2%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have enjoyed great success in deep reinforcement\nlearning but suffer from high variance of gradient estimates. The high variance\nproblem is particularly exasperated in problems with long horizons or\nhigh-dimensional action spaces. To mitigate this issue, we derive a bias-free\naction-dependent baseline for variance reduction which fully exploits the\nstructural form of the stochastic policy itself and does not make any\nadditional assumptions about the MDP. We demonstrate and quantify the benefit\nof the action-dependent baseline through both theoretical analysis as well as\nnumerical results, including an analysis of the suboptimality of the optimal\nstate-dependent baseline. The result is a computationally efficient policy\ngradient algorithm, which scales to high-dimensional control problems, as\ndemonstrated by a synthetic 2000-dimensional target matching task. Our\nexperimental results indicate that action-dependent baselines allow for faster\nlearning on standard reinforcement learning benchmarks and high-dimensional\nhand manipulation and synthetic tasks. Finally, we show that the general idea\nof including additional information in baselines for improved variance\nreduction can be extended to partially observed and multi-agent tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:52:04 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wu", "Cathy", ""], ["Rajeswaran", "Aravind", ""], ["Duan", "Yan", ""], ["Kumar", "Vikash", ""], ["Bayen", "Alexandre M", ""], ["Kakade", "Sham", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.07247", "submitter": "Ziping Zhao", "authors": "Ziping Zhao, Daniel P. Palomar", "title": "Sparse Reduced Rank Regression With Nonconvex Regularization", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.CP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the estimation problem for sparse reduced rank regression\n(SRRR) model is considered. The SRRR model is widely used for dimension\nreduction and variable selection with applications in signal processing,\neconometrics, etc. The problem is formulated to minimize the least squares loss\nwith a sparsity-inducing penalty considering an orthogonality constraint.\nConvex sparsity-inducing functions have been used for SRRR in literature. In\nthis work, a nonconvex function is proposed for better sparsity inducing. An\nefficient algorithm is developed based on the alternating minimization (or\nprojection) method to solve the nonconvex optimization problem. Numerical\nsimulations show that the proposed algorithm is much more efficient compared to\nthe benchmark methods and the nonconvex function can result in a better\nestimation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 04:07:02 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Zhao", "Ziping", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1803.07276", "submitter": "Zhenglin Wu", "authors": "Haohan Wang, Zhenglin Wu and Eric P. Xing", "title": "Removing Confounding Factors Associated Weights in Deep Neural Networks\n  Improves the Prediction Accuracy for Healthcare Applications", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of healthcare data has brought the opportunities of\napplying data-driven approaches, such as machine learning methods, to assist\ndiagnosis. Recently, many deep learning methods have been shown with impressive\nsuccesses in predicting disease status with raw input data. However, the\n\"black-box\" nature of deep learning and the high-reliability requirement of\nbiomedical applications have created new challenges regarding the existence of\nconfounding factors. In this paper, with a brief argument that inappropriate\nhandling of confounding factors will lead to models' sub-optimal performance in\nreal-world applications, we present an efficient method that can remove the\ninfluences of confounding factors such as age or gender to improve the\nacross-cohort prediction accuracy of neural networks. One distinct advantage of\nour method is that it only requires minimal changes of the baseline model's\narchitecture so that it can be plugged into most of the existing neural\nnetworks. We conduct experiments across CT-scan, MRA, and EEG brain wave with\nconvolutional neural networks and LSTM to verify the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 07:24:40 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 19:25:39 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 05:35:08 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Wang", "Haohan", ""], ["Wu", "Zhenglin", ""], ["Xing", "Eric P.", ""]]}, {"id": "1803.07294", "submitter": "Jiani Zhang", "authors": "Jiani Zhang, Xingjian Shi, Junyuan Xie, Hao Ma, Irwin King, Dit-Yan\n  Yeung", "title": "GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new network architecture, Gated Attention Networks (GaAN), for\nlearning on graphs. Unlike the traditional multi-head attention mechanism,\nwhich equally consumes all attention heads, GaAN uses a convolutional\nsub-network to control each attention head's importance. We demonstrate the\neffectiveness of GaAN on the inductive node classification problem. Moreover,\nwith GaAN as a building block, we construct the Graph Gated Recurrent Unit\n(GGRU) to address the traffic speed forecasting problem. Extensive experiments\non three real-world datasets show that our GaAN framework achieves\nstate-of-the-art results on both tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 08:33:20 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Zhang", "Jiani", ""], ["Shi", "Xingjian", ""], ["Xie", "Junyuan", ""], ["Ma", "Hao", ""], ["King", "Irwin", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1803.07300", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji and Matus Telgarsky", "title": "Risk and parameter convergence of logistic regression", "comments": "Appears in COLT 2019 with the title \"The implicit bias of gradient\n  descent on nonseparable data\" (and no other changes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent, when applied to the task of logistic regression, outputs\niterates which are biased to follow a unique ray defined by the data. The\ndirection of this ray is the maximum margin predictor of a maximal linearly\nseparable subset of the data; the gradient descent iterates converge to this\nray in direction at the rate $\\mathcal{O}(\\ln\\ln t / \\ln t)$. The ray does not\npass through the origin in general, and its offset is the bounded global\noptimum of the risk over the remaining data; gradient descent recovers this\noffset at a rate $\\mathcal{O}((\\ln t)^2 / \\sqrt{t})$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 08:47:27 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 07:53:44 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 13:57:05 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1803.07347", "submitter": "Li He", "authors": "Li He, Liang Wang, Kaipeng Liu, Bo Wu, Weinan Zhang", "title": "Optimizing Sponsored Search Ranking Strategy by Deep Reinforcement\n  Learning", "comments": "revise some content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search is an indispensable business model and a major revenue\ncontributor of almost all the search engines. From the advertisers' side,\nparticipating in ranking the search results by paying for the sponsored search\nadvertisement to attract more awareness and purchase facilitates their\ncommercial goal. From the users' side, presenting personalized advertisement\nreflecting their propensity would make their online search experience more\nsatisfactory. Sponsored search platforms rank the advertisements by a ranking\nfunction to determine the list of advertisements to show and the charging price\nfor the advertisers. Hence, it is crucial to find a good ranking function which\ncan simultaneously satisfy the platform, the users and the advertisers.\nMoreover, advertisements showing positions under different queries from\ndifferent users may associate with advertisement candidates of different bid\nprice distributions and click probability distributions, which requires the\nranking functions to be optimized adaptively to the traffic characteristics. In\nthis work, we proposed a generic framework to optimize the ranking functions by\ndeep reinforcement learning methods. The framework is composed of two parts: an\noffline learning part which initializes the ranking functions by learning from\na simulated advertising environment, allowing adequate exploration of the\nranking function parameter space without hurting the performance of the\ncommercial platform. An online learning part which further optimizes the\nranking functions by adapting to the online data distribution. Experimental\nresults on a large-scale sponsored search platform confirm the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:18:26 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 09:29:59 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 05:01:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["He", "Li", ""], ["Wang", "Liang", ""], ["Liu", "Kaipeng", ""], ["Wu", "Bo", ""], ["Zhang", "Weinan", ""]]}, {"id": "1803.07348", "submitter": "Thomas Kerdreux", "authors": "Thomas Kerdreux, Fabian Pedregosa and Alexandre d'Aspremont", "title": "Frank-Wolfe with Subsampling Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze two novel randomized variants of the Frank-Wolfe (FW) or\nconditional gradient algorithm. While classical FW algorithms require solving a\nlinear minimization problem over the domain at each iteration, the proposed\nmethod only requires to solve a linear minimization problem over a small\n\\emph{subset} of the original domain. The first algorithm that we propose is a\nrandomized variant of the original FW algorithm and achieves a\n$\\mathcal{O}(1/t)$ sublinear convergence rate as in the deterministic\ncounterpart. The second algorithm is a randomized variant of the Away-step FW\nalgorithm, and again as its deterministic counterpart, reaches linear (i.e.,\nexponential) convergence rate making it the first provably convergent\nrandomized variant of Away-step FW. In both cases, while subsampling reduces\nthe convergence rate by a constant factor, the linear minimization step can be\na fraction of the cost of that of the deterministic versions, especially when\nthe data is streamed. We illustrate computational gains of the algorithms on\nregression problems, involving both $\\ell_1$ and latent group lasso penalties.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:18:59 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Kerdreux", "Thomas", ""], ["Pedregosa", "Fabian", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "1803.07416", "submitter": "Ryan Sepassi", "authors": "Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N.\n  Gomez, Stephan Gouws, Llion Jones, {\\L}ukasz Kaiser, Nal Kalchbrenner, Niki\n  Parmar, Ryan Sepassi, Noam Shazeer, Jakob Uszkoreit", "title": "Tensor2Tensor for Neural Machine Translation", "comments": "arXiv admin note: text overlap with arXiv:1706.03762", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tensor2Tensor is a library for deep learning models that is well-suited for\nneural machine translation and includes the reference implementation of the\nstate-of-the-art Transformer model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 18:49:22 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Vaswani", "Ashish", ""], ["Bengio", "Samy", ""], ["Brevdo", "Eugene", ""], ["Chollet", "Francois", ""], ["Gomez", "Aidan N.", ""], ["Gouws", "Stephan", ""], ["Jones", "Llion", ""], ["Kaiser", "\u0141ukasz", ""], ["Kalchbrenner", "Nal", ""], ["Parmar", "Niki", ""], ["Sepassi", "Ryan", ""], ["Shazeer", "Noam", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1803.07423", "submitter": "Chengjia Wang", "authors": "Chengjia Wang, Keith A. Goatman, James Boardman, Erin Beveridge, David\n  Newby, and Scott Semple", "title": "A Distance Oriented Kalman Filter Particle Swarm Optimizer Applied to\n  Multi-Modality Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe improvements to the particle swarm optimizer (PSO)\nmade by inclusion of an unscented Kalman filter to guide particle motion. We\ndemonstrate the effectiveness of the unscented Kalman filter PSO by comparing\nit with the original PSO algorithm and its variants designed to improve\nperformance. The PSOs were tested firstly on a number of common synthetic\nbenchmarking functions, and secondly applied to a practical three-dimensional\nimage registration problem. The proposed methods displayed better performances\nfor 4 out of 8 benchmark functions, and reduced the target registration errors\nby at least 2mm when registering down-sampled benchmark brain images. Our\nmethods also demonstrated an ability to align images featuring motion related\nartefacts which all other methods failed to register. These new PSO methods\nprovide a novel, efficient mechanism to integrate prior knowledge into each\niteration of the optimization process, which can enhance the accuracy and speed\nof convergence in the application of medical image registration.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 13:40:36 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Chengjia", ""], ["Goatman", "Keith A.", ""], ["Boardman", "James", ""], ["Beveridge", "Erin", ""], ["Newby", "David", ""], ["Semple", "Scott", ""]]}, {"id": "1803.07445", "submitter": "Henggang Cui Dr", "authors": "Henggang Cui, Gregory R. Ganger, Phillip B. Gibbons", "title": "MLtuner: System Support for Automatic Machine Learning Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MLtuner automatically tunes settings for training tunables (such as the\nlearning rate, the momentum, the mini-batch size, and the data staleness bound)\nthat have a significant impact on large-scale machine learning (ML)\nperformance. Traditionally, these tunables are set manually, which is\nunsurprisingly error-prone and difficult to do without extensive domain\nknowledge. MLtuner uses efficient snapshotting, branching, and\noptimization-guided online trial-and-error to find good initial settings as\nwell as to re-tune settings during execution. Experiments show that MLtuner can\nrobustly find and re-tune tunable settings for a variety of ML applications,\nincluding image classification (for 3 models and 2 datasets), video\nclassification, and matrix factorization. Compared to state-of-the-art ML\nauto-tuning approaches, MLtuner is more robust for large problems and over an\norder of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 14:17:36 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Cui", "Henggang", ""], ["Ganger", "Gregory R.", ""], ["Gibbons", "Phillip B.", ""]]}, {"id": "1803.07452", "submitter": "Adrian Shajkofci", "authors": "Adrian Shajkofci, Michael Liebling", "title": "Semi-Blind Spatially-Variant Deconvolution in Optical Microscopy with\n  Local Point Spread Function Estimation By Use Of Convolutional Neural\n  Networks", "comments": "2018/02/11: submitted to IEEE ICIP 2018 - 2018/05/04: accepted to\n  IEEE ICIP 2018", "journal-ref": "2018 25th IEEE International Conference on Image Processing (ICIP)", "doi": "10.1109/ICIP.2018.8451736", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semi-blind, spatially-variant deconvolution technique aimed at\noptical microscopy that combines a local estimation step of the point spread\nfunction (PSF) and deconvolution using a spatially variant, regularized\nRichardson-Lucy algorithm. To find the local PSF map in a computationally\ntractable way, we train a convolutional neural network to perform regression of\nan optical parametric model on synthetically blurred image patches. We\ndeconvolved both synthetic and experimentally-acquired data, and achieved an\nimprovement of image SNR of 1.00 dB on average, compared to other deconvolution\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 14:29:12 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 13:49:44 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 13:42:13 GMT"}, {"version": "v4", "created": "Fri, 17 May 2019 18:17:54 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Shajkofci", "Adrian", ""], ["Liebling", "Michael", ""]]}, {"id": "1803.07482", "submitter": "Ethan Knight", "authors": "Ethan Knight, Osher Lerner", "title": "Natural Gradient Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm to train a deep Q-learning agent using\nnatural-gradient techniques. We compare the original deep Q-network (DQN)\nalgorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a\ncollection of classic control domains. Without employing target networks, NGDQN\nsignificantly outperforms DQN without target networks, and performs no worse\nthan DQN with target networks, suggesting that NGDQN stabilizes training and\ncan help reduce the need for additional hyperparameter tuning. We also find\nthat NGDQN is less sensitive to hyperparameter optimization relative to DQN.\nTogether these results suggest that natural-gradient techniques can improve\nvalue-function optimization in deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 15:22:52 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 20:10:03 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Knight", "Ethan", ""], ["Lerner", "Osher", ""]]}, {"id": "1803.07517", "submitter": "Gabrielle Ras", "authors": "Gabrielle Ras, Marcel van Gerven, Pim Haselager", "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges", "comments": "14 pages, 1 figure, This article will appear as a chapter in\n  Explainable and Interpretable Models in Computer Vision and Machine Learning\n  Springer series on Challenges in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:44:47 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 15:06:04 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Haselager", "Pim", ""]]}, {"id": "1803.07519", "submitter": "Minhui Xue", "authors": "Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li,\n  Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang", "title": "DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems", "comments": "The 33rd IEEE/ACM International Conference on Automated Software\n  Engineering (ASE 2018)", "journal-ref": "DeepGauge: Multi-Granularity Testing Criteria for Deep Learning\n  Systems. In Proceedings of the 33rd ACM/IEEE International Conference on\n  Automated Software Engineering (ASE 18), September 3-7, 2018, Montpellier,\n  France", "doi": "10.1145/3238147.3238202", "report-no": null, "categories": "cs.SE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) defines a new data-driven programming paradigm that\nconstructs the internal system logic of a crafted neuron network through a set\nof training data. We have seen wide adoption of DL in many safety-critical\nscenarios. However, a plethora of studies have shown that the state-of-the-art\nDL systems suffer from various vulnerabilities which can lead to severe\nconsequences when applied to real-world applications. Currently, the testing\nadequacy of a DL system is usually measured by the accuracy of test data.\nConsidering the limitation of accessible high quality test data, good accuracy\nperformance on test data can hardly provide confidence to the testing adequacy\nand generality of DL systems. Unlike traditional software systems that have\nclear and controllable logic and functionality, the lack of interpretability in\na DL system makes system analysis and defect detection difficult, which could\npotentially hinder its real-world deployment. In this paper, we propose\nDeepGauge, a set of multi-granularity testing criteria for DL systems, which\naims at rendering a multi-faceted portrayal of the testbed. The in-depth\nevaluation of our proposed testing criteria is demonstrated on two well-known\ndatasets, five DL systems, and with four state-of-the-art adversarial attack\ntechniques against DL. The potential usefulness of DeepGauge sheds light on the\nconstruction of more generic and robust DL systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:52:12 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 05:02:54 GMT"}, {"version": "v3", "created": "Sat, 28 Jul 2018 07:47:27 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 23:07:39 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Zhang", "Fuyuan", ""], ["Sun", "Jiyuan", ""], ["Xue", "Minhui", ""], ["Li", "Bo", ""], ["Chen", "Chunyang", ""], ["Su", "Ting", ""], ["Li", "Li", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Wang", "Yadong", ""]]}, {"id": "1803.07534", "submitter": "Charles Lu", "authors": "Charles Lu, M. Marx, M. Zahid, C. W. Lo, C. Chennubhotla, S. P. Quinn", "title": "Stacked Neural Networks for end-to-end ciliary motion analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cilia are hairlike structures protruding from nearly every cell in the body.\nDiseases known as ciliopathies, where cilia function is disrupted, can result\nin a wide spectrum of disorders. However, most techniques for assessing ciliary\nmotion rely on manual identification and tracking of cilia; this process is\nlaborious and error-prone, and does not scale well. Even where automated\nciliary motion analysis tools exist, their applicability is limited. Here, we\npropose an end-to-end computational machine learning pipeline that\nautomatically identifies regions of cilia from videos, extracts patches of\ncilia, and classifies patients as exhibiting normal or abnormal ciliary motion.\nIn particular, we demonstrate how convolutional LSTM are able to encode complex\nfeatures while remaining sensitive enough to differentiate between a variety of\nmotion patterns. Our framework achieves 90% with only a few hundred training\nepochs. We find that the combination of segmentation and classification\nnetworks in a single pipeline yields performance comparable to existing\ncomputational pipelines, while providing the additional benefit of an\nend-to-end, fully-automated analysis toolbox for ciliary motion.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:17:39 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Lu", "Charles", ""], ["Marx", "M.", ""], ["Zahid", "M.", ""], ["Lo", "C. W.", ""], ["Chennubhotla", "C.", ""], ["Quinn", "S. P.", ""]]}, {"id": "1803.07551", "submitter": "Steindor Saemundsson", "authors": "Steind\\'or S{\\ae}mundsson, Katja Hofmann, Marc Peter Deisenroth", "title": "Meta Reinforcement Learning with Latent Variable Gaussian Processes", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from small data sets is critical in many practical applications\nwhere data collection is time consuming or expensive, e.g., robotics, animal\nexperiments or drug design. Meta learning is one way to increase the data\nefficiency of learning algorithms by generalizing learned concepts from a set\nof training tasks to unseen, but related, tasks. Often, this relationship\nbetween tasks is hard coded or relies in some other way on human expertise. In\nthis paper, we frame meta learning as a hierarchical latent variable model and\ninfer the relationship between tasks automatically from data. We apply our\nframework in a model-based reinforcement learning setting and show that our\nmeta-learning model effectively generalizes to novel tasks by identifying how\nnew tasks relate to prior ones from minimal data. This results in up to a 60%\nreduction in the average interaction time needed to solve tasks compared to\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:51:10 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 09:28:57 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["S\u00e6mundsson", "Steind\u00f3r", ""], ["Hofmann", "Katja", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1803.07554", "submitter": "Lijun Ding", "authors": "Lijun Ding, Yudong Chen", "title": "Leave-one-out Approach for Matrix Completion: Primal and Dual Analysis", "comments": "45 pages. The sample complexity for nuclear norm minimization has\n  been reduced to $\\mathcal{O}(\\mu r \\log(\\mu r)d \\log d )$ from\n  $\\mathcal{O}(\\mu^2 r^3 d \\log d)$ in the early version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a powerful technique based on Leave-one-out\nanalysis to the study of low-rank matrix completion problems. Using this\ntechnique, we develop a general approach for obtaining fine-grained, entrywise\nbounds for iterative stochastic procedures in the presence of probabilistic\ndependency. We demonstrate the power of this approach in analyzing two of the\nmost important algorithms for matrix completion: (i) the non-convex approach\nbased on Projected Gradient Descent (PGD) for a rank-constrained formulation,\nalso known as the Singular Value Projection algorithm, and (ii) the convex\nrelaxation approach based on nuclear norm minimization (NNM).\n  Using this approach, we establish the first convergence guarantee for the\noriginal form of PGD without regularization or sample splitting}, and in\nparticular shows that it converges linearly in the infinity norm. For NNM, we\nuse this approach to study a fictitious iterative procedure that arises in the\ndual analysis. Our results show that \\NNM recovers an $ d $-by-$ d $ rank-$ r $\nmatrix with $\\mathcal{O}(\\mu r \\log(\\mu r) d \\log d )$ observed entries. This\nbound has optimal dependence on the matrix dimension and is independent of the\ncondition number. To the best of our knowledge, this is the first sample\ncomplexity result for a tractable matrix completion algorithm that satisfies\nthese two properties simultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:54:49 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 02:01:03 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 04:45:20 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ding", "Lijun", ""], ["Chen", "Yudong", ""]]}, {"id": "1803.07612", "submitter": "Eric Zhan", "authors": "Eric Zhan, Stephan Zheng, Yisong Yue, Long Sha, Patrick Lucey", "title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training sequential generative models for capturing\ncoordinated multi-agent trajectory behavior, such as offensive basketball\ngameplay. When modeling such settings, it is often beneficial to design\nhierarchical models that can capture long-term coordination using intermediate\nvariables. Furthermore, these intermediate variables should capture interesting\nhigh-level behavioral semantics in an interpretable and manipulatable way. We\npresent a hierarchical framework that can effectively learn such sequential\ngenerative models. Our approach is inspired by recent work on leveraging\nprogrammatically produced weak labels, which we extend to the spatiotemporal\nregime. In addition to synthetic settings, we show how to instantiate our\nframework to effectively model complex interactions between basketball players\nand generate realistic multi-agent trajectories of basketball gameplay over\nlong time periods. We validate our approach using both quantitative and\nqualitative evaluations, including a user study comparison conducted with\nprofessional sports analysts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:19:13 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 08:31:55 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 06:35:59 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2018 18:36:15 GMT"}, {"version": "v5", "created": "Sun, 20 May 2018 20:48:45 GMT"}, {"version": "v6", "created": "Fri, 22 Feb 2019 05:40:13 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Zhan", "Eric", ""], ["Zheng", "Stephan", ""], ["Yue", "Yisong", ""], ["Sha", "Long", ""], ["Lucey", "Patrick", ""]]}, {"id": "1803.07617", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin and Karthik Sridharan", "title": "Online Learning: Sufficient Statistics and the Burkholder Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We uncover a fairly general principle in online learning: If regret can be\n(approximately) expressed as a function of certain \"sufficient statistics\" for\nthe data sequence, then there exists a special Burkholder function that 1) can\nbe used algorithmically to achieve the regret bound and 2) only depends on\nthese sufficient statistics, not the entire data sequence, so that the online\nstrategy is only required to keep the sufficient statistics in memory. This\ncharacterization is achieved by bringing the full power of the Burkholder\nMethod --- originally developed for certifying probabilistic martingale\ninequalities --- to bear on the online learning setting.\n  To demonstrate the scope and effectiveness of the Burkholder method, we\ndevelop a novel online strategy for matrix prediction that attains a regret\nbound corresponding to the variance term in matrix concentration inequalities.\nWe also present a linear-time/space prediction strategy for parameter free\nsupervised learning with linear classes and general smooth norms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:29:46 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1803.07624", "submitter": "Jialin Wu", "authors": "Jialin Wu, Dai Li, Yu Yang, Chandrajit Bajaj, Xiangyang Ji", "title": "Dynamic Filtering with Large Sampling Field for ConvNets", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic filtering strategy with large sampling field for\nConvNets (LS-DFN), where the position-specific kernels learn from not only the\nidentical position but also multiple sampled neighbor regions. During sampling,\nresidual learning is introduced to ease training and an attention mechanism is\napplied to fuse features from different samples. Such multiple samples enlarge\nthe kernels' receptive fields significantly without requiring more parameters.\nWhile LS-DFN inherits the advantages of DFN, namely avoiding feature map\nblurring by position-wise kernels while keeping translation invariance, it also\nefficiently alleviates the overfitting issue caused by much more parameters\nthan normal CNNs. Our model is efficient and can be trained end-to-end via\nstandard back-propagation. We demonstrate the merits of our LS-DFN on both\nsparse and dense prediction tasks involving object detection, semantic\nsegmentation, and flow estimation. Our results show LS-DFN enjoys stronger\nrecognition abilities in object detection and semantic segmentation tasks on\nVOC benchmark and sharper responses in flow estimation on FlyingChairs dataset\ncompared to strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:52:16 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:03:36 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 14:37:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wu", "Jialin", ""], ["Li", "Dai", ""], ["Yang", "Yu", ""], ["Bajaj", "Chandrajit", ""], ["Ji", "Xiangyang", ""]]}, {"id": "1803.07634", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven, Elena Marchiori", "title": "Domain Adaptation with Randomized Expectation Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) is the task of classifying an unlabeled dataset\n(target) using a labeled dataset (source) from a related domain. The majority\nof successful DA methods try to directly match the distributions of the source\nand target data by transforming the feature space. Despite their success, state\nof the art methods based on this approach are either involved or unable to\ndirectly scale to data with many features. This article shows that domain\nadaptation can be successfully performed by using a very simple randomized\nexpectation maximization (EM) method. We consider two instances of the method,\nwhich involve logistic regression and support vector machine, respectively. The\nunderlying assumption of the proposed method is the existence of a good single\nlinear classifier for both source and target domain. The potential limitations\nof this assumption are alleviated by the flexibility of the method, which can\ndirectly incorporate deep features extracted from a pre-trained deep neural\nnetwork. The resulting algorithm is strikingly easy to implement and apply. We\ntest its performance on 36 real-life adaptation tasks over text and image data\nwith diverse characteristics. The method achieves state-of-the-art results,\ncompetitive with those of involved end-to-end deep transfer-learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 20:13:09 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1803.07635", "submitter": "Garrett Thomas", "authors": "Garrett Thomas, Melissa Chien, Aviv Tamar, Juan Aparicio Ojea, Pieter\n  Abbeel", "title": "Learning Robotic Assembly from CAD", "comments": "In the proceedings of the IEEE International Conference on Robotics\n  and Automation (ICRA), Brisbane, Australia, May 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, motivated by recent manufacturing trends, we investigate\nautonomous robotic assembly. Industrial assembly tasks require contact-rich\nmanipulation skills, which are challenging to acquire using classical control\nand motion planning approaches. Consequently, robot controllers for assembly\ndomains are presently engineered to solve a particular task, and cannot easily\nhandle variations in the product or environment. Reinforcement learning (RL) is\na promising approach for autonomously acquiring robot skills that involve\ncontact-rich dynamics. However, RL relies on random exploration for learning a\ncontrol policy, which requires many robot executions, and often gets trapped in\nlocally suboptimal solutions. Instead, we posit that prior knowledge, when\navailable, can improve RL performance. We exploit the fact that in modern\nassembly domains, geometric information about the task is readily available via\nthe CAD design files. We propose to leverage this prior knowledge by guiding RL\nalong a geometric motion plan, calculated using the CAD data. We show that our\napproach effectively improves over traditional control approaches for tracking\nthe motion plan, and can solve assembly tasks that require high precision, even\nwithout accurate state estimation. In addition, we propose a neural network\narchitecture that can learn to track the motion plan, and generalize the\nassembly controller to changes in the object positions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 20:16:18 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 21:22:57 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Thomas", "Garrett", ""], ["Chien", "Melissa", ""], ["Tamar", "Aviv", ""], ["Ojea", "Juan Aparicio", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.07658", "submitter": "Benjamin Mark", "authors": "Yuan Li, Benjamin Mark, Garvesh Raskutti, Rebecca Willett, Hyebin\n  Song, David Neiman", "title": "Graph-based regularization for regression problems with alignment and\n  highly-correlated designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse models for high-dimensional linear regression and machine learning\nhave received substantial attention over the past two decades. Model selection,\nor determining which features or covariates are the best explanatory variables,\nis critical to the interpretability of a learned model. Much of the current\nliterature assumes that covariates are only mildly correlated. However, in many\nmodern applications covariates are highly correlated and do not exhibit key\nproperties (such as the restricted eigenvalue condition, restricted isometry\nproperty, or other related assumptions). This work considers a high-dimensional\nregression setting in which a graph governs both correlations among the\ncovariates and the similarity among regression coefficients -- meaning there is\n\\emph{alignment} between the covariates and regression coefficients. Using side\ninformation about the strength of correlations among features, we form a graph\nwith edge weights corresponding to pairwise covariances. This graph is used to\ndefine a graph total variation regularizer that promotes similar weights for\ncorrelated features.\n  This work shows how the proposed graph-based regularization yields\nmean-squared error guarantees for a broad range of covariance graph structures.\nThese guarantees are optimal for many specific covariance graphs, including\nblock and lattice graphs. Our proposed approach outperforms other methods for\nhighly-correlated design in a variety of experiments on synthetic data and real\nbiochemistry data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 21:07:36 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 02:04:21 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 15:02:10 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Li", "Yuan", ""], ["Mark", "Benjamin", ""], ["Raskutti", "Garvesh", ""], ["Willett", "Rebecca", ""], ["Song", "Hyebin", ""], ["Neiman", "David", ""]]}, {"id": "1803.07661", "submitter": "Zhe Li", "authors": "Zhe Li, Shuo Wang, Caiwen Ding, Qinru Qiu, Yanzhi Wang, Yun Liang", "title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "comments": "To appear in International Conference on Learning Representations\n  2018 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are becoming increasingly important for time\nseries-related applications which require efficient and real-time\nimplementations. The recent pruning based work ESE suffers from degradation of\nperformance/energy efficiency due to the irregular network structure after\npruning. We propose block-circulant matrices for weight matrix representation\nin RNNs, thereby achieving simultaneous model compression and acceleration. We\naim to implement RNNs in FPGA with highest performance and energy efficiency,\nwith certain accuracy requirement (negligible accuracy degradation).\nExperimental results on actual FPGA deployments shows that the proposed\nframework achieves a maximum energy efficiency improvement of 35.7$\\times$\ncompared with ESE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 21:21:22 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:26:10 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Li", "Zhe", ""], ["Wang", "Shuo", ""], ["Ding", "Caiwen", ""], ["Qiu", "Qinru", ""], ["Wang", "Yanzhi", ""], ["Liang", "Yun", ""]]}, {"id": "1803.07679", "submitter": "Fabio Daolio", "authors": "\\^Angelo Cardoso, Fabio Daolio and Sa\\'ul Vargas", "title": "Product Characterisation towards Personalisation: Learning Attributes\n  from Unstructured Data to Recommend Fashion Products", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a solution to tackle a common set of challenges in\ne-commerce, which arise from the fact that new products are continually being\nadded to the catalogue. The challenges involve properly personalising the\ncustomer experience, forecasting demand and planning the product range. We\nargue that the foundational piece to solve all of these problems is having\nconsistent and detailed information about each product, information that is\nrarely available or consistent given the multitude of suppliers and types of\nproducts. We describe in detail the architecture and methodology implemented at\nASOS, one of the world's largest fashion e-commerce retailers, to tackle this\nproblem. We then show how this quantitative understanding of the products can\nbe leveraged to improve recommendations in a hybrid recommender system\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 22:25:29 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Cardoso", "\u00c2ngelo", ""], ["Daolio", "Fabio", ""], ["Vargas", "Sa\u00fal", ""]]}, {"id": "1803.07710", "submitter": "KiJung Yoon", "authors": "KiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya,\n  Raquel Urtasun, Richard Zemel, Xaq Pitkow", "title": "Inference in Probabilistic Graphical Models by Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental computation for statistical inference and accurate\ndecision-making is to compute the marginal probabilities or most probable\nstates of task-relevant variables. Probabilistic graphical models can\nefficiently represent the structure of such complex data, but performing these\ninferences is generally difficult. Message-passing algorithms, such as belief\npropagation, are a natural way to disseminate evidence amongst correlated\nvariables while exploiting the graph structure, but these algorithms can\nstruggle when the conditional dependency graphs contain loops. Here we use\nGraph Neural Networks (GNNs) to learn a message-passing algorithm that solves\nthese inference tasks. We first show that the architecture of GNNs is\nwell-matched to inference tasks. We then demonstrate the efficacy of this\ninference approach by training GNNs on a collection of graphical models and\nshowing that they substantially outperform belief propagation on loopy graphs.\nOur message-passing algorithms generalize out of the training set to larger\ngraphs and graphs with different structure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:09:07 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:09:34 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 21:26:30 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 15:02:25 GMT"}, {"version": "v5", "created": "Thu, 27 Jun 2019 15:10:06 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yoon", "KiJung", ""], ["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Zhang", "Lisa", ""], ["Fetaya", "Ethan", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1803.07712", "submitter": "Furui Liu", "authors": "Furui Liu, Laiwan Chan", "title": "Causal Inference on Discrete Data via Estimating Distance Correlations", "comments": null, "journal-ref": "Neural Computation, Vol. 28, No. 5, 2016", "doi": "10.1162/NECO_a_00820", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:39:08 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 15:47:04 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:04:11 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Liu", "Furui", ""], ["Chan", "Laiwan", ""]]}, {"id": "1803.07726", "submitter": "Cong Ma", "authors": "Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma", "title": "Gradient Descent with Random Initialization: Fast Global Convergence for\n  Nonconvex Phase Retrieval", "comments": "Accepted to Mathematical Programming", "journal-ref": "Mathematical Programming 2019, Volume 176, Issue 1-2, 5-37", "doi": "10.1007/s10107-019-01363-6", "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of solving systems of quadratic equations,\nnamely, recovering an object of interest\n$\\mathbf{x}^{\\natural}\\in\\mathbb{R}^{n}$ from $m$ quadratic equations/samples\n$y_{i}=(\\mathbf{a}_{i}^{\\top}\\mathbf{x}^{\\natural})^{2}$, $1\\leq i\\leq m$. This\nproblem, also dubbed as phase retrieval, spans multiple domains including\nphysical sciences and machine learning.\n  We investigate the efficiency of gradient descent (or Wirtinger flow)\ndesigned for the nonconvex least squares problem. We prove that under Gaussian\ndesigns, gradient descent --- when randomly initialized --- yields an\n$\\epsilon$-accurate solution in $O\\big(\\log n+\\log(1/\\epsilon)\\big)$ iterations\ngiven nearly minimal samples, thus achieving near-optimal computational and\nsample complexities at once. This provides the first global convergence\nguarantee concerning vanilla gradient descent for phase retrieval, without the\nneed of (i) carefully-designed initialization, (ii) sample splitting, or (iii)\nsophisticated saddle-point escaping schemes. All of these are achieved by\nexploiting the statistical models in analyzing optimization algorithms, via a\nleave-one-out approach that enables the decoupling of certain statistical\ndependency between the gradient descent iterates and the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:14:16 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:56:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""]]}, {"id": "1803.07728", "submitter": "Spyros Gidaris", "authors": "Spyros Gidaris, Praveer Singh, Nikos Komodakis", "title": "Unsupervised Representation Learning by Predicting Image Rotations", "comments": "Accepted at ICLR2018. Code and models will be published on:\n  https://github.com/gidariss/FeatureLearningRotNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, deep convolutional neural networks (ConvNets) have\ntransformed the field of computer vision thanks to their unparalleled capacity\nto learn high level semantic image features. However, in order to successfully\nlearn those features, they usually require massive amounts of manually labeled\ndata, which is both expensive and impractical to scale. Therefore, unsupervised\nsemantic feature learning, i.e., learning without requiring manual annotation\neffort, is of crucial importance in order to successfully harvest the vast\namount of visual data that are available today. In our work we propose to learn\nimage features by training ConvNets to recognize the 2d rotation that is\napplied to the image that it gets as input. We demonstrate both qualitatively\nand quantitatively that this apparently simple task actually provides a very\npowerful supervisory signal for semantic feature learning. We exhaustively\nevaluate our method in various unsupervised feature learning benchmarks and we\nexhibit in all of them state-of-the-art performance. Specifically, our results\non those benchmarks demonstrate dramatic improvements w.r.t. prior\nstate-of-the-art approaches in unsupervised representation learning and thus\nsignificantly close the gap with supervised feature learning. For instance, in\nPASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model\nachieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that is\nonly 2.4 points lower from the supervised case. We get similarly striking\nresults when we transfer our unsupervised learned features on various other\ntasks, such as ImageNet classification, PASCAL classification, PASCAL\nsegmentation, and CIFAR-10 classification. The code and models of our paper\nwill be published on: https://github.com/gidariss/FeatureLearningRotNet .\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:21:14 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Gidaris", "Spyros", ""], ["Singh", "Praveer", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1803.07764", "submitter": "Ritu Kapur", "authors": "Ritu Kapur and Balwinder Sodhi", "title": "Estimating defectiveness of source code: A predictive model using GitHub\n  content", "comments": "Submitted to ACM ESEC/FSE 2018. Keywords: Maintaining software;\n  Source code mining; Software defect identification; Automated software\n  engineering; AI in software engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Two key contributions presented in this paper are: i) A method for building a\ndataset containing source code features extracted from source files taken from\nOpen Source Software (OSS) and associated bug reports, ii) A predictive model\nfor estimating defectiveness of a given source code. These artifacts can be\nuseful for building tools and techniques pertaining to several automated\nsoftware engineering areas such as bug localization, code review, and\nrecommendation and program repair.\n  In order to achieve our goal, we first extract coding style information (e.g.\nrelated to programming language constructs used in the source code) for source\ncode files present on GitHub. Then the information available in bug reports (if\nany) associated with these source code files are extracted. Thus fetched un(/\nsemi)-structured information is then transformed into a structured knowledge\nbase. We considered more than 30400 source code files from 20 different GitHub\nrepositories with about 14950 associated bug reports across 4 bug tracking\nportals. The source code files considered are written in four programming\nlanguages (viz., C, C++, Java, and Python) and belong to different types of\napplications.\n  A machine learning (ML) model for estimating the defectiveness of a given\ninput source code is then trained using the knowledge base. In order to pick\nthe best ML model, we evaluated 8 different ML algorithms such as Random\nForest, K Nearest Neighbour and SVM with around 50 parameter configurations to\ncompare their performance on our tasks. One of our findings shows that best\nK-fold (with k=5) cross-validation results are obtained with the NuSVM\ntechnique that gives a mean F1 score of 0.914.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 06:31:17 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Kapur", "Ritu", ""], ["Sodhi", "Balwinder", ""]]}, {"id": "1803.07819", "submitter": "Biau Gerard", "authors": "G. Biau (LPSM), B. Cadre (ENS Rennes), M. Sangnier (LPSM), U.\n  Tanielian (LPSM)", "title": "Some Theoretical Properties of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a class of generative algorithms\nthat have been shown to produce state-of-the art samples, especially in the\ndomain of image creation. The fundamental principle of GANs is to approximate\nthe unknown distribution of a given data set by optimizing an objective\nfunction through an adversarial game between a family of generators and a\nfamily of discriminators. In this paper, we offer a better theoretical\nunderstanding of GANs by analyzing some of their mathematical and statistical\nproperties. We study the deep connection between the adversarial principle\nunderlying GANs and the Jensen-Shannon divergence, together with some\noptimality characteristics of the problem. An analysis of the role of the\ndiscriminator family via approximation arguments is also provided. In addition,\ntaking a statistical point of view, we study the large sample properties of the\nestimated distribution and prove in particular a central limit theorem. Some of\nour results are illustrated with simulated examples.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 09:52:14 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Biau", "G.", "", "LPSM"], ["Cadre", "B.", "", "ENS Rennes"], ["Sangnier", "M.", "", "LPSM"], ["Tanielian", "U.", "", "LPSM"]]}, {"id": "1803.07821", "submitter": "Riikka Huusari", "authors": "Riikka Huusari (LIS, QARMA, AMU), Hachem Kadri (QARMA, LIS, AMU),\n  C\\'ecile Capponi (QARMA, LIS, AMU)", "title": "Multi-view Metric Learning in Vector-valued Kernel Spaces", "comments": null, "journal-ref": "The 21st International Conference on Artificial Intelligence and\n  Statistics, Apr 2018, Lanzarote, Spain", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of metric learning for multi-view data and present a\nnovel method for learning within-view as well as between-view metrics in\nvector-valued kernel spaces, as a way to capture multi-modal structure of the\ndata. We formulate two convex optimization problems to jointly learn the metric\nand the classifier or regressor in kernel feature spaces. An iterative\nthree-step multi-view metric learning algorithm is derived from the\noptimization problems. In order to scale the computation to large training\nsets, a block-wise Nystr{\\\"o}m approximation of the multi-view kernel matrix is\nintroduced. We justify our approach theoretically and experimentally, and show\nits performance on real-world datasets against relevant state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 09:56:33 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Huusari", "Riikka", "", "LIS, QARMA, AMU"], ["Kadri", "Hachem", "", "QARMA, LIS, AMU"], ["Capponi", "C\u00e9cile", "", "QARMA, LIS, AMU"]]}, {"id": "1803.07859", "submitter": "Jack Kuipers", "authors": "Jack Kuipers, Polina Suter and Giusi Moffa", "title": "Efficient Sampling and Structure Learning of Bayesian Networks", "comments": "Revised version. 40 pages including 16 pages of supplement, 5 figures\n  and 15 supplemental figures; R package BiDAG is available at\n  https://CRAN.R-project.org/package=BiDAG", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are probabilistic graphical models widely employed to\nunderstand dependencies in high dimensional data, and even to facilitate causal\ndiscovery. Learning the underlying network structure, which is encoded as a\ndirected acyclic graph (DAG) is highly challenging mainly due to the vast\nnumber of possible networks. Efforts have focussed on two fronts:\nconstraint-based methods that perform conditional independence tests to exclude\nedges and score and search approaches which explore the DAG space with greedy\nor MCMC schemes. Here we synthesise these two fields in a novel hybrid method\nwhich reduces the complexity of MCMC approaches to that of a constraint-based\nmethod. Individual steps in the MCMC scheme only require simple table lookups\nso that very long chains can be efficiently obtained. Furthermore, the scheme\nincludes an iterative procedure to correct for errors from the conditional\nindependence tests. The algorithm offers markedly superior performance to\nalternatives, particularly because DAGs can also be sampled from the posterior\ndistribution, enabling full Bayesian model averaging for much larger Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 11:12:42 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 15:25:13 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 18:33:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kuipers", "Jack", ""], ["Suter", "Polina", ""], ["Moffa", "Giusi", ""]]}, {"id": "1803.07868", "submitter": "Florian Wenzel", "authors": "Patrick J\\\"ahnichen, Florian Wenzel, Marius Kloft, Stephan Mandt", "title": "Scalable Generalized Dynamic Topic Models", "comments": "Published version, International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic topic models (DTMs) model the evolution of prevalent themes in\nliterature, online media, and other forms of text over time. DTMs assume that\nword co-occurrence statistics change continuously and therefore impose\ncontinuous stochastic process priors on their model parameters. These dynamical\npriors make inference much harder than in regular topic models, and also limit\nscalability. In this paper, we present several new results around DTMs. First,\nwe extend the class of tractable priors from Wiener processes to the generic\nclass of Gaussian processes (GPs). This allows us to explore topics that\ndevelop smoothly over time, that have a long-term memory or are temporally\nconcentrated (for event detection). Second, we show how to perform scalable\napproximate inference in these models based on ideas around stochastic\nvariational inference and sparse Gaussian processes. This way we can train a\nrich family of DTMs to massive data. Our experiments on several large-scale\ndatasets show that our generalized model allows us to find interesting patterns\nthat were not accessible by previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 11:50:35 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["J\u00e4hnichen", "Patrick", ""], ["Wenzel", "Florian", ""], ["Kloft", "Marius", ""], ["Mandt", "Stephan", ""]]}, {"id": "1803.07879", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi,\n  Arthur Revhaug and Robert Jenssen", "title": "An Unsupervised Multivariate Time Series Kernel Approach for Identifying\n  Patients with Surgical Site Infection from Blood Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of the electronic health records consists of clinical\nmeasurements collected over time, such as blood tests, which provide important\ninformation about the health status of a patient. These sequences of clinical\nmeasurements are naturally represented as time series, characterized by\nmultiple variables and the presence of missing data, which complicate analysis.\nIn this work, we propose a surgical site infection detection framework for\npatients undergoing colorectal cancer surgery that is completely unsupervised,\nhence alleviating the problem of getting access to labelled training data. The\nframework is based on powerful kernels for multivariate time series that\naccount for missing data when computing similarities. Our approach show\nsuperior performance compared to baselines that have to resort to imputation\ntechniques and performs comparable to a supervised classification baseline.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 12:20:43 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Bianchi", "Filippo Maria", ""], ["Revhaug", "Arthur", ""], ["Jenssen", "Robert", ""]]}, {"id": "1803.07890", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen, Nattiya Kanhabua, Wolfgang Nejdl", "title": "Multiple Models for Recommending Temporal Aspects of Entities", "comments": "In proceedings of the 15th Extended Semantic Web Conference (ESWC\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity aspect recommendation is an emerging task in semantic search that\nhelps users discover serendipitous and prominent information with respect to an\nentity, of which salience (e.g., popularity) is the most important factor in\nprevious work. However, entity aspects are temporally dynamic and often driven\nby events happening over time. For such cases, aspect suggestion based solely\non salience features can give unsatisfactory results, for two reasons. First,\nsalience is often accumulated over a long time period and does not account for\nrecency. Second, many aspects related to an event entity are strongly\ntime-dependent. In this paper, we study the task of temporal aspect\nrecommendation for a given entity, which aims at recommending the most relevant\naspects and takes into account time in order to improve search experience. We\npropose a novel event-centric ensemble ranking method that learns from multiple\ntime and type-dependent models and dynamically trades off salience and recency\ncharacteristics. Through extensive experiments on real-world query logs, we\ndemonstrate that our method is robust and achieves better effectiveness than\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 12:51:51 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 08:39:20 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Nguyen", "Tu Ngoc", ""], ["Kanhabua", "Nattiya", ""], ["Nejdl", "Wolfgang", ""]]}, {"id": "1803.07947", "submitter": "Evgeny Krivosheev", "authors": "Evgeny Krivosheev, Bahareh Harandizadeh, Fabio Casati and Boualem\n  Benatallah", "title": "Crowd-Machine Collaboration for Item Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe how crowd and machine classifier can be efficiently\ncombined to screen items that satisfy a set of predicates. We show that this is\na recurring problem in many domains, present machine-human (hybrid) algorithms\nthat screen items efficiently and estimate the gain over human-only or\nmachine-only screening in terms of performance and cost.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 14:40:05 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Krivosheev", "Evgeny", ""], ["Harandizadeh", "Bahareh", ""], ["Casati", "Fabio", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1803.07952", "submitter": "Chi-Hua Chen", "authors": "Ming-Yen Wu, Chi-Hua Chen, Chi-Chun Lo", "title": "An Exercise Fatigue Detection Model Based on Machine Learning Methods", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an exercise fatigue detection model based on real-time\nclinical data which includes time domain analysis, frequency domain analysis,\ndetrended fluctuation analysis, approximate entropy, and sample entropy.\nFurthermore, this study proposed a feature extraction method which is combined\nwith an analytical hierarchy process to analyze and extract critical features.\nFinally, machine learning algorithms were adopted to analyze the data of each\nfeature for the detection of exercise fatigue. The practical experimental\nresults showed that the proposed exercise fatigue detection model and feature\nextraction method could precisely detect the level of exercise fatigue, and the\naccuracy of exercise fatigue detection could be improved up to 98.65%.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 13:23:42 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Wu", "Ming-Yen", ""], ["Chen", "Chi-Hua", ""], ["Lo", "Chi-Chun", ""]]}, {"id": "1803.07954", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Ali Jadbabaie, George J. Pappas", "title": "Resilient Monotone Sequential Maximization", "comments": "Extended version accepted in IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications in machine learning, optimization, and control require the\nsequential selection of a few system elements, such as sensors, data, or\nactuators, to optimize the system performance across multiple time steps.\nHowever, in failure-prone and adversarial environments, sensors get attacked,\ndata get deleted, and actuators fail. Thence, traditional sequential design\nparadigms become insufficient and, in contrast, resilient sequential designs\nthat adapt against system-wide attacks, deletions, or failures become\nimportant. In general, resilient sequential design problems are computationally\nhard. Also, even though they often involve objective functions that are\nmonotone and (possibly) submodular, no scalable approximation algorithms are\nknown for their solution. In this paper, we provide the first scalable\nalgorithm, that achieves the following characteristics: system-wide resiliency,\ni.e., the algorithm is valid for any number of denial-of-service attacks,\ndeletions, or failures; adaptiveness, i.e., at each time step, the algorithm\nselects system elements based on the history of inflicted attacks, deletions,\nor failures; and provable approximation performance, i.e., the algorithm\nguarantees for monotone objective functions a solution close to the optimal. We\nquantify the algorithm's approximation performance using a notion of curvature\nfor monotone (not necessarily submodular) set functions. Finally, we support\nour theoretical analyses with simulated experiments, by considering a\ncontrol-aware sensor scheduling scenario, namely, sensing-constrained robot\nnavigation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:00:33 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:22:28 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2018 23:41:13 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 15:42:46 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Jadbabaie", "Ali", ""], ["Pappas", "George J.", ""]]}, {"id": "1803.07964", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Kun Yuan and Stefan Vlaski and Ali H. Sayed", "title": "Stochastic Learning under Random Reshuffling with Constant Step-sizes", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2878551", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In empirical risk optimization, it has been observed that stochastic gradient\nimplementations that rely on random reshuffling of the data achieve better\nperformance than implementations that rely on sampling the data uniformly.\nRecent works have pursued justifications for this behavior by examining the\nconvergence rate of the learning process under diminishing step-sizes. This\nwork focuses on the constant step-size case and strongly convex loss function.\nIn this case, convergence is guaranteed to a small neighborhood of the\noptimizer albeit at a linear rate. The analysis establishes analytically that\nrandom reshuffling outperforms uniform sampling by showing explicitly that\niterates approach a smaller neighborhood of size $O(\\mu^2)$ around the\nminimizer rather than $O(\\mu)$. Furthermore, we derive an analytical expression\nfor the steady-state mean-square-error performance of the algorithm, which\nhelps clarify in greater detail the differences between sampling with and\nwithout replacement. We also explain the periodic behavior that is observed in\nrandom reshuffling implementations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:27:52 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 18:48:57 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ying", "Bicheng", ""], ["Yuan", "Kun", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1803.07976", "submitter": "Cristina Rottondi", "authors": "Francesco Musumeci, Cristina Rottondi, Avishek Nag, Irene Macaluso,\n  Darko Zibar, Marco Ruffini, and Massimo Tornatore", "title": "An Overview on Application of Machine Learning Techniques in Optical\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's telecommunication networks have become sources of enormous amounts of\nwidely heterogeneous data. This information can be retrieved from network\ntraffic traces, network alarms, signal quality indicators, users' behavioral\ndata, etc. Advanced mathematical tools are required to extract meaningful\ninformation from these data and take decisions pertaining to the proper\nfunctioning of the networks from the network-generated data. Among these\nmathematical tools, Machine Learning (ML) is regarded as one of the most\npromising methodological approaches to perform network-data analysis and enable\nautomated network self-configuration and fault management. The adoption of ML\ntechniques in the field of optical communication networks is motivated by the\nunprecedented growth of network complexity faced by optical networks in the\nlast few years. Such complexity increase is due to the introduction of a huge\nnumber of adjustable and interdependent system parameters (e.g., routing\nconfigurations, modulation format, symbol rate, coding schemes, etc.) that are\nenabled by the usage of coherent transmission/reception technologies, advanced\ndigital signal processing and compensation of nonlinear effects in optical\nfiber propagation. In this paper we provide an overview of the application of\nML to optical communications and networking. We classify and survey relevant\nliterature dealing with the topic, and we also provide an introductory tutorial\non ML for researchers and practitioners interested in this field. Although a\ngood number of research papers have recently appeared, the application of ML to\noptical networks is still in its infancy: to stimulate further work in this\narea, we conclude the paper proposing new possible research directions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 15:58:36 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 19:23:31 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 08:37:30 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 13:57:13 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Musumeci", "Francesco", ""], ["Rottondi", "Cristina", ""], ["Nag", "Avishek", ""], ["Macaluso", "Irene", ""], ["Zibar", "Darko", ""], ["Ruffini", "Marco", ""], ["Tornatore", "Massimo", ""]]}, {"id": "1803.07980", "submitter": "Tianchen Zhao Mr.", "authors": "Tianchen Zhao", "title": "Information Theoretic Interpretation of Deep learning", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 02:36:59 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zhao", "Tianchen", ""]]}, {"id": "1803.07994", "submitter": "Joachim Folz", "authors": "Joachim Folz and Sebastian Palacio and Joern Hees and Damian Borth and\n  Andreas Dengel", "title": "Adversarial Defense based on Structure-to-Signal Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack methods have demonstrated the fragility of deep neural\nnetworks. Their imperceptible perturbations are frequently able fool\nclassifiers into potentially dangerous misclassifications. We propose a novel\nway to interpret adversarial perturbations in terms of the effective input\nsignal that classifiers actually use. Based on this, we apply specially trained\nautoencoders, referred to as S2SNets, as defense mechanism. They follow a\ntwo-stage training scheme: first unsupervised, followed by a fine-tuning of the\ndecoder, using gradients from an existing classifier. S2SNets induce a shift in\nthe distribution of gradients propagated through them, stripping them from\nclass-dependent signal. We analyze their robustness against several white-box\nand gray-box scenarios on the large ImageNet dataset. Our approach reaches\ncomparable resilience in white-box attack scenarios as other state-of-the-art\ndefenses in gray-box scenarios. We further analyze the relationships of\nAlexNet, VGG 16, ResNet 50 and Inception v3 in adversarial space, and found\nthat VGG 16 is the easiest to fool, while perturbations from ResNet 50 are the\nmost transferable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:25:26 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Folz", "Joachim", ""], ["Palacio", "Sebastian", ""], ["Hees", "Joern", ""], ["Borth", "Damian", ""], ["Dengel", "Andreas", ""]]}, {"id": "1803.08000", "submitter": "Indrayudh Ghosal", "authors": "Indrayudh Ghosal, Giles Hooker", "title": "Boosting Random Forests to Reduce Bias; One-Step Boosted Forest and its\n  Variance Estimate", "comments": "39 pages, 7 tables, 3 figures", "journal-ref": null, "doi": "10.1080/10618600.2020.1820345", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose using the principle of boosting to reduce the bias\nof a random forest prediction in the regression setting. From the original\nrandom forest fit we extract the residuals and then fit another random forest\nto these residuals. We call the sum of these two random forests a\n\\textit{one-step boosted forest}. We show with simulated and real data that the\none-step boosted forest has a reduced bias compared to the original random\nforest. The paper also provides a variance estimate of the one-step boosted\nforest by an extension of the infinitesimal Jackknife estimator. Using this\nvariance estimate we can construct prediction intervals for the boosted forest\nand we show that they have good coverage probabilities. Combining the bias\nreduction and the variance estimate we show that the one-step boosted forest\nhas a significant reduction in predictive mean squared error and thus an\nimprovement in predictive performance. When applied on datasets from the UCI\ndatabase, one-step boosted forest performs better than random forest and\ngradient boosting machine algorithms. Theoretically we can also extend such a\nboosting process to more than one step and the same principles outlined in this\npaper can be used to find variance estimates for such predictors. Such boosting\nwill reduce bias even further but it risks over-fitting and also increases the\ncomputational burden.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:41:30 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 16:34:47 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 20:00:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ghosal", "Indrayudh", ""], ["Hooker", "Giles", ""]]}, {"id": "1803.08018", "submitter": "Akhil Gurram", "authors": "Akhil Gurram, Onay Urfalioglu, Ibrahim Halfaoui, Fahd Bouzaraa and\n  Antonio M. Lopez", "title": "Monocular Depth Estimation by Learning from Heterogeneous Datasets", "comments": "Accepted in IEEE-Intelligent Vehicles Symposium, IV'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth estimation provides essential information to perform autonomous driving\nand driver assistance. Especially, Monocular Depth Estimation is interesting\nfrom a practical point of view, since using a single camera is cheaper than\nmany other options and avoids the need for continuous calibration strategies as\nrequired by stereo-vision approaches. State-of-the-art methods for Monocular\nDepth Estimation are based on Convolutional Neural Networks (CNNs). A promising\nline of work consists of introducing additional semantic information about the\ntraffic scene when training CNNs for depth estimation. In practice, this means\nthat the depth data used for CNN training is complemented with images having\npixel-wise semantic labels, which usually are difficult to annotate (e.g.\ncrowded urban images). Moreover, so far it is common practice to assume that\nthe same raw training data is associated with both types of ground truth, i.e.,\ndepth and semantic labels. The main contribution of this paper is to show that\nthis hard constraint can be circumvented, i.e., that we can train CNNs for\ndepth estimation by leveraging the depth and semantic information coming from\nheterogeneous datasets. In order to illustrate the benefits of our approach, we\ncombine KITTI depth and Cityscapes semantic segmentation datasets,\noutperforming state-of-the-art results on Monocular Depth Estimation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:18:25 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 17:40:58 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Gurram", "Akhil", ""], ["Urfalioglu", "Onay", ""], ["Halfaoui", "Ibrahim", ""], ["Bouzaraa", "Fahd", ""], ["Lopez", "Antonio M.", ""]]}, {"id": "1803.08021", "submitter": "Shusen Wang", "authors": "Miles E. Lopes, Shusen Wang, Michael W. Mahoney", "title": "Error Estimation for Randomized Least-Squares Algorithms via the\n  Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the course of the past decade, a variety of randomized algorithms have\nbeen proposed for computing approximate least-squares (LS) solutions in\nlarge-scale settings. A longstanding practical issue is that, for any given\ninput, the user rarely knows the actual error of an approximate solution\n(relative to the exact solution). Likewise, it is difficult for the user to\nknow precisely how much computation is needed to achieve the desired error\ntolerance. Consequently, the user often appeals to worst-case error bounds that\ntend to offer only qualitative guidance. As a more practical alternative, we\npropose a bootstrap method to compute a posteriori error estimates for\nrandomized LS algorithms. These estimates permit the user to numerically assess\nthe error of a given solution, and to predict how much work is needed to\nimprove a \"preliminary\" solution. In addition, we provide theoretical\nconsistency results for the method, which are the first such results in this\ncontext (to the best of our knowledge). From a practical standpoint, the method\nalso has considerable flexibility, insofar as it can be applied to several\npopular sketching algorithms, as well as a variety of error metrics. Moreover,\nthe extra step of error estimation does not add much cost to an underlying\nsketching algorithm. Finally, we demonstrate the effectiveness of the method\nwith empirical results.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:19:41 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 05:01:36 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Lopes", "Miles E.", ""], ["Wang", "Shusen", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1803.08024", "submitter": "Kuang-Huei Lee", "authors": "Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He", "title": "Stacked Cross Attention for Image-Text Matching", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of image-text matching. Inferring the\nlatent semantic alignment between objects or other salient stuff (e.g. snow,\nsky, lawn) and the corresponding words in sentences allows to capture\nfine-grained interplay between vision and language, and makes image-text\nmatching more interpretable. Prior work either simply aggregates the similarity\nof all possible pairs of regions and words without attending differentially to\nmore and less important words or regions, or uses a multi-step attentional\nprocess to capture limited number of semantic alignments which is less\ninterpretable. In this paper, we present Stacked Cross Attention to discover\nthe full latent alignments using both image regions and words in a sentence as\ncontext and infer image-text similarity. Our approach achieves the\nstate-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K,\nour approach outperforms the current best methods by 22.1% relatively in text\nretrieval from image query, and 18.2% relatively in image retrieval with text\nquery (based on Recall@1). On MS-COCO, our approach improves sentence retrieval\nby 17.8% relatively and image retrieval by 16.6% relatively (based on Recall@1\nusing the 5K test set). Code has been made available at:\nhttps://github.com/kuanghuei/SCAN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:22:27 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 04:41:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lee", "Kuang-Huei", ""], ["Chen", "Xi", ""], ["Hua", "Gang", ""], ["Hu", "Houdong", ""], ["He", "Xiaodong", ""]]}, {"id": "1803.08037", "submitter": "Pedro Felzenszwalb", "authors": "Pedro F. Felzenszwalb", "title": "Similar Elements and Metric Labeling on Complete Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem that involves finding similar elements in a collection\nof sets. The problem is motivated by applications in machine learning and\npattern recognition. We formulate the similar elements problem as an\noptimization and give an efficient approximation algorithm that finds a\nsolution within a factor of 2 of the optimal. The similar elements problem is a\nspecial case of the metric labeling problem and we also give an efficient\n2-approximation algorithm for the metric labeling problem on complete graphs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:55:02 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 13:38:50 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Felzenszwalb", "Pedro F.", ""]]}, {"id": "1803.08089", "submitter": "Massimiliano Pontil", "authors": "Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, Massimiliano Pontil", "title": "Incremental Learning-to-Learn with Statistical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning-to-learn the goal is to infer a learning algorithm that works\nwell on a class of tasks sampled from an unknown meta distribution. In contrast\nto previous work on batch learning-to-learn, we consider a scenario where tasks\nare presented sequentially and the algorithm needs to adapt incrementally to\nimprove its performance on future tasks. Key to this setting is for the\nalgorithm to rapidly incorporate new observations into the model as they\narrive, without keeping them in memory. We focus on the case where the\nunderlying algorithm is ridge regression parameterized by a positive\nsemidefinite matrix. We propose to learn this matrix by applying a stochastic\nstrategy to minimize the empirical error incurred by ridge regression on future\ntasks sampled from the meta distribution. We study the statistical properties\nof the proposed algorithm and prove non-asymptotic bounds on its excess\ntransfer risk, that is, the generalization performance on new tasks from the\nsame meta distribution. We compare our online learning-to-learn approach with a\nstate of the art batch method, both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 18:50:18 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Denevi", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Stamos", "Dimitris", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1803.08101", "submitter": "Geoff Boeing", "authors": "Geoff Boeing", "title": "Clustering to Reduce Spatial Data Set Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally it had been a problem that researchers did not have access to\nenough spatial data to answer pressing research questions or build compelling\nvisualizations. Today, however, the problem is often that we have too much\ndata. Spatially redundant or approximately redundant points may refer to a\nsingle feature (plus noise) rather than many distinct spatial features. We use\na machine learning approach with density-based clustering to compress such\nspatial data into a set of representative features.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 19:38:27 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Boeing", "Geoff", ""]]}, {"id": "1803.08118", "submitter": "David Burns", "authors": "David M. Burns, Cari M. Whyne", "title": "Seglearn: A Python Package for Learning Sequences and Time Series", "comments": null, "journal-ref": "Journal of Machine Learning Research 19 (2018) 1-7", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seglearn is an open-source python package for machine learning time series or\nsequences using a sliding window segmentation approach. The implementation\nprovides a flexible pipeline for tackling classification, regression, and\nforecasting problems with multivariate sequence and contextual data. This\npackage is compatible with scikit-learn and is listed under scikit-learn\nRelated Projects. The package depends on numpy, scipy, and scikit-learn.\nSeglearn is distributed under the BSD 3-Clause License. Documentation includes\na detailed API description, user guide, and examples. Unit tests provide a high\ndegree of code coverage.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:30:34 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 19:45:08 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 17:11:55 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Burns", "David M.", ""], ["Whyne", "Cari M.", ""]]}, {"id": "1803.08138", "submitter": "Aydogan Ozcan", "authors": "Yichen Wu, Yair Rivenson, Yibo Zhang, Zhensong Wei, Harun Gunaydin,\n  Xing Lin, Aydogan Ozcan", "title": "Extended depth-of-field in holographic image reconstruction using deep\n  learning based auto-focusing and phase-recovery", "comments": null, "journal-ref": "Optica, Vol. 5, Issue 6, pp. 704-710 (2018)", "doi": "10.1364/OPTICA.5.000704", "report-no": null, "categories": "cs.CV cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holography encodes the three dimensional (3D) information of a sample in the\nform of an intensity-only recording. However, to decode the original sample\nimage from its hologram(s), auto-focusing and phase-recovery are needed, which\nare in general cumbersome and time-consuming to digitally perform. Here we\ndemonstrate a convolutional neural network (CNN) based approach that\nsimultaneously performs auto-focusing and phase-recovery to significantly\nextend the depth-of-field (DOF) in holographic image reconstruction. For this,\na CNN is trained by using pairs of randomly de-focused back-propagated\nholograms and their corresponding in-focus phase-recovered images. After this\ntraining phase, the CNN takes a single back-propagated hologram of a 3D sample\nas input to rapidly achieve phase-recovery and reconstruct an in focus image of\nthe sample over a significantly extended DOF. This deep learning based DOF\nextension method is non-iterative, and significantly improves the algorithm\ntime-complexity of holographic image reconstruction from O(nm) to O(1), where n\nrefers to the number of individual object points or particles within the sample\nvolume, and m represents the focusing search space within which each object\npoint or particle needs to be individually focused. These results highlight\nsome of the unique opportunities created by data-enabled statistical image\nreconstruction methods powered by machine learning, and we believe that the\npresented approach can be broadly applicable to computationally extend the DOF\nof other imaging modalities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:59:33 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Wu", "Yichen", ""], ["Rivenson", "Yair", ""], ["Zhang", "Yibo", ""], ["Wei", "Zhensong", ""], ["Gunaydin", "Harun", ""], ["Lin", "Xing", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1803.08153", "submitter": "Arash Behboodi", "authors": "Linchen Xiao, Arash Behboodi, Rudolf Mathar", "title": "Learning the Localization Function: Machine Learning Approach to\n  Fingerprinting Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considered as a data-driven approach, Fingerprinting Localization Solutions\n(FPSs) enjoy huge popularity due to their good performance and minimal\nenvironment information requirement. This papers addresses applications of\nartificial intelligence to solve two problems in Received Signal Strength\nIndicator (RSSI) based FPS, first the cumbersome training database construction\nand second the extrapolation of fingerprinting algorithm for similar buildings\nwith slight environmental changes. After a concise overview of deep learning\ndesign techniques, two main techniques widely used in deep learning are\nexploited for the above mentioned issues namely data augmentation and transfer\nlearning. We train a multi-layer neural network that learns the mapping from\nthe observations to the locations. A data augmentation method is proposed to\nincrease the training database size based on the structure of RSSI measurements\nand hence reducing effectively the amount of training data. Then it is shown\nexperimentally how a model trained for a particular building can be transferred\nto a similar one by fine tuning with significantly smaller training numbers.\nThe paper implicitly discusses the new guidelines to consider about deep\nlearning designs when they are employed in a new application context.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:25:34 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Xiao", "Linchen", ""], ["Behboodi", "Arash", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1803.08165", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Daniel Fojo, V\\'ictor Campos and Xavier Giro-i-Nieto", "title": "Comparing Fixed and Adaptive Computation Time for Recurrent Neural\n  Networks", "comments": "Accepted as workshop paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Computation Time for Recurrent Neural Networks (ACT) is one of the\nmost promising architectures for variable computation. ACT adapts to the input\nsequence by being able to look at each sample more than once, and learn how\nmany times it should do it. In this paper, we compare ACT to Repeat-RNN, a\nnovel architecture based on repeating each sample a fixed number of times. We\nfound surprising results, where Repeat-RNN performs as good as ACT in the\nselected tasks. Source code in TensorFlow and PyTorch is publicly available at\nhttps://imatge-upc.github.io/danifojo-2018-repeatrnn/\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:59:53 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Fojo", "Daniel", ""], ["Campos", "V\u00edctor", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1803.08178", "submitter": "Zac Cranko", "authors": "Zac Cranko and Richard Nock", "title": "Boosted Density Estimation Remastered", "comments": "Contains lots of essential info", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 00:09:00 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 01:52:06 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 03:45:54 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Cranko", "Zac", ""], ["Nock", "Richard", ""]]}, {"id": "1803.08182", "submitter": "Panos Stinis", "authors": "Panos Stinis, Tobias Hagge, Alexandre M. Tartakovsky, Enoch Yeung", "title": "Enforcing constraints for interpolation and extrapolation in Generative\n  Adversarial Networks", "comments": "29 pages; v2 has major text revision/restructuring, includes results\n  for the Lorenz system and has several more references", "journal-ref": null, "doi": "10.1016/j.jcp.2019.07.042", "report-no": "PNNL-SA-133233", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest ways to enforce given constraints in the output of a Generative\nAdversarial Network (GAN) generator both for interpolation and extrapolation\n(prediction). For the case of dynamical systems, given a time series, we wish\nto train GAN generators that can be used to predict trajectories starting from\na given initial condition. In this setting, the constraints can be in algebraic\nand/or differential form. Even though we are predominantly interested in the\ncase of extrapolation, we will see that the tasks of interpolation and\nextrapolation are related. However, they need to be treated differently.\n  For the case of interpolation, the incorporation of constraints is built into\nthe training of the GAN. The incorporation of the constraints respects the\nprimary game-theoretic setup of a GAN so it can be combined with existing\nalgorithms. However, it can exacerbate the problem of instability during\ntraining that is well-known for GANs. We suggest adding small noise to the\nconstraints as a simple remedy that has performed well in our numerical\nexperiments.\n  The case of extrapolation (prediction) is more involved. During training, the\nGAN generator learns to interpolate a noisy version of the data and we enforce\nthe constraints. This approach has connections with model reduction that we can\nutilize to improve the efficiency and accuracy of the training. Depending on\nthe form of the constraints, we may enforce them also during prediction through\na projection step. We provide examples of linear and nonlinear systems of\ndifferential equations to illustrate the various constructions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 00:25:07 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 21:33:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Stinis", "Panos", ""], ["Hagge", "Tobias", ""], ["Tartakovsky", "Alexandre M.", ""], ["Yeung", "Enoch", ""]]}, {"id": "1803.08203", "submitter": "Kamil Nar", "authors": "Kamil Nar, Shankar Sastry", "title": "Residual Networks: Lyapunov Stability and Convex Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training error of most deep neural networks degrades as the depth of\nthe network increases, residual networks appear to be an exception. We show\nthat the main reason for this is the Lyapunov stability of the gradient descent\nalgorithm: for an arbitrarily chosen step size, the equilibria of the gradient\ndescent are most likely to remain stable for the parametrization of residual\nnetworks. We then present an architecture with a pair of residual networks to\napproximate a large class of functions by decomposing them into a convex and a\nconcave part. Some parameters of this model are shown to change little during\ntraining, and this imperfect optimization prevents overfitting the data and\nleads to solutions with small Lipschitz constants, while providing clues about\nthe generalization of other deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 02:14:08 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "Shankar", ""]]}, {"id": "1803.08276", "submitter": "Maxime Jumelle", "authors": "Maxime Jumelle, Taqiyeddine Sakmeche", "title": "Speaker Clustering With Neural Networks And Audio Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speaker clustering is the task of differentiating speakers in a recording. In\na way, the aim is to answer \"who spoke when\" in audio recordings. A common\nmethod used in industry is feature extraction directly from the recording\nthanks to MFCC features, and by using well-known techniques such as Gaussian\nMixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied\nneural networks (especially CNN) followed by clustering and audio processing in\nthe quest to reach similar accuracy to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 09:21:56 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Jumelle", "Maxime", ""], ["Sakmeche", "Taqiyeddine", ""]]}, {"id": "1803.08287", "submitter": "Felix Berkenkamp", "authors": "Torsten Koller, Felix Berkenkamp, Matteo Turchetta, Andreas Krause", "title": "Learning-based Model Predictive Control for Safe Exploration", "comments": "Proc. of the Conference on Decision and Control, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methods have been successful in solving complex control tasks\nwithout significant prior knowledge about the system. However, these methods\ntypically do not provide any safety guarantees, which prevents their use in\nsafety-critical, real-world applications. In this paper, we present a\nlearning-based model predictive control scheme that can provide provable\nhigh-probability safety guarantees. To this end, we exploit regularity\nassumptions on the dynamics in terms of a Gaussian process prior to construct\nprovably accurate confidence intervals on predicted trajectories. Unlike\nprevious approaches, we do not assume that model uncertainties are independent.\nBased on these predictions, we guarantee that trajectories satisfy safety\nconstraints. Moreover, we use a terminal set constraint to recursively\nguarantee the existence of safe control actions at every iteration. In our\nexperiments, we show that the resulting algorithm can be used to safely and\nefficiently explore and learn about dynamic systems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 09:41:45 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 14:58:17 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 11:08:25 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Koller", "Torsten", ""], ["Berkenkamp", "Felix", ""], ["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""]]}, {"id": "1803.08312", "submitter": "Antonio Pertusa", "authors": "Aurelia Bustos and Antonio Pertusa", "title": "Learning Eligibility in Cancer Clinical Trials using Deep Neural\n  Networks", "comments": null, "journal-ref": "Applied Sciences, 8(7), 2018", "doi": "10.3390/app8071206", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interventional cancer clinical trials are generally too restrictive, and some\npatients are often excluded on the basis of comorbidity, past or concomitant\ntreatments, or the fact that they are over a certain age. The efficacy and\nsafety of new treatments for patients with these characteristics are,\ntherefore, not defined. In this work, we built a model to automatically predict\nwhether short clinical statements were considered inclusion or exclusion\ncriteria. We used protocols from cancer clinical trials that were available in\npublic registries from the last 18 years to train word-embeddings, and we\nconstructed a~dataset of 6M short free-texts labeled as eligible or not\neligible. A text classifier was trained using deep neural networks, with\npre-trained word-embeddings as inputs, to predict whether or not short\nfree-text statements describing clinical information were considered eligible.\nWe additionally analyzed the semantic reasoning of the word-embedding\nrepresentations obtained and were able to identify equivalent treatments for a\ntype of tumor analogous with the drugs used to treat other tumors. We show that\nrepresentation learning using {deep} neural networks can be successfully\nleveraged to extract the medical knowledge from clinical trial protocols for\npotentially assisting practitioners when prescribing treatments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 11:38:53 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 14:45:57 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 10:06:35 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Bustos", "Aurelia", ""], ["Pertusa", "Antonio", ""]]}, {"id": "1803.08337", "submitter": "Joachim Folz", "authors": "Sebastian Palacio and Joachim Folz and J\\\"orn Hees and Federico Raue\n  and Damian Borth and Andreas Dengel", "title": "What do Deep Networks Like to See?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way to measure and understand convolutional neural\nnetworks by quantifying the amount of input signal they let in. To do this, an\nautoencoder (AE) was fine-tuned on gradients from a pre-trained classifier with\nfixed parameters. We compared the reconstructed samples from AEs that were\nfine-tuned on a set of image classifiers (AlexNet, VGG16, ResNet-50, and\nInception~v3) and found substantial differences. The AE learns which aspects of\nthe input space to preserve and which ones to ignore, based on the information\nencoded in the backpropagated gradients. Measuring the changes in accuracy when\nthe signal of one classifier is used by a second one, a relation of total order\nemerges. This order depends directly on each classifier's input signal but it\ndoes not correlate with classification accuracy or network size. Further\nevidence of this phenomenon is provided by measuring the normalized mutual\ninformation between original images and auto-encoded reconstructions from\ndifferent fine-tuned AEs. These findings break new ground in the area of neural\nnetwork understanding, opening a new way to reason, debug, and interpret their\nresults. We present four concrete examples in the literature where observations\ncan now be explained in terms of the input signal that a model uses.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:10:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Palacio", "Sebastian", ""], ["Folz", "Joachim", ""], ["Hees", "J\u00f6rn", ""], ["Raue", "Federico", ""], ["Borth", "Damian", ""], ["Dengel", "Andreas", ""]]}, {"id": "1803.08355", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Slim Essid, Chlo\\'e Clavel, Florence d'Alch\\'e-Buc", "title": "Structured Output Learning with Abstention: Application to Accurate\n  Opinion Prediction", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 80 (2018) 1695-1703", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Supervised Opinion Analysis, we propose a novel framework\ndevoted to Structured Output Learning with Abstention (SOLA). The structure\nprediction model is able to abstain from predicting some labels in the\nstructured output at a cost chosen by the user in a flexible way. For that\npurpose, we decompose the problem into the learning of a pair of predictors,\none devoted to structured abstention and the other, to structured output\nprediction. To compare fully labeled training data with predictions potentially\ncontaining abstentions, we define a wide class of asymmetric abstention-aware\nlosses. Learning is achieved by surrogate regression in an appropriate feature\nspace while prediction with abstention is performed by solving a new pre-image\nproblem. Thus, SOLA extends recent ideas about Structured Output Prediction via\nsurrogate problems and calibration theory and enjoys statistical guarantees on\nthe resulting excess risk. Instantiated on a hierarchical abstention-aware\nloss, SOLA is shown to be relevant for fine-grained opinion mining and gives\nstate-of-the-art results on this task. Moreover, the abstention-aware\nrepresentations can be used to competitively predict user-review ratings based\non a sentence-level opinion predictor.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:48:30 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 13:31:51 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Garcia", "Alexandre", ""], ["Essid", "Slim", ""], ["Clavel", "Chlo\u00e9", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1803.08367", "submitter": "Hartmut Maennel", "authors": "Hartmut Maennel, Olivier Bousquet, Sylvain Gelly", "title": "Gradient Descent Quantizes ReLU Network Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are often trained in the over-parametrized regime (i.e.\nwith far more parameters than training examples), and understanding why the\ntraining converges to solutions that generalize remains an open problem.\nSeveral studies have highlighted the fact that the training procedure, i.e.\nmini-batch Stochastic Gradient Descent (SGD) leads to solutions that have\nspecific properties in the loss landscape. However, even with plain Gradient\nDescent (GD) the solutions found in the over-parametrized regime are pretty\ngood and this phenomenon is poorly understood.\n  We propose an analysis of this behavior for feedforward networks with a ReLU\nactivation function under the assumption of small initialization and learning\nrate and uncover a quantization effect: The weight vectors tend to concentrate\nat a small number of directions determined by the input data. As a consequence,\nwe show that for given input data there are only finitely many, \"simple\"\nfunctions that can be obtained, independent of the network size. This puts\nthese functions in analogy to linear interpolations (for given input data there\nare finitely many triangulations, which each determine a function by linear\ninterpolation). We ask whether this analogy extends to the generalization\nproperties - while the usual distribution-independent generalization property\ndoes not hold, it could be that for e.g. smooth functions with bounded second\nderivative an approximation property holds which could \"explain\" generalization\nof networks (of unbounded size) to unseen inputs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:08:58 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Maennel", "Hartmut", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1803.08374", "submitter": "Shao-Bo Lin", "authors": "Jian Fang, Shaobo Lin, Zongben Xu", "title": "Learning through deterministic assignment of hidden parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning frequently boils down to determining hidden and bright\nparameters in a parameterized hypothesis space based on finite input-output\nsamples. The hidden parameters determine the attributions of hidden predictors\nor the nonlinear mechanism of an estimator, while the bright parameters\ncharacterize how hidden predictors are linearly combined or the linear\nmechanism. In traditional learning paradigm, hidden and bright parameters are\nnot distinguished and trained simultaneously in one learning process. Such an\none-stage learning (OSL) brings a benefit of theoretical analysis but suffers\nfrom the high computational burden. To overcome this difficulty, a two-stage\nlearning (TSL) scheme, featured by learning through deterministic assignment of\nhidden parameters (LtDaHP) was proposed, which suggests to deterministically\ngenerate the hidden parameters by using minimal Riesz energy points on a sphere\nand equally spaced points in an interval. We theoretically show that with such\ndeterministic assignment of hidden parameters, LtDaHP with a neural network\nrealization almost shares the same generalization performance with that of OSL.\nWe also present a series of simulations and application examples to support the\noutperformance of LtDaHP\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:25:39 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 02:41:23 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Fang", "Jian", ""], ["Lin", "Shaobo", ""], ["Xu", "Zongben", ""]]}, {"id": "1803.08375", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Deep Learning using Rectified Linear Units (ReLU)", "comments": "7 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:30:17 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:13:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1803.08416", "submitter": "Ashkan Panahi", "authors": "Ashkan Panahi, Hamid Krim and Liyi Dai", "title": "Demystifying Deep Learning: A Geometric Approach to Iterative\n  Projections", "comments": "To be appeared in the ICASSP 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric approaches to Learning, such as deep learning (DL), are highly\npopular in nonlinear regression, in spite of their extremely difficult training\nwith their increasing complexity (e.g. number of layers in DL). In this paper,\nwe present an alternative semi-parametric framework which foregoes the\nordinarily required feedback, by introducing the novel idea of geometric\nregularization. We show that certain deep learning techniques such as residual\nnetwork (ResNet) architecture are closely related to our approach. Hence, our\ntechnique can be used to analyze these types of deep learning. Moreover, we\npresent preliminary results which confirm that our approach can be easily\ntrained to obtain complex structures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:49:32 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Dai", "Liyi", ""]]}, {"id": "1803.08456", "submitter": "Stephan Alaniz", "authors": "Stephan Alaniz", "title": "Deep Reinforcement Learning with Model Learning and Monte Carlo Tree\n  Search in Minecraft", "comments": "The 3rd Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making (RLDM) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successfully applied to several\nvisual-input tasks using model-free methods. In this paper, we propose a\nmodel-based approach that combines learning a DNN-based transition model with\nMonte Carlo tree search to solve a block-placing task in Minecraft. Our learned\ntransition model predicts the next frame and the rewards one step ahead given\nthe last four frames of the agent's first-person-view image and the current\naction. Then a Monte Carlo tree search algorithm uses this model to plan the\nbest sequence of actions for the agent to perform. On the proposed task in\nMinecraft, our model-based approach reaches the performance comparable to the\nDeep Q-Network's, but learns faster and, thus, is more training sample\nefficient.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 16:53:34 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Alaniz", "Stephan", ""]]}, {"id": "1803.08460", "submitter": "Yi Zhu", "authors": "Yi Zhu, Yang Long, Yu Guan, Shawn Newsam, Ling Shao", "title": "Towards Universal Representation for Unseen Action Recognition", "comments": "Accepted at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen Action Recognition (UAR) aims to recognise novel action categories\nwithout training examples. While previous methods focus on inner-dataset\nseen/unseen splits, this paper proposes a pipeline using a large-scale training\nsource to achieve a Universal Representation (UR) that can generalise to a more\nrealistic Cross-Dataset UAR (CD-UAR) scenario. We first address UAR as a\nGeneralised Multiple-Instance Learning (GMIL) problem and discover\n'building-blocks' from the large-scale ActivityNet dataset using distribution\nkernels. Essential visual and semantic components are preserved in a shared\nspace to achieve the UR that can efficiently generalise to new datasets.\nPredicted UR exemplars can be improved by a simple semantic adaptation, and\nthen an unseen action can be directly recognised using UR during the test.\nWithout further training, extensive experiments manifest significant\nimprovements over the UCF101 and HMDB51 benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:02:45 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zhu", "Yi", ""], ["Long", "Yang", ""], ["Guan", "Yu", ""], ["Newsam", "Shawn", ""], ["Shao", "Ling", ""]]}, {"id": "1803.08471", "submitter": "Hanna Wallach", "authors": "Aaron Schein, Zhiwei Steven Wu, Alexandra Schofield, Mingyuan Zhou,\n  Hanna Wallach", "title": "Locally Private Bayesian Inference for Count Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for privacy-preserving Bayesian inference in\nPoisson factorization, a broad class of models that includes some of the most\nwidely used models in the social sciences. Our method satisfies limited\nprecision local privacy, a generalization of local differential privacy, which\nwe introduce to formulate privacy guarantees appropriate for sparse count data.\nWe develop an MCMC algorithm that approximates the locally private posterior\nover model parameters given data that has been locally privatized by the\ngeometric mechanism (Ghosh et al., 2012). Our solution is based on two\ninsights: 1) a novel reinterpretation of the geometric mechanism in terms of\nthe Skellam distribution (Skellam, 1946) and 2) a general theorem that relates\nthe Skellam to the Bessel distribution (Yuan & Kalbfleisch, 2000). We\ndemonstrate our method in two case studies on real-world email data in which we\nshow that our method consistently outperforms the commonly-used naive approach,\nobtaining higher quality topics in text and more accurate link prediction in\nnetworks. On some tasks, our privacy-preserving method even outperforms\nnon-private inference which conditions on the true data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:14:29 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 01:20:02 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 21:44:51 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Schein", "Aaron", ""], ["Wu", "Zhiwei Steven", ""], ["Schofield", "Alexandra", ""], ["Zhou", "Mingyuan", ""], ["Wallach", "Hanna", ""]]}, {"id": "1803.08475", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof and Max Welling", "title": "Attention, Learn to Solve Routing Problems!", "comments": "Accepted at ICLR 2019. 25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently presented idea to learn heuristics for combinatorial\noptimization problems is promising as it can save costly development. However,\nto push this idea towards practical implementation, we need better models and\nbetter ways of training. We contribute in both directions: we propose a model\nbased on attention layers with benefits over the Pointer Network and we show\nhow to train this model using REINFORCE with a simple baseline based on a\ndeterministic greedy rollout, which we find is more efficient than using a\nvalue function. We significantly improve over recent learned heuristics for the\nTravelling Salesman Problem (TSP), getting close to optimal results for\nproblems up to 100 nodes. With the same hyperparameters, we learn strong\nheuristics for two variants of the Vehicle Routing Problem (VRP), the\nOrienteering Problem (OP) and (a stochastic variant of) the Prize Collecting\nTSP (PCTSP), outperforming a wide range of baselines and getting results close\nto highly optimized and specialized algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:22:24 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 12:37:55 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 09:10:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "1803.08494", "submitter": "Kaiming He", "authors": "Yuxin Wu, Kaiming He", "title": "Group Normalization", "comments": "v3: Update trained-from-scratch results in COCO to 41.0AP. Code and\n  models at\n  https://github.com/facebookresearch/Detectron/blob/master/projects/GN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is a milestone technique in the development of deep\nlearning, enabling various networks to train. However, normalizing along the\nbatch dimension introduces problems --- BN's error increases rapidly when the\nbatch size becomes smaller, caused by inaccurate batch statistics estimation.\nThis limits BN's usage for training larger models and transferring features to\ncomputer vision tasks including detection, segmentation, and video, which\nrequire small batches constrained by memory consumption. In this paper, we\npresent Group Normalization (GN) as a simple alternative to BN. GN divides the\nchannels into groups and computes within each group the mean and variance for\nnormalization. GN's computation is independent of batch sizes, and its accuracy\nis stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN\nhas 10.6% lower error than its BN counterpart when using a batch size of 2;\nwhen using typical batch sizes, GN is comparably good with BN and outperforms\nother normalization variants. Moreover, GN can be naturally transferred from\npre-training to fine-tuning. GN can outperform its BN-based counterparts for\nobject detection and segmentation in COCO, and for video classification in\nKinetics, showing that GN can effectively replace the powerful BN in a variety\nof tasks. GN can be easily implemented by a few lines of code in modern\nlibraries.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:57:16 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 18:12:19 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 22:48:02 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Wu", "Yuxin", ""], ["He", "Kaiming", ""]]}, {"id": "1803.08495", "submitter": "Kevin Chen", "authors": "Kevin Chen, Christopher B. Choy, Manolis Savva, Angel X. Chang, Thomas\n  Funkhouser, Silvio Savarese", "title": "Text2Shape: Generating Shapes from Natural Language by Learning Joint\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for generating colored 3D shapes from natural language.\nTo this end, we first learn joint embeddings of freeform text descriptions and\ncolored 3D shapes. Our model combines and extends learning by association and\nmetric learning approaches to learn implicit cross-modal connections, and\nproduces a joint representation that captures the many-to-many relations\nbetween language and physical properties of 3D shapes such as color and shape.\nTo evaluate our approach, we collect a large dataset of natural language\ndescriptions for physical 3D objects in the ShapeNet dataset. With this learned\njoint embedding we demonstrate text-to-shape retrieval that outperforms\nbaseline approaches. Using our embeddings with a novel conditional Wasserstein\nGAN framework, we generate colored 3D shapes from text. Our method is the first\nto connect natural language text with realistic 3D objects exhibiting rich\nvariations in color, texture, and shape detail. See video at\nhttps://youtu.be/zraPvRdl13Q\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:57:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Chen", "Kevin", ""], ["Choy", "Christopher B.", ""], ["Savva", "Manolis", ""], ["Chang", "Angel X.", ""], ["Funkhouser", "Thomas", ""], ["Savarese", "Silvio", ""]]}, {"id": "1803.08501", "submitter": "Francesco Riccio Mr.", "authors": "Francesco Riccio, Roberto Capobianco, Daniele Nardi", "title": "DOP: Deep Optimistic Planning with Approximate Value Function Evaluation", "comments": "to appear as an extended abstract paper in the Proc. of the 17th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2018), Stockholm, Sweden, July 10-15, 2018, IFAAMAS. arXiv admin note: text\n  overlap with arXiv:1803.00297", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on reinforcement learning has demonstrated promising results in\nmanifold applications and domains. Still, efficiently learning effective robot\nbehaviors is very difficult, due to unstructured scenarios, high uncertainties,\nand large state dimensionality (e.g. multi-agent systems or hyper-redundant\nrobots). To alleviate this problem, we present DOP, a deep model-based\nreinforcement learning algorithm, which exploits action values to both (1)\nguide the exploration of the state space and (2) plan effective policies.\nSpecifically, we exploit deep neural networks to learn Q-functions that are\nused to attack the curse of dimensionality during a Monte-Carlo tree search.\nOur algorithm, in fact, constructs upper confidence bounds on the learned value\nfunction to select actions optimistically. We implement and evaluate DOP on\ndifferent scenarios: (1) a cooperative navigation problem, (2) a fetching task\nfor a 7-DOF KUKA robot, and (3) a human-robot handover with a humanoid robot\n(both in simulation and real). The obtained results show the effectiveness of\nDOP in the chosen applications, where action values drive the exploration and\nreduce the computational demand of the planning process while achieving good\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:59:16 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Riccio", "Francesco", ""], ["Capobianco", "Roberto", ""], ["Nardi", "Daniele", ""]]}, {"id": "1803.08533", "submitter": "Lewis Smith", "authors": "Lewis Smith and Yarin Gal", "title": "Understanding Measures of Uncertainty for Adversarial Example Detection", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring uncertainty is a promising technique for detecting adversarial\nexamples, crafted inputs on which the model predicts an incorrect class with\nhigh confidence. But many measures of uncertainty exist, including predictive\nen- tropy and mutual information, each capturing different types of\nuncertainty. We study these measures, and shed light on why mutual information\nseems to be effective at the task of adversarial example detection. We\nhighlight failure modes for MC dropout, a widely used approach for estimating\nuncertainty in deep models. This leads to an improved understanding of the\ndrawbacks of current methods, and a proposal to improve the quality of\nuncertainty estimates using probabilistic model ensembles. We give illustrative\nexperiments using MNIST to demonstrate the intuition underlying the different\nmeasures of uncertainty, as well as experiments on a real world Kaggle dogs vs\ncats classification dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 18:26:22 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "1803.08552", "submitter": "Kim Peter Wabersich", "authors": "Kim P. Wabersich and Melanie N. Zeilinger", "title": "Linear model predictive safety certification for learning-based control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it has been repeatedly shown that learning-based controllers can\nprovide superior performance, they often lack of safety guarantees. This paper\naims at addressing this problem by introducing a model predictive safety\ncertification (MPSC) scheme for polytopic linear systems with additive\ndisturbances. The scheme verifies safety of a proposed learning-based input and\nmodifies it as little as necessary in order to keep the system within a given\nset of constraints. Safety is thereby related to the existence of a model\npredictive controller (MPC) providing a feasible trajectory towards a safe\ntarget set. A robust MPC formulation accounts for the fact that the model is\ngenerally uncertain in the context of learning, which allows proving constraint\nsatisfaction at all times under the proposed MPSC strategy. The MPSC scheme can\nbe used in order to expand any potentially conservative set of safe states for\nlearning and we prove an iterative technique for enlarging the safe set.\nFinally, a practical data-based design procedure for MPSC is proposed using\nscenario optimization.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 19:19:09 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 06:54:54 GMT"}, {"version": "v3", "created": "Thu, 3 May 2018 14:14:36 GMT"}, {"version": "v4", "created": "Tue, 29 May 2018 12:16:49 GMT"}, {"version": "v5", "created": "Tue, 18 Sep 2018 12:29:54 GMT"}, {"version": "v6", "created": "Mon, 8 Apr 2019 11:39:34 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wabersich", "Kim P.", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "1803.08554", "submitter": "Ramin M. Hasani", "authors": "Mathias Lechner, Ramin M. Hasani, Radu Grosu", "title": "Neuronal Circuit Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective way to create interpretable control agents, by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real world reinforcement learning (RL) test-beds. We model the\ntap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit\nresponsible for the worm's reflexive response to external mechanical touch\nstimulations, and learn its synaptic and neuronal parameters as a policy for\ncontrolling basic RL tasks. We also autonomously park a real rover robot on a\npre-defined trajectory, by deploying such neuronal circuit policies learned in\na simulated environment. For reconfiguration of the purpose of the TW neural\ncircuit, we adopt a search-based RL algorithm. We show that our neuronal\npolicies perform as good as deep neural network policies with the advantage of\nrealizing interpretable dynamics at the cell level.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 19:23:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lechner", "Mathias", ""], ["Hasani", "Ramin M.", ""], ["Grosu", "Radu", ""]]}, {"id": "1803.08577", "submitter": "Francois Fagan", "authors": "Francois Fagan and Garud Iyengar", "title": "Unbiased scalable softmax optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network and language models rely on softmax distributions with\nan extremely large number of categories. Since calculating the softmax\nnormalizing constant in this context is prohibitively expensive, there is a\ngrowing literature of efficiently computable but biased estimates of the\nsoftmax. In this paper we propose the first unbiased algorithms for maximizing\nthe softmax likelihood whose work per iteration is independent of the number of\nclasses and datapoints (and no extra work is required at the end of each\nepoch). We show that our proposed unbiased methods comprehensively outperform\nthe state-of-the-art on seven real world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 20:32:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Fagan", "Francois", ""], ["Iyengar", "Garud", ""]]}, {"id": "1803.08586", "submitter": "Yining Wang", "authors": "Yining Wang, Sivaraman Balakrishnan, Aarti Singh", "title": "Optimization of Smooth Functions with Noisy Observations: Local Minimax\n  Rates", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of global optimization of an unknown non-convex\nsmooth function with zeroth-order feedback. In this setup, an algorithm is\nallowed to adaptively query the underlying function at different locations and\nreceives noisy evaluations of function values at the queried points (i.e. the\nalgorithm has access to zeroth-order information). Optimization performance is\nevaluated by the expected difference of function values at the estimated\noptimum and the true optimum. In contrast to the classical optimization setup,\nfirst-order information like gradients are not directly accessible to the\noptimization algorithm. We show that the classical minimax framework of\nanalysis, which roughly characterizes the worst-case query complexity of an\noptimization algorithm in this setting, leads to excessively pessimistic\nresults. We propose a local minimax framework to study the fundamental\ndifficulty of optimizing smooth functions with adaptive function evaluations,\nwhich provides a refined picture of the intrinsic difficulty of zeroth-order\noptimization. We show that for functions with fast level set growth around the\nglobal minimum, carefully designed optimization algorithms can identify a near\nglobal minimizer with many fewer queries. For the special case of strongly\nconvex and smooth functions, our implied convergence rates match the ones\ndeveloped for zeroth-order convex optimization problems. At the other end of\nthe spectrum, for worst-case smooth functions no algorithm can converge faster\nthan the minimax rate of estimating the entire unknown function in the\n$\\ell_\\infty$-norm. We provide an intuitive and efficient algorithm that\nattains the derived upper error bounds.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 21:21:02 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Wang", "Yining", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1803.08591", "submitter": "Di Chen", "authors": "Di Chen, Yexiang Xue, Carla P. Gomes", "title": "End-to-End Learning for the Deep Multivariate Probit Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multivariate probit model (MVP) is a popular classic model for studying\nbinary responses of multiple entities. Nevertheless, the computational\nchallenge of learning the MVP model, given that its likelihood involves\nintegrating over a multidimensional constrained space of latent variables,\nsignificantly limits its application in practice. We propose a flexible deep\ngeneralization of the classic MVP, the Deep Multivariate Probit Model (DMVP),\nwhich is an end-to-end learning scheme that uses an efficient parallel sampling\nprocess of the multivariate probit model to exploit GPU-boosted deep neural\nnetworks. We present both theoretical and empirical analysis of the convergence\nbehavior of DMVP's sampling process with respect to the resolution of the\ncorrelation structure. We provide convergence guarantees for DMVP and our\nempirical analysis demonstrates the advantages of DMVP's sampling compared with\nstandard MCMC-based methods. We also show that when applied to multi-entity\nmodelling problems, which are natural DMVP applications, DMVP trains faster\nthan classical MVP, by at least an order of magnitude, captures rich\ncorrelations among entities, and further improves the joint likelihood of\nentities compared with several competitive models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 21:35:39 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 23:57:40 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 23:58:27 GMT"}, {"version": "v4", "created": "Fri, 13 Jul 2018 07:40:03 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Chen", "Di", ""], ["Xue", "Yexiang", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1803.08604", "submitter": "Jennifer Ortiz", "authors": "Jennifer Ortiz, Magdalena Balazinska, Johannes Gehrke, S. Sathiya\n  Keerthi", "title": "Learning State Representations for Query Optimization with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is quickly changing the field of artificial\nintelligence. These models are able to capture a high level understanding of\ntheir environment, enabling them to learn difficult dynamic tasks in a variety\nof domains. In the database field, query optimization remains a difficult\nproblem. Our goal in this work is to explore the capabilities of deep\nreinforcement learning in the context of query optimization. At each state, we\nbuild queries incrementally and encode properties of subqueries through a\nlearned representation. The challenge here lies in the formation of the state\ntransition function, which defines how the current subquery state combines with\nthe next query operation (action) to yield the next state. As a first step in\nthis direction, we focus the state representation problem and the formation of\nthe state transition function. We describe our approach and show preliminary\nresults. We further discuss how we can use the state representation to improve\nquery optimization using reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 22:39:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Ortiz", "Jennifer", ""], ["Balazinska", "Magdalena", ""], ["Gehrke", "Johannes", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "1803.08624", "submitter": "G. Adam Cox", "authors": "G. A. Cox and S. Egly and G. R. Harp and J. Richards and S. Vinodababu\n  and J. Voien", "title": "Classification of simulated radio signals using Wide Residual Networks\n  for use in the search for extra-terrestrial intelligence", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a new approach and algorithm for the detection of artificial\nsignals and their classification in the search for extraterrestrial\nintelligence (SETI). The characteristics of radio signals observed during SETI\nresearch are often most apparent when those signals are represented as\nspectrograms. Additionally, many observed signals tend to share the same\ncharacteristics, allowing for sorting of the signals into different classes.\nFor this work, complex-valued time-series data were simulated to produce a\ncorpus of 140,000 signals from seven different signal classes. A wide residual\nneural network was then trained to classify these signal types using the\ngray-scale 2D spectrogram representation of those signals. An average $F_1$\nscore of 95.11\\% was attained when tested on previously unobserved simulated\nsignals. We also report on the performance of the model across a range of\nsignal amplitudes.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 00:56:13 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Cox", "G. A.", ""], ["Egly", "S.", ""], ["Harp", "G. R.", ""], ["Richards", "J.", ""], ["Vinodababu", "S.", ""], ["Voien", "J.", ""]]}, {"id": "1803.08629", "submitter": "Shariq Mobin", "authors": "Shariq Mobin, Brian Cheung, Bruno Olshausen", "title": "Generalization Challenges for Neural Architectures in Audio Source\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that recurrent neural networks can be trained to\nseparate individual speakers in a sound mixture with high fidelity. Here we\nexplore convolutional neural network models as an alternative and show that\nthey achieve state-of-the-art results with an order of magnitude fewer\nparameters. We also characterize and compare the robustness and ability of\nthese different approaches to generalize under three different test conditions:\nlonger time sequences, the addition of intermittent noise, and different\ndatasets not seen during training. For the last condition, we create a new\ndataset, RealTalkLibri, to test source separation in real-world environments.\nWe show that the acoustics of the environment have significant impact on the\nstructure of the waveform and the overall performance of neural network models,\nwith the convolutional model showing superior ability to generalize to new\nenvironments. The code for our study is available at\nhttps://github.com/ShariqM/source_separation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:26:39 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 17:03:09 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Mobin", "Shariq", ""], ["Cheung", "Brian", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1803.08631", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "SEGEN: Sample-Ensemble Genetic Evolutional Network Model", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:43:37 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:39:53 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1803.08647", "submitter": "Hao Ge", "authors": "Hao Ge, Yin Xia, Xu Chen, Randall Berry and Ying Wu", "title": "Fictitious GAN: Training GANs with Historical Models", "comments": "19 pages. First three authors have equal contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are powerful tools for learning\ngenerative models. In practice, the training may suffer from lack of\nconvergence. GANs are commonly viewed as a two-player zero-sum game between two\nneural networks. Here, we leverage this game theoretic view to study the\nconvergence behavior of the training process. Inspired by the fictitious play\nlearning process, a novel training method, referred to as Fictitious GAN, is\nintroduced. Fictitious GAN trains the deep neural networks using a mixture of\nhistorical models. Specifically, the discriminator (resp. generator) is updated\naccording to the best-response to the mixture outputs from a sequence of\npreviously trained generators (resp. discriminators). It is shown that\nFictitious GAN can effectively resolve some convergence issues that cannot be\nresolved by the standard training approach. It is proved that asymptotically\nthe average of the generator outputs has the same distribution as the data\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 03:46:12 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 18:50:03 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Ge", "Hao", ""], ["Xia", "Yin", ""], ["Chen", "Xu", ""], ["Berry", "Randall", ""], ["Wu", "Ying", ""]]}, {"id": "1803.08651", "submitter": "Rahul Meshram", "authors": "Rahul Meshram, D. Manjunath and Nikhil Karamchandani", "title": "Learning Recommendations While Influencing Interests", "comments": "13 pages, submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendation systems (RS) are extensively used in many\nservices. Many of these are based on learning algorithms where the RS uses the\nrecommendation history and the user response to learn an optimal strategy.\nFurther, these algorithms are based on the assumption that the user interests\nare rigid. Specifically, they do not account for the effect of learning\nstrategy on the evolution of the user interests. In this paper we develop\ninfluence models for a learning algorithm that is used to optimally recommend\nwebsites to web users. We adapt the model of \\cite{Ioannidis10} to include an\nitem-dependent reward to the RS from the suggestions that are accepted by the\nuser. For this we first develop a static optimisation scheme when all the\nparameters are known. Next we develop a stochastic approximation based learning\nscheme for the RS to learn the optimal strategy when the user profiles are not\nknown. Finally, we describe several user-influence models for the learning\nalgorithm and analyze their effect on the steady user interests and on the\nsteady state optimal strategy as compared to that when the users are not\ninfluenced.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 04:09:24 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Meshram", "Rahul", ""], ["Manjunath", "D.", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "1803.08661", "submitter": "Saul Toscano-Palmerin", "authors": "Saul Toscano-Palmerin, Peter I. Frazier", "title": "Bayesian Optimization with Expensive Integrands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian optimization algorithm for objective functions that are\nsums or integrals of expensive-to-evaluate functions, allowing noisy\nevaluations. These objective functions arise in multi-task Bayesian\noptimization for tuning machine learning hyperparameters, optimization via\nsimulation, and sequential design of experiments with random environmental\nconditions. Our method is average-case optimal by construction when a single\nevaluation of the integrand remains within our evaluation budget. Achieving\nthis one-step optimality requires solving a challenging value of information\noptimization problem, for which we provide a novel efficient\ndiscretization-free computational method. We also provide consistency proofs\nfor our method in both continuum and discrete finite domains for objective\nfunctions that are sums. In numerical experiments comparing against previous\nstate-of-the-art methods, including those that also leverage sum or integral\nstructure, our method performs as well or better across a wide range of\nproblems and offers significant improvements when evaluations are noisy or the\nintegrand varies smoothly in the integrated variables.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 05:53:26 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Toscano-Palmerin", "Saul", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1803.08680", "submitter": "Daniel Jakubovitz", "authors": "Daniel Jakubovitz, Raja Giryes", "title": "Improving DNN Robustness to Adversarial Attacks using Jacobian\n  Regularization", "comments": "ECCV 2018 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have lately shown tremendous performance in various\napplications including vision and speech processing tasks. However, alongside\ntheir ability to perform these tasks with such high accuracy, it has been shown\nthat they are highly susceptible to adversarial attacks: a small change in the\ninput would cause the network to err with high confidence. This phenomenon\nexposes an inherent fault in these networks and their ability to generalize\nwell. For this reason, providing robustness to adversarial attacks is an\nimportant challenge in networks training, which has led to extensive research.\nIn this work, we suggest a theoretically inspired novel approach to improve the\nnetworks' robustness. Our method applies regularization using the Frobenius\nnorm of the Jacobian of the network, which is applied as post-processing, after\nregular training has finished. We demonstrate empirically that it leads to\nenhanced robustness results with a minimal change in the original network's\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 07:57:04 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 16:02:08 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 16:43:36 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 09:48:05 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Jakubovitz", "Daniel", ""], ["Giryes", "Raja", ""]]}, {"id": "1803.08700", "submitter": "Nicolas Tremblay", "authors": "Nicolas Tremblay, Simon Barthelm\\'e, Pierre-Olivier Amblard", "title": "Determinantal Point Processes for Coresets", "comments": null, "journal-ref": "Journal of Machine Learning Research 20 (2019) 1-70", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When faced with a data set too large to be processed all at once, an obvious\nsolution is to retain only part of it. In practice this takes a wide variety of\ndifferent forms, and among them \"coresets\" are especially appealing. A coreset\nis a (small) weighted sample of the original data that comes with the following\nguarantee: a cost function can be evaluated on the smaller set instead of the\nlarger one, with low relative error. For some classes of problems, and via a\ncareful choice of sampling distribution (based on the so-called \"sensitivity\"\nmetric), iid random sampling has turned to be one of the most successful\nmethods for building coresets efficiently. However, independent samples are\nsometimes overly redundant, and one could hope that enforcing diversity would\nlead to better performance. The difficulty lies in proving coreset properties\nin non-iid samples. We show that the coreset property holds for samples formed\nwith determinantal point processes (DPP). DPPs are interesting because they are\na rare example of repulsive point processes with tractable theoretical\nproperties, enabling us to prove general coreset theorems. We apply our results\nto both the k-means and the linear regression problems, and give extensive\nempirical evidence that the small additional computational cost of DPP sampling\ncomes with superior performance over its iid counterpart. Of independent\ninterest, we also provide analytical formulas for the sensitivity in the linear\nregression and 1-means cases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:17:48 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 15:58:34 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 08:18:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Barthelm\u00e9", "Simon", ""], ["Amblard", "Pierre-Olivier", ""]]}, {"id": "1803.08706", "submitter": "Irene Teinemaa", "authors": "Irene Teinemaa, Niek Tax, Massimiliano de Leoni, Marlon Dumas,\n  Fabrizio Maria Maggi", "title": "Alarm-Based Prescriptive Process Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring is concerned with the analysis of events\nproduced during the execution of a process in order to predict the future state\nof ongoing cases thereof. Existing techniques in this field are able to\npredict, at each step of a case, the likelihood that the case will end up in an\nundesired outcome. These techniques, however, do not take into account what\nprocess workers may do with the generated predictions in order to decrease the\nlikelihood of undesired outcomes. This paper proposes a framework for\nprescriptive process monitoring, which extends predictive process monitoring\napproaches with the concepts of alarms, interventions, compensations, and\nmitigation effects. The framework incorporates a parameterized cost model to\nassess the cost-benefit tradeoffs of applying prescriptive process monitoring\nin a given setting. The paper also outlines an approach to optimize the\ngeneration of alarms given a dataset and a set of cost model parameters. The\nproposed approach is empirically evaluated using a range of real-life event\nlogs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:27:38 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 20:08:32 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Teinemaa", "Irene", ""], ["Tax", "Niek", ""], ["de Leoni", "Massimiliano", ""], ["Dumas", "Marlon", ""], ["Maggi", "Fabrizio Maria", ""]]}, {"id": "1803.08740", "submitter": "Elisa Maiettini", "authors": "Elisa Maiettini, Giulia Pasquale, Lorenzo Rosasco and Lorenzo Natale", "title": "Speeding-up Object Detection Training for Robotics with FALKON", "comments": null, "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), 2018", "doi": "10.1109/IROS.2018.8593990", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest deep learning methods for object detection provide remarkable\nperformance, but have limits when used in robotic applications. One of the most\nrelevant issues is the long training time, which is due to the large size and\nimbalance of the associated training sets, characterized by few positive and a\nlarge number of negative examples (i.e. background). Proposed approaches are\nbased on end-to-end learning by back-propagation [22] or kernel methods trained\nwith Hard Negatives Mining on top of deep features [8]. These solutions are\neffective, but prohibitively slow for on-line applications. In this paper we\npropose a novel pipeline for object detection that overcomes this problem and\nprovides comparable performance, with a 60x training speedup. Our pipeline\ncombines (i) the Region Proposal Network and the deep feature extractor from\n[22] to efficiently select candidate RoIs and encode them into powerful\nrepresentations, with (ii) the FALKON [23] algorithm, a novel kernel-based\nmethod that allows fast training on large scale problems (millions of points).\nWe address the size and imbalance of training data by exploiting the stochastic\nsubsampling intrinsic into the method and a novel, fast, bootstrapping\napproach. We assess the effectiveness of the approach on a standard Computer\nVision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a\nreal robotic scenario with the iCubWorld Transformations [18] dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 11:13:29 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 15:19:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Maiettini", "Elisa", ""], ["Pasquale", "Giulia", ""], ["Rosasco", "Lorenzo", ""], ["Natale", "Lorenzo", ""]]}, {"id": "1803.08773", "submitter": "Chiliang Zhang", "authors": "Chiliang Zhang, Zhimou Yang, Zuochang Ye", "title": "Detecting Adversarial Perturbations with Saliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel method for detecting adversarial examples by\ntraining a binary classifier with both origin data and saliency data. In the\ncase of image classification model, saliency simply explain how the model make\ndecisions by identifying significant pixels for prediction. A model shows wrong\nclassification output always learns wrong features and shows wrong saliency as\nwell. Our approach shows good performance on detecting adversarial\nperturbations. We quantitatively evaluate generalization ability of the\ndetector, showing that detectors trained with strong adversaries perform well\non weak adversaries.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 12:52:28 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Zhang", "Chiliang", ""], ["Yang", "Zhimou", ""], ["Ye", "Zuochang", ""]]}, {"id": "1803.08784", "submitter": "Stephan Bongers", "authors": "Stephan Bongers, Joris M. Mooij", "title": "From Random Differential Equations to Structural Causal Models: the\n  stochastic case", "comments": "Submitted to UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Differential Equations provide a natural extension of Ordinary\nDifferential Equations to the stochastic setting. We show how, and under which\nconditions, every equilibrium state of a Random Differential Equation (RDE) can\nbe described by a Structural Causal Model (SCM), while pertaining the causal\nsemantics. This provides an SCM that captures the stochastic and causal\nbehavior of the RDE, which can model both cycles and confounders. This enables\nthe study of the equilibrium states of the RDE by applying the theory and\nstatistical tools available for SCMs, for example, marginalizations and Markov\nproperties, as we illustrate by means of an example. Our work thus provides a\ndirect connection between two fields that so far have been developing in\nisolation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 13:20:56 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 09:09:52 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Bongers", "Stephan", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1803.08790", "submitter": "Md Saiful Islam", "authors": "Hemayet Ahmed Chowdhury, Tanvir Alam Nibir and Md. Saiful Islam", "title": "Sentiment Analysis of Comments on Rohingya Movement with Support Vector\n  Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Rohingya Movement and Crisis caused a huge uproar in the political and\neconomic state of Bangladesh. Refugee movement is a recurring event and a large\namount of data in the form of opinions remains on social media such as\nFacebook, with very little analysis done on them.To analyse the comments based\non all Rohingya related posts, we had to create and modify a classifier based\non the Support Vector Machine algorithm. The code is implemented in python and\nuses scikit-learn library. A dataset on Rohingya analysis is not currently\navailable so we had to use our own data set of 2500 positive and 2500 negative\ncomments. We specifically used a support vector machine with linear kernel. A\nprevious experiment was performed by us on the same dataset using the naive\nbayes algorithm, but that did not yield impressive results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:30:03 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Chowdhury", "Hemayet Ahmed", ""], ["Nibir", "Tanvir Alam", ""], ["Islam", "Md. Saiful", ""]]}, {"id": "1803.08793", "submitter": "Jack Lanchantin", "authors": "Jack Lanchantin, Ji Gao", "title": "Exploring the Naturalness of Buggy Code with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical language models are powerful tools which have been used for many\ntasks within natural language processing. Recently, they have been used for\nother sequential data such as source code.(Ray et al., 2015) showed that it is\npossible train an n-gram source code language mode, and use it to predict buggy\nlines in code by determining \"unnatural\" lines via entropy with respect to the\nlanguage model. In this work, we propose using a more advanced language\nmodeling technique, Long Short-term Memory recurrent neural networks, to model\nsource code and classify buggy lines based on entropy. We show that our method\nslightly outperforms an n-gram model in the buggy line classification task\nusing AUC.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:14:22 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lanchantin", "Jack", ""], ["Gao", "Ji", ""]]}, {"id": "1803.08823", "submitter": "Marin Bukov Dr.", "authors": "Pankaj Mehta, Marin Bukov, Ching-Hao Wang, Alexandre G.R. Day, Clint\n  Richardson, Charles K. Fisher, and David J. Schwab", "title": "A high-bias, low-variance introduction to Machine Learning for\n  physicists", "comments": "Notebooks have been updated. 122 pages, 78 figures, 20 Python\n  notebooks", "journal-ref": "Phyics Reports 810 (2019) 1-124", "doi": "10.1016/j.physrep.2019.03.001", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is one of the most exciting and dynamic areas of modern\nresearch and application. The purpose of this review is to provide an\nintroduction to the core concepts and tools of machine learning in a manner\neasily understood and intuitive to physicists. The review begins by covering\nfundamental concepts in ML and modern statistics such as the bias-variance\ntradeoff, overfitting, regularization, generalization, and gradient descent\nbefore moving on to more advanced topics in both supervised and unsupervised\nlearning. Topics covered in the review include ensemble models, deep learning\nand neural networks, clustering and data visualization, energy-based models\n(including MaxEnt models and Restricted Boltzmann Machines), and variational\nmethods. Throughout, we emphasize the many natural connections between ML and\nstatistical physics. A notable aspect of the review is the use of Python\nJupyter notebooks to introduce modern ML/statistical packages to readers using\nphysics-inspired datasets (the Ising Model and Monte-Carlo simulations of\nsupersymmetric decays of proton-proton collisions). We conclude with an\nextended outlook discussing possible uses of machine learning for furthering\nour understanding of the physical world as well as open problems in ML where\nphysicists may be able to contribute. (Notebooks are available at\nhttps://physics.bu.edu/~pankajm/MLnotebooks.html )\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 14:53:05 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 23:39:08 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 16:51:57 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Mehta", "Pankaj", ""], ["Bukov", "Marin", ""], ["Wang", "Ching-Hao", ""], ["Day", "Alexandre G. R.", ""], ["Richardson", "Clint", ""], ["Fisher", "Charles K.", ""], ["Schwab", "David J.", ""]]}, {"id": "1803.08841", "submitter": "Nikola Konstantinov", "authors": "Dan Alistarh, Christopher De Sa, Nikola Konstantinov", "title": "The Convergence of Stochastic Gradient Descent in Asynchronous Shared\n  Memory", "comments": "To be published in PoDC 2018; 18 pages, 1 figure; Changes: added\n  pseudocode for Algorithm 2, some references and corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is a fundamental algorithm in machine\nlearning, representing the optimization backbone for training several classic\nmodels, from regression to neural networks. Given the recent practical focus on\ndistributed machine learning, significant work has been dedicated to the\nconvergence properties of this algorithm under the inconsistent and noisy\nupdates arising from execution in a distributed environment. However,\nsurprisingly, the convergence properties of this classic algorithm in the\nstandard shared-memory model are still not well-understood.\n  In this work, we address this gap, and provide new convergence bounds for\nlock-free concurrent stochastic gradient descent, executing in the classic\nasynchronous shared memory model, against a strong adaptive adversary. Our\nresults give improved upper and lower bounds on the \"price of asynchrony\" when\nexecuting the fundamental SGD algorithm in a concurrent setting. They show that\nthis classic optimization tool can converge faster and with a wider range of\nparameters than previously known under asynchronous iterations. At the same\ntime, we exhibit a fundamental trade-off between the maximum delay in the\nsystem and the rate at which SGD can converge, which governs the set of\nparameters under which this algorithm can still work efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 15:32:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 16:14:39 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Alistarh", "Dan", ""], ["De Sa", "Christopher", ""], ["Konstantinov", "Nikola", ""]]}, {"id": "1803.08869", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Lieke Gelderloos, \\'Akos K\\'ad\\'ar, Afra\n  Alishahi", "title": "On the difficulty of a distributional semantics of spoken language", "comments": "Proceedings of the Society for Computation in Linguistics 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of unsupervised learning most work on speech has focused on\ndiscovering low-level constructs such as phoneme inventories or word-like\nunits. In contrast, for written language, where there is a large body of work\non unsupervised induction of semantic representations of words, whole sentences\nand longer texts. In this study we examine the challenges of adapting these\napproaches from written to spoken language. We conjecture that unsupervised\nlearning of the semantics of spoken language becomes feasible if we abstract\nfrom the surface variability. We simulate this setting with a dataset of\nutterances spoken by a realistic but uniform synthetic voice. We evaluate two\nsimple unsupervised models which, to varying degrees of success, learn semantic\nrepresentations of speech fragments. Finally we present inconclusive results on\nhuman speech, and discuss the challenges inherent in learning distributional\nsemantic representations on unrestricted natural spoken language.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:30:06 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 13:52:41 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Gelderloos", "Lieke", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Alishahi", "Afra", ""]]}, {"id": "1803.08882", "submitter": "Alexander B\\\"ottcher", "authors": "Alexander B\\\"ottcher, Wieland Brendel, Bernhard Englitz, Matthias\n  Bethge", "title": "Trace your sources in large-scale data: one ring to find them all", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important preprocessing step in most data analysis pipelines aims to\nextract a small set of sources that explain most of the data. Currently used\nalgorithms for blind source separation (BSS), however, often fail to extract\nthe desired sources and need extensive cross-validation. In contrast, their\nrarely used probabilistic counterparts can get away with little\ncross-validation and are more accurate and reliable but no simple and scalable\nimplementations are available. Here we present a novel probabilistic BSS\nframework (DECOMPOSE) that can be flexibly adjusted to the data, is extensible\nand easy to use, adapts to individual sources and handles large-scale data\nthrough algorithmic efficiency. DECOMPOSE encompasses and generalises many\ntraditional BSS algorithms such as PCA, ICA and NMF and we demonstrate\nsubstantial improvements in accuracy and robustness on artificial and real\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:56:13 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["B\u00f6ttcher", "Alexander", ""], ["Brendel", "Wieland", ""], ["Englitz", "Bernhard", ""], ["Bethge", "Matthias", ""]]}, {"id": "1803.08917", "submitter": "Zeyuan Allen-Zhu", "authors": "Dan Alistarh, Zeyuan Allen-Zhu, Jerry Li", "title": "Byzantine Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of distributed stochastic optimization in an\nadversarial setting where, out of the $m$ machines which allegedly compute\nstochastic gradients every iteration, an $\\alpha$-fraction are Byzantine, and\ncan behave arbitrarily and adversarially. Our main result is a variant of\nstochastic gradient descent (SGD) which finds $\\varepsilon$-approximate\nminimizers of convex functions in $T = \\tilde{O}\\big( \\frac{1}{\\varepsilon^2 m}\n+ \\frac{\\alpha^2}{\\varepsilon^2} \\big)$ iterations. In contrast, traditional\nmini-batch SGD needs $T = O\\big( \\frac{1}{\\varepsilon^2 m} \\big)$ iterations,\nbut cannot tolerate Byzantine failures. Further, we provide a lower bound\nshowing that, up to logarithmic factors, our algorithm is\ninformation-theoretically optimal both in terms of sampling complexity and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:58:54 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Alistarh", "Dan", ""], ["Allen-Zhu", "Zeyuan", ""], ["Li", "Jerry", ""]]}, {"id": "1803.08978", "submitter": "Bokai Cao", "authors": "Bokai Cao", "title": "Broad Learning for Healthcare", "comments": "PhD Thesis, University of Illinois at Chicago, March 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad spectrum of data from different modalities are generated in the\nhealthcare domain every day, including scalar data (e.g., clinical measures\ncollected at hospitals), tensor data (e.g., neuroimages analyzed by research\ninstitutes), graph data (e.g., brain connectivity networks), and sequence data\n(e.g., digital footprints recorded on smart sensors). Capability for modeling\ninformation from these heterogeneous data sources is potentially transformative\nfor investigating disease mechanisms and for informing therapeutic\ninterventions.\n  Our works in this thesis attempt to facilitate healthcare applications in the\nsetting of broad learning which focuses on fusing heterogeneous data sources\nfor a variety of synergistic knowledge discovery and machine learning tasks. We\nare generally interested in computer-aided diagnosis, precision medicine, and\nmobile health by creating accurate user profiles which include important\nbiomarkers, brain connectivity patterns, and latent representations. In\nparticular, our works involve four different data mining problems with\napplication to the healthcare domain: multi-view feature selection, subgraph\npattern mining, brain network embedding, and multi-view sequence prediction.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:01:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Cao", "Bokai", ""]]}, {"id": "1803.08979", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From Shannon's Channel to Semantic Channel via New Bayes' Formulas for\n  Machine Learning", "comments": "17 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A group of transition probability functions form a Shannon's channel whereas\na group of truth functions form a semantic channel. By the third kind of Bayes'\ntheorem, we can directly convert a Shannon's channel into an optimized semantic\nchannel. When a sample is not big enough, we can use a truth function with\nparameters to produce the likelihood function, then train the truth function by\nthe conditional sampling distribution. The third kind of Bayes' theorem is\nproved. A semantic information theory is simply introduced. The semantic\ninformation measure reflects Popper's hypothesis-testing thought. The Semantic\nInformation Method (SIM) adheres to maximum semantic information criterion\nwhich is compatible with maximum likelihood criterion and Regularized Least\nSquares criterion. It supports Wittgenstein's view: the meaning of a word lies\nin its use. Letting the two channels mutually match, we obtain the Channels'\nMatching (CM) algorithm for machine learning. The CM algorithm is used to\nexplain the evolution of the semantic meaning of natural language, such as \"Old\nage\". The semantic channel for medical tests and the confirmation measures of\ntest-positive and test-negative are discussed. The applications of the CM\nalgorithm to semi-supervised learning and non-supervised learning are simply\nintroduced. As a predictive model, the semantic channel fits variable sources\nand hence can overcome class-imbalance problem. The SIM strictly distinguishes\nstatistical probability and logical probability and uses both at the same time.\nThis method is compatible with the thoughts of Bayes, Fisher, Shannon, Zadeh,\nTarski, Davidson, Wittgenstein, and Popper.It is a competitive alternative to\nBayesian inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 05:15:49 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1803.08993", "submitter": "Joseph Gomes", "authors": "Amir Barati Farimani, Joseph Gomes, Rishi Sharma, Franklin L. Lee,\n  Vijay S. Pande", "title": "Deep Learning Phase Segregation", "comments": "arXiv admin note: text overlap with arXiv:1709.02432", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase segregation, the process by which the components of a binary mixture\nspontaneously separate, is a key process in the evolution and design of many\nchemical, mechanical, and biological systems. In this work, we present a\ndata-driven approach for the learning, modeling, and prediction of phase\nsegregation. A direct mapping between an initially dispersed, immiscible binary\nfluid and the equilibrium concentration field is learned by conditional\ngenerative convolutional neural networks. Concentration field predictions by\nthe deep learning model conserve phase fraction, correctly predict phase\ntransition, and reproduce area, perimeter, and total free energy distributions\nup to 98% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:59:01 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Farimani", "Amir Barati", ""], ["Gomes", "Joseph", ""], ["Sharma", "Rishi", ""], ["Lee", "Franklin L.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.08996", "submitter": "David Friedlander", "authors": "David Friedlander", "title": "Pattern Analysis with Layered Self-Organizing Maps", "comments": "16 pages, 21 color figures, DRAFT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a new learning architecture, Layered Self-Organizing Maps\n(LSOMs), that uses the SOM and supervised-SOM learning algorithms. The\narchitecture is validated with the MNIST database of hand-written digit images.\nLSOMs are similar to convolutional neural nets (covnets) in the way they sample\ndata, but different in the way they represent features and learn. LSOMs analyze\n(or generate) image patches with maps of exemplars determined by the SOM\nlearning algorithm rather than feature maps from filter-banks learned via\nbackprop.\n  LSOMs provide an alternative to features derived from covnets. Multi-layer\nLSOMs are trained bottom-up, without the use of backprop and therefore may be\nof interest as a model of the visual cortex. The results show organization at\nmultiple levels. The algorithm appears to be resource efficient in learning,\nclassifying and generating images. Although LSOMs can be used for\nclassification, their validation accuracy for these exploratory runs was well\nbelow the state of the art. The goal of this article is to define the\narchitecture and display the structures resulting from its application to the\nMNIST images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:07:52 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 17:07:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Friedlander", "David", ""]]}, {"id": "1803.09001", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Marlos C. Machado, Patrick M. Pilarski", "title": "Accelerating Learning in Constructive Predictive Frameworks with the\n  Successor Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we propose using the successor representation (SR) to accelerate\nlearning in a constructive knowledge system based on general value functions\n(GVFs). In real-world settings like robotics for unstructured and dynamic\nenvironments, it is infeasible to model all meaningful aspects of a system and\nits environment by hand due to both complexity and size. Instead, robots must\nbe capable of learning and adapting to changes in their environment and task,\nincrementally constructing models from their own experience. GVFs, taken from\nthe field of reinforcement learning (RL), are a way of modeling the world as\npredictive questions. One approach to such models proposes a massive network of\ninterconnected and interdependent GVFs, which are incrementally added over\ntime. It is reasonable to expect that new, incrementally added predictions can\nbe learned more swiftly if the learning process leverages knowledge gained from\npast experience. The SR provides such a means of separating the dynamics of the\nworld from the prediction targets and thus capturing regularities that can be\nreused across multiple GVFs. As a primary contribution of this work, we show\nthat using SR-based predictions can improve sample efficiency and learning\nspeed in a continual learning setting where new predictions are incrementally\nadded and learned over time. We analyze our approach in a grid-world and then\ndemonstrate its potential on data from a physical robot arm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:40:22 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sherstan", "Craig", ""], ["Machado", "Marlos C.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1803.09010", "submitter": "Hanna Wallach", "authors": "Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman\n  Vaughan, Hanna Wallach, Hal Daum\\'e III, and Kate Crawford", "title": "Datasheets for Datasets", "comments": "Working Paper, comments are encouraged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community currently has no standardized process for\ndocumenting datasets, which can lead to severe consequences in high-stakes\ndomains. To address this gap, we propose datasheets for datasets. In the\nelectronics industry, every component, no matter how simple or complex, is\naccompanied with a datasheet that describes its operating characteristics, test\nresults, recommended uses, and other information. By analogy, we propose that\nevery dataset be accompanied with a datasheet that documents its motivation,\ncomposition, collection process, recommended uses, and so on. Datasheets for\ndatasets will facilitate better communication between dataset creators and\ndataset consumers, and encourage the machine learning community to prioritize\ntransparency and accountability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 23:22:18 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 03:22:43 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 18:26:32 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2019 22:03:18 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2020 00:59:24 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2020 01:36:33 GMT"}, {"version": "v7", "created": "Thu, 19 Mar 2020 17:26:37 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Gebru", "Timnit", ""], ["Morgenstern", "Jamie", ""], ["Vecchione", "Briana", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""], ["Daum\u00e9", "Hal", "III"], ["Crawford", "Kate", ""]]}, {"id": "1803.09017", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, Daisy Stanton, Yu Zhang, RJ Skerry-Ryan, Eric Battenberg,\n  Joel Shor, Ying Xiao, Fei Ren, Ye Jia, Rif A. Saurous", "title": "Style Tokens: Unsupervised Style Modeling, Control and Transfer in\n  End-to-End Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings\nthat are jointly trained within Tacotron, a state-of-the-art end-to-end speech\nsynthesis system. The embeddings are trained with no explicit labels, yet learn\nto model a large range of acoustic expressiveness. GSTs lead to a rich set of\nsignificant results. The soft interpretable \"labels\" they generate can be used\nto control synthesis in novel ways, such as varying speed and speaking style -\nindependently of the text content. They can also be used for style transfer,\nreplicating the speaking style of a single audio clip across an entire\nlong-form text corpus. When trained on noisy, unlabeled found data, GSTs learn\nto factorize noise and speaker identity, providing a path towards highly\nscalable but robust speech synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 23:56:49 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wang", "Yuxuan", ""], ["Stanton", "Daisy", ""], ["Zhang", "Yu", ""], ["Skerry-Ryan", "RJ", ""], ["Battenberg", "Eric", ""], ["Shor", "Joel", ""], ["Xiao", "Ying", ""], ["Ren", "Fei", ""], ["Jia", "Ye", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1803.09018", "submitter": "Abraham Nunes", "authors": "Abraham Nunes and Alexander Rudiuk", "title": "The Importance of Constraint Smoothness for Parameter Estimation in\n  Computational Cognitive Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychiatric neuroscience is increasingly aware of the need to define\npsychopathology in terms of abnormal neural computation. The central tool in\nthis endeavour is the fitting of computational models to behavioural data. The\nmost prominent example of this procedure is fitting reinforcement learning (RL)\nmodels to decision-making data collected from mentally ill and healthy subject\npopulations. These models are generative models of the decision-making data\nthemselves, and the parameters we seek to infer can be psychologically and\nneurobiologically meaningful. Currently, the gold standard approach to this\ninference procedure involves Monte-Carlo sampling, which is robust but\ncomputationally intensive---rendering additional procedures, such as\ncross-validation, impractical. Searching for point estimates of model\nparameters using optimization procedures remains a popular and interesting\noption. On a novel testbed simulating parameter estimation from a common RL\ntask, we investigated the effects of smooth vs. boundary constraints on\nparameter estimation using interior point and deterministic direct search\nalgorithms for optimization. Ultimately, we show that the use of boundary\nconstraints can lead to substantial truncation effects. Our results discourage\nthe use of boundary constraints for these applications.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 00:25:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Nunes", "Abraham", ""], ["Rudiuk", "Alexander", ""]]}, {"id": "1803.09047", "submitter": "R J Skerry-Ryan", "authors": "RJ Skerry-Ryan, Eric Battenberg, Ying Xiao, Yuxuan Wang, Daisy\n  Stanton, Joel Shor, Ron J. Weiss, Rob Clark, Rif A. Saurous", "title": "Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with\n  Tacotron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension to the Tacotron speech synthesis architecture that\nlearns a latent embedding space of prosody, derived from a reference acoustic\nrepresentation containing the desired prosody. We show that conditioning\nTacotron on this learned embedding space results in synthesized audio that\nmatches the prosody of the reference signal with fine time detail even when the\nreference and synthesis speakers are different. Additionally, we show that a\nreference prosody embedding can be used to synthesize text that is different\nfrom that of the reference utterance. We define several quantitative and\nsubjective metrics for evaluating prosody transfer, and report results with\naccompanying audio samples from single-speaker and 44-speaker Tacotron models\non a prosody transfer task.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 02:52:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Skerry-Ryan", "RJ", ""], ["Battenberg", "Eric", ""], ["Xiao", "Ying", ""], ["Wang", "Yuxuan", ""], ["Stanton", "Daisy", ""], ["Shor", "Joel", ""], ["Weiss", "Ron J.", ""], ["Clark", "Rob", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1803.09050", "submitter": "Mengye Ren", "authors": "Mengye Ren, Wenyuan Zeng, Bin Yang, Raquel Urtasun", "title": "Learning to Reweight Examples for Robust Deep Learning", "comments": "13 pages; Published at ICML 2018; Code released at:\n  https://github.com/uber-research/learning-to-reweight-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be very powerful modeling tools for\nmany supervised learning tasks involving complex input patterns. However, they\ncan also easily overfit to training set biases and label noises. In addition to\nvarious regularizers, example reweighting algorithms are popular solutions to\nthese problems, but they require careful tuning of additional hyperparameters,\nsuch as example mining schedules and regularization hyperparameters. In\ncontrast to past reweighting methods, which typically consist of functions of\nthe cost value of each example, in this work we propose a novel meta-learning\nalgorithm that learns to assign weights to training examples based on their\ngradient directions. To determine the example weights, our method performs a\nmeta gradient descent step on the current mini-batch example weights (which are\ninitialized from zero) to minimize the loss on a clean unbiased validation set.\nOur proposed method can be easily implemented on any type of deep network, does\nnot require any additional hyperparameter tuning, and achieves impressive\nperformance on class imbalance and corrupted label problems where only a small\namount of clean validation data is available.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 03:41:59 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 15:29:31 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 15:21:40 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Ren", "Mengye", ""], ["Zeng", "Wenyuan", ""], ["Yang", "Bin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1803.09080", "submitter": "Lei Sang", "authors": "Lei Sang and Min Xu and Shengsheng Qian and Xindong Wu", "title": "AAANE: Attention-based Adversarial Autoencoder for Multi-scale Network\n  Embedding", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding represents nodes in a continuous vector space and preserves\nstructure information from the Network. Existing methods usually adopt a\n\"one-size-fits-all\" approach when concerning multi-scale structure information,\nsuch as first- and second-order proximity of nodes, ignoring the fact that\ndifferent scales play different roles in the embedding learning. In this paper,\nwe propose an Attention-based Adversarial Autoencoder Network Embedding(AAANE)\nframework, which promotes the collaboration of different scales and lets them\nvote for robust representations. The proposed AAANE consists of two components:\n1) Attention-based autoencoder effectively capture the highly non-linear\nnetwork structure, which can de-emphasize irrelevant scales during training. 2)\nAn adversarial regularization guides the autoencoder learn robust\nrepresentations by matching the posterior distribution of the latent embeddings\nto given prior distribution. This is the first attempt to introduce attention\nmechanisms to multi-scale network embedding. Experimental results on real-world\nnetworks show that our learned attention parameters are different for every\nnetwork and the proposed approach outperforms existing state-of-the-art\napproaches for network embedding.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 09:15:05 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sang", "Lei", ""], ["Xu", "Min", ""], ["Qian", "Shengsheng", ""], ["Wu", "Xindong", ""]]}, {"id": "1803.09082", "submitter": "Tim Tsz-Kit Lau", "authors": "Tim Tsz-Kit Lau, Jinshan Zeng, Baoyuan Wu, Yuan Yao", "title": "A Proximal Block Coordinate Descent Algorithm for Deep Neural Network\n  Training", "comments": "The 6th International Conference on Learning Representations (ICLR\n  2018), Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks (DNNs) efficiently is a challenge due to the\nassociated highly nonconvex optimization. The backpropagation (backprop)\nalgorithm has long been the most widely used algorithm for gradient computation\nof parameters of DNNs and is used along with gradient descent-type algorithms\nfor this optimization task. Recent work have shown the efficiency of block\ncoordinate descent (BCD) type methods empirically for training DNNs. In view of\nthis, we propose a novel algorithm based on the BCD method for training DNNs\nand provide its global convergence results built upon the powerful framework of\nthe Kurdyka-Lojasiewicz (KL) property. Numerical experiments on standard\ndatasets demonstrate its competitive efficiency against standard optimizers\nwith backprop.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 09:17:27 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lau", "Tim Tsz-Kit", ""], ["Zeng", "Jinshan", ""], ["Wu", "Baoyuan", ""], ["Yao", "Yuan", ""]]}, {"id": "1803.09093", "submitter": "Mathijs Pieters", "authors": "Mathijs Pieters and Marco Wiering", "title": "Comparing Generative Adversarial Network Techniques for Image Creation\n  and Modification", "comments": "20 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have demonstrated to be successful at\ngenerating realistic real-world images. In this paper we compare various GAN\ntechniques, both supervised and unsupervised. The effects on training stability\nof different objective functions are compared. We add an encoder to the\nnetwork, making it possible to encode images to the latent space of the GAN.\nThe generator, discriminator and encoder are parameterized by deep\nconvolutional neural networks. For the discriminator network we experimented\nwith using the novel Capsule Network, a state-of-the-art technique for\ndetecting global features in images. Experiments are performed using a digit\nand face dataset, with various visualizations illustrating the results. The\nresults show that using the encoder network it is possible to reconstruct\nimages. With the conditional GAN we can alter visual attributes of generated or\nencoded images. The experiments with the Capsule Network as discriminator\nresult in generated images of a lower quality, compared to a standard\nconvolutional neural network.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 11:19:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Pieters", "Mathijs", ""], ["Wiering", "Marco", ""]]}, {"id": "1803.09111", "submitter": "Yuhan Liu", "authors": "Yuhan Liu, Xiao Zhang, Maciej Lewenstein, and Shi-Ju Ran", "title": "Entanglement-guided architectures of machine learning by quantum tensor\n  network", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a fundamental, but still elusive question whether the schemes based on\nquantum mechanics, in particular on quantum entanglement, can be used for\nclassical information processing and machine learning. Even partial answer to\nthis question would bring important insights to both fields of machine learning\nand quantum mechanics. In this work, we implement simple numerical experiments,\nrelated to pattern/images classification, in which we represent the classifiers\nby many-qubit quantum states written in the matrix product states (MPS).\nClassical machine learning algorithm is applied to these quantum states to\nlearn the classical data. We explicitly show how quantum entanglement (i.e.,\nsingle-site and bipartite entanglement) can emerge in such represented images.\nEntanglement characterizes here the importance of data, and such information\nare practically used to guide the architecture of MPS, and improve the\nefficiency. The number of needed qubits can be reduced to less than 1/10 of the\noriginal number, which is within the access of the state-of-the-art quantum\ncomputers. We expect such numerical experiments could open new paths in\ncharactering classical machine learning algorithms, and at the same time shed\nlights on the generic quantum simulations/computations of machine learning\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 13:48:33 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 14:07:34 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 01:29:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Liu", "Yuhan", ""], ["Zhang", "Xiao", ""], ["Lewenstein", "Maciej", ""], ["Ran", "Shi-Ju", ""]]}, {"id": "1803.09119", "submitter": "Stefan Zohren", "authors": "Mariano Chouza, Stephen Roberts, Stefan Zohren", "title": "Gradient descent in Gaussian random fields as a toy model for\n  high-dimensional optimisation in deep learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we model the loss function of high-dimensional optimization\nproblems by a Gaussian random field, or equivalently a Gaussian process. Our\naim is to study gradient descent in such loss functions or energy landscapes\nand compare it to results obtained from real high-dimensional optimization\nproblems such as encountered in deep learning. In particular, we analyze the\ndistribution of the improved loss function after a step of gradient descent,\nprovide analytic expressions for the moments as well as prove asymptotic\nnormality as the dimension of the parameter space becomes large. Moreover, we\ncompare this with the expectation of the global minimum of the landscape\nobtained by means of the Euler characteristic of excursion sets. Besides\ncomplementing our analytical findings with numerical results from simulated\nGaussian random fields, we also compare it to loss functions obtained from\noptimisation problems on synthetic and real data sets by proposing a \"black\nbox\" random field toy-model for a deep neural network loss function.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 14:22:36 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Chouza", "Mariano", ""], ["Roberts", "Stephen", ""], ["Zohren", "Stefan", ""]]}, {"id": "1803.09123", "submitter": "Kriste Krstovski", "authors": "Kriste Krstovski and David M. Blei", "title": "Equation Embeddings", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised approach for discovering semantic representations\nof mathematical equations. Equations are challenging to analyze because each is\nunique, or nearly unique. Our method, which we call equation embeddings, finds\ngood representations of equations by using the representations of their\nsurrounding words. We used equation embeddings to analyze four collections of\nscientific articles from the arXiv, covering four computer science domains\n(NLP, IR, AI, and ML) and $\\sim$98.5k equations. Quantitatively, we found that\nequation embeddings provide better models when compared to existing word\nembedding approaches. Qualitatively, we found that equation embeddings provide\ncoherent semantic representations of equations and can capture semantic\nsimilarity to other equations and to words.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 15:04:17 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Krstovski", "Kriste", ""], ["Blei", "David M.", ""]]}, {"id": "1803.09138", "submitter": "Veronika Rockova", "authors": "Nicholas Polson and Veronika Rockova", "title": "Posterior Concentration for Sparse Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-and-Slab Deep Learning (SS-DL) is a fully Bayesian alternative to\nDropout for improving generalizability of deep ReLU networks. This new type of\nregularization enables provable recovery of smooth input-output maps with\nunknown levels of smoothness. Indeed, we show that the posterior distribution\nconcentrates at the near minimax rate for $\\alpha$-H\\\"older smooth maps,\nperforming as well as if we knew the smoothness level $\\alpha$ ahead of time.\nOur result sheds light on architecture design for deep neural networks, namely\nthe choice of depth, width and sparsity level. These network attributes\ntypically depend on unknown smoothness in order to be optimal. We obviate this\nconstraint with the fully Bayes construction. As an aside, we show that SS-DL\ndoes not overfit in the sense that the posterior concentrates on smaller\nnetworks with fewer (up to the optimal number of) nodes and links. Our results\nprovide new theoretical justifications for deep ReLU networks from a Bayesian\npoint of view.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 17:51:15 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Polson", "Nicholas", ""], ["Rockova", "Veronika", ""]]}, {"id": "1803.09151", "submitter": "Stefanos Eleftheriadis PhD", "authors": "Hugh Salimbeni, Stefanos Eleftheriadis, James Hensman", "title": "Natural Gradients in Practice: Non-Conjugate Variational Inference in\n  Gaussian Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural gradient method has been used effectively in conjugate Gaussian\nprocess models, but the non-conjugate case has been largely unexplored. We\nexamine how natural gradients can be used in non-conjugate stochastic settings,\ntogether with hyperparameter learning. We conclude that the natural gradient\ncan significantly improve performance in terms of wall-clock time. For\nill-conditioned posteriors the benefit of the natural gradient method is\nespecially pronounced, and we demonstrate a practical setting where ordinary\ngradients are unusable. We show how natural gradients can be computed\nefficiently and automatically in any parameterization, using automatic\ndifferentiation. Our code is integrated into the GPflow package.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 19:11:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Salimbeni", "Hugh", ""], ["Eleftheriadis", "Stefanos", ""], ["Hensman", "James", ""]]}, {"id": "1803.09153", "submitter": "Niko Br\\\"ummer", "authors": "Anna Silnova and Niko Brummer and Daniel Garcia-Romero and David\n  Snyder and Lukas Burget", "title": "Fast variational Bayes for heavy-tailed PLDA applied to i-vectors and\n  x-vectors", "comments": "Submittted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard state-of-the-art backend for text-independent speaker\nrecognizers that use i-vectors or x-vectors, is Gaussian PLDA (G-PLDA),\nassisted by a Gaussianization step involving length normalization. G-PLDA can\nbe trained with both generative or discriminative methods. It has long been\nknown that heavy-tailed PLDA (HT-PLDA), applied without length normalization,\ngives similar accuracy, but at considerable extra computational cost. We have\nrecently introduced a fast scoring algorithm for a discriminatively trained\nHT-PLDA backend. This paper extends that work by introducing a fast,\nvariational Bayes, generative training algorithm. We compare old and new\nbackends, with and without length-normalization, with i-vectors and x-vectors,\non SRE'10, SRE'16 and SITW.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 19:19:32 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Silnova", "Anna", ""], ["Brummer", "Niko", ""], ["Garcia-Romero", "Daniel", ""], ["Snyder", "David", ""], ["Burget", "Lukas", ""]]}, {"id": "1803.09160", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic", "title": "Handling Adversarial Concept Drift in Streaming Data", "comments": "Journal paper", "journal-ref": "Expert Systems with Applications 97 (2018): 18-40", "doi": "10.1016/j.eswa.2017.12.022", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers operating in a dynamic, real world environment, are vulnerable to\nadversarial activity, which causes the data distribution to change over time.\nThese changes are traditionally referred to as concept drift, and several\napproaches have been developed in literature to deal with the problem of drift\nhandling and detection. However, most concept drift handling techniques,\napproach it as a domain independent task, to make them applicable to a wide\ngamut of reactive systems. These techniques were developed from an adversarial\nagnostic perspective, where they are naive and assume that drift is a benign\nchange, which can be fixed by updating the model. However, this is not the case\nwhen an active adversary is trying to evade the deployed classification system.\nIn such an environment, the properties of concept drift are unique, as the\ndrift is intended to degrade the system and at the same time designed to avoid\ndetection by traditional concept drift detection techniques. This special\ncategory of drift is termed as adversarial drift, and this paper analyzes its\ncharacteristics and impact, in a streaming environment. A novel framework for\ndealing with adversarial concept drift is proposed, called the Predict-Detect\nstreaming framework. Experimental evaluation of the framework, on generated\nadversarial drifting data streams, demonstrates that this framework is able to\nprovide reliable unsupervised indication of drift, and is able to recover from\ndrifts swiftly. While traditional partially labeled concept drift detection\nmethodologies fail to detect adversarial drifts, the proposed framework is able\nto detect such drifts and operates with <6% labeled data, on average. Also, the\nframework provides benefits for active learning over imbalanced data streams,\nby innately providing for feature space honeypots, where minority class\nadversarial samples may be captured.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 20:30:50 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1803.09162", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic, Lingyu Lyua, Jiashun Chen", "title": "A Dynamic-Adversarial Mining Approach to the Security of Machine\n  Learning", "comments": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery.\n  2018", "journal-ref": null, "doi": "10.1002/widm.1245", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating in a dynamic real world environment requires a forward thinking and\nadversarial aware design for classifiers, beyond fitting the model to the\ntraining data. In such scenarios, it is necessary to make classifiers - a)\nharder to evade, b) easier to detect changes in the data distribution over\ntime, and c) be able to retrain and recover from model degradation. While most\nworks in the security of machine learning has concentrated on the evasion\nresistance (a) problem, there is little work in the areas of reacting to\nattacks (b and c). Additionally, while streaming data research concentrates on\nthe ability to react to changes to the data distribution, they often take an\nadversarial agnostic view of the security problem. This makes them vulnerable\nto adversarial activity, which is aimed towards evading the concept drift\ndetection mechanism itself. In this paper, we analyze the security of machine\nlearning, from a dynamic and adversarial aware perspective. The existing\ntechniques of Restrictive one class classifier models, Complex learning models\nand Randomization based ensembles, are shown to be myopic as they approach\nsecurity as a static task. These methodologies are ill suited for a dynamic\nenvironment, as they leak excessive information to an adversary, who can\nsubsequently launch attacks which are indistinguishable from the benign data.\nBased on empirical vulnerability analysis against a sophisticated adversary, a\nnovel feature importance hiding approach for classifier design, is proposed.\nThe proposed design ensures that future attacks on classifiers can be detected\nand recovered from. The proposed work presents motivation, by serving as a\nblueprint, for future work in the area of Dynamic-Adversarial mining, which\ncombines lessons learned from Streaming data mining, Adversarial learning and\nCybersecurity.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 20:55:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""], ["Lyua", "Lingyu", ""], ["Chen", "Jiashun", ""]]}, {"id": "1803.09163", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic, Joung Woo Ryu", "title": "Security Theater: On the Vulnerability of Classifiers to Exploratory\n  Attacks", "comments": "Pacific-Asia Workshop on Intelligence and Security Informatics.\n  Springer, Cham, 2017", "journal-ref": null, "doi": "10.1007/978-3-319-57463-9_4", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing scale and sophistication of cyberattacks has led to the\nadoption of machine learning based classification techniques, at the core of\ncybersecurity systems. These techniques promise scale and accuracy, which\ntraditional rule or signature based methods cannot. However, classifiers\noperating in adversarial domains are vulnerable to evasion attacks by an\nadversary, who is capable of learning the behavior of the system by employing\nintelligently crafted probes. Classification accuracy in such domains provides\na false sense of security, as detection can easily be evaded by carefully\nperturbing the input samples. In this paper, a generic data driven framework is\npresented, to analyze the vulnerability of classification systems to black box\nprobing based attacks. The framework uses an exploration exploitation based\nstrategy, to understand an adversary's point of view of the attack defense\ncycle. The adversary assumes a black box model of the defender's classifier and\ncan launch indiscriminate attacks on it, without information of the defender's\nmodel type, training data or the domain of application. Experimental evaluation\non 10 real world datasets demonstrates that even models having high perceived\naccuracy (>90%), by a defender, can be effectively circumvented with a high\nevasion rate (>95%, on average). The detailed attack algorithms, adversarial\nmodel and empirical evaluation, serve.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 21:10:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""], ["Ryu", "Joung Woo", ""]]}, {"id": "1803.09177", "submitter": "Kahkashan Afrin", "authors": "Kahkashan Afrin, Gurudev Illangovan, Sanjay S. Srivatsa, and Satish T.\n  S. Bukkapatnam", "title": "Balanced Random Survival Forests for Extremely Unbalanced, Right\n  Censored Data", "comments": "27 pages, 10 figures, to be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracies of survival models for life expectancy prediction as well as\ncritical-care applications are significantly compromised due to the sparsity of\nsamples and extreme imbalance between the survival (usually, the majority) and\nmortality class sizes. While a recent random survival forest (RSF) model\novercomes the limitations of the proportional hazard assumption, an imbalance\nin the data results in an underestimation (overestimation) of the hazard of the\nmortality (survival) classes. A balanced random survival forests (BRSF) model,\nbased on training the RSF model with data generated from a synthetic minority\nsampling scheme is presented to address this gap. Theoretical results on the\neffect of balancing on prediction accuracies in BRSF are reported. Benchmarking\nstudies were conducted using five datasets with different levels of class\nimbalance from public repositories and an imbalanced dataset of 267 acute\ncardiac patients, collected at the Heart, Artery, and Vein Center of Fresno,\nCA. Investigations suggest that BRSF provides an improved discriminatory\nstrength between the survival and the mortality classes. It outperformed both\noptimized Cox (without and with balancing) and RSF with an average reduction of\n55\\% in the prediction error over the next best alternative.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 22:58:41 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 19:57:58 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Afrin", "Kahkashan", ""], ["Illangovan", "Gurudev", ""], ["Srivatsa", "Sanjay S.", ""], ["Bukkapatnam", "Satish T. S.", ""]]}, {"id": "1803.09180", "submitter": "Sicheng Zhao Dr.", "authors": "Sicheng Zhao, Bichen Wu, Joseph Gonzalez, Sanjit A. Seshia, Kurt\n  Keutzer", "title": "Unsupervised Domain Adaptation: from Simulation Engine to the RealWorld", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale labeled training datasets have enabled deep neural networks to\nexcel on a wide range of benchmark vision tasks. However, in many applications\nit is prohibitively expensive or time-consuming to obtain large quantities of\nlabeled data. To cope with limited labeled training data, many have attempted\nto directly apply models trained on a large-scale labeled source domain to\nanother sparsely labeled target domain. Unfortunately, direct transfer across\ndomains often performs poorly due to domain shift and dataset bias. Domain\nadaptation is the machine learning paradigm that aims to learn a model from a\nsource domain that can perform well on a different (but related) target domain.\nIn this paper, we summarize and compare the latest unsupervised domain\nadaptation methods in computer vision applications. We classify the non-deep\napproaches into sample re-weighting and intermediate subspace transformation\ncategories, while the deep strategy includes discrepancy-based methods,\nadversarial generative models, adversarial discriminative models and\nreconstruction-based methods. We also discuss some potential directions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 23:34:06 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhao", "Sicheng", ""], ["Wu", "Bichen", ""], ["Gonzalez", "Joseph", ""], ["Seshia", "Sanjit A.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1803.09186", "submitter": "Ross Boczar", "authors": "Ross Boczar and Nikolai Matni and Benjamin Recht", "title": "Finite-Data Performance Guarantees for the Output-Feedback Control of an\n  Unknown System", "comments": "Changed margins", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the systems we control become more complex, first-principle modeling\nbecomes either impossible or intractable, motivating the use of machine\nlearning techniques for the control of systems with continuous action spaces.\nAs impressive as the empirical success of these methods have been, strong\ntheoretical guarantees of performance, safety, or robustness are few and far\nbetween. This paper takes a step towards such providing such guarantees by\nestablishing finite-data performance guarantees for the robust output-feedback\ncontrol of an unknown FIR SISO system. In particular, we introduce the\n\"Coarse-ID control\" pipeline, which is composed of a system identification step\nfollowed by a robust controller synthesis procedure, and analyze its end-to-end\nperformance, providing quantitative bounds on the performance degradation\nsuffered due to model uncertainty as a function of the number of experiments\nrun to identify the system. We conclude with numerical examples demonstrating\nthe effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 01:17:30 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 23:53:52 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Boczar", "Ross", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""]]}, {"id": "1803.09211", "submitter": "Sumit Bhatia", "authors": "Vinith Misra and Sumit Bhatia", "title": "Bernoulli Embeddings for Graphs", "comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 07:19:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Misra", "Vinith", ""], ["Bhatia", "Sumit", ""]]}, {"id": "1803.09237", "submitter": "Amos Azaria", "authors": "Avigail Stekel, Merav Chkroun and Amos Azaria", "title": "Goldbach's Function Approximation Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goldbach conjecture is one of the most famous open mathematical problems. It\nstates that every even number, bigger than two, can be presented as a sum of 2\nprime numbers. % In this work we present a deep learning based model that\npredicts the number of Goldbach partitions for a given even number.\nSurprisingly, our model outperforms all state-of-the-art analytically derived\nestimations for the number of couples, while not requiring prime factorization\nof the given number. We believe that building a model that can accurately\npredict the number of couples brings us one step closer to solving one of the\nworld most famous open problems. To the best of our knowledge, this is the\nfirst attempt to consider machine learning based data-driven methods to\napproximate open mathematical problems in the field of number theory, and hope\nthat this work will encourage such attempts.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 12:09:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Stekel", "Avigail", ""], ["Chkroun", "Merav", ""], ["Azaria", "Amos", ""]]}, {"id": "1803.09285", "submitter": "Hazem Torfah", "authors": "Bernd Finkbeiner and Hazem Torfah", "title": "Synthesizing Skeletons for Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis technique for temporal specifications of reactive\nsystems that identifies, on the level of individual system outputs over time,\nwhich parts of the implementation are determined by the specification, and\nwhich parts are still open. This information is represented in the form of a\nlabeled transition system, which we call skeleton. Each state of the skeleton\nis labeled with a three-valued assignment to the output variables: each output\ncan be true, false, or open, where true or false means that the value must be\ntrue or false, respectively, and open means that either value is still\npossible. We present algorithms for the verification of skeletons and for the\nlearning-based synthesis of skeletons from specifications in linear-time\ntemporal logic (LTL). The algorithm returns a skeleton that satisfies the given\nLTL specification in time polynomial in the size of the minimal skeleton. Our\nnew analysis technique can be used to recognize and repair specifications that\nunderspecify critical situations. The technique thus complements existing\nmethods for the recognition and repair of overspecifications via the\nidentification of unrealizable cores.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 16:02:28 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Torfah", "Hazem", ""]]}, {"id": "1803.09319", "submitter": "Soledad Villar", "authors": "Dustin G. Mixon, Soledad Villar", "title": "SUNLayer: Stable denoising with generative networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been experimentally established that deep neural networks can be used\nto produce good generative models for real world data. It has also been\nestablished that such generative models can be exploited to solve classical\ninverse problems like compressed sensing and super resolution. In this work we\nfocus on the classical signal processing problem of image denoising. We propose\na theoretical setting that uses spherical harmonics to identify what\nmathematical properties of the activation functions will allow signal denoising\nwith local methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 19:33:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Villar", "Soledad", ""]]}, {"id": "1803.09327", "submitter": "Jiong Zhang", "authors": "Jiong Zhang, Qi Lei, Inderjit S. Dhillon", "title": "Stabilizing Gradients for Deep Neural Networks via Efficient SVD\n  Parameterization", "comments": "main text 13 pages, 22 pages including reference and appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanishing and exploding gradients are two of the main obstacles in training\ndeep neural networks, especially in capturing long range dependencies in\nrecurrent neural networks~(RNNs). In this paper, we present an efficient\nparametrization of the transition matrix of an RNN that allows us to stabilize\nthe gradients that arise in its training. Specifically, we parameterize the\ntransition matrix by its singular value decomposition(SVD), which allows us to\nexplicitly track and control its singular values. We attain efficiency by using\ntools that are common in numerical linear algebra, namely Householder\nreflectors for representing the orthogonal matrices that arise in the SVD. By\nexplicitly controlling the singular values, our proposed Spectral-RNN method\nallows us to easily solve the exploding gradient problem and we observe that it\nempirically solves the vanishing gradient issue to a large extent. We note that\nthe SVD parameterization can be used for any rectangular weight matrix, hence\nit can be easily extended to any deep neural network, such as a multi-layer\nperceptron. Theoretically, we demonstrate that our parameterization does not\nlose any expressive power, and show how it controls generalization of RNN for\nthe classification task. %, and show how it potentially makes the optimization\nprocess easier. Our extensive experimental results also demonstrate that the\nproposed framework converges faster, and has good generalization, especially in\ncapturing long range dependencies, as shown on the synthetic addition and copy\ntasks, as well as on MNIST and Penn Tree Bank data sets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 20:12:18 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Jiong", ""], ["Lei", "Qi", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1803.09349", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, Karthik\n  Sridharan", "title": "Logistic Regression: The Importance of Being Improper", "comments": "Appeared at COLT 2018. V2 changes: Updated to match conference\n  version, added discussion of Bayesian model averaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning linear predictors with the logistic loss---both in stochastic and\nonline settings---is a fundamental task in machine learning and statistics,\nwith direct connections to classification and boosting. Existing \"fast rates\"\nfor this setting exhibit exponential dependence on the predictor norm, and\nHazan et al. (2014) showed that this is unfortunately unimprovable. Starting\nwith the simple observation that the logistic loss is $1$-mixable, we design a\nnew efficient improper learning algorithm for online logistic regression that\ncircumvents the aforementioned lower bound with a regret bound exhibiting a\ndoubly-exponential improvement in dependence on the predictor norm. This\nprovides a positive resolution to a variant of the COLT 2012 open problem of\nMcMahan and Streeter (2012) when improper learning is allowed. This improvement\nis obtained both in the online setting and, with some extra work, in the batch\nstatistical setting with high probability. We also show that the improved\ndependence on predictor norm is near-optimal.\n  Leveraging this improved dependency on the predictor norm yields the\nfollowing applications: (a) we give algorithms for online bandit multiclass\nlearning with the logistic loss with an $\\tilde{O}(\\sqrt{n})$ relative mistake\nbound across essentially all parameter ranges, thus providing a solution to the\nCOLT 2009 open problem of Abernethy and Rakhlin (2009), and (b) we give an\nadaptive algorithm for online multiclass boosting with optimal sample\ncomplexity, thus partially resolving an open problem of Beygelzimer et al.\n(2015) and Jung et al. (2017). Finally, we give information-theoretic bounds on\nthe optimal rates for improper logistic regression with general function\nclasses, thereby characterizing the extent to which our improvement for linear\nclasses extends to other parametric and even nonparametric settings.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 21:37:08 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 03:07:19 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Foster", "Dylan J.", ""], ["Kale", "Satyen", ""], ["Luo", "Haipeng", ""], ["Mohri", "Mehryar", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1803.09353", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Vahab Mirrokni, Renato Paes Leme", "title": "Stochastic bandits robust to adversarial corruptions", "comments": "To appear in STOC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model of stochastic bandits with adversarial corruptions\nwhich aims to capture settings where most of the input follows a stochastic\npattern but some fraction of it can be adversarially changed to trick the\nalgorithm, e.g., click fraud, fake reviews and email spam. The goal of this\nmodel is to encourage the design of bandit algorithms that (i) work well in\nmixed adversarial and stochastic models, and (ii) whose performance\ndeteriorates gracefully as we move from fully stochastic to fully adversarial\nmodels.\n  In our model, the rewards for all arms are initially drawn from a\ndistribution and are then altered by an adaptive adversary. We provide a simple\nalgorithm whose performance gracefully degrades with the total corruption the\nadversary injected in the data, measured by the sum across rounds of the\nbiggest alteration the adversary made in the data in that round; this total\ncorruption is denoted by $C$. Our algorithm provides a guarantee that retains\nthe optimal guarantee (up to a logarithmic term) if the input is stochastic and\nwhose performance degrades linearly to the amount of corruption $C$, while\ncrucially being agnostic to it. We also provide a lower bound showing that this\nlinear degradation is necessary if the algorithm achieves optimal performance\nin the stochastic setting (the lower bound works even for a known amount of\ncorruption, a special case in which our algorithm achieves optimal performance\nwithout the extra logarithm).\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 21:48:53 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Mirrokni", "Vahab", ""], ["Leme", "Renato Paes", ""]]}, {"id": "1803.09356", "submitter": "Bart Jacobs", "authors": "Bart Jacobs and David Sprunger", "title": "Neural Nets via Forward State Transformation and Backward Loss\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies (multilayer perceptron) neural networks with an emphasis\non the transformations involved --- both forward and backward --- in order to\ndevelop a semantical/logical perspective that is in line with standard program\nsemantics. The common two-pass neural network training algorithms make this\nviewpoint particularly fitting. In the forward direction, neural networks act\nas state transformers. In the reverse direction, however, neural networks\nchange losses of outputs to losses of inputs, thereby acting like a\n(real-valued) predicate transformer. In this way, backpropagation is functorial\nby construction, as shown earlier in recent other work. We illustrate this\nperspective by training a simple instance of a neural network.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 22:01:32 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Jacobs", "Bart", ""], ["Sprunger", "David", ""]]}, {"id": "1803.09357", "submitter": "Lydia T. Liu", "authors": "Chi Jin, Lydia T. Liu, Rong Ge, Michael I. Jordan", "title": "On the Local Minima of the Empirical Risk", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population risk is always of primary interest in machine learning; however,\nlearning algorithms only have access to the empirical risk. Even for\napplications with nonconvex nonsmooth losses (such as modern deep networks),\nthe population risk is generally significantly more well-behaved from an\noptimization point of view than the empirical risk. In particular, sampling can\ncreate many spurious local minima. We consider a general framework which aims\nto optimize a smooth nonconvex function $F$ (population risk) given only access\nto an approximation $f$ (empirical risk) that is pointwise close to $F$ (i.e.,\n$\\|F-f\\|_{\\infty} \\le \\nu$). Our objective is to find the\n$\\epsilon$-approximate local minima of the underlying function $F$ while\navoiding the shallow local minima---arising because of the tolerance\n$\\nu$---which exist only in $f$. We propose a simple algorithm based on\nstochastic gradient descent (SGD) on a smoothed version of $f$ that is\nguaranteed to achieve our goal as long as $\\nu \\le O(\\epsilon^{1.5}/d)$. We\nalso provide an almost matching lower bound showing that our algorithm achieves\noptimal error tolerance $\\nu$ among all algorithms making a polynomial number\nof queries of $f$. As a concrete example, we show that our results can be\ndirectly used to give sample complexities for learning a ReLU unit.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 22:18:04 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 22:55:49 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Lydia T.", ""], ["Ge", "Rong", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1803.09374", "submitter": "Brendan Duke", "authors": "Brendan Duke and Graham W. Taylor", "title": "Generalized Hadamard-Product Fusion Operators for Visual Question\n  Answering", "comments": "8 pages, 3 figures. To appear in CRV, 2018, 15th Canadian Conference\n  on Computer and Robot Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized class of multimodal fusion operators for the task of\nvisual question answering (VQA). We identify generalizations of existing\nmultimodal fusion operators based on the Hadamard product, and show that\nspecific non-trivial instantiations of this generalized fusion operator exhibit\nsuperior performance in terms of OpenEnded accuracy on the VQA task. In\nparticular, we introduce Nonlinearity Ensembling, Feature Gating, and\npost-fusion neural network layers as fusion operator components, culminating in\nan absolute percentage point improvement of $1.1\\%$ on the VQA 2.0 test-dev set\nover baseline fusion operators, which use the same features as input. We use\nour findings as evidence that our generalized class of fusion operators could\nlead to the discovery of even superior task-specific operators when used as a\nsearch space in an architecture search over fusion operators.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 00:30:34 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 15:18:26 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Duke", "Brendan", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1803.09383", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "Online Second Order Methods for Non-Convex Stochastic Optimizations", "comments": "Supplement: Tensorflow implementation at\n  https://github.com/lixilinx/psgd_tf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a family of online second order methods for possibly\nnon-convex stochastic optimizations based on the theory of preconditioned\nstochastic gradient descent (PSGD), which can be regarded as an enhance\nstochastic Newton method with the ability to handle gradient noise and\nnon-convexity simultaneously. We have improved the implementations of the\noriginal PSGD in several ways, e.g., new forms of preconditioners, more\naccurate Hessian vector product calculations, and better numerical stability\nwith vanishing or ill-conditioned Hessian, etc.. We also have unrevealed the\nrelationship between feature normalization and PSGD with Kronecker product\npreconditioners, which explains the excellent performance of Kronecker product\npreconditioners in deep neural network learning. A software package\n(https://github.com/lixilinx/psgd_tf) implemented in Tensorflow is provided to\ncompare variations of stochastic gradient descent (SGD) and PSGD with five\ndifferent preconditioners on a wide range of benchmark problems with commonly\nused neural network architectures, e.g., convolutional and recurrent neural\nnetworks. Experimental results clearly demonstrate the advantages of PSGD in\nterms of generalization performance and convergence speed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 01:39:27 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 01:50:29 GMT"}, {"version": "v3", "created": "Sun, 29 Apr 2018 05:04:45 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "1803.09386", "submitter": "Michael Teti", "authors": "Michael Teti, William Edward Hahn, Shawn Martin, Christopher Teti, and\n  Elan Barenholtz", "title": "A Systematic Comparison of Deep Learning Architectures in an Autonomous\n  Vehicle", "comments": "16 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving technology is advancing rapidly --- albeit with significant\nchallenges and limitations. This progress is largely due to recent developments\nin deep learning algorithms. To date, however, there has been no systematic\ncomparison of how different deep learning architectures perform at such tasks,\nor an attempt to determine a correlation between classification performance and\nperformance in an actual vehicle, a potentially critical factor in developing\nself-driving systems. Here, we introduce the first controlled comparison of\nmultiple deep-learning architectures in an end-to-end autonomous driving task\nacross multiple testing conditions. We compared performance, under identical\ndriving conditions, across seven architectures including a fully-connected\nnetwork, a simple 2 layer CNN, AlexNet, VGG-16, Inception-V3, ResNet, and an\nLSTM by assessing the number of laps each model was able to successfully\ncomplete without crashing while traversing an indoor racetrack. We compared\nperformance across models when the conditions exactly matched those in training\nas well as when the local environment and track were configured differently and\nobjects that were not included in the training dataset were placed on the track\nin various positions. In addition, we considered performance using several\ndifferent data types for training and testing including single grayscale and\ncolor frames, and multiple grayscale frames stacked together in sequence. With\nthe exception of a fully-connected network, all models performed reasonably\nwell (around or above 80\\%) and most very well (~95\\%) on at least one input\ntype but with considerable variation across models and inputs. Overall,\nAlexNet, operating on single color frames as input, achieved the best level of\nperformance (100\\% success rate in phase one and 55\\% in phase two) while\nVGG-16 performed well most consistently across image types.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 01:58:07 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 00:04:29 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Teti", "Michael", ""], ["Hahn", "William Edward", ""], ["Martin", "Shawn", ""], ["Teti", "Christopher", ""], ["Barenholtz", "Elan", ""]]}, {"id": "1803.09468", "submitter": "Boussad Addad", "authors": "Boussad Addad, Jerome Kodjabachian, and Christophe Meyer", "title": "Clipping free attacks against artificial neural networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years, a remarkable breakthrough has been made in AI domain\nthanks to artificial deep neural networks that achieved a great success in many\nmachine learning tasks in computer vision, natural language processing, speech\nrecognition, malware detection and so on. However, they are highly vulnerable\nto easily crafted adversarial examples. Many investigations have pointed out\nthis fact and different approaches have been proposed to generate attacks while\nadding a limited perturbation to the original data. The most robust known\nmethod so far is the so called C&W attack [1]. Nonetheless, a countermeasure\nknown as feature squeezing coupled with ensemble defense showed that most of\nthese attacks can be destroyed [6]. In this paper, we present a new method we\ncall Centered Initial Attack (CIA) whose advantage is twofold : first, it\ninsures by construction the maximum perturbation to be smaller than a threshold\nfixed beforehand, without the clipping process that degrades the quality of\nattacks. Second, it is robust against recently introduced defenses such as\nfeature squeezing, JPEG encoding and even against a voting ensemble of\ndefenses. While its application is not limited to images, we illustrate this\nusing five of the current best classifiers on ImageNet dataset among which two\nare adversarialy retrained on purpose to be robust against attacks. With a\nfixed maximum perturbation of only 1.5% on any pixel, around 80% of attacks\n(targeted) fool the voting ensemble defense and nearly 100% when the\nperturbation is only 6%. While this shows how it is difficult to defend against\nCIA attacks, the last section of the paper gives some guidelines to limit their\nimpact.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 08:39:15 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 07:44:38 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Addad", "Boussad", ""], ["Kodjabachian", "Jerome", ""], ["Meyer", "Christophe", ""]]}, {"id": "1803.09473", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "code2vec: Learning Distributed Representations of Code", "comments": "Accepted in POPL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for representing snippets of code as continuous\ndistributed vectors (\"code embeddings\"). The main idea is to represent a code\nsnippet as a single fixed-length $\\textit{code vector}$, which can be used to\npredict semantic properties of the snippet. This is performed by decomposing\ncode to a collection of paths in its abstract syntax tree, and learning the\natomic representation of each path $\\textit{simultaneously}$ with learning how\nto aggregate a set of them. We demonstrate the effectiveness of our approach by\nusing it to predict a method's name from the vector representation of its body.\nWe evaluate our approach by training a model on a dataset of 14M methods. We\nshow that code vectors trained on this dataset can predict method names from\nfiles that were completely unobserved during training. Furthermore, we show\nthat our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies. Comparing previous techniques over\nthe same data set, our approach obtains a relative improvement of over 75%,\nbeing the first to successfully predict method names based on a large,\ncross-project, corpus. Our trained model, visualizations and vector\nsimilarities are available as an interactive online demo at\nhttp://code2vec.org. The code, data, and trained models are available at\nhttps://github.com/tech-srl/code2vec.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 09:05:30 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:57:57 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 10:00:14 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 09:38:16 GMT"}, {"version": "v5", "created": "Tue, 30 Oct 2018 09:45:07 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09518", "submitter": "Kristina Preuer", "authors": "Kristina Preuer and Philipp Renz and Thomas Unterthiner and Sepp\n  Hochreiter and G\\\"unter Klambauer", "title": "Fr\\'echet ChemNet Distance: A metric for generative models for molecules\n  in drug discovery", "comments": "Implementations are available at:\n  https://www.github.com/bioinf-jku/FCD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new wave of successful generative models in machine learning has\nincreased the interest in deep learning driven de novo drug design. However,\nassessing the performance of such generative models is notoriously difficult.\nMetrics that are typically used to assess the performance of such generative\nmodels are the percentage of chemically valid molecules or the similarity to\nreal molecules in terms of particular descriptors, such as the partition\ncoefficient (logP) or druglikeness. However, method comparison is difficult\nbecause of the inconsistent use of evaluation metrics, the necessity for\nmultiple metrics, and the fact that some of these measures can easily be\ntricked by simple rule-based systems. We propose a novel distance measure\nbetween two sets of molecules, called Fr\\'echet ChemNet distance (FCD), that\ncan be used as an evaluation metric for generative models. The FCD is similar\nto a recently established performance metric for comparing image generation\nmethods, the Fr\\'echet Inception Distance (FID). Whereas the FID uses one of\nthe hidden layers of InceptionNet, the FCD utilizes the penultimate layer of a\ndeep neural network called ChemNet, which was trained to predict drug\nactivities. Thus, the FCD metric takes into account chemically and biologically\nrelevant information about molecules, and also measures the diversity of the\nset via the distribution of generated molecules. The FCD's advantage over\nprevious metrics is that it can detect if generated molecules are a) diverse\nand have similar b) chemical and c) biological properties as real molecules. We\nfurther provide an easy-to-use implementation that only requires the SMILES\nrepresentation of the generated molecules as input to calculate the FCD.\nImplementations are available at: https://www.github.com/bioinf-jku/FCD\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:36:24 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 06:57:03 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 14:20:53 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Preuer", "Kristina", ""], ["Renz", "Philipp", ""], ["Unterthiner", "Thomas", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "1803.09522", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "A Provably Correct Algorithm for Deep Learning that Actually Works", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a layer-by-layer algorithm for training deep convolutional\nnetworks, where each step involves gradient updates for a two layer network\nfollowed by a simple clustering algorithm. Our algorithm stems from a deep\ngenerative model that generates mages level by level, where lower resolution\nimages correspond to latent semantic classes. We analyze the convergence rate\nof our algorithm assuming that the data is indeed generated according to this\nmodel (as well as additional assumptions). While we do not pretend to claim\nthat the assumptions are realistic for natural images, we do believe that they\ncapture some true properties of real data. Furthermore, we show that our\nalgorithm actually works in practice (on the CIFAR dataset), achieving results\nin the same ballpark as that of vanilla convolutional neural networks that are\nbeing trained by stochastic gradient descent. Finally, our proof techniques may\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:48:14 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 13:55:48 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1803.09533", "submitter": "Marc Lelarge", "authors": "Jean-Baptiste Escudi\\'e, Alaa Saade, Alice Coucke, Marc Lelarge", "title": "Deep Representation for Patient Visits from Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to learn low-dimensional representations (embeddings) of patient\nvisits from the corresponding electronic health record (EHR) where\nInternational Classification of Diseases (ICD) diagnosis codes are removed. We\nexpect that these embeddings will be useful for the construction of predictive\nstatistical models anticipated to drive personalized medicine and improve\nhealthcare quality. These embeddings are learned using a deep neural network\ntrained to predict ICD diagnosis categories. We show that our embeddings\ncapture relevant clinical informations and can be used directly as input to\nstandard machine learning algorithms like multi-output classifiers for ICD code\nprediction. We also show that important medical informations correspond to\nparticular directions in our embedding space.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:02:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Escudi\u00e9", "Jean-Baptiste", ""], ["Saade", "Alaa", ""], ["Coucke", "Alice", ""], ["Lelarge", "Marc", ""]]}, {"id": "1803.09539", "submitter": "Sai Praneeth Karimireddy", "authors": "Francesco Locatello, Anant Raj, Sai Praneeth Karimireddy, Gunnar\n  R\\\"atsch, Bernhard Sch\\\"olkopf, Sebastian U. Stich, Martin Jaggi", "title": "On Matching Pursuit and Coordinate Descent", "comments": null, "journal-ref": "ICML 2018 - Proceedings of the 35th International Conference on\n  Machine Learning", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two popular examples of first-order optimization methods over linear spaces\nare coordinate descent and matching pursuit algorithms, with their randomized\nvariants. While the former targets the optimization by moving along\ncoordinates, the latter considers a generalized notion of directions.\nExploiting the connection between the two algorithms, we present a unified\nanalysis of both, providing affine invariant sublinear $\\mathcal{O}(1/t)$ rates\non smooth objectives and linear convergence on strongly convex objectives. As a\nbyproduct of our affine invariant analysis of matching pursuit, our rates for\nsteepest coordinate descent are the tightest known. Furthermore, we show the\nfirst accelerated convergence rate $\\mathcal{O}(1/t^2)$ for matching pursuit\nand steepest coordinate descent on convex objectives.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:15:21 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 07:33:05 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 17:39:04 GMT"}, {"version": "v4", "created": "Fri, 8 Jun 2018 07:31:49 GMT"}, {"version": "v5", "created": "Mon, 2 Jul 2018 14:00:23 GMT"}, {"version": "v6", "created": "Tue, 26 Feb 2019 08:40:16 GMT"}, {"version": "v7", "created": "Fri, 31 May 2019 17:33:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Locatello", "Francesco", ""], ["Raj", "Anant", ""], ["Karimireddy", "Sai Praneeth", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1803.09544", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "A General Path-Based Representation for Predicting Program Properties", "comments": "to appear in PLDI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting program properties such as names or expression types has a wide\nrange of applications. It can ease the task of programming and increase\nprogrammer productivity. A major challenge when learning from programs is\n$\\textit{how to represent programs in a way that facilitates effective\nlearning}$.\n  We present a $\\textit{general path-based representation}$ for learning from\nprograms. Our representation is purely syntactic and extracted automatically.\nThe main idea is to represent a program using paths in its abstract syntax tree\n(AST). This allows a learning model to leverage the structured nature of code\nrather than treating it as a flat sequence of tokens.\n  We show that this representation is general and can: (i) cover different\nprediction tasks, (ii) drive different learning algorithms (for both generative\nand discriminative models), and (iii) work across different programming\nlanguages.\n  We evaluate our approach on the tasks of predicting variable names, method\nnames, and full types. We use our representation to drive both CRF-based and\nword2vec-based learning, for programs of four languages: JavaScript, Java,\nPython and C\\#. Our evaluation shows that our approach obtains better results\nthan task-specific handcrafted representations across different tasks and\nprogramming languages.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:30:21 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:09:32 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 07:48:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09546", "submitter": "Gil Keren", "authors": "Gil Keren, Nicholas Cummins, Bj\\\"orn Schuller", "title": "Calibrated Prediction Intervals for Neural Network Regressors", "comments": null, "journal-ref": "IEEE Access (Volume 6), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ongoing developments in neural network models are continually advancing the\nstate of the art in terms of system accuracy. However, the predicted labels\nshould not be regarded as the only core output; also important is a\nwell-calibrated estimate of the prediction uncertainty. Such estimates and\ntheir calibration are critical in many practical applications. Despite their\nobvious aforementioned advantage in relation to accuracy, contemporary neural\nnetworks can, generally, be regarded as poorly calibrated and as such do not\nproduce reliable output probability estimates. Further, while post-processing\ncalibration solutions can be found in the relevant literature, these tend to be\nfor systems performing classification. In this regard, we herein present two\nnovel methods for acquiring calibrated predictions intervals for neural network\nregressors: empirical calibration and temperature scaling. In experiments using\ndifferent regression tasks from the audio and computer vision domains, we find\nthat both our proposed methods are indeed capable of producing calibrated\nprediction intervals for neural network regressors with any desired confidence\nlevel, a finding that is consistent across all datasets and neural network\narchitectures we experimented with. In addition, we derive an additional\npractical recommendation for producing more accurate calibrated prediction\nintervals. We release the source code implementing our proposed methods for\ncomputing calibrated predicted intervals. The code for computing calibrated\npredicted intervals is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:35:12 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 12:58:45 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 15:56:34 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Keren", "Gil", ""], ["Cummins", "Nicholas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1803.09551", "submitter": "Guang-Neng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai, Feng-Yu Qiu, Rui Xia, Tao Li, Shu-Jian\n  Huang, Jia-Jun Chen", "title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback", "comments": "27 pages, 11 figures, 6 tables, ACM TKDD 2018", "journal-ref": null, "doi": "10.1145/3127873", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:46:13 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""], ["Qiu", "Feng-Yu", ""], ["Xia", "Rui", ""], ["Li", "Tao", ""], ["Huang", "Shu-Jian", ""], ["Chen", "Jia-Jun", ""]]}, {"id": "1803.09578", "submitter": "Nils Reimers", "authors": "Nils Reimers, Iryna Gurevych", "title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:35:14 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1803.09587", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Dietmar Jannach", "title": "Evaluation of Session-based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-018-9209-6", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems help users find relevant items of interest, for example\non e-commerce or media streaming sites. Most academic research is concerned\nwith approaches that personalize the recommendations according to long-term\nuser profiles. In many real-world applications, however, such long-term\nprofiles often do not exist and recommendations therefore have to be made\nsolely based on the observed behavior of a user during an ongoing session.\nGiven the high practical relevance of the problem, an increased interest in\nthis problem can be observed in recent years, leading to a number of proposals\nfor session-based recommendation algorithms that typically aim to predict the\nuser's immediate next actions. In this work, we present the results of an\nin-depth performance comparison of a number of such algorithms, using a variety\nof datasets and evaluation measures. Our comparison includes the most recent\napproaches based on recurrent neural networks like GRU4REC, factorized Markov\nmodel approaches such as FISM or FOSSIL, as well as simpler methods based,\ne.g., on nearest neighbor schemes. Our experiments reveal that algorithms of\nthis latter class, despite their sometimes almost trivial nature, often perform\nequally well or significantly better than today's more complex approaches based\non deep neural networks. Our results therefore suggest that there is\nsubstantial room for improvement regarding the development of more\nsophisticated session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:46:07 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:14:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ludewig", "Malte", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1803.09592", "submitter": "Fabian Schrumpf", "authors": "Fabian Schrumpf, Gerold Bausch, Matthias Sturm, Mirco Fuchs", "title": "Similarity based hierarchical clustering of physiological parameters for\n  the identification of health states - a feasibility study", "comments": "39th Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC)", "journal-ref": "2017 39th Annual International Conference of the IEEE Engineering\n  in Medicine and Biology Society (EMBC) (pp. 458-462)", "doi": "10.1109/EMBC.2017.8036861", "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new unsupervised method for the clustering of\nphysiological data into health states based on their similarity. We propose an\niterative hierarchical clustering approach that combines health states\naccording to a similarity constraint to new arbitrary health states. We applied\nmethod to experimental data in which the physical strain of subjects was\nsystematically varied. We derived health states based on parameters extracted\nfrom ECG data. The occurrence of health states shows a high temporal\ncorrelation to the experimental phases of the physical exercise. We compared\nour method to other clustering algorithms and found a significantly higher\naccuracy with respect to the identification of health states.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:51:38 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Schrumpf", "Fabian", ""], ["Bausch", "Gerold", ""], ["Sturm", "Matthias", ""], ["Fuchs", "Mirco", ""]]}, {"id": "1803.09621", "submitter": "Yoav Kaempfer", "authors": "Yoav Kaempfer and Lior Wolf", "title": "Learning the Multiple Traveling Salesmen Problem with Permutation\n  Invariant Pooling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there are optimal TSP solvers, as well as recent learning-based\napproaches, the generalization of the TSP to the Multiple Traveling Salesmen\nProblem is much less studied. Here, we design a neural network solution that\ntreats the salesmen, cities and depot as three different sets of varying\ncardinalities. We apply a novel technique that combines elements from recent\narchitectures that were developed for sets, as well as elements from graph\nnetworks. Coupled with new constraint enforcing output layers, a dedicated\nloss, and a search method, our solution is shown to outperform all the\nmeta-heuristics of the leading solver in the field.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 14:29:42 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 14:24:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Kaempfer", "Yoav", ""], ["Wolf", "Lior", ""]]}, {"id": "1803.09630", "submitter": "Ibrahim Omara", "authors": "Ibrahim Omara, Hongzhi Zhang, Faqiang Wang, and Wangmeng Zuo", "title": "Metric Learning with Dynamically Generated Pairwise Constraints for Ear\n  Recognition", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ear recognition task is known as predicting whether two ear images belong to\nthe same person or not. In this paper, we present a novel metric learning\nmethod for ear recognition. This method is formulated as a pairwise constrained\noptimization problem. In each training cycle, this method selects the nearest\nsimilar and dissimilar neighbors of each sample to construct the pairwise\nconstraints, and then solve the optimization problem by the iterated Bregman\nprojections. Experiments are conducted on AMI, USTB II and WPUT databases. The\nresults show that the proposed approach can achieve promising recognition rates\nin ear recognition, and its training process is much more efficient than the\nother competing metric learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 14:45:36 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Omara", "Ibrahim", ""], ["Zhang", "Hongzhi", ""], ["Wang", "Faqiang", ""], ["Zuo", "Wangmeng", ""]]}, {"id": "1803.09638", "submitter": "Pin-Yu Chen", "authors": "Pei-Hsuan Lu, Pin-Yu Chen, Chia-Mu Yu", "title": "On the Limitation of Local Intrinsic Dimensionality for Characterizing\n  the Subspaces of Adversarial Examples", "comments": "Accepted to ICLR 2018 Worshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and characterizing the subspaces of adversarial examples aid in\nstudying the robustness of deep neural networks (DNNs) to adversarial\nperturbations. Very recently, Ma et al. (ICLR 2018) proposed to use local\nintrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to\nstudy adversarial subspaces. It was demonstrated that LID can be used to\ncharacterize the adversarial subspaces associated with different attack\nmethods, e.g., the Carlini and Wagner's (C&W) attack and the fast gradient sign\nattack.\n  In this paper, we use MNIST and CIFAR-10 to conduct two new sets of\nexperiments that are absent in existing LID analysis and report the limitation\nof LID in characterizing the corresponding adversarial subspaces, which are (i)\noblivious attacks and LID analysis using adversarial examples with different\nconfidence levels; and (ii) black-box transfer attacks. For (i), we find that\nthe performance of LID is very sensitive to the confidence parameter deployed\nby an attack, and the LID learned from ensembles of adversarial examples with\nvarying confidence levels surprisingly gives poor performance. For (ii), we\nfind that when adversarial examples are crafted from another DNN model, LID is\nineffective in characterizing their adversarial subspaces. These two findings\ntogether suggest the limited capability of LID in characterizing the subspaces\nof adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 14:56:28 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Lu", "Pei-Hsuan", ""], ["Chen", "Pin-Yu", ""], ["Yu", "Chia-Mu", ""]]}, {"id": "1803.09655", "submitter": "Giovanni Mariani", "authors": "Giovanni Mariani, Florian Scheidegger, Roxana Istrate, Costas Bekas,\n  Cristiano Malossi", "title": "BAGAN: Data Augmentation with Balancing GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification datasets are often imbalanced, characteristic that\nnegatively affects the accuracy of deep-learning classifiers. In this work we\npropose balancing GAN (BAGAN) as an augmentation tool to restore balance in\nimbalanced datasets. This is challenging because the few minority-class images\nmay not be enough to train a GAN. We overcome this issue by including during\nthe adversarial training all available images of majority and minority classes.\nThe generative model learns useful features from majority classes and uses\nthese to generate images for minority classes. We apply class conditioning in\nthe latent space to drive the generation process towards a target class. The\ngenerator in the GAN is initialized with the encoder module of an autoencoder\nthat enables us to learn an accurate class-conditioning in the latent space. We\ncompare the proposed methodology with state-of-the-art GANs and demonstrate\nthat BAGAN generates images of superior quality when trained with an imbalanced\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 15:20:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 08:07:30 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Mariani", "Giovanni", ""], ["Scheidegger", "Florian", ""], ["Istrate", "Roxana", ""], ["Bekas", "Costas", ""], ["Malossi", "Cristiano", ""]]}, {"id": "1803.09689", "submitter": "Cem Eteke", "authors": "Cem Eteke, Hayati Havlucu, Nisa \\.Irem K{\\i}rba\\c{c}, Mehmet Cengiz\n  Onba\\c{s}l{\\i}, Aykut Co\\c{s}kun, Terry Eskenazi, O\\u{g}uzhan \\\"Ozcan,\n  Bar{\\i}\\c{s} Akg\\\"un", "title": "Flow From Motion: A Deep Learning Approach", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices have the potential to enhance sports performance, yet they\nare not fulfilling this promise. Our previous studies with 6 professional\ntennis coaches and 20 players indicate that this could be due the lack of\npsychological or mental state feedback, which the coaches claim to provide.\nTowards this end, we propose to detect the flow state, mental state of optimal\nperformance, using wearables data to be later used in training. We performed a\nstudy with a professional tennis coach and two players. The coach provided\nlabels about the players' flow state while each player had a wearable device on\ntheir racket holding wrist. We trained multiple models using the wearables data\nand the coach labels. Our deep neural network models achieved around 98%\ntesting accuracy for a variety of conditions. This suggests that the flow state\nor what coaches recognize as flow, can be detected using wearables data in\ntennis which is a novel result. The implication for the HCI community is that\nhaving access to such information would allow for design of novel hardware and\ninteraction paradigms that would be helpful in professional athlete training.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:12:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Eteke", "Cem", ""], ["Havlucu", "Hayati", ""], ["K\u0131rba\u00e7", "Nisa \u0130rem", ""], ["Onba\u015fl\u0131", "Mehmet Cengiz", ""], ["Co\u015fkun", "Aykut", ""], ["Eskenazi", "Terry", ""], ["\u00d6zcan", "O\u011fuzhan", ""], ["Akg\u00fcn", "Bar\u0131\u015f", ""]]}, {"id": "1803.09702", "submitter": "Olivier Deiss", "authors": "Olivier Deiss, Siddharth Biswal, Jing Jin, Haoqi Sun, M. Brandon\n  Westover, Jimeng Sun", "title": "HAMLET: Interpretable Human And Machine co-LEarning Technique", "comments": "Removed KDD template", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community. Here,\nwe enable efficient training of deep neural networks. From low-confidence\nlabels, we iteratively improve their quality by simultaneous learning of\nmachines and experts. We call it Human And Machine co-LEarning Technique\n(HAMLET). Throughout the process, experts become more consistent, while the\nalgorithm provides them with explainable feedback for confirmation. HAMLET uses\na neural embedding function and a memory module filled with diverse reference\nembeddings from different classes. Its output includes classification labels\nand highly relevant reference embeddings as explanation. We took the study of\nbrain monitoring at intensive care unit (ICU) as an application of HAMLET on\ncontinuous electroencephalography (cEEG) data. Although cEEG monitoring yields\nlarge volumes of data, labeling costs and difficulty make it hard to build a\nclassifier. Additionally, while experts agree on the labels of clear-cut\nexamples of cEEG patterns, labeling many real-world cEEG data can be extremely\nchallenging. Thus, a large minority of sequences might be mislabeled. HAMLET\nhas shown significant performance gain against deep learning and other\nbaselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.\nBesides improved performance, clinical experts confirmed the interpretability\nof those reference embeddings in helping explaining the classification results\nby HAMLET.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:29:03 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 13:28:50 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 05:41:09 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Deiss", "Olivier", ""], ["Biswal", "Siddharth", ""], ["Jin", "Jing", ""], ["Sun", "Haoqi", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.09704", "submitter": "Bernardo P\\'erez Orozco", "authors": "Bernardo P\\'erez Orozco, Gabriele Abbati, Stephen Roberts", "title": "MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time\n  Series Forecasting", "comments": "30 pages, 12 figures * This version expands on the literature review;\n  presents appendices in a graphical manner (as opposed to the previous\n  tables); adds a mapping between dataset descriptions and shorthands; expands\n  on results analysis and conclusions; corrects a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is ubiquitous in the modern world. Applications range\nfrom health care to astronomy, and include climate modelling, financial trading\nand monitoring of critical engineering equipment. To offer value over this\nrange of activities, models must not only provide accurate forecasts, but also\nquantify and adjust their uncertainty over time. In this work, we directly\ntackle this task with a novel, fully end-to-end deep learning method for time\nseries forecasting. By recasting time series forecasting as an ordinal\nregression task, we develop a principled methodology to assess long-term\npredictive uncertainty and describe rich multimodal, non-Gaussian behaviour,\nwhich arises regularly in applied settings.\n  Notably, our framework is a wholly general-purpose approach that requires\nlittle to no user intervention to be used. We showcase this key feature in a\nlarge-scale benchmark test with 45 datasets drawn from both, a wide range of\nreal-world application domains, as well as a comprehensive list of synthetic\nmaps. This wide comparison encompasses state-of-the-art methods in both the\nMachine Learning and Statistics modelling literature, such as the Gaussian\nProcess. We find that our approach does not only provide excellent predictive\nforecasts, shadowing true future values, but also allows us to infer valuable\ninformation, such as the predictive distribution of the occurrence of critical\nevents of interest, accurately and reliably even over long time horizons.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:36:37 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:20:24 GMT"}, {"version": "v3", "created": "Sat, 11 Aug 2018 14:24:07 GMT"}, {"version": "v4", "created": "Wed, 24 Oct 2018 23:51:41 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Orozco", "Bernardo P\u00e9rez", ""], ["Abbati", "Gabriele", ""], ["Roberts", "Stephen", ""]]}, {"id": "1803.09733", "submitter": "Fang Su", "authors": "Fang Su, Jing-Yan Wang", "title": "Domain transfer convolutional attribute embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of transfer learning with the attribute\ndata. In the transfer learning problem, we want to leverage the data of the\nauxiliary and the target domains to build an effective model for the\nclassification problem in the target domain. Meanwhile, the attributes are\nnaturally stable cross different domains. This strongly motives us to learn\neffective domain transfer attribute representations. To this end, we proposed\nto embed the attributes of the data to a common space by using the powerful\nconvolutional neural network (CNN) model. The convolutional representations of\nthe data points are mapped to the corresponding attributes so that they can be\neffective embedding of the attributes. We also represent the data of different\ndomains by a domain-independent CNN, ant a domain-specific CNN, and combine\ntheir outputs with the attribute embedding to build the classification model.\nAn joint learning framework is constructed to minimize the classification\nerrors, the attribute mapping error, the mismatching of the domain-independent\nrepresentations cross different domains, and to encourage the the neighborhood\nsmoothness of representations in the target domain. The minimization problem is\nsolved by an iterative algorithm based on gradient descent. Experiments over\nbenchmark data sets of person re-identification, bankruptcy prediction, and\nspam email detection, show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:44:45 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 17:20:03 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Su", "Fang", ""], ["Wang", "Jing-Yan", ""]]}, {"id": "1803.09737", "submitter": "In\\^es Almeida", "authors": "In\\^es Almeida and Jo\\~ao Xavier", "title": "DJAM: distributed Jacobi asynchronous method for learning personal\n  models", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": "10.1109/LSP.2018.2859596", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing data collected by a network of agents often boils down to solving\nan optimization problem. The distributed nature of these problems calls for\nmethods that are, themselves, distributed. While most collaborative learning\nproblems require agents to reach a common (or consensus) model, there are\nsituations in which the consensus solution may not be optimal. For instance,\nagents may want to reach a compromise between agreeing with their neighbors and\nminimizing a personal loss function. We present DJAM, a Jacobi-like distributed\nalgorithm for learning personalized models. This method is\nimplementation-friendly: it has no hyperparameters that need tuning, it is\nasynchronous, and its updates only require single-neighbor interactions. We\nprove that DJAM converges with probability one to the solution, provided that\nthe personal loss functions are strongly convex and have Lipschitz gradient. We\nthen give evidence that DJAM is on par with state-of-the-art methods: our\nmethod reaches a solution with error similar to the error of a carefully tuned\nADMM in about the same number of single-neighbor interactions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:53:56 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 16:54:17 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Almeida", "In\u00eas", ""], ["Xavier", "Jo\u00e3o", ""]]}, {"id": "1803.09760", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Oleh Rybkin, Konstantinos G. Derpanis, Kostas\n  Daniilidis", "title": "Predicting the Future with Transformational States", "comments": "24 pages, including supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:00:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Jaegle", "Andrew", ""], ["Rybkin", "Oleh", ""], ["Derpanis", "Konstantinos G.", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1803.09780", "submitter": "Yoav Levine", "authors": "Yoav Levine, Or Sharir, Nadav Cohen and Amnon Shashua", "title": "Quantum Entanglement in Deep Learning Architectures", "comments": null, "journal-ref": "Phys. Rev. Lett. 122, 065301 (2019)", "doi": "10.1103/PhysRevLett.122.065301", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning has enabled unprecedented achievements in various\ndomains. Nonetheless, employment of machine learning for wave function\nrepresentations is focused on more traditional architectures such as restricted\nBoltzmann machines (RBMs) and fully-connected neural networks. In this letter,\nwe establish that contemporary deep learning architectures, in the form of deep\nconvolutional and recurrent networks, can efficiently represent highly\nentangled quantum systems. By constructing Tensor Network equivalents of these\narchitectures, we identify an inherent reuse of information in the network\noperation as a key trait which distinguishes them from standard Tensor Network\nbased representations, and which enhances their entanglement capacity. Our\nresults show that such architectures can support volume-law entanglement\nscaling, polynomially more efficiently than presently employed RBMs. Thus,\nbeyond a quantification of the entanglement capacity of leading deep learning\narchitectures, our analysis formally motivates a shift of trending\nneural-network based wave function representations closer to the\nstate-of-the-art in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:30:29 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 15:39:15 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 18:25:01 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Levine", "Yoav", ""], ["Sharir", "Or", ""], ["Cohen", "Nadav", ""], ["Shashua", "Amnon", ""]]}, {"id": "1803.09791", "submitter": "Mustafa Haider", "authors": "Adnan Haider", "title": "A Common Framework for Natural Gradient and Taylor based Optimisation\n  using Manifold Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report constructs a theoretical framework to relate standard\nTaylor approximation based optimisation methods with Natural Gradient (NG), a\nmethod which is Fisher efficient with probabilistic models. Such a framework\nwill be shown to also provide mathematical justification to combine higher\norder methods with the method of NG.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:54:36 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 21:45:59 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 13:44:05 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Haider", "Adnan", ""]]}, {"id": "1803.09820", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay", "comments": "Files to help replicate the results reported here are available on\n  Github", "journal-ref": null, "doi": null, "report-no": "US Naval Research Laboratory Technical Report 5510-026", "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:05:59 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 17:43:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1803.09824", "submitter": "Ronald Kemker", "authors": "Ronald Kemker and Ryan Luu and Christopher Kanan", "title": "Low-Shot Learning for the Semantic Segmentation of Remote Sensing\n  Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computer vision using deep learning with RGB imagery\n(e.g., object recognition and detection) have been made possible thanks to the\ndevelopment of large annotated RGB image datasets. In contrast, multispectral\nimage (MSI) and hyperspectral image (HSI) datasets contain far fewer labeled\nimages, in part due to the wide variety of sensors used. These annotations are\nespecially limited for semantic segmentation, or pixel-wise classification, of\nremote sensing imagery because it is labor intensive to generate image\nannotations. Low-shot learning algorithms can make effective inferences despite\nsmaller amounts of annotated data. In this paper, we study low-shot learning\nusing self-taught feature learning for semantic segmentation. We introduce 1)\nan improved self-taught feature learning framework for HSI and MSI data and 2)\na semi-supervised classification algorithm. When these are combined, they\nachieve state-of-the-art performance on remote sensing datasets that have\nlittle annotated training data available. These low-shot learning frameworks\nwill reduce the manual image annotation burden and improve semantic\nsegmentation performance for remote sensing imagery.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:17:19 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kemker", "Ronald", ""], ["Luu", "Ryan", ""], ["Kanan", "Christopher", ""]]}, {"id": "1803.09862", "submitter": "Timothy Graham", "authors": "Senuri Wijenayake, Timothy Graham, Peter Christen", "title": "A Decision Tree Approach to Predicting Recidivism in Domestic Violence", "comments": "12 pages; Accepted at The 2018 Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic violence (DV) is a global social and public health issue that is\nhighly gendered. Being able to accurately predict DV recidivism, i.e.,\nre-offending of a previously convicted offender, can speed up and improve risk\nassessment procedures for police and front-line agencies, better protect\nvictims of DV, and potentially prevent future re-occurrences of DV. Previous\nwork in DV recidivism has employed different classification techniques,\nincluding decision tree (DT) induction and logistic regression, where the main\nfocus was on achieving high prediction accuracy. As a result, even the diagrams\nof trained DTs were often too difficult to interpret due to their size and\ncomplexity, making decision-making challenging. Given there is often a\ntrade-off between model accuracy and interpretability, in this work our aim is\nto employ DT induction to obtain both interpretable trees as well as high\nprediction accuracy. Specifically, we implement and evaluate different\napproaches to deal with class imbalance as well as feature selection. Compared\nto previous work in DV recidivism prediction that employed logistic regression,\nour approach can achieve comparable area under the ROC curve results by using\nonly 3 of 11 available features and generating understandable decision trees\nthat contain only 4 leaf nodes.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:03:26 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wijenayake", "Senuri", ""], ["Graham", "Timothy", ""], ["Christen", "Peter", ""]]}, {"id": "1803.09868", "submitter": "Yash Sharma", "authors": "Yash Sharma and Pin-Yu Chen", "title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Squeezing is a recently proposed defense method which reduces the\nsearch space available to an adversary by coalescing samples that correspond to\nmany different feature vectors in the original space into a single sample. It\nhas been shown that feature squeezing defenses can be combined in a joint\ndetection framework to achieve high detection rates against state-of-the-art\nattacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by\nincreasing the adversary strength of said state-of-the-art attacks, one can\nbypass the detection framework with adversarial examples of minimal visual\ndistortion. These results suggest for proposed defenses to validate against\nstronger attack configurations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:08:39 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sharma", "Yash", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "1803.09877", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Hongyi Wang and Zachary Charles and Dimitris\n  Papailiopoulos", "title": "DRACO: Byzantine-resilient Distributed Training via Redundant Gradients", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed model training is vulnerable to byzantine system failures and\nadversarial compute nodes, i.e., nodes that use malicious updates to corrupt\nthe global model stored at a parameter server (PS). To guarantee some form of\nrobustness, recent work suggests using variants of the geometric median as an\naggregation rule, in place of gradient averaging. Unfortunately, median-based\nrules can incur a prohibitive computational overhead in large-scale settings,\nand their convergence guarantees often require strong assumptions. In this\nwork, we present DRACO, a scalable framework for robust distributed training\nthat uses ideas from coding theory. In DRACO, each compute node evaluates\nredundant gradients that are used by the parameter server to eliminate the\neffects of adversarial updates. DRACO comes with problem-independent robustness\nguarantees, and the model that it trains is identical to the one trained in the\nadversary-free setup. We provide extensive experiments on real datasets and\ndistributed setups across a variety of large-scale models, where we show that\nDRACO is several times, to orders of magnitude faster than median-based\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:34:25 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 05:38:33 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 02:10:56 GMT"}, {"version": "v4", "created": "Fri, 22 Jun 2018 02:47:53 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Chen", "Lingjiao", ""], ["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1803.09887", "submitter": "Jie Liu", "authors": "Jie Liu, Hao Zheng", "title": "MLE-induced Likelihood for Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intractable partition function, the exact likelihood function for\na Markov random field (MRF), in many situations, can only be approximated.\nMajor approximation approaches include pseudolikelihood and Laplace\napproximation. In this paper, we propose a novel way of approximating the\nlikelihood function through first approximating the marginal likelihood\nfunctions of individual parameters and then reconstructing the joint likelihood\nfunction from these marginal likelihood functions. For approximating the\nmarginal likelihood functions, we derive a particular likelihood function from\na modified scenario of coin tossing which is useful for capturing how one\nparameter interacts with the remaining parameters in the likelihood function.\nFor reconstructing the joint likelihood function, we use an appropriate copula\nto link up these marginal likelihood functions. Numerical investigation\nsuggests the superior performance of our approach. Especially as the size of\nthe MRF increases, both the numerical performance and the computational cost of\nour approach remain consistently satisfactory, whereas Laplace approximation\ndeteriorates and pseudolikelihood becomes computationally unbearable.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:05:44 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Liu", "Jie", ""], ["Zheng", "Hao", ""]]}, {"id": "1803.09928", "submitter": "Tanvi Verma", "authors": "Tanvi Verma, Pradeep Varakantham and Hoong Chuin Lau", "title": "Entropy based Independent Learning in Anonymous Multi-Agent Settings", "comments": null, "journal-ref": "Vol 29 (2019): Proceedings of the Twenty-Ninth International\n  Conference on Automated Planning and Scheduling", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient sequential matching of supply and demand is a problem of interest\nin many online to offline services. For instance, Uber, Lyft, Grab for matching\ntaxis to customers; Ubereats, Deliveroo, FoodPanda etc for matching restaurants\nto customers. In these online to offline service problems, individuals who are\nresponsible for supply (e.g., taxi drivers, delivery bikes or delivery van\ndrivers) earn more by being at the \"right\" place at the \"right\" time. We are\ninterested in developing approaches that learn to guide individuals to be in\nthe \"right\" place at the \"right\" time (to maximize revenue) in the presence of\nother similar \"learning\" individuals and only local aggregated observation of\nother agents states (e.g., only number of other taxis in same zone as current\nagent).\n  A key characteristic of the domains of interest is that the interactions\nbetween individuals are anonymous, i.e., the outcome of an interaction\n(competing for demand) is dependent only on the number and not on the identity\nof the agents. We model these problems using the Anonymous MARL (AyMARL) model.\nThe key contribution of this paper is in employing principle of maximum entropy\nto provide a general framework of independent learning that is both empirically\neffective (even with only local aggregated information of agent population\ndistribution) and theoretically justified.\n  Finally, our approaches provide a significant improvement with respect to\njoint and individual revenue on a generic simulator for online to offline\nservices and a real world taxi problem over existing approaches. More\nimportantly, this is achieved while having the least variance in revenues\nearned by the learning individuals, an indicator of fairness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 07:10:20 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 08:21:10 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 09:07:50 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 06:25:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Verma", "Tanvi", ""], ["Varakantham", "Pradeep", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1803.09946", "submitter": "Toru Nakashika", "authors": "Toru Nakashika, Shinji Takaki, Junichi Yamagishi", "title": "Complex-Valued Restricted Boltzmann Machine for Direct Speech\n  Parameterization from Complex Spectra", "comments": "Under the IEEE T-ASLP Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a novel energy-based probabilistic distribution that\nrepresents complex-valued data and explains how to apply it to direct feature\nextraction from complex-valued spectra. The proposed model, the complex-valued\nrestricted Boltzmann machine (CRBM), is designed to deal with complex-valued\nvisible units as an extension of the well-known restricted Boltzmann machine\n(RBM). Like the RBM, the CRBM learns the relationships between visible and\nhidden units without having connections between units in the same layer, which\ndramatically improves training efficiency by using Gibbs sampling or\ncontrastive divergence (CD). Another important characteristic is that the CRBM\nalso has connections between real and imaginary parts of each of the\ncomplex-valued visible units that help represent the data distribution in the\ncomplex domain. In speech signal processing, classification and generation\nfeatures are often based on amplitude spectra (e.g., MFCC, cepstra, and\nmel-cepstra) even if they are calculated from complex spectra, and they ignore\nphase information. In contrast, the proposed feature extractor using the CRBM\ndirectly encodes the complex spectra (or another complex-valued representation\nof the complex spectra) into binary-valued latent features (hidden units).\nSince the visible-hidden connections are undirected, we can also recover\n(decode) the complex spectra from the latent features directly. Our speech\ncoding experiments demonstrated that the CRBM outperformed other speech coding\nmethods, such as methods using the conventional RBM, the mel-log spectrum\napproximate (MLSA) decoder, etc.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:07:20 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Nakashika", "Toru", ""], ["Takaki", "Shinji", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1803.09956", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto Rodriguez,\n  Thomas Funkhouser", "title": "Learning Synergies between Pushing and Grasping with Self-supervised\n  Deep Reinforcement Learning", "comments": "To appear at the International Conference On Intelligent Robots and\n  Systems (IROS) 2018. Project webpage: http://vpg.cs.princeton.edu Summary\n  video: https://youtu.be/-OkyX7ZlhiU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skilled robotic manipulation benefits from complex synergies between\nnon-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing\ncan help rearrange cluttered objects to make space for arms and fingers;\nlikewise, grasping can help displace objects to make pushing movements more\nprecise and collision-free. In this work, we demonstrate that it is possible to\ndiscover and learn these synergies from scratch through model-free deep\nreinforcement learning. Our method involves training two fully convolutional\nnetworks that map from visual observations to actions: one infers the utility\nof pushes for a dense pixel-wise sampling of end effector orientations and\nlocations, while the other does the same for grasping. Both networks are\ntrained jointly in a Q-learning framework and are entirely self-supervised by\ntrial and error, where rewards are provided from successful grasps. In this\nway, our policy learns pushing motions that enable future grasps, while\nlearning grasps that can leverage past pushes. During picking experiments in\nboth simulation and real-world scenarios, we find that our system quickly\nlearns complex behaviors amid challenging cases of clutter, and achieves better\ngrasping success rates and picking efficiencies than baseline alternatives\nafter only a few hours of training. We further demonstrate that our method is\ncapable of generalizing to novel objects. Qualitative results (videos), code,\npre-trained models, and simulation environments are available at\nhttp://vpg.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:31:28 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 03:39:11 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 20:34:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Welker", "Stefan", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1803.09967", "submitter": "Juan Duque Rodriguez", "authors": "Roberto Maestre, Juan Duque, Alberto Rubio, Juan Ar\\'evalo", "title": "Reinforcement Learning for Fair Dynamic Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:00:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Maestre", "Roberto", ""], ["Duque", "Juan", ""], ["Rubio", "Alberto", ""], ["Ar\u00e9valo", "Juan", ""]]}, {"id": "1803.09984", "submitter": "Aur\\'elien Bellet", "authors": "Pierre Dellenbach, Aur\\'elien Bellet, Jan Ramon", "title": "Hiding in the Crowd: A Massively Distributed Algorithm for Private\n  Averaging with Malicious Adversaries", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of personal data collected in our everyday interactions with\nconnected devices offers great opportunities for innovative services fueled by\nmachine learning, as well as raises serious concerns for the privacy of\nindividuals. In this paper, we propose a massively distributed protocol for a\nlarge set of users to privately compute averages over their joint data, which\ncan then be used to learn predictive models. Our protocol can find a solution\nof arbitrary accuracy, does not rely on a third party and preserves the privacy\nof users throughout the execution in both the honest-but-curious and malicious\nadversary models. Specifically, we prove that the information observed by the\nadversary (the set of maliciours users) does not significantly reduce the\nuncertainty in its prediction of private values compared to its prior belief.\nThe level of privacy protection depends on a quantity related to the Laplacian\nmatrix of the network graph and generally improves with the size of the graph.\nFurthermore, we design a verification procedure which offers protection against\nmalicious users joining the service with the goal of manipulating the outcome\nof the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:35:29 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Dellenbach", "Pierre", ""], ["Bellet", "Aur\u00e9lien", ""], ["Ramon", "Jan", ""]]}, {"id": "1803.10016", "submitter": "Matthias Treder", "authors": "Matthias S. Treder", "title": "Cross-validation in high-dimensional spaces: a lifeline for\n  least-squares models and multi-class LDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least-squares models such as linear regression and Linear Discriminant\nAnalysis (LDA) are amongst the most popular statistical learning techniques.\nHowever, since their computation time increases cubically with the number of\nfeatures, they are inefficient in high-dimensional neuroimaging datasets.\nFortunately, for k-fold cross-validation, an analytical approach has been\ndeveloped that yields the exact cross-validated predictions in least-squares\nmodels without explicitly training the model. Its computation time grows with\nthe number of test samples. Here, this approach is systematically investigated\nin the context of cross-validation and permutation testing. LDA is used\nexemplarily but results hold for all other least-squares methods. Furthermore,\na non-trivial extension to multi-class LDA is formally derived. The analytical\napproach is evaluated using complexity calculations, simulations, and\npermutation testing of an EEG/MEG dataset. Depending on the ratio between\nfeatures and samples, the analytical approach is up to 10,000x faster than the\nstandard approach (retraining the model on each training set). This allows for\na fast cross-validation of least-squares models and multi-class LDA in\nhigh-dimensional data, with obvious applications in multi-dimensional datasets,\nRepresentational Similarity Analysis, and permutation testing.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 11:20:10 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Treder", "Matthias S.", ""]]}, {"id": "1803.10049", "submitter": "Jack Rae", "authors": "Jack W Rae, Chris Dyer, Peter Dayan, Timothy P Lillicrap", "title": "Fast Parametric Learning with Activation Memorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained with backpropagation often struggle to identify\nclasses that have been observed a small number of times. In applications where\nmost class labels are rare, such as language modelling, this can become a\nperformance bottleneck. One potential remedy is to augment the network with a\nfast-learning non-parametric model which stores recent activations and class\nlabels into an external memory. We explore a simplified architecture where we\ntreat a subset of the model parameters as fast memory stores. This can help\nretain information over longer time intervals than a traditional memory, and\ndoes not require additional space or compute. In the case of image\nclassification, we display faster binding of novel classes on an Omniglot image\ncurriculum task. We also show improved performance for word-based language\nmodels on news reports (GigaWord), books (Project Gutenberg) and Wikipedia\narticles (WikiText-103) --- the latter achieving a state-of-the-art perplexity\nof 29.2.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 12:53:24 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Rae", "Jack W", ""], ["Dyer", "Chris", ""], ["Dayan", "Peter", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1803.10056", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Krister Wolff, Leo Laine", "title": "Automated Speed and Lane Change Decision Making using Deep Reinforcement\n  Learning", "comments": null, "journal-ref": "IEEE International Conference on Intelligent Transportation\n  Systems (ITSC), 2018, pp. 2148-2155", "doi": "10.1109/ITSC.2018.8569568", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method, based on deep reinforcement learning, for\nautomatically generating a general purpose decision making function. A Deep\nQ-Network agent was trained in a simulated environment to handle speed and lane\nchange decisions for a truck-trailer combination. In a highway driving case, it\nis shown that the method produced an agent that matched or surpassed the\nperformance of a commonly used reference model. To demonstrate the generality\nof the method, the exact same algorithm was also tested by training it for an\novertaking case on a road with oncoming traffic. Furthermore, a novel way of\napplying a convolutional neural network to high level input that represents\ninterchangeable objects is also introduced.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:25:44 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 15:18:22 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""]]}, {"id": "1803.10109", "submitter": "Szu-Jui Chen", "authors": "Szu-Jui Chen, Aswin Shanmugam Subramanian, Hainan Xu, Shinji Watanabe", "title": "Building state-of-the-art distant speech recognition using the CHiME-4\n  challenge with a setup of speech enhancement baseline", "comments": "Submitted for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new baseline system for automatic speech recognition\n(ASR) in the CHiME-4 challenge to promote the development of noisy ASR in\nspeech processing communities by providing 1) state-of-the-art system with a\nsimplified single system comparable to the complicated top systems in the\nchallenge, 2) publicly available and reproducible recipe through the main\nrepository in the Kaldi speech recognition toolkit. The proposed system adopts\ngeneralized eigenvalue beamforming with bidirectional long short-term memory\n(LSTM) mask estimation. We also propose to use a time delay neural network\n(TDNN) based on the lattice-free version of the maximum mutual information\n(LF-MMI) trained with augmented all six microphones plus the enhanced data\nafter beamforming. Finally, we use a LSTM language model for lattice and n-best\nre-scoring. The final system achieved 2.74\\% WER for the real test set in the\n6-channel track, which corresponds to the 2nd place in the challenge. In\naddition, the proposed baseline recipe includes four different speech\nenhancement measures, short-time objective intelligibility measure (STOI),\nextended STOI (eSTOI), perceptual evaluation of speech quality (PESQ) and\nspeech distortion ratio (SDR) for the simulation test set. Thus, the recipe\nalso provides an experimental platform for speech enhancement studies with\nthese performance measures.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 14:33:53 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Chen", "Szu-Jui", ""], ["Subramanian", "Aswin Shanmugam", ""], ["Xu", "Hainan", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1803.10122", "submitter": "David Ha", "authors": "David Ha and J\\\"urgen Schmidhuber", "title": "World Models", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.1207631", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore building generative neural network models of popular reinforcement\nlearning environments. Our world model can be trained quickly in an\nunsupervised manner to learn a compressed spatial and temporal representation\nof the environment. By using features extracted from the world model as inputs\nto an agent, we can train a very compact and simple policy that can solve the\nrequired task. We can even train our agent entirely inside of its own\nhallucinated dream generated by its world model, and transfer this policy back\ninto the actual environment.\n  An interactive version of this paper is available at\nhttps://worldmodels.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:08:55 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 05:20:40 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 07:33:20 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 09:06:27 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Ha", "David", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1803.10123", "submitter": "Chen Zeno", "authors": "Chen Zeno, Itay Golan, Elad Hoffer, Daniel Soudry", "title": "Task Agnostic Continual Learning Using Online Variational Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is the notorious vulnerability of neural networks to\nthe change of the data distribution while learning. This phenomenon has long\nbeen considered a major obstacle for allowing the use of learning agents in\nrealistic continual learning settings. A large body of continual learning\nresearch assumes that task boundaries are known during training. However,\nresearch for scenarios in which task boundaries are unknown during training has\nbeen lacking. In this paper we present, for the first time, a method for\npreventing catastrophic forgetting (BGD) for scenarios with task boundaries\nthat are unknown during training --- task-agnostic continual learning. Code of\nour algorithm is available at https://github.com/igolan/bgd.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:11:08 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 09:03:30 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 12:21:07 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Zeno", "Chen", ""], ["Golan", "Itay", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1803.10161", "submitter": "Wilson Ye Chen", "authors": "Wilson Ye Chen, Lester Mackey, Jackson Gorham, Fran\\c{c}ois-Xavier\n  Briol, Chris J. Oates", "title": "Stein Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in computational statistics and machine learning is to\napproximate a posterior distribution $p(x)$ with an empirical measure supported\non a set of representative points $\\{x_i\\}_{i=1}^n$. This paper focuses on\nmethods where the selection of points is essentially deterministic, with an\nemphasis on achieving accurate approximation when $n$ is small. To this end, we\npresent `Stein Points'. The idea is to exploit either a greedy or a conditional\ngradient method to iteratively minimise a kernel Stein discrepancy between the\nempirical measure and $p(x)$. Our empirical results demonstrate that Stein\nPoints enable accurate approximation of the posterior at modest computational\ncost. In addition, theoretical results are provided to establish convergence of\nthe method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:12:33 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 13:14:22 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 18:34:04 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 16:30:55 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chen", "Wilson Ye", ""], ["Mackey", "Lester", ""], ["Gorham", "Jackson", ""], ["Briol", "Fran\u00e7ois-Xavier", ""], ["Oates", "Chris J.", ""]]}, {"id": "1803.10172", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Alessandro Lazaric and Michal Valko", "title": "Distributed Adaptive Sampling for Kernel Matrix Approximation", "comments": "Presented at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most kernel-based methods, such as kernel or Gaussian process regression,\nkernel PCA, ICA, or $k$-means clustering, do not scale to large datasets,\nbecause constructing and storing the kernel matrix $\\mathbf{K}_n$ requires at\nleast $\\mathcal{O}(n^2)$ time and space for $n$ samples. Recent works show that\nsampling points with replacement according to their ridge leverage scores (RLS)\ngenerates small dictionaries of relevant points with strong spectral\napproximation guarantees for $\\mathbf{K}_n$. The drawback of RLS-based methods\nis that computing exact RLS requires constructing and storing the whole kernel\nmatrix. In this paper, we introduce SQUEAK, a new algorithm for kernel\napproximation based on RLS sampling that sequentially processes the dataset,\nstoring a dictionary which creates accurate kernel matrix approximations with a\nnumber of points that only depends on the effective dimension $d_{eff}(\\gamma)$\nof the dataset. Moreover since all the RLS estimations are efficiently\nperformed using only the small dictionary, SQUEAK is the first RLS sampling\nalgorithm that never constructs the whole matrix $\\mathbf{K}_n$, runs in linear\ntime $\\widetilde{\\mathcal{O}}(nd_{eff}(\\gamma)^3)$ w.r.t. $n$, and requires\nonly a single pass over the dataset. We also propose a parallel and distributed\nversion of SQUEAK that linearly scales across multiple machines, achieving\nsimilar accuracy in as little as\n$\\widetilde{\\mathcal{O}}(\\log(n)d_{eff}(\\gamma)^3)$ time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:39:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""]]}, {"id": "1803.10227", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Laura Downs, James C. Davidson", "title": "Forward-Backward Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:33:08 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Downs", "Laura", ""], ["Davidson", "James C.", ""]]}, {"id": "1803.10228", "submitter": "Fei Wang", "authors": "Fei Wang, Daniel Zheng, James Decker, Xilun Wu, Gr\\'egory M. Essertel,\n  and Tiark Rompf", "title": "Demystifying Differentiable Programming: Shift/Reset the Penultimate\n  Backpropagator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has seen tremendous success over the past decade in computer\nvision, machine translation, and gameplay. This success rests in crucial ways\non gradient-descent optimization and the ability to learn parameters of a\nneural network by backpropagating observed errors. However, neural network\narchitectures are growing increasingly sophisticated and diverse, which\nmotivates an emerging quest for even more general forms of differentiable\nprogramming, where arbitrary parameterized computations can be trained by\ngradient descent. In this paper, we take a fresh look at automatic\ndifferentiation (AD) techniques, and especially aim to demystify the\nreverse-mode form of AD that generalizes backpropagation in neural networks.\n  We uncover a tight connection between reverse-mode AD and delimited\ncontinuations, which permits implementing reverse-mode AD purely via operator\noverloading and without any auxiliary data structures. We further show how this\nformulation of AD can be fruitfully combined with multi-stage programming\n(staging), leading to a highly efficient implementation that combines the\nperformance benefits of deep learning frameworks based on explicit reified\ncomputation graphs (e.g., TensorFlow) with the expressiveness of pure library\napproaches (e.g., PyTorch).\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:43:12 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 16:28:41 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 03:09:03 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Wang", "Fei", ""], ["Zheng", "Daniel", ""], ["Decker", "James", ""], ["Wu", "Xilun", ""], ["Essertel", "Gr\u00e9gory M.", ""], ["Rompf", "Tiark", ""]]}, {"id": "1803.10231", "submitter": "Kamil Saigol", "authors": "Keuntaek Lee, Kamil Saigol, Evangelos A. Theodorou", "title": "Safe end-to-end imitation learning for model predictive control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of Bayesian networks, which provide both a mean value and\nan uncertainty estimate as output, to enhance the safety of learned control\npolicies under circumstances in which a test-time input differs significantly\nfrom the training set. Our algorithm combines reinforcement learning and\nend-to-end imitation learning to simultaneously learn a control policy as well\nas a threshold over the predictive uncertainty of the learned model, with no\nhand-tuning required. Corrective action, such as a return of control to the\nmodel predictive controller or human expert, is taken when the uncertainty\nthreshold is exceeded. We validate our method on fully-observable and\nvision-based partially-observable systems using cart-pole and autonomous\ndriving simulations using deep convolutional Bayesian neural networks. We\ndemonstrate that our method is robust to uncertainty resulting from varying\nsystem dynamics as well as from partial state observability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:47:29 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 00:46:27 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 03:37:16 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Lee", "Keuntaek", ""], ["Saigol", "Kamil", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1803.10232", "submitter": "Roxana Istrate Rox", "authors": "Roxana Istrate, Adelmo Cristiano Innocenza Malossi, Costas Bekas,\n  Dimitrios Nikolopoulos", "title": "Incremental Training of Deep Convolutional Neural Networks", "comments": null, "journal-ref": "http://ceur-ws.org/Vol-1998", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an incremental training method that partitions the original\nnetwork into sub-networks, which are then gradually incorporated in the running\nnetwork during the training process. To allow for a smooth dynamic growth of\nthe network, we introduce a look-ahead initialization that outperforms the\nrandom initialization. We demonstrate that our incremental approach reaches the\nreference network baseline accuracy. Additionally, it allows to identify\nsmaller partitions of the original state-of-the-art network, that deliver the\nsame final accuracy, by using only a fraction of the global number of\nparameters. This allows for a potential speedup of the training time of several\nfactors. We report training results on CIFAR-10 for ResNet and VGGNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 16:05:34 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Istrate", "Roxana", ""], ["Malossi", "Adelmo Cristiano Innocenza", ""], ["Bekas", "Costas", ""], ["Nikolopoulos", "Dimitrios", ""]]}, {"id": "1803.10254", "submitter": "Bryan Lim", "authors": "Bryan Lim and Mihaela van der Schaar", "title": "Disease-Atlas: Navigating Disease Trajectories with Deep Learning", "comments": "Accepted for publication in proceedings of the 3rd Machine Learning\n  for Healthcare Conference (MLHC 2018)", "journal-ref": "Proceedings of the 3rd Machine Learning for Healthcare Conference,\n  PMLR 85:137-160, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint models for longitudinal and time-to-event data are commonly used in\nlongitudinal studies to forecast disease trajectories over time. While there\nare many advantages to joint modeling, the standard forms suffer from\nlimitations that arise from a fixed model specification, and computational\ndifficulties when applied to high-dimensional datasets. In this paper, we\npropose a deep learning approach to address these limitations, enhancing\nexisting methods with the inherent flexibility and scalability of deep neural\nnetworks, while retaining the benefits of joint modeling. Using longitudinal\ndata from a real-world medical dataset, we demonstrate improvements in\nperformance and scalability, as well as robustness in the presence of\nirregularly sampled data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 18:03:02 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:27:13 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 17:10:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lim", "Bryan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1803.10266", "submitter": "Vitaly Feldman", "authors": "Cynthia Dwork and Vitaly Feldman", "title": "Privacy-preserving Prediction", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring differential privacy of models learned from sensitive user data is\nan important goal that has been studied extensively in recent years. It is now\nknown that for some basic learning problems, especially those involving\nhigh-dimensional data, producing an accurate private model requires much more\ndata than learning without privacy. At the same time, in many applications it\nis not necessary to expose the model itself. Instead users may be allowed to\nquery the prediction model on their inputs only through an appropriate\ninterface. Here we formulate the problem of ensuring privacy of individual\npredictions and investigate the overheads required to achieve it in several\nstandard models of classification and regression.\n  We first describe a simple baseline approach based on training several models\non disjoint subsets of data and using standard private aggregation techniques\nto predict. We show that this approach has nearly optimal sample complexity for\n(realizable) PAC learning of any class of Boolean functions. At the same time,\nwithout strong assumptions on the data distribution, the aggregation step\nintroduces a substantial overhead. We demonstrate that this overhead can be\navoided for the well-studied class of thresholds on a line and for a number of\nstandard settings of convex regression. The analysis of our algorithm for\nlearning thresholds relies crucially on strong generalization guarantees that\nwe establish for all differentially private prediction algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 18:40:05 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 00:36:56 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Dwork", "Cynthia", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1803.10274", "submitter": "Gustavo Ch\\'avez", "authors": "Elizaveta Rebrova, Gustavo Chavez, Yang Liu, Pieter Ghysels, Xiaoye\n  Sherry Li", "title": "A Study of Clustering Techniques and Hierarchical Matrix Formats for\n  Kernel Ridge Regression", "comments": "10 pages, 8 figures", "journal-ref": "IPDPS workshops 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present memory-efficient and scalable algorithms for kernel methods used\nin machine learning. Using hierarchical matrix approximations for the kernel\nmatrix the memory requirements, the number of floating point operations, and\nthe execution time are drastically reduced compared to standard dense linear\nalgebra routines. We consider both the general $\\mathcal{H}$ matrix\nhierarchical format as well as Hierarchically Semi-Separable (HSS) matrices.\nFurthermore, we investigate the impact of several preprocessing and clustering\ntechniques on the hierarchical matrix compression. Effective clustering of the\ninput leads to a ten-fold increase in efficiency of the compression. The\nalgorithms are implemented using the STRUMPACK solver library. These results\nconfirm that --- with correct tuning of the hyperparameters --- classification\nusing kernel ridge regression with the compressed matrix does not lose\nprediction accuracy compared to the exact --- not compressed --- kernel matrix\nand that our approach can be extended to $\\mathcal{O}(1M)$ datasets, for which\ncomputation with the full kernel matrix becomes prohibitively expensive. We\npresent numerical experiments in a distributed memory environment up to 1,024\nprocessors of the NERSC's Cori supercomputer using well-known datasets to the\nmachine learning community that range from dimension 8 up to 784.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 19:04:52 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Rebrova", "Elizaveta", ""], ["Chavez", "Gustavo", ""], ["Liu", "Yang", ""], ["Ghysels", "Pieter", ""], ["Li", "Xiaoye Sherry", ""]]}, {"id": "1803.10309", "submitter": "Jia Chen", "authors": "Jia Chen, Gang Wang, Yanning Shen, Georgios B. Giannakis", "title": "Canonical Correlation Analysis of Datasets with a Common Source Graph", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2853130", "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a powerful technique for discovering\nwhether or not hidden sources are commonly present in two (or more) datasets.\nIts well-appreciated merits include dimensionality reduction, clustering,\nclassification, feature selection, and data fusion. The standard CCA however,\ndoes not exploit the geometry of the common sources, which may be available\nfrom the given data or can be deduced from (cross-) correlations. In this\npaper, this extra information provided by the common sources generating the\ndata is encoded in a graph, and is invoked as a graph regularizer. This leads\nto a novel graph-regularized CCA approach, that is termed graph (g) CCA. The\nnovel gCCA accounts for the graph-induced knowledge of common sources, while\nminimizing the distance between the wanted canonical variables. Tailored for\ndiverse practical settings where the number of data is smaller than the data\nvector dimensions, the dual formulation of gCCA is also developed. One such\nsetting includes kernels that are incorporated to account for nonlinear data\ndependencies. The resultant graph-kernel (gk) CCA is also obtained in closed\nform. Finally, corroborating image classification tests over several real\ndatasets are presented to showcase the merits of the novel linear, dual, and\nkernel approaches relative to competing alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:36:26 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Chen", "Jia", ""], ["Wang", "Gang", ""], ["Shen", "Yanning", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1803.10311", "submitter": "Doris Xin", "authors": "Doris Xin, Litian Ma, Shuchen Song, Aditya Parameswaran", "title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the\n  Applied Machine Learning Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning workflow development is anecdotally regarded to be an\niterative process of trial-and-error with humans-in-the-loop. However, we are\nnot aware of quantitative evidence corroborating this popular belief. A\nquantitative characterization of iteration can serve as a benchmark for machine\nlearning workflow development in practice, and can aid the development of\nhuman-in-the-loop machine learning systems. To this end, we conduct a\nsmall-scale survey of the applied machine learning literature from five\ndistinct application domains. We collect and distill statistics on the role of\niteration within machine learning workflow development, and report preliminary\ntrends and insights from our investigation, as a starting point towards this\nbenchmark. Based on our findings, we finally describe desiderata for effective\nand versatile human-in-the-loop machine learning systems that can cater to\nusers in diverse domains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:38:05 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 22:16:31 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Xin", "Doris", ""], ["Ma", "Litian", ""], ["Song", "Shuchen", ""], ["Parameswaran", "Aditya", ""]]}, {"id": "1803.10342", "submitter": "Patrick Charbonneau", "authors": "Andrew E. Bruno, Patrick Charbonneau, Janet Newman, Edward H. Snell,\n  David R. So, Vincent Vanhoucke, Christopher J. Watkins, Shawn Williams, Julie\n  Wilson", "title": "Classification of crystallization outcomes using deep convolutional\n  neural networks", "comments": "11 pages, 4 figures, minor text and figure updates", "journal-ref": null, "doi": "10.1371/journal.pone.0198883", "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Machine Recognition of Crystallization Outcomes (MARCO) initiative has\nassembled roughly half a million annotated images of macromolecular\ncrystallization experiments from various sources and setups. Here,\nstate-of-the-art machine learning algorithms are trained and tested on\ndifferent parts of this data set. We find that more than 94% of the test images\ncan be correctly labeled, irrespective of their experimental origin. Because\ncrystal recognition is key to high-density screening and the systematic\nanalysis of crystallization experiments, this approach opens the door to both\nindustrial and fundamental research applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 22:03:20 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 02:28:35 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Bruno", "Andrew E.", ""], ["Charbonneau", "Patrick", ""], ["Newman", "Janet", ""], ["Snell", "Edward H.", ""], ["So", "David R.", ""], ["Vanhoucke", "Vincent", ""], ["Watkins", "Christopher J.", ""], ["Williams", "Shawn", ""], ["Wilson", "Julie", ""]]}, {"id": "1803.10358", "submitter": "Ervin Teng", "authors": "Ervin Teng, Rui Huang, Bob Iannucci", "title": "ClickBAIT-v2: Training an Object Detector in Real-Time", "comments": "8 pages, 13 figures. For ClickBAIT-v1, see arXiv:1709.05021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep convolutional neural networks (CNNs) for image classification and\nobject detection are often trained offline on large static datasets. Some\napplications, however, will require training in real-time on live video streams\nwith a human-in-the-loop. We refer to this class of problem as time-ordered\nonline training (ToOT). These problems will require a consideration of not only\nthe quantity of incoming training data, but the human effort required to\nannotate and use it. We demonstrate and evaluate a system tailored to training\nan object detector on a live video stream with minimal input from a human\noperator. We show that we can obtain bounding box annotation from\nweakly-supervised single-point clicks through interactive segmentation.\nFurthermore, by exploiting the time-ordered nature of the video stream through\nobject tracking, we can increase the average training benefit of human\ninteractions by 3-4 times.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 23:30:08 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Teng", "Ervin", ""], ["Huang", "Rui", ""], ["Iannucci", "Bob", ""]]}, {"id": "1803.10366", "submitter": "Gautam Goel", "authors": "Niangjun Chen, Gautam Goel, and Adam Wierman", "title": "Smoothed Online Convex Optimization in High Dimensions via Online\n  Balanced Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Smoothed Online Convex Optimization, a version of online convex\noptimization where the learner incurs a penalty for changing her actions\nbetween rounds. Given a $\\Omega(\\sqrt{d})$ lower bound on the competitive ratio\nof any online algorithm, where $d$ is the dimension of the action space, we ask\nunder what conditions this bound can be beaten. We introduce a novel\nalgorithmic framework for this problem, Online Balanced Descent (OBD), which\nworks by iteratively projecting the previous point onto a carefully chosen\nlevel set of the current cost function so as to balance the switching costs and\nhitting costs. We demonstrate the generality of the OBD framework by showing\nhow, with different choices of \"balance,\" OBD can improve upon state-of-the-art\nperformance guarantees for both competitive ratio and regret, in particular,\nOBD is the first algorithm to achieve a dimension-free competitive ratio, $3 +\nO(1/\\alpha)$, for locally polyhedral costs, where $\\alpha$ measures the\n\"steepness\" of the costs. We also prove bounds on the dynamic regret of OBD\nwhen the balance is performed in the dual space that are dimension-free and\nimply that OBD has sublinear static regret.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 00:39:33 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 13:14:17 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Chen", "Niangjun", ""], ["Goel", "Gautam", ""], ["Wierman", "Adam", ""]]}, {"id": "1803.10371", "submitter": "Aravind Rajeswaran", "authors": "Kendall Lowrey, Svetoslav Kolev, Jeremy Dao, Aravind Rajeswaran,\n  Emanuel Todorov", "title": "Reinforcement learning for non-prehensile manipulation: Transfer from\n  simulation to physical system", "comments": "Accepted at IEEE SIMPAR 2018. Project page:\n  https://sites.google.com/view/phantomsim2real", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has emerged as a promising methodology for training\nrobot controllers. However, most results have been limited to simulation due to\nthe need for a large number of samples and the lack of automated-yet-safe data\ncollection methods. Model-based reinforcement learning methods provide an\navenue to circumvent these challenges, but the traditional concern has been the\nmismatch between the simulator and the real world. Here, we show that control\npolicies learned in simulation can successfully transfer to a physical system,\ncomposed of three Phantom robots pushing an object to various desired target\npositions. We use a modified form of the natural policy gradient algorithm for\nlearning, applied to a carefully identified simulation model. The resulting\npolicies, trained entirely in simulation, work well on the physical system\nwithout additional training. In addition, we show that training with an\nensemble of models makes the learned policies more robust to modeling errors,\nthus compensating for difficulties in system identification.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 01:12:46 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Lowrey", "Kendall", ""], ["Kolev", "Svetoslav", ""], ["Dao", "Jeremy", ""], ["Rajeswaran", "Aravind", ""], ["Todorov", "Emanuel", ""]]}, {"id": "1803.10384", "submitter": "Yuan Gong", "authors": "Yuan Gong and Christian Poellabauer", "title": "Topic Modeling Based Multi-modal Depression Detection", "comments": "Proceedings of the 7th Audio/Visual Emotion Challenge and Workshop\n  (AVEC). (Official Depression Challenge Winner)", "journal-ref": null, "doi": "10.1145/3133944.3133945", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major depressive disorder is a common mental disorder that affects almost 7%\nof the adult U.S. population. The 2017 Audio/Visual Emotion Challenge (AVEC)\nasks participants to build a model to predict depression levels based on the\naudio, video, and text of an interview ranging between 7-33 minutes. Since\naveraging features over the entire interview will lose most temporal\ninformation, how to discover, capture, and preserve useful temporal details for\nsuch a long interview are significant challenges. Therefore, we propose a novel\ntopic modeling based approach to perform context-aware analysis of the\nrecording. Our experiments show that the proposed approach outperforms\ncontext-unaware methods and the challenge baselines for all metrics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:12:48 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1803.10397", "submitter": "Takeshi Inagaki", "authors": "Takeshi Inagaki", "title": "Supervising Unsupervised Learning with Evolutionary Algorithm in Deep\n  Neural Network", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to control results of gradient descent unsupervised learning in a\ndeep neural network by using evolutionary algorithm is proposed. To process\ncrossover of unsupervisedly trained models, the algorithm evaluates pointwise\nfitness of individual nodes in neural network. Labeled training data is\nrandomly sampled and breeding process selects nodes by calculating degree of\ntheir consistency on different sets of sampled data. This method supervises\nunsupervised training by evolutionary process. We also introduce modified\nRestricted Boltzmann Machine which contains repulsive force among nodes in a\nneural network and it contributes to isolate network nodes each other to avoid\naccidental degeneration of nodes by evolutionary process. These new methods are\napplied to document classification problem and it results better accuracy than\na traditional fully supervised classifier implemented with linear regression\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:20:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Inagaki", "Takeshi", ""]]}, {"id": "1803.10415", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Koby Crammer", "title": "A Better Resource Allocation Algorithm with Semi-Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a sequential resource allocation problem between a fixed number of\narms. On each iteration the algorithm distributes a resource among the arms in\norder to maximize the expected success rate. Allocating more of the resource to\na given arm increases the probability that it succeeds, yet with a cut-off. We\nfollow Lattimore et al. (2014) and assume that the probability increases\nlinearly until it equals one, after which allocating more of the resource is\nwasteful. These cut-off values are fixed and unknown to the learner. We present\nan algorithm for this problem and prove a regret upper bound of $O(\\log n)$\nimproving over the best known bound of $O(\\log^2 n)$. Lower bounds we prove\nshow that our upper bound is tight. Simulations demonstrate the superiority of\nour algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 05:05:24 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Dagan", "Yuval", ""], ["Crammer", "Koby", ""]]}, {"id": "1803.10459", "submitter": "Aditya Grover", "authors": "Aditya Grover, Aaron Zweig, Stefano Ermon", "title": "Graphite: Iterative Generative Modeling of Graphs", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a fundamental abstraction for modeling relational data. However,\ngraphs are discrete and combinatorial in nature, and learning representations\nsuitable for machine learning tasks poses statistical and computational\nchallenges. In this work, we propose Graphite, an algorithmic framework for\nunsupervised learning of representations over nodes in large graphs using deep\nlatent variable generative models. Our model parameterizes variational\nautoencoders (VAE) with graph neural networks, and uses a novel iterative graph\nrefinement strategy inspired by low-rank approximations for decoding. On a wide\nvariety of synthetic and benchmark datasets, Graphite outperforms competing\napproaches for the tasks of density estimation, link prediction, and node\nclassification. Finally, we derive a theoretical connection between message\npassing in graph neural networks and mean-field variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:37:25 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 08:15:20 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 06:02:17 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 07:13:30 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Grover", "Aditya", ""], ["Zweig", "Aaron", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10470", "submitter": "Jaan Aru", "authors": "Jaan Aru and Raul Vicente", "title": "What deep learning can tell us about higher cognitive functions like\n  mindreading?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can deep learning (DL) guide our understanding of computations happening in\nbiological brain? We will first briefly consider how DL has contributed to the\nresearch on visual object recognition. In the main part we will assess whether\nDL could also help us to clarify the computations underlying higher cognitive\nfunctions such as Theory of Mind. In addition, we will compare the objectives\nand learning signals of brains and machines, leading us to conclude that simply\nscaling up the current DL algorithms will most likely not lead to human level\nTheory of Mind.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:58:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 05:44:47 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Aru", "Jaan", ""], ["Vicente", "Raul", ""]]}, {"id": "1803.10520", "submitter": "Joseph Fitzsimons", "authors": "Zhikuan Zhao, Jack K. Fitzsimons, Michael A. Osborne, Stephen J.\n  Roberts and Joseph F. Fitzsimons", "title": "Quantum algorithms for training Gaussian Processes", "comments": "5 pages. Comments welcome", "journal-ref": "Phys. Rev. A 100, 012304 (2019)", "doi": "10.1103/PhysRevA.100.012304", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are important models in supervised machine learning.\nTraining in Gaussian processes refers to selecting the covariance functions and\nthe associated parameters in order to improve the outcome of predictions, the\ncore of which amounts to evaluating the logarithm of the marginal likelihood\n(LML) of a given model. LML gives a concrete measure of the quality of\nprediction that a GP model is expected to achieve. The classical computation of\nLML typically carries a polynomial time overhead with respect to the input\nsize. We propose a quantum algorithm that computes the logarithm of the\ndeterminant of a Hermitian matrix, which runs in logarithmic time for sparse\nmatrices. This is applied in conjunction with a variant of the quantum linear\nsystem algorithm that allows for logarithmic time computation of the form\n$\\mathbf{y}^TA^{-1}\\mathbf{y}$, where $\\mathbf{y}$ is a dense vector and $A$ is\nthe covariance matrix. We hence show that quantum computing can be used to\nestimate the LML of a GP with exponentially improved efficiency under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 10:53:37 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Zhao", "Zhikuan", ""], ["Fitzsimons", "Jack K.", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1803.10525", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Machine Speech Chain with One-shot Speaker Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, we developed a closed-loop speech chain model based on deep\nlearning, in which the architecture enabled the automatic speech recognition\n(ASR) and text-to-speech synthesis (TTS) components to mutually improve their\nperformance. This was accomplished by the two parts teaching each other using\nboth labeled and unlabeled data. This approach could significantly improve\nmodel performance within a single-speaker speech dataset, but only a slight\nincrease could be gained in multi-speaker tasks. Furthermore, the model is\nstill unable to handle unseen speakers. In this paper, we present a new speech\nchain mechanism by integrating a speaker recognition model inside the loop. We\nalso propose extending the capability of TTS to handle unseen speakers by\nimplementing one-shot speaker adaptation. This enables TTS to mimic voice\ncharacteristics from one speaker to another with only a one-shot speaker\nsample, even from a text without any speaker information. In the speech chain\nloop mechanism, ASR also benefits from the ability to further learn an\narbitrary speaker's characteristics from the generated speech waveform,\nresulting in a significant improvement in the recognition rate.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 11:06:15 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1803.10554", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "Joint PLDA for Simultaneous Modeling of Two Factors", "comments": "Submitted to Journal of Machine Learning Research", "journal-ref": "Journal of Machine Learning Research, January, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic linear discriminant analysis (PLDA) is a method used for\nbiometric problems like speaker or face recognition that models the variability\nof the samples using two latent variables, one that depends on the class of the\nsample and another one that is assumed independent across samples and models\nthe within-class variability. In this work, we propose a generalization of PLDA\nthat enables joint modeling of two sample-dependent factors: the class of\ninterest and a nuisance condition. The approach does not change the basic form\nof PLDA but rather modifies the training procedure to consider the dependency\nacross samples of the latent variable that models within-class variability.\nWhile the identity of the nuisance condition is needed during training, it is\nnot needed during testing since we propose a scoring procedure that\nmarginalizes over the corresponding latent variable. We show results on a\nmultilingual speaker-verification task, where the language spoken is considered\na nuisance condition. We show that the proposed joint PLDA approach leads to\nsignificant performance gains in this task for two different datasets, in\nparticular when the training data contains mostly or only monolingual speakers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:11:56 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "1803.10560", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov, Boris Flach", "title": "Normalization of Neural Networks using Analytic Variance Propagation", "comments": null, "journal-ref": "In Proceedings of Computer Vision Winter Workshop 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:37:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "1803.10586", "submitter": "Tobias Pl\\\"otz", "authors": "Tobias Pl\\\"otz, Anne S. Wannenwetsch, Stefan Roth", "title": "Stochastic Variational Inference with Gradient Linearization", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference has experienced a recent surge in popularity owing to\nstochastic approaches, which have yielded practical tools for a wide range of\nmodel classes. A key benefit is that stochastic variational inference obviates\nthe tedious process of deriving analytical expressions for closed-form variable\nupdates. Instead, one simply needs to derive the gradient of the log-posterior,\nwhich is often much easier. Yet for certain model classes, the log-posterior\nitself is difficult to optimize using standard gradient techniques. One such\nexample are random field models, where optimization based on gradient\nlinearization has proven popular, since it speeds up convergence significantly\nand can avoid poor local optima. In this paper we propose stochastic\nvariational inference with gradient linearization (SVIGL). It is similarly\nconvenient as standard stochastic variational inference - all that is required\nis a local linearization of the energy gradient. Its benefit over stochastic\nvariational inference with conventional gradient methods is a clear improvement\nin convergence speed, while yielding comparable or even better variational\napproximations in terms of KL divergence. We demonstrate the benefits of SVIGL\nin three applications: Optical flow estimation, Poisson-Gaussian denoising, and\n3D surface reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:22:57 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Pl\u00f6tz", "Tobias", ""], ["Wannenwetsch", "Anne S.", ""], ["Roth", "Stefan", ""]]}, {"id": "1803.10590", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Boris Flach and Michal Busta", "title": "Feed-forward Uncertainty Propagation in Belief and Neural Networks", "comments": "error corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a feed-forward inference method applicable to belief and neural\nnetworks. In a belief network, the method estimates an approximate factorized\nposterior of all hidden units given the input. In neural networks the method\npropagates uncertainty of the input through all the layers. In neural networks\nwith injected noise, the method analytically takes into account uncertainties\nresulting from this noise. Such feed-forward analytic propagation is\ndifferentiable in parameters and can be trained end-to-end. Compared to\nstandard NN, which can be viewed as propagating only the means, we propagate\nthe mean and variance. The method can be useful in all scenarios that require\nknowledge of the neuron statistics, e.g. when dealing with uncertain inputs,\nconsidering sigmoid activations as probabilities of Bernoulli units, training\nthe models regularized by injected noise (dropout) or estimating activation\nstatistics over the dataset (as needed for normalization methods). In the\nexperiments we show the possible utility of the method in all these tasks as\nwell as its current limitations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:26:47 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:02:02 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""], ["Busta", "Michal", ""]]}, {"id": "1803.10639", "submitter": "Hasan Abasi", "authors": "Hasan Abasi, Nader H. Bshouty", "title": "On Learning Graphs with Edge-Detecting Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a general graph $G=(V,E)$ using\nedge-detecting queries, where the number of vertices $|V|=n$ is given to the\nlearner. The information theoretic lower bound gives $m\\log n$ for the number\nof queries, where $m=|E|$ is the number of edges. In case the number of edges\n$m$ is also given to the learner, Angluin-Chen's Las Vegas algorithm\n\\cite{AC08} runs in $4$ rounds and detects the edges in $O(m\\log n)$ queries.\nIn the other harder case where the number of edges $m$ is unknown, their\nalgorithm runs in $5$ rounds and asks $O(m\\log n+\\sqrt{m}\\log^2 n)$ queries.\nThere have been two open problems: \\emph{(i)} can the number of queries be\nreduced to $O(m\\log n)$ in the second case, and, \\emph{(ii)} can the number of\nrounds be reduced without substantially increasing the number of queries (in\nboth cases). For the first open problem (when $m$ is unknown) we give two\nalgorithms. The first is an $O(1)$-round Las Vegas algorithm that asks $m\\log\nn+\\sqrt{m}(\\log^{[k]}n)\\log n$ queries for any constant $k$ where\n$\\log^{[k]}n=\\log \\stackrel{k}{\\cdots} \\log n$. The second is an\n$O(\\log^*n)$-round Las Vegas algorithm that asks $O(m\\log n)$ queries. This\nsolves the first open problem for any practical $n$, for example,\n$n<2^{65536}$. We also show that no deterministic algorithm can solve this\nproblem in a constant number of rounds. To solve the second problem we study\nthe case when $m$ is known. We first show that any non-adaptive Monte Carlo\nalgorithm (one-round) must ask at least $\\Omega(m^2\\log n)$ queries, and any\ntwo-round Las Vegas algorithm must ask at least $m^{4/3-o(1)}\\log n$ queries on\naverage. We then give two two-round Monte Carlo algorithms, the first asks\n$O(m^{4/3}\\log n)$ queries for any $n$ and $m$, and the second asks $O(m\\log\nn)$ queries when $n>2^m$. Finally, we give a $3$-round Monte Carlo algorithm\nthat asks $O(m\\log n)$ queries for any $n$ and $m$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:20:17 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Abasi", "Hasan", ""], ["Bshouty", "Nader H.", ""]]}, {"id": "1803.10647", "submitter": "Martin Tak\\'a\\v{c}", "authors": "Krishnan Kumaran, Dimitri Papageorgiou, Yutong Chang, Minhan Li,\n  Martin Tak\\'a\\v{c}", "title": "Active Metric Learning for Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering and classification critically rely on distance metrics that\nprovide meaningful comparisons between data points. We present mixed-integer\noptimization approaches to find optimal distance metrics that generalize the\nMahalanobis metric extensively studied in the literature. Additionally, we\ngeneralize and improve upon leading methods by removing reliance on\npre-designated \"target neighbors,\" \"triplets,\" and \"similarity pairs.\" Another\nsalient feature of our method is its ability to enable active learning by\nrecommending precise regions to sample after an optimal metric is computed to\nimprove classification performance. This targeted acquisition can significantly\nreduce computational burden by ensuring training data completeness,\nrepresentativeness, and economy. We demonstrate classification and\ncomputational performance of the algorithms through several simple and\nintuitive examples, followed by results on real image and medical datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:36:37 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kumaran", "Krishnan", ""], ["Papageorgiou", "Dimitri", ""], ["Chang", "Yutong", ""], ["Li", "Minhan", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1803.10705", "submitter": "Djordje Gligorijevic", "authors": "Jelena Stojanovic, Milos Jovanovic, Djordje Gligorijevic and Zoran\n  Obradovic", "title": "Semi-supervised learning for structured regression on partially observed\n  attributed graphs", "comments": "Proceedings of the 2015 SIAM International Conference on Data Mining\n  (SDM 2015) Vancouver, Canada, April 30 - May 02, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional probabilistic graphical models provide a powerful framework for\nstructured regression in spatio-temporal datasets with complex correlation\npatterns. However, in real-life applications a large fraction of observations\nis often missing, which can severely limit the representational power of these\nmodels. In this paper we propose a Marginalized Gaussian Conditional Random\nFields (m-GCRF) structured regression model for dealing with missing labels in\npartially observed temporal attributed graphs. This method is aimed at learning\nwith both labeled and unlabeled parts and effectively predicting future values\nin a graph. The method is even capable of learning from nodes for which the\nresponse variable is never observed in history, which poses problems for many\nstate-of-the-art models that can handle missing data. The proposed model is\ncharacterized for various missingness mechanisms on 500 synthetic graphs. The\nbenefits of the new method are also demonstrated on a challenging application\nfor predicting precipitation based on partial observations of climate variables\nin a temporal graph that spans the entire continental US. We also show that the\nmethod can be useful for optimizing the costs of data collection in climate\napplications via active reduction of the number of weather stations to\nconsider. In experiments on these real-world and synthetic datasets we show\nthat the proposed model is consistently more accurate than alternative\nsemi-supervised structured models, as well as models that either use imputation\nto deal with missing values or simply ignore them altogether.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 16:16:14 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Stojanovic", "Jelena", ""], ["Jovanovic", "Milos", ""], ["Gligorijevic", "Djordje", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.10743", "submitter": "Taco Cohen", "authors": "Taco S. Cohen and Mario Geiger and Maurice Weiler", "title": "Intertwiners between Induced Representations (with Applications to the\n  Theory of Equivariant Neural Networks)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group equivariant and steerable convolutional neural networks (regular and\nsteerable G-CNNs) have recently emerged as a very effective model class for\nlearning from signal data such as 2D and 3D images, video, and other data where\nsymmetries are present. In geometrical terms, regular G-CNNs represent data in\nterms of scalar fields (\"feature channels\"), whereas the steerable G-CNN can\nalso use vector or tensor fields (\"capsules\") to represent data. In algebraic\nterms, the feature spaces in regular G-CNNs transform according to a regular\nrepresentation of the group G, whereas the feature spaces in Steerable G-CNNs\ntransform according to the more general induced representations of G. In order\nto make the network equivariant, each layer in a G-CNN is required to\nintertwine between the induced representations associated with its input and\noutput space.\n  In this paper we present a general mathematical framework for G-CNNs on\nhomogeneous spaces like Euclidean space or the sphere. We show, using\nelementary methods, that the layers of an equivariant network are convolutional\nif and only if the input and output feature spaces transform according to an\ninduced representation. This result, which follows from G.W. Mackey's abstract\ntheory on induced representations, establishes G-CNNs as a universal class of\nequivariant network architectures, and generalizes the important recent work of\nKondor & Trivedi on the intertwiners between regular representations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:30:26 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 09:27:16 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Cohen", "Taco S.", ""], ["Geiger", "Mario", ""], ["Weiler", "Maurice", ""]]}, {"id": "1803.10746", "submitter": "Charles Gadd", "authors": "Charles Gadd, Sara Wade, Akeel Shah, Dimitris Grammatopoulos", "title": "Pseudo-marginal Bayesian inference for supervised Gaussian process\n  latent variable models", "comments": "9 pages, 2 figures, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian framework for inference with a supervised version of\nthe Gaussian process latent variable model. The framework overcomes the high\ncorrelations between latent variables and hyperparameters by using an unbiased\npseudo estimate for the marginal likelihood that approximately integrates over\nthe latent variables. This is used to construct a Markov Chain to explore the\nposterior of the hyperparameters. We demonstrate the procedure on simulated and\nreal examples, showing its ability to capture uncertainty and multimodality of\nthe hyperparameters and improved uncertainty quantification in predictions when\ncompared with variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:31:12 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gadd", "Charles", ""], ["Wade", "Sara", ""], ["Shah", "Akeel", ""], ["Grammatopoulos", "Dimitris", ""]]}, {"id": "1803.10750", "submitter": "Vasileios Belagiannis", "authors": "Vasileios Belagiannis, Azade Farshad, Fabio Galasso", "title": "Adversarial Network Compression", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network compression has recently received much attention due to the\ncomputational requirements of modern deep models. In this work, our objective\nis to transfer knowledge from a deep and accurate model to a smaller one. Our\ncontributions are threefold: (i) we propose an adversarial network compression\napproach to train the small student network to mimic the large teacher, without\nthe need for labels during training; (ii) we introduce a regularization scheme\nto prevent a trivially-strong discriminator without reducing the network\ncapacity and (iii) our approach generalizes on different teacher-student\nmodels.\n  In an extensive evaluation on five standard datasets, we show that our\nstudent has small accuracy drop, achieves better performance than other\nknowledge transfer approaches and it surpasses the performance of the same\nnetwork trained with labels. In addition, we demonstrate state-of-the-art\nresults compared to other compression strategies.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:38:20 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 17:25:53 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Belagiannis", "Vasileios", ""], ["Farshad", "Azade", ""], ["Galasso", "Fabio", ""]]}, {"id": "1803.10760", "submitter": "Greg Wayne", "authors": "Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja,\n  Agnieszka Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel Z. Leibo, Adam\n  Santoro, Mevlana Gemici, Malcolm Reynolds, Tim Harley, Josh Abramson, Shakir\n  Mohamed, Danilo Rezende, David Saxton, Adam Cain, Chloe Hillier, David\n  Silver, Koray Kavukcuoglu, Matt Botvinick, Demis Hassabis, Timothy Lillicrap", "title": "Unsupervised Predictive Memory in a Goal-Directed Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals execute goal-directed behaviours despite the limited range and scope\nof their sensors. To cope, they explore environments and store memories\nmaintaining estimates of important information that is not presently available.\nRecently, progress has been made with artificial intelligence (AI) agents that\nlearn to perform tasks from sensory input, even at a human level, by merging\nreinforcement learning (RL) algorithms with deep neural networks, and the\nexcitement surrounding these results has led to the pursuit of related ideas as\nexplanations of non-human animal learning. However, we demonstrate that\ncontemporary RL algorithms struggle to solve simple tasks when enough\ninformation is concealed from the sensors of the agent, a property called\n\"partial observability\". An obvious requirement for handling partially observed\ntasks is access to extensive memory, but we show memory is not enough; it is\ncritical that the right information be stored in the right format. We develop a\nmodel, the Memory, RL, and Inference Network (MERLIN), in which memory\nformation is guided by a process of predictive modeling. MERLIN facilitates the\nsolution of tasks in 3D virtual reality environments for which partial\nobservability is severe and memories must be maintained over long durations.\nOur model demonstrates a single learning agent architecture that can solve\ncanonical behavioural tasks in psychology and neurobiology without strong\nsimplifying assumptions about the dimensionality of sensory input or the\nduration of experiences.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:54:01 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Wayne", "Greg", ""], ["Hung", "Chia-Chun", ""], ["Amos", "David", ""], ["Mirza", "Mehdi", ""], ["Ahuja", "Arun", ""], ["Grabska-Barwinska", "Agnieszka", ""], ["Rae", "Jack", ""], ["Mirowski", "Piotr", ""], ["Leibo", "Joel Z.", ""], ["Santoro", "Adam", ""], ["Gemici", "Mevlana", ""], ["Reynolds", "Malcolm", ""], ["Harley", "Tim", ""], ["Abramson", "Josh", ""], ["Mohamed", "Shakir", ""], ["Rezende", "Danilo", ""], ["Saxton", "David", ""], ["Cain", "Adam", ""], ["Hillier", "Chloe", ""], ["Silver", "David", ""], ["Kavukcuoglu", "Koray", ""], ["Botvinick", "Matt", ""], ["Hassabis", "Demis", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1803.10768", "submitter": "Finn Macleod Dr", "authors": "Finn Macleod", "title": "Unreasonable Effectivness of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how well known rules of back propagation arise from a weighted\ncombination of finite automata. By redefining a finite automata as a predictor\nwe combine the set of all $k$-state finite automata using a weighted majority\nalgorithm. This aggregated prediction algorithm can be simplified using\nsymmetry, and we prove the equivalence of an algorithm that does this. We\ndemonstrate that this algorithm is equivalent to a form of a back propagation\nacting in a completely connected $k$-node neural network. Thus the use of the\nweighted majority algorithm allows a bound on the general performance of deep\nlearning approaches to prediction via known results from online statistics. The\npresented framework opens more detailed questions about network topology; it is\na bridge to the well studied techniques of semigroup theory and applying these\ntechniques to answer what specific network topologies are capable of\npredicting. This informs both the design of artificial networks and the\nexploration of neuroscience models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:29:30 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Macleod", "Finn", ""]]}, {"id": "1803.10769", "submitter": "Benajmin Radford J", "authors": "Benjamin J. Radford, Leonardo M. Apolonio, Antonio J. Trias, Jim A.\n  Simpson", "title": "Network Traffic Anomaly Detection Using Recurrent Neural Networks", "comments": "Prepared for the 2017 National Symposium on Sensor and Data Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a recurrent neural network is able to learn a model to represent\nsequences of communications between computers on a network and can be used to\nidentify outlier network traffic. Defending computer networks is a challenging\nproblem and is typically addressed by manually identifying known malicious\nactor behavior and then specifying rules to recognize such behavior in network\ncommunications. However, these rule-based approaches often generalize poorly\nand identify only those patterns that are already known to researchers. An\nalternative approach that does not rely on known malicious behavior patterns\ncan potentially also detect previously unseen patterns. We tokenize and\ncompress netflow into sequences of \"words\" that form \"sentences\" representative\nof a conversation between computers. These sentences are then used to generate\na model that learns the semantic and syntactic grammar of the newly generated\nlanguage. We use Long-Short-Term Memory (LSTM) cell Recurrent Neural Networks\n(RNN) to capture the complex relationships and nuances of this language. The\nlanguage model is then used predict the communications between two IPs and the\nprediction error is used as a measurement of how typical or atyptical the\nobserved communication are. By learning a model that is specific to each\nnetwork, yet generalized to typical computer-to-computer traffic within and\noutside the network, a language model is able to identify sequences of network\nactivity that are outliers with respect to the model. We demonstrate positive\nunsupervised attack identification performance (AUC 0.84) on the ISCX IDS\ndataset which contains seven days of network activity with normal traffic and\nfour distinct attack patterns.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:49:25 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Radford", "Benjamin J.", ""], ["Apolonio", "Leonardo M.", ""], ["Trias", "Antonio J.", ""], ["Simpson", "Jim A.", ""]]}, {"id": "1803.10799", "submitter": "Djordje Gligorijevic", "authors": "Jelena Stojanovic, Djordje Gligorijevic and Zoran Obradovic", "title": "Modeling Customer Engagement from Partial Observations", "comments": "Proceedings of the 25th ACM International Conference on Information\n  and Knowledge Management (CIKM 2016), Indianapolis, United States October 24\n  - 28, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of high interest for a company to identify customers expected to bring\nthe largest profit in the upcoming period. Knowing as much as possible about\neach customer is crucial for such predictions. However, their demographic data,\npreferences, and other information that might be useful for building loyalty\nprograms is often missing. Additionally, modeling relations among different\ncustomers as a network can be beneficial for predictions at an individual\nlevel, as similar customers tend to have similar purchasing patterns. We\naddress this problem by proposing a robust framework for structured regression\non deficient data in evolving networks with a supervised representation\nlearning based on neural features embedding. The new method is compared to\nseveral unstructured and structured alternatives for predicting customer\nbehavior (e.g. purchasing frequency and customer ticket) on user networks\ngenerated from customer databases of two companies from different industries.\nThe obtained results show $4\\%$ to $130\\%$ improvement in accuracy over\nalternatives when all customer information is known. Additionally, the\nrobustness of our method is demonstrated when up to $80\\%$ of demographic\ninformation was missing where it was up to several folds more accurate as\ncompared to alternatives that are either ignoring cases with missing values or\nlearn their feature representation in an unsupervised manner.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 18:49:07 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Stojanovic", "Jelena", ""], ["Gligorijevic", "Djordje", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.10806", "submitter": "Louis-\\'Emile Robitaille", "authors": "Louis-\\'Emile Robitaille, Audrey Durand, Marc-Andr\\'e Gardner,\n  Christian Gagn\\'e, Paul De Koninck, Flavie Lavoie-Cardinal", "title": "Learning to Become an Expert: Deep Networks Applied To Super-Resolution\n  Microscopy", "comments": "Accepted to the Thirtieth Innovative Applications of Artificial\n  Intelligence Conference (IAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With super-resolution optical microscopy, it is now possible to observe\nmolecular interactions in living cells. The obtained images have a very high\nspatial precision but their overall quality can vary a lot depending on the\nstructure of interest and the imaging parameters. Moreover, evaluating this\nquality is often difficult for non-expert users. In this work, we tackle the\nproblem of learning the quality function of super- resolution images from\nscores provided by experts. More specifically, we are proposing a system based\non a deep neural network that can provide a quantitative quality measure of a\nSTED image of neuronal structures given as input. We conduct a user study in\norder to evaluate the quality of the predictions of the neural network against\nthose of a human expert. Results show the potential while highlighting some of\nthe limits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:01:45 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Robitaille", "Louis-\u00c9mile", ""], ["Durand", "Audrey", ""], ["Gardner", "Marc-Andr\u00e9", ""], ["Gagn\u00e9", "Christian", ""], ["De Koninck", "Paul", ""], ["Lavoie-Cardinal", "Flavie", ""]]}, {"id": "1803.10815", "submitter": "Piotr Mardziel", "authors": "Shayak Sen and Piotr Mardziel and Anupam Datta and Matthew Fredrikson", "title": "Supervising Feature Influence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal influence measures for machine learnt classifiers shed light on the\nreasons behind classification, and aid in identifying influential input\nfeatures and revealing their biases. However, such analyses involve evaluating\nthe classifier using datapoints that may be atypical of its training\ndistribution. Standard methods for training classifiers that minimize empirical\nrisk do not constrain the behavior of the classifier on such datapoints. As a\nresult, training to minimize empirical risk does not distinguish among\nclassifiers that agree on predictions in the training distribution but have\nwildly different causal influences. We term this problem covariate shift in\ncausal testing and formally characterize conditions under which it arises. As a\nsolution to this problem, we propose a novel active learning algorithm that\nconstrains the influence measures of the trained model. We prove that any two\npredictors whose errors are close on both the original training distribution\nand the distribution of atypical points are guaranteed to have causal\ninfluences that are also close. Further, we empirically demonstrate with\nsynthetic labelers that our algorithm trains models that (i) have similar\ncausal influences as the labeler's model, and (ii) generalize better to\nout-of-distribution points while (iii) retaining their accuracy on\nin-distribution points.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:16:39 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 23:46:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Sen", "Shayak", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matthew", ""]]}, {"id": "1803.10837", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis and Anastasios Tefas", "title": "Learning Deep Representations with Probabilistic Knowledge Transfer", "comments": "Accepted at ECCV2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer (KT) techniques tackle the problem of transferring the\nknowledge from a large and complex neural network into a smaller and faster\none. However, existing KT methods are tailored towards classification tasks and\nthey cannot be used efficiently for other representation learning tasks. In\nthis paper a novel knowledge transfer technique, that is capable of training a\nstudent model that maintains the same amount of mutual information between the\nlearned representation and a set of (possible unknown) labels as the teacher\nmodel, is proposed. Apart from outperforming existing KT techniques, the\nproposed method allows for overcoming several limitations of existing methods\nproviding new insight into KT as well as novel KT applications, ranging from\nknowledge transfer from handcrafted feature extractors to {cross-modal} KT from\nthe textual modality into the representation extracted from the visual modality\nof the data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:14:08 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 19:03:32 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 07:45:15 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "1803.10840", "submitter": "Uri Shaham", "authors": "Uri Shaham, James Garritano, Yutaro Yamada, Ethan Weinberger, Alex\n  Cloninger, Xiuyuan Cheng, Kelly Stanton, Yuval Kluger", "title": "Defending against Adversarial Images using Basis Functions\n  Transformations", "comments": "added link to GitHub repository", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of various approaches that defend against\nadversarial attacks on deep networks via manipulations based on basis function\nrepresentations of images. Specifically, we experiment with low-pass filtering,\nPCA, JPEG compression, low resolution wavelet approximation, and\nsoft-thresholding. We evaluate these defense techniques using three types of\npopular attacks in black, gray and white-box settings. Our results show JPEG\ncompression tends to outperform the other tested defenses in most of the\nsettings considered, in addition to soft-thresholding, which performs well in\nspecific cases, and yields a more mild decrease in accuracy on benign examples.\nIn addition, we also mathematically derive a novel white-box attack in which\nthe adversarial perturbation is composed only of terms corresponding a to\npre-determined subset of the basis functions, of which a \"low frequency attack\"\nis a special case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:27:58 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 22:14:16 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 18:44:46 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Shaham", "Uri", ""], ["Garritano", "James", ""], ["Yamada", "Yutaro", ""], ["Weinberger", "Ethan", ""], ["Cloninger", "Alex", ""], ["Cheng", "Xiuyuan", ""], ["Stanton", "Kelly", ""], ["Kluger", "Yuval", ""]]}, {"id": "1803.10846", "submitter": "Yu Cheng", "authors": "Yu Cheng, Rong Ge", "title": "Non-Convex Matrix Completion Against a Semi-Random Adversary", "comments": "added references and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a well-studied problem with many machine learning\napplications. In practice, the problem is often solved by non-convex\noptimization algorithms. However, the current theoretical analysis for\nnon-convex algorithms relies heavily on the assumption that every entry is\nobserved with exactly the same probability $p$, which is not realistic in\npractice.\n  In this paper, we investigate a more realistic semi-random model, where the\nprobability of observing each entry is at least $p$. Even with this mild\nsemi-random perturbation, we can construct counter-examples where existing\nnon-convex algorithms get stuck in bad local optima.\n  In light of the negative results, we propose a pre-processing step that tries\nto re-weight the semi-random input, so that it becomes \"similar\" to a random\ninput. We give a nearly-linear time algorithm for this problem, and show that\nafter our pre-processing, all the local minima of the non-convex objective can\nbe used to approximately recover the underlying ground-truth matrix.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:46:27 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 19:11:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Cheng", "Yu", ""], ["Ge", "Rong", ""]]}, {"id": "1803.10888", "submitter": "Kostas Hatalis", "authors": "Kostas Hatalis, Shalinee Kishore, Katya Scheinberg, Alberto Lamadrid", "title": "An Empirical Analysis of Constrained Support Vector Quantile Regression\n  for Nonparametric Probabilistic Forecasting of Wind Power", "comments": "Originally published at The AAAI-17 Workshop on Artificial\n  Intelligence for Smart Grids and Smart Buildings", "journal-ref": "Thirty-First AAAI Conference on Artificial Intelligence, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty analysis in the form of probabilistic forecasting can provide\nsignificant improvements in decision-making processes in the smart power grid\nfor better integrating renewable energies such as wind. Whereas point\nforecasting provides a single expected value, probabilistic forecasts provide\nmore information in the form of quantiles, prediction intervals, or full\npredictive densities. This paper analyzes the effectiveness of an approach for\nnonparametric probabilistic forecasting of wind power that combines support\nvector machines and nonlinear quantile regression with non-crossing\nconstraints. A numerical case study is conducted using publicly available wind\ndata from the Global Energy Forecasting Competition 2014. Multiple quantiles\nare estimated to form 20%, 40%, 60% and 80% prediction intervals which are\nevaluated using the pinball loss function and reliability measures. Three\nbenchmark models are used for comparison where results demonstrate the proposed\napproach leads to significantly better performance while preventing the problem\nof overlapping quantile estimates.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 01:05:54 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Hatalis", "Kostas", ""], ["Kishore", "Shalinee", ""], ["Scheinberg", "Katya", ""], ["Lamadrid", "Alberto", ""]]}, {"id": "1803.10927", "submitter": "Amir Hossein Akhavan Rahnama", "authors": "Amir Hossein Akhavan Rahnama, Mehdi Toloo, Nezer Jacob Zaidenberg", "title": "An LP-based hyperparameter optimization model for language modeling", "comments": null, "journal-ref": "The Journal of Supercomputing (2018)", "doi": "10.1007/s11227-018-2236-6", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to find hyperparameters for a machine learning model, algorithms\nsuch as grid search or random search are used over the space of possible values\nof the models hyperparameters. These search algorithms opt the solution that\nminimizes a specific cost function. In language models, perplexity is one of\nthe most popular cost functions. In this study, we propose a fractional\nnonlinear programming model that finds the optimal perplexity value. The\nspecial structure of the model allows us to approximate it by a linear\nprogramming model that can be solved using the well-known simplex algorithm. To\nthe best of our knowledge, this is the first attempt to use optimization\ntechniques to find perplexity values in the language modeling literature. We\napply our model to find hyperparameters of a language model and compare it to\nthe grid search algorithm. Furthermore, we illustrating that it results in\nlower perplexity values. We perform this experiment on a real-world dataset\nfrom SwiftKey to validate our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 05:15:36 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Rahnama", "Amir Hossein Akhavan", ""], ["Toloo", "Mehdi", ""], ["Zaidenberg", "Nezer Jacob", ""]]}, {"id": "1803.10930", "submitter": "Hideo Terada", "authors": "Hideo Terada, Hayaru Shouno", "title": "B-DCGAN:Evaluation of Binarized DCGAN for FPGA", "comments": "10 pages", "journal-ref": null, "doi": "10.1007/978-3-030-36708-4_5", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are trying to implement deep neural networks in the edge computing\nenvironment for real-world applications such as the IoT(Internet of Things),\nthe FinTech etc., for the purpose of utilizing the significant achievement of\nDeep Learning in recent years. Especially, we now focus algorithm\nimplementation on FPGA, because FPGA is one of the promising devices for\nlow-cost and low-power implementation of the edge computer. In this work, we\nintroduce Binary-DCGAN(B-DCGAN) - Deep Convolutional GAN model with binary\nweights and activations, and with using integer-valued operations in forward\npass(train-time and run-time). And we show how to implement B-DCGAN on\nFPGA(Xilinx Zynq). Using the B-DCGAN, we do feasibility study of FPGA's\ncharacteristic and performance for Deep Learning. Because the binarization and\nusing integer-valued operation reduce the memory capacity and the number of the\ncircuit gates, it is very effective for FPGA implementation. On the other hand,\nthe quality of generated data from the model will be decreased by these\nreductions. So we investigate the influence of these reductions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 05:43:23 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 08:57:41 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Terada", "Hideo", ""], ["Shouno", "Hayaru", ""]]}, {"id": "1803.10937", "submitter": "Aditya Grover", "authors": "Aditya Grover, Todor Markov, Peter Attia, Norman Jin, Nicholas\n  Perkins, Bryan Cheong, Michael Chen, Zi Yang, Stephen Harris, William Chueh,\n  Stefano Ermon", "title": "Best arm identification in multi-armed bandits with delayed feedback", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 06:46:38 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grover", "Aditya", ""], ["Markov", "Todor", ""], ["Attia", "Peter", ""], ["Jin", "Norman", ""], ["Perkins", "Nicholas", ""], ["Cheong", "Bryan", ""], ["Chen", "Michael", ""], ["Yang", "Zi", ""], ["Harris", "Stephen", ""], ["Chueh", "William", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10986", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz, Andrew Anderson, Kirk M. Soodhalter and David Gregg", "title": "Error Analysis and Improving the Accuracy of Winograd Convolution for\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular deep neural networks (DNNs) spend the majority of their execution\ntime computing convolutions. The Winograd family of algorithms can greatly\nreduce the number of arithmetic operations required and is present in many DNN\nsoftware frameworks. However, the performance gain is at the expense of a\nreduction in floating point (FP) numerical accuracy. In this paper, we analyse\nthe worst case FP error and prove the estimation of norm and conditioning of\nthe algorithm. We show that the bound grows exponentially with the size of the\nconvolution, but the error bound of the \\textit{modified} algorithm is smaller\nthan the original one. We propose several methods for reducing FP error. We\npropose a canonical evaluation ordering based on Huffman coding that reduces\nsummation error. We study the selection of sampling \"points\" experimentally and\nfind empirically good points for the most important sizes. We identify the main\nfactors associated with good points. In addition, we explore other methods to\nreduce FP error, including mixed-precision convolution, and pairwise summation\nacross DNN channels. Using our methods we can significantly reduce FP error for\na given block size, which allows larger block sizes and reduced computation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 09:48:02 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 17:32:05 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 19:38:11 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Barabasz", "Barbara", ""], ["Anderson", "Andrew", ""], ["Soodhalter", "Kirk M.", ""], ["Gregg", "David", ""]]}, {"id": "1803.10995", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Protection against Cloning for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The susceptibility of deep learning to adversarial attack can be understood\nin the framework of the Renormalisation Group (RG) and the vulnerability of a\nspecific network may be diagnosed provided the weights in each layer are known.\nAn adversary with access to the inputs and outputs could train a second network\nto clone these weights and, having identified a weakness, use them to compute\nthe perturbation of the input data which exploits it. However, the RG framework\nalso provides a means to poison the outputs of the network imperceptibly,\nwithout affecting their legitimate use, so as to prevent such cloning of its\nweights and thereby foil the generation of adversarial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:02:09 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.10996", "submitter": "Hyeongki Kim", "authors": "Hyeongki Kim", "title": "Dihedral angle prediction using generative adversarial networks", "comments": "72 pages, MSc thesis under the supervision of Assoc. Prof. Thomas\n  Hamelryck and Asst. Prof. Wouter Boomsma", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several dihedral angles prediction methods were developed for protein\nstructure prediction and their other applications. However, distribution of\npredicted angles would not be similar to that of real angles. To address this\nwe employed generative adversarial networks (GAN). Generative adversarial\nnetworks are composed of two adversarially trained networks: a discriminator\nand a generator. A discriminator distinguishes samples from a dataset and\ngenerated samples while a generator generates realistic samples. Although the\ndiscriminator of GANs is trained to estimate density, GAN model is intractable.\nOn the other hand, noise-contrastive estimation (NCE) was introduced to\nestimate a normalization constant of an unnormalized statistical model and thus\nthe density function. In this thesis, we introduce noise-contrastive estimation\ngenerative adversarial networks (NCE-GAN) which enables explicit density\nestimation of a GAN model. And a new loss for the generator is proposed. We\nalso propose residue-wise variants of auxiliary classifier GAN (AC-GAN) and\nSemi-supervised GAN to handle sequence information in a window. In our\nexperiment, the conditional generative adversarial network (C-GAN), AC-GAN and\nSemi-supervised GAN were compared. And experiments done with improved\nconditions were invested. We identified a phenomenon of AC-GAN that\ndistribution of its predicted angles is composed of unusual clusters. The\ndistribution of the predicted angles of Semi-supervised GAN was most similar to\nthe Ramachandran plot. We found that adding the output of the NCE as an\nadditional input of the discriminator is helpful to stabilize the training of\nthe GANs and to capture the detailed structures. Adding regression loss and\nusing predicted angles by regression loss only model could improve the\nconditional generation performance of the C-GAN and AC-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:02:14 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kim", "Hyeongki", ""]]}, {"id": "1803.11002", "submitter": "Mehdi Ghatee Dr.", "authors": "Sima Sharifirad and Azra Nazari and Mehdi Ghatee", "title": "Modified SMOTE Using Mutual Information and Different Sorts of Entropies", "comments": "10 Pages, 4 Tables, 8 Figures, Extracted from an MSc project with\n  Department of Computer Science, Amirkabir University of Technology, Tehran,\n  Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMOTE is one of the oversampling techniques for balancing the datasets and it\nis considered as a pre-processing step in learning algorithms. In this paper,\nfour new enhanced SMOTE are proposed that include an improved version of KNN in\nwhich the attribute weights are defined by mutual information firstly and then\nthey are replaced by maximum entropy, Renyi entropy and Tsallis entropy. These\nfour pre-processing methods are combined with 1NN and J48 classifiers and their\nperformance are compared with the previous methods on 11 imbalanced datasets\nfrom KEEL repository. The results show that these pre-processing methods\nimproves the accuracy compared with the previous stablished works. In addition,\nas a case study, the first pre-processing method is applied on transportation\ndata of Tehran-Bazargan Highway in Iran with IR equal to 36.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:41:19 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Sharifirad", "Sima", ""], ["Nazari", "Azra", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1803.11008", "submitter": "Mattes Mollenhauer", "authors": "Luzie Helfmann, Johannes von Lindheim, Mattes Mollenhauer, Ralf\n  Banisch", "title": "On Hyperparameter Search in Cluster Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quality assessments of models in unsupervised learning and clustering\nverification in particular have been a long-standing problem in the machine\nlearning research. The lack of robust and universally applicable cluster\nvalidity scores often makes the algorithm selection and hyperparameter\nevaluation a tough guess. In this paper, we show that cluster ensemble\naggregation techniques such as consensus clustering may be used to evaluate\nclusterings and their hyperparameter configurations. We use normalized mutual\ninformation to compare individual objects of a clustering ensemble to the\nconstructed consensus of the whole ensemble and show, that the resulting score\ncan serve as an overall quality measure for clustering problems. This method is\ncapable of highlighting the standout clustering and hyperparameter\nconfiguration in the ensemble even in the case of a distorted consensus. We\napply this very general framework to various data sets and give possible\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 11:11:10 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Helfmann", "Luzie", ""], ["von Lindheim", "Johannes", ""], ["Mollenhauer", "Mattes", ""], ["Banisch", "Ralf", ""]]}, {"id": "1803.11060", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Sebastijan Duman\\v{c}i\\'c, Elia Van Wolputte\n  and Hendrik Blockeel", "title": "COBRAS: Fast, Iterative, Active Clustering with Pairwise Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based clustering algorithms exploit background knowledge to\nconstruct clusterings that are aligned with the interests of a particular user.\nThis background knowledge is often obtained by allowing the clustering system\nto pose pairwise queries to the user: should these two elements be in the same\ncluster or not? Active clustering methods aim to minimize the number of queries\nneeded to obtain a good clustering by querying the most informative pairs\nfirst. Ideally, a user should be able to answer a couple of these queries,\ninspect the resulting clustering, and repeat these two steps until a\nsatisfactory result is obtained. We present COBRAS, an approach to active\nclustering with pairwise constraints that is suited for such an interactive\nclustering process. A core concept in COBRAS is that of a super-instance: a\nlocal region in the data in which all instances are assumed to belong to the\nsame cluster. COBRAS constructs such super-instances in a top-down manner to\nproduce high-quality results early on in the clustering process, and keeps\nrefining these super-instances as more pairwise queries are given to get more\ndetailed clusterings later on. We experimentally demonstrate that COBRAS\nproduces good clusterings at fast run times, making it an excellent candidate\nfor the iterative clustering scenario outlined above.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 13:52:59 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Van Wolputte", "Elia", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1803.11062", "submitter": "Weijun Zhu", "authors": "Weijun Zhu", "title": "Analyzing DNA Hybridization via machine learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In DNA computing, it is impossible to decide whether a specific hybridization\namong complex DNA molecules is effective or not within acceptable time. In\norder to address this common problem, we introduce a new method based on the\nmachine learning technique. First, a sample set is employed to train the\nBoosted Tree (BT) algorithm, and the corresponding model is obtained. Second,\nthis model is used to predict classification results of molecular\nhybridizations. The experiments show that the average accuracy of the new\nmethod is over 94.2%, and its average efficiency is over 90839 times higher\nthan that of the existing method. These results indicate that the new method\ncan quickly and accurately determine the biological effectiveness of molecular\nhybridization for a given DNA design.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 14:00:34 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 11:12:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Zhu", "Weijun", ""]]}, {"id": "1803.11080", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicolas Duchateau, Nicholas Ayache", "title": "3D Consistent Biventricular Myocardial Segmentation Using Deep Learning\n  for Mesh Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel automated method to segment the myocardium of both left\nand right ventricles in MRI volumes. The segmentation is consistent in 3D\nacross the slices such that it can be directly used for mesh generation. Two\nspecific neural networks with multi-scale coarse-to-fine prediction structure\nare proposed to cope with the small training dataset and trained using an\noriginal loss function. The former segments a slice in the middle of the\nvolume. Then the latter iteratively propagates the slice segmentations towards\nthe base and the apex, in a spatially consistent way. We perform 5-fold\ncross-validation on the 15 cases from STACOM to validate the method. For\ntraining, we use real cases and their synthetic variants generated by combining\nmotion simulation and image synthesis. Accurate and consistent testing results\nare obtained.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 14:08:12 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Duchateau", "Nicolas", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1803.11115", "submitter": "Xiaoyuan Liang", "authors": "Xiaoyuan Liang, Xunsheng Du, Guiling Wang, Zhu Han", "title": "Deep Reinforcement Learning for Traffic Light Control in Vehicular\n  Networks", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology ( Volume: 68 , Issue: 2\n  , Feb. 2019 )", "doi": "10.1109/TVT.2018.2890726", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing inefficient traffic light control causes numerous problems, such as\nlong delay and waste of energy. To improve efficiency, taking real-time traffic\ninformation as an input and dynamically adjusting the traffic light duration\naccordingly is a must. In terms of how to dynamically adjust traffic signals'\nduration, existing works either split the traffic signal into equal duration or\nextract limited traffic information from the real data. In this paper, we study\nhow to decide the traffic signals' duration based on the collected data from\ndifferent sensors and vehicular networks. We propose a deep reinforcement\nlearning model to control the traffic light. In the model, we quantify the\ncomplex traffic scenario as states by collecting data and dividing the whole\nintersection into small grids. The timing changes of a traffic light are the\nactions, which are modeled as a high-dimension Markov decision process. The\nreward is the cumulative waiting time difference between two cycles. To solve\nthe model, a convolutional neural network is employed to map the states to\nrewards. The proposed model is composed of several components to improve the\nperformance, such as dueling network, target network, double Q-learning\nnetwork, and prioritized experience replay. We evaluate our model via\nsimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,\nand the simulation results show the efficiency of our model in controlling\ntraffic lights.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 15:24:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liang", "Xiaoyuan", ""], ["Du", "Xunsheng", ""], ["Wang", "Guiling", ""], ["Han", "Zhu", ""]]}, {"id": "1803.11132", "submitter": "Alexander Wein", "authors": "Afonso S. Bandeira, Amelia Perry, Alexander S. Wein", "title": "Notes on computational-to-statistical gaps: predictions using\n  statistical physics", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In these notes we describe heuristics to predict computational-to-statistical\ngaps in certain statistical problems. These are regimes in which the underlying\nstatistical problem is information-theoretically possible although no efficient\nalgorithm exists, rendering the problem essentially unsolvable for large\ninstances. The methods we describe here are based on mature, albeit\nnon-rigorous, tools from statistical physics.\n  These notes are based on a lecture series given by the authors at the Courant\nInstitute of Mathematical Sciences in New York City, on May 16th, 2017.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:10:04 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 04:10:11 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Perry", "Amelia", ""], ["Wein", "Alexander S.", ""]]}, {"id": "1803.11136", "submitter": "Niharika Gauraha", "authors": "Niharika Gauraha, Lars Carlsson and Ola Spjuth", "title": "Conformal Prediction in Learning Under Privileged Information Paradigm\n  with Applications in Drug Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores conformal prediction in the learning under privileged\ninformation (LUPI) paradigm. We use the SVM+ realization of LUPI in an\ninductive conformal predictor, and apply it to the MNIST benchmark dataset and\nthree datasets in drug discovery. The results show that using privileged\ninformation produces valid models and improves efficiency compared to standard\nSVM, however the improvement varies between the tested datasets and is not\nsubstantial in the drug discovery applications. More importantly, using SVM+ in\na conformal prediction framework enables valid prediction intervals at\nspecified significance levels.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:21:10 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 10:38:12 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Gauraha", "Niharika", ""], ["Carlsson", "Lars", ""], ["Spjuth", "Ola", ""]]}, {"id": "1803.11157", "submitter": "Pengpeng Yang", "authors": "Wei Zhao and Pengpeng Yang and Rongrong Ni and Yao Zhao and Haorui Wu", "title": "Security Consideration For Deep Learning-Based Image Forensics", "comments": null, "journal-ref": null, "doi": "10.1587/transinf.2018EDL8091", "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, image forensics community has paied attention to the research on\nthe design of effective algorithms based on deep learning technology and facts\nproved that combining the domain knowledge of image forensics and deep learning\nwould achieve more robust and better performance than the traditional schemes.\nInstead of improving it, in this paper, the safety of deep learning based\nmethods in the field of image forensics is taken into account. To the best of\nour knowledge, this is a first work focusing on this topic. Specifically, we\nexperimentally find that the method using deep learning would fail when adding\nthe slight noise into the images (adversarial images). Furthermore, two kinds\nof strategys are proposed to enforce security of deep learning-based method.\nFirstly, an extra penalty term to the loss function is added, which is referred\nto the 2-norm of the gradient of the loss with respect to the input images, and\nthen an novel training method are adopt to train the model by fusing the normal\nand adversarial images. Experimental results show that the proposed algorithm\ncan achieve good performance even in the case of adversarial images and provide\na safety consideration for deep learning-based image forensics\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:06:00 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 09:54:20 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Zhao", "Wei", ""], ["Yang", "Pengpeng", ""], ["Ni", "Rongrong", ""], ["Zhao", "Yao", ""], ["Wu", "Haorui", ""]]}, {"id": "1803.11159", "submitter": "Zhize Li", "authors": "Zhize Li, Tianyi Zhang, Shuyu Cheng, Jun Zhu, Jian Li", "title": "Stochastic Gradient Hamiltonian Monte Carlo with Variance Reduction for\n  Bayesian Inference", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based Monte Carlo sampling algorithms, like Langevin dynamics and\nHamiltonian Monte Carlo, are important methods for Bayesian inference. In\nlarge-scale settings, full-gradients are not affordable and thus stochastic\ngradients evaluated on mini-batches are used as a replacement. In order to\nreduce the high variance of noisy stochastic gradients, Dubey et al. [2016]\napplied the standard variance reduction technique on stochastic gradient\nLangevin dynamics and obtained both theoretical and experimental improvements.\nIn this paper, we apply the variance reduction tricks on Hamiltonian Monte\nCarlo and achieve better theoretical convergence results compared with the\nvariance-reduced Langevin dynamics. Moreover, we apply the symmetric splitting\nscheme in our variance-reduced Hamiltonian Monte Carlo algorithms to further\nimprove the theoretical results. The experimental results are also consistent\nwith the theoretical results. As our experiment shows, variance-reduced\nHamiltonian Monte Carlo demonstrates better performance than variance-reduced\nLangevin dynamics in Bayesian regression and classification tasks on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:06:26 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 19:03:50 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 18:47:35 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Zhize", ""], ["Zhang", "Tianyi", ""], ["Cheng", "Shuyu", ""], ["Zhu", "Jun", ""], ["Li", "Jian", ""]]}, {"id": "1803.11173", "submitter": "Jarrod McClean", "authors": "Jarrod R. McClean, Sergio Boixo, Vadim N. Smelyanskiy, Ryan Babbush,\n  Hartmut Neven", "title": "Barren plateaus in quantum neural network training landscapes", "comments": null, "journal-ref": "Nature Communications, Volume 9, Article Number: 4812 (2018)", "doi": "10.1038/s41467-018-07090-4", "report-no": null, "categories": "quant-ph cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many experimental proposals for noisy intermediate scale quantum devices\ninvolve training a parameterized quantum circuit with a classical optimization\nloop. Such hybrid quantum-classical algorithms are popular for applications in\nquantum simulation, optimization, and machine learning. Due to its simplicity\nand hardware efficiency, random circuits are often proposed as initial guesses\nfor exploring the space of quantum states. We show that the exponential\ndimension of Hilbert space and the gradient estimation complexity make this\nchoice unsuitable for hybrid quantum-classical algorithms run on more than a\nfew qubits. Specifically, we show that for a wide class of reasonable\nparameterized quantum circuits, the probability that the gradient along any\nreasonable direction is non-zero to some fixed precision is exponentially small\nas a function of the number of qubits. We argue that this is related to the\n2-design characteristic of random circuits, and that solutions to this problem\nmust be studied.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:39:09 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["McClean", "Jarrod R.", ""], ["Boixo", "Sergio", ""], ["Smelyanskiy", "Vadim N.", ""], ["Babbush", "Ryan", ""], ["Neven", "Hartmut", ""]]}, {"id": "1803.11203", "submitter": "Karol Kurach", "authors": "Sylvain Gelly, Karol Kurach, Marcin Michalski, Xiaohua Zhai", "title": "MemGEN: Memory is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new learning paradigm called Deep Memory. It has the potential\nto completely revolutionize the Machine Learning field. Surprisingly, this\nparadigm has not been reinvented yet, unlike Deep Learning. At the core of this\napproach is the \\textit{Learning By Heart} principle, well studied in primary\nschools all over the world.\n  Inspired by poem recitation, or by $\\pi$ decimal memorization, we propose a\nconcrete algorithm that mimics human behavior. We implement this paradigm on\nthe task of generative modeling, and apply to images, natural language and even\nthe $\\pi$ decimals as long as one can print them as text. The proposed\nalgorithm even generated this paper, in a one-shot learning setting. In\ncarefully designed experiments, we show that the generated samples are\nindistinguishable from the training examples, as measured by any statistical\ntests or metrics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 18:06:38 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gelly", "Sylvain", ""], ["Kurach", "Karol", ""], ["Michalski", "Marcin", ""], ["Zhai", "Xiaohua", ""]]}, {"id": "1803.11259", "submitter": "Ai Munandar Tb", "authors": "T.A. Munandar and Sumiati", "title": "The Classification of Cropping Patterns Based on Regional Climate\n  Classification Using Decision Tree Approach", "comments": null, "journal-ref": "Journal of Computer Science 2017, 13 (9): 408.415", "doi": "10.3844/jcssp.2017.408.415", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, agricultural field is experiencing problems related to climate\nchange that result in the changing patterns in cropping season, especially for\npaddy and coarse grains, pulses roots and Tuber (CGPRT/Palawija) crops. The\ncropping patterns of rice and CGPRT crops highly depend on the availability of\nrainfall throughout the year. The changing and shifting of the rainy season\nresult in the changing cropping seasons. It is important to find out the\ncropping patterns of paddy and CGPRT crops based on monthly rainfall pattern in\nevery area. The Oldeman's method which is usually used in the classification of\nof cropping patterns of paddy and CGPRT crops is considered less able to\ndetermine the cropping patterns because it requires to see the rainfall data\nthroughout the year. This research proposes an alternative solution to\ndetermine the cropping pattern of paddy and CGPRT crops based on the pattern of\nrainfall in the area using decision tree approach. There were three algorithms,\nnamely, J48, RandomTree and REPTree, tested to determine the best algorithm\nused in the process of the classification of the cropping pattern in the area.\nThe results showed that J48 algorithm has a higher classification accuracy than\nRandomTree and REPTree for 48%, 42.67% and 38.67%, respectively. Meanwhile, the\nresults of data testing into the decision tree rule indicate that most of the\nareas in DKI Jakarta are suggested to apply the cropping pattern of 1 paddy\ncropping and 1 CGRPT cropping (1 PS + 1 PL). While in Banten, there are three\ncropping patterns that can be applied, they are, 1 paddy cropping and 1 CGPRT\ncropping (1 PS + 1 PL), 3 short-period paddy croppings or 2 paddy croppings and\n1 CGPRT cropping (3 short-period PS or 2 PS + 1 PL) and 2 paddy croppings and 1\nCGPRT cropping (2 PS + 1 PL).\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 01:01:59 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Munandar", "T. A.", ""], ["Sumiati", "", ""]]}, {"id": "1803.11266", "submitter": "Patrick Schratz", "authors": "Patrick Schratz, Jannes Muenchow, Eugenia Iturritxa, Jakob Richter,\n  Alexander Brenning", "title": "Performance evaluation and hyperparameter tuning of statistical and\n  machine-learning models using spatial data", "comments": null, "journal-ref": "Ecological Modelling Volume 406, 24 August 2019, Pages 109-120", "doi": "10.1016/j.ecolmodel.2019.06.002", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine-learning algorithms have gained popularity in recent years in the\nfield of ecological modeling due to their promising results in predictive\nperformance of classification problems. While the application of such\nalgorithms has been highly simplified in the last years due to their\nwell-documented integration in commonly used statistical programming languages\nsuch as R, there are several practical challenges in the field of ecological\nmodeling related to unbiased performance estimation, optimization of algorithms\nusing hyperparameter tuning and spatial autocorrelation. We address these\nissues in the comparison of several widely used machine-learning algorithms\nsuch as Boosted Regression Trees (BRT), k-Nearest Neighbor (WKNN), Random\nForest (RF) and Support Vector Machine (SVM) to traditional parametric\nalgorithms such as logistic regression (GLM) and semi-parametric ones like\ngeneralized additive models (GAM). Different nested cross-validation methods\nincluding hyperparameter tuning methods are used to evaluate model performances\nwith the aim to receive bias-reduced performance estimates. As a case study the\nspatial distribution of forest disease Diplodia sapinea in the Basque Country\nin Spain is investigated using common environmental variables such as\ntemperature, precipitation, soil or lithology as predictors. Results show that\nGAM and RF (mean AUROC estimates 0.708 and 0.699) outperform all other methods\nin predictive accuracy. The effect of hyperparameter tuning saturates at around\n50 iterations for this data set. The AUROC differences between the bias-reduced\n(spatial cross-validation) and overoptimistic (non-spatial cross-validation)\nperformance estimates of the GAM and RF are 0.167 (24%) and 0.213 (30%),\nrespectively. It is recommended to also use spatial partitioning for\ncross-validation hyperparameter tuning of spatial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 21:48:11 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Schratz", "Patrick", ""], ["Muenchow", "Jannes", ""], ["Iturritxa", "Eugenia", ""], ["Richter", "Jakob", ""], ["Brenning", "Alexander", ""]]}, {"id": "1803.11287", "submitter": "Biyi Fang", "authors": "Biyi Fang and Diego Klabjan", "title": "A Stochastic Large-scale Machine Learning Algorithm for Distributed\n  Features and Observations", "comments": "11 figures, 41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size of modern data sets exceeds the disk and memory capacities of a\nsingle computer, machine learning practitioners have resorted to parallel and\ndistributed computing. Given that optimization is one of the pillars of machine\nlearning and predictive modeling, distributed optimization methods have\nrecently garnered ample attention, in particular when either observations or\nfeatures are distributed, but not both. We propose a general stochastic\nalgorithm where observations, features, and gradient components can be sampled\nin a double distributed setting, i.e., with both features and observations\ndistributed. Very technical analyses establish convergence properties of the\nalgorithm under different conditions on the learning rate (diminishing to zero\nor constant). Computational experiments in Spark demonstrate a superior\nperformance of our algorithm versus a benchmark in early iterations of the\nalgorithm, which is due to the stochastic components of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 23:26:00 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 21:20:24 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Fang", "Biyi", ""], ["Klabjan", "Diego", ""]]}, {"id": "1803.11293", "submitter": "Aydogan Ozcan", "authors": "Yair Rivenson, Hongda Wang, Zhensong Wei, Yibo Zhang, Harun Gunaydin,\n  Aydogan Ozcan", "title": "Deep learning-based virtual histology staining using auto-fluorescence\n  of label-free tissue", "comments": null, "journal-ref": "Nature Biomedical Engineering (2019)", "doi": "10.1038/s41551-019-0362-y", "report-no": null, "categories": "cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histological analysis of tissue samples is one of the most widely used\nmethods for disease diagnosis. After taking a sample from a patient, it goes\nthrough a lengthy and laborious preparation, which stains the tissue to\nvisualize different histological features under a microscope. Here, we\ndemonstrate a label-free approach to create a virtually-stained microscopic\nimage using a single wide-field auto-fluorescence image of an unlabeled tissue\nsample, bypassing the standard histochemical staining process, saving time and\ncost. This method is based on deep learning, and uses a convolutional neural\nnetwork trained using a generative adversarial network model to transform an\nauto-fluorescence image of an unlabeled tissue section into an image that is\nequivalent to the bright-field image of the stained-version of the same sample.\nWe validated this method by successfully creating virtually-stained microscopic\nimages of human tissue samples, including sections of salivary gland, thyroid,\nkidney, liver and lung tissue, also covering three different stains. This\nlabel-free virtual-staining method eliminates cumbersome and costly\nhistochemical staining procedures, and would significantly simplify tissue\npreparation in pathology and histology fields.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 00:23:22 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Rivenson", "Yair", ""], ["Wang", "Hongda", ""], ["Wei", "Zhensong", ""], ["Zhang", "Yibo", ""], ["Gunaydin", "Harun", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1803.11347", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald S. Fearing, Pieter\n  Abbeel, Sergey Levine, Chelsea Finn", "title": "Learning to Adapt in Dynamic, Real-World Environments Through\n  Meta-Reinforcement Learning", "comments": "First 2 authors contributed equally. Website:\n  https://sites.google.com/berkeley.edu/metaadaptivecontrol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although reinforcement learning methods can achieve impressive results in\nsimulation, the real world presents two major challenges: generating samples is\nexceedingly expensive, and unexpected perturbations or unseen situations cause\nproficient but specialized policies to fail at test time. Given that it is\nimpractical to train separate policies to accommodate all situations the agent\nmay see in the real world, this work proposes to learn how to quickly and\neffectively adapt online to new tasks. To enable sample-efficient learning, we\nconsider learning online adaptation in the context of model-based reinforcement\nlearning. Our approach uses meta-learning to train a dynamics model prior such\nthat, when combined with recent data, this prior can be rapidly adapted to the\nlocal context. Our experiments demonstrate online adaptation for continuous\ncontrol tasks on both simulated and real-world agents. We first show simulated\nagents adapting their behavior online to novel terrains, crippled body parts,\nand highly-dynamic environments. We also illustrate the importance of\nincorporating online adaptation into autonomous agents that operate in the real\nworld by applying our method to a real dynamic legged millirobot. We\ndemonstrate the agent's learned ability to quickly adapt online to a missing\nleg, adjust to novel terrains and slopes, account for miscalibration or errors\nin pose estimation, and compensate for pulling payloads.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 05:47:11 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 07:57:30 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 23:44:09 GMT"}, {"version": "v4", "created": "Thu, 6 Dec 2018 20:26:09 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 21:55:30 GMT"}, {"version": "v6", "created": "Wed, 27 Feb 2019 19:23:41 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Clavera", "Ignasi", ""], ["Liu", "Simin", ""], ["Fearing", "Ronald S.", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1803.11364", "submitter": "Daiki Tanaka", "authors": "Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, Kiyoharu Aizawa", "title": "Joint Optimization Framework for Learning with Noisy Labels", "comments": "To appear at CVPR 2018 (poster), including supplementary material", "journal-ref": "CVPR 2018, pp.5552--5550", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) trained on large-scale datasets have exhibited\nsignificant performance in image classification. Many large-scale datasets are\ncollected from websites, however they tend to contain inaccurate labels that\nare termed as noisy labels. Training on such noisy labeled datasets causes\nperformance degradation because DNNs easily overfit to noisy labels. To\novercome this problem, we propose a joint optimization framework of learning\nDNN parameters and estimating true labels. Our framework can correct labels\nduring training by alternating update of network parameters and labels. We\nconduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset.\nThe results indicate that our approach significantly outperforms other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 06:53:40 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Tanaka", "Daiki", ""], ["Ikami", "Daiki", ""], ["Yamasaki", "Toshihiko", ""], ["Aizawa", "Kiyoharu", ""]]}, {"id": "1803.11373", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Ryota Kanai", "title": "Learning to generate classifiers", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a network to generate mappings between training sets and\nclassification policies (a 'classifier generator') by conditioning on the\nentire training set via an attentional mechanism. The network is directly\noptimized for test set performance on an training set of related tasks, which\nis then transferred to unseen 'test' tasks. We use this to optimize for\nperformance in the low-data and unsupervised learning regimes, and obtain\nsignificantly better performance in the 10-50 datapoint regime than support\nvector classifiers, random forests, XGBoost, and k-nearest neighbors on a range\nof small datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 07:43:35 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Kanai", "Ryota", ""]]}, {"id": "1803.11395", "submitter": "Guanbin Li", "authors": "Guanbin Li and Yizhou Yu", "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection", "comments": "Accept to TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 09:51:04 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Li", "Guanbin", ""], ["Yu", "Yizhou", ""]]}, {"id": "1803.11410", "submitter": "Amnon Drory", "authors": "Amnon Drory, Oria Ratzon, Shai Avidan, Raja Giryes", "title": "The Resistance to Label Noise in K-NN and DNN Depends on its\n  Concentration", "comments": "None", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the classification performance of K-nearest neighbors (K-NN)\nand deep neural networks (DNNs) in the presence of label noise. We first show\nempirically that a DNN's prediction for a given test example depends on the\nlabels of the training examples in its local neighborhood. This motivates us to\nderive a realizable analytic expression that approximates the multi-class K-NN\nclassification error in the presence of label noise, which is of independent\nimportance. We then suggest that the expression for K-NN may serve as a\nfirst-order approximation for the DNN error. Finally, we demonstrate\nempirically the proximity of the developed expression to the observed\nperformance of K-NN and DNN classifiers. Our result may explain the already\nobserved surprising resistance of DNN to some types of label noise. It also\ncharacterizes an important factor of it showing that the more concentrated the\nnoise the greater is the degradation in performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 11:06:43 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:49:57 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 09:18:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Drory", "Amnon", ""], ["Ratzon", "Oria", ""], ["Avidan", "Shai", ""], ["Giryes", "Raja", ""]]}, {"id": "1803.11411", "submitter": "Majid Mazouchi", "authors": "Majid Mazouchi, Mohammad Bagher Naghibi-Sistani, Seyed Kamal Hosseini\n  Sani, Farzaneh Tatari, Hamidreza Modares", "title": "Observer-based Adaptive Optimal Output Containment Control problem of\n  Linear Heterogeneous Multi-agent Systems with Relative Output Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops an optimal relative output-feedback based solution to the\ncontainment control problem of linear heterogeneous multi-agent systems. A\ndistributed optimal control protocol is presented for the followers to not only\nassure that their outputs fall into the convex hull of the leaders' output\n(i.e., the desired or safe region), but also optimizes their transient\nperformance. The proposed optimal control solution is composed of a feedback\npart, depending of the followers' state, and a feed-forward part, depending on\nthe convex hull of the leaders' state. To comply with most real-world\napplications, the feedback and feed-forward states are assumed to be\nunavailable and are estimated using two distributed observers. That is, since\nthe followers cannot directly sense their absolute states, a distributed\nobserver is designed that uses only relative output measurements with respect\nto their neighbors (measured for example by using range sensors in robotic) and\nthe information which is broadcasted by their neighbors to estimate their\nstates. Moreover, another adaptive distributed observer is designed that uses\nexchange of information between followers over a communication network to\nestimate the convex hull of the leaders' state. The proposed observer relaxes\nthe restrictive requirement of knowing the complete knowledge of the leaders'\ndynamics by all followers. An off-policy reinforcement learning algorithm on an\nactor-critic structure is next developed to solve the optimal containment\ncontrol problem online, using relative output measurements and without\nrequirement of knowing the leaders' dynamics by all followers. Finally, the\ntheoretical results are verified by numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 11:07:17 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Mazouchi", "Majid", ""], ["Naghibi-Sistani", "Mohammad Bagher", ""], ["Sani", "Seyed Kamal Hosseini", ""], ["Tatari", "Farzaneh", ""], ["Modares", "Hamidreza", ""]]}, {"id": "1803.11462", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Stojanovic and Zoran Obradovic", "title": "Improving confidence while predicting trends in temporal disease\n  networks", "comments": "Proceedings of the 4th Workshop on Data Mining for Medicine and\n  Healthcare, 2015 SIAM International Conference on Data Mining, Vancouver,\n  Canada, April 30 - May 02, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For highly sensitive real-world predictive analytic applications such as\nhealthcare and medicine, having good prediction accuracy alone is often not\nenough. These kinds of applications require a decision making process which\nuses uncertainty estimation as input whenever possible. Quality of uncertainty\nestimation is a subject of over or under confident prediction, which is often\nnot addressed in many models. In this paper we show several extensions to the\nGaussian Conditional Random Fields model, which aim to provide higher quality\nuncertainty estimation. These extensions are applied to the temporal disease\ngraph built from the State Inpatient Database (SID) of California, acquired\nfrom the HCUP. Our experiments demonstrate benefits of using graph information\nin modeling temporal disease properties as well as improvements in uncertainty\nestimation provided by given extensions of the Gaussian Conditional Random\nFields method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 15:53:39 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Stojanovic", "Jelena", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1803.11485", "submitter": "Mikayel Samvelyan", "authors": "Tabish Rashid, Mikayel Samvelyan, Christian Schroeder de Witt, Gregory\n  Farquhar, Jakob Foerster, Shimon Whiteson", "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning", "comments": "Camera-ready version, International Conference of Machine Learning\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world settings, a team of agents must coordinate their behaviour\nwhile acting in a decentralised way. At the same time, it is often possible to\ntrain the agents in a centralised fashion in a simulated or laboratory setting,\nwhere global state information is available and communication constraints are\nlifted. Learning joint action-values conditioned on extra state information is\nan attractive way to exploit centralised learning, but the best strategy for\nthen extracting decentralised policies is unclear. Our solution is QMIX, a\nnovel value-based method that can train decentralised policies in a centralised\nend-to-end fashion. QMIX employs a network that estimates joint action-values\nas a complex non-linear combination of per-agent values that condition only on\nlocal observations. We structurally enforce that the joint-action value is\nmonotonic in the per-agent values, which allows tractable maximisation of the\njoint action-value in off-policy learning, and guarantees consistency between\nthe centralised and decentralised policies. We evaluate QMIX on a challenging\nset of StarCraft II micromanagement tasks, and show that QMIX significantly\noutperforms existing value-based multi-agent reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 14:23:39 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 17:58:09 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Rashid", "Tabish", ""], ["Samvelyan", "Mikayel", ""], ["de Witt", "Christian Schroeder", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1803.11521", "submitter": "Mingyuan Wang", "authors": "Lizhe Sun, Mingyuan Wang, Yangzi Guo, Adrian Barbu", "title": "A Novel Framework for Online Supervised Learning with Feature Selection", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current online learning methods suffer issues such as lower convergence rates\nand limited capability to recover the support of the true features compared to\ntheir offline counterparts. In this paper, we present a novel framework for\nonline learning based on running averages and introduce a series of online\nversions of some popular existing offline methods such as Elastic Net, Minimax\nConcave Penalty and Feature Selection with Annealing. The framework can handle\nan arbitrarily large number of observations with the restriction that the data\ndimension is not too large, e.g. p<50,000. We prove the equivalence between our\nonline methods and their offline counterparts and give theoretical true feature\nrecovery and convergence guarantees for some of them. In contrast to the\nexisting online methods, the proposed methods can extract models with any\ndesired sparsity level at any time. Numerical experiments indicate that our new\nmethods enjoy high accuracy of true feature recovery and a fast convergence\nrate, compared with standard online and offline algorithms. We also show how\nthe running averages framework can be used for model adaptation in the presence\nof model drift. Finally, we present some applications to large datasets where\nagain the proposed framework shows competitive results compared to popular\nonline and offline algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 15:52:10 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 14:41:55 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 00:47:49 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 19:14:20 GMT"}, {"version": "v5", "created": "Sun, 4 Aug 2019 17:12:52 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 14:21:01 GMT"}, {"version": "v7", "created": "Wed, 17 Jun 2020 21:10:02 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Sun", "Lizhe", ""], ["Wang", "Mingyuan", ""], ["Guo", "Yangzi", ""], ["Barbu", "Adrian", ""]]}, {"id": "1803.11537", "submitter": "E.M. Stoudenmire", "authors": "William Huggins, Piyush Patel, K. Birgitta Whaley, E. Miles\n  Stoudenmire", "title": "Towards Quantum Machine Learning with Tensor Networks", "comments": "10 pages; 14 figures; added new detailed study of noise resilience", "journal-ref": "Quantum Science and Technology, Volume 4, 024001 (2019)", "doi": "10.1088/2058-9565/aaea94", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a promising application of quantum computing, but\nchallenges remain as near-term devices will have a limited number of physical\nqubits and high error rates. Motivated by the usefulness of tensor networks for\nmachine learning in the classical context, we propose quantum computing\napproaches to both discriminative and generative learning, with circuits based\non tree and matrix product state tensor networks that could have benefits for\nnear-term devices. The result is a unified framework where classical and\nquantum computing can benefit from the same theoretical and algorithmic\ndevelopments, and the same model can be trained classically then transferred to\nthe quantum setting for additional optimization. Tensor network circuits can\nalso provide qubit-efficient schemes where, depending on the architecture, the\nnumber of physical qubits required scales only logarithmically with, or\nindependently of the input or output data sizes. We demonstrate our proposals\nwith numerical experiments, training a discriminative model to perform\nhandwriting recognition using a optimization procedure that could be carried\nout on quantum hardware, and testing the noise resilience of the trained model.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 17:19:47 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 01:41:23 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Huggins", "William", ""], ["Patel", "Piyush", ""], ["Whaley", "K. Birgitta", ""], ["Stoudenmire", "E. Miles", ""]]}, {"id": "1803.11551", "submitter": "Minh Tang", "authors": "Minh Tang", "title": "The eigenvalues of stochastic blockmodel graphs", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the limiting distribution for the largest eigenvalues of the\nadjacency matrix for a stochastic blockmodel graph when the number of vertices\ntends to infinity. We show that, in the limit, these eigenvalues are jointly\nmultivariate normal with bounded covariances. Our result extends the classic\nresult of F\\\"{u}redi and Koml\\'{o}s on the fluctuation of the largest\neigenvalue for Erd\\H{o}s-R\\'{e}nyi graphs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 17:43:16 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Tang", "Minh", ""]]}, {"id": "1803.11556", "submitter": "Zhongzheng Ren", "authors": "Zhongzheng Ren, Yong Jae Lee, Michael S. Ryoo", "title": "Learning to Anonymize Faces for Privacy Preserving Action Detection", "comments": "ECCV'18 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing concern in computer vision devices invading users'\nprivacy by recording unwanted videos. On the one hand, we want the camera\nsystems to recognize important events and assist human daily lives by\nunderstanding its videos, but on the other hand we want to ensure that they do\nnot intrude people's privacy. In this paper, we propose a new principled\napproach for learning a video \\emph{face anonymizer}. We use an adversarial\ntraining setting in which two competing systems fight: (1) a video anonymizer\nthat modifies the original video to remove privacy-sensitive information while\nstill trying to maximize spatial action detection performance, and (2) a\ndiscriminator that tries to extract privacy-sensitive information from the\nanonymized videos. The end result is a video anonymizer that performs\npixel-level modifications to anonymize each person's face, with minimal effect\non action detection performance. We experimentally confirm the benefits of our\napproach compared to conventional hand-crafted anonymization methods including\nmasking, blurring, and noise adding. Code, demo, and more results can be found\non our project page https://jason718.github.io/project/privacy/main.html.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 17:55:04 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 18:40:52 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ren", "Zhongzheng", ""], ["Lee", "Yong Jae", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "1803.11560", "submitter": "Samuel Albanie", "authors": "Samuel Albanie and James Thewlis and Joao F. Henriques", "title": "Substitute Teacher Networks: Learning with Almost No Supervision", "comments": "Published as a conference at SIGBOVIK 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning through experience is time-consuming, inefficient and often bad for\nyour cortisol levels. To address this problem, a number of recently proposed\nteacher-student methods have demonstrated the benefits of private tuition, in\nwhich a single model learns from an ensemble of more experienced tutors.\nUnfortunately, the cost of such supervision restricts good representations to a\nprivileged minority. Unsupervised learning can be used to lower tuition fees,\nbut runs the risk of producing networks that require extracurriculum learning\nto strengthen their CVs and create their own LinkedIn profiles. Inspired by the\nlogo on a promotional stress ball at a local recruitment fair, we make the\nfollowing three contributions. First, we propose a novel almost no supervision\ntraining algorithm that is effective, yet highly scalable in the number of\nstudent networks being supervised, ensuring that education remains affordable.\nSecond, we demonstrate our approach on a typical use case: learning to bake,\ndeveloping a method that tastily surpasses the current state of the art.\nFinally, we provide a rigorous quantitive analysis of our method, proving that\nwe have access to a calculator. Our work calls into question the long-held\ndogma that life is the best teacher.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 18:41:18 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Albanie", "Samuel", ""], ["Thewlis", "James", ""], ["Henriques", "Joao F.", ""]]}]