[{"id": "1202.0302", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland, Liang Xiong, Barnab\\'as P\\'oczos, and Jeff\n  Schneider", "title": "Kernels on Sample Sets via Nonparametric Divergence Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning algorithms, such as classification or regression, treat\nthe individual data point as the object of interest. Here we consider extending\nmachine learning algorithms to operate on groups of data points. We suggest\ntreating a group of data points as an i.i.d. sample set from an underlying\nfeature distribution for that group. Our approach employs kernel machines with\na kernel on i.i.d. sample sets of vectors. We define certain kernel functions\non pairs of distributions, and then use a nonparametric estimator to\nconsistently estimate those functions based on sample sets. The projection of\nthe estimated Gram matrix to the cone of symmetric positive semi-definite\nmatrices enables us to use kernel machines for classification, regression,\nanomaly detection, and low-dimensional embedding in the space of distributions.\nWe present several numerical experiments both on real and simulated datasets to\ndemonstrate the advantages of our new approach.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 21:36:40 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2012 15:43:04 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 06:58:28 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""], ["Xiong", "Liang", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Schneider", "Jeff", ""]]}, {"id": "1202.0786", "submitter": "Vincent Vu", "authors": "Vincent Q. Vu and Jing Lei", "title": "Minimax Rates of Estimation for Sparse PCA in High Dimensions", "comments": "To appear in Proceedings of the 15th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2012, La Palma, Canary\n  Islands. Volume 22 of JMLR: W&CP 22", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sparse principal components analysis in the high-dimensional\nsetting, where $p$ (the number of variables) can be much larger than $n$ (the\nnumber of observations). We prove optimal, non-asymptotic lower and upper\nbounds on the minimax estimation error for the leading eigenvector when it\nbelongs to an $\\ell_q$ ball for $q \\in [0,1]$. Our bounds are sharp in $p$ and\n$n$ for all $q \\in [0, 1]$ over a wide class of distributions. The upper bound\nis obtained by analyzing the performance of $\\ell_q$-constrained PCA. In\nparticular, our results provide convergence rates for $\\ell_1$-constrained PCA.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 17:44:36 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2012 01:19:43 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Vu", "Vincent Q.", ""], ["Lei", "Jing", ""]]}, {"id": "1202.0855", "submitter": "Buyue Qian", "authors": "Buyue Qian, Xiang Wang and Ian Davidson", "title": "A Reconstruction Error Formulation for Semi-Supervised Multi-task and\n  Multi-view Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge to make learning techniques more suitable for general\npurpose use is to move beyond i) complete supervision, ii) low dimensional\ndata, iii) a single task and single view per instance. Solving these challenges\nallows working with \"Big Data\" problems that are typically high dimensional\nwith multiple (but possibly incomplete) labelings and views. While other work\nhas addressed each of these problems separately, in this paper we show how to\naddress them together, namely semi-supervised dimension reduction for\nmulti-task and multi-view learning (SSDR-MML), which performs optimization for\ndimension reduction and label inference in semi-supervised setting. The\nproposed framework is designed to handle both multi-task and multi-view\nlearning settings, and can be easily adapted to many useful applications.\nInformation obtained from all tasks and views is combined via reconstruction\nerrors in a linear fashion that can be efficiently solved using an alternating\noptimization scheme. Our formulation has a number of advantages. We explicitly\nmodel the information combining mechanism as a data structure (a\nweight/nearest-neighbor matrix) which allows investigating fundamental\nquestions in multi-task and multi-view learning. We address one such question\nby presenting a general measure to quantify the success of simultaneous\nlearning of multiple tasks or from multiple views. We show that our SSDR-MML\napproach can outperform many state-of-the-art baseline methods and demonstrate\nthe effectiveness of connecting dimension reduction and learning.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 01:41:36 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Qian", "Buyue", ""], ["Wang", "Xiang", ""], ["Davidson", "Ian", ""]]}, {"id": "1202.1119", "submitter": "Ranjitha Prasad", "authors": "Ranjitha Prasad and Chandra R. Murthy", "title": "Cramer Rao-Type Bounds for Sparse Bayesian Learning", "comments": "Accepted for publication in the IEEE Transactions on Signal\n  Processing, 11 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TSP.2012.2226165", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive Hybrid, Bayesian and Marginalized Cram\\'{e}r-Rao\nlower bounds (HCRB, BCRB and MCRB) for the single and multiple measurement\nvector Sparse Bayesian Learning (SBL) problem of estimating compressible\nvectors and their prior distribution parameters. We assume the unknown vector\nto be drawn from a compressible Student-t prior distribution. We derive CRBs\nthat encompass the deterministic or random nature of the unknown parameters of\nthe prior distribution and the regression noise variance. We extend the MCRB to\nthe case where the compressible vector is distributed according to a general\ncompressible prior distribution, of which the generalized Pareto distribution\nis a special case. We use the derived bounds to uncover the relationship\nbetween the compressibility and Mean Square Error (MSE) in the estimates.\nFurther, we illustrate the tightness and utility of the bounds through\nsimulations, by comparing them with the MSE performance of two popular\nSBL-based estimators. It is found that the MCRB is generally the tightest among\nthe bounds derived and that the MSE performance of the Expectation-Maximization\n(EM) algorithm coincides with the MCRB for the compressible vector. Through\nsimulations, we demonstrate the dependence of the MSE performance of SBL based\nestimators on the compressibility of the vector for several values of the\nnumber of observations and at different signal powers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 12:39:37 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2012 04:17:59 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Prasad", "Ranjitha", ""], ["Murthy", "Chandra R.", ""]]}, {"id": "1202.1121", "submitter": "Miron Kursa", "authors": "Miron B. Kursa", "title": "rFerns: An Implementation of the Random Ferns Method for General-Purpose\n  Machine Learning", "comments": null, "journal-ref": "Journal of Statistical Software, 61(10), 1-13", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I present an extended implementation of the Random ferns\nalgorithm contained in the R package rFerns. It differs from the original by\nthe ability of consuming categorical and numerical attributes instead of only\nbinary ones. Also, instead of using simple attribute subspace ensemble it\nemploys bagging and thus produce error approximation and variable importance\nmeasure modelled after Random forest algorithm. I also present benchmarks'\nresults which show that although Random ferns' accuracy is mostly smaller than\nachieved by Random forest, its speed and good quality of importance measure it\nprovides make rFerns a reasonable choice for a specific applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 12:43:12 GMT"}, {"version": "v2", "created": "Fri, 14 Nov 2014 14:39:39 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Kursa", "Miron B.", ""]]}, {"id": "1202.1334", "submitter": "John Langford", "authors": "Alekh Agarwal and Miroslav Dud\\'ik and Satyen Kale and John Langford\n  and Robert E. Schapire", "title": "Contextual Bandit Learning with Predictable Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit learning is a reinforcement learning problem where the\nlearner repeatedly receives a set of features (context), takes an action and\nreceives a reward based on the action and context. We consider this problem\nunder a realizability assumption: there exists a function in a (known) function\nclass, always capable of predicting the expected reward, given the action and\ncontext. Under this assumption, we show three things. We present a new\nalgorithm---Regressor Elimination--- with a regret similar to the agnostic\nsetting (i.e. in the absence of realizability assumption). We prove a new lower\nbound showing no algorithm can achieve superior performance in the worst case\neven with the realizability assumption. However, we do show that for any set of\npolicies (mapping contexts to actions), there is a distribution over rewards\n(given context) such that our new algorithm has constant regret unlike the\nprevious approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 02:27:55 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2012 15:02:28 GMT"}], "update_date": "2012-03-05", "authors_parsed": [["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Kale", "Satyen", ""], ["Langford", "John", ""], ["Schapire", "Robert E.", ""]]}, {"id": "1202.1523", "submitter": "Stefano Soatto", "authors": "Zhao Yi, Stefano Soatto, Maneesh Dewan, Yiqiang Zhan", "title": "Information Forests", "comments": "Proceedings of the Information Theory and Applications (ITA)\n  Workshop, 2/7/2012", "journal-ref": null, "doi": null, "report-no": "UCLA CSD TR120002", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Information Forests, an approach to classification that\ngeneralizes Random Forests by replacing the splitting criterion of non-leaf\nnodes from a discriminative one -- based on the entropy of the label\ndistribution -- to a generative one -- based on maximizing the information\ndivergence between the class-conditional distributions in the resulting\npartitions. The basic idea consists of deferring classification until a measure\nof \"classification confidence\" is sufficiently high, and instead breaking down\nthe data so as to maximize this measure. In an alternative interpretation,\nInformation Forests attempt to partition the data into subsets that are \"as\ninformative as possible\" for the purpose of the task, which is to classify the\ndata. Classification confidence, or informative content of the subsets, is\nquantified by the Information Divergence. Our approach relates to active\nlearning, semi-supervised learning, mixed generative/discriminative learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 14:54:59 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Yi", "Zhao", ""], ["Soatto", "Stefano", ""], ["Dewan", "Maneesh", ""], ["Zhan", "Yiqiang", ""]]}, {"id": "1202.1558", "submitter": "Ruben Martinez-Cantin", "authors": "H\\'ector Ratia and Luis Montesano and Ruben Martinez-Cantin", "title": "On the Performance of Maximum Likelihood Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) addresses the problem of recovering a\ntask description given a demonstration of the optimal policy used to solve such\na task. The optimal policy is usually provided by an expert or teacher, making\nIRL specially suitable for the problem of apprenticeship learning. The task\ndescription is encoded in the form of a reward function of a Markov decision\nprocess (MDP). Several algorithms have been proposed to find the reward\nfunction corresponding to a set of demonstrations. One of the algorithms that\nhas provided best results in different applications is a gradient method to\noptimize a policy squared error criterion. On a parallel line of research,\nother authors have presented recently a gradient approximation of the maximum\nlikelihood estimate of the reward signal. In general, both approaches\napproximate the gradient estimate and the criteria at different stages to make\nthe algorithm tractable and efficient. In this work, we provide a detailed\ndescription of the different methods to highlight differences in terms of\nreward estimation, policy similarity and computational costs. We also provide\nexperimental results to evaluate the differences in performance of the methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 23:14:36 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Ratia", "H\u00e9ctor", ""], ["Montesano", "Luis", ""], ["Martinez-Cantin", "Ruben", ""]]}, {"id": "1202.2112", "submitter": "Debadeepta Dey", "authors": "Debadeepta Dey, Tian Yu Liu, Martial Hebert, J. Andrew Bagnell", "title": "Predicting Contextual Sequences via Submodular Function Maximization", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": "CMU-RI-TR-12-05", "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence optimization, where the items in a list are ordered to maximize some\nreward has many applications such as web advertisement placement, search, and\ncontrol libraries in robotics. Previous work in sequence optimization produces\na static ordering that does not take any features of the item or context of the\nproblem into account. In this work, we propose a general approach to order the\nitems within the sequence based on the context (e.g., perceptual information,\nenvironment description, and goals). We take a simple, efficient,\nreduction-based approach where the choice and order of the items is established\nby repeatedly learning simple classifiers or regressors for each \"slot\" in the\nsequence. Our approach leverages recent work on submodular function\nmaximization to provide a formal regret reduction from submodular sequence\noptimization to simple cost-sensitive prediction. We apply our contextual\nsequence prediction algorithm to optimize control libraries and demonstrate\nresults on two robotics problems: manipulator trajectory prediction and mobile\nrobot path planning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 20:48:22 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Dey", "Debadeepta", ""], ["Liu", "Tian Yu", ""], ["Hebert", "Martial", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1202.2143", "submitter": "Il Memming Park", "authors": "Il Memming Park, Marcel Nassar, Mijung Park", "title": "Active Bayesian Optimization: Minimizing Minimizer Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultimate goal of optimization is to find the minimizer of a target\nfunction.However, typical criteria for active optimization often ignore the\nuncertainty about the minimizer. We propose a novel criterion for global\noptimization and an associated sequential active learning strategy using\nGaussian processes.Our criterion is the reduction of uncertainty in the\nposterior distribution of the function minimizer. It can also flexibly\nincorporate multiple global minimizers. We implement a tractable approximation\nof the criterion and demonstrate that it obtains the global minimizer\naccurately compared to conventional Bayesian optimization criteria.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 22:31:01 GMT"}], "update_date": "2012-02-13", "authors_parsed": [["Park", "Il Memming", ""], ["Nassar", "Marcel", ""], ["Park", "Mijung", ""]]}, {"id": "1202.2160", "submitter": "Laurent Najman", "authors": "Cl\\'ement Farabet and Camille Couprie and Laurent Najman and Yann\n  LeCun", "title": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and\n  Optimal Covers", "comments": "9 pages, 4 figures - Published in 29th International Conference on\n  Machine Learning (ICML 2012), Jun 2012, Edinburgh, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene parsing, or semantic segmentation, consists in labeling each pixel in\nan image with the category of the object it belongs to. It is a challenging\ntask that involves the simultaneous detection, segmentation and recognition of\nall the objects in the image.\n  The scene parsing method proposed here starts by computing a tree of segments\nfrom a graph of pixel dissimilarities. Simultaneously, a set of dense feature\nvectors is computed which encodes regions of multiple sizes centered on each\npixel. The feature extractor is a multiscale convolutional network trained from\nraw pixels. The feature vectors associated with the segments covered by each\nnode in the tree are aggregated and fed to a classifier which produces an\nestimate of the distribution of object categories contained in the segment. A\nsubset of tree nodes that cover the image are then selected so as to maximize\nthe average \"purity\" of the class distributions, hence maximizing the overall\nlikelihood that each segment will contain a single object. The convolutional\nnetwork feature extractor is trained end-to-end from raw pixels, alleviating\nthe need for engineered features. After training, the system is parameter free.\n  The system yields record accuracies on the Stanford Background Dataset (8\nclasses), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170\nclasses) while being an order of magnitude faster than competing approaches,\nproducing a 320 \\times 240 image labeling in less than 1 second.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 00:30:48 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2012 21:32:24 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Farabet", "Cl\u00e9ment", ""], ["Couprie", "Camille", ""], ["Najman", "Laurent", ""], ["LeCun", "Yann", ""]]}, {"id": "1202.2703", "submitter": "Maxime Berar", "authors": "Maxime Berar (LITIS), Fran\\c{c}oise Tilotta, Joan Alexis Glaun\\`es\n  (MAP5), Yves Rozenholc (MAP5)", "title": "Craniofacial reconstruction as a prediction problem using a Latent Root\n  Regression model", "comments": null, "journal-ref": "Forensic Science International 210, 1-3 (2011) 228 - 236", "doi": "10.1016/j.forsciint.2011.03.010", "report-no": null, "categories": "cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a computer-assisted method for facial\nreconstruction. This method provides an estimation of the facial shape\nassociated with unidentified skeletal remains. Current computer-assisted\nmethods using a statistical framework rely on a common set of extracted points\nlocated on the bone and soft-tissue surfaces. Most of the facial reconstruction\nmethods then consist of predicting the position of the soft-tissue surface\npoints, when the positions of the bone surface points are known. We propose to\nuse Latent Root Regression for prediction. The results obtained are then\ncompared to those given by Principal Components Analysis linear models. In\nconjunction, we have evaluated the influence of the number of skull landmarks\nused. Anatomical skull landmarks are completed iteratively by points located\nupon geodesics which link these anatomical landmarks, thus enabling us to\nartificially increase the number of skull points. Facial points are obtained\nusing a mesh-matching algorithm between a common reference mesh and individual\nsoft-tissue surface meshes. The proposed method is validated in term of\naccuracy, based on a leave-one-out cross-validation test applied to a\nhomogeneous database. Accuracy measures are obtained by computing the distance\nbetween the original face surface and its reconstruction. Finally, these\nresults are discussed referring to current computer-assisted reconstruction\nfacial techniques.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 12:28:12 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Berar", "Maxime", "", "LITIS"], ["Tilotta", "Fran\u00e7oise", "", "MAP5"], ["Glaun\u00e8s", "Joan Alexis", "", "MAP5"], ["Rozenholc", "Yves", "", "MAP5"]]}, {"id": "1202.3079", "submitter": "Nicol\\`o Cesa-Bianchi", "authors": "S\\'ebastien Bubeck, Nicol\\`o Cesa-Bianchi, Sham M. Kakade", "title": "Towards minimax policies for online linear optimization with bandit\n  feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the online linear optimization problem with bandit feedback. Our\ncontribution is twofold. First, we provide an algorithm (based on exponential\nweights) with a regret of order $\\sqrt{d n \\log N}$ for any finite action set\nwith $N$ actions, under the assumption that the instantaneous loss is bounded\nby 1. This shaves off an extraneous $\\sqrt{d}$ factor compared to previous\nworks, and gives a regret bound of order $d \\sqrt{n \\log n}$ for any compact\nset of actions. Without further assumptions on the action set, this last bound\nis minimax optimal up to a logarithmic factor. Interestingly, our result also\nshows that the minimax regret for bandit linear optimization with expert advice\nin $d$ dimension is the same as for the basic $d$-armed bandit with expert\nadvice. Our second contribution is to show how to use the Mirror Descent\nalgorithm to obtain computationally efficient strategies with minimax optimal\nregret bounds in specific examples. More precisely we study two canonical\naction sets: the hypercube and the Euclidean ball. In the former case, we\nobtain the first computationally efficient algorithm with a $d \\sqrt{n}$\nregret, thus improving by a factor $\\sqrt{d \\log n}$ over the best known result\nfor a computationally efficient algorithm. In the latter case, our approach\ngives the first algorithm with a $\\sqrt{d n \\log n}$ regret, again shaving off\nan extraneous $\\sqrt{d}$ compared to previous works.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:12:09 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1202.3323", "submitter": "Gilles Stoltz", "authors": "Nicol\\`o Cesa-Bianchi, Pierre Gaillard (INRIA Paris - Rocquencourt,\n  DMA), Gabor Lugosi (ICREA), Gilles Stoltz (INRIA Paris - Rocquencourt, DMA,\n  GREGH)", "title": "Mirror Descent Meets Fixed Share (and feels no regret)", "comments": null, "journal-ref": "NIPS 2012, Lake Tahoe : United States (2012)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror descent with an entropic regularizer is known to achieve shifting\nregret bounds that are logarithmic in the dimension. This is done using either\na carefully designed projection or by a weight sharing technique. Via a novel\nunified analysis, we show that these two approaches deliver essentially\nequivalent bounds on a notion of regret generalizing shifting, adaptive,\ndiscounted, and other related regrets. Our analysis also captures and extends\nthe generalized weight sharing technique of Bousquet and Warmuth, and can be\nrefined in several ways, including improvements for small losses and adaptive\ntuning of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 14:39:42 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2012 19:39:42 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", "", "INRIA Paris - Rocquencourt,\n  DMA"], ["Gaillard", "Pierre", "", "INRIA Paris - Rocquencourt,\n  DMA"], ["Lugosi", "Gabor", "", "ICREA"], ["Stoltz", "Gilles", "", "INRIA Paris - Rocquencourt, DMA,\n  GREGH"]]}, {"id": "1202.3335", "submitter": "Sarge Rogatch", "authors": "Sarge Rogatch", "title": "An efficient high-quality hierarchical clustering algorithm for\n  automatic inference of software architecture from the source code of a\n  software system", "comments": "130 pages. I am looking for someone serious about investing into\n  development of a commercial tool on the basis of my algorithm and my\n  prototype. arXiv admin note: text overlap with arXiv:0803.4025 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  It is a high-quality algorithm for hierarchical clustering of large software\nsource code. This effectively allows to break the complexity of tens of\nmillions lines of source code, so that a human software engineer can comprehend\na software system at high level by means of looking at its architectural\ndiagram that is reconstructed automatically from the source code of the\nsoftware system. The architectural diagram shows a tree of subsystems having\nOOP classes in its leaves (in the other words, a nested software\ndecomposition). The tool reconstructs the missing\n(inconsistent/incomplete/inexistent) architectural documentation for a software\nsystem from its source code. This facilitates software maintenance: change\nrequests can be performed substantially faster. Simply speaking, this unique\ntool allows to lift the comprehensible grain of object-oriented software\nsystems from OOP class-level to subsystem-level. It is estimated that a\ncommercial tool, developed on the basis of this work, will reduce software\nmaintenance expenses 10 times on the current needs, and will allow to implement\nnext-generation software systems which are currently too complex to be within\nthe range of human comprehension, therefore can't yet be designed or\nimplemented. Implemented prototype in Open Source:\nhttp://sourceforge.net/p/insoar/code-0/1/tree/\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 15:03:01 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Rogatch", "Sarge", ""]]}, {"id": "1202.3505", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis, Petros Drineas, Malik Magdon-Ismail", "title": "Near-optimal Coresets For Least-Squares Regression", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2013.2272457", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study (constrained) least-squares regression as well as multiple response\nleast-squares regression and ask the question of whether a subset of the data,\na coreset, suffices to compute a good approximate solution to the regression.\nWe give deterministic, low order polynomial-time algorithms to construct such\ncoresets with approximation guarantees, together with lower bounds indicating\nthat there is not much room for improvement upon our results.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 03:07:35 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2013 20:58:43 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Boutsidis", "Christos", ""], ["Drineas", "Petros", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1202.3639", "submitter": "Karthekeyan Chandrasekaran", "authors": "Karthekeyan Chandrasekaran and Richard Karp", "title": "Finding a most biased coin with fewest flips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a most biased coin among a set of coins by\ntossing the coins adaptively. The goal is to minimize the number of tosses\nuntil we identify a coin i* whose posterior probability of being most biased is\nat least 1-delta for a given delta. Under a particular probabilistic model, we\ngive an optimal algorithm, i.e., an algorithm that minimizes the expected\nnumber of future tosses. The problem is closely related to finding the best arm\nin the multi-armed bandit problem using adaptive strategies. Our algorithm\nemploys an optimal adaptive strategy -- a strategy that performs the best\npossible action at each step after observing the outcomes of all previous coin\ntosses. Consequently, our algorithm is also optimal for any starting history of\noutcomes. To our knowledge, this is the first algorithm that employs an optimal\nadaptive strategy under a Bayesian setting for this problem. Our proof of\noptimality employs tools from the field of Markov games.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 16:40:56 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2012 14:53:35 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2013 17:09:32 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Chandrasekaran", "Karthekeyan", ""], ["Karp", "Richard", ""]]}, {"id": "1202.3663", "submitter": "Brendan Ames", "authors": "Brendan P. W. Ames", "title": "Guaranteed clustering and biclustering via semidefinite programming", "comments": null, "journal-ref": null, "doi": "10.1007/s10107-013-0729-x", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying clusters of similar objects in data plays a significant role in a\nwide range of applications. As a model problem for clustering, we consider the\ndensest k-disjoint-clique problem, whose goal is to identify the collection of\nk disjoint cliques of a given weighted complete graph maximizing the sum of the\ndensities of the complete subgraphs induced by these cliques. In this paper, we\nestablish conditions ensuring exact recovery of the densest k cliques of a\ngiven graph from the optimal solution of a particular semidefinite program. In\nparticular, the semidefinite relaxation is exact for input graphs corresponding\nto data consisting of k large, distinct clusters and a smaller number of\noutliers. This approach also yields a semidefinite relaxation for the\nbiclustering problem with similar recovery guarantees. Given a set of objects\nand a set of features exhibited by these objects, biclustering seeks to\nsimultaneously group the objects and features according to their expression\nlevels. This problem may be posed as partitioning the nodes of a weighted\nbipartite complete graph such that the sum of the densities of the resulting\nbipartite complete subgraphs is maximized. As in our analysis of the densest\nk-disjoint-clique problem, we show that the correct partition of the objects\nand features can be recovered from the optimal solution of a semidefinite\nprogram in the case that the given data consists of several disjoint sets of\nobjects exhibiting similar features. Empirical evidence from numerical\nexperiments supporting these theoretical guarantees is also provided.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 18:41:42 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 21:48:07 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2012 20:40:39 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2013 20:55:20 GMT"}, {"version": "v5", "created": "Wed, 6 Nov 2013 01:07:19 GMT"}, {"version": "v6", "created": "Mon, 18 Nov 2013 22:47:23 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Ames", "Brendan P. W.", ""]]}, {"id": "1202.3701", "submitter": "Gowtham Bellala", "authors": "Gowtham Bellala, Jason Stanley, Clayton Scott, Suresh K. Bhavnani", "title": "Active Diagnosis via AUC Maximization: An Efficient Approach for\n  Multiple Fault Identification in Large Scale, Noisy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-35-42", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of active diagnosis arises in several applications such as\ndisease diagnosis, and fault diagnosis in computer networks, where the goal is\nto rapidly identify the binary states of a set of objects (e.g., faulty or\nworking) by sequentially selecting, and observing, (noisy) responses to binary\nvalued queries. Current algorithms in this area rely on loopy belief\npropagation for active query selection. These algorithms have an exponential\ntime complexity, making them slow and even intractable in large networks. We\npropose a rank-based greedy algorithm that sequentially chooses queries such\nthat the area under the ROC curve of the rank-based output is maximized. The\nAUC criterion allows us to make a simplifying assumption that significantly\nreduces the complexity of active query selection (from exponential to near\nquadratic), with little or no compromise on the performance quality.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Bellala", "Gowtham", ""], ["Stanley", "Jason", ""], ["Scott", "Clayton", ""], ["Bhavnani", "Suresh K.", ""]]}, {"id": "1202.3702", "submitter": "Avleen S. Bijral", "authors": "Avleen S. Bijral, Nathan Ratliff, Nathan Srebro", "title": "Semi-supervised Learning with Density Based Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-43-50", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple, yet effective, approach to Semi-Supervised Learning. Our\napproach is based on estimating density-based distances (DBD) using a shortest\npath calculation on a graph. These Graph-DBD estimates can then be used in any\ndistance-based supervised learning method, such as Nearest Neighbor methods and\nSVMs with RBF kernels. In order to apply the method to very large data sets, we\nalso present a novel algorithm which integrates nearest neighbor computations\ninto the shortest path search and can find exact shortest paths even in\nextremely large dense graphs. Significant runtime improvement over the commonly\nused Laplacian regularization method is then shown on a large scale dataset.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Bijral", "Avleen S.", ""], ["Ratliff", "Nathan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1202.3704", "submitter": "Mithun Chakraborty", "authors": "Mithun Chakraborty, Sanmay Das, Malik Magdon-Ismail", "title": "Near-Optimal Target Learning With Stochastic Binary Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-69-76", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning in a noisy bisection model: specifically, Bayesian\nalgorithms to learn a target value V given access only to noisy realizations of\nwhether V is less than or greater than a threshold theta. At step t = 0, 1, 2,\n..., the learner sets threshold theta t and observes a noisy realization of\nsign(V - theta t). After T steps, the goal is to output an estimate V^ which is\nwithin an eta-tolerance of V . This problem has been studied, predominantly in\nenvironments with a fixed error probability q < 1/2 for the noisy realization\nof sign(V - theta t). In practice, it is often the case that q can approach\n1/2, especially as theta -> V, and there is little known when this happens. We\ngive a pseudo-Bayesian algorithm which provably converges to V. When the true\nprior matches our algorithm's Gaussian prior, we show near-optimal expected\nperformance. Our methods extend to the general multiple-threshold setting where\nthe observation noisily indicates which of k >= 2 regions V belongs to.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Chakraborty", "Mithun", ""], ["Das", "Sanmay", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1202.3708", "submitter": "Xi Chen", "authors": "Xi Chen, Qihang Lin, Seyoung Kim, Jaime G. Carbonell, Eric P. Xing", "title": "Smoothing Proximal Gradient Method for General Structured Sparse\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1005.4717", "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-105-114", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning high dimensional regression models\nregularized by a structured-sparsity-inducing penalty that encodes prior\nstructural information on either input or output sides. We consider two widely\nadopted types of such penalties as our motivating examples: 1) overlapping\ngroup lasso penalty, based on the l1/l2 mixed-norm penalty, and 2) graph-guided\nfusion penalty. For both types of penalties, due to their non-separability,\ndeveloping an efficient optimization method has remained a challenging problem.\nIn this paper, we propose a general optimization approach, called smoothing\nproximal gradient method, which can solve the structured sparse regression\nproblems with a smooth convex loss and a wide spectrum of\nstructured-sparsity-inducing penalties. Our approach is based on a general\nsmoothing technique of Nesterov. It achieves a convergence rate faster than the\nstandard first-order method, subgradient method, and is much more scalable than\nthe most widely used interior-point method. Numerical results are reported to\ndemonstrate the efficiency and scalability of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Chen", "Xi", ""], ["Lin", "Qihang", ""], ["Kim", "Seyoung", ""], ["Carbonell", "Jaime G.", ""], ["Xing", "Eric P.", ""]]}, {"id": "1202.3712", "submitter": "Corinna Cortes", "authors": "Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh", "title": "Ensembles of Kernel Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-145-152", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the problem of learning with a finite and possibly large\nset of p base kernels. It presents a theoretical and empirical analysis of an\napproach addressing this problem based on ensembles of kernel predictors. This\nincludes novel theoretical guarantees based on the Rademacher complexity of the\ncorresponding hypothesis sets, the introduction and analysis of a learning\nalgorithm based on these hypothesis sets, and a series of experiments using\nensembles of kernel predictors with several data sets. Both convex combinations\nof kernel-based hypotheses and more general Lq-regularized nonnegative\ncombinations are analyzed. These theoretical, algorithmic, and empirical\nresults are compared with those achieved by using learning kernel techniques,\nwhich can be viewed as another approach for solving the same problem.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "1202.3714", "submitter": "Kun Deng", "authors": "Kun Deng, Joelle Pineau, Susan A. Murphy", "title": "Active Learning for Developing Personalized Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-161-168", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personalization of treatment via bio-markers and other risk categories\nhas drawn increasing interest among clinical scientists. Personalized treatment\nstrategies can be learned using data from clinical trials, but such trials are\nvery costly to run. This paper explores the use of active learning techniques\nto design more efficient trials, addressing issues such as whom to recruit, at\nwhat point in the trial, and which treatment to assign, throughout the duration\nof the trial. We propose a minimax bandit model with two different optimization\ncriteria, and discuss the computational challenges and issues pertaining to\nthis approach. We evaluate our active learning policies using both simulated\ndata, and data modeled after a clinical trial for treating depressed\nindividuals, and contrast our methods with other plausible active learning\npolicies.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Deng", "Kun", ""], ["Pineau", "Joelle", ""], ["Murphy", "Susan A.", ""]]}, {"id": "1202.3716", "submitter": "Narayanan U. Edakunni", "authors": "Narayanan U. Edakunni, Gary Brown, Tim Kovacs", "title": "Boosting as a Product of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-187-194", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a novel probabilistic model of boosting as a Product\nof Experts. We re-derive the boosting algorithm as a greedy incremental model\nselection procedure which ensures that addition of new experts to the ensemble\ndoes not decrease the likelihood of the data. These learning rules lead to a\ngeneric boosting algorithm - POE- Boost which turns out to be similar to the\nAdaBoost algorithm under certain assumptions on the expert probabilities. The\npaper then extends the POEBoost algorithm to POEBoost.CS which handles\nhypothesis that produce probabilistic predictions. This new algorithm is shown\nto have better generalization performance compared to other state of the art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Edakunni", "Narayanan U.", ""], ["Brown", "Gary", ""], ["Kovacs", "Tim", ""]]}, {"id": "1202.3717", "submitter": "Mahdi MIlani Fard", "authors": "Mahdi MIlani Fard, Joelle Pineau, Csaba Szepesvari", "title": "PAC-Bayesian Policy Evaluation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-195-202", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian priors offer a compact yet general means of incorporating domain\nknowledge into many learning tasks. The correctness of the Bayesian analysis\nand inference, however, largely depends on accuracy and correctness of these\npriors. PAC-Bayesian methods overcome this problem by providing bounds that\nhold regardless of the correctness of the prior distribution. This paper\nintroduces the first PAC-Bayesian bound for the batch reinforcement learning\nproblem with function approximation. We show how this bound can be used to\nperform model-selection in a transfer learning scenario. Our empirical results\nconfirm that PAC-Bayesian policy evaluation is able to leverage prior\ndistributions when they are informative and, unlike standard Bayesian RL\napproaches, ignore them when they are misleading.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Fard", "Mahdi MIlani", ""], ["Pineau", "Joelle", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1202.3722", "submitter": "Inmar Givoni", "authors": "Inmar Givoni, Clement Chung, Brendan J. Frey", "title": "Hierarchical Affinity Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-238-246", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affinity propagation is an exemplar-based clustering algorithm that finds a\nset of data-points that best exemplify the data, and associates each datapoint\nwith one exemplar. We extend affinity propagation in a principled way to solve\nthe hierarchical clustering problem, which arises in a variety of domains\nincluding biology, sensor networks and decision making in operational research.\nWe derive an inference algorithm that operates by propagating information up\nand down the hierarchy, and is efficient despite the high-order potentials\nrequired for the graphical model formulation. We demonstrate that our method\noutperforms greedy techniques that cluster one layer at a time. We show that on\nan artificial dataset designed to mimic the HIV-strain mutation dynamics, our\nmethod outperforms related methods. For real HIV sequences, where the ground\ntruth is not available, we show our method achieves better results, in terms of\nthe underlying objective function, and show the results correspond meaningfully\nto geographical location and strain subtypes. Finally we report results on\nusing the method for the analysis of mass spectra, showing it performs\nfavorably compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Givoni", "Inmar", ""], ["Chung", "Clement", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1202.3725", "submitter": "Quanquan Gu", "authors": "Quanquan Gu, Zhenhui Li, Jiawei Han", "title": "Generalized Fisher Score for Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-266-273", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher score is one of the most widely used supervised feature selection\nmethods. However, it selects each feature independently according to their\nscores under the Fisher criterion, which leads to a suboptimal subset of\nfeatures. In this paper, we present a generalized Fisher score to jointly\nselect features. It aims at finding an subset of features, which maximize the\nlower bound of traditional Fisher score. The resulting feature selection\nproblem is a mixed integer programming, which can be reformulated as a\nquadratically constrained linear programming (QCLP). It is solved by cutting\nplane algorithm, in each iteration of which a multiple kernel learning problem\nis solved alternatively by multivariate ridge regression and projected gradient\ndescent. Experiments on benchmark data sets indicate that the proposed method\noutperforms Fisher score as well as many other state-of-the-art feature\nselection methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Gu", "Quanquan", ""], ["Li", "Zhenhui", ""], ["Han", "Jiawei", ""]]}, {"id": "1202.3726", "submitter": "Andrew Guillory", "authors": "Andrew Guillory, Jeff A. Bilmes", "title": "Active Semi-Supervised Learning using Submodular Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-274-282", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active, semi-supervised learning in an offline transductive\nsetting. We show that a previously proposed error bound for active learning on\nundirected weighted graphs can be generalized by replacing graph cut with an\narbitrary symmetric submodular function. Arbitrary non-symmetric submodular\nfunctions can be used via symmetrization. Different choices of submodular\nfunctions give different versions of the error bound that are appropriate for\ndifferent kinds of problems. Moreover, the bound is deterministic and holds for\nadversarially chosen labels. We show exactly minimizing this error bound is\nNP-complete. However, we also introduce for any submodular function an\nassociated active semi-supervised learning method that approximately minimizes\nthe corresponding error bound. We show that the error bound is tight in the\nsense that there is no other bound of the same form which is better. Our\ntheoretical results are supported by experiments on real data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Guillory", "Andrew", ""], ["Bilmes", "Jeff A.", ""]]}, {"id": "1202.3727", "submitter": "Michael Gutmann", "authors": "Michael Gutmann, Jun-ichiro Hirayama", "title": "Bregman divergence as general framework to estimate unnormalized\n  statistical models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-283-290", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Bregman divergence provides a rich framework to estimate\nunnormalized statistical models for continuous or discrete random variables,\nthat is, models which do not integrate or sum to one, respectively. We prove\nthat recent estimation methods such as noise-contrastive estimation, ratio\nmatching, and score matching belong to the proposed framework, and explain\ntheir interconnection based on supervised learning. Further, we discuss the\nrole of boosting in unsupervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Gutmann", "Michael", ""], ["Hirayama", "Jun-ichiro", ""]]}, {"id": "1202.3730", "submitter": "Jouni Hartikainen", "authors": "Jouni Hartikainen, Simo Sarkka", "title": "Sequential Inference for Latent Force Models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-311-318", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent force models (LFMs) are hybrid models combining mechanistic principles\nwith non-parametric components. In this article, we shall show how LFMs can be\nequivalently formulated and solved using the state variable approach. We shall\nalso show how the Gaussian process prior used in LFMs can be equivalently\nformulated as a linear statespace model driven by a white noise process and how\ninference on the resulting model can be efficiently implemented using Kalman\nfilter and smoother. Then we shall show how the recently proposed switching LFM\ncan be reformulated using the state variable approach, and how we can construct\na probabilistic model for the switches by formulating a similar switching LFM\nas a switching linear dynamic system (SLDS). We illustrate the performance of\nthe proposed methodology in simulated scenarios and apply it to inferring the\nswitching points in GPS data collected from car movement data in urban\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Hartikainen", "Jouni", ""], ["Sarkka", "Simo", ""]]}, {"id": "1202.3731", "submitter": "Uri Heinemann", "authors": "Uri Heinemann, Amir Globerson", "title": "What Cannot be Learned with Bethe Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-319-326", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning the parameters in graphical models when\ninference is intractable. A common strategy in this case is to replace the\npartition function with its Bethe approximation. We show that there exists a\nregime of empirical marginals where such Bethe learning will fail. By failure\nwe mean that the empirical marginals cannot be recovered from the approximated\nmaximum likelihood parameters (i.e., moment matching is not achieved). We\nprovide several conditions on empirical marginals that yield outer and inner\nbounds on the set of Bethe learnable marginals. An interesting implication of\nour results is that there exists a large class of marginals that cannot be\nobtained as stable fixed points of belief propagation. Taken together our\nresults provide a novel approach to analyzing learning with Bethe\napproximations and highlight when it can be expected to work or fail.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Heinemann", "Uri", ""], ["Globerson", "Amir", ""]]}, {"id": "1202.3732", "submitter": "Hoifung Poon", "authors": "Hoifung Poon, Pedro Domingos", "title": "Sum-Product Networks: A New Deep Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-337-346", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key limiting factor in graphical model inference and learning is the\ncomplexity of the partition function. We thus ask the question: what are\ngeneral conditions under which the partition function is tractable? The answer\nleads to a new kind of deep architecture, which we call sum-product networks\n(SPNs). SPNs are directed acyclic graphs with variables as leaves, sums and\nproducts as internal nodes, and weighted edges. We show that if an SPN is\ncomplete and consistent it represents the partition function and all marginals\nof some graphical model, and give semantics to its nodes. Essentially all\ntractable graphical models can be cast as SPNs, but SPNs are also strictly more\ngeneral. We then propose learning algorithms for SPNs, based on backpropagation\nand EM. Experiments show that inference and learning with SPNs can be both\nfaster and more accurate than with standard deep networks. For example, SPNs\nperform image completion better than state-of-the-art deep networks for this\ntask. SPNs also have intriguing potential connections to the architecture of\nthe cortex.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Poon", "Hoifung", ""], ["Domingos", "Pedro", ""]]}, {"id": "1202.3733", "submitter": "Jean Honorio", "authors": "Jean Honorio", "title": "Lipschitz Parametrization of Probabilistic Graphical Models", "comments": null, "journal-ref": "Uncertainty in Artificial Intelligence (UAI), 2011", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the log-likelihood of several probabilistic graphical models is\nLipschitz continuous with respect to the lp-norm of the parameters. We discuss\nseveral implications of Lipschitz parametrization. We present an upper bound of\nthe Kullback-Leibler divergence that allows understanding methods that penalize\nthe lp-norm of differences of parameters as the minimization of that upper\nbound. The expected log-likelihood is lower bounded by the negative lp-norm,\nwhich allows understanding the generalization ability of probabilistic models.\nThe exponential of the negative lp-norm is involved in the lower bound of the\nBayes error rate, which shows that it is reasonable to use parameters as\nfeatures in algorithms that rely on metric spaces (e.g. classification,\ndimensionality reduction, clustering). Our results do not rely on specific\nalgorithms for learning the structure or parameters. We show preliminary\nresults for activity recognition and temporal segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Honorio", "Jean", ""]]}, {"id": "1202.3734", "submitter": "Jonathan Huang", "authors": "Jonathan Huang, Ashish Kapoor, Carlos E. Guestrin", "title": "Efficient Probabilistic Inference with Partial Ranking Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-355-362", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions over rankings are used to model data in various settings such\nas preference analysis and political elections. The factorial size of the space\nof rankings, however, typically forces one to make structural assumptions, such\nas smoothness, sparsity, or probabilistic independence about these underlying\ndistributions. We approach the modeling problem from the computational\nprinciple that one should make structural assumptions which allow for efficient\ncalculation of typical probabilistic queries. For ranking models, \"typical\"\nqueries predominantly take the form of partial ranking queries (e.g., given a\nuser's top-k favorite movies, what are his preferences over remaining movies?).\nIn this paper, we argue that riffled independence factorizations proposed in\nrecent literature [7, 8] are a natural structural assumption for ranking\ndistributions, allowing for particularly efficient processing of partial\nranking queries.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Huang", "Jonathan", ""], ["Kapoor", "Ashish", ""], ["Guestrin", "Carlos E.", ""]]}, {"id": "1202.3735", "submitter": "Antti Hyttinen", "authors": "Antti Hyttinen, Frederick Eberhardt, Patrik O. Hoyer", "title": "Noisy-OR Models with Latent Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-363-372", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of experiments in which varying subsets of observed variables are\nsubject to intervention, we consider the problem of identifiability of causal\nmodels exhibiting latent confounding. While identifiability is trivial when\neach experiment intervenes on a large number of variables, the situation is\nmore complicated when only one or a few variables are subject to intervention\nper experiment. For linear causal models with latent variables Hyttinen et al.\n(2010) gave precise conditions for when such data are sufficient to identify\nthe full model. While their result cannot be extended to discrete-valued\nvariables with arbitrary cause-effect relationships, we show that a similar\nresult can be obtained for the class of causal models whose conditional\nprobability distributions are restricted to a `noisy-OR' parameterization. We\nfurther show that identification is preserved under an extension of the model\nthat allows for negative influences, and present learning algorithms that we\ntest for accuracy, scalability and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Hyttinen", "Antti", ""], ["Eberhardt", "Frederick", ""], ["Hoyer", "Patrik O.", ""]]}, {"id": "1202.3736", "submitter": "Takanori Inazumi", "authors": "Takanori Inazumi, Takashi Washio, Shohei Shimizu, Joe Suzuki, Akihiro\n  Yamamoto, Yoshinobu Kawahara", "title": "Discovering causal structures in binary exclusive-or skew acyclic models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-373-382", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal relations among observed variables in a given data set is\na main topic in studies of statistics and artificial intelligence. Recently,\nsome techniques to discover an identifiable causal structure have been explored\nbased on non-Gaussianity of the observed data distribution. However, most of\nthese are limited to continuous data. In this paper, we present a novel causal\nmodel for binary data and propose a new approach to derive an identifiable\ncausal structure governing the data based on skew Bernoulli distributions of\nexternal noise. Experimental evaluation shows excellent performance for both\nartificial and real world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Inazumi", "Takanori", ""], ["Washio", "Takashi", ""], ["Shimizu", "Shohei", ""], ["Suzuki", "Joe", ""], ["Yamamoto", "Akihiro", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1202.3737", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Eleni Sgouritsa, Oliver Stegle, Jonas Peters,\n  Bernhard Schoelkopf", "title": "Detecting low-complexity unobserved causes", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-383-391", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method that infers whether statistical dependences between two\nobserved variables X and Y are due to a \"direct\" causal link or only due to a\nconnecting causal path that contains an unobserved variable of low complexity,\ne.g., a binary variable. This problem is motivated by statistical genetics.\nGiven a genetic marker that is correlated with a phenotype of interest, we want\nto detect whether this marker is causal or it only correlates with a causal\none. Our method is based on the analysis of the location of the conditional\ndistributions P(Y|x) in the simplex of all distributions of Y. We report\nencouraging results on semi-empirical data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Janzing", "Dominik", ""], ["Sgouritsa", "Eleni", ""], ["Stegle", "Oliver", ""], ["Peters", "Jonas", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1202.3738", "submitter": "Alex Kulesza", "authors": "Alex Kulesza, Ben Taskar", "title": "Learning Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-419-427", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs), which arise in random matrix theory and\nquantum physics, are natural models for subset selection problems where\ndiversity is preferred. Among many remarkable properties, DPPs offer tractable\nalgorithms for exact inference, including computing marginal probabilities and\nsampling; however, an important open question has been how to learn a DPP from\nlabeled training data. In this paper we propose a natural feature-based\nparameterization of conditional DPPs, and show how it leads to a convex and\nefficient learning formulation. We analyze the relationship between our model\nand binary Markov random fields with repulsive potentials, which are\nqualitatively similar but computationally intractable. Finally, we apply our\napproach to the task of extractive summarization, where the goal is to choose a\nsmall subset of sentences conveying the most important information from a set\nof documents. In this task there is a fundamental tradeoff between sentences\nthat are highly relevant to the collection as a whole, and sentences that are\ndiverse and not repetitive. Our parameterization allows us to naturally balance\nthese two characteristics. We evaluate our system on data from the DUC 2003/04\nmulti-document summarization task, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Kulesza", "Alex", ""], ["Taskar", "Ben", ""]]}, {"id": "1202.3742", "submitter": "Qiang Liu", "authors": "Qiang Liu, Alexander T. Ihler", "title": "Variational Algorithms for Marginal MAP", "comments": "conference version. full journal version is at arXiv:1302.6584", "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-453-462", "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal MAP problems are notoriously difficult tasks for graphical models.\nWe derive a general variational framework for solving marginal MAP problems, in\nwhich we apply analogues of the Bethe, tree-reweighted, and mean field\napproximations. We then derive a \"mixed\" message passing algorithm and a\nconvergent alternative using CCCP to solve the BP-type approximations.\nTheoretically, we give conditions under which the decoded solution is a global\nor local optimum, and obtain novel upper bounds on solutions. Experimentally we\ndemonstrate that our algorithms outperform related approaches. We also show\nthat EM and variational EM comprise a special case of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Liu", "Qiang", ""], ["Ihler", "Alexander T.", ""]]}, {"id": "1202.3746", "submitter": "Benjamin Marlin", "authors": "Benjamin Marlin, Nando de Freitas", "title": "Asymptotic Efficiency of Deterministic Estimators for Discrete\n  Energy-Based Models: Ratio Matching and Pseudolikelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-497-505", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard maximum likelihood estimation cannot be applied to discrete\nenergy-based models in the general case because the computation of exact model\nprobabilities is intractable. Recent research has seen the proposal of several\nnew estimators designed specifically to overcome this intractability, but\nvirtually nothing is known about their theoretical properties. In this paper,\nwe present a generalized estimator that unifies many of the classical and\nrecently proposed estimators. We use results from the standard asymptotic\ntheory for M-estimators to derive a generic expression for the asymptotic\ncovariance matrix of our generalized estimator. We apply these results to study\nthe relative statistical efficiency of classical pseudolikelihood and the\nrecently-proposed ratio matching estimator.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Marlin", "Benjamin", ""], ["de Freitas", "Nando", ""]]}, {"id": "1202.3747", "submitter": "David Mimno", "authors": "David Mimno", "title": "Reconstructing Pompeian Households", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-506-513", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A database of objects discovered in houses in the Roman city of Pompeii\nprovides a unique view of ordinary life in an ancient city. Experts have used\nthis collection to study the structure of Roman households, exploring the\ndistribution and variability of tasks in architectural spaces, but such\napproaches are necessarily affected by modern cultural assumptions. In this\nstudy we present a data-driven approach to household archeology, treating it as\nan unsupervised labeling problem. This approach scales to large data sets and\nprovides a more objective complement to human interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Mimno", "David", ""]]}, {"id": "1202.3748", "submitter": "Volodymyr Mnih", "authors": "Volodymyr Mnih, Hugo Larochelle, Geoffrey E. Hinton", "title": "Conditional Restricted Boltzmann Machines for Structured Output\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-514-522", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic\nmodels that have recently been applied to a wide range of problems, including\ncollaborative filtering, classification, and modeling motion capture data.\nWhile much progress has been made in training non-conditional RBMs, these\nalgorithms are not applicable to conditional models and there has been almost\nno work on training and generating predictions from conditional RBMs for\nstructured output problems. We first argue that standard Contrastive\nDivergence-based learning may not be suitable for training CRBMs. We then\nidentify two distinct types of structured output prediction problems and\npropose an improved learning algorithm for each. The first problem type is one\nwhere the output space has arbitrary structure but the set of likely output\nconfigurations is relatively small, such as in multi-label classification. The\nsecond problem is one where the output space is arbitrarily structured but\nwhere the output space variability is much greater, such as in image denoising\nor pixel labeling. We show that the new learning algorithms can work much\nbetter than Contrastive Divergence on both types of problems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Mnih", "Volodymyr", ""], ["Larochelle", "Hugo", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1202.3750", "submitter": "Ananda Narayanan B", "authors": "Ananda Narayanan B, Balaraman Ravindran", "title": "Fractional Moments on Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-531-538", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning addresses the dilemma between exploration to find\nprofitable actions and exploitation to act according to the best observations\nalready made. Bandit problems are one such class of problems in stateless\nenvironments that represent this explore/exploit situation. We propose a\nlearning algorithm for bandit problems based on fractional expectation of\nrewards acquired. The algorithm is theoretically shown to converge on an\neta-optimal arm and achieve O(n) sample complexity. Experimental results show\nthe algorithm incurs substantially lower regrets than parameter-optimized\neta-greedy and SoftMax approaches and other low sample complexity\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["B", "Ananda Narayanan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1202.3752", "submitter": "Nebojsa Jojic", "authors": "Nebojsa Jojic, Alessandro Perina", "title": "Multidimensional counting grids: Inferring word order from disordered\n  bags of words", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-547-556", "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of bags of words typically assume topic mixing so that the words in a\nsingle bag come from a limited number of topics. We show here that many sets of\nbag of words exhibit a very different pattern of variation than the patterns\nthat are efficiently captured by topic mixing. In many cases, from one bag of\nwords to the next, the words disappear and new ones appear as if the theme\nslowly and smoothly shifted across documents (providing that the documents are\nsomehow ordered). Examples of latent structure that describe such ordering are\neasily imagined. For example, the advancement of the date of the news stories\nis reflected in a smooth change over the theme of the day as certain evolving\nnews stories fall out of favor and new events create new stories. Overlaps\namong the stories of consecutive days can be modeled by using windows over\nlinearly arranged tight distributions over words. We show here that such\nstrategy can be extended to multiple dimensions and cases where the ordering of\ndata is not readily obvious. We demonstrate that this way of modeling\ncovariation in word occurrences outperforms standard topic models in\nclassification and prediction tasks in applications in biology, text modeling\nand computer vision.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Jojic", "Nebojsa", ""], ["Perina", "Alessandro", ""]]}, {"id": "1202.3753", "submitter": "Teppo Niinimaki", "authors": "Teppo Niinimaki, Pekka Parviainen, Mikko Koivisto", "title": "Partial Order MCMC for Structure Discovery in Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-557-564", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Markov chain Monte Carlo method for estimating posterior\nprobabilities of structural features in Bayesian networks. The method draws\nsamples from the posterior distribution of partial orders on the nodes; for\neach sampled partial order, the conditional probabilities of interest are\ncomputed exactly. We give both analytical and empirical results that suggest\nthe superiority of the new method compared to previous methods, which sample\neither directed acyclic graphs or linear orders on the nodes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Niinimaki", "Teppo", ""], ["Parviainen", "Pekka", ""], ["Koivisto", "Mikko", ""]]}, {"id": "1202.3757", "submitter": "Jonas Peters", "authors": "Jonas Peters, Joris Mooij, Dominik Janzing, Bernhard Schoelkopf", "title": "Identifiability of Causal Graphs using Functional Models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-589-598", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the following question: Under what assumptions on the\ndata generating process can one infer the causal graph from the joint\ndistribution? The approach taken by conditional independence-based causal\ndiscovery methods is based on two assumptions: the Markov condition and\nfaithfulness. It has been shown that under these assumptions the causal graph\ncan be identified up to Markov equivalence (some arrows remain undirected)\nusing methods like the PC algorithm. In this work we propose an alternative by\ndefining Identifiable Functional Model Classes (IFMOCs). As our main theorem we\nprove that if the data generating process belongs to an IFMOC, one can identify\nthe complete causal graph. To the best of our knowledge this is the first\nidentifiability result of this kind that is not limited to linear functional\nrelationships. We discuss how the IFMOC assumption and the Markov and\nfaithfulness assumptions relate to each other and explain why we believe that\nthe IFMOC assumption can be tested more easily on given data. We further\nprovide a practical algorithm that recovers the causal graph from finitely many\ndata; experiments on simulated data support the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Peters", "Jonas", ""], ["Mooij", "Joris", ""], ["Janzing", "Dominik", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1202.3758", "submitter": "Barnabas Poczos", "authors": "Barnabas Poczos, Liang Xiong, Jeff Schneider", "title": "Nonparametric Divergence Estimation with Applications to Machine\n  Learning on Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-599-608", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional embedding, manifold learning, clustering, classification, and\nanomaly detection are among the most important problems in machine learning.\nThe existing methods usually consider the case when each instance has a fixed,\nfinite-dimensional feature representation. Here we consider a different\nsetting. We assume that each instance corresponds to a continuous probability\ndistribution. These distributions are unknown, but we are given some i.i.d.\nsamples from each distribution. Our goal is to estimate the distances between\nthese distributions and use these distances to perform low-dimensional\nembedding, clustering/classification, or anomaly detection for the\ndistributions. We present estimation algorithms, describe how to apply them for\nmachine learning tasks on distributions, and show empirical results on\nsynthetic data, real word images, and astronomical data sets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Poczos", "Barnabas", ""], ["Xiong", "Liang", ""], ["Schneider", "Jeff", ""]]}, {"id": "1202.3760", "submitter": "Vinayak Rao", "authors": "Vinayak Rao, Yee Whye Teh", "title": "Fast MCMC sampling for Markov jump processes and continuous time\n  Bayesian networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-619-626", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov jump processes and continuous time Bayesian networks are important\nclasses of continuous time dynamical systems. In this paper, we tackle the\nproblem of inferring unobserved paths in these models by introducing a fast\nauxiliary variable Gibbs sampler. Our approach is based on the idea of\nuniformization, and sets up a Markov chain over paths by sampling a finite set\nof virtual jump times and then running a standard hidden Markov model forward\nfiltering-backward sampling algorithm over states at the set of extant and\nvirtual jump times. We demonstrate significant computational benefits over a\nstate-of-the-art Gibbs sampler on a number of continuous time Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Rao", "Vinayak", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1202.3761", "submitter": "Nima Reyhani", "authors": "Nima Reyhani, Hideitsu Hino, Ricardo Vigario", "title": "New Probabilistic Bounds on Eigenvalues and Eigenvectors of Random\n  Kernel Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-627-634", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are successful approaches for different machine learning\nproblems. This success is mainly rooted in using feature maps and kernel\nmatrices. Some methods rely on the eigenvalues/eigenvectors of the kernel\nmatrix, while for other methods the spectral information can be used to\nestimate the excess risk. An important question remains on how close the sample\neigenvalues/eigenvectors are to the population values. In this paper, we\nimprove earlier results on concentration bounds for eigenvalues of general\nkernel matrices. For distance and inner product kernel functions, e.g. radial\nbasis functions, we provide new concentration bounds, which are characterized\nby the eigenvalues of the sample covariance matrix. Meanwhile, the obstacles\nfor sharper bounds are accounted for and partially addressed. As a case study,\nwe derive a concentration inequality for sample kernel target-alignment.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Reyhani", "Nima", ""], ["Hino", "Hideitsu", ""], ["Vigario", "Ricardo", ""]]}, {"id": "1202.3763", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Thomas S. Richardson, James M. Robins", "title": "An Efficient Algorithm for Computing Interventional Distributions in\n  Latent Variable Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-661-670", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inference in graphical models is the task of computing marginal\nand conditional densities of interest from a factorized representation of a\njoint probability distribution. Inference algorithms such as variable\nelimination and belief propagation take advantage of constraints embedded in\nthis factorization to compute such densities efficiently. In this paper, we\npropose an algorithm which computes interventional distributions in latent\nvariable causal models represented by acyclic directed mixed graphs(ADMGs). To\ncompute these distributions efficiently, we take advantage of a recursive\nfactorization which generalizes the usual Markov factorization for DAGs and the\nmore recent factorization for ADMGs. Our algorithm can be viewed as a\ngeneralization of variable elimination to the mixed graph case. We show our\nalgorithm is exponential in the mixed graph generalization of treewidth.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Shpitser", "Ilya", ""], ["Richardson", "Thomas S.", ""], ["Robins", "James M.", ""]]}, {"id": "1202.3765", "submitter": "Inma Tur", "authors": "Inma Tur, Robert Castelo", "title": "Learning mixed graphical models from data with p larger than n", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-689-697", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure learning of Gaussian graphical models is an extensively studied\nproblem in the classical multivariate setting where the sample size n is larger\nthan the number of random variables p, as well as in the more challenging\nsetting when p>>n. However, analogous approaches for learning the structure of\ngraphical models with mixed discrete and continuous variables when p>>n remain\nlargely unexplored. Here we describe a statistical learning procedure for this\nproblem based on limited-order correlations and assess its performance with\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Tur", "Inma", ""], ["Castelo", "Robert", ""]]}, {"id": "1202.3766", "submitter": "Maomi Ueno", "authors": "Maomi Ueno", "title": "Robust learning Bayesian networks for prior belief", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-698-707", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reports have described that learning Bayesian networks are highly\nsensitive to the chosen equivalent sample size (ESS) in the Bayesian Dirichlet\nequivalence uniform (BDeu). This sensitivity often engenders some unstable or\nundesirable results. This paper describes some asymptotic analyses of BDeu to\nexplain the reasons for the sensitivity and its effects. Furthermore, this\npaper presents a proposal for a robust learning score for ESS by eliminating\nthe sensitive factors from the approximation of log-BDeu.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Ueno", "Maomi", ""]]}, {"id": "1202.3769", "submitter": "Feng Yan", "authors": "Feng Yan, Zenglin Xu, Yuan (Alan) Qi", "title": "Sparse matrix-variate Gaussian process blockmodels for network modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-745-752", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We face network data from various sources, such as protein interactions and\nonline social networks. A critical problem is to model network interactions and\nidentify latent groups of network nodes. This problem is challenging due to\nmany reasons. For example, the network nodes are interdependent instead of\nindependent of each other, and the data are known to be very noisy (e.g.,\nmissing edges). To address these challenges, we propose a new relational model\nfor network data, Sparse Matrix-variate Gaussian process Blockmodel (SMGB). Our\nmodel generalizes popular bilinear generative models and captures nonlinear\nnetwork interactions using a matrix-variate Gaussian process with latent\nmembership variables. We also assign sparse prior distributions on the latent\nmembership variables to learn sparse group assignments for individual network\nnodes. To estimate the latent variables efficiently from data, we develop an\nefficient variational expectation maximization method. We compared our\napproaches with several state-of-the-art network models on both synthetic and\nreal-world network datasets. Experimental results demonstrate SMGBs outperform\nthe alternative approaches in terms of discovering latent classes or predicting\nunknown interactions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Yan", "Feng", "", "Alan"], ["Xu", "Zenglin", "", "Alan"], ["Yuan", "", "", "Alan"], ["Qi", "", ""]]}, {"id": "1202.3770", "submitter": "Jian-Bo Yang", "authors": "Jian-Bo Yang, Ivor W. Tsang", "title": "Hierarchical Maximum Margin Learning for Multi-Class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-753-760", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to myriads of classes, designing accurate and efficient classifiers\nbecomes very challenging for multi-class classification. Recent research has\nshown that class structure learning can greatly facilitate multi-class\nlearning. In this paper, we propose a novel method to learn the class structure\nfor multi-class classification problems. The class structure is assumed to be a\nbinary hierarchical tree. To learn such a tree, we propose a maximum separating\nmargin method to determine the child nodes of any internal node. The proposed\nmethod ensures that two classgroups represented by any two sibling nodes are\nmost separable. In the experiments, we evaluate the accuracy and efficiency of\nthe proposed method over other multi-class classification methods on real world\nlarge-scale problems. The results show that the proposed method outperforms\nbenchmark methods in terms of accuracy for most datasets and performs\ncomparably with other class structure learning methods in terms of efficiency\nfor all datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Yang", "Jian-Bo", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1202.3771", "submitter": "Julian Yarkony", "authors": "Julian Yarkony, Ragib Morshed, Alexander T. Ihler, Charless C. Fowlkes", "title": "Tightening MRF Relaxations with Planar Subproblems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-770-777", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new technique for computing lower-bounds on the minimum energy\nconfiguration of a planar Markov Random Field (MRF). Our method successively\nadds large numbers of constraints and enforces consistency over binary\nprojections of the original problem state space. These constraints are\nrepresented in terms of subproblems in a dual-decomposition framework that is\noptimized using subgradient techniques. The complete set of constraints we\nconsider enforces cycle consistency over the original graph. In practice we\nfind that the method converges quickly on most problems with the addition of a\nfew subproblems and outperforms existing methods for some interesting classes\nof hard potentials.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Yarkony", "Julian", ""], ["Morshed", "Ragib", ""], ["Ihler", "Alexander T.", ""], ["Fowlkes", "Charless C.", ""]]}, {"id": "1202.3772", "submitter": "Yao-Liang Yu", "authors": "Yao-Liang Yu, Dale Schuurmans", "title": "Rank/Norm Regularization with Closed-Form Solutions: Application to\n  Subspace Clustering", "comments": "11 pages, 1 figure, appeared in UAI 2011. One footnote corrected and\n  appendix added", "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-778-785", "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is sampled from an unknown subspace, principal component analysis\n(PCA) provides an effective way to estimate the subspace and hence reduce the\ndimension of the data. At the heart of PCA is the Eckart-Young-Mirsky theorem,\nwhich characterizes the best rank k approximation of a matrix. In this paper,\nwe prove a generalization of the Eckart-Young-Mirsky theorem under all\nunitarily invariant norms. Using this result, we obtain closed-form solutions\nfor a set of rank/norm regularized problems, and derive closed-form solutions\nfor a general class of subspace clustering problems (where data is modelled by\nunions of unknown subspaces). From these results we obtain new theoretical\ninsights and promising experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 21:00:59 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Yu", "Yao-Liang", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1202.3774", "submitter": "Chao Zhang", "authors": "Chao Zhang, Dacheng Tao", "title": "Risk Bounds for Infinitely Divisible Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-796-803", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the risk bounds for samples independently drawn from\nan infinitely divisible (ID) distribution. In particular, based on a martingale\nmethod, we develop two deviation inequalities for a sequence of random\nvariables of an ID distribution with zero Gaussian component. By applying the\ndeviation inequalities, we obtain the risk bounds based on the covering number\nfor the ID distribution. Finally, we analyze the asymptotic convergence of the\nrisk bound derived from one of the two deviation inequalities and show that the\nconvergence rate of the bound is faster than the result for the generic i.i.d.\nempirical process (Mendelson, 2003).\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zhang", "Chao", ""], ["Tao", "Dacheng", ""]]}, {"id": "1202.3775", "submitter": "Kun Zhang", "authors": "Kun Zhang, Jonas Peters, Dominik Janzing, Bernhard Schoelkopf", "title": "Kernel-based Conditional Independence Test and Application in Causal\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-804-813", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional independence testing is an important problem, especially in\nBayesian network learning and causal discovery. Due to the curse of\ndimensionality, testing for conditional independence of continuous variables is\nparticularly challenging. We propose a Kernel-based Conditional Independence\ntest (KCI-test), by constructing an appropriate test statistic and deriving its\nasymptotic distribution under the null hypothesis of conditional independence.\nThe proposed method is computationally efficient and easy to implement.\nExperimental results show that it outperforms other methods, especially when\nthe conditioning set is large or the sample size is not very large, in which\ncase other methods encounter difficulties.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zhang", "Kun", ""], ["Peters", "Jonas", ""], ["Janzing", "Dominik", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1202.3776", "submitter": "Xinhua Zhang", "authors": "Xinhua Zhang, Ankan Saha, S. V.N. Vishwanatan", "title": "Smoothing Multivariate Performance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-814-821", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Support Vector Method for multivariate performance measures was recently\nintroduced by Joachims (2005). The underlying optimization problem is currently\nsolved using cutting plane methods such as SVM-Perf and BMRM. One can show that\nthese algorithms converge to an eta accurate solution in O(1/Lambda*e)\niterations, where lambda is the trade-off parameter between the regularizer and\nthe loss function. We present a smoothing strategy for multivariate performance\nscores, in particular precision/recall break-even point and ROCArea. When\ncombined with Nesterov's accelerated gradient algorithm our smoothing strategy\nyields an optimization algorithm which converges to an eta accurate solution in\nO(min{1/e,1/sqrt(lambda*e)}) iterations. Furthermore, the cost per iteration of\nour scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on a\nnumber of publicly available datasets shows that our method converges\nsignificantly faster than cutting plane methods without sacrificing\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zhang", "Xinhua", ""], ["Saha", "Ankan", ""], ["Vishwanatan", "S. V. N.", ""]]}, {"id": "1202.3778", "submitter": "Jun Zhu", "authors": "Jun Zhu, Eric P. Xing", "title": "Sparse Topical Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-831-838", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sparse topical coding (STC), a non-probabilistic formulation of\ntopic models for discovering latent representations of large collections of\ndata. Unlike probabilistic topic models, STC relaxes the normalization\nconstraint of admixture proportions and the constraint of defining a normalized\nlikelihood function. Such relaxations make STC amenable to: 1) directly control\nthe sparsity of inferred representations by using sparsity-inducing\nregularizers; 2) be seamlessly integrated with a convex error function (e.g.,\nSVM hinge loss) for supervised learning; and 3) be efficiently learned with a\nsimply structured coordinate descent algorithm. Our results demonstrate the\nadvantages of STC and supervised MedSTC on identifying topical meanings of\nwords and improving classification accuracy and time efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zhu", "Jun", ""], ["Xing", "Eric P.", ""]]}, {"id": "1202.3779", "submitter": "Jakob Zscheischler", "authors": "Jakob Zscheischler, Dominik Janzing, Kun Zhang", "title": "Testing whether linear equations are causal: A free probability theory\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-839-846", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that infers whether linear relations between two\nhigh-dimensional variables X and Y are due to a causal influence from X to Y or\nfrom Y to X. The earlier proposed so-called Trace Method is extended to the\nregime where the dimension of the observed variables exceeds the sample size.\nBased on previous work, we postulate conditions that characterize a causal\nrelation between X and Y. Moreover, we describe a statistical test and argue\nthat both causal directions are typically rejected if there is a common cause.\nA full theoretical analysis is presented for the deterministic case but our\napproach seems to be valid for the noisy case, too, for which we additionally\npresent an approach based on a sparsity constraint. The discussed method yields\npromising results for both simulated and real world data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zscheischler", "Jakob", ""], ["Janzing", "Dominik", ""], ["Zhang", "Kun", ""]]}, {"id": "1202.3782", "submitter": "Kareem Amin", "authors": "Kareem Amin, Michael Kearns, Umar Syed", "title": "Graphical Models for Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-1-10", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a rich class of graphical models for multi-armed bandit problems\nthat permit both the state or context space and the action space to be very\nlarge, yet succinctly specify the payoffs for any context-action pair. Our main\nresult is an algorithm for such models whose regret is bounded by the number of\nparameters and whose running time depends only on the treewidth of the graph\nsubstructure induced by the action space.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Amin", "Kareem", ""], ["Kearns", "Michael", ""], ["Syed", "Umar", ""]]}, {"id": "1202.3890", "submitter": "Marcus Hutter", "authors": "Tor Lattimore and Marcus Hutter", "title": "PAC Bounds for Discounted MDPs", "comments": "25 LaTeX pages", "journal-ref": "Proc. 23rd International Conf. on Algorithmic Learning Theory (ALT\n  2012) pages 320-334", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study upper and lower bounds on the sample-complexity of learning\nnear-optimal behaviour in finite-state discounted Markov Decision Processes\n(MDPs). For the upper bound we make the assumption that each action leads to at\nmost two possible next-states and prove a new bound for a UCRL-style algorithm\non the number of time-steps when it is not Probably Approximately Correct\n(PAC). The new lower bound strengthens previous work by being both more general\n(it applies to all policies) and tighter. The upper and lower bounds match up\nto logarithmic factors.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 11:59:55 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Lattimore", "Tor", ""], ["Hutter", "Marcus", ""]]}, {"id": "1202.4002", "submitter": "Rene Vidal", "authors": "Rene Vidal, Yi Ma, Shankar Sastry", "title": "Generalized Principal Component Analysis (GPCA)", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol 27, no 12, 2005", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an algebro-geometric solution to the problem of\nsegmenting an unknown number of subspaces of unknown and varying dimensions\nfrom sample data points. We represent the subspaces with a set of homogeneous\npolynomials whose degree is the number of subspaces and whose derivatives at a\ndata point give normal vectors to the subspace passing through the point. When\nthe number of subspaces is known, we show that these polynomials can be\nestimated linearly from data; hence, subspace segmentation is reduced to\nclassifying one point per subspace. We select these points optimally from the\ndata set by minimizing certain distance function, thus dealing automatically\nwith moderate noise in the data. A basis for the complement of each subspace is\nthen recovered by applying standard PCA to the collection of derivatives\n(normal vectors). Extensions of GPCA that deal with data in a high- dimensional\nspace and with an unknown number of subspaces are also presented. Our\nexperiments on low-dimensional data show that GPCA outperforms existing\nalgebraic algorithms based on polynomial factorization and provides a good\ninitialization to iterative techniques such as K-subspaces and Expectation\nMaximization. We also present applications of GPCA to computer vision problems\nsuch as face clustering, temporal video segmentation, and 3D motion\nsegmentation from point correspondences in multiple affine views.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 20:07:25 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Vidal", "Rene", ""], ["Ma", "Yi", ""], ["Sastry", "Shankar", ""]]}, {"id": "1202.4050", "submitter": "Nishant Mehta", "authors": "Nishant A. Mehta and Alexander G. Gray", "title": "On the Sample Complexity of Predictive Sparse Coding", "comments": "Sparse Coding Stability Theorem from version 1 has been relaxed\n  considerably using a new notion of coding margin. Old Sparse Coding Stability\n  Theorem still in new version, now as Theorem 2. Presentation of all proofs\n  simplified/improved considerably. Paper reorganized. Empirical analysis\n  showing new coding margin is non-trivial on real datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of predictive sparse coding is to learn a representation of examples\nas sparse linear combinations of elements from a dictionary, such that a\nlearned hypothesis linear in the new representation performs well on a\npredictive task. Predictive sparse coding algorithms recently have demonstrated\nimpressive performance on a variety of supervised tasks, but their\ngeneralization properties have not been studied. We establish the first\ngeneralization error bounds for predictive sparse coding, covering two\nsettings: 1) the overcomplete setting, where the number of features k exceeds\nthe original dimensionality d; and 2) the high or infinite-dimensional setting,\nwhere only dimension-free bounds are useful. Both learning bounds intimately\ndepend on stability properties of the learned sparse encoder, as measured on\nthe training sample. Consequently, we first present a fundamental stability\nresult for the LASSO, a result characterizing the stability of the sparse codes\nwith respect to perturbations to the dictionary. In the overcomplete setting,\nwe present an estimation error bound that decays as \\tilde{O}(sqrt(d k/m)) with\nrespect to d and k. In the high or infinite-dimensional setting, we show a\ndimension-free bound that is \\tilde{O}(sqrt(k^2 s / m)) with respect to k and\ns, where s is an upper bound on the number of non-zeros in the sparse code for\nany training data point.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2012 02:28:49 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 00:07:13 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Mehta", "Nishant A.", ""], ["Gray", "Alexander G.", ""]]}, {"id": "1202.4473", "submitter": "Aleksandrs Slivkins", "authors": "Sebastien Bubeck and Aleksandrs Slivkins", "title": "The best of both worlds: stochastic and adversarial bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal),\nwhose regret is, essentially, optimal both for adversarial rewards and for\nstochastic rewards. Specifically, SAO combines the square-root worst-case\nregret of Exp3 (Auer et al., SIAM J. on Computing 2002) and the\n(poly)logarithmic regret of UCB1 (Auer et al., Machine Learning 2002) for\nstochastic rewards. Adversarial rewards and stochastic rewards are the two main\nsettings in the literature on (non-Bayesian) multi-armed bandits. Prior work on\nmulti-armed bandits treats them separately, and does not attempt to jointly\noptimize for both. Our result falls into a general theme of achieving good\nworst-case performance while also taking advantage of \"nice\" problem instances,\nan important issue in the design of algorithms with partially known inputs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 21:29:28 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Bubeck", "Sebastien", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "1202.4478", "submitter": "Elad Hazan", "authors": "Elad Hazan, Sham Kakade", "title": "(weak) Calibration is Computationally Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the existence of a computationally efficient calibration\nalgorithm, with a low weak calibration rate, would imply the existence of an\nefficient algorithm for computing approximate Nash equilibria - thus implying\nthe unlikely conclusion that every problem in PPAD is solvable in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 21:48:09 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham", ""]]}, {"id": "1202.4482", "submitter": "David Balduzzi", "authors": "David Balduzzi, Pedro A Ortega, Michel Besserve", "title": "Metabolic cost as an organizing principle for cooperative learning", "comments": "14 pages, 2 figures, to appear in Advances in Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how neurons can use metabolic cost to facilitate\nlearning at a population level. Although decision-making by individual neurons\nhas been extensively studied, questions regarding how neurons should behave to\ncooperate effectively remain largely unaddressed. Under assumptions that\ncapture a few basic features of cortical neurons, we show that constraining\nreward maximization by metabolic cost aligns the information content of actions\nwith their expected reward. Thus, metabolic cost provides a mechanism whereby\nneurons encode expected reward into their outputs. Further, aside from reducing\nenergy expenditures, imposing a tight metabolic constraint also increases the\naccuracy of empirical estimates of rewards, increasing the robustness of\ndistributed learning. Finally, we present two implementations of metabolically\nconstrained learning that confirm our theoretical finding. These results\nsuggest that metabolic cost may be an organizing principle underlying the\nneural code, and may also provide a useful guide to the design and analysis of\nother cooperating populations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 22:02:16 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2013 21:34:51 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Balduzzi", "David", ""], ["Ortega", "Pedro A", ""], ["Besserve", "Michel", ""]]}, {"id": "1202.5298", "submitter": "Raphael Fonteneau", "authors": "Raphael Fonteneau, Damien Ernst, Bernard Boigelot and Quentin Louveaux", "title": "Min Max Generalization for Two-stage Deterministic Batch Mode\n  Reinforcement Learning: Relaxation Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minmax optimization problem introduced in [22] for computing\npolicies for batch mode reinforcement learning in a deterministic setting.\nFirst, we show that this problem is NP-hard. In the two-stage case, we provide\ntwo relaxation schemes. The first relaxation scheme works by dropping some\nconstraints in order to obtain a problem that is solvable in polynomial time.\nThe second relaxation scheme, based on a Lagrangian relaxation where all\nconstraints are dualized, leads to a conic quadratic programming problem. We\nalso theoretically prove and empirically illustrate that both relaxation\nschemes provide better results than those given in [22].\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 20:53:18 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 16:29:38 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Fonteneau", "Raphael", ""], ["Ernst", "Damien", ""], ["Boigelot", "Bernard", ""], ["Louveaux", "Quentin", ""]]}, {"id": "1202.5514", "submitter": "Simplice Dossou-Gb\\'et\\'e", "authors": "Cheikh Ndour (1,2,3), Aliou Diop (1), Simplice Dossou-Gb\\'et\\'e (2)\n  ((1) Universit\\'e Gaston Berger, Saint-Louis, S\\'en\\'egal (2) Universit\\'e de\n  Pau et des Pays de l 'Adour, Pau, France (3) Universit\\'e de Bordeaux,\n  Bordeaux, France)", "title": "Classification approach based on association rules mining for unbalanced\n  data", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the binary classification task when the target class\nhas the lower probability of occurrence. In such situation, it is not possible\nto build a powerful classifier by using standard methods such as logistic\nregression, classification tree, discriminant analysis, etc. To overcome this\nshort-coming of these methods which yield classifiers with low sensibility, we\ntackled the classification problem here through an approach based on the\nassociation rules learning. This approach has the advantage of allowing the\nidentification of the patterns that are well correlated with the target class.\nAssociation rules learning is a well known method in the area of data-mining.\nIt is used when dealing with large database for unsupervised discovery of local\npatterns that expresses hidden relationships between input variables. In\nconsidering association rules from a supervised learning point of view, a\nrelevant set of weak classifiers is obtained from which one derives a\nclassifier that performs well.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 17:55:33 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2015 21:17:54 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Ndour", "Cheikh", ""], ["Diop", "Aliou", ""], ["Dossou-Gb\u00e9t\u00e9", "Simplice", ""]]}, {"id": "1202.5597", "submitter": "Ali Jalali", "authors": "Javad Azimi, Ali Jalali and Xiaoli Fern", "title": "Hybrid Batch Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization aims at optimizing an unknown non-convex/concave\nfunction that is costly to evaluate. We are interested in application scenarios\nwhere concurrent function evaluations are possible. Under such a setting, BO\ncould choose to either sequentially evaluate the function, one input at a time\nand wait for the output of the function before making the next selection, or\nevaluate the function at a batch of multiple inputs at once. These two\ndifferent settings are commonly referred to as the sequential and batch\nsettings of Bayesian Optimization. In general, the sequential setting leads to\nbetter optimization performance as each function evaluation is selected with\nmore information, whereas the batch setting has an advantage in terms of the\ntotal experimental time (the number of iterations). In this work, our goal is\nto combine the strength of both settings. Specifically, we systematically\nanalyze Bayesian optimization using Gaussian process as the posterior estimator\nand provide a hybrid algorithm that, based on the current state, dynamically\nswitches between a sequential policy and a batch policy with variable batch\nsizes. We provide theoretical justification for our algorithm and present\nexperimental results on eight benchmark BO problems. The results show that our\nmethod achieves substantial speedup (up to %78) compared to a pure sequential\npolicy, without suffering any significant performance loss.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 02:00:51 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 01:55:33 GMT"}, {"version": "v3", "created": "Tue, 1 May 2012 03:08:22 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Azimi", "Javad", ""], ["Jalali", "Ali", ""], ["Fern", "Xiaoli", ""]]}, {"id": "1202.5598", "submitter": "Ali Jalali", "authors": "Ali Jalali and Nathan Srebro", "title": "Clustering using Max-norm Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest using the max-norm as a convex surrogate constraint for\nclustering. We show how this yields a better exact cluster recovery guarantee\nthan previously suggested nuclear-norm relaxation, and study the effectiveness\nof our method, and other related convex relaxations, compared to other\nclustering approaches.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 02:10:20 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2012 22:09:44 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2012 20:56:40 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2012 06:52:44 GMT"}], "update_date": "2012-04-16", "authors_parsed": [["Jalali", "Ali", ""], ["Srebro", "Nathan", ""]]}, {"id": "1202.5695", "submitter": "Hugo Larochelle", "authors": "George E. Dahl, Ryan P. Adams and Hugo Larochelle", "title": "Training Restricted Boltzmann Machines on Word Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted Boltzmann machine (RBM) is a flexible tool for modeling\ncomplex data, however there have been significant computational difficulties in\nusing RBMs to model high-dimensional multinomial observations. In natural\nlanguage processing applications, words are naturally modeled by K-ary discrete\ndistributions, where K is determined by the vocabulary size and can easily be\nin the hundreds of thousands. The conventional approach to training RBMs on\nword observations is limited because it requires sampling the states of K-way\nsoftmax visible units during block Gibbs updates, an operation that takes time\nlinear in K. In this work, we address this issue by employing a more general\nclass of Markov chain Monte Carlo operators on the visible units, yielding\nupdates with computational complexity independent of K. We demonstrate the\nsuccess of our approach by training RBMs on hundreds of millions of word\nn-grams using larger vocabularies than previously feasible and using the\nlearned features to improve performance on chunking and sentiment\nclassification tasks, achieving state-of-the-art results on the latter.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 20:23:37 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2012 12:15:40 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Dahl", "George E.", ""], ["Adams", "Ryan P.", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1202.6001", "submitter": "Hyokun Yun", "authors": "Hyokun Yun and S. V. N. Vishwanathan", "title": "Efficiently Sampling Multiplicative Attribute Graphs Using a\n  Ball-Dropping Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel and efficient sampling algorithm for the Multiplicative\nAttribute Graph Model (MAGM - Kim and Leskovec (2010)}). Our algorithm is\n\\emph{strictly} more efficient than the algorithm proposed by Yun and\nVishwanathan (2012), in the sense that our method extends the \\emph{best} time\ncomplexity guarantee of their algorithm to a larger fraction of parameter\nspace. Both in theory and in empirical evaluation on sparse graphs, our new\nalgorithm outperforms the previous one. To design our algorithm, we first\ndefine a stochastic \\emph{ball-dropping process} (BDP). Although a special case\nof this process was introduced as an efficient approximate sampling algorithm\nfor the Kronecker Product Graph Model (KPGM - Leskovec et al. (2010)}), neither\n\\emph{why} such an approximation works nor \\emph{what} is the actual\ndistribution this process is sampling from has been addressed so far to the\nbest of our knowledge. Our rigorous treatment of the BDP enables us to clarify\nthe rational behind a BDP approximation of KPGM, and design an efficient\nsampling algorithm for the MAGM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 17:17:16 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2012 02:34:47 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Yun", "Hyokun", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "1202.6078", "submitter": "Avishek Saha", "authors": "Hal Daume III, Jeff M. Phillips, Avishek Saha, Suresh\n  Venkatasubramanian", "title": "Protocols for Learning Classifiers on Distributed Data", "comments": "19 pages, 12 figures, accepted at AISTATS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning classifiers for labeled data that has\nbeen distributed across several nodes. Our goal is to find a single classifier,\nwith small approximation error, across all datasets while minimizing the\ncommunication between nodes. This setting models real-world communication\nbottlenecks in the processing of massive distributed datasets. We present\nseveral very general sampling-based solutions as well as some two-way protocols\nwhich have a provable exponential speed-up over any one-way protocol. We focus\non core problems for noiseless data distributed across two or more nodes. The\ntechniques we introduce are reminiscent of active learning, but rather than\nactively probing labels, nodes actively communicate with each other, each node\nsimultaneously learning the important data from another node.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 21:33:32 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Daume", "Hal", "III"], ["Phillips", "Jeff M.", ""], ["Saha", "Avishek", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1202.6103", "submitter": "Dimitrios Giannakis", "authors": "Dimitrios Giannakis and Andrew J. Majda", "title": "Nonlinear Laplacian spectral analysis: Capturing intermittent and\n  low-frequency spatiotemporal patterns in high-dimensional data", "comments": "39 pages, 8 figures, invited paper under review in Statistical\n  Analysis and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for spatiotemporal data analysis called nonlinear\nLaplacian spectral analysis (NLSA), which generalizes singular spectrum\nanalysis (SSA) to take into account the nonlinear manifold structure of complex\ndata sets. The key principle underlying NLSA is that the functions used to\nrepresent temporal patterns should exhibit a degree of smoothness on the\nnonlinear data manifold M; a constraint absent from classical SSA. NLSA\nenforces such a notion of smoothness by requiring that temporal patterns belong\nin low-dimensional Hilbert spaces V_l spanned by the leading l Laplace-Beltrami\neigenfunctions on M. These eigenfunctions can be evaluated efficiently in high\nambient-space dimensions using sparse graph-theoretic algorithms. Moreover,\nthey provide orthonormal bases to expand a family of linear maps, whose\nsingular value decomposition leads to sets of spatiotemporal patterns at\nprogressively finer resolution on the data manifold. The Riemannian measure of\nM and an adaptive graph kernel width enhances the capability of NLSA to detect\nimportant nonlinear processes, including intermittency and rare events. The\nminimum dimension of V_l required to capture these features while avoiding\noverfitting is estimated here using spectral entropy criteria.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 01:53:01 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2012 13:53:24 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Giannakis", "Dimitrios", ""], ["Majda", "Andrew J.", ""]]}, {"id": "1202.6157", "submitter": "Luca Rose", "authors": "Luca Rose, Samir M. Perlaza, M\\'erouane Debbah, Christophe J. Le\n  Martret", "title": "Distributed Power Allocation with SINR Constraints Using Trial and Error\n  Learning", "comments": "6 pages, 3 figures, accepted at WCNC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of global transmit power minimization\nin a self-congiguring network where radio devices are subject to operate at a\nminimum signal to interference plus noise ratio (SINR) level. We model the\nnetwork as a parallel Gaussian interference channel and we introduce a fully\ndecentralized algorithm (based on trial and error) able to statistically\nachieve a congiguration where the performance demands are met. Contrary to\nexisting solutions, our algorithm requires only local information and can learn\nstable and efficient working points by using only one bit feedback. We model\nthe network under two different game theoretical frameworks: normal form and\nsatisfaction form. We show that the converging points correspond to equilibrium\npoints, namely Nash and satisfaction equilibrium. Similarly, we provide\nsufficient conditions for the algorithm to converge in both formulations.\nMoreover, we provide analytical results to estimate the algorithm's\nperformance, as a function of the network parameters. Finally, numerical\nresults are provided to validate our theoretical conclusions. Keywords:\nLearning, power control, trial and error, Nash equilibrium, spectrum sharing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 09:51:29 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Rose", "Luca", ""], ["Perlaza", "Samir M.", ""], ["Debbah", "M\u00e9rouane", ""], ["Martret", "Christophe J. Le", ""]]}, {"id": "1202.6221", "submitter": "Pierre Machart", "authors": "Pierre Machart (LIF, LSIS), Liva Ralaivola (LIF)", "title": "Confusion Matrix Stability Bounds for Multiclass Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide new theoretical results on the generalization\nproperties of learning algorithms for multiclass classification problems. The\noriginality of our work is that we propose to use the confusion matrix of a\nclassifier as a measure of its quality; our contribution is in the line of work\nwhich attempts to set up and study the statistical properties of new evaluation\nmeasures such as, e.g. ROC curves. In the confusion-based learning framework we\npropose, we claim that a targetted objective is to minimize the size of the\nconfusion matrix C, measured through its operator norm ||C||. We derive\ngeneralization bounds on the (size of the) confusion matrix in an extended\nframework of uniform stability, adapted to the case of matrix valued loss.\nPivotal to our study is a very recent matrix concentration inequality that\ngeneralizes McDiarmid's inequality. As an illustration of the relevance of our\ntheoretical results, we show how two SVM learning procedures can be proved to\nbe confusion-friendly. To the best of our knowledge, the present paper is the\nfirst that focuses on the confusion matrix from a theoretical point of view.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 14:03:11 GMT"}, {"version": "v2", "created": "Thu, 24 May 2012 19:27:24 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Machart", "Pierre", "", "LIF, LSIS"], ["Ralaivola", "Liva", "", "LIF"]]}, {"id": "1202.6228", "submitter": "Emilie Morvant", "authors": "Emilie Morvant (LIF), Sokol Ko\\c{c}o (LIF), Liva Ralaivola (LIF)", "title": "PAC-Bayesian Generalization Bound on Confusion Matrix for Multi-Class\n  Classification", "comments": "Arxiv: http://arxiv.org/abs/1202.6228, Accepted at ICML 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a PAC-Bayes bound for the generalization risk of the\nGibbs classifier in the multi-class classification framework. The novelty of\nour work is the critical use of the confusion matrix of a classifier as an\nerror measure; this puts our contribution in the line of work aiming at dealing\nwith performance measure that are richer than mere scalar criterion such as the\nmisclassification rate. Thanks to very recent and beautiful results on matrix\nconcentration inequalities, we derive two bounds showing that the true\nconfusion risk of the Gibbs classifier is upper-bounded by its empirical risk\nplus a term depending on the number of training examples in each class. To the\nbest of our knowledge, this is the first PAC-Bayes bounds based on confusion\nmatrices.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 14:13:01 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 09:29:28 GMT"}, {"version": "v3", "created": "Thu, 24 May 2012 06:26:12 GMT"}, {"version": "v4", "created": "Sat, 30 Jun 2012 19:23:14 GMT"}, {"version": "v5", "created": "Wed, 4 Jul 2012 14:57:53 GMT"}, {"version": "v6", "created": "Tue, 22 Oct 2013 08:25:52 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Morvant", "Emilie", "", "LIF"], ["Ko\u00e7o", "Sokol", "", "LIF"], ["Ralaivola", "Liva", "", "LIF"]]}, {"id": "1202.6258", "submitter": "Nicolas Le Roux", "authors": "Nicolas Le Roux (INRIA Paris - Rocquencourt, LIENS), Mark Schmidt\n  (INRIA Paris - Rocquencourt, LIENS), Francis Bach (INRIA Paris -\n  Rocquencourt, LIENS)", "title": "A Stochastic Gradient Method with an Exponential Convergence Rate for\n  Finite Training Sets", "comments": "The notable changes over the current version: - worked example of\n  convergence rates showing SAG can be faster than first-order methods -\n  pointing out that the storage cost is O(n) for linear models - the\n  more-stable line-search - comparison to additional optimal SG methods -\n  comparison to rates of coordinate descent methods in quadratic case", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new stochastic gradient method for optimizing the sum of a\nfinite set of smooth functions, where the sum is strongly convex. While\nstandard stochastic gradient methods converge at sublinear rates for this\nproblem, the proposed method incorporates a memory of previous gradient values\nin order to achieve a linear convergence rate. In a machine learning context,\nnumerical experiments indicate that the new algorithm can dramatically\noutperform standard algorithms, both in terms of optimizing the training error\nand reducing the test error quickly.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 15:42:51 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2012 19:41:32 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2012 10:59:04 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2013 19:54:48 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Roux", "Nicolas Le", "", "INRIA Paris - Rocquencourt, LIENS"], ["Schmidt", "Mark", "", "INRIA Paris - Rocquencourt, LIENS"], ["Bach", "Francis", "", "INRIA Paris -\n  Rocquencourt, LIENS"]]}, {"id": "1202.6504", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Kenji Fukumizu, Francesco Dinuzzo, Bernhard\n  Sch\\\"olkopf", "title": "Learning from Distributions via Support Measure Machines", "comments": "Advances in Neural Information Processing Systems 25", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a kernel-based discriminative learning framework on\nprobability measures. Rather than relying on large collections of vectorial\ntraining examples, our framework learns using a collection of probability\ndistributions that have been constructed to meaningfully represent training\ndata. By representing these probability distributions as mean embeddings in the\nreproducing kernel Hilbert space (RKHS), we are able to apply many standard\nkernel-based learning techniques in straightforward fashion. To accomplish\nthis, we construct a generalization of the support vector machine (SVM) called\na support measure machine (SMM). Our analyses of SMMs provides several insights\ninto their relationship to traditional SVMs. Based on such insights, we propose\na flexible SVM (Flex-SVM) that places different kernel functions on each\ntraining example. Experimental results on both synthetic and real-world data\ndemonstrate the effectiveness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 10:09:26 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2013 12:43:09 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Muandet", "Krikamol", ""], ["Fukumizu", "Kenji", ""], ["Dinuzzo", "Francesco", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1202.6548", "submitter": "Davide Albanese", "authors": "Davide Albanese and Roberto Visintainer and Stefano Merler and\n  Samantha Riccadonna and Giuseppe Jurman and Cesare Furlanello", "title": "mlpy: Machine Learning Python", "comments": "Corrected a few typos; rephrased two sentences in the Overview\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 13:49:10 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 13:31:54 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Albanese", "Davide", ""], ["Visintainer", "Roberto", ""], ["Merler", "Stefano", ""], ["Riccadonna", "Samantha", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}]