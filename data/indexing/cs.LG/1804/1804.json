[{"id": "1804.00021", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Hsiang-Huang Wu, Yuzhong Yan, Lijun Qian", "title": "Hierarchical Transfer Convolutional Neural Networks for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the issue of how to enhance the generalization\nperformance of convolutional neural networks (CNN) in the early learning stage\nfor image classification. This is motivated by real-time applications that\nrequire the generalization performance of CNN to be satisfactory within limited\ntraining time. In order to achieve this, a novel hierarchical transfer CNN\nframework is proposed. It consists of a group of shallow CNNs and a cloud CNN,\nwhere the shallow CNNs are trained firstly and then the first layers of the\ntrained shallow CNNs are used to initialize the first layer of the cloud CNN.\nThis method will boost the generalization performance of the cloud CNN\nsignificantly, especially during the early stage of training. Experiments using\nCIFAR-10 and ImageNet datasets are performed to examine the proposed method.\nResults demonstrate the improvement of testing accuracy is 12% on average and\nas much as 20% for the CIFAR-10 case while 5% testing accuracy improvement for\nthe ImageNet case during the early stage of learning. It is also shown that\nuniversal improvements of testing accuracy are obtained across different\nsettings of dropout and number of shallow CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 18:19:32 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 19:38:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Dong", "Xishuang", ""], ["Wu", "Hsiang-Huang", ""], ["Yan", "Yuzhong", ""], ["Qian", "Lijun", ""]]}, {"id": "1804.00047", "submitter": "Albert Haque", "authors": "Albert Haque, Michelle Guo, Prateek Verma", "title": "Conditional End-to-End Audio Transforms", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end method for transforming audio from one style to\nanother. For the case of speech, by conditioning on speaker identities, we can\ntrain a single model to transform words spoken by multiple people into multiple\ntarget voices. For the case of music, we can specify musical instruments and\nachieve the same result. Architecturally, our method is a fully-differentiable\nsequence-to-sequence model based on convolutional and hierarchical recurrent\nneural networks. It is designed to capture long-term acoustic dependencies,\nrequires minimal post-processing, and produces realistic audio transforms.\nAblation studies confirm that our model can separate speaker and instrument\nproperties from acoustic content at different receptive fields. Empirically,\nour method achieves competitive performance on community-standard datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 20:17:31 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 06:37:44 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Haque", "Albert", ""], ["Guo", "Michelle", ""], ["Verma", "Prateek", ""]]}, {"id": "1804.00057", "submitter": "Shujian Yu", "authors": "Shujian Yu, Jose C. Principe", "title": "Understanding Autoencoders with Information Theoretic Concepts", "comments": "Paper accepted by Neural Networks. Code for estimating information\n  quantities and drawing the information plane is available from\n  https://drive.google.com/drive/folders/1e5sIywZfmWp4Dn0WEesb6fqQRM0DIGxZ?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their great success in practical applications, there is still a lack\nof theoretical and systematic methods to analyze deep neural networks. In this\npaper, we illustrate an advanced information theoretic methodology to\nunderstand the dynamics of learning and the design of autoencoders, a special\ntype of deep learning architectures that resembles a communication channel. By\ngeneralizing the information plane to any cost function, and inspecting the\nroles and dynamics of different layers using layer-wise information quantities,\nwe emphasize the role that mutual information plays in quantifying learning\nfrom data. We further suggest and also experimentally validate, for mean square\nerror training, three fundamental properties regarding the layer-wise flow of\ninformation and intrinsic dimensionality of the bottleneck layer, using\nrespectively the data processing inequality and the identification of a\nbifurcation point in the information plane that is controlled by the given\ndata. Our observations have a direct impact on the optimal design of\nautoencoders, the design of alternative feedforward training methods, and even\nin the problem of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 21:13:34 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 21:14:20 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 01:29:39 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Yu", "Shujian", ""], ["Principe", "Jose C.", ""]]}, {"id": "1804.00069", "submitter": "Edward Raff", "authors": "Edward Raff, Jared Sylvester, Charles Nicholas", "title": "Engineering a Simplified 0-Bit Consistent Weighted Sampling", "comments": null, "journal-ref": "In Proceedings of the 27th ACM International Conference on\n  Information and Knowledge Management. (2018) 1203-1212", "doi": "10.1145/3269206.3271690", "report-no": null, "categories": "stat.ML cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Min-Hashing approach to sketching has become an important tool in data\nanalysis, information retrial, and classification. To apply it to real-valued\ndatasets, the ICWS algorithm has become a seminal approach that is widely used,\nand provides state-of-the-art performance for this problem space. However, ICWS\nsuffers a computational burden as the sketch size K increases. We develop a new\nSimplified approach to the ICWS algorithm, that enables us to obtain over 20x\nspeedups compared to the standard algorithm. The veracity of our approach is\ndemonstrated empirically on multiple datasets and scenarios, showing that our\nnew Simplified CWS obtains the same quality of results while being an order of\nmagnitude faster.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 22:12:44 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 07:45:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""], ["Nicholas", "Charles", ""]]}, {"id": "1804.00097", "submitter": "Alexey Kurakin", "authors": "Alexey Kurakin, Ian Goodfellow, Samy Bengio, Yinpeng Dong, Fangzhou\n  Liao, Ming Liang, Tianyu Pang, Jun Zhu, Xiaolin Hu, Cihang Xie, Jianyu Wang,\n  Zhishuai Zhang, Zhou Ren, Alan Yuille, Sangxia Huang, Yao Zhao, Yuzhe Zhao,\n  Zhonglin Han, Junjiajia Long, Yerkebulan Berdibekov, Takuya Akiba, Seiya\n  Tokui, Motoki Abe", "title": "Adversarial Attacks and Defences Competition", "comments": "36 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accelerate research on adversarial examples and robustness of machine\nlearning classifiers, Google Brain organized a NIPS 2017 competition that\nencouraged researchers to develop new methods to generate adversarial examples\nas well as to develop new ways to defend against them. In this chapter, we\ndescribe the structure and organization of the competition and the solutions\ndeveloped by several of the top-placing teams.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 00:52:20 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""], ["Bengio", "Samy", ""], ["Dong", "Yinpeng", ""], ["Liao", "Fangzhou", ""], ["Liang", "Ming", ""], ["Pang", "Tianyu", ""], ["Zhu", "Jun", ""], ["Hu", "Xiaolin", ""], ["Xie", "Cihang", ""], ["Wang", "Jianyu", ""], ["Zhang", "Zhishuai", ""], ["Ren", "Zhou", ""], ["Yuille", "Alan", ""], ["Huang", "Sangxia", ""], ["Zhao", "Yao", ""], ["Zhao", "Yuzhe", ""], ["Han", "Zhonglin", ""], ["Long", "Junjiajia", ""], ["Berdibekov", "Yerkebulan", ""], ["Akiba", "Takuya", ""], ["Tokui", "Seiya", ""], ["Abe", "Motoki", ""]]}, {"id": "1804.00099", "submitter": "Dongmian Zou", "authors": "Dongmian Zou, Gilad Lerman", "title": "Graph Convolutional Neural Networks via Scattering", "comments": "26 pages, 9 figures, 4 tables", "journal-ref": "Applied and Computational Harmonic Analysis, 49:3 (2020), pp.\n  1046-1074", "doi": "10.1016/j.acha.2019.06.003", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the scattering transform to graphs and consequently construct a\nconvolutional neural network on graphs. We show that under certain conditions,\nany feature generated by such a network is approximately invariant to\npermutations and stable to graph manipulations. Numerical results demonstrate\ncompetitive performance on relevant datasets.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 01:08:10 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 22:39:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zou", "Dongmian", ""], ["Lerman", "Gilad", ""]]}, {"id": "1804.00104", "submitter": "Emilien Dupont", "authors": "Emilien Dupont", "title": "Learning Disentangled Joint Continuous and Discrete Representations", "comments": "NIPS camera ready, added quantitative evaluation and figures for\n  dsprites dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for learning disentangled and interpretable jointly\ncontinuous and discrete representations in an unsupervised manner. By\naugmenting the continuous latent distribution of variational autoencoders with\na relaxed discrete distribution and controlling the amount of information\nencoded in each latent unit, we show how continuous and categorical factors of\nvariation can be discovered automatically from data. Experiments show that the\nframework disentangles continuous and discrete generative factors on various\ndatasets and outperforms current disentangling methods when a discrete\ngenerative factor is prominent.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 01:37:56 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 01:13:36 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 13:53:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dupont", "Emilien", ""]]}, {"id": "1804.00117", "submitter": "Baoyuan Wu", "authors": "Baoyuan Wu, Fan Jia, Wei Liu, Bernard Ghanem, Siwei Lyu", "title": "Multi-label Learning with Missing Labels using Mixed Dependency Graphs", "comments": "Published in International Journal of Computer Vision, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the problem of multi-label learning with missing labels\n(MLML), which aims to label each test instance with multiple class labels given\ntraining instances that have an incomplete/partial set of these labels. The key\npoint to handle missing labels is propagating the label information from\nprovided labels to missing labels, through a dependency graph that each label\nof each instance is treated as a node. We build this graph by utilizing\ndifferent types of label dependencies. Specifically, the instance-level\nsimilarity is served as undirected edges to connect the label nodes across\ndifferent instances and the semantic label hierarchy is used as directed edges\nto connect different classes. This base graph is referred to as the mixed\ndependency graph, as it includes both undirected and directed edges.\nFurthermore, we present another two types of label dependencies to connect the\nlabel nodes across different classes. One is the class co-occurrence, which is\nalso encoded as undirected edges. Combining with the base graph, we obtain a\nnew mixed graph, called MG-CO (mixed graph with co-occurrence). The other is\nthe sparse and low rank decomposition of the whole label matrix, to embed\nhigh-order dependencies over all labels. Combining with the base graph, the new\nmixed graph is called as MG-SL (mixed graph with sparse and low rank\ndecomposition). Based on MG-CO and MG-SL, we propose two convex transductive\nformulations of the MLML problem, denoted as MLMG-CO and MLMG-SL, respectively.\nTwo important applications, including image annotation and tag based image\nretrieval, can be jointly handled using our proposed methods. Experiments on\nbenchmark datasets show that our methods give significant improvements in\nperformance and robustness to missing labels over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 04:15:11 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Wu", "Baoyuan", ""], ["Jia", "Fan", ""], ["Liu", "Wei", ""], ["Ghanem", "Bernard", ""], ["Lyu", "Siwei", ""]]}, {"id": "1804.00130", "submitter": "Saikat  Chatterjee", "authors": "Ahmed Zaki and Saikat Chatterjee and Partha P. Mitra and Lars K.\n  Rasmussen", "title": "Locally Convex Sparse Learning over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning setup where a sparse signal is estimated\nover a network. Our main interest is to save communication resource for\ninformation exchange over the network and reduce processing time. Each node of\nthe network uses a convex optimization based algorithm that provides a locally\noptimum solution for that node. The nodes exchange their signal estimates over\nthe network in order to refine their local estimates. At a node, the\noptimization algorithm is based on an $\\ell_1$-norm minimization with\nappropriate modifications to promote sparsity as well as to include influence\nof estimates from neighboring nodes. Our expectation is that local estimates in\neach node improve fast and converge, resulting in a limited demand for\ncommunication of estimates between nodes and reducing the processing time. We\nprovide restricted-isometry-property (RIP)-based theoretical analysis on\nestimation quality. In the scenario of clean observation, it is shown that the\nlocal estimates converge to the exact sparse signal under certain technical\nconditions. Simulation results show that the proposed algorithms show\ncompetitive performance compared to a globally optimum distributed LASSO\nalgorithm in the sense of convergence speed and estimation error.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 07:50:38 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Zaki", "Ahmed", ""], ["Chatterjee", "Saikat", ""], ["Mitra", "Partha P.", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1804.00140", "submitter": "Sujit Gujar Dr", "authors": "P Manisha and Sujit Gujar", "title": "Generative Adversarial Networks (GANs): What it can generate and What it\n  cannot?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Generative Adversarial Networks (GANs) have received\nsignificant attention from the research community. With a straightforward\nimplementation and outstanding results, GANs have been used for numerous\napplications. Despite the success, GANs lack a proper theoretical explanation.\nThese models suffer from issues like mode collapse, non-convergence, and\ninstability during training. To address these issues, researchers have proposed\ntheoretically rigorous frameworks inspired by varied fields of Game theory,\nStatistical theory, Dynamical systems, etc.\n  In this paper, we propose to give an appropriate structure to study these\ncontributions systematically. We essentially categorize the papers based on the\nissues they raise and the kind of novelty they introduce to address them.\nBesides, we provide insight into how each of the discussed articles solves the\nconcerned problems. We compare and contrast different results and put forth a\nsummary of theoretical contributions about GANs with focus on image/visual\napplications. We expect this summary paper to give a bird's eye view to a\nperson wishing to understand the theoretical progress in GANs so far.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 09:01:21 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 03:50:51 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Manisha", "P", ""], ["Gujar", "Sujit", ""]]}, {"id": "1804.00217", "submitter": "Seyed Mohammadreza Mousavi Kalan", "authors": "A. Salman Avestimehr, Seyed Mohammadreza Mousavi Kalan, Mahdi\n  Soltanolkotabi", "title": "Fundamental Resource Trade-offs for Encoded Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with the shear size and complexity of today's massive data sets\nrequires computational platforms that can analyze data in a parallelized and\ndistributed fashion. A major bottleneck that arises in such modern distributed\ncomputing environments is that some of the worker nodes may run slow. These\nnodes a.k.a.~stragglers can significantly slow down computation as the slowest\nnode may dictate the overall computational time. A recent computational\nframework, called encoded optimization, creates redundancy in the data to\nmitigate the effect of stragglers. In this paper we develop novel mathematical\nunderstanding for this framework demonstrating its effectiveness in much\nbroader settings than was previously understood. We also analyze the\nconvergence behavior of iterative encoded optimization algorithms, allowing us\nto characterize fundamental trade-offs between convergence rate, size of data\nset, accuracy, computational load (or data redundancy), and straggler\ntoleration in this framework.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 21:29:33 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:04:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Avestimehr", "A. Salman", ""], ["Kalan", "Seyed Mohammadreza Mousavi", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1804.00218", "submitter": "Lazar Valkov", "authors": "Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton,\n  Swarat Chaudhuri", "title": "HOUDINI: Lifelong Learning as Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neurosymbolic framework for the lifelong learning of algorithmic\ntasks that mix perception and procedural reasoning. Reusing high-level concepts\nacross domains and learning complex procedures are key challenges in lifelong\nlearning. We show that a program synthesis approach that combines gradient\ndescent with combinatorial search over programs can be a more effective\nresponse to these challenges than purely neural methods. Our framework, called\nHOUDINI, represents neural networks as strongly typed, differentiable\nfunctional programs that use symbolic higher-order combinators to compose a\nlibrary of neural functions. Our learning algorithm consists of: (1) a symbolic\nprogram synthesizer that performs a type-directed search over parameterized\nprograms, and decides on the library functions to reuse, and the architectures\nto combine them, while learning a sequence of tasks; and (2) a neural module\nthat trains these programs using stochastic gradient descent. We evaluate\nHOUDINI on three benchmarks that combine perception with the algorithmic tasks\nof counting, summing, and shortest-path computation. Our experiments show that\nHOUDINI transfers high-level concepts more effectively than traditional\ntransfer learning and progressive neural networks, and that the typed\nrepresentation of networks significantly accelerates the search.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 21:34:50 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 15:59:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Valkov", "Lazar", ""], ["Chaudhari", "Dipak", ""], ["Srivastava", "Akash", ""], ["Sutton", "Charles", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1804.00222", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein", "title": "Meta-Learning Update Rules for Unsupervised Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major goal of unsupervised learning is to discover data representations\nthat are useful for subsequent tasks, without access to supervised labels\nduring training. Typically, this involves minimizing a surrogate objective,\nsuch as the negative log likelihood of a generative model, with the hope that\nrepresentations useful for subsequent tasks will arise as a side effect. In\nthis work, we propose instead to directly target later desired tasks by\nmeta-learning an unsupervised learning rule which leads to representations\nuseful for those tasks. Specifically, we target semi-supervised classification\nperformance, and we meta-learn an algorithm -- an unsupervised weight update\nrule -- that produces representations useful for this task. Additionally, we\nconstrain our unsupervised update rule to a be a biologically-motivated,\nneuron-local function, which enables it to generalize to different neural\nnetwork architectures, datasets, and data modalities. We show that the\nmeta-learned update rule produces useful features and sometimes outperforms\nexisting unsupervised learning techniques. We further show that the\nmeta-learned unsupervised update rule generalizes to train networks with\ndifferent widths, depths, and nonlinearities. It also generalizes to train on\ndata with randomly permuted input dimensions and even generalizes from image\ndatasets to a text task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 22:44:28 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 01:41:23 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 05:26:00 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Cheung", "Brian", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1804.00229", "submitter": "Alina Striner", "authors": "Alina Striner", "title": "Can Multisensory Cues in VR Help Train Pattern Recognition to Citizen\n  Scientists?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the internet of things (IoT) has integrated physical and digital\ntechnologies, designing for multiple sensory media (mulsemedia) has become more\nattainable. Designing technology for multiple senses has the capacity to\nimprove virtual realism, extend our ability to process information, and more\neasily transfer knowledge between physical and digital environments. HCI\nresearchers are beginning to explore the viability of integrating multimedia\ninto virtual experiences, however research has yet to consider whether\nmulsemedia truly enhances realism, immersion and knowledge transfer. My work\ndeveloping StreamBED, a VR training platform to train citizen science water\nmonitors plans to consider the role of mulsemedia in immersion and learning\ngoals. Future findings about the role of mulsemedia in learning contexts will\npotentially allow learners to experience, connect to, learn from spaces that\nare impossible to experience firsthand.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 00:00:51 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Striner", "Alina", ""]]}, {"id": "1804.00236", "submitter": "Andreas K\\\"olsch", "authors": "Andreas K\\\"olsch, Ashutosh Mishra, Saurabh Varshneya, Muhammad Zeshan\n  Afzal, Marcus Liwicki", "title": "Recognizing Challenging Handwritten Annotations with Fully Convolutional\n  Networks", "comments": null, "journal-ref": "16th International Conference on Frontiers in Handwriting\n  Recognition 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a very challenging dataset of historic German documents\nand evaluates Fully Convolutional Neural Network (FCNN) based methods to locate\nhandwritten annotations of any kind in these documents. The handwritten\nannotations can appear in form of underlines and text by using various writing\ninstruments, e.g., the use of pencils makes the data more challenging. We train\nand evaluate various end-to-end semantic segmentation approaches and report the\nresults. The task is to classify the pixels of documents into two classes:\nbackground and handwritten annotation. The best model achieves a mean\nIntersection over Union (IoU) score of 95.6% on the test documents of the\npresented dataset. We also present a comparison of different strategies used\nfor data augmentation and training on our presented dataset. For evaluation, we\nuse the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout\nAnalysis for Challenging Medieval Manuscripts.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 00:56:02 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 12:40:23 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["K\u00f6lsch", "Andreas", ""], ["Mishra", "Ashutosh", ""], ["Varshneya", "Saurabh", ""], ["Afzal", "Muhammad Zeshan", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1804.00243", "submitter": "Baochang Zhang", "authors": "Baochang Zhang, Lian Zhuo, Ze Wang, Jungong Han, Xiantong Zhen", "title": "The Structure Transfer Machine Theory and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a fundamental but challenging problem, especially\nwhen the distribution of data is unknown. We propose a new representation\nlearning method, termed Structure Transfer Machine (STM), which enables feature\nlearning process to converge at the representation expectation in a\nprobabilistic way. We theoretically show that such an expected value of the\nrepresentation (mean) is achievable if the manifold structure can be\ntransferred from the data space to the feature space. The resulting structure\nregularization term, named manifold loss, is incorporated into the loss\nfunction of the typical deep learning pipeline. The STM architecture is\nconstructed to enforce the learned deep representation to satisfy the intrinsic\nmanifold structure from the data, which results in robust features that suit\nvarious application scenarios, such as digit recognition, image classification\nand object tracking. Compared to state-of-the-art CNN architectures, we achieve\nthe better results on several commonly used benchmarks\\footnote{The source code\nis available. https://github.com/stmstmstm/stm }.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 01:40:10 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 08:17:02 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zhang", "Baochang", ""], ["Zhuo", "Lian", ""], ["Wang", "Ze", ""], ["Han", "Jungong", ""], ["Zhen", "Xiantong", ""]]}, {"id": "1804.00290", "submitter": "Jiacen Zhang", "authors": "Jiacen Zhang, Nakamasa Inoue, Koichi Shinoda", "title": "I-vector Transformation Using Conditional Generative Adversarial\n  Networks for Short Utterance Speaker Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I-vector based text-independent speaker verification (SV) systems often have\npoor performance with short utterances, as the biased phonetic distribution in\na short utterance makes the extracted i-vector unreliable. This paper proposes\nan i-vector compensation method using a generative adversarial network (GAN),\nwhere its generator network is trained to generate a compensated i-vector from\na short-utterance i-vector and its discriminator network is trained to\ndetermine whether an i-vector is generated by the generator or the one\nextracted from a long utterance. Additionally, we assign two other learning\ntasks to the GAN to stabilize its training and to make the generated ivector\nmore speaker-specific. Speaker verification experiments on the NIST SRE 2008\n\"10sec-10sec\" condition show that our method reduced the equal error rate by\n11.3% from the conventional i-vector and PLDA system.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 12:36:03 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Zhang", "Jiacen", ""], ["Inoue", "Nakamasa", ""], ["Shinoda", "Koichi", ""]]}, {"id": "1804.00292", "submitter": "Ronald Kemker", "authors": "Ronald Kemker and Utsav B. Gewali and Christopher Kanan", "title": "EarthMapper: A Tool Box for the Semantic Segmentation of Remote Sensing\n  Imagery", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning continues to push state-of-the-art performance for the semantic\nsegmentation of color (i.e., RGB) imagery; however, the lack of annotated data\nfor many remote sensing sensors (i.e. hyperspectral imagery (HSI)) prevents\nresearchers from taking advantage of this recent success. Since generating\nsensor specific datasets is time intensive and cost prohibitive, remote sensing\nresearchers have embraced deep unsupervised feature extraction. Although these\nmethods have pushed state-of-the-art performance on current HSI benchmarks,\nmany of these tools are not readily accessible to many researchers. In this\nletter, we introduce a software pipeline, which we call EarthMapper, for the\nsemantic segmentation of non-RGB remote sensing imagery. It includes\nself-taught spatial-spectral feature extraction, various standard and deep\nlearning classifiers, and undirected graphical models for post-processing. We\nevaluated EarthMapper on the Indian Pines and Pavia University datasets and\nhave released this code for public use.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 12:44:20 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kemker", "Ronald", ""], ["Gewali", "Utsav B.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1804.00293", "submitter": "Kien Do", "authors": "Kien Do, Truyen Tran, Thin Nguyen, Svetha Venkatesh", "title": "Attentional Multilabel Learning over Graphs: A Message Passing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 13:01:24 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 07:19:29 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Nguyen", "Thin", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1804.00306", "submitter": "Cun Mu", "authors": "Cun Mu, Guang Yang and Zheng Yan", "title": "Revisiting Skip-Gram Negative Sampling Model with Rectification", "comments": "Accepted for publication in the proceedings of 2019 Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit skip-gram negative sampling (SGNS), one of the most popular\nneural-network based approaches to learning distributed word representation. We\nfirst point out the ambiguity issue undermining the SGNS model, in the sense\nthat the word vectors can be entirely distorted without changing the objective\nvalue. To resolve the issue, we investigate the intrinsic structures in\nsolution that a good word embedding model should deliver. Motivated by this, we\nrectify the SGNS model with quadratic regularization, and show that this simple\nmodification suffices to structure the solution in the desired manner. A\ntheoretical justification is presented, which provides novel insights into\nquadratic regularization . Preliminary experiments are also conducted on\nGoogle's analytical reasoning task to support the modified SGNS model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 15:41:01 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:14:55 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Mu", "Cun", ""], ["Yang", "Guang", ""], ["Yan", "Zheng", ""]]}, {"id": "1804.00308", "submitter": "Matthew Jagielski", "authors": "Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina\n  Nita-Rotaru, Bo Li", "title": "Manipulating Machine Learning: Poisoning Attacks and Countermeasures for\n  Regression Learning", "comments": "Preprint of the work accepted for publication at the 39th IEEE\n  Symposium on Security and Privacy, San Francisco, CA, USA, May 21-23, 2018;\n  May 14 '21 update: fixed bug in TRIM algorithm which led to incorrect results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes widely used for automated decisions, attackers\nhave strong incentives to manipulate the results and models generated by\nmachine learning algorithms. In this paper, we perform the first systematic\nstudy of poisoning attacks and their countermeasures for linear regression\nmodels. In poisoning attacks, attackers deliberately influence the training\ndata to manipulate the results of a predictive model. We propose a\ntheoretically-grounded optimization framework specifically designed for linear\nregression and demonstrate its effectiveness on a range of datasets and models.\nWe also introduce a fast statistical attack that requires limited knowledge of\nthe training process. Finally, we design a new principled defense method that\nis highly resilient against all poisoning attacks. We provide formal guarantees\nabout its convergence and an upper bound on the effect of poisoning attacks\nwhen the defense is deployed. We evaluate extensively our attacks and defenses\non three realistic datasets from health care, loan assessment, and real estate\ndomains.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 15:56:43 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 22:17:47 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jagielski", "Matthew", ""], ["Oprea", "Alina", ""], ["Biggio", "Battista", ""], ["Liu", "Chang", ""], ["Nita-Rotaru", "Cristina", ""], ["Li", "Bo", ""]]}, {"id": "1804.00325", "submitter": "James Lucas", "authors": "James Lucas, Shengyang Sun, Richard Zemel, Roger Grosse", "title": "Aggregated Momentum: Stability Through Passive Damping", "comments": "11 primary pages, 11 supplementary pages, 12 figures total", "journal-ref": "International Conference on Learning Representations, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed along low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and analyze\nrates of convergence for quadratic objectives. Empirically, we find that AggMo\nis a suitable drop-in replacement for other momentum methods, and frequently\ndelivers faster convergence.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 17:53:03 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 16:49:44 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 14:09:52 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Lucas", "James", ""], ["Sun", "Shengyang", ""], ["Zemel", "Richard", ""], ["Grosse", "Roger", ""]]}, {"id": "1804.00335", "submitter": "Zhili Feng", "authors": "Zhili Feng, Po-Ling Loh", "title": "Online learning with graph-structured feedback against adaptive\n  adversaries", "comments": "This paper has been accepted to ISIT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive upper and lower bounds for the policy regret of $T$-round online\nlearning problems with graph-structured feedback, where the adversary is\nnonoblivious but assumed to have a bounded memory. We obtain upper bounds of\n$\\widetilde O(T^{2/3})$ and $\\widetilde O(T^{3/4})$ for strongly-observable and\nweakly-observable graphs, respectively, based on analyzing a variant of the\nExp3 algorithm. When the adversary is allowed a bounded memory of size 1, we\nshow that a matching lower bound of $\\widetilde\\Omega(T^{2/3})$ is achieved in\nthe case of full-information feedback. We also study the particular loss\nstructure of an oblivious adversary with switching costs, and show that in such\na setting, non-revealing strongly-observable feedback graphs achieve a lower\nbound of $\\widetilde\\Omega(T^{2/3})$, as well.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 19:56:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Feng", "Zhili", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1804.00338", "submitter": "Le Liang", "authors": "Le Liang and Hao Ye and Geoffrey Ye Li", "title": "Toward Intelligent Vehicular Networks: A Machine Learning Framework", "comments": "Updated title. Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2018.2872122", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As wireless networks evolve towards high mobility and providing better\nsupport for connected vehicles, a number of new challenges arise due to the\nresulting high dynamics in vehicular environments and thus motive rethinking of\ntraditional wireless design methodologies. Future intelligent vehicles, which\nare at the heart of high mobility networks, are increasingly equipped with\nmultiple advanced onboard sensors and keep generating large volumes of data.\nMachine learning, as an effective approach to artificial intelligence, can\nprovide a rich set of tools to exploit such data for the benefit of the\nnetworks. In this article, we first identify the distinctive characteristics of\nhigh mobility vehicular networks and motivate the use of machine learning to\naddress the resulting challenges. After a brief introduction of the major\nconcepts of machine learning, we discuss its applications to learn the dynamics\nof vehicular networks and make informed decisions to optimize network\nperformance. In particular, we discuss in greater detail the application of\nreinforcement learning in managing network resources as an alternative to the\nprevalent optimization approach. Finally, some open issues worth further\ninvestigation are highlighted.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:28:18 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 00:22:58 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 16:03:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Liang", "Le", ""], ["Ye", "Hao", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1804.00341", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson, Peng Zheng, Krithika Manohar, Steven L. Brunton,\n  J. Nathan Kutz and Aleksandr Y. Aravkin", "title": "Sparse Principal Component Analysis via Variable Projection", "comments": null, "journal-ref": "SIAM Journal on Applied Mathematics 2020 80:2, 977-1002", "doi": "10.1137/18M1211350", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (SPCA) has emerged as a powerful\ntechnique for modern data analysis, providing improved interpretation of\nlow-rank structures by identifying localized spatial structures in the data and\ndisambiguating between distinct time scales. We demonstrate a robust and\nscalable SPCA algorithm by formulating it as a value-function optimization\nproblem. This viewpoint leads to a flexible and computationally efficient\nalgorithm. Further, we can leverage randomized methods from linear algebra to\nextend the approach to the large-scale (big data) setting. Our proposed\ninnovation also allows for a robust SPCA formulation which obtains meaningful\nsparse principal components in spite of grossly corrupted input data. The\nproposed algorithms are demonstrated using both synthetic and real world data,\nand show exceptional computational efficiency and diagnostic performance.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:49:56 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 22:41:07 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 02:00:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Zheng", "Peng", ""], ["Manohar", "Krithika", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Aravkin", "Aleksandr Y.", ""]]}, {"id": "1804.00347", "submitter": "Yedid Hoshen", "authors": "Yedid Hoshen, Lior Wolf", "title": "Unsupervised Correlation Analysis", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking between two data sources is a basic building block in numerous\ncomputer vision problems. In this paper, we set to answer a fundamental\ncognitive question: are prior correspondences necessary for linking between\ndifferent domains?\n  One of the most popular methods for linking between domains is Canonical\nCorrelation Analysis (CCA). All current CCA algorithms require correspondences\nbetween the views. We introduce a new method Unsupervised Correlation Analysis\n(UCA), which requires no prior correspondences between the two domains. The\ncorrelation maximization term in CCA is replaced by a combination of a\nreconstruction term (similar to autoencoders), full cycle loss, orthogonality\nand multiple domain confusion terms. Due to lack of supervision, the\noptimization leads to multiple alternative solutions with similar scores and we\ntherefore introduce a consensus-based mechanism that is often able to recover\nthe desired solution. Remarkably, this suffices in order to link remote domains\nsuch as text and images. We also present results on well accepted CCA\nbenchmarks, showing that performance far exceeds other unsupervised baselines,\nand approaches supervised performance in some cases.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 21:14:06 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Hoshen", "Yedid", ""], ["Wolf", "Lior", ""]]}, {"id": "1804.00361", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Sharada Prasanna Mohanty, Carmichael Ong,\n  Zhewei Huang, Shuchang Zhou, Anton Pechenko, Adam Stelmaszczyk, Piotr\n  Jarosik, Mikhail Pavlov, Sergey Kolesnikov, Sergey Plis, Zhibo Chen, Zhizheng\n  Zhang, Jiale Chen, Jun Shi, Zhuobin Zheng, Chun Yuan, Zhihui Lin, Henryk\n  Michalewski, Piotr Mi{\\l}o\\'s, B{\\l}a\\.zej Osi\\'nski, Andrew Melnik, Malte\n  Schilling, Helge Ritter, Sean Carroll, Jennifer Hicks, Sergey Levine, Marcel\n  Salath\\'e, Scott Delp", "title": "Learning to Run challenge solutions: Adapting reinforcement learning\n  methods for neuromusculoskeletal environments", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the NIPS 2017 Learning to Run challenge, participants were tasked with\nbuilding a controller for a musculoskeletal model to make it run as fast as\npossible through an obstacle course. Top participants were invited to describe\ntheir algorithms. In this work, we present eight solutions that used deep\nreinforcement learning approaches, based on algorithms such as Deep\nDeterministic Policy Gradient, Proximal Policy Optimization, and Trust Region\nPolicy Optimization. Many solutions use similar relaxations and heuristics,\nsuch as reward shaping, frame skipping, discretization of the action space,\nsymmetry, and policy blending. However, each of the eight teams implemented\ndifferent modifications of the known algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 00:19:31 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Mohanty", "Sharada Prasanna", ""], ["Ong", "Carmichael", ""], ["Huang", "Zhewei", ""], ["Zhou", "Shuchang", ""], ["Pechenko", "Anton", ""], ["Stelmaszczyk", "Adam", ""], ["Jarosik", "Piotr", ""], ["Pavlov", "Mikhail", ""], ["Kolesnikov", "Sergey", ""], ["Plis", "Sergey", ""], ["Chen", "Zhibo", ""], ["Zhang", "Zhizheng", ""], ["Chen", "Jiale", ""], ["Shi", "Jun", ""], ["Zheng", "Zhuobin", ""], ["Yuan", "Chun", ""], ["Lin", "Zhihui", ""], ["Michalewski", "Henryk", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Melnik", "Andrew", ""], ["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Carroll", "Sean", ""], ["Hicks", "Jennifer", ""], ["Levine", "Sergey", ""], ["Salath\u00e9", "Marcel", ""], ["Delp", "Scott", ""]]}, {"id": "1804.00379", "submitter": "William Fedus", "authors": "Anirudh Goyal, Philemon Brakel, William Fedus, Soumye Singhal, Timothy\n  Lillicrap, Sergey Levine, Hugo Larochelle, Yoshua Bengio", "title": "Recall Traces: Backtracking Models for Efficient Reinforcement Learning", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many environments only a tiny subset of all states yield high reward. In\nthese cases, few of the interactions with the environment provide a relevant\nlearning signal. Hence, we may want to preferentially train on those\nhigh-reward states and the probable trajectories leading to them. To this end,\nwe advocate for the use of a backtracking model that predicts the preceding\nstates that terminate at a given high-reward state. We can train a model which,\nstarting from a high value state (or one that is estimated to have high value),\npredicts and sample for which the (state, action)-tuples may have led to that\nhigh value state. These traces of (state, action) pairs, which we refer to as\nRecall Traces, sampled from this backtracking model starting from a high value\nstate, are informative as they terminate in good states, and hence we can use\nthese traces to improve a policy. We provide a variational interpretation for\nthis idea and a practical algorithm in which the backtracking model samples\nfrom an approximate posterior distribution over trajectories which lead to\nlarge rewards. Our method improves the sample efficiency of both on- and\noff-policy RL algorithms across several environments and tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 03:02:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 22:56:28 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Goyal", "Anirudh", ""], ["Brakel", "Philemon", ""], ["Fedus", "William", ""], ["Singhal", "Soumye", ""], ["Lillicrap", "Timothy", ""], ["Levine", "Sergey", ""], ["Larochelle", "Hugo", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.00381", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Zexin Cai, Wenbo Liu, Xiaoqi Wang and Ming Li", "title": "Insights into End-to-End Learning Scheme for Language Identification", "comments": "ICASSP 2018 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel interpretable end-to-end learning scheme for language identification\nis proposed. It is in line with the classical GMM i-vector methods both\ntheoretically and practically. In the end-to-end pipeline, a general encoding\nlayer is employed on top of the front-end CNN, so that it can encode the\nvariable-length input sequence into an utterance level vector automatically.\nAfter comparing with the state-of-the-art GMM i-vector methods, we give\ninsights into CNN, and reveal its role and effect in the whole pipeline. We\nfurther introduce a general encoding layer, illustrating the reason why they\nmight be appropriate for language identification. We elaborate on several\ntypical encoding layers, including a temporal average pooling layer, a\nrecurrent encoding layer and a novel learnable dictionary encoding layer. We\nconducted experiment on NIST LRE07 closed-set task, and the results show that\nour proposed end-to-end systems achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 03:19:44 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Cai", "Weicheng", ""], ["Cai", "Zexin", ""], ["Liu", "Wenbo", ""], ["Wang", "Xiaoqi", ""], ["Li", "Ming", ""]]}, {"id": "1804.00385", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Zexin Cai, Xiang Zhang, Xiaoqi Wang and Ming Li", "title": "A Novel Learnable Dictionary Encoding Layer for End-to-End Language\n  Identification", "comments": "ICASSP 2018 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel learnable dictionary encoding layer is proposed in this paper for\nend-to-end language identification. It is inline with the conventional GMM\ni-vector approach both theoretically and practically. We imitate the mechanism\nof traditional GMM training and Supervector encoding procedure on the top of\nCNN. The proposed layer can accumulate high-order statistics from\nvariable-length input sequence and generate an utterance level\nfixed-dimensional vector representation. Unlike the conventional methods, our\nnew approach provides an end-to-end learning framework, where the inherent\ndictionary are learned directly from the loss function. The dictionaries and\nthe encoding representation for the classifier are learned jointly. The\nrepresentation is orderless and therefore appropriate for language\nidentification. We conducted a preliminary experiment on NIST LRE07 closed-set\ntask, and the results reveal that our proposed dictionary encoding layer\nachieves significant error reduction comparing with the simple average pooling.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 03:31:01 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Cai", "Weicheng", ""], ["Cai", "Zexin", ""], ["Zhang", "Xiang", ""], ["Wang", "Xiaoqi", ""], ["Li", "Ming", ""]]}, {"id": "1804.00403", "submitter": "Ke Ding", "authors": "Ke Ding", "title": "A Note on Kaldi's PLDA Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some explanations to Kaldi's PLDA implementation to make formula derivation\neasier to catch.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 05:44:59 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Ding", "Ke", ""]]}, {"id": "1804.00408", "submitter": "Nilin Abrahamsen", "authors": "Nilin Abrahamsen, Philippe Rigollet", "title": "Sparse Gaussian ICA", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a cornerstone of modern data\nanalysis. Its goal is to recover a latent random vector S with independent\ncomponents from samples of X=AS where A is an unknown mixing matrix.\nCritically, all existing methods for ICA rely on and exploit strongly the\nassumption that S is not Gaussian as otherwise A becomes unidentifiable. In\nthis paper, we show that in fact one can handle the case of Gaussian components\nby imposing structure on the matrix A. Specifically, we assume that A is sparse\nand generic in the sense that it is generated from a sparse Bernoulli-Gaussian\nensemble. Under this condition, we give an efficient algorithm to recover the\ncolumns of A given only the covariance matrix of X as input even when S has\nseveral Gaussian components.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 06:14:08 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 14:07:46 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Abrahamsen", "Nilin", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1804.00432", "submitter": "Jong Chul Ye", "authors": "Dongwook Lee, Jaejun Yoo, Sungho Tak and Jong Chul Ye", "title": "Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks", "comments": "This paper will appear in IEEE Trans. Biomedical Engineering, Special\n  Section on Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 09:08:02 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Lee", "Dongwook", ""], ["Yoo", "Jaejun", ""], ["Tak", "Sungho", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1804.00456", "submitter": "Oleksii Zhelo", "authors": "Oleksii Zhelo, Jingwei Zhang, Lei Tai, Ming Liu, Wolfram Burgard", "title": "Curiosity-driven Exploration for Mapless Navigation with Deep\n  Reinforcement Learning", "comments": "5 pages, 4 figures; to be published in MLPC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates exploration strategies of Deep Reinforcement Learning\n(DRL) methods to learn navigation policies for mobile robots. In particular, we\naugment the normal external reward for training DRL algorithms with intrinsic\nreward signals measured by curiosity. We test our approach in a mapless\nnavigation setting, where the autonomous agent is required to navigate without\nthe occupancy map of the environment, to targets whose relative locations can\nbe easily acquired through low-cost solutions (e.g., visible light\nlocalization, Wi-Fi signal localization). We validate that the intrinsic\nmotivation is crucial for improving DRL performance in tasks with challenging\nexploration requirements. Our experimental results show that our proposed\nmethod is able to more effectively learn navigation policies, and has better\ngeneralization capabilities in previously unseen environments. A video of our\nexperimental results can be found at https://goo.gl/pWbpcF.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 11:40:00 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:08:26 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhelo", "Oleksii", ""], ["Zhang", "Jingwei", ""], ["Tai", "Lei", ""], ["Liu", "Ming", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1804.00490", "submitter": "Masayuki Tanaka", "authors": "Masayuki Tanaka", "title": "Learnable Image Encryption", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network-based machine learning algorithm is very powerful tools. However,\nit requires huge training dataset. Researchers often meet privacy issues when\nthey collect image dataset especially for surveillance applications. A\nlearnable image encryption scheme is introduced. The key idea of this scheme is\nto encrypt images, so that human cannot understand images but the network can\nbe train with encrypted images. This scheme allows us to train the network\nwithout the privacy issues. In this paper, a simple learnable image encryption\nalgorithm is proposed. Then, the proposed algorithm is validated with cifar\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 05:44:53 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Tanaka", "Masayuki", ""]]}, {"id": "1804.00495", "submitter": "Macheng Shen", "authors": "Macheng Shen, Golnaz Habibi, Jonathan P. How", "title": "Transferable Pedestrian Motion Prediction Models at Intersections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One desirable capability of autonomous cars is to accurately predict the\npedestrian motion near intersections for safe and efficient trajectory\nplanning. We are interested in developing transfer learning algorithms that can\nbe trained on the pedestrian trajectories collected at one intersection and yet\nstill provide accurate predictions of the trajectories at another, previously\nunseen intersection. We first discussed the feature selection for transferable\npedestrian motion models in general. Following this discussion, we developed\none transferable pedestrian motion prediction algorithm based on Inverse\nReinforcement Learning (IRL) that infers pedestrian intentions and predicts\nfuture trajectories based on observed trajectory. We evaluated our algorithm on\na dataset collected at two intersections, trained at one intersection and\ntested at the other intersection. We used the accuracy of augmented\nsemi-nonnegative sparse coding (ASNSC), trained and tested at the same\nintersection as a baseline. The result shows that the proposed algorithm\nimproves the baseline accuracy by 40% in the non-transfer task, and 16% in the\ntransfer task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 23:58:19 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 23:51:54 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shen", "Macheng", ""], ["Habibi", "Golnaz", ""], ["How", "Jonathan P.", ""]]}, {"id": "1804.00499", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini and Radha Poovendran", "title": "Semantic Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 18:02:14 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Hosseini", "Hossein", ""], ["Poovendran", "Radha", ""]]}, {"id": "1804.00522", "submitter": "Ehsan Hosseini-Asl", "authors": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher", "title": "A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech\n  Domain Adaptation", "comments": "Accepted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation plays an important role for speech recognition models, in\nparticular, for domains that have low resources. We propose a novel generative\nmodel based on cyclic-consistent generative adversarial network (CycleGAN) for\nunsupervised non-parallel speech domain adaptation. The proposed model employs\nmultiple independent discriminators on the power spectrogram, each in charge of\ndifferent frequency bands. As a result we have 1) better discriminators that\nfocus on fine-grained details of the frequency features, and 2) a generator\nthat is capable of generating more realistic domain-adapted spectrogram. We\ndemonstrate the effectiveness of our method on speech recognition with gender\nadaptation, where the model only has access to supervised data from one gender\nduring training, but is evaluated on the other at test time. Our model is able\nto achieve an average of $7.41\\%$ on phoneme error rate, and $11.10\\%$ word\nerror rate relative performance improvement as compared to the baseline, on\nTIMIT and WSJ dataset, respectively. Qualitatively, our model also generates\nmore natural sounding speech, when conditioned on data from the other domain.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 05:04:39 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 23:53:05 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 03:30:29 GMT"}, {"version": "v4", "created": "Mon, 9 Jul 2018 19:25:18 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Hosseini-Asl", "Ehsan", ""], ["Zhou", "Yingbo", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1804.00525", "submitter": "Ismail Elezi", "authors": "Lukas Tuggener, Ismail Elezi, J\\\"urgen Schmidhuber, Marcello Pelillo\n  and Thilo Stadelmann", "title": "DeepScores -- A Dataset for Segmentation, Detection and Classification\n  of Tiny Objects", "comments": "6 pages, accepted on IEEE International Conference on Pattern\n  Recognition 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the DeepScores dataset with the goal of advancing the\nstate-of-the-art in small objects recognition, and by placing the question of\nobject recognition in the context of scene understanding. DeepScores contains\nhigh quality images of musical scores, partitioned into 300,000 sheets of\nwritten music that contain symbols of different shapes and sizes. With close to\na hundred millions of small objects, this makes our dataset not only unique,\nbut also the largest public dataset. DeepScores comes with ground truth for\nobject classification, detection and semantic segmentation. DeepScores thus\nposes a relevant challenge for computer vision in general, beyond the scope of\noptical music recognition (OMR) research. We present a detailed statistical\nanalysis of the dataset, comparing it with other computer vision datasets like\nCaltech101/256, PASCAL VOC, SUN, SVHN, ImageNet, MS-COCO, smaller computer\nvision datasets, as well as with other OMR datasets. Finally, we provide\nbaseline performances for object classification and give pointers to future\nresearch based on this dataset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 14:44:45 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 21:12:59 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tuggener", "Lukas", ""], ["Elezi", "Ismail", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Pelillo", "Marcello", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1804.00532", "submitter": "Zhou Xing Dr", "authors": "Zhou Xing, Fei Xiao", "title": "Predictions of short-term driving intention using recurrent neural\n  network on sequential data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions of driver's intentions and their behaviors using the road is of\ngreat importance for planning and decision making processes of autonomous\ndriving vehicles. In particular, relatively short-term driving intentions are\nthe fundamental units that constitute more sophisticated driving goals,\nbehaviors, such as overtaking the slow vehicle in front, exit or merge onto a\nhigh way, etc. While it is not uncommon that most of the time human driver can\nrationalize, in advance, various on-road behaviors, intentions, as well as the\nassociated risks, aggressiveness, reciprocity characteristics, etc., such\nreasoning skills can be challenging and difficult for an autonomous driving\nsystem to learn. In this article, we demonstrate a disciplined methodology that\ncan be used to build and train a predictive drive system, therefore to learn\nthe on-road characteristics aforementioned.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:14:50 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Xing", "Zhou", ""], ["Xiao", "Fei", ""]]}, {"id": "1804.00551", "submitter": "Artem Artemov", "authors": "A.Artemov, A. Sergeev, A. Khasenevich, A. Yuzhakov, M. Chugunov", "title": "The Training of Neuromodels for Machine Comprehension of Text.\n  Brain2Text Algorithm", "comments": "5 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the Internet represents a vast informational space, growing\nexponentially and the problem of search for relevant data becomes essential as\nnever before. The algorithm proposed in the article allows to perform natural\nlanguage queries on content of the document and get comprehensive meaningful\nanswers. The problem is partially solved for English as SQuAD contains enough\ndata to learn on, but there is no such dataset in Russian, so the methods used\nby scientists now are not applicable to Russian. Brain2 framework allows to\ncope with the problem - it stands out for its ability to be applied on small\ndatasets and does not require impressive computing power. The algorithm is\nillustrated on Sberbank of Russia Strategy's text and assumes the use of a\nneuromodel consisting of 65 mln synapses. The trained model is able to\nconstruct word-by-word answers to questions based on a given text. The existing\nlimitations are its current inability to identify synonyms, pronoun relations\nand allegories. Nevertheless, the results of conducted experiments showed high\ncapacity and generalisation ability of the suggested approach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 08:32:42 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Artemov", "A.", ""], ["Sergeev", "A.", ""], ["Khasenevich", "A.", ""], ["Yuzhakov", "A.", ""], ["Chugunov", "M.", ""]]}, {"id": "1804.00644", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong, Biing-Hwang (Fred) Juang", "title": "Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation", "comments": "5 pages, 1 figure, ICASSP 2018", "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Calgary, Canada", "doi": "10.1109/ICASSP.2018.8461682", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The teacher-student (T/S) learning has been shown effective in unsupervised\ndomain adaptation [1]. It is a form of transfer learning, not in terms of the\ntransfer of recognition decisions, but the knowledge of posteriori\nprobabilities in the source domain as evaluated by the teacher model. It learns\nto handle the speaker and environment variability inherent in and restricted to\nthe speech signal in the target domain without proactively addressing the\nrobustness to other likely conditions. Performance degradation may thus ensue.\nIn this work, we advance T/S learning by proposing adversarial T/S learning to\nexplicitly achieve condition-robust unsupervised domain adaptation. In this\nmethod, a student acoustic model and a condition classifier are jointly\noptimized to minimize the Kullback-Leibler divergence between the output\ndistributions of the teacher and student models, and simultaneously, to\nmin-maximize the condition classification loss. A condition-invariant deep\nfeature is learned in the adapted student model through this procedure. We\nfurther propose multi-factorial adversarial T/S learning which suppresses\ncondition variabilities caused by multiple factors simultaneously. Evaluated\nwith the noisy CHiME-3 test set, the proposed methods achieve relative word\nerror rate improvements of 44.60% and 5.38%, respectively, over a clean source\nmodel and a strong T/S learning baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:45:57 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:43:09 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1804.00645", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, Chelsea\n  Finn", "title": "Universal Planning Networks", "comments": "Videos available at https://sites.google.com/view/upn-public/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:51:53 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 17:36:36 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Srinivas", "Aravind", ""], ["Jabri", "Allan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1804.00681", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Stochastic EM for Shuffled Linear Regression", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inference in a linear regression model in which\nthe relative ordering of the input features and output labels is not known.\nSuch datasets naturally arise from experiments in which the samples are\nshuffled or permuted during the protocol. In this work, we propose a framework\nthat treats the unknown permutation as a latent variable. We maximize the\nlikelihood of observations using a stochastic expectation-maximization (EM)\napproach. We compare this to the dominant approach in the literature, which\ncorresponds to hard EM in our framework. We show on synthetic data that the\nstochastic EM algorithm we develop has several advantages, including lower\nparameter error, less sensitivity to the choice of initialization, and\nsignificantly better performance on datasets that are only partially shuffled.\nWe conclude by performing two experiments on real datasets that have been\npartially shuffled, in which we show that the stochastic EM algorithm can\nrecover the weights with modest error.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 18:13:49 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1804.00684", "submitter": "Bao Wang", "authors": "Bao Wang, Xiyang Luo, Fangbo Zhang, Baichuan Yuan, Andrea L. Bertozzi,\n  P. Jeffrey Brantingham", "title": "Graph-Based Deep Modeling and Real Time Forecasting of Sparse\n  Spatio-Temporal Data", "comments": "9 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic framework for spatio-temporal (ST) data modeling,\nanalysis, and forecasting, with a special focus on data that is sparse in both\nspace and time. Our multi-scaled framework is a seamless coupling of two major\ncomponents: a self-exciting point process that models the macroscale\nstatistical behaviors of the ST data and a graph structured recurrent neural\nnetwork (GSRNN) to discover the microscale patterns of the ST data on the\ninferred graph. This novel deep neural network (DNN) incorporates the real time\ninteractions of the graph nodes to enable more accurate real time forecasting.\nThe effectiveness of our method is demonstrated on both crime and traffic\nforecasting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 18:23:27 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wang", "Bao", ""], ["Luo", "Xiyang", ""], ["Zhang", "Fangbo", ""], ["Yuan", "Baichuan", ""], ["Bertozzi", "Andrea L.", ""], ["Brantingham", "P. Jeffrey", ""]]}, {"id": "1804.00706", "submitter": "Cheng Tan", "authors": "Guanwen Zhong, Akshat Dubey, Tan Cheng, Tulika Mitra", "title": "Synergy: A HW/SW Framework for High Throughput CNNs on Embedded\n  Heterogeneous SoC", "comments": "34 pages, submitted to ACM Transactions on Embedded Computing Systems\n  (TECS)", "journal-ref": "TECS, 18 (2019) 13-39", "doi": "10.1145/3301278", "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have been widely deployed in diverse\napplication domains. There has been significant progress in accelerating both\ntheir training and inference using high-performance GPUs, FPGAs, and custom\nASICs for datacenter-scale environments. The recent proliferation of mobile and\nIoT devices have necessitated real-time, energy-efficient deep neural network\ninference on embedded-class, resource-constrained platforms. In this context,\nwe present {\\em Synergy}, an automated, hardware-software co-designed,\npipelined, high-throughput CNN inference framework on embedded heterogeneous\nsystem-on-chip (SoC) architectures (Xilinx Zynq). {\\em Synergy} leverages,\nthrough multi-threading, all the available on-chip resources, which includes\nthe dual-core ARM processor along with the FPGA and the NEON SIMD engines as\naccelerators. Moreover, {\\em Synergy} provides a unified abstraction of the\nheterogeneous accelerators (FPGA and NEON) and can adapt to different network\nconfigurations at runtime without changing the underlying hardware accelerator\narchitecture by balancing workload across accelerators through work-stealing.\n{\\em Synergy} achieves 7.3X speedup, averaged across seven CNN models, over a\nwell-optimized software-only solution. {\\em Synergy} demonstrates substantially\nbetter throughput and energy-efficiency compared to the contemporary CNN\nimplementations on the same SoC architecture.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 16:02:45 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Zhong", "Guanwen", ""], ["Dubey", "Akshat", ""], ["Cheng", "Tan", ""], ["Mitra", "Tulika", ""]]}, {"id": "1804.00709", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Generative Adversarial Learning for Spectrum Sensing", "comments": "IEEE ICC 2018 COGNITIVE RADIO AND NETWORKING (ICC'18 CRN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach of training data augmentation and domain adaptation is\npresented to support machine learning applications for cognitive radio. Machine\nlearning provides effective tools to automate cognitive radio functionalities\nby reliably extracting and learning intrinsic spectrum dynamics. However, there\nare two important challenges to overcome, in order to fully utilize the machine\nlearning benefits with cognitive radios. First, machine learning requires\nsignificant amount of truthed data to capture complex channel and emitter\ncharacteristics, and train the underlying algorithm (e.g., a classifier).\nSecond, the training data that has been identified for one spectrum environment\ncannot be used for another one (e.g., after channel and emitter conditions\nchange). To address these challenges, a generative adversarial network (GAN)\nwith deep learning structures is used to 1)~generate additional synthetic\ntraining data to improve classifier accuracy, and 2) adapt training data to\nspectrum dynamics. This approach is applied to spectrum sensing by assuming\nonly limited training data without knowledge of spectrum statistics. Machine\nlearning classifiers are trained with limited, augmented and adapted training\ndata to detect signals. Results show that training data augmentation increases\nthe classifier accuracy significantly and this increase is sustained with\ndomain adaptation as spectrum conditions change.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 19:23:06 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1804.00714", "submitter": "Anshul Ramachandran", "authors": "Anshul Ramachandran, Ashwin Balakrishna, Peter Kundzicz, Anirudh Neti", "title": "Predicting Electric Vehicle Charging Station Usage: Using Machine\n  Learning to Estimate Individual Station Statistics from Physical\n  Configurations of Charging Station Networks", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric vehicles (EVs) have been gaining popularity due to their\nenvironmental friendliness and efficiency. EV charging station networks are\nscalable solutions for supporting increasing numbers of EVs within modern\nelectric grid constraints, yet few tools exist to aid the physical\nconfiguration design of new networks. We use neural networks to predict\nindividual charging station usage statistics from the station's physical\nlocation within a network. We have shown this quickly gives accurate estimates\nof average usage statistics given a proposed configuration, without the need\nfor running many computationally expensive simulations. The trained neural\nnetwork can help EV charging network designers rapidly test various placements\nof charging stations under additional individual constraints in order to find\nan optimal configuration given their design objectives.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 19:41:47 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ramachandran", "Anshul", ""], ["Balakrishna", "Ashwin", ""], ["Kundzicz", "Peter", ""], ["Neti", "Anirudh", ""]]}, {"id": "1804.00720", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Danish Pruthi, Dheeraj Rajagopal", "title": "Simple and Effective Semi-Supervised Question Answering", "comments": "Short paper, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of deep learning models for the task of extractive Question\nAnswering (QA) is hinged on the availability of large annotated corpora.\nHowever, large domain specific annotated corpora are limited and expensive to\nconstruct. In this work, we envision a system where the end user specifies a\nset of base documents and only a few labelled examples. Our system exploits the\ndocument structure to create cloze-style questions from these base documents;\npre-trains a powerful neural network on the cloze style questions; and further\nfine-tunes the model on the labeled examples. We evaluate our proposed system\nacross three diverse datasets from different domains, and find it to be highly\neffective with very little labeled data. We attain more than 50% F1 score on\nSQuAD and TriviaQA with less than a thousand labelled examples. We are also\nreleasing a set of 3.2M cloze-style questions for practitioners to use while\nbuilding QA systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 20:29:21 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Pruthi", "Danish", ""], ["Rajagopal", "Dheeraj", ""]]}, {"id": "1804.00722", "submitter": "Kibok Lee", "authors": "Kibok Lee, Kimin Lee, Kyle Min, Yuting Zhang, Jinwoo Shin, Honglak Lee", "title": "Hierarchical Novelty Detection for Visual Object Recognition", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive success in large-scale visual\nobject recognition tasks with a predefined set of classes. However, recognizing\nobjects of novel classes unseen during training still remains challenging. The\nproblem of detecting such novel classes has been addressed in the literature,\nbut most prior works have focused on providing simple binary or regressive\ndecisions, e.g., the output would be \"known,\" \"novel,\" or corresponding\nconfidence intervals. In this paper, we study more informative novelty\ndetection schemes based on a hierarchical classification framework. For an\nobject of a novel class, we aim for finding its closest super class in the\nhierarchical taxonomy of known classes. To this end, we propose two different\napproaches termed top-down and flatten methods, and their combination as well.\nThe essential ingredients of our methods are confidence-calibrated classifiers,\ndata relabeling, and the leave-one-out strategy for modeling novel classes\nunder the hierarchical taxonomy. Furthermore, our method can generate a\nhierarchical embedding that leads to improved generalized zero-shot learning\nperformance in combination with other commonly-used semantic embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 20:36:43 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 10:18:15 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Lee", "Kibok", ""], ["Lee", "Kimin", ""], ["Min", "Kyle", ""], ["Zhang", "Yuting", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "1804.00727", "submitter": "Shun Kataoka", "authors": "Kazuyuki Tanaka, Masamichi Nakamura, Shun Kataoka, Masayuki Ohzeki,\n  Muneki Yasuda", "title": "Momentum-Space Renormalization Group Transformation in Bayesian Image\n  Modeling by Gaussian Graphical Model", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": "10.7566/JPSJ.87.085001", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Bayesian modeling method is proposed by combining the maximization of\nthe marginal likelihood with a momentum-space renormalization group\ntransformation for Gaussian graphical models. Moreover, we present a scheme for\ncomputint the statistical averages of hyperparameters and mean square errors in\nour proposed method based on a momentumspace renormalization transformation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 01:29:13 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Tanaka", "Kazuyuki", ""], ["Nakamura", "Masamichi", ""], ["Kataoka", "Shun", ""], ["Ohzeki", "Masayuki", ""], ["Yasuda", "Muneki", ""]]}, {"id": "1804.00736", "submitter": "Abhinav Valada", "authors": "Abhinav Valada and Wolfram Burgard", "title": "Deep Spatiotemporal Models for Robust Proprioceptive Terrain\n  Classification", "comments": null, "journal-ref": "The International Journal of Robotics Research 36, no. 13-14\n  (2017): 1521-1539", "doi": "10.1177/0278364917727062", "report-no": null, "categories": "cs.RO cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terrain classification is a critical component of any autonomous mobile robot\nsystem operating in unknown real-world environments. Over the years, several\nproprioceptive terrain classification techniques have been introduced to\nincrease robustness or act as a fallback for traditional vision based\napproaches. However, they lack widespread adaptation due to various factors\nthat include inadequate accuracy, robustness and slow run-times. In this paper,\nwe use vehicle-terrain interaction sounds as a proprioceptive modality and\npropose a deep Long-Short Term Memory (LSTM) based recurrent model that\ncaptures both the spatial and temporal dynamics of such a problem, thereby\novercoming these past limitations. Our model consists of a new Convolution\nNeural Network (CNN) architecture that learns deep spatial features,\ncomplemented with LSTM units that learn complex temporal dynamics. Experiments\non two extensive datasets collected with different microphones on various\nindoor and outdoor terrains demonstrate state-of-the-art performance compared\nto existing techniques. We additionally evaluate the performance in adverse\nacoustic conditions with high ambient noise and propose a noise-aware training\nscheme that enables learning of more generalizable models that are essential\nfor robust real-world deployments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 21:38:56 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Valada", "Abhinav", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1804.00779", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, David Krueger, Alexandre Lacoste, Aaron Courville", "title": "Neural Autoregressive Flows", "comments": "16 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows and autoregressive models have been successfully combined\nto produce state-of-the-art results in density estimation, via Masked\nAutoregressive Flows (MAF), and to accelerate state-of-the-art WaveNet-based\nspeech synthesis to 20x faster than real-time, via Inverse Autoregressive Flows\n(IAF). We unify and generalize these approaches, replacing the (conditionally)\naffine univariate transformations of MAF/IAF with a more general class of\ninvertible univariate transformations expressed as monotonic neural networks.\nWe demonstrate that the proposed neural autoregressive flows (NAF) are\nuniversal approximators for continuous probability distributions, and their\ngreater expressivity allows them to better capture multimodal target\ndistributions. Experimentally, NAF yields state-of-the-art performance on a\nsuite of density estimation tasks and outperforms IAF in variational\nautoencoders trained on binarized MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 01:41:27 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Krueger", "David", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1804.00782", "submitter": "Jiajun Wu", "authors": "Jiajun Wu, Tianfan Xue, Joseph J. Lim, Yuandong Tian, Joshua B.\n  Tenenbaum, Antonio Torralba, William T. Freeman", "title": "3D Interpreter Networks for Viewer-Centered Wireframe Modeling", "comments": "Journal preprint of arXiv:1604.08685 (IJCV, 2018). The first two\n  authors contributed equally to this work. Project page:\n  http://3dinterpreter.csail.mit.edu", "journal-ref": "International Journal of Computer Vision, Volume 126, Issue 9, pp\n  1009-1026, 2018", "doi": "10.1007/s11263-018-1074-6", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding 3D object structure from a single image is an important but\nchallenging task in computer vision, mostly due to the lack of 3D object\nannotations to real images. Previous research tackled this problem by either\nsearching for a 3D shape that best explains 2D annotations, or training purely\non synthetic data with ground truth 3D information. In this work, we propose 3D\nINterpreter Networks (3D-INN), an end-to-end trainable framework that\nsequentially estimates 2D keypoint heatmaps and 3D object skeletons and poses.\nOur system learns from both 2D-annotated real images and synthetic 3D data.\nThis is made possible mainly by two technical innovations. First, heatmaps of\n2D keypoints serve as an intermediate representation to connect real and\nsynthetic data. 3D-INN is trained on real images to estimate 2D keypoint\nheatmaps from an input image; it then predicts 3D object structure from\nheatmaps using knowledge learned from synthetic 3D shapes. By doing so, 3D-INN\nbenefits from the variation and abundance of synthetic 3D objects, without\nsuffering from the domain difference between real and synthesized images, often\ndue to imperfect rendering. Second, we propose a Projection Layer, mapping\nestimated 3D structure back to 2D. During training, it ensures 3D-INN to\npredict 3D structure whose projection is consistent with the 2D annotations to\nreal images. Experiments show that the proposed system performs well on both 2D\nkeypoint estimation and 3D structure recovery. We also demonstrate that the\nrecovered 3D information has wide vision applications, such as image retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 01:55:31 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 23:14:56 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wu", "Jiajun", ""], ["Xue", "Tianfan", ""], ["Lim", "Joseph J.", ""], ["Tian", "Yuandong", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""], ["Freeman", "William T.", ""]]}, {"id": "1804.00792", "submitter": "Wenqian Ronny Huang", "authors": "Ali Shafahi, W. Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph\n  Studer, Tudor Dumitras, Tom Goldstein", "title": "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks", "comments": "Presented at the NIPS 2018 conference. 11 pages, 4 figures, with a\n  supplementary section of 7 pages, 7 figures. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning is an attack on machine learning models wherein the attacker\nadds examples to the training set to manipulate the behavior of the model at\ntest time. This paper explores poisoning attacks on neural nets. The proposed\nattacks use \"clean-labels\"; they don't require the attacker to have any control\nover the labeling of training data. They are also targeted; they control the\nbehavior of the classifier on a $\\textit{specific}$ test instance without\ndegrading overall classifier performance. For example, an attacker could add a\nseemingly innocuous image (that is properly labeled) to a training set for a\nface recognition engine, and control the identity of a chosen person at test\ntime. Because the attacker does not need to control the labeling function,\npoisons could be entered into the training set simply by leaving them on the\nweb and waiting for them to be scraped by a data collection bot.\n  We present an optimization-based method for crafting poisons, and show that\njust one single poison image can control classifier behavior when transfer\nlearning is used. For full end-to-end training, we present a \"watermarking\"\nstrategy that makes poisoning reliable using multiple ($\\approx$50) poisoned\ntraining instances. We demonstrate our method by generating poisoned frog\nimages from the CIFAR dataset and using them to manipulate image classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 02:24:31 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 15:37:17 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Shafahi", "Ali", ""], ["Huang", "W. Ronny", ""], ["Najibi", "Mahyar", ""], ["Suciu", "Octavian", ""], ["Studer", "Christoph", ""], ["Dumitras", "Tudor", ""], ["Goldstein", "Tom", ""]]}, {"id": "1804.00795", "submitter": "Xudong Li", "authors": "Xudong Li, Mengdi Wang, Anru Zhang", "title": "Estimation of Markov Chain via Rank-Constrained Likelihood", "comments": "Accepted at ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML2018), Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the estimation of low-rank Markov chains from empirical\ntrajectories. We propose a non-convex estimator based on rank-constrained\nlikelihood maximization. Statistical upper bounds are provided for the\nKullback-Leiber divergence and the $\\ell_2$ risk between the estimator and the\ntrue transition matrix. The estimator reveals a compressed state space of the\nMarkov chain. We also develop a novel DC (difference of convex function)\nprogramming algorithm to tackle the rank-constrained non-smooth optimization\nproblem. Convergence results are established. Experiments show that the\nproposed estimator achieves better empirical performance than other popular\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 02:28:47 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 02:01:04 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Li", "Xudong", ""], ["Wang", "Mengdi", ""], ["Zhang", "Anru", ""]]}, {"id": "1804.00810", "submitter": "Kun Shao", "authors": "Kun Shao, Yuanheng Zhu, Dongbin Zhao", "title": "StarCraft Micromanagement with Reinforcement Learning and Curriculum\n  Transfer Learning", "comments": "12 pages, 14 figures, accepted to IEEE Transactions on Emerging\n  Topics in Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time strategy games have been an important field of game artificial\nintelligence in recent years. This paper presents a reinforcement learning and\ncurriculum transfer learning method to control multiple units in StarCraft\nmicromanagement. We define an efficient state representation, which breaks down\nthe complexity caused by the large state space in the game environment. Then a\nparameter sharing multi-agent gradientdescent Sarsa({\\lambda}) (PS-MAGDS)\nalgorithm is proposed to train the units. The learning policy is shared among\nour units to encourage cooperative behaviors. We use a neural network as a\nfunction approximator to estimate the action-value function, and propose a\nreward function to help units balance their move and attack. In addition, a\ntransfer learning method is used to extend our model to more difficult\nscenarios, which accelerates the training process and improves the learning\nperformance. In small scale scenarios, our units successfully learn to combat\nand defeat the built-in AI with 100% win rates. In large scale scenarios,\ncurriculum transfer learning method is used to progressively train a group of\nunits, and shows superior performance over some baseline methods in target\nscenarios. With reinforcement learning and curriculum transfer learning, our\nunits are able to learn appropriate strategies in StarCraft micromanagement\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:57:02 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Shao", "Kun", ""], ["Zhu", "Yuanheng", ""], ["Zhao", "Dongbin", ""]]}, {"id": "1804.00815", "submitter": "Shamak Dutta", "authors": "Shamak Dutta, Bryan Tripp, Graham Taylor", "title": "Convolutional Neural Networks Regularized by Correlated Noise", "comments": "Accepted at CRV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the visual cortex are correlated in their variability. The\npresence of correlation impacts cortical processing because noise cannot be\naveraged out over many neurons. In an effort to understand the functional\npurpose of correlated variability, we implement and evaluate correlated noise\nmodels in deep convolutional neural networks. Inspired by the cortex,\ncorrelation is defined as a function of the distance between neurons and their\nselectivity. We show how to sample from high-dimensional correlated\ndistributions while keeping the procedure differentiable, so that\nback-propagation can proceed as usual. The impact of correlated variability is\nevaluated on the classification of occluded and non-occluded images with and\nwithout the presence of other regularization techniques, such as dropout. More\nwork is needed to understand the effects of correlations in various conditions,\nhowever in 10/12 of the cases we studied, the best performance on occluded\nimages was obtained from a model with correlated noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:05:00 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dutta", "Shamak", ""], ["Tripp", "Bryan", ""], ["Taylor", "Graham", ""]]}, {"id": "1804.00823", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and\n  Vadim Sheinin", "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks", "comments": "16 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:47:22 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 11:58:25 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 06:13:54 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 16:43:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Witbrock", "Michael", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1804.00831", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Kyomin Jung", "title": "AttnConvnet at SemEval-2018 Task 1: Attention-based Convolutional Neural\n  Networks for Multi-label Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an attention-based classifier that predicts\nmultiple emotions of a given sentence. Our model imitates human's two-step\nprocedure of sentence understanding and it can effectively represent and\nclassify sentences. With emoji-to-meaning preprocessing and extra lexicon\nutilization, we further improve the model performance. We train and evaluate\nour model with data provided by SemEval-2018 task 1-5, each sentence of which\nhas several labels among 11 given sentiments. Our model achieves 5-th/1-th rank\nin English/Spanish respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 05:31:35 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 00:21:43 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Jung", "Kyomin", ""]]}, {"id": "1804.00836", "submitter": "Canh Hao Nguyen", "authors": "Canh Hao Nguyen, Hiroshi Mamitsuka", "title": "Learning on Hypergraphs with Sparsity", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (2020)", "doi": "10.1109/TPAMI.2020.2974746", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph is a general way of representing high-order relations on a set of\nobjects. It is a generalization of graph, in which only pairwise relations can\nbe represented. It finds applications in various domains where relationships of\nmore than two objects are observed. On a hypergraph, as a generalization of\ngraph, one wishes to learn a smooth function with respect to its topology. A\nfundamental issue is to find suitable smoothness measures of functions on the\nnodes of a graph/hypergraph. We show a general framework that generalizes\npreviously proposed smoothness measures and also gives rise to new ones. To\naddress the problem of irrelevant or noisy data, we wish to incorporate sparse\nlearning framework into learning on hypergraphs. We propose sparsely smooth\nformulations that learn smooth functions and induce sparsity on hypergraphs at\nboth hyperedge and node levels. We show their properties and sparse support\nrecovery results. We conduct experiments to show that our sparsely smooth\nmodels have benefits to irrelevant and noisy data, and usually give similar or\nimproved performances compared to dense models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 06:16:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Nguyen", "Canh Hao", ""], ["Mamitsuka", "Hiroshi", ""]]}, {"id": "1804.00846", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Albert Zhao, Aadyot Bhatnagar, Yisong Yue,\n  Masahiro Ono", "title": "Learning to Search via Retrospective Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a good search policy for combinatorial\nsearch spaces. We propose retrospective imitation learning, which, after\ninitial training by an expert, improves itself by learning from\n\\textit{retrospective inspections} of its own roll-outs. That is, when the\npolicy eventually reaches a feasible solution in a combinatorial search tree\nafter making mistakes and backtracks, it retrospectively constructs an improved\nsearch trace to the solution by removing backtracks, which is then used to\nfurther train the policy. A key feature of our approach is that it can\niteratively scale up, or transfer, to larger problem sizes than those solved by\nthe initial expert demonstrations, thus dramatically expanding its\napplicability beyond that of conventional imitation learning. We showcase the\neffectiveness of our approach on a range of tasks, including synthetic maze\nsolving and combinatorial problems expressed as integer programs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 06:52:09 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 22:33:54 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 07:57:21 GMT"}, {"version": "v4", "created": "Sun, 23 Jun 2019 17:23:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Zhao", "Albert", ""], ["Bhatnagar", "Aadyot", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1804.00874", "submitter": "Michael Bloesch", "authors": "Michael Bloesch, Jan Czarnowski, Ronald Clark, Stefan Leutenegger,\n  Andrew J. Davison", "title": "CodeSLAM - Learning a Compact, Optimisable Representation for Dense\n  Visual SLAM", "comments": "Published in Proceedings of the IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of geometry in real-time 3D perception systems continues\nto be a critical research issue. Dense maps capture complete surface shape and\ncan be augmented with semantic labels, but their high dimensionality makes them\ncomputationally costly to store and process, and unsuitable for rigorous\nprobabilistic inference. Sparse feature-based representations avoid these\nproblems, but capture only partial scene information and are mainly useful for\nlocalisation only.\n  We present a new compact but dense representation of scene geometry which is\nconditioned on the intensity data from a single image and generated from a code\nconsisting of a small number of parameters. We are inspired by work both on\nlearned depth from images, and auto-encoders. Our approach is suitable for use\nin a keyframe-based monocular dense SLAM system: While each keyframe with a\ncode can produce a depth map, the code can be optimised efficiently jointly\nwith pose variables and together with the codes of overlapping keyframes to\nattain global consistency. Conditioning the depth map on the image allows the\ncode to only represent aspects of the local geometry which cannot directly be\npredicted from the image. We explain how to learn our code representation, and\ndemonstrate its advantageous properties in monocular SLAM.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:00:42 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 11:54:05 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bloesch", "Michael", ""], ["Czarnowski", "Jan", ""], ["Clark", "Ronald", ""], ["Leutenegger", "Stefan", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1804.00891", "submitter": "Nicola De Cao", "authors": "Tim R. Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, Jakub M.\n  Tomczak", "title": "Hyperspherical Variational Auto-Encoders", "comments": "GitHub repository: http://github.com/nicola-decao/s-vae-tf, Blogpost:\n  https://nicola-decao.github.io/s-vae", "journal-ref": "Uncertainty in Artificial Intelligence (UAI). Proceedings of the\n  Thirty-Fourth Conference (2018) 856- 865", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Auto-Encoder (VAE) is one of the most used unsupervised\nmachine learning models. But although the default choice of a Gaussian\ndistribution for both the prior and posterior represents a mathematically\nconvenient distribution often leading to competitive results, we show that this\nparameterization fails to model data with a latent hyperspherical structure. To\naddress this issue we propose using a von Mises-Fisher (vMF) distribution\ninstead, leading to a hyperspherical latent space. Through a series of\nexperiments we show how such a hyperspherical VAE, or $\\mathcal{S}$-VAE, is\nmore suitable for capturing data with a hyperspherical latent structure, while\noutperforming a normal, $\\mathcal{N}$-VAE, in low dimensions on other data\ntypes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:57:26 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 14:55:34 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Davidson", "Tim R.", ""], ["Falorsi", "Luca", ""], ["De Cao", "Nicola", ""], ["Kipf", "Thomas", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "1804.00921", "submitter": "Camille Couprie", "authors": "Othman Sbai, Mohamed Elhoseiny, Antoine Bordes, Yann LeCun, Camille\n  Couprie", "title": "DeSIGN: Design Inspiration from Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an algorithm create original and compelling fashion designs to serve as\nan inspirational assistant? To help answer this question, we design and\ninvestigate different image generation models associated with different loss\nfunctions to boost creativity in fashion generation. The dimensions of our\nexplorations include: (i) different Generative Adversarial Networks\narchitectures that start from noise vectors to generate fashion items, (ii)\nnovel loss functions that encourage novelty, inspired from Sharma-Mittal\ndivergence, a generalized mutual information measure for the widely used\nrelative entropies such as Kullback-Leibler, and (iii) a generation process\nfollowing the key elements of fashion design (disentangling shape and texture\ncomponents). A key challenge of this study is the evaluation of generated\ndesigns and the retrieval of best ones, hence we put together an evaluation\nprotocol associating automatic metrics and human experimental studies that we\nhope will help ease future research. We show that our proposed creativity\ncriterion yield better overall appreciation than the one employed in Creative\nAdversarial Networks. In the end, about 61% of our images are thought to be\ncreated by human designers rather than by a computer while also being\nconsidered original per our human subject experiments, and our proposed loss\nscores the highest compared to existing losses in both novelty and likability.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 11:54:57 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 10:17:31 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Sbai", "Othman", ""], ["Elhoseiny", "Mohamed", ""], ["Bordes", "Antoine", ""], ["LeCun", "Yann", ""], ["Couprie", "Camille", ""]]}, {"id": "1804.00925", "submitter": "Ratnik Gandhi", "authors": "Shreyas Patel, Ashutosh Kakadiya, Maitrey Mehta, Raj Derasari, Rahul\n  Patel, Ratnik Gandhi", "title": "Correlated discrete data generation using adversarial training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have shown great promise in tasks like\nsynthetic image generation, image inpainting, style transfer, and anomaly\ndetection. However, generating discrete data is a challenge. This work presents\nan adversarial training based correlated discrete data (CDD) generation model.\nIt also details an approach for conditional CDD generation. The results of our\napproach are presented over two datasets; job-seeking candidates skill set\n(private dataset) and MNIST (public dataset). From quantitative and qualitative\nanalysis of these results, we show that our model performs better as it\nleverages inherent correlation in the data, than an existing model that\noverlooks correlation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 12:10:39 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Patel", "Shreyas", ""], ["Kakadiya", "Ashutosh", ""], ["Mehta", "Maitrey", ""], ["Derasari", "Raj", ""], ["Patel", "Rahul", ""], ["Gandhi", "Ratnik", ""]]}, {"id": "1804.01002", "submitter": "Chuan Zhang", "authors": "Xiaosi Tan (1 and 2 and 3), Weihong Xu (1 and 2 and 3), Yair Be'ery\n  (4), Zaichen Zhang (2 and 3), Xiaohu You (2), and Chuan Zhang (1 and 2 and 3)\n  ((1) Lab of Efficient Architectures for Digital-communication and\n  Signal-processing (LEADS), (2) National Mobile Communications Research\n  Laboratory, (3) Quantum Information Center, Southeast University, China, (4)\n  School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel)", "title": "Improving Massive MIMO Belief Propagation Detector with Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, deep neural network (DNN) is utilized to improve the belief\npropagation (BP) detection for massive multiple-input multiple-output (MIMO)\nsystems. A neural network architecture suitable for detection task is firstly\nintroduced by unfolding BP algorithms. DNN MIMO detectors are then proposed\nbased on two modified BP detectors, damped BP and max-sum BP. The correction\nfactors in these algorithms are optimized through deep learning techniques,\naiming at improved detection performance. Numerical results are presented to\ndemonstrate the performance of the DNN detectors in comparison with various BP\nmodifications. The neural network is trained once and can be used for multiple\nonline detections. The results show that, compared to other state-of-the-art\ndetectors, the DNN detectors can achieve lower bit error rate (BER) with\nimproved robustness against various antenna configurations and channel\nconditions at the same level of complexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 10:39:53 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 08:58:12 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Tan", "Xiaosi", "", "1 and 2 and 3"], ["Xu", "Weihong", "", "1 and 2 and 3"], ["Be'ery", "Yair", "", "2 and 3"], ["Zhang", "Zaichen", "", "2 and 3"], ["You", "Xiaohu", "", "1 and 2 and 3"], ["Zhang", "Chuan", "", "1 and 2 and 3"]]}, {"id": "1804.01016", "submitter": "S.T. John", "authors": "S.T. John and James Hensman", "title": "Large-Scale Cox Process Inference using Variational Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process modulated Poisson processes provide a flexible framework for\nmodelling spatiotemporal point patterns. So far this had been restricted to one\ndimension, binning to a pre-determined grid, or small data sets of up to a few\nthousand data points. Here we introduce Cox process inference based on Fourier\nfeatures. This sparse representation induces global rather than local\nconstraints on the function space and is computationally efficient. This allows\nus to formulate a grid-free approximation that scales well with the number of\ndata points and the size of the domain. We demonstrate that this allows MCMC\napproximations to the non-Gaussian posterior. We also find that, in practice,\nFourier features have more consistent optimization behavior than previous\napproaches. Our approximate Bayesian method can fit over 100,000 events with\ncomplex spatiotemporal patterns in three dimensions on a single GPU.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 15:00:01 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["John", "S. T.", ""], ["Hensman", "James", ""]]}, {"id": "1804.01031", "submitter": "Mohamed K. Helwa", "authors": "Mohamed K. Helwa, Adam Heins, and Angela P. Schoellig", "title": "Provably Robust Learning-Based Approach for High-Accuracy Tracking\n  Control of Lagrangian Systems", "comments": "8 pages, 4 figures, 2 tables, submitted to IEEE Robotics and\n  Automation Letters (RA-L) and the 2019 International Conference on Robotics\n  and Automation (ICRA) (created: March 2018; updated: September 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lagrangian systems represent a wide range of robotic systems, including\nmanipulators, wheeled and legged robots, and quadrotors. Inverse dynamics\ncontrol and feedforward linearization techniques are typically used to convert\nthe complex nonlinear dynamics of Lagrangian systems to a set of decoupled\ndouble integrators, and then a standard, outer-loop controller can be used to\ncalculate the commanded acceleration for the linearized system. However, these\nmethods typically depend on having a very accurate system model, which is often\nnot available in practice. While this challenge has been addressed in the\nliterature using different learning approaches, most of these approaches do not\nprovide safety guarantees in terms of stability of the learning-based control\nsystem. In this paper, we provide a novel, learning-based control approach\nbased on Gaussian processes (GPs) that ensures both stability of the\nclosed-loop system and high-accuracy tracking. We use GPs to approximate the\nerror between the commanded acceleration and the actual acceleration of the\nsystem, and then use the predicted mean and variance of the GP to calculate an\nupper bound on the uncertainty of the linearized model. This uncertainty bound\nis then used in a robust, outer-loop controller to ensure stability of the\noverall system. Moreover, we show that the tracking error converges to a ball\nwith a radius that can be made arbitrarily small. Furthermore, we verify the\neffectiveness of our approach via simulations on a 2 degree-of-freedom (DOF)\nplanar manipulator and experimentally on a 6 DOF industrial manipulator.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 15:18:56 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 16:16:00 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Helwa", "Mohamed K.", ""], ["Heins", "Adam", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1804.01050", "submitter": "Garoe Dorta", "authors": "Garoe Dorta, Sara Vicente, Lourdes Agapito, Neill D.F. Campbell, Ivor\n  Simpson", "title": "Training VAEs Under Structured Residuals", "comments": "Simplified training methodology, added more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAEs) are a popular and powerful deep generative\nmodel. Previous works on VAEs have assumed a factorized likelihood model,\nwhereby the output uncertainty of each pixel is assumed to be independent. This\napproximation is clearly limited as demonstrated by observing a residual image\nfrom a VAE reconstruction, which often possess a high level of structure. This\npaper demonstrates a novel scheme to incorporate a structured Gaussian\nlikelihood prediction network within the VAE that allows the residual\ncorrelations to be modeled. Our novel architecture, with minimal increase in\ncomplexity, incorporates the covariance matrix prediction within the VAE. We\nalso propose a new mechanism for allowing structured uncertainty on color\nimages. Furthermore, we provide a scheme for effectively training this model,\nand include some suggestions for improving performance in terms of efficiency\nor modeling longer range correlations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 16:04:22 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 19:00:03 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:53:19 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Dorta", "Garoe", ""], ["Vicente", "Sara", ""], ["Agapito", "Lourdes", ""], ["Campbell", "Neill D. F.", ""], ["Simpson", "Ivor", ""]]}, {"id": "1804.01071", "submitter": "Stephane Chretien", "authors": "Stephane Chretien, Christophe Guyeux and Zhen-Wai Olivier HO", "title": "Average performance analysis of the stochastic gradient method for\n  online PCA", "comments": "11 pages, 1 figure, Submitted to LOD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of the stochastic gradient algorithm for\nPCA when the data are observed in a streaming setting. We also propose an\nonline approach for selecting the learning rate. Simulation experiments confirm\nthe practical relevance of the plain stochastic gradient approach and that\ndrastic improvements can be achieved by learning the learning rate.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 17:31:32 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Chretien", "Stephane", ""], ["Guyeux", "Christophe", ""], ["HO", "Zhen-Wai Olivier", ""]]}, {"id": "1804.01116", "submitter": "Jayakumar Subramanian", "authors": "Jayakumar Subramanian and Aditya Mahajan", "title": "Renewal Monte Carlo: Renewal theory based reinforcement learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an online reinforcement learning algorithm, called\nRenewal Monte Carlo (RMC), for infinite horizon Markov decision processes with\na designated start state. RMC is a Monte Carlo algorithm and retains the\nadvantages of Monte Carlo methods including low bias, simplicity, and ease of\nimplementation while, at the same time, circumvents their key drawbacks of high\nvariance and delayed (end of episode) updates. The key ideas behind RMC are as\nfollows. First, under any reasonable policy, the reward process is ergodic. So,\nby renewal theory, the performance of a policy is equal to the ratio of\nexpected discounted reward to the expected discounted time over a regenerative\ncycle. Second, by carefully examining the expression for performance gradient,\nwe propose a stochastic approximation algorithm that only requires estimates of\nthe expected discounted reward and discounted time over a regenerative cycle\nand their gradients. We propose two unbiased estimators for evaluating\nperformance gradients---a likelihood ratio based estimator and a simultaneous\nperturbation based estimator---and show that for both estimators, RMC converges\nto a locally optimal policy. We generalize the RMC algorithm to post-decision\nstate models and also present a variant that converges faster to an\napproximately optimal policy. We conclude by presenting numerical experiments\non a randomly generated MDP, event-triggered communication, and inventory\nmanagement.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:18:54 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Subramanian", "Jayakumar", ""], ["Mahajan", "Aditya", ""]]}, {"id": "1804.01118", "submitter": "Yaroslav Ganin", "authors": "Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S.M. Ali Eslami,\n  Oriol Vinyals", "title": "Synthesizing Programs for Images using Reinforced Adversarial Learning", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep generative networks have led to impressive results in recent\nyears. Nevertheless, such models can often waste their capacity on the minutiae\nof datasets, presumably due to weak inductive biases in their decoders. This is\nwhere graphics engines may come in handy since they abstract away low-level\ndetails and represent images as high-level programs. Current methods that\ncombine deep learning and renderers are limited by hand-crafted likelihood or\ndistance functions, a need for large amounts of supervision, or difficulties in\nscaling their inference algorithms to richer datasets. To mitigate these\nissues, we present SPIRAL, an adversarially trained agent that generates a\nprogram which is executed by a graphics engine to interpret and sample images.\nThe goal of this agent is to fool a discriminator network that distinguishes\nbetween real and rendered data, trained with a distributed reinforcement\nlearning setup without any supervision. A surprising finding is that using the\ndiscriminator's output as a reward signal is the key to allow the agent to make\nmeaningful progress at matching the desired output rendering. To the best of\nour knowledge, this is the first demonstration of an end-to-end, unsupervised\nand adversarial inverse graphics agent on challenging real world (MNIST,\nOmniglot, CelebA) and synthetic 3D datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:25:42 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Ganin", "Yaroslav", ""], ["Kulkarni", "Tejas", ""], ["Babuschkin", "Igor", ""], ["Eslami", "S. M. Ali", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1804.01119", "submitter": "Stephane Chretien", "authors": "Stephane Chretien and Zhen-Wai Olivier Ho", "title": "Feature selection in weakly coherent matrices", "comments": "14 pages, 6 Figures, Accepted for LVA-ICA 2018 Surrey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of paramount importance in both pure (Restricted Invertibility\nproblem) and applied mathematics (Feature extraction) is the one of selecting a\nsubmatrix of a given matrix, such that this submatrix has its smallest singular\nvalue above a specified level. Such problems can be addressed using\nperturbation analysis. In this paper, we propose a perturbation bound for the\nsmallest singular value of a given matrix after appending a column, under the\nassumption that its initial coherence is not large, and we use this bound to\nderive a fast algorithm for feature extraction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:26:46 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Chretien", "Stephane", ""], ["Ho", "Zhen-Wai Olivier", ""]]}, {"id": "1804.01186", "submitter": "Oleksandr Polozov", "authors": "Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek\n  Jain, Sumit Gulwani", "title": "Neural-Guided Deductive Search for Real-Time Program Synthesis from\n  Examples", "comments": "Published in ICLR 2018, International Conference on Learning\n  Representations (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing user-intended programs from a small number of input-output\nexamples is a challenging problem with several important applications like\nspreadsheet manipulation, data wrangling and code refactoring. Existing\nsynthesis systems either completely rely on deductive logic techniques that are\nextensively hand-engineered or on purely statistical models that need massive\namounts of data, and in general fail to provide real-time synthesis on\nchallenging benchmarks. In this work, we propose Neural Guided Deductive Search\n(NGDS), a hybrid synthesis technique that combines the best of both symbolic\nlogic techniques and statistical models. Thus, it produces programs that\nsatisfy the provided specifications by construction and generalize well on\nunseen examples, similar to data-driven systems. Our technique effectively\nutilizes the deductive search framework to reduce the learning problem of the\nneural component to a simple supervised learning setup. Further, this allows us\nto both train on sparingly available real-world data and still leverage\npowerful recurrent neural network encoders. We demonstrate the effectiveness of\nour method by evaluating on real-world customer scenarios by synthesizing\naccurate programs with up to 12x speed-up compared to state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 22:37:08 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:32:49 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Kalyan", "Ashwin", ""], ["Mohta", "Abhishek", ""], ["Polozov", "Oleksandr", ""], ["Batra", "Dhruv", ""], ["Jain", "Prateek", ""], ["Gulwani", "Sumit", ""]]}, {"id": "1804.01188", "submitter": "Jialiang Jiang", "authors": "Jialiang Jiang, Sharon Hewner, Varun Chandola", "title": "Hospital Readmission Prediction - Applying Hierarchical Sparsity Norms\n  for Interpretable Models", "comments": "included in the proceedings of the MLDM 2016 conference, #1323", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hospital readmissions have become one of the key measures of healthcare\nquality. Preventable readmissions have been identified as one of the primary\ntargets for reducing costs and improving healthcare delivery. However, most\ndata driven studies for understanding readmissions have produced black box\nclassification and predictive models with moderate performance, which precludes\nthem from being used effectively within the decision support systems in the\nhospitals. In this paper we present an application of structured\nsparsity-inducing norms for predicting readmission risk for patients based on\ntheir disease history and demographics. Most existing studies have focused on\nhospital utilization, test results, etc., to assign a readmission label to each\nepisode of hospitalization. However, we focus on assigning a readmission risk\nlabel to a patient based on their disease history. Our emphasis is on\ninterpreting the models to improve the understanding of the readmission\nproblem. To achieve this, we exploit the domain induced hierarchical structure\navailable for the disease codes which are the features for the classification\nalgorithm. We use a tree based sparsity-inducing regularization strategy that\nexplicitly uses the domain hierarchy. The resulting model not only outperforms\nstandard regularization procedures but is also highly sparse and interpretable.\nWe analyze the model and identify several significant factors that have an\neffect on readmission risk. Some of these factors conform to existing beliefs,\ne.g., impact of surgical complications and infections during hospital stay.\nOther factors, such as the impact of mental disorder and substance abuse on\nreadmission, provide empirical evidence for several pre-existing but unverified\nhypotheses. The analysis also reveals previously undiscovered connections such\nas the influence of socioeconomic factors like lack of housing and\nmalnutrition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 22:56:25 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Jiang", "Jialiang", ""], ["Hewner", "Sharon", ""], ["Chandola", "Varun", ""]]}, {"id": "1804.01195", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta and Rahul Jain and Peter Glynn", "title": "Probabilistic Contraction Analysis of Iterated Random Operators", "comments": "37 pages, submitted to SIAM Journal on Control and Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a contraction operator $T$ over a complete metric space $\\mathcal X$\nwith the fixed point $x^\\star$. In many computational applications, it is\ndifficult to compute $T(x)$; therefore, one replaces the application\ncontraction operator $T$ at iteration $k$ by a random operator $\\hat T^n_k$\nusing $n$ independent and identically distributed samples of a random variable.\nConsider the Markov chain $(\\hat X^n_k)_{k\\in\\mathbb{N}}$, which is generated\nby $\\hat X^n_{k+1} = \\hat T^n_k(\\hat X^n_k)$. In this paper, we identify some\nsufficient conditions under which (i) the distribution of $\\hat X^n_k$\nconverges to a Dirac mass over $x^\\star$ as $k$ and $n$ go to infinity, and\n(ii) the probability that $\\hat X^n_k$ is far from $x^\\star$ as $k$ goes to\ninfinity can be made arbitrarily small by an appropriate choice of $n$. We also\nderive an upper bound on the probability that $\\hat X^n_k$ is far from\n$x^\\star$ as $k\\rightarrow \\infty$. We apply the result to study the\nconvergence in probability of iterates generated by empirical value iteration\nalgorithms for discounted and average cost Markov decision problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 00:10:58 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 18:40:47 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 00:49:26 GMT"}, {"version": "v4", "created": "Tue, 12 Feb 2019 11:05:06 GMT"}, {"version": "v5", "created": "Wed, 15 Jul 2020 18:18:12 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Gupta", "Abhishek", ""], ["Jain", "Rahul", ""], ["Glynn", "Peter", ""]]}, {"id": "1804.01221", "submitter": "Max Simchowitz", "authors": "Max Simchowitz and Ahmed El Alaoui and Benjamin Recht", "title": "Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed\n  Wigner Law", "comments": "To appear in STOC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a \\emph{query complexity} lower bound for approximating the top $r$\ndimensional eigenspace of a matrix. We consider an oracle model where, given a\nsymmetric matrix $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$, an algorithm\n$\\mathsf{Alg}$ is allowed to make $\\mathsf{T}$ exact queries of the form\n$\\mathsf{w}^{(i)} = \\mathbf{M} \\mathsf{v}^{(i)}$ for $i$ in\n$\\{1,...,\\mathsf{T}\\}$, where $\\mathsf{v}^{(i)}$ is drawn from a distribution\nwhich depends arbitrarily on the past queries and measurements\n$\\{\\mathsf{v}^{(j)},\\mathsf{w}^{(i)}\\}_{1 \\le j \\le i-1}$. We show that for\nevery $\\mathtt{gap} \\in (0,1/2]$, there exists a distribution over matrices\n$\\mathbf{M}$ for which 1) $\\mathrm{gap}_r(\\mathbf{M}) = \\Omega(\\mathtt{gap})$\n(where $\\mathrm{gap}_r(\\mathbf{M})$ is the normalized gap between the $r$ and\n$r+1$-st largest-magnitude eigenvector of $\\mathbf{M}$), and 2) any algorithm\n$\\mathsf{Alg}$ which takes fewer than $\\mathrm{const} \\times \\frac{r \\log\nd}{\\sqrt{\\mathtt{gap}}}$ queries fails (with overwhelming probability) to\nidentity a matrix $\\widehat{\\mathsf{V}} \\in \\mathbb{R}^{d \\times r}$ with\northonormal columns for which $\\langle \\widehat{\\mathsf{V}}, \\mathbf{M}\n\\widehat{\\mathsf{V}}\\rangle \\ge (1 - \\mathrm{const} \\times\n\\mathtt{gap})\\sum_{i=1}^r \\lambda_i(\\mathbf{M})$. Our bound requires only that\n$d$ is a small polynomial in $1/\\mathtt{gap}$ and $r$, and matches the upper\nbounds of Musco and Musco '15. Moreover, it establishes a strict separation\nbetween convex optimization and \\emph{randomized}, \"strict-saddle\" non-convex\noptimization of which PCA is a canonical example: in the former, first-order\nmethods can have dimension-free iteration complexity, whereas in PCA, the\niteration complexity of gradient-based methods must necessarily grow with the\ndimension.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 03:00:06 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:55:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Simchowitz", "Max", ""], ["Alaoui", "Ahmed El", ""], ["Recht", "Benjamin", ""]]}, {"id": "1804.01238", "submitter": "Trevor Barron", "authors": "Trevor Barron, Oliver Obst, Heni Ben Amor", "title": "Information Maximizing Exploration with a Latent Dynamics Model", "comments": "Presented at the NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All reinforcement learning algorithms must handle the trade-off between\nexploration and exploitation. Many state-of-the-art deep reinforcement learning\nmethods use noise in the action selection, such as Gaussian noise in policy\ngradient methods or $\\epsilon$-greedy in Q-learning. While these methods are\nappealing due to their simplicity, they do not explore the state space in a\nmethodical manner. We present an approach that uses a model to derive reward\nbonuses as a means of intrinsic motivation to improve model-free reinforcement\nlearning. A key insight of our approach is that this dynamics model can be\nlearned in the latent feature space of a value function, representing the\ndynamics of the agent and the environment. This method is both theoretically\ngrounded and computationally advantageous, permitting the efficient use of\nBayesian information-theoretic methods in high-dimensional state spaces. We\nevaluate our method on several continuous control tasks, focusing on improving\nexploration.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 05:04:41 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Barron", "Trevor", ""], ["Obst", "Oliver", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1804.01310", "submitter": "Guillermo Gallego", "authors": "Ana I. Maqueda, Antonio Loquercio, Guillermo Gallego, Narciso Garcia,\n  Davide Scaramuzza", "title": "Event-based Vision meets Deep Learning on Steering Prediction for\n  Self-driving Cars", "comments": "9 pages, 8 figures, 6 tables. Video: https://youtu.be/_r_bsjkJTHA", "journal-ref": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n  Salt Lake City, 2018", "doi": "10.1109/CVPR.2018.00568", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event cameras are bio-inspired vision sensors that naturally capture the\ndynamics of a scene, filtering out redundant information. This paper presents a\ndeep neural network approach that unlocks the potential of event cameras on a\nchallenging motion-estimation task: prediction of a vehicle's steering angle.\nTo make the best out of this sensor-algorithm combination, we adapt\nstate-of-the-art convolutional architectures to the output of event sensors and\nextensively evaluate the performance of our approach on a publicly available\nlarge scale event-camera dataset (~1000 km). We present qualitative and\nquantitative explanations of why event cameras allow robust steering prediction\neven in cases where traditional cameras fail, e.g. challenging illumination\nconditions and fast motion. Finally, we demonstrate the advantages of\nleveraging transfer learning from traditional to event-based vision, and show\nthat our approach outperforms state-of-the-art algorithms based on standard\ncameras.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 09:05:41 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Maqueda", "Ana I.", ""], ["Loquercio", "Antonio", ""], ["Gallego", "Guillermo", ""], ["Garcia", "Narciso", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "1804.01330", "submitter": "Thomas Krak", "authors": "Thomas Krak, Alexander Erreygers, Jasper De Bock", "title": "An Imprecise Probabilistic Estimator for the Transition Rate Matrix of a\n  Continuous-Time Markov Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the transition rate matrix of a\ncontinuous-time Markov chain from a finite-duration realisation of this\nprocess. We approach this problem in an imprecise probabilistic framework,\nusing a set of prior distributions on the unknown transition rate matrix. The\nresulting estimator is a set of transition rate matrices that, for reasons of\nconjugacy, is easy to find. To determine the hyperparameters for our set of\npriors, we reconsider the problem in discrete time, where we can use the\nwell-known Imprecise Dirichlet Model. In particular, we show how the limit of\nthe resulting discrete-time estimators is a continuous-time estimator. It\ncorresponds to a specific choice of hyperparameters and has an exceptionally\nsimple closed-form expression.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 10:20:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:42:47 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Krak", "Thomas", ""], ["Erreygers", "Alexander", ""], ["De Bock", "Jasper", ""]]}, {"id": "1804.01382", "submitter": "Chaochen Wu", "authors": "Chaochen Wu", "title": "Vanlearning: A Machine Learning SaaS Application for People Without\n  Programming Backgrounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although we have tons of machine learning tools to analyze data, most of them\nrequire users have some programming backgrounds. Here we introduce a SaaS\napplication which allows users analyze their data without any coding and even\nwithout any knowledge of machine learning. Users can upload, train, predict and\ndownload their data by simply clicks their mouses. Our system uses data\npre-processor and validator to relieve the computational cost of our server.\nThe simple architecture of Vanlearning helps developers can easily maintain and\nextend it.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 01:17:16 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Wu", "Chaochen", ""]]}, {"id": "1804.01466", "submitter": "William Herlands", "authors": "William Herlands, Edward McFowland III, Andrew Gordon Wilson, Daniel\n  B. Neill", "title": "Gaussian Process Subset Scanning for Anomalous Pattern Detection in\n  Non-iid Data", "comments": "Presented at AISTATS 2018. 11 pages. Supplement to main paper is\n  included here as an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying anomalous patterns in real-world data is essential for\nunderstanding where, when, and how systems deviate from their expected\ndynamics. Yet methods that separately consider the anomalousness of each\nindividual data point have low detection power for subtle, emerging\nirregularities. Additionally, recent detection techniques based on subset\nscanning make strong independence assumptions and suffer degraded performance\nin correlated data. We introduce methods for identifying anomalous patterns in\nnon-iid data by combining Gaussian processes with novel log-likelihood ratio\nstatistic and subset scanning techniques. Our approaches are powerful,\ninterpretable, and can integrate information across multiple data streams. We\nillustrate their performance on numeric simulations and three open source\nspatiotemporal datasets of opioid overdose deaths, 311 calls, and storm\nreports.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 15:23:16 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Herlands", "William", ""], ["McFowland", "Edward", "III"], ["Wilson", "Andrew Gordon", ""], ["Neill", "Daniel B.", ""]]}, {"id": "1804.01491", "submitter": "Zahra Ahmadi", "authors": "Zahra Ahmadi and Stefan Kramer", "title": "Online Multi-Label Classification: A Label Compression Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications deal with multi-label data, such as functional\ncategorizations of genes, image labeling and text categorization.\nClassification of such data with a large number of labels and latent\ndependencies among them is a challenging task, and it becomes even more\nchallenging when the data is received online and in chunks. Many of the current\nmulti-label classification methods require a lot of time and memory, which make\nthem infeasible for practical real-world applications. In this paper, we\npropose a fast linear label space dimension reduction method that transforms\nthe labels into a reduced encoded space and trains models on the obtained\npseudo labels. Additionally, it provides an analytical method to update the\ndecoding matrix which maps the labels into the original space and is used\nduring the test phase. Experimental results show the effectiveness of this\napproach in terms of running times and the prediction performance over\ndifferent measures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:18:28 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Ahmadi", "Zahra", ""], ["Kramer", "Stefan", ""]]}, {"id": "1804.01508", "submitter": "Ole-Christoffer Granmo", "authors": "Ole-Christoffer Granmo", "title": "The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to\n  Optimal Pattern Recognition with Propositional Logic", "comments": "42 pages, 14 figures, further formalizing key concepts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although simple individually, artificial neurons provide state-of-the-art\nperformance when interconnected in deep networks. Arguably, the Tsetlin\nAutomaton is an even simpler and more versatile learning mechanism, capable of\nsolving the multi-armed bandit problem. Merely by means of a single integer as\nmemory, it learns the optimal action in stochastic environments through\nincrement and decrement operations. In this paper, we introduce the Tsetlin\nMachine, which solves complex pattern recognition problems with propositional\nformulas, composed by a collective of Tsetlin Automata. To eliminate the\nlongstanding problem of vanishing signal-to-noise ratio, the Tsetlin Machine\norchestrates the automata using a novel game. Further, both inputs, patterns,\nand outputs are expressed as bits, while recognition and learning rely on bit\nmanipulation, simplifying computation. Our theoretical analysis establishes\nthat the Nash equilibria of the game align with the propositional formulas that\nprovide optimal pattern recognition accuracy. This translates to learning\nwithout local optima, only global ones. In five benchmarks, the Tsetlin Machine\nprovides competitive accuracy compared with SVMs, Decision Trees, Random\nForests, Naive Bayes Classifier, Logistic Regression, and Neural Networks. We\nfurther demonstrate how the propositional formulas facilitate interpretation.\nIn conclusion, we believe the combination of high accuracy, interpretability,\nand computational simplicity makes the Tsetlin Machine a promising tool for a\nwide range of domains.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:52:34 GMT"}, {"version": "v10", "created": "Tue, 15 Jan 2019 17:29:40 GMT"}, {"version": "v11", "created": "Mon, 4 Feb 2019 12:00:26 GMT"}, {"version": "v12", "created": "Thu, 23 Apr 2020 16:17:31 GMT"}, {"version": "v13", "created": "Thu, 11 Jun 2020 08:09:55 GMT"}, {"version": "v14", "created": "Thu, 3 Dec 2020 13:02:37 GMT"}, {"version": "v15", "created": "Sat, 2 Jan 2021 00:51:08 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 15:19:24 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 14:33:17 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 16:42:33 GMT"}, {"version": "v5", "created": "Wed, 11 Apr 2018 16:26:27 GMT"}, {"version": "v6", "created": "Mon, 16 Apr 2018 13:33:49 GMT"}, {"version": "v7", "created": "Mon, 23 Apr 2018 12:51:28 GMT"}, {"version": "v8", "created": "Mon, 7 Jan 2019 13:01:31 GMT"}, {"version": "v9", "created": "Thu, 10 Jan 2019 17:11:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Granmo", "Ole-Christoffer", ""]]}, {"id": "1804.01523", "submitter": "Alex Lee", "authors": "Alex X. Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea\n  Finn, Sergey Levine", "title": "Stochastic Adversarial Video Prediction", "comments": "Website: https://alexlee-gk.github.io/video_prediction/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to predict what may happen in the future requires an in-depth\nunderstanding of the physical and causal rules that govern the world. A model\nthat is able to do so has a number of appealing applications, from robotic\nplanning to representation learning. However, learning to predict raw future\nobservations, such as frames in a video, is exceedingly challenging -- the\nambiguous nature of the problem can cause a naively designed model to average\ntogether possible futures into a single, blurry prediction. Recently, this has\nbeen addressed by two distinct approaches: (a) latent variational variable\nmodels that explicitly model underlying stochasticity and (b)\nadversarially-trained models that aim to produce naturalistic images. However,\na standard latent variable model can struggle to produce realistic results, and\na standard adversarially-trained model underutilizes latent variables and fails\nto produce diverse predictions. We show that these distinct methods are in fact\ncomplementary. Combining the two produces predictions that look more realistic\nto human raters and better cover the range of possible futures. Our method\noutperforms prior and concurrent work in these aspects.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 17:55:40 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Lee", "Alex X.", ""], ["Zhang", "Richard", ""], ["Ebert", "Frederik", ""], ["Abbeel", "Pieter", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "1804.01526", "submitter": "Mario Drumond", "authors": "Mario Drumond, Tao Lin, Martin Jaggi, Babak Falsafi", "title": "Training DNNs with Hybrid Block Floating Point", "comments": "9 pages, 3 figures. Accepted in Neural Information Processing Systems\n  2018 (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of DNNs has given birth to unrelenting computing\nrequirements, forcing datacenter operators to adopt domain-specific\naccelerators to train them. These accelerators typically employ densely packed\nfull precision floating-point arithmetic to maximize performance per area.\nOngoing research efforts seek to further increase that performance density by\nreplacing floating-point with fixed-point arithmetic. However, a significant\nroadblock for these attempts has been fixed point's narrow dynamic range, which\nis insufficient for DNN training convergence. We identify block floating point\n(BFP) as a promising alternative representation since it exhibits wide dynamic\nrange and enables the majority of DNN operations to be performed with\nfixed-point logic. Unfortunately, BFP alone introduces several limitations that\npreclude its direct applicability. In this work, we introduce HBFP, a hybrid\nBFP-FP approach, which performs all dot products in BFP and other operations in\nfloating point. HBFP delivers the best of both worlds: the high accuracy of\nfloating point at the superior hardware density of fixed point. For a wide\nvariety of models, we show that HBFP matches floating point's accuracy while\nenabling hardware implementations that deliver up to 8.5x higher throughput.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 09:40:59 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 21:48:51 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 17:48:03 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 15:11:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Drumond", "Mario", ""], ["Lin", "Tao", ""], ["Jaggi", "Martin", ""], ["Falsafi", "Babak", ""]]}, {"id": "1804.01527", "submitter": "Jos\\'e Carlos Aradillas Jaramillo", "authors": "Jos\\'e Carlos Aradillas, Juan Jos\\'e Murillo-Fuentes, Pablo M. Olmos", "title": "Boosting Handwriting Text Recognition in Small Databases with Transfer\n  Learning", "comments": "ICFHR 2018 Conference", "journal-ref": null, "doi": "10.1109/ICFHR-2018.2018.00081", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the offline handwriting text recognition (HTR)\nproblem with reduced training datasets. Recent HTR solutions based on\nartificial neural networks exhibit remarkable solutions in referenced\ndatabases. These deep learning neural networks are composed of both\nconvolutional (CNN) and long short-term memory recurrent units (LSTM). In\naddition, connectionist temporal classification (CTC) is the key to avoid\nsegmentation at character level, greatly facilitating the labeling task. One of\nthe main drawbacks of the CNNLSTM-CTC (CLC) solutions is that they need a\nconsiderable part of the text to be transcribed for every type of calligraphy,\ntypically in the order of a few thousands of lines. Furthermore, in some\nscenarios the text to transcribe is not that long, e.g. in the Washington\ndatabase. The CLC typically overfits for this reduced number of training\nsamples. Our proposal is based on the transfer learning (TL) from the\nparameters learned with a bigger database. We first investigate, for a reduced\nand fixed number of training samples, 350 lines, how the learning from a large\ndatabase, the IAM, can be transferred to the learning of the CLC of a reduced\ndatabase, Washington. We focus on which layers of the network could be not\nre-trained. We conclude that the best solution is to re-train the whole CLC\nparameters initialized to the values obtained after the training of the CLC\nfrom the larger database. We also investigate results when the training size is\nfurther reduced. The differences in the CER are more remarkable when training\nwith just 350 lines, a CER of 3.3% is achieved with TL while we have a CER of\n18.2% when training from scratch. As a byproduct, the learning times are quite\nreduced. Similar good results are obtained from the Parzival database when\ntrained with this reduced number of lines and this new approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 11:20:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aradillas", "Jos\u00e9 Carlos", ""], ["Murillo-Fuentes", "Juan Jos\u00e9", ""], ["Olmos", "Pablo M.", ""]]}, {"id": "1804.01557", "submitter": "Tobias D. Krafft", "authors": "Tobias D. Krafft", "title": "Qualit\\\"atsma{\\ss}e bin\\\"arer Klassifikationen im Bereich\n  kriminalprognostischer Instrumente der vierten Generation", "comments": "master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This master's thesis discusses an important issue regarding how algorithmic\ndecision making (ADM) is used in crime forecasting. In America forecasting\ntools are widely used by judiciary systems for making decisions about risk\noffenders based on criminal justice for risk offenders. By making use of such\ntools, the judiciary relies on ADM in order to make error free judgement on\noffenders. For this purpose, one of the quality measures for machine learning\ntechniques which is widly used, the $AUC$ (area under curve), is compared to\nand contrasted for results with the $PPV_k$ (positive predictive value).\nKeeping in view the criticality of judgement along with a high dependency on\ntools offering ADM, it is necessary to evaluate risk tools that aid in decision\nmaking based on algorithms. In this methodology, such an evaluation is\nconducted by implementing a common machine learning approach called binary\nclassifier, as it determines the binary outcome of the underlying juristic\nquestion. This thesis showed that the $PPV_k$ (positive predictive value)\ntechnique models the decision of judges much better than the $AUC$. Therefore,\nthis research has investigated whether there exists a classifier for which the\n$PPV_k$ deviates from $AUC$ by a large proportion. It could be shown that the\ndeviation can rise up to 0.75. In order to test this deviation on an already in\nused Classifier, data from the fourth generation risk assement tool COMPAS was\nused. The result were were quite alarming as the two measures derivate from\neach other by 0.48. In this study, the risk assessment evaluation of the\nforecasting tools was successfully conducted, carefully reviewed and examined.\nAdditionally, it is also discussed whether such systems used for the purpose of\nmaking decisions should be socially accepted or not.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 18:27:45 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Krafft", "Tobias D.", ""]]}, {"id": "1804.01575", "submitter": "Aubrey Gress", "authors": "Aubrey Gress and Ian Davidson", "title": "Probabilistic Formulations of Regression with Mixed Guidance", "comments": "Appeared in ICDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression problems assume every instance is annotated (labeled) with a real\nvalue, a form of annotation we call \\emph{strong guidance}. In order for these\nannotations to be accurate, they must be the result of a precise experiment or\nmeasurement. However, in some cases additional \\emph{weak guidance} might be\ngiven by imprecise measurements, a domain expert or even crowd sourcing.\nCurrent formulations of regression are unable to use both types of guidance. We\npropose a regression framework that can also incorporate weak guidance based on\nrelative orderings, bounds, neighboring and similarity relations. Consider\nlearning to predict ages from portrait images, these new types of guidance\nallow weaker forms of guidance such as stating a person is in their 20s or two\npeople are similar in age. These types of annotations can be easier to generate\nthan strong guidance. We introduce a probabilistic formulation for these forms\nof weak guidance and show that the resulting optimization problems are convex.\nOur experimental results show the benefits of these formulations on several\ndata sets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:36:33 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Gress", "Aubrey", ""], ["Davidson", "Ian", ""]]}, {"id": "1804.01592", "submitter": "Jan Vyb\\'iral", "authors": "Massimo Fornasier, Jan Vyb\\'iral, Ingrid Daubechies", "title": "Robust and Resource Efficient Identification of Shallow Neural Networks\n  by Fewest Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the structure identification and the uniform approximation of sums\nof ridge functions $f(x)=\\sum_{i=1}^m g_i(a_i\\cdot x)$ on ${\\mathbb R}^d$,\nrepresenting a general form of a shallow feed-forward neural network, from a\nsmall number of query samples. Higher order differentiation, as used in our\nconstructive approximations, of sums of ridge functions or of their\ncompositions, as in deeper neural network, yields a natural connection between\nneural network weight identification and tensor product decomposition\nidentification. In the case of the shallowest feed-forward neural network,\nsecond order differentiation and tensors of order two (i.e., matrices) suffice\nas we prove in this paper. We use two sampling schemes to perform approximate\ndifferentiation - active sampling, where the sampling points are universal,\nactively, and randomly designed, and passive sampling, where sampling points\nwere preselected at random from a distribution with known density. Based on\nmultiple gathered approximated first and second order differentials, our\ngeneral approximation strategy is developed as a sequence of algorithms to\nperform individual sub-tasks. We first perform an active subspace search by\napproximating the span of the weight vectors $a_1,\\dots,a_m$. Then we use a\nstraightforward substitution, which reduces the dimensionality of the problem\nfrom $d$ to $m$. The core of the construction is then the stable and efficient\napproximation of weights expressed in terms of rank-$1$ matrices $a_i \\otimes\na_i$, realized by formulating their individual identification as a suitable\nnonlinear program. We prove the successful identification by this program of\nweight vectors being close to orthonormal and we also show how we can\ncostructively reduce to this case by a whitening procedure, without loss of any\ngenerality.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 19:56:40 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 10:32:37 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 07:55:12 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Fornasier", "Massimo", ""], ["Vyb\u00edral", "Jan", ""], ["Daubechies", "Ingrid", ""]]}, {"id": "1804.01619", "submitter": "Yuansi Chen", "authors": "Yuansi Chen, Chi Jin and Bin Yu", "title": "Stability and Convergence Trade-off of Iterative Optimization Algorithms", "comments": "45 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall performance or expected excess risk of an iterative machine\nlearning algorithm can be decomposed into training error and generalization\nerror. While the former is controlled by its convergence analysis, the latter\ncan be tightly handled by algorithmic stability. The machine learning community\nhas a rich history investigating convergence and stability separately. However,\nthe question about the trade-off between these two quantities remains open. In\nthis paper, we show that for any iterative algorithm at any iteration, the\noverall performance is lower bounded by the minimax statistical error over an\nappropriately chosen loss function class. This implies an important trade-off\nbetween convergence and stability of the algorithm -- a faster converging\nalgorithm has to be less stable, and vice versa. As a direct consequence of\nthis fundamental tradeoff, new convergence lower bounds can be derived for\nclasses of algorithms constrained with different stability bounds. In\nparticular, when the loss function is convex (or strongly convex) and smooth,\nwe discuss the stability upper bounds of gradient descent (GD) and stochastic\ngradient descent and their variants with decreasing step sizes. For Nesterov's\naccelerated gradient descent (NAG) and heavy ball method (HB), we provide\nstability upper bounds for the quadratic loss function. Applying existing\nstability upper bounds for the gradient methods in our trade-off framework, we\nobtain lower bounds matching the well-established convergence upper bounds up\nto constants for these algorithms and conjecture similar lower bounds for NAG\nand HB. Finally, we numerically demonstrate the tightness of our stability\nbounds in terms of exponents in the rate and also illustrate via a simulated\nlogistic regression problem that our stability bounds reflect the\ngeneralization errors better than the simple uniform convergence bounds for GD\nand NAG.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:23:40 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Chen", "Yuansi", ""], ["Jin", "Chi", ""], ["Yu", "Bin", ""]]}, {"id": "1804.01620", "submitter": "Eduardo Pavez", "authors": "Eduardo Pavez and Antonio Ortega", "title": "Active covariance estimation by random sub-sampling of variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study covariance matrix estimation for the case of partially observed\nrandom vectors, where different samples contain different subsets of vector\ncoordinates. Each observation is the product of the variable of interest with a\n$0-1$ Bernoulli random variable. We analyze an unbiased covariance estimator\nunder this model, and derive an error bound that reveals relations between the\nsub-sampling probabilities and the entries of the covariance matrix. We apply\nour analysis in an active learning framework, where the expected number of\nobserved variables is small compared to the dimension of the vector of\ninterest, and propose a design of optimal sub-sampling probabilities and an\nactive covariance matrix estimation algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:49:12 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Pavez", "Eduardo", ""], ["Ortega", "Antonio", ""]]}, {"id": "1804.01622", "submitter": "Justin Johnson", "authors": "Justin Johnson, Agrim Gupta, Li Fei-Fei", "title": "Image Generation from Scene Graphs", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To truly understand the visual world our models should be able not only to\nrecognize images but also generate them. To this end, there has been exciting\nrecent progress on generating images from natural language descriptions. These\nmethods give stunning results on limited domains such as descriptions of birds\nor flowers, but struggle to faithfully reproduce complex sentences with many\nobjects and relationships. To overcome this limitation we propose a method for\ngenerating images from scene graphs, enabling explicitly reasoning about\nobjects and their relationships. Our model uses graph convolution to process\ninput graphs, computes a scene layout by predicting bounding boxes and\nsegmentation masks for objects, and converts the layout to an image with a\ncascaded refinement network. The network is trained adversarially against a\npair of discriminators to ensure realistic outputs. We validate our approach on\nVisual Genome and COCO-Stuff, where qualitative results, ablations, and user\nstudies demonstrate our method's ability to generate complex images with\nmultiple objects.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:59:08 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Johnson", "Justin", ""], ["Gupta", "Agrim", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1804.01650", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Sebastian Ewert, Simon Dixon", "title": "Jointly Detecting and Separating Singing Voice: A Multi-Task Approach", "comments": "10 pages, 2 figures, accepted for the 14th International Conference\n  on Latent Variable Analysis and Signal Separation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main challenge in applying deep learning to music processing is the\navailability of training data. One potential solution is Multi-task Learning,\nin which the model also learns to solve related auxiliary tasks on additional\ndatasets to exploit their correlation. While intuitive in principle, it can be\nchallenging to identify related tasks and construct the model to optimally\nshare information between tasks. In this paper, we explore vocal activity\ndetection as an additional task to stabilise and improve the performance of\nvocal separation. Further, we identify problematic biases specific to each\ndataset that could limit the generalisation capability of separation and\ndetection models, to which our proposed approach is robust. Experiments show\nimproved performance in separation as well as vocal detection compared to\nsingle-task baselines. However, we find that the commonly used\nSignal-to-Distortion Ratio (SDR) metrics did not capture the improvement on\nnon-vocal sections, indicating the need for improved evaluation methodologies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 01:55:39 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Stoller", "Daniel", ""], ["Ewert", "Sebastian", ""], ["Dixon", "Simon", ""]]}, {"id": "1804.01653", "submitter": "Rong Zhang", "authors": "Rong Zhang, Weiping Li, Tong Mo", "title": "Review of Deep Learning", "comments": "In Chinese. Have been published in the journal \"Information and\n  Control\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including speech processing, computer vision,\nnatural language processing and so on. Finally, this paper discusses the\nexisting problems of deep learning and gives the corresponding possible\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 02:23:59 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 15:34:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhang", "Rong", ""], ["Li", "Weiping", ""], ["Mo", "Tong", ""]]}, {"id": "1804.01675", "submitter": "Andrew Paplinski", "authors": "Yanan Li, Haixiang Guo, Andrew P Paplinski", "title": "Semi-Supervised Classification for oil reservoir", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the general problem of accurate identification of oil\nreservoirs. Recent improvements in well or borehole logging technology have\nresulted in an explosive amount of data available for processing. The\ntraditional methods of analysis of the logs characteristics by experts require\nsignificant amount of time and money and is no longer practicable. In this\npaper, we use the semi-supervised learning to solve the problem of\never-increasing amount of unlabelled data available for interpretation. The\nexperts are needed to label only a small amount of the log data. The neural\nnetwork classifier is first trained with the initial labelled data. Next,\nbatches of unlabelled data are being classified and the samples with the very\nhigh class probabilities are being used in the next training session,\nbootstrapping the classifier. The process of training, classifying, enhancing\nthe labelled data is repeated iteratively until the stopping criteria are met,\nthat is, no more high probability samples are found. We make an empirical study\non the well data from Jianghan oil field and test the performance of the neural\nnetwork semi-supervised classifier. We compare this method with other\nclassifiers. The comparison results show that our neural network\nsemi-supervised classifier is superior to other classification methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 05:41:39 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Li", "Yanan", ""], ["Guo", "Haixiang", ""], ["Paplinski", "Andrew P", ""]]}, {"id": "1804.01684", "submitter": "Philippe Thomas", "authors": "Philippe Thomas (CRAN), Hind Bril El Haouzi, Marie-Christine Suhner\n  (CRAN), Andr\\'e Thomas (CRAN), Emmanuel Zimmermann (CRAN), M\\'elanie Noyel", "title": "Using a Classifier Ensemble for Proactive Quality Monitoring and\n  Control: the impact of the choice of classifiers types, selection criterion,\n  and fusion process", "comments": null, "journal-ref": "Computers in Industry Computers in Industry, 99, pp.193 - 204", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, the manufacturing processes are faced with many external or\ninternal (the increase of customized product rescheduling , process\nreliability,..) changes. Therefore, monitoring and quality management\nactivities for these manufacturing processes are difficult. Thus, the managers\nneed more proactive approaches to deal with this variability. In this study, a\nproactive quality monitoring and control approach based on classifiers to\npredict defect occurrences and provide optimal values for factors critical to\nthe quality processes is proposed. In a previous work (Noyel et al. 2013), the\nclassification approach had been used in order to improve the quality of a\nlacquering process at a company plant; the results obtained are promising, but\nthe accuracy of the classification model used needs to be improved. One way to\nachieve this is to construct a committee of classifiers (referred to as an\nensemble) to obtain a better predictive model than its constituent models.\nHowever, the selection of the best classification methods and the construction\nof the final ensemble still poses a challenging issue. In this study, we focus\nand analyze the impact of the choice of classifier types on the accuracy of the\nclassifier ensemble; in addition, we explore the effects of the selection\ncriterion and fusion process on the ensemble accuracy as well. Several fusion\nscenarios were tested and compared based on a real-world case. Our results show\nthat using an ensemble classification leads to an increase in the accuracy of\nthe classifier models. Consequently, the monitoring and control of the\nconsidered real-world case can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:46:19 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Thomas", "Philippe", "", "CRAN"], ["Haouzi", "Hind Bril El", "", "CRAN"], ["Suhner", "Marie-Christine", "", "CRAN"], ["Thomas", "Andr\u00e9", "", "CRAN"], ["Zimmermann", "Emmanuel", "", "CRAN"], ["Noyel", "M\u00e9lanie", ""]]}, {"id": "1804.01694", "submitter": "Anvita Gupta", "authors": "Anvita Gupta and James Zou", "title": "Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for\n  Optimizing Protein Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) represent an attractive and novel\napproach to generate realistic data, such as genes, proteins, or drugs, in\nsynthetic biology. Here, we apply GANs to generate synthetic DNA sequences\nencoding for proteins of variable length. We propose a novel feedback-loop\narchitecture, called Feedback GAN (FBGAN), to optimize the synthetic gene\nsequences for desired properties using an external function analyzer. The\nproposed architecture also has the advantage that the analyzer need not be\ndifferentiable. We apply the feedback-loop mechanism to two examples: 1)\ngenerating synthetic genes coding for antimicrobial peptides, and 2) optimizing\nsynthetic genes for the secondary structure of their resulting peptides. A\nsuite of metrics demonstrate that the GAN generated proteins have desirable\nbiophysical properties. The FBGAN architecture can also be used to optimize\nGAN-generated datapoints for useful properties in domains beyond genomics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:17:42 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Gupta", "Anvita", ""], ["Zou", "James", ""]]}, {"id": "1804.01712", "submitter": "Aditya Grover", "authors": "Aditya Grover, Ramki Gummadi, Miguel Lazaro-Gredilla, Dale Schuurmans,\n  Stefano Ermon", "title": "Variational Rejection Sampling", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:53:41 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Grover", "Aditya", ""], ["Gummadi", "Ramki", ""], ["Lazaro-Gredilla", "Miguel", ""], ["Schuurmans", "Dale", ""], ["Ermon", "Stefano", ""]]}, {"id": "1804.01720", "submitter": "Martin Engilberge", "authors": "Martin Engilberge, Louis Chevallier, Patrick P\\'erez, Matthieu Cord", "title": "Finding beans in burgers: Deep semantic-visual embedding with\n  localization", "comments": "Accepted to CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have proposed to learn a two-path neural network that maps\nimages and texts, respectively, to a same shared Euclidean space where geometry\ncaptures useful semantic relationships. Such a multi-modal embedding can be\ntrained and used for various tasks, notably image captioning. In the present\nwork, we introduce a new architecture of this type, with a visual path that\nleverages recent space-aware pooling mechanisms. Combined with a textual path\nwhich is jointly trained from scratch, our semantic-visual embedding offers a\nversatile model. Once trained under the supervision of captioned images, it\nyields new state-of-the-art performance on cross-modal retrieval. It also\nallows the localization of new concepts from the embedding space into any input\nimage, delivering state-of-the-art result on the visual grounding of phrases.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 08:13:37 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 14:04:35 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Engilberge", "Martin", ""], ["Chevallier", "Louis", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.01756", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Alex Graves, Timothy Lillicrap", "title": "The Kanerva Machine: A Generative Distributed Memory", "comments": "Published as a conference paper at ICLR 2018 (corrected typos in\n  revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:07:05 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:23:40 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 09:52:40 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Graves", "Alex", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.01825", "submitter": "Alexei Botchkarev", "authors": "Alexei Botchkarev", "title": "Evaluating Hospital Case Cost Prediction Models Using Azure Machine\n  Learning Studio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability for accurate hospital case cost modelling and prediction is critical\nfor efficient health care financial management and budgetary planning. A\nvariety of regression machine learning algorithms are known to be effective for\nhealth care cost predictions. The purpose of this experiment was to build an\nAzure Machine Learning Studio tool for rapid assessment of multiple types of\nregression models. The tool offers environment for comparing 14 types of\nregression models in a unified experiment: linear regression, Bayesian linear\nregression, decision forest regression, boosted decision tree regression,\nneural network regression, Poisson regression, Gaussian processes for\nregression, gradient boosted machine, nonlinear least squares regression,\nprojection pursuit regression, random forest regression, robust regression,\nrobust regression with mm-type estimators, support vector regression. The tool\npresents assessment results arranged by model accuracy in a single table using\nfive performance metrics. Evaluation of regression machine learning models for\nperforming hospital case cost prediction demonstrated advantage of robust\nregression model, boosted decision tree regression and decision forest\nregression. The operational tool has been published to the web and openly\navailable for experiments and extensions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 02:40:43 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 04:00:10 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Botchkarev", "Alexei", ""]]}, {"id": "1804.01834", "submitter": "Mehdi Salehi Heydar Abad", "authors": "Mehdi Salehi Heydar Abad, Ozgur Ercetin", "title": "Finite Horizon Throughput Maximization and Sensing Optimization in\n  Wireless Powered Devices over Fading Channels", "comments": "Single column, 31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless power transfer (WPT) is a promising technology that provides the\nnetwork a way to replenish the batteries of the remote devices by utilizing RF\ntransmissions. We study a class of harvest-first-transmit-later type of WPT\npolicy, where an access point (AP) first employs RF power transfer to recharge\na wireless powered device (WPD) for a certain period subjected to optimization,\nand then, the harvested energy is subsequently used by the WPD to transmit its\ndata bits back to the AP over a finite horizon. A significant challenge\nregarding the studied WPT scenario is the time-varying nature of the wireless\nchannel linking the WPD to the AP. We first investigate as a benchmark the\noffline case where the channel realizations are known non-causally prior to the\nstarting of the horizon. For the offline case, by finding the optimal WPT\nduration and power allocations in the data transmission period, we derive an\nupper bound on the throughput of the WPD. We then focus on the online\ncounterpart of the problem where the channel realizations are known causally.\nWe prove that the optimal WPT duration obeys a time-dependent threshold form\ndepending on the energy state of the WPD. In the subsequent data transmission\nstage, the optimal transmit power allocation for the WPD is shown to be of a\nfractional structure where at each time slot a fraction of energy depending on\nthe current channel and a measure of future channel state expectations is\nallocated for data transmission. We numerically show that the online policy\nperforms almost identical to the upper bound. We then consider a data sensing\napplication, where the WPD adjusts the sensing resolution to balance between\nthe quality of the sensed data and the probability of successfully delivering\nit. We use Bayesian inference as a reinforcement learning method to provide a\nmean for the WPD in learning to balance the sensing resolution.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:40:40 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:23:31 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Abad", "Mehdi Salehi Heydar", ""], ["Ercetin", "Ozgur", ""]]}, {"id": "1804.01849", "submitter": "Filip Korzeniowski", "authors": "Filip Korzeniowski, David R. W. Sears, Gerhard Widmer", "title": "A Large-Scale Study of Language Models for Chord Prediction", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large-scale study of language models for chord prediction.\nSpecifically, we compare N-gram models to various flavours of recurrent neural\nnetworks on a comprehensive dataset comprising all publicly available datasets\nof annotated chords known to us. This large amount of data allows us to\nsystematically explore hyper-parameter settings for the recurrent neural\nnetworks---a crucial step in achieving good results with this model class. Our\nresults show not only a quantitative difference between the models, but also a\nqualitative one: in contrast to static N-gram models, certain RNN\nconfigurations adapt to the songs at test time. This finding constitutes a\nfurther step towards the development of chord recognition systems that are more\naware of local musical context than what was previously possible.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 13:51:10 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Korzeniowski", "Filip", ""], ["Sears", "David R. W.", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1804.01852", "submitter": "Michael Blot", "authors": "Michael Blot, David Picard, Matthieu Cord", "title": "GoSGD: Distributed Optimization for Deep Learning with Gossip Exchange", "comments": "Correction to do, and difficulties to change the document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of speeding up the training of convolutional neural\nnetworks by studying a distributed method adapted to stochastic gradient\ndescent. Our parallel optimization setup uses several threads, each applying\nindividual gradient descents on a local variable. We propose a new way of\nsharing information between different threads based on gossip algorithms that\nshow good consensus convergence properties. Our method called GoSGD has the\nadvantage to be fully asynchronous and decentralized.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 12:13:41 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 08:49:48 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Blot", "Michael", ""], ["Picard", "David", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.01874", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Saeid Nahavandi, Thanh Nguyen", "title": "A Human Mixed Strategy Approach to Deep Reinforcement Learning", "comments": null, "journal-ref": "2018 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC)", "doi": "10.1109/SMC.2018.00682", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 14:24:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nahavandi", "Saeid", ""], ["Nguyen", "Thanh", ""]]}, {"id": "1804.01882", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Gary B\\'ecigneul and Thomas Hofmann", "title": "Hyperbolic Entailment Cones for Learning Hierarchical Embeddings", "comments": "International Conference on Machine Learning (ICML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph representations via low-dimensional embeddings that preserve\nrelevant network properties is an important class of problems in machine\nlearning. We here present a novel method to embed directed acyclic graphs.\nFollowing prior work, we first advocate for using hyperbolic spaces which\nprovably model tree-like structures better than Euclidean geometry. Second, we\nview hierarchical relations as partial orders defined using a family of nested\ngeodesically convex cones. We prove that these entailment cones admit an\noptimal shape with a closed form expression both in the Euclidean and\nhyperbolic spaces, and they canonically define the embedding learning process.\nExperiments show significant improvements of our method over strong recent\nbaselines both in terms of representational capacity and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:25:10 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 16:51:12 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 22:57:37 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["B\u00e9cigneul", "Gary", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1804.01900", "submitter": "Davood Zabihzadeh", "authors": "Baida Hamdan, Davood Zabihzadeh, Monsefi Reza", "title": "Large Scale Local Online Similarity/Distance Learning Framework based on\n  Passive/Aggressive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity/Distance measures play a key role in many machine learning,\npattern recognition, and data mining algorithms, which leads to the emergence\nof metric learning field. Many metric learning algorithms learn a global\ndistance function from data that satisfy the constraints of the problem.\nHowever, in many real-world datasets that the discrimination power of features\nvaries in the different regions of input space, a global metric is often unable\nto capture the complexity of the task. To address this challenge, local metric\nlearning methods are proposed that learn multiple metrics across the different\nregions of input space. Some advantages of these methods are high flexibility\nand the ability to learn a nonlinear mapping but typically achieves at the\nexpense of higher time requirement and overfitting problem. To overcome these\nchallenges, this research presents an online multiple metric learning\nframework. Each metric in the proposed framework is composed of a global and a\nlocal component learned simultaneously. Adding a global component to a local\nmetric efficiently reduce the problem of overfitting. The proposed framework is\nalso scalable with both sample size and the dimension of input data. To the\nbest of our knowledge, this is the first local online similarity/distance\nlearning framework based on PA (Passive/Aggressive). In addition, for\nscalability with the dimension of input data, DRP (Dual Random Projection) is\nextended for local online learning in the present work. It enables our methods\nto be run efficiently on high-dimensional datasets, while maintains their\npredictive performance. The proposed framework provides a straightforward local\nextension to any global online similarity/distance learning algorithm based on\nPA.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 15:11:11 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Hamdan", "Baida", ""], ["Zabihzadeh", "Davood", ""], ["Reza", "Monsefi", ""]]}, {"id": "1804.01947", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Phillip E. Pope, Charles E. Martin, Gustavo K. Rohde", "title": "Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study generative modeling via autoencoders while using the\nelegant geometric properties of the optimal transport (OT) problem and the\nWasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE),\nwhich are generative models that enable one to shape the distribution of the\nlatent space into any samplable probability distribution without the need for\ntraining an adversarial network or defining a closed-form for the distribution.\nIn short, we regularize the autoencoder loss with the sliced-Wasserstein\ndistance between the distribution of the encoded training samples and a\npredefined samplable distribution. We show that the proposed formulation has an\nefficient numerical solution that provides similar capabilities to Wasserstein\nAutoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an\nembarrassingly simple implementation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:45:06 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 21:51:24 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 00:05:29 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Kolouri", "Soheil", ""], ["Pope", "Phillip E.", ""], ["Martin", "Charles E.", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1804.01955", "submitter": "Przemyslaw Biecek", "authors": "Mateusz Staniak and Przemyslaw Biecek", "title": "Explanations of model predictions with live and breakDown packages", "comments": null, "journal-ref": "The R Journal (2018), 10 (2) p. 395-409", "doi": "10.32614/RJ-2018-072", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex models are commonly used in predictive modeling. In this paper we\npresent R packages that can be used to explain predictions from complex black\nbox models and attribute parts of these predictions to input features. We\nintroduce two new approaches and corresponding packages for such attribution,\nnamely live and breakDown. We also compare their results with existing\nimplementations of state of the art solutions, namely lime that implements\nLocally Interpretable Model-agnostic Explanations and ShapleyR that implements\nShapley values.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:05:15 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 19:49:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Staniak", "Mateusz", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1804.01983", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Qibin Zhao, Lihua Gui and Jianting Cao", "title": "High-dimension Tensor Completion via Gradient-based Optimization Under\n  Tensor-train Format", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor train (TT) decomposition has drawn people's attention due to its\npowerful representation ability and performance stability in high-order\ntensors. In this paper, we propose a novel approach to recover the missing\nentries of incomplete data represented by higher-order tensors. We attempt to\nfind the low-rank TT decomposition of the incomplete data which captures the\nlatent features of the whole data and then reconstruct the missing entries. By\napplying gradient descent algorithms, tensor completion problem is efficiently\nsolved by optimization models. We propose two TT-based algorithms: Tensor Train\nWeighted Optimization (TT-WOPT) and Tensor Train Stochastic Gradient Descent\n(TT-SGD) to optimize TT decomposition factors. In addition, a method named\nVisual Data Tensorization (VDT) is proposed to transform visual data into\nhigher-order tensors, resulting in the performance improvement of our\nalgorithms. The experiments in synthetic data and visual data show high\nefficiency and performance of our algorithms compared to the state-of-the-art\ncompletion algorithms, especially in high-order, high missing rate, and\nlarge-scale tensor completion situations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 02:06:28 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 09:03:23 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 03:21:55 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Yuan", "Longhao", ""], ["Zhao", "Qibin", ""], ["Gui", "Lihua", ""], ["Cao", "Jianting", ""]]}, {"id": "1804.02075", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Dariusz Dereniowski, Stefan Tiegel, Przemys{\\l}aw Uzna\\'nski, Daniel\n  Wolleb-Graf", "title": "A Framework for Searching in Graphs in the Presence of Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of searching for an unknown target vertex $t$ in a\n(possibly edge-weighted) graph. Each \\emph{vertex-query} points to a vertex $v$\nand the response either admits $v$ is the target or provides any neighbor\n$s\\not=v$ that lies on a shortest path from $v$ to $t$. This model has been\nintroduced for trees by Onak and Parys [FOCS 2006] and for general graphs by\nEmamjomeh-Zadeh et al. [STOC 2016]. In the latter, the authors provide\nalgorithms for the error-less case and for the independent noise model (where\neach query independently receives an erroneous answer with known probability\n$p<1/2$ and a correct one with probability $1-p$).\n  We study this problem in both adversarial errors and independent noise\nmodels. First, we show an algorithm that needs $\\frac{\\log_2 n}{1 - H(r)}$\nqueries against \\emph{adversarial} errors, where adversary is bounded with its\nrate of errors by a known constant $r<1/2$. Our algorithm is in fact a\nsimplification of previous work, and our refinement lies in invoking\namortization argument. We then show that our algorithm coupled with Chernoff\nbound argument leads to an algorithm for independent noise that is simpler and\nwith a query complexity that is both simpler and asymptotically better to one\nof Emamjomeh-Zadeh et al. [STOC 2016].\n  Our approach has a wide range of applications. First, it improves and\nsimplifies Robust Interactive Learning framework proposed by Emamjomeh-Zadeh et\nal. [NIPS 2017]. Secondly, performing analogous analysis for\n\\emph{edge-queries} (where query to edge $e$ returns its endpoint that is\ncloser to target) we actually recover (as a special case) noisy binary search\nalgorithm that is asymptotically optimal, matching the complexity of Feige et\nal. [SIAM J. Comput. 1994]. Thirdly, we improve and simplify upon existing\nalgorithm for searching of \\emph{unbounded} domains due to Aslam and Dhagat\n[STOC 1991].\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 22:49:15 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 17:31:28 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 20:17:09 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 21:27:19 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Dereniowski", "Dariusz", ""], ["Tiegel", "Stefan", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""], ["Wolleb-Graf", "Daniel", ""]]}, {"id": "1804.02081", "submitter": "Dimitrios Berberidis", "authors": "Dimitris Berberidis, Athanasios N. Nikolakopoulos, Georgios B.\n  Giannakis", "title": "Adaptive Diffusions for Scalable Learning over Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2889984", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion-based classifiers such as those relying on the Personalized\nPageRank and the Heat kernel, enjoy remarkable classification accuracy at\nmodest computational requirements. Their performance however is affected by the\nextent to which the chosen diffusion captures a typically unknown label\npropagation mechanism, that can be specific to the underlying graph, and\npotentially different for each class. The present work introduces a\ndisciplined, data-efficient approach to learning class-specific diffusion\nfunctions adapted to the underlying network topology. The novel learning\napproach leverages the notion of \"landing probabilities\" of class-specific\nrandom walks, which can be computed efficiently, thereby ensuring scalability\nto large graphs. This is supported by rigorous analysis of the properties of\nthe model as well as the proposed algorithms. Furthermore, a robust version of\nthe classifier facilitates learning even in noisy environments.\n  Classification tests on real networks demonstrate that adapting the diffusion\nfunction to the given graph and observed labels, significantly improves the\nperformance over fixed diffusions; reaching -- and many times surpassing -- the\nclassification accuracy of computationally heavier state-of-the-art competing\nmethods, that rely on node embeddings and deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:41:11 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 04:25:45 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 00:32:13 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Berberidis", "Dimitris", ""], ["Nikolakopoulos", "Athanasios N.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1804.02086", "submitter": "Babak Esmaeili", "authors": "Babak Esmaeili, Hao Wu, Sarthak Jain, Alican Bozkurt, N. Siddharth,\n  Brooks Paige, Dana H. Brooks, Jennifer Dy, Jan-Willem van de Meent", "title": "Structured Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent-variable models learn representations of high-dimensional data in\nan unsupervised manner. A number of recent efforts have focused on learning\nrepresentations that disentangle statistically independent axes of variation by\nintroducing modifications to the standard objective function. These approaches\ngenerally assume a simple diagonal Gaussian prior and as a result are not able\nto reliably disentangle discrete factors of variation. We propose a two-level\nhierarchical objective to control relative degree of statistical independence\nbetween blocks of variables and individual variables within blocks. We derive\nthis objective as a generalization of the evidence lower bound, which allows us\nto explicitly represent the trade-offs between mutual information between data\nand representation, KL divergence between representation and prior, and\ncoverage of the support of the empirical data distribution. Experiments on a\nvariety of datasets demonstrate that our objective can not only disentangle\ndiscrete variables, but that doing so also improves disentanglement of other\nvariables and, importantly, generalization even to unseen combinations of\nfactors.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 00:11:26 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 16:44:43 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 16:12:11 GMT"}, {"version": "v4", "created": "Wed, 12 Dec 2018 16:31:31 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Esmaeili", "Babak", ""], ["Wu", "Hao", ""], ["Jain", "Sarthak", ""], ["Bozkurt", "Alican", ""], ["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["Brooks", "Dana H.", ""], ["Dy", "Jennifer", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1804.02149", "submitter": "Bo Jiang", "authors": "Bo Jiang, Ming Li and Ravi Tandon", "title": "Context-aware Data Aggregation with Localized Information Privacy", "comments": "17 pages, 15 figures, To appear in the processing of the IEEE\n  Conference on Communications and Network Security, 30 May-1 June , 2018,\n  Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, localized information privacy (LIP) is proposed, as a new\nprivacy definition, which allows statistical aggregation while protecting\nusers' privacy without relying on a trusted third party. The notion of\ncontext-awareness is incorporated in LIP by the introduction of priors, which\nenables the design of privacy-preserving data aggregation with knowledge of\npriors. We show that LIP relaxes the Localized Differential Privacy (LDP)\nnotion by explicitly modeling the adversary's knowledge. However, it is\nstricter than $2\\epsilon$-LDP and $\\epsilon$-mutual information privacy. The\nincorporation of local priors allows LIP to achieve higher utility compared to\nother approaches. We then present an optimization framework for\nprivacy-preserving data aggregation, with the goal of minimizing the expected\nsquared error while satisfying the LIP privacy constraints. Utility-privacy\ntradeoffs are obtained under several models in closed-form. We then validate\nour analysis by {numerical analysis} using both synthetic and real-world data.\nResults show that our LIP mechanism provides better utility-privacy tradeoffs\nthan LDP and when the prior is not uniformly distributed, the advantage of LIP\nis even more significant.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 06:42:16 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 03:32:30 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 20:59:00 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Jiang", "Bo", ""], ["Li", "Ming", ""], ["Tandon", "Ravi", ""]]}, {"id": "1804.02181", "submitter": "Hirokazu Kameoka", "authors": "Keisuke Oyamada, Hirokazu Kameoka, Takuhiro Kaneko, Kou Tanaka,\n  Nobukatsu Hojo, Hiroyasu Ando", "title": "Generative adversarial network-based approach to signal reconstruction\n  from magnitude spectrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of reconstructing a time-domain signal\n(or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude\nspectrograms do not contain phase information, we must restore or infer phase\ninformation to reconstruct a time-domain signal. One widely used approach for\ndealing with the signal reconstruction problem was proposed by Griffin and Lim.\nThis method usually requires many iterations for the signal reconstruction\nprocess and depending on the inputs, it does not always produce high-quality\naudio signals. To overcome these shortcomings, we apply a learning-based\napproach to the signal reconstruction problem by modeling the signal\nreconstruction process using a deep neural network and training it using the\nidea of a generative adversarial network. Experimental evaluations revealed\nthat our method was able to reconstruct signals faster with higher quality than\nthe Griffin-Lim method.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 09:42:59 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Oyamada", "Keisuke", ""], ["Kameoka", "Hirokazu", ""], ["Kaneko", "Takuhiro", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""], ["Ando", "Hiroyasu", ""]]}, {"id": "1804.02204", "submitter": "Mustafa Haider", "authors": "Adnan Haider and Philip C. Woodland", "title": "Sequence Training of DNN Acoustic Models With Natural Gradient", "comments": "In Proceedings of IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:05:53 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Haider", "Adnan", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1804.02246", "submitter": "Yifan Zhang", "authors": "Peilin Zhao, Yifan Zhang, Min Wu, Steven C. H. Hoi, Mingkui Tan, and\n  Junzhou Huang", "title": "Adaptive Cost-sensitive Online Classification", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2019", "doi": "10.1109/TKDE.2018.2826011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost-Sensitive Online Classification has drawn extensive attention in recent\nyears, where the main approach is to directly online optimize two well-known\ncost-sensitive metrics: (i) weighted sum of sensitivity and specificity; (ii)\nweighted misclassification cost. However, previous existing methods only\nconsidered first-order information of data stream. It is insufficient in\npractice, since many recent studies have proved that incorporating second-order\ninformation enhances the prediction performance of classification models. Thus,\nwe propose a family of cost-sensitive online classification algorithms with\nadaptive regularization in this paper. We theoretically analyze the proposed\nalgorithms and empirically validate their effectiveness and properties in\nextensive experiments. Then, for better trade off between the performance and\nefficiency, we further introduce the sketching technique into our algorithms,\nwhich significantly accelerates the computational speed with quite slight\nperformance loss. Finally, we apply our algorithms to tackle several online\nanomaly detection tasks from real world. Promising results prove that the\nproposed algorithms are effective and efficient in solving cost-sensitive\nonline classification problems in various real-world domains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:09:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhao", "Peilin", ""], ["Zhang", "Yifan", ""], ["Wu", "Min", ""], ["Hoi", "Steven C. H.", ""], ["Tan", "Mingkui", ""], ["Huang", "Junzhou", ""]]}, {"id": "1804.02253", "submitter": "Konstantin Eckle", "authors": "Konstantin Eckle, Johannes Schmidt-Hieber", "title": "A comparison of deep networks with ReLU activation function and linear\n  spline-type methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) generate much richer function spaces than shallow\nnetworks. Since the function spaces induced by shallow networks have several\napproximation theoretic drawbacks, this explains, however, not necessarily the\nsuccess of deep networks. In this article we take another route by comparing\nthe expressive power of DNNs with ReLU activation function to piecewise linear\nspline methods. We show that MARS (multivariate adaptive regression splines) is\nimproper learnable by DNNs in the sense that for any given function that can be\nexpressed as a function in MARS with $M$ parameters there exists a multilayer\nneural network with $O(M \\log (M/\\varepsilon))$ parameters that approximates\nthis function up to sup-norm error $\\varepsilon.$ We show a similar result for\nexpansions with respect to the Faber-Schauder system. Based on this, we derive\nrisk comparison inequalities that bound the statistical risk of fitting a\nneural network by the statistical risk of spline-based methods. This shows that\ndeep networks perform better or only slightly worse than the considered spline\nmethods. We provide a constructive proof for the function approximations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:28:15 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 09:11:59 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Eckle", "Konstantin", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1804.02261", "submitter": "Jose Perea", "authors": "Firas A. Khasawneh, Elizabeth Munch, Jose A. Perea", "title": "Chatter Classification in Turning Using Machine Learning and Topological\n  Data Analysis", "comments": null, "journal-ref": null, "doi": "10.1016/j.ifacol.2018.07.222", "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatter identification and detection in machining processes has been an\nactive area of research in the past two decades. Part of the challenge in\nstudying chatter is that machining equations that describe its occurrence are\noften nonlinear delay differential equations. The majority of the available\ntools for chatter identification rely on defining a metric that captures the\ncharacteristics of chatter, and a threshold that signals its occurrence. The\ndifficulty in choosing these parameters can be somewhat alleviated by utilizing\nmachine learning techniques. However, even with a successful classification\nalgorithm, the transferability of typical machine learning methods from one\ndata set to another remains very limited. In this paper we combine supervised\nmachine learning with Topological Data Analysis (TDA) to obtain a descriptor of\nthe process which can detect chatter. The features we use are derived from the\npersistence diagram of an attractor reconstructed from the time series via\nTakens embedding. We test the approach using deterministic and stochastic\nturning models, where the stochasticity is introduced via the cutting\ncoefficient term. Our results show a 97% successful classification rate on the\ndeterministic model labeled by the stability diagram obtained using the\nspectral element method. The features gleaned from the deterministic model are\nthen utilized for characterization of chatter in a stochastic turning model\nwhere there are very limited analysis methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 18:13:07 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Khasawneh", "Firas A.", ""], ["Munch", "Elizabeth", ""], ["Perea", "Jose A.", ""]]}, {"id": "1804.02339", "submitter": "Fabian Pedregosa", "authors": "Fabian Pedregosa, Gauthier Gidel", "title": "Adaptive Three Operator Splitting", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:4082-4091, 2018", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose and analyze an adaptive step-size variant of the Davis-Yin three\noperator splitting. This method can solve optimization problems composed by a\nsum of a smooth term for which we have access to its gradient and an arbitrary\nnumber of potentially non-smooth terms for which we have access to their\nproximal operator. The proposed method sets the step-size based on local\ninformation of the objective --hence allowing for larger step-sizes--, only\nrequires two extra function evaluations per iteration and does not depend on\nany step-size hyperparameter besides an initial estimate. We provide an\niteration complexity analysis that matches the best known results for the\nnon-adaptive variant: sublinear convergence for general convex functions and\nlinear convergence under strong convexity of the smooth term and smoothness of\none of the proximal terms. Finally, an empirical comparison with related\nmethods on 6 different problems illustrates the computational advantage of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:09:36 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 21:53:30 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 20:39:58 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Pedregosa", "Fabian", ""], ["Gidel", "Gauthier", ""]]}, {"id": "1804.02341", "submitter": "Edward Choi", "authors": "Edward Choi, Angeliki Lazaridou, Nando de Freitas", "title": "Compositional Obverter Communication Learning From Raw Visual Input", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:12:51 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Choi", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["de Freitas", "Nando", ""]]}, {"id": "1804.02370", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chris Ding", "title": "Minimal Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machine (SVM) is an efficient classification approach, which\nfinds a hyperplane to separate data from different classes. This hyperplane is\ndetermined by support vectors. In existing SVM formulations, the objective\nfunction uses L2 norm or L1 norm on slack variables. The number of support\nvectors is a measure of generalization errors. In this work, we propose a\nMinimal SVM, which uses L0.5 norm on slack variables. The result model further\nreduces the number of support vectors and increases the classification\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 17:44:01 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Zheng", "Shuai", ""], ["Ding", "Chris", ""]]}, {"id": "1804.02386", "submitter": "Sina Dabiri", "authors": "Sina Dabiri, Kevin Heaslip", "title": "Inferring transportation modes from GPS trajectories using a\n  convolutional neural network", "comments": "12 pages, 3 figures, 7 tables, Transportation Research Part C:\n  Emerging Technologies", "journal-ref": "Transportation Research Part C: Emerging Technologies 86 (2018):\n  360-371", "doi": "10.1016/j.trc.2017.11.021", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Identifying the distribution of users' transportation modes is an essential\npart of travel demand analysis and transportation planning. With the advent of\nubiquitous GPS-enabled devices (e.g., a smartphone), a cost-effective approach\nfor inferring commuters' mobility mode(s) is to leverage their GPS\ntrajectories. A majority of studies have proposed mode inference models based\non hand-crafted features and traditional machine learning algorithms. However,\nmanual features engender some major drawbacks including vulnerability to\ntraffic and environmental conditions as well as possessing human's bias in\ncreating efficient features. One way to overcome these issues is by utilizing\nConvolutional Neural Network (CNN) schemes that are capable of automatically\ndriving high-level features from the raw input. Accordingly, in this paper, we\ntake advantage of CNN architectures so as to predict travel modes based on only\nraw GPS trajectories, where the modes are labeled as walk, bike, bus, driving,\nand train. Our key contribution is designing the layout of the CNN's input\nlayer in such a way that not only is adaptable with the CNN schemes but\nrepresents fundamental motion characteristics of a moving object including\nspeed, acceleration, jerk, and bearing rate. Furthermore, we ameliorate the\nquality of GPS logs through several data preprocessing steps. Using the clean\ninput layer, a variety of CNN configurations are evaluated to achieve the best\nCNN architecture. The highest accuracy of 84.8% has been achieved through the\nensemble of the best CNN configuration. In this research, we contrast our\nmethodology with traditional machine learning algorithms as well as the seminal\nand most related studies to demonstrate the superiority of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 18:26:12 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Dabiri", "Sina", ""], ["Heaslip", "Kevin", ""]]}, {"id": "1804.02395", "submitter": "Krzysztof Choromanski", "authors": "Krzysztof Choromanski, Mark Rowland, Vikas Sindhwani, Richard E.\n  Turner, Adrian Weller", "title": "Structured Evolution with Compact Architectures for Scalable Policy\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method of blackbox optimization via gradient approximation\nwith the use of structured random orthogonal matrices, providing more accurate\nestimators than baselines and with provable theoretical guarantees. We show\nthat this algorithm can be successfully applied to learn better quality compact\npolicies than those using standard gradient estimation techniques. The compact\npolicies we learn have several advantages over unstructured ones, including\nfaster training algorithms and faster inference. These benefits are important\nwhen the policy is deployed on real hardware with limited resources. Further,\ncompact policies provide more scalable architectures for derivative-free\noptimization (DFO) in high-dimensional spaces. We show that most robotics tasks\nfrom the OpenAI Gym can be solved using neural networks with less than 300\nparameters, with almost linear time complexity of the inference phase, with up\nto 13x fewer parameters relative to the Evolution Strategies (ES) algorithm\nintroduced by Salimans et al. (2017). We do not need heuristics such as fitness\nshaping to learn good quality policies, resulting in a simple and theoretically\nmotivated training mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 15:25:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 14:52:29 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Rowland", "Mark", ""], ["Sindhwani", "Vikas", ""], ["Turner", "Richard E.", ""], ["Weller", "Adrian", ""]]}, {"id": "1804.02398", "submitter": "Jacob Biamonte", "authors": "Andrey Kardashin and Alexey Uvarov and Jacob Biamonte", "title": "Quantum Machine Learning Tensor Network States", "comments": "6 pages, 2 figures, numerics added", "journal-ref": "Frontiers in Physics 8: 586374 (2021)", "doi": "10.3389/fphy.2020.586374", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor network algorithms seek to minimize correlations to compress the\nclassical data representing quantum states. Tensor network algorithms and\nsimilar tools---called tensor network methods---form the backbone of modern\nnumerical methods used to simulate many-body physics and have a further range\nof applications in machine learning. Finding and contracting tensor network\nstates is a computational task which quantum computers might be used to\naccelerate. We present a quantum algorithm which returns a classical\ndescription of a rank-$r$ tensor network state satisfying an area law and\napproximating an eigenvector given black-box access to a unitary matrix. Our\nwork creates a bridge between several contemporary approaches, including tensor\nnetworks, the variational quantum eigensolver (VQE), quantum approximate\noptimization (QAOA), and quantum computation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 18:00:00 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 10:12:59 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 10:21:24 GMT"}, {"version": "v4", "created": "Sat, 12 Sep 2020 11:29:04 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Kardashin", "Andrey", ""], ["Uvarov", "Alexey", ""], ["Biamonte", "Jacob", ""]]}, {"id": "1804.02411", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Xiaojun Zhao, Edgar A. Bernal, David J. Wales", "title": "The Loss Surface of XOR Artificial Neural Networks", "comments": "19 pages, 6 figures. Submitted to journal in Oct, 2017", "journal-ref": "Phys. Rev. E 97, 052307 (2018)", "doi": "10.1103/PhysRevE.97.052307", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training an artificial neural network involves an optimization process over\nthe landscape defined by the cost (loss) as a function of the network\nparameters. We explore these landscapes using optimisation tools developed for\npotential energy landscapes in molecular science. The number of local minima\nand transition states (saddle points of index one), as well as the ratio of\ntransition states to minima, grow rapidly with the number of nodes in the\nnetwork. There is also a strong dependence on the regularisation parameter,\nwith the landscape becoming more convex (fewer minima) as the regularisation\nterm increases. We demonstrate that in our formulation, stationary points for\nnetworks with $N_h$ hidden nodes, including the minimal network required to fit\nthe XOR data, are also stationary points for networks with $N_{h} +1$ hidden\nnodes when all the weights involving the additional nodes are zero. Hence,\nsmaller networks optimized to train the XOR data are embedded in the landscapes\nof larger networks. Our results clarify certain aspects of the classification\nand sensitivity (to perturbations in the input data) of minima and saddle\npoints for this system, and may provide insight into dropout and network\ncompression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 18:11:23 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mehta", "Dhagash", ""], ["Zhao", "Xiaojun", ""], ["Bernal", "Edgar A.", ""], ["Wales", "David J.", ""]]}, {"id": "1804.02464", "submitter": "Thomas Miconi", "authors": "Thomas Miconi, Jeff Clune, Kenneth O. Stanley", "title": "Differentiable plasticity: training plastic neural networks with\n  backpropagation", "comments": "Presented at ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML2018), Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build agents that keep learning from experience, quickly and\nefficiently, after their initial training? Here we take inspiration from the\nmain mechanism of learning in biological brains: synaptic plasticity, carefully\ntuned by evolution to produce efficient lifelong learning. We show that\nplasticity, just like connection weights, can be optimized by gradient descent\nin large (millions of parameters) recurrent networks with Hebbian plastic\nconnections. First, recurrent plastic networks with more than two million\nparameters can be trained to memorize and reconstruct sets of novel,\nhigh-dimensional 1000+ pixels natural images not seen during training.\nCrucially, traditional non-plastic recurrent networks fail to solve this task.\nFurthermore, trained plastic networks can also solve generic meta-learning\ntasks such as the Omniglot task, with competitive results and little parameter\noverhead. Finally, in reinforcement learning settings, plastic networks\noutperform a non-plastic equivalent in a maze exploration task. We conclude\nthat differentiable plasticity may provide a powerful novel approach to the\nlearning-to-learn problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 21:43:13 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 00:50:53 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:55:11 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Miconi", "Thomas", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1804.02465", "submitter": "Shuai Huang", "authors": "Shuai Huang, Ivan Dokmani\\'c", "title": "Reconstructing Point Sets from Distance Distributions", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, Vol. 69, 1181-1127, Mar.\n  2021", "doi": "10.1109/TSP.2021.3063458", "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of reconstructing a set of points on a line or a loop\nfrom their unassigned noisy pairwise distances. When the points lie on a line,\nthe problem is known as the turnpike; when they are on a loop, it is known as\nthe beltway. We approximate the problem by discretizing the domain and\nrepresenting the $N$ points via an $N$-hot encoding, which is a density\nsupported on the discretized domain. We show how the distance distribution is\nthen simply a collection of quadratic functionals of this density and propose\nto recover the point locations so that the estimated distance distribution\nmatches the measured distance distribution. This can be cast as a constrained\nnonconvex optimization problem which we solve using projected gradient descent\nwith a suitable spectral initializer. We derive conditions under which the\nproposed distance distribution matching approach locally converges to a global\noptimizer at a linear rate. Compared to the conventional backtracking approach,\nour method jointly reconstructs all the point locations and is robust to noise\nin the measurements. We substantiate these claims with state-of-the-art\nperformance across a number of numerical experiments. Our method is the first\npractical approach to solve the large-scale noisy beltway problem where the\npoints lie on a loop.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 21:44:54 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 17:07:11 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 04:11:32 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 02:13:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Huang", "Shuai", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "1804.02476", "submitter": "Alex Graves", "authors": "Alex Graves, Jacob Menick, Aaron van den Oord", "title": "Associative Compression Networks for Representation Learning", "comments": "Revised to clarify difference between ACN and IID loss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Associative Compression Networks (ACNs), a new\nframework for variational autoencoding with neural networks. The system differs\nfrom existing variational autoencoders (VAEs) in that the prior distribution\nused to model each code is conditioned on a similar code from the dataset. In\ncompression terms this equates to sequentially transmitting the dataset using\nan ordering determined by proximity in latent space. Since the prior need only\naccount for local, rather than global variations in the latent space, the\ncoding cost is greatly reduced, leading to rich, informative codes. Crucially,\nthe codes remain informative when powerful, autoregressive decoders are used,\nwhich we argue is fundamentally difficult with normal VAEs. Experimental\nresults on MNIST, CIFAR-10, ImageNet and CelebA show that ACNs discover\nhigh-level latent features such as object class, writing style, pose and facial\nexpression, which can be used to cluster and classify the data, as well as to\ngenerate diverse and convincing samples. We conclude that ACNs are a promising\nnew direction for representation learning: one that steps away from IID\nmodelling, and towards learning a structured description of the dataset as a\nwhole.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:04 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 16:20:25 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Graves", "Alex", ""], ["Menick", "Jacob", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1804.02477", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli,\n  Swarat Chaudhuri", "title": "Programmatically Interpretable Reinforcement Learning", "comments": "Published at The 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "PMLR 80:5045-5054", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning framework, called Programmatically\nInterpretable Reinforcement Learning (PIRL), that is designed to generate\ninterpretable and verifiable agent policies. Unlike the popular Deep\nReinforcement Learning (DRL) paradigm, which represents policies by neural\nnetworks, PIRL represents policies using a high-level, domain-specific\nprogramming language. Such programmatic policies have the benefits of being\nmore easily interpreted than neural networks, and being amenable to\nverification by symbolic methods. We propose a new method, called Neurally\nDirected Program Search (NDPS), for solving the challenging nonsmooth\noptimization problem of finding a programmatic policy with maximal reward. NDPS\nworks by first learning a neural policy network using DRL, and then performing\na local search over programmatic policies that seeks to minimize a distance\nfrom this neural \"oracle\". We evaluate NDPS on the task of learning to drive a\nsimulated car in the TORCS car-racing environment. We demonstrate that NDPS is\nable to discover human-readable policies that pass some significant performance\nbars. We also show that PIRL policies can have smoother trajectories, and can\nbe more easily transferred to environments not encountered during training,\nthan corresponding policies discovered by DRL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 02:27:26 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 09:09:46 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Verma", "Abhinav", ""], ["Murali", "Vijayaraghavan", ""], ["Singh", "Rishabh", ""], ["Kohli", "Pushmeet", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1804.02484", "submitter": "Andrea Rocchetto", "authors": "Alessandro Rudi, Leonard Wossnig, Carlo Ciliberto, Andrea Rocchetto,\n  Massimiliano Pontil, Simone Severini", "title": "Approximating Hamiltonian dynamics with the Nystr\\\"om method", "comments": "v2: 22 pages, fixed typos in Eq.27 and 28 + other minor changes to\n  the presentation of the results; v3 final version accepted to Quantum; v4\n  DOIs added in order to comply with Quantum requirements", "journal-ref": "Quantum 4, 234 (2020)", "doi": "10.22331/q-2020-02-20-234", "report-no": null, "categories": "quant-ph cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating the time-evolution of quantum mechanical systems is BQP-hard and\nexpected to be one of the foremost applications of quantum computers. We\nconsider classical algorithms for the approximation of Hamiltonian dynamics\nusing subsampling methods from randomized numerical linear algebra. We derive a\nsimulation technique whose runtime scales polynomially in the number of qubits\nand the Frobenius norm of the Hamiltonian. As an immediate application, we show\nthat sample based quantum simulation, a type of evolution where the Hamiltonian\nis a density matrix, can be efficiently classically simulated under specific\nstructural conditions. Our main technical contribution is a randomized\nalgorithm for approximating Hermitian matrix exponentials. The proof leverages\na low-rank, symmetric approximation via the Nystr\\\"om method. Our results\nsuggest that under strong sampling assumptions there exist classical\npoly-logarithmic time simulations of quantum computations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 23:58:30 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 10:32:34 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 16:52:23 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 20:30:19 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Rudi", "Alessandro", ""], ["Wossnig", "Leonard", ""], ["Ciliberto", "Carlo", ""], ["Rocchetto", "Andrea", ""], ["Pontil", "Massimiliano", ""], ["Severini", "Simone", ""]]}, {"id": "1804.02485", "submitter": "Alex Lamb", "authors": "Alex Lamb, Jonathan Binas, Anirudh Goyal, Dmitriy Serdyuk, Sandeep\n  Subramanian, Ioannis Mitliagkas, Yoshua Bengio", "title": "Fortified Networks: Improving the Robustness of Deep Networks by\n  Modeling the Manifold of Hidden Representations", "comments": "Under Review ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have achieved impressive results across a variety of important\ntasks. However a known weakness is a failure to perform well when evaluated on\ndata which differ from the training distribution, even if these differences are\nvery small, as is the case with adversarial examples. We propose Fortified\nNetworks, a simple transformation of existing networks, which fortifies the\nhidden layers in a deep network by identifying when the hidden states are off\nof the data manifold, and maps these hidden states back to parts of the data\nmanifold where the network performs well. Our principal contribution is to show\nthat fortifying these hidden states improves the robustness of deep networks\nand our experiments (i) demonstrate improved robustness to standard adversarial\nattacks in both black-box and white-box threat models; (ii) suggest that our\nimprovements are not primarily due to the gradient masking problem and (iii)\nshow the advantage of doing this fortification in the hidden layers instead of\nthe input space.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 00:11:05 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Lamb", "Alex", ""], ["Binas", "Jonathan", ""], ["Goyal", "Anirudh", ""], ["Serdyuk", "Dmitriy", ""], ["Subramanian", "Sandeep", ""], ["Mitliagkas", "Ioannis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.02491", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Ethem Alpayd{\\i}n", "title": "Continuously Constructive Deep Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, deep learning algorithms update the network weights whereas\nthe network architecture is chosen manually, using a process of trial and\nerror. In this work, we propose two novel approaches that automatically update\nthe network structure while also learning its weights. The novelty of our\napproach lies in our parameterization where the depth, or additional\ncomplexity, is encapsulated continuously in the parameter space through control\nparameters that add additional complexity. We propose two methods: In tunnel\nnetworks, this selection is done at the level of a hidden unit, and in budding\nperceptrons, this is done at the level of a network layer; updating this\ncontrol parameter introduces either another hidden unit or another hidden\nlayer. We show the effectiveness of our methods on the synthetic two-spirals\ndata and on two real data sets of MNIST and MIRFLICKR, where we see that our\nproposed methods, with the same set of hyperparameters, can correctly adjust\nthe network complexity to the task complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 02:09:16 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1804.02527", "submitter": "Shixia Liu", "authors": "Jaegul Choo and Shixia Liu", "title": "Visual Analytics for Explainable Deep Learning", "comments": "IEEE Computer Graphics and Applications, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been advancing the state of the art in artificial\nintelligence to a new level, and humans rely on artificial intelligence\ntechniques more than ever. However, even with such unprecedented advancements,\nthe lack of explanation regarding the decisions made by deep learning models\nand absence of control over their internal processes act as major drawbacks in\ncritical decision-making processes, such as precision medicine and law\nenforcement. In response, efforts are being made to make deep learning\ninterpretable and controllable by humans. In this paper, we review visual\nanalytics, information visualization, and machine learning perspectives\nrelevant to this aim, and discuss potential challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:52:04 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Choo", "Jaegul", ""], ["Liu", "Shixia", ""]]}, {"id": "1804.02528", "submitter": "Iraklis Klampanos", "authors": "Iraklis A. Klampanos, Athanasios Davvetas, Antonis Koukourikos,\n  Vangelis Karkaletsis", "title": "ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:56:29 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 09:04:59 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Klampanos", "Iraklis A.", ""], ["Davvetas", "Athanasios", ""], ["Koukourikos", "Antonis", ""], ["Karkaletsis", "Vangelis", ""]]}, {"id": "1804.02541", "submitter": "Anil Bas", "authors": "Anil Bas, William A. P. Smith", "title": "Statistical transformer networks: learning shape and appearance models\n  via self supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise Spatial Transformer Networks (STN) by replacing the parametric\ntransformation of a fixed, regular sampling grid with a deformable, statistical\nshape model which is itself learnt. We call this a Statistical Transformer\nNetwork (StaTN). By training a network containing a StaTN end-to-end for a\nparticular task, the network learns the optimal nonrigid alignment of the input\ndata for the task. Moreover, the statistical shape model is learnt with no\ndirect supervision (such as landmarks) and can be reused for other tasks.\nBesides training for a specific task, we also show that a StaTN can learn a\nshape model using generic loss functions. This includes a loss inspired by the\nminimum description length principle in which an appearance model is also\nlearnt from scratch. In this configuration, our model learns an active\nappearance model and a means to fit the model from scratch with no supervision\nat all, even identity labels.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 10:18:15 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bas", "Anil", ""], ["Smith", "William A. P.", ""]]}, {"id": "1804.02543", "submitter": "Egor Illarionov", "authors": "Egor Illarionov and Roman Khudorozhkov", "title": "Not quite unreasonable effectiveness of machine learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine learning algorithms demonstrate close to absolute\nperformance in selected challenges. We provide arguments that the reason can be\nin low variability of the samples and high effectiveness in learning typical\npatterns. Due to this fact, standard performance metrics do not reveal model\ncapacity and new metrics are required for the better understanding of\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 10:24:04 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Illarionov", "Egor", ""], ["Khudorozhkov", "Roman", ""]]}, {"id": "1804.02617", "submitter": "Utkarsh Contractor", "authors": "Mehrad Moradshahi and Utkarsh Contractor", "title": "Language Modeling with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been promising in the field of\nimage generation, however, they have been hard to train for language\ngeneration. GANs were originally designed to output differentiable values, so\ndiscrete language generation is challenging for them which causes high levels\nof instability in training GANs. Consequently, past work has resorted to\npre-training with maximum-likelihood or training GANs without pre-training with\na WGAN objective with a gradient penalty. In this study, we present a\ncomparison of those approaches. Furthermore, we present the results of some\nexperiments that indicate better training and convergence of Wasserstein GANs\n(WGANs) when a weaker regularization term is enforcing the Lipschitz\nconstraint.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 03:18:13 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Moradshahi", "Mehrad", ""], ["Contractor", "Utkarsh", ""]]}, {"id": "1804.02665", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Environmental Sound Recognition using Masked Conditional Neural Networks", "comments": "Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Neural Network,\n  DNN, Conditional Neural Network, CLNN, Masked Conditional Neural Net-work,\n  MCLNN, Environmental Sound Recognition, ESR, Advanced Data Mining and\n  Applications (ADMA) Year: 2017", "journal-ref": null, "doi": "10.1007/978-3-319-69179-4_26", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based architectures used for sound recognition are usually\nadapted from other application domains, which may not harness sound related\nproperties. The ConditionaL Neural Network (CLNN) is designed to consider the\nrelational properties across frames in a temporal signal, and its extension the\nMasked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within\nthe network, which enforces the network to learn in frequency bands rather than\nbins. Additionally, it automates the exploration of different feature\ncombinations analogous to handcrafting the optimum combination of features for\na recognition task. We applied the MCLNN to the environmental sounds of the\nESC-10 dataset. The MCLNN achieved competitive accuracies compared to\nstate-of-the-art convolutional neural networks and hand-crafted attempts.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 10:22:02 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 14:07:51 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1804.02668", "submitter": "Shahar Harel", "authors": "Shahar Harel, Kira Radinsky", "title": "Accelerating Prototype-Based Drug Discovery using Conditional Diversity\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3219819.3219882", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a new drug is a lengthy and expensive process. As the space of\npotential molecules is very large (10^23-10^60), a common technique during drug\ndiscovery is to start from a molecule which already has some of the desired\nproperties. An interdisciplinary team of scientists generates hypothesis about\nthe required changes to the prototype. In this work, we develop an algorithmic\nunsupervised-approach that automatically generates potential drug molecules\ngiven a prototype drug. We show that the molecules generated by the system are\nvalid molecules and significantly different from the prototype drug. Out of the\ncompounds generated by the system, we identified 35 FDA-approved drugs. As an\nexample, our system generated Isoniazid - one of the main drugs for\nTuberculosis. The system is currently being deployed for use in collaboration\nwith pharmaceutical companies to further analyze the additional generated\nmolecules.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 11:08:08 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Harel", "Shahar", ""], ["Radinsky", "Kira", ""]]}, {"id": "1804.02693", "submitter": "Hassan Jaleel", "authors": "Hassan Jaleel and Jeff S. Shamma", "title": "Path to Stochastic Stability: Comparative Analysis of Stochastic\n  Learning Dynamics in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic stability is a popular solution concept for stochastic learning\ndynamics in games. However, a critical limitation of this solution concept is\nits inability to distinguish between different learning rules that lead to the\nsame steady-state behavior. We address this limitation for the first time and\ndevelop a framework for the comparative analysis of stochastic learning\ndynamics with different update rules but same steady-state behavior. We present\nthe framework in the context of two learning dynamics: Log-Linear Learning\n(LLL) and Metropolis Learning (ML). Although both of these dynamics have the\nsame stochastically stable states, LLL and ML correspond to different\nbehavioral models for decision making. Moreover, we demonstrate through an\nexample setup of sensor coverage game that for each of these dynamics, the\npaths to stochastically stable states exhibit distinctive behaviors. Therefore,\nwe propose multiple criteria to analyze and quantify the differences in the\nshort and medium run behavior of stochastic learning dynamics. We derive and\ncompare upper bounds on the expected hitting time to the set of Nash equilibria\nfor both LLL and ML. For the medium to long-run behavior, we identify a set of\ntools from the theory of perturbed Markov chains that result in a hierarchical\ndecomposition of the state space into collections of states called cycles. We\ncompare LLL and ML based on the proposed criteria and develop invaluable\ninsights into the comparative behavior of the two dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:07:46 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Jaleel", "Hassan", ""], ["Shamma", "Jeff S.", ""]]}, {"id": "1804.02698", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Daisuke Igaue", "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem", "comments": "6pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624799", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:39:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Igaue", "Daisuke", ""]]}, {"id": "1804.02704", "submitter": "Fabrizio Maria Maggi", "authors": "Volodymyr Leno and Abel Armas-Cervantes and Marlon Dumas and Marcello\n  La Rosa and Fabrizio M. Maggi", "title": "Discovering Process Maps from Event Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated process discovery is a class of process mining methods that allow\nanalysts to extract business process models from event logs. Traditional\nprocess discovery methods extract process models from a snapshot of an event\nlog stored in its entirety. In some scenarios, however, events keep coming with\na high arrival rate to the extent that it is impractical to store the entire\nevent log and to continuously re-discover a process model from scratch. Such\nscenarios require online process discovery approaches. Given an event stream\nproduced by the execution of a business process, the goal of an online process\ndiscovery method is to maintain a continuously updated model of the process\nwith a bounded amount of memory while at the same time achieving similar\naccuracy as offline methods. However, existing online discovery approaches\nrequire relatively large amounts of memory to achieve levels of accuracy\ncomparable to that of offline methods. Therefore, this paper proposes an\napproach that addresses this limitation by mapping the problem of online\nprocess discovery to that of cache memory management, and applying well-known\ncache replacement policies to the problem of online process discovery. The\napproach has been implemented in .NET, experimentally integrated with the Minit\nprocess mining tool and comparatively evaluated against an existing baseline\nusing real-life datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 15:23:52 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Leno", "Volodymyr", ""], ["Armas-Cervantes", "Abel", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio M.", ""]]}, {"id": "1804.02717", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Pieter Abbeel, Sergey Levine, Michiel van de Panne", "title": "DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based\n  Character Skills", "comments": null, "journal-ref": null, "doi": "10.1145/3197517.3201311", "report-no": null, "categories": "cs.GR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal in character animation is to combine data-driven\nspecification of behavior with a system that can execute a similar behavior in\na physical simulation, thus enabling realistic responses to perturbations and\nenvironmental variation. We show that well-known reinforcement learning (RL)\nmethods can be adapted to learn robust control policies capable of imitating a\nbroad range of example motion clips, while also learning complex recoveries,\nadapting to changes in morphology, and accomplishing user-specified goals. Our\nmethod handles keyframed motions, highly-dynamic actions such as\nmotion-captured flips and spins, and retargeted motions. By combining a\nmotion-imitation objective with a task objective, we can train characters that\nreact intelligently in interactive settings, e.g., by walking in a desired\ndirection or throwing a ball at a user-specified target. This approach thus\ncombines the convenience and motion quality of using motion clips to define the\ndesired style and appearance, with the flexibility and generality afforded by\nRL methods and physics-based animation. We further explore a number of methods\nfor integrating multiple clips into the learning process to develop\nmulti-skilled agents capable of performing a rich repertoire of diverse skills.\nWe demonstrate results using multiple characters (human, Atlas robot, bipedal\ndinosaur, dragon) and a large variety of skills, including locomotion,\nacrobatics, and martial arts.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 17:04:58 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 20:48:52 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 03:44:10 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Peng", "Xue Bin", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1804.02744", "submitter": "Sida Liu", "authors": "Sida Liu, Adrian Barbu", "title": "Unsupervised Learning of GMM with a Uniform Background Component", "comments": "36 pages, 16 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Mixture Models are one of the most studied and mature models in\nunsupervised learning. However, outliers are often present in the data and\ncould influence the cluster estimation. In this paper, we study a new model\nthat assumes that data comes from a mixture of a number of Gaussians as well as\na uniform ``background'' component assumed to contain outliers and other\nnon-interesting observations. We develop a novel method based on robust loss\nminimization that performs well in clustering such GMM with a uniform\nbackground. We give theoretical guarantees for our clustering algorithm to\nobtain best clustering results with high probability. Besides, we show that the\nresult of our algorithm does not depend on initialization or local optima, and\nthe parameter tuning is an easy task. By numeric simulations, we demonstrate\nthat our algorithm enjoys high accuracy and achieves the best clustering\nresults given a large enough sample size. Finally, experimental comparisons\nwith typical clustering methods on real datasets witness the potential of our\nalgorithm in real applications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 19:27:39 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 14:42:25 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 00:19:16 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 19:15:55 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Sida", ""], ["Barbu", "Adrian", ""]]}, {"id": "1804.02747", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt", "title": "Fast Conditional Independence Test for Vector Variables with Large\n  Sample Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate the Fast (conditional) Independence Test (FIT) -- a\nnonparametric conditional independence test. The test is based on the idea that\nwhen $P(X \\mid Y, Z) = P(X \\mid Y)$, $Z$ is not useful as a feature to predict\n$X$, as long as $Y$ is also a regressor. On the contrary, if $P(X \\mid Y, Z)\n\\neq P(X \\mid Y)$, $Z$ might improve prediction results. FIT applies to\nthousand-dimensional random variables with a hundred thousand samples in a\nfraction of the time required by alternative methods. We provide an extensive\nevaluation that compares FIT to six extant nonparametric independence tests.\nThe evaluation shows that FIT has low probability of making both Type I and\nType II errors compared to other tests, especially as the number of available\nsamples grows. Our implementation of FIT is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 20:03:07 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Perona", "Pietro", ""], ["Eberhardt", "Frederick", ""]]}, {"id": "1804.02756", "submitter": "Nikita Puchkin", "authors": "Nikita Puchkin and Vladimir Spokoiny", "title": "An adaptive multiclass nearest neighbor classifier", "comments": "Accepted in ESAIM: Probability & Statistics. The original publication\n  is available at www.esaim-ps.org", "journal-ref": null, "doi": "10.1051/ps/2019021", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of multiclass classification, where the training sample\n$S_n = \\{(X_i, Y_i)\\}_{i=1}^n$ is generated from the model $\\mathbb P(Y = m | X\n= x) = \\eta_m(x)$, $1 \\leq m \\leq M$, and $\\eta_1(x), \\dots, \\eta_M(x)$ are\nunknown $\\alpha$-Holder continuous functions.Given a test point $X$, our goal\nis to predict its label. A widely used $\\mathsf k$-nearest-neighbors classifier\nconstructs estimates of $\\eta_1(X), \\dots, \\eta_M(X)$ and uses a plug-in rule\nfor the prediction. However, it requires a proper choice of the smoothing\nparameter $\\mathsf k$, which may become tricky in some situations. In our\nsolution, we fix several integers $n_1, \\dots, n_K$, compute corresponding\n$n_k$-nearest-neighbor estimates for each $m$ and each $n_k$ and apply an\naggregation procedure. We study an algorithm, which constructs a convex\ncombination of these estimates such that the aggregated estimate behaves\napproximately as well as an oracle choice. We also provide a non-asymptotic\nanalysis of the procedure, prove its adaptation to the unknown smoothness\nparameter $\\alpha$ and to the margin and establish rates of convergence under\nmild assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 21:07:46 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 12:57:43 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 09:38:07 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 20:57:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Puchkin", "Nikita", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1804.02763", "submitter": "Dabal Pedamonti", "authors": "Dabal Pedamonti", "title": "Comparison of non-linear activation functions for deep neural networks\n  on MNIST classification task", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activation functions play a key role in neural networks so it becomes\nfundamental to understand their advantages and disadvantages in order to\nachieve better performances. This paper will first introduce common types of\nnon linear activation functions that are alternative to the well known sigmoid\nfunction and then evaluate their characteristics. Moreover deeper neural\nnetworks will be analysed because they positively influence the final\nperformances compared to shallower networks. They also strictly depend on the\nweight initialisation hence the effect of drawing weights from Gaussian and\nuniform distribution will be analysed making particular attention on how the\nnumber of incoming and outgoing connection to a node influence the whole\nnetwork.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 22:16:36 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Pedamonti", "Dabal", ""]]}, {"id": "1804.02772", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Cengiz \\\"Oztireli, Stephan Mandt, Giampiero Salvi", "title": "Active Mini-Batch Sampling using Repulsive Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence speed of stochastic gradient descent (SGD) can be improved by\nactively selecting mini-batches. We explore sampling schemes where similar data\npoints are less likely to be selected in the same mini-batch. In particular, we\nprove that such repulsive sampling schemes lowers the variance of the gradient\nestimator. This generalizes recent work on using Determinantal Point Processes\n(DPPs) for mini-batch diversification (Zhang et al., 2017) to the broader class\nof repulsive point processes. We first show that the phenomenon of variance\nreduction by diversified sampling generalizes in particular to non-stationary\npoint processes. We then show that other point processes may be computationally\nmuch more efficient than DPPs. In particular, we propose and investigate\nPoisson Disk sampling---frequently encountered in the computer graphics\ncommunity---for this task. We show empirically that our approach improves over\nstandard SGD both in terms of convergence speed as well as final model\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 22:48:20 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 15:12:20 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Zhang", "Cheng", ""], ["\u00d6ztireli", "Cengiz", ""], ["Mandt", "Stephan", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1804.02800", "submitter": "Sourya Basu", "authors": "Sourya Basu and Lav R. Varshney", "title": "Universal and Succinct Source Coding of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown incredible performance for inference tasks in\na variety of domains. Unfortunately, most current deep networks are enormous\ncloud-based structures that require significant storage space, which limits\nscaling of deep learning as a service (DLaaS) and use for on-device\nintelligence. This paper is concerned with finding universal lossless\ncompressed representations of deep feedforward networks with synaptic weights\ndrawn from discrete sets, and directly performing inference without full\ndecompression. The basic insight that allows less rate than naive approaches is\nrecognizing that the bipartite graph layers of feedforward networks have a kind\nof permutation invariance to the labeling of nodes, in terms of inferential\noperation. We provide efficient algorithms to dissipate this irrelevant\nuncertainty and then use arithmetic coding to nearly achieve the entropy bound\nin a universal manner. We also provide experimental results of our approach on\nseveral standard datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 03:01:41 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 03:56:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Basu", "Sourya", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1804.02808", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, Sergey Levine", "title": "Latent Space Policies for Hierarchical Reinforcement Learning", "comments": "ICML 2018; Videos: https://sites.google.com/view/latent-space-deep-rl\n  Code: https://github.com/haarnoja/sac", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning hierarchical deep neural network policies\nfor reinforcement learning. In contrast to methods that explicitly restrict or\ncripple lower layers of a hierarchy to force them to use higher-level\nmodulating signals, each layer in our framework is trained to directly solve\nthe task, but acquires a range of diverse strategies via a maximum entropy\nreinforcement learning objective. Each layer is also augmented with latent\nrandom variables, which are sampled from a prior distribution during the\ntraining of that layer. The maximum entropy objective causes these latent\nvariables to be incorporated into the layer's policy, and the higher level\nlayer can directly control the behavior of the lower layer through this latent\nspace. Furthermore, by constraining the mapping from latent variables to\nactions to be invertible, higher layers retain full expressivity: neither the\nhigher layers nor the lower layers are constrained in their behavior. Our\nexperimental evaluation demonstrates that we can improve on the performance of\nsingle-layer policies on standard benchmark tasks simply by adding additional\nlayers, and that our method can solve more complex sparse-reward tasks by\nlearning higher-level policies on top of high-entropy skills optimized for\nsimple low-level objectives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:00:30 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 19:24:16 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Hartikainen", "Kristian", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1804.02813", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Kosuke Tanabe, Toshiyuki Yamashita", "title": "An Adaptive Learning Method of Personality Trait Based Mood in Mental\n  State Transition Network by Recurrent Neural Network", "comments": "6 pages, 9 figures, Proc. of IEEE 7th International Workshop on\n  Computational Intelligence and Applications (IWCIA2014)", "journal-ref": null, "doi": "10.1109/IWCIA.2014.6988081", "report-no": null, "categories": "cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental State Transition Network (MSTN) is a basic concept of approximating to\nhuman psychological and mental responses. A stimulus calculated by Emotion\nGenerating Calculations (EGC) method can cause the transition of mood from an\nemotional state to others. In this paper, the agent can interact with human to\nrealize smooth communication by an adaptive learning method of the user's\npersonality trait based mood. The learning method consists of the profit\nsharing (PS) method and the recurrent neural network (RNN). An emotion for\nsensor inputs to MSTN is calculated by EGC and the variance of emotion leads to\nthe change of mental state, and then the sequence of states forms an episode.\nIn order to learn the tendency of personality trait effectively, the\nineffective rules should be removed from the episode. PS method finds out a\ndetour in episode and should be deleted. Furthermore, RNN works to realize the\nvariance of user's mood. Some experimental results were shown the success of\nrepresenting a various human's delicate emotion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:41:27 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tanabe", "Kosuke", ""], ["Yamashita", "Toshiyuki", ""]]}, {"id": "1804.02884", "submitter": "Duc Thien Nguyen", "authors": "Duc Thien Nguyen and Akshat Kumar and Hoong Chuin Lau", "title": "Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 09:45:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Nguyen", "Duc Thien", ""], ["Kumar", "Akshat", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1804.02948", "submitter": "Jochen Cremer", "authors": "Jochen L. Cremer, Ioannis Konstantelos, Simon H. Tindemans, Goran\n  Strbac", "title": "Sample-Derived Disjunctive Rules for Secure Power System Operation", "comments": "6 pages, accepted paper to IEEE PMAPS 2018", "journal-ref": null, "doi": "10.1109/PMAPS.2018.8440373", "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been used in the past using Monte Carlo\nsamples to construct predictors of the dynamic stability of power systems. In\nthis paper we move beyond the task of prediction and propose a comprehensive\napproach to use predictors, such as Decision Trees (DT), within a standard\noptimization framework for pre- and post-fault control purposes. In particular,\nwe present a generalizable method for embedding rules derived from DTs in an\noperation decision-making model. We begin by pointing out the specific\nchallenges entailed when moving from a prediction to a control framework. We\nproceed with introducing the solution strategy based on generalized disjunctive\nprogramming (GDP) as well as a two-step search method for identifying optimal\nhyper-parameters for balancing cost and control accuracy. We showcase how the\nproposed approach constructs security proxies that cover multiple contingencies\nwhile facing high-dimensional uncertainty with respect to operating conditions\nwith the use of a case study on the IEEE 39-bus system. The method is shown to\nachieve efficient system control at a marginal increase in system price\ncompared to an oracle model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 12:51:53 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Cremer", "Jochen L.", ""], ["Konstantelos", "Ioannis", ""], ["Tindemans", "Simon H.", ""], ["Strbac", "Goran", ""]]}, {"id": "1804.02958", "submitter": "Michael Tschannen", "authors": "Eirikur Agustsson, Michael Tschannen, Fabian Mentzer, Radu Timofte,\n  Luc Van Gool", "title": "Generative Adversarial Networks for Extreme Learned Image Compression", "comments": "E. Agustsson, M. Tschannen, and F. Mentzer contributed equally to\n  this work. ICCV 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learned image compression system based on GANs, operating at\nextremely low bitrates. Our proposed framework combines an encoder,\ndecoder/generator and a multi-scale discriminator, which we train jointly for a\ngenerative learned compression objective. The model synthesizes details it\ncannot afford to store, obtaining visually pleasing results at bitrates where\nprevious methods fail and show strong artifacts. Furthermore, if a semantic\nlabel map of the original image is available, our method can fully synthesize\nunimportant regions in the decoded image such as streets and trees from the\nlabel map, proportionally reducing the storage cost. A user study confirms that\nfor low bitrates, our approach is preferred to state-of-the-art methods, even\nwhen they use more than double the bits.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:13:29 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 17:13:59 GMT"}, {"version": "v3", "created": "Sun, 18 Aug 2019 13:02:02 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Agustsson", "Eirikur", ""], ["Tschannen", "Michael", ""], ["Mentzer", "Fabian", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1804.02960", "submitter": "Simone Gelmini", "authors": "Simone Gelmini, Silvia Strada, Mara Tanelli, Sergio Savaresi and\n  Vincenzo Biase", "title": "Analysis and development of a novel algorithm for the in-vehicle\n  hand-usage of a smartphone", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Smartphone usage while driving is unanimously considered to be a really\ndangerous habit due to strong correlation with road accidents. In this paper,\nthe problem of detecting whether the driver is using the phone during a trip is\naddressed. To do this, high-frequency data from the triaxial inertial\nmeasurement unit (IMU) integrated in almost all modern phone is processed\nwithout relying on external inputs so as to provide a self-contained approach.\nBy resorting to a frequency-domain analysis, it is possible to extract from the\nraw signals the useful information needed to detect when the driver is using\nthe phone, without being affected by the effects that vehicle motion has on the\nsame signals. The selected features are used to train a Support Vector Machine\n(SVM) algorithm. The performance of the proposed approach are analyzed and\ntested on experimental data collected during mixed naturalistic driving\nscenarios, proving the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:42:06 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 09:53:41 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Gelmini", "Simone", ""], ["Strada", "Silvia", ""], ["Tanelli", "Mara", ""], ["Savaresi", "Sergio", ""], ["Biase", "Vincenzo", ""]]}, {"id": "1804.02969", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "A review of possible effects of cognitive biases on the interpretation\n  of rule-based machine learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the interpretability of machine learning models is often equated with\ntheir mere syntactic comprehensibility, we think that interpretability goes\nbeyond that, and that human interpretability should also be investigated from\nthe point of view of cognitive science. In particular, the goal of this paper\nis to discuss to what extent cognitive biases may affect human understanding of\ninterpretable machine learning models, in particular of logical rules\ndiscovered from data. Twenty cognitive biases are covered, as are possible\ndebiasing techniques that can be adopted by designers of machine learning\nalgorithms and software. Our review transfers results obtained in cognitive\npsychology to the domain of machine learning, aiming to bridge the current gap\nbetween these two areas. It needs to be followed by empirical studies\nspecifically focused on the machine learning domain.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:28:56 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 06:31:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 06:43:29 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 08:44:37 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 09:13:13 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 17:42:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1804.02998", "submitter": "Neil Caithness", "authors": "Neil Caithness and David Wallom", "title": "Anomaly Detection for Industrial Big Data", "comments": "9 pages; 11 figures", "journal-ref": "In Proceedings of the 7th International Conference on Data\n  Science, Technology and Applications - Volume 1: DATA (2018), ISBN\n  978-989-758-318-6, pages 285-293", "doi": "10.5220/0006835502850293", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Industrial Internet of Things (IIoT) grows, systems are increasingly\nbeing monitored by arrays of sensors returning time-series data at\never-increasing 'volume, velocity and variety' (i.e. Industrial Big Data). An\nobvious use for these data is real-time systems condition monitoring and\nprognostic time to failure analysis (remaining useful life, RUL). (e.g. See\nwhite papers by Senseye.io, and output of the NASA Prognostics Center of\nExcellence (PCoE).) However, as noted by Agrawal and Choudhary 'Our ability to\ncollect \"big data\" has greatly surpassed our capability to analyze it,\nunderscoring the emergence of the fourth paradigm of science, which is\ndata-driven discovery.' In order to fully utilize the potential of Industrial\nBig Data we need data-driven techniques that operate at scales that process\nmodels cannot. Here we present a prototype technique for data-driven anomaly\ndetection to operate at industrial scale. The method generalizes to application\nwith almost any multivariate dataset based on independent ordinations of\nrepeated (bootstrapped) partitions of the dataset and inspection of the joint\ndistribution of ordinal distances.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 14:09:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Caithness", "Neil", ""], ["Wallom", "David", ""]]}, {"id": "1804.03022", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Pedro Vicente, Atabak Dehban, Lorenzo Jamone,\n  Alexandre Bernardino, Jos\\'e Santos-Victor", "title": "Learning at the Ends: From Hand to Tool Affordances in Humanoid Robots", "comments": "dataset available at htts://vislab.isr.tecnico.ulisboa.pt/, IEEE\n  International Conference on Development and Learning and on Epigenetic\n  Robotics (ICDL-EpiRob 2017)", "journal-ref": null, "doi": "10.1109/DEVLRN.2017.8329826", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the open challenges in designing robots that operate successfully in\nthe unpredictable human environment is how to make them able to predict what\nactions they can perform on objects, and what their effects will be, i.e., the\nability to perceive object affordances. Since modeling all the possible world\ninteractions is unfeasible, learning from experience is required, posing the\nchallenge of collecting a large amount of experiences (i.e., training data).\nTypically, a manipulative robot operates on external objects by using its own\nhands (or similar end-effectors), but in some cases the use of tools may be\ndesirable, nevertheless, it is reasonable to assume that while a robot can\ncollect many sensorimotor experiences using its own hands, this cannot happen\nfor all possible human-made tools.\n  Therefore, in this paper we investigate the developmental transition from\nhand to tool affordances: what sensorimotor skills that a robot has acquired\nwith its bare hands can be employed for tool use? By employing a visual and\nmotor imagination mechanism to represent different hand postures compactly, we\npropose a probabilistic model to learn hand affordances, and we show how this\nmodel can generalize to estimate the affordances of previously unseen tools,\nultimately supporting planning, decision-making and tool selection tasks in\nhumanoid robots. We present experimental results with the iCub humanoid robot,\nand we publicly release the collected sensorimotor data in the form of a hand\nposture affordances dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 14:28:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Vicente", "Pedro", ""], ["Dehban", "Atabak", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1804.03048", "submitter": "Cagatay Demiralp", "authors": "Marco Cavallo and \\c{C}a\\u{g}atay Demiralp", "title": "Clustrophile 2: Guided Visual Clustering Analysis", "comments": "IEEE VIS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data clustering is a common unsupervised learning method frequently used in\nexploratory data analysis. However, identifying relevant structures in\nunlabeled, high-dimensional data is nontrivial, requiring iterative\nexperimentation with clustering parameters as well as data features and\ninstances. The number of possible clusterings for a typical dataset is vast,\nand navigating in this vast space is also challenging. The absence of\nground-truth labels makes it impossible to define an optimal solution, thus\nrequiring user judgment to establish what can be considered a satisfiable\nclustering result. Data scientists need adequate interactive tools to\neffectively explore and navigate the large clustering space so as to improve\nthe effectiveness of exploratory clustering analysis. We introduce\n\\textit{Clustrophile~2}, a new interactive tool for guided clustering analysis.\n\\textit{Clustrophile~2} guides users in clustering-based exploratory analysis,\nadapts user feedback to improve user guidance, facilitates the interpretation\nof clusters, and helps quickly reason about differences between clusterings. To\nthis end, \\textit{Clustrophile~2} contributes a novel feature, the Clustering\nTour, to help users choose clustering parameters and assess the quality of\ndifferent clustering results in relation to current analysis goals and user\nexpectations. We evaluate \\textit{Clustrophile~2} through a user study with 12\ndata scientists, who used our tool to explore and interpret sub-cohorts in a\ndataset of Parkinson's disease patients. Results suggest that\n\\textit{Clustrophile~2} improves the speed and effectiveness of exploratory\nclustering analysis for both experts and non-experts.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:05:56 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 04:25:02 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 02:57:14 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Cavallo", "Marco", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1804.03065", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Parikshit Gopalan, Udi Wieder", "title": "Efficient Anomaly Detection via Matrix Sketching", "comments": "Updates for NeurIPS'18 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding anomalies in high-dimensional data using\npopular PCA based anomaly scores. The naive algorithms for computing these\nscores explicitly compute the PCA of the covariance matrix which uses space\nquadratic in the dimensionality of the data. We give the first streaming\nalgorithms that use space that is linear or sublinear in the dimension. We\nprove general results showing that \\emph{any} sketch of a matrix that satisfies\na certain operator norm guarantee can be used to approximate these scores. We\ninstantiate these results with powerful matrix sketching techniques such as\nFrequent Directions and random projections to derive efficient and practical\nalgorithms for these problems, which we validate over real-world data sets. Our\nmain technical contribution is to prove matrix perturbation inequalities for\noperators arising in the computation of these measures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:47:36 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 16:46:19 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sharan", "Vatsal", ""], ["Gopalan", "Parikshit", ""], ["Wieder", "Udi", ""]]}, {"id": "1804.03077", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "A plug-in approach to maximising precision at the top and recall at the\n  top", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For information retrieval and binary classification, we show that precision\nat the top (or precision at k) and recall at the top (or recall at k) are\nmaximised by thresholding the posterior probability of the positive class. This\nfinding is a consequence of a result on constrained minimisation of the\ncost-sensitive expected classification error which generalises an earlier\nrelated result from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 16:10:45 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "1804.03115", "submitter": "Jiri Fajtl", "authors": "Jiri Fajtl, Vasileios Argyriou, Dorothy Monekosso, Paolo Remagnino", "title": "AMNet: Memorability Estimation with Attention", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the design and evaluation of an end-to-end\ntrainable, deep neural network with a visual attention mechanism for\nmemorability estimation in still images. We analyze the suitability of transfer\nlearning of deep models from image classification to the memorability task.\nFurther on we study the impact of the attention mechanism on the memorability\nestimation and evaluate our network on the SUN Memorability and the LaMem\ndatasets. Our network outperforms the existing state of the art models on both\ndatasets in terms of the Spearman's rank correlation as well as the mean\nsquared error, closely matching human consistency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:28:00 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Fajtl", "Jiri", ""], ["Argyriou", "Vasileios", ""], ["Monekosso", "Dorothy", ""], ["Remagnino", "Paolo", ""]]}, {"id": "1804.03126", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Victor Dibia and \\c{C}a\\u{g}atay Demiralp", "title": "Data2Vis: Automatic Generation of Data Visualizations Using Sequence to\n  Sequence Recurrent Neural Networks", "comments": "IEEE VDS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly creating effective visualizations using expressive grammars is\nchallenging for users who have limited time and limited skills in statistics\nand data visualization. Even high-level, dedicated visualization tools often\nrequire users to manually select among data attributes, decide which\ntransformations to apply, and specify mappings between visual encoding\nvariables and raw or transformed attributes.\n  In this paper we introduce Data2Vis, a neural translation model for\nautomatically generating visualizations from given datasets. We formulate\nvisualization generation as a sequence to sequence translation problem where\ndata specifications are mapped to visualization specifications in a declarative\nlanguage (Vega-Lite). To this end, we train a multilayered attention-based\nrecurrent neural network (RNN) with long short-term memory (LSTM) units on a\ncorpus of visualization specifications.\n  Qualitative results show that our model learns the vocabulary and syntax for\na valid visualization specification, appropriate transformations (count, bins,\nmean) and how to use common data selection patterns that occur within data\nvisualizations. Data2Vis generates visualizations that are comparable to\nmanually-created visualizations in a fraction of the time, with potential to\nlearn more complex visualization strategies at scale.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:48:23 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 05:18:37 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 22:02:37 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Dibia", "Victor", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1804.03154", "submitter": "Tomohiro Hayase", "authors": "Tomohiro Hayase", "title": "Cauchy noise loss for stochastic optimization of random matrix models\n  via free deterministic equivalents", "comments": "29 pages, 13 figures, v3: minor correction. Submitted. Our simulation\n  code is available at https://github.com/ThayaFluss/cnl. Submitted to a\n  journal", "journal-ref": "Journal of Mathematical Analysis and Applications Volume 483,\n  Issue 2, 15 March 2020, 123597", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random matrix models, the parameter estimation based on the traditional\nlikelihood functions is not straightforward in particular when we have only one\nsample matrix. We introduce a new parameter optimization method for random\nmatrix models which works even in such a case. The method is based on the\nspectral distribution instead of the traditional likelihood. In the method, the\nCauchy noise has an essential role because the free deterministic equivalent,\nwhich is a tool in free probability theory, allows us to approximate the\nspectral distribution perturbed by Cauchy noises by a smooth and accessible\ndensity function.\n  Moreover, we study an asymptotic property of determination gap, which has a\nsimilar role as generalization gap. Besides, we propose a new dimensionality\nrecovery method for the signal-plus-noise model, and experimentally demonstrate\nthat it recovers the rank of the signal part even if the true rank is not\nsmall. It is a simultaneous rank selection and parameter estimation procedure.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:00:08 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 11:21:26 GMT"}, {"version": "v3", "created": "Sun, 5 Aug 2018 10:05:13 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 15:12:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Hayase", "Tomohiro", ""]]}, {"id": "1804.03166", "submitter": "Zhizhong Li", "authors": "Zhizhong Li, Derek Hoiem", "title": "Improving Confidence Estimates for Unfamiliar Examples", "comments": "Published in CVPR 2020 (oral). ERRATA: (1) a previous version (v3)\n  included erroneous results for $T$-scaling, where novel samples are\n  mistakenly included in the validation set for calibration. Please disregard\n  those results. (2) Previous versions (v4, v5) incorrectly stated that Adam\n  was used. In fact, we used SGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, unfamiliarity should lead to lack of confidence. In reality,\ncurrent algorithms often make highly confident yet wrong predictions when faced\nwith relevant but unfamiliar examples. A classifier we trained to recognize\ngender is 12 times more likely to be wrong with a 99% confident prediction if\npresented with a subject from a different age group than those seen during\ntraining. In this paper, we compare and evaluate several methods to improve\nconfidence estimates for unfamiliar and familiar samples. We propose a testing\nmethodology of splitting unfamiliar and familiar samples by attribute (age,\nbreed, subcategory) or sampling (similar datasets collected by different people\nat different times). We evaluate methods including confidence calibration,\nensembles, distillation, and a Bayesian model and use several metrics to\nanalyze label, likelihood, and calibration error. While all methods reduce\nover-confident errors, the ensemble of calibrated models performs best overall,\nand T-scaling performs best among the approaches with fastest inference. Our\ncode is available at https://github.com/lizhitwo/ConfidenceEstimates .\n  $\\color{red}{\\text{Please see UPDATED ERRATA.}}$\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:08:14 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:41:03 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 17:59:22 GMT"}, {"version": "v4", "created": "Mon, 6 Jan 2020 18:58:24 GMT"}, {"version": "v5", "created": "Thu, 14 May 2020 17:57:18 GMT"}, {"version": "v6", "created": "Mon, 7 Sep 2020 18:42:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Li", "Zhizhong", ""], ["Hoiem", "Derek", ""]]}, {"id": "1804.03176", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, Fabian Pedregosa and Simon Lacoste-Julien", "title": "Frank-Wolfe Splitting via Augmented Lagrangian Method", "comments": "Appears in: Proceedings of the 21st International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2018). 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a function over an intersection of convex sets is an important\ntask in optimization that is often much more challenging than minimizing it\nover each individual constraint set. While traditional methods such as\nFrank-Wolfe (FW) or proximal gradient descent assume access to a linear or\nquadratic oracle on the intersection, splitting techniques take advantage of\nthe structure of each sets, and only require access to the oracle on the\nindividual constraints. In this work, we develop and analyze the Frank-Wolfe\nAugmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth\nfunction over convex compact sets related by a \"linear consistency\" constraint\nthat only requires access to a linear minimization oracle over the individual\nconstraints. It is based on the Augmented Lagrangian Method (ALM), also known\nas Method of Multipliers, but unlike most existing splitting methods, it only\nrequires access to linear (instead of quadratic) minimization oracles. We use\nrecent advances in the analysis of Frank-Wolfe and the alternating direction\nmethod of multipliers algorithms to prove a sublinear convergence rate for\nFW-AL over general convex compact sets and a linear convergence rate for\npolytopes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:33:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gidel", "Gauthier", ""], ["Pedregosa", "Fabian", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1804.03184", "submitter": "Paidamoyo Chapfuwa", "authors": "Paidamoyo Chapfuwa, Chenyang Tao, Chunyuan Li, Courtney Page, Benjamin\n  Goldstein, Lawrence Carin, Ricardo Henao", "title": "Adversarial Time-to-Event Modeling", "comments": "Published in ICML 2018; Code:\n  https://github.com/paidamoyo/adversarial_time_to_event", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:735-744, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern health data science applications leverage abundant molecular and\nelectronic health data, providing opportunities for machine learning to build\nstatistical models to support clinical practice. Time-to-event analysis, also\ncalled survival analysis, stands as one of the most representative examples of\nsuch statistical models. We present a deep-network-based approach that\nleverages adversarial learning to address a key challenge in modern\ntime-to-event modeling: nonparametric estimation of event-time distributions.\nWe also introduce a principled cost function to exploit information from\ncensored events (events that occur subsequent to the observation window).\nUnlike most time-to-event models, we focus on the estimation of time-to-event\ndistributions, rather than time ordering. We validate our model on both\nbenchmark and real datasets, demonstrating that the proposed formulation yields\nsignificant performance gains relative to a parametric alternative, which we\nalso propose.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 21:04:17 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Chapfuwa", "Paidamoyo", ""], ["Tao", "Chenyang", ""], ["Li", "Chunyuan", ""], ["Page", "Courtney", ""], ["Goldstein", "Benjamin", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1804.03193", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Yanzhi Wang, Xue Lin", "title": "An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural\n  Networks", "comments": "9 pages, 3 figures, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That\nis, adversarial examples, obtained by adding delicately crafted distortions\nonto original legal inputs, can mislead a DNN to classify them as any target\nlabels. In a successful adversarial attack, the targeted mis-classification\nshould be achieved with the minimal distortion added. In the literature, the\nadded distortions are usually measured by L0, L1, L2, and L infinity norms,\nnamely, L0, L1, L2, and L infinity attacks, respectively. However, there lacks\na versatile framework for all types of adversarial attacks.\n  This work for the first time unifies the methods of generating adversarial\nexamples by leveraging ADMM (Alternating Direction Method of Multipliers), an\noperator splitting optimization approach, such that L0, L1, L2, and L infinity\nattacks can be effectively implemented by this general framework with little\nmodifications. Comparing with the state-of-the-art attacks in each category,\nour ADMM-based attacks are so far the strongest, achieving both the 100% attack\nsuccess rate and the minimal distortion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:23:01 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1804.03194", "submitter": "Andreas Henelius", "authors": "Andreas Henelius and Emilia Oikarinen and Kai Puolam\\\"aki", "title": "Human-Guided Data Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outcome of the explorative data analysis (EDA) phase is vital for\nsuccessful data analysis. EDA is more effective when the user interacts with\nthe system used to carry out the exploration. In the recently proposed paradigm\nof iterative data mining the user controls the exploration by inputting\nknowledge in the form of patterns observed during the process. The system then\nshows the user views of the data that are maximally informative given the\nuser's current knowledge. Although this scheme is good at showing surprising\nviews of the data to the user, there is a clear shortcoming: the user cannot\nsteer the process. In many real cases we want to focus on investigating\nspecific questions concerning the data. This paper presents the Human Guided\nData Exploration framework, generalising previous research. This framework\nallows the user to incorporate existing knowledge into the exploration process,\nfocus on exploring a subset of the data, and compare different complex\nhypotheses concerning relations in the data. The framework utilises a\ncomputationally efficient constrained randomisation scheme. To showcase the\nframework, we developed a free open-source tool, using which the empirical\nevaluation on real-world datasets was carried out. Our evaluation shows that\nthe ability to focus on particular subsets and being able to compare hypotheses\nare important additions to the interactive iterative data mining process.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:29:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Henelius", "Andreas", ""], ["Oikarinen", "Emilia", ""], ["Puolam\u00e4ki", "Kai", ""]]}, {"id": "1804.03195", "submitter": "Jonathan Schneider", "authors": "Renato Paes Leme and Jon Schneider", "title": "Contextual Search via Intrinsic Volumes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of contextual search, a multidimensional generalization\nof binary search that captures many problems in contextual decision-making. In\ncontextual search, a learner is trying to learn the value of a hidden vector $v\n\\in [0,1]^d$. Every round the learner is provided an adversarially-chosen\ncontext $u_t \\in \\mathbb{R}^d$, submits a guess $p_t$ for the value of $\\langle\nu_t, v\\rangle$, learns whether $p_t < \\langle u_t, v\\rangle$, and incurs loss\n$\\ell(\\langle u_t, v\\rangle, p_t)$ (for some loss function $\\ell$). The\nlearner's goal is to minimize their total loss over the course of $T$ rounds.\n  We present an algorithm for the contextual search problem for the symmetric\nloss function $\\ell(\\theta, p) = |\\theta - p|$ that achieves $O_{d}(1)$ total\nloss. We present a new algorithm for the dynamic pricing problem (which can be\nrealized as a special case of the contextual search problem) that achieves\n$O_{d}(\\log \\log T)$ total loss, improving on the previous best known upper\nbounds of $O_{d}(\\log T)$ and matching the known lower bounds (up to a\npolynomial dependence on $d$). Both algorithms make significant use of ideas\nfrom the field of integral geometry, most notably the notion of intrinsic\nvolumes of a convex set. To the best of our knowledge this is the first\napplication of intrinsic volumes to algorithm design.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:30:29 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 07:12:21 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Leme", "Renato Paes", ""], ["Schneider", "Jon", ""]]}, {"id": "1804.03198", "submitter": "Casimiro Adays Curbelo Monta\\~nez", "authors": "Casimiro Adays Curbelo Monta\\~nez, Paul Fergus, Almudena Curbelo\n  Monta\\~nez and Carl Chalmers", "title": "Deep Learning Classification of Polygenic Obesity using Genome Wide\n  Association Study SNPs", "comments": "8 pages, 2 figures, 4 tables, 9 equations, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CE cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, association results from genome-wide association studies\n(GWAS) are combined with a deep learning framework to test the predictive\ncapacity of statistically significant single nucleotide polymorphism (SNPs)\nassociated with obesity phenotype. Our approach demonstrates the potential of\ndeep learning as a powerful framework for GWAS analysis that can capture\ninformation about SNPs and the important interactions between them. Basic\nstatistical methods and techniques for the analysis of genetic SNP data from\npopulation-based genome-wide studies have been considered. Statistical\nassociation testing between individual SNPs and obesity was conducted under an\nadditive model using logistic regression. Four subsets of loci after\nquality-control (QC) and association analysis were selected: P-values lower\nthan 1x10-5 (5 SNPs), 1x10-4 (32 SNPs), 1x10-3 (248 SNPs) and 1x10-2 (2465\nSNPs). A deep learning classifier is initialised using these sets of SNPs and\nfine-tuned to classify obese and non-obese observations. Using a deep learning\nclassifier model and genetic variants with P-value < 1x10-2 (2465 SNPs) it was\npossible to obtain results (SE=0.9604, SP=0.9712, Gini=0.9817, LogLoss=0.1150,\nAUC=0.9908 and MSE=0.0300). As the P-value increased, an evident deterioration\nin performance was observed. Results demonstrate that single SNP analysis fails\nto capture the cumulative effect of less significant variants and their overall\ncontribution to the outcome in disease prediction, which is captured using a\ndeep learning framework.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:37:37 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 10:18:40 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Monta\u00f1ez", "Casimiro Adays Curbelo", ""], ["Fergus", "Paul", ""], ["Monta\u00f1ez", "Almudena Curbelo", ""], ["Chalmers", "Carl", ""]]}, {"id": "1804.03201", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Scalable Factorized Hierarchical Variational Autoencoder Training", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved great success in unsupervised learning\nwith the ability to capture complex nonlinear relationships between latent\ngenerating factors and observations. Among them, a factorized hierarchical\nvariational autoencoder (FHVAE) is a variational inference-based model that\nformulates a hierarchical generative process for sequential data. Specifically,\nan FHVAE model can learn disentangled and interpretable representations, which\nhave been proven useful for numerous speech applications, such as speaker\nverification, robust speech recognition, and voice conversion. However, as we\nwill elaborate in this paper, the training algorithm proposed in the original\npaper is not scalable to datasets of thousands of hours, which makes this model\nless applicable on a larger scale. After identifying limitations in terms of\nruntime, memory, and hyperparameter optimization, we propose a hierarchical\nsampling training algorithm to address all three issues. Our proposed method is\nevaluated comprehensively on a wide variety of datasets, ranging from 3 to\n1,000 hours and involving different types of generating factors, such as\nrecording conditions and noise types. In addition, we also present a new\nvisualization method for qualitatively evaluating the performance with respect\nto the interpretability and disentanglement. Models trained with our proposed\nalgorithm demonstrate the desired characteristics on all the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:44:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 04:25:16 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1804.03235", "submitter": "Rohan Anil", "authors": "Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George\n  E. Dahl and Geoffrey E. Hinton", "title": "Large scale distributed neural network training through online\n  distillation", "comments": "Clarify that implementations should use available parallelism in\n  pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:56:03 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 22:04:36 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Anil", "Rohan", ""], ["Pereyra", "Gabriel", ""], ["Passos", "Alexandre", ""], ["Ormandi", "Robert", ""], ["Dahl", "George E.", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1804.03236", "submitter": "Fernando Fernandes Neto", "authors": "Fernando Fernandes Neto", "title": "Building Function Approximators on top of Haar Scattering Networks", "comments": "7 pages, 5 figures, to appear in International Journal of Machine\n  Learning and Computing, vol. 8 number 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose building general-purpose function approximators on\ntop of Haar Scattering Networks. We advocate that this architecture enables a\nbetter comprehension of feature extraction, in addition to its implementation\nsimplicity and low computational costs. We show its approximation and feature\nextraction capabilities in a wide range of different problems, which can be\napplied on several phenomena in signal processing, system identification,\neconometrics and other potential fields.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:56:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Neto", "Fernando Fernandes", ""]]}, {"id": "1804.03240", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Stojanovic, Wayne Satz, Ivan Stojkovic,\n  Kathrin Schreyer, Daniel Del Portal, Zoran Obradovic", "title": "Deep Attention Model for Triage of Emergency Department Patients", "comments": "Proceedings of the 2018 SIAM International Conference on Data Mining\n  (SDM 2018), San Diego, CA, May 2018. *Authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of patient throughput and wait time in emergency departments\n(ED) is an important task for hospital systems. For that reason, Emergency\nSeverity Index (ESI) system for patient triage was introduced to help guide\nmanual estimation of acuity levels, which is used by nurses to rank the\npatients and organize hospital resources. However, despite improvements that it\nbrought to managing medical resources, such triage system greatly depends on\nnurse's subjective judgment and is thus prone to human errors. Here, we propose\na novel deep model based on the word attention mechanism designed for\npredicting a number of resources an ED patient would need. Our approach\nincorporates routinely available continuous and nominal (structured) data with\nmedical text (unstructured) data, including patient's chief complaint, past\nmedical history, medication list, and nurse assessment collected for 338,500 ED\nvisits over three years in a large urban hospital. Using both structured and\nunstructured data, the proposed approach achieves the AUC of $\\sim 88\\%$ for\nthe task of identifying resource intensive patients (binary classification),\nand the accuracy of $\\sim 44\\%$ for predicting exact category of number of\nresources (multi-class classification task), giving an estimated lift over\nnurses' performance by 16\\% in accuracy. Furthermore, the attention mechanism\nof the proposed model provides interpretability by assigning attention scores\nfor nurses' notes which is crucial for decision making and implementation of\nsuch approaches in the real systems working on human health.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 16:06:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Stojanovic", "Jelena", ""], ["Satz", "Wayne", ""], ["Stojkovic", "Ivan", ""], ["Schreyer", "Kathrin", ""], ["Del Portal", "Daniel", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1804.03273", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen and Dennis Wei", "title": "On the Supermodularity of Active Graph-based Semi-supervised Learning\n  with Stieltjes Matrix Regularization", "comments": "Accepted to IEEE ICASSP 2018. Pin-Yu Chen and Dennis Wei contribute\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active graph-based semi-supervised learning (AG-SSL) aims to select a small\nset of labeled examples and utilize their graph-based relation to other\nunlabeled examples to aid in machine learning tasks. It is also closely related\nto the sampling theory in graph signal processing. In this paper, we revisit\nthe original formulation of graph-based SSL and prove the supermodularity of an\nAG-SSL objective function under a broad class of regularization functions\nparameterized by Stieltjes matrices. Under this setting, supermodularity yields\na novel greedy label sampling algorithm with guaranteed performance relative to\nthe optimal sampling set. Compared to three state-of-the-art graph signal\nsampling and recovery methods on two real-life community detection datasets,\nthe proposed AG-SSL method attains superior classification accuracy given\nlimited sample budgets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 23:53:11 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Wei", "Dennis", ""]]}, {"id": "1804.03280", "submitter": "Milad Zafar Nezhad", "authors": "Milad Zafar Nezhad, Najibesadat Sadati, Kai Yang, Dongxiao Zhu", "title": "A Deep Active Survival Analysis Approach for Precision Treatment\n  Recommendations: Application of Prostate Cancer", "comments": null, "journal-ref": "Expert Systems with Applications Volume 115, January 2019, Pages\n  16-26", "doi": "10.1016/j.eswa.2018.07.070", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis has been developed and applied in the number of areas\nincluding manufacturing, finance, economics and healthcare. In healthcare\ndomain, usually clinical data are high-dimensional, sparse and complex and\nsometimes there exists few amount of time-to-event (labeled) instances.\nTherefore building an accurate survival model from electronic health records is\nchallenging. With this motivation, we address this issue and provide a new\nsurvival analysis framework using deep learning and active learning with a\nnovel sampling strategy. First, our approach provides better representation\nwith lower dimensions from clinical features using labeled (time-to-event) and\nunlabeled (censored) instances and then actively trains the survival model by\nlabeling the censored data using an oracle. As a clinical assistive tool, we\nintroduce a simple effective treatment recommendation approach based on our\nsurvival model. In the experimental study, we apply our approach on\nSEER-Medicare data related to prostate cancer among African-Americans and white\npatients. The results indicate that our approach outperforms significantly than\nbaseline models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 00:05:29 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Nezhad", "Milad Zafar", ""], ["Sadati", "Najibesadat", ""], ["Yang", "Kai", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1804.03286", "submitter": "Nicholas Carlini", "authors": "Anish Athalye, Nicholas Carlini", "title": "On the Robustness of the CVPR 2018 White-Box Adversarial Example\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to adversarial examples. In this\nnote, we evaluate the two white-box defenses that appeared at CVPR 2018 and\nfind they are ineffective: when applying existing techniques, we can reduce the\naccuracy of the defended models to 0%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 04:54:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Athalye", "Anish", ""], ["Carlini", "Nicholas", ""]]}, {"id": "1804.03294", "submitter": "Tianyun Zhang", "authors": "Tianyun Zhang, Shaokai Ye, Kaiqi Zhang, Jian Tang, Wujie Wen, Makan\n  Fardad, Yanzhi Wang", "title": "A Systematic DNN Weight Pruning Framework using Alternating Direction\n  Method of Multipliers", "comments": null, "journal-ref": "ECCV 2018, pp 191-207", "doi": "10.1007/978-3-030-01237-3_12", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning methods for deep neural networks (DNNs) have been investigated\nrecently, but prior work in this area is mainly heuristic, iterative pruning,\nthereby lacking guarantees on the weight reduction ratio and convergence time.\nTo mitigate these limitations, we present a systematic weight pruning framework\nof DNNs using the alternating direction method of multipliers (ADMM). We first\nformulate the weight pruning problem of DNNs as a nonconvex optimization\nproblem with combinatorial constraints specifying the sparsity requirements,\nand then adopt the ADMM framework for systematic weight pruning. By using ADMM,\nthe original nonconvex optimization problem is decomposed into two subproblems\nthat are solved iteratively. One of these subproblems can be solved using\nstochastic gradient descent, the other can be solved analytically. Besides, our\nmethod achieves a fast convergence rate.\n  The weight pruning results are very promising and consistently outperform the\nprior work. On the LeNet-5 model for the MNIST data set, we achieve 71.2 times\nweight reduction without accuracy loss. On the AlexNet model for the ImageNet\ndata set, we achieve 21 times weight reduction without accuracy loss. When we\nfocus on the convolutional layer pruning for computation reductions, we can\nreduce the total computation by five times compared with the prior work\n(achieving a total of 13.4 times weight reduction in convolutional layers). Our\nmodels and codes are released at https://github.com/KaiqiZhang/admm-pruning\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:14:51 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 02:19:16 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 16:52:02 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Zhang", "Tianyun", ""], ["Ye", "Shaokai", ""], ["Zhang", "Kaiqi", ""], ["Tang", "Jian", ""], ["Wen", "Wujie", ""], ["Fardad", "Makan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1804.03308", "submitter": "Angus Galloway", "authors": "Angus Galloway and Thomas Tanay and Graham W. Taylor", "title": "Adversarial Training Versus Weight Decay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance-critical machine learning models should be robust to input\nperturbations not seen during training. Adversarial training is a method for\nimproving a model's robustness to some perturbations by including them in the\ntraining process, but this tends to exacerbate other vulnerabilities of the\nmodel. The adversarial training framework has the effect of translating the\ndata with respect to the cost function, while weight decay has a scaling\neffect. Although weight decay could be considered a crude regularization\ntechnique, it appears superior to adversarial training as it remains stable\nover a broader range of regimes and reduces all generalization errors. Equipped\nwith these abstractions, we provide key baseline results and methodology for\ncharacterizing robustness. The two approaches can be combined to yield one\nsmall model that demonstrates good robustness to several white-box attacks\nassociated with different metrics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:57:39 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:52:46 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 03:40:42 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Galloway", "Angus", ""], ["Tanay", "Thomas", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1804.03313", "submitter": "Liyao Gao Mr.", "authors": "Liyao Gao", "title": "Cortex Neural Network: learning with Neural Network groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network has been successfully applied to many real-world problems,\nsuch as image recognition and machine translation. However, for the current\narchitecture of neural networks, it is hard to perform complex cognitive tasks,\nfor example, to process the image and audio inputs together. Cortex, as an\nimportant architecture in the brain, is important for animals to perform the\ncomplex cognitive task. We view the architecture of Cortex in the brain as a\nmissing part in the design of the current artificial neural network. In this\npaper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is\nan upper architecture of neural networks which motivated from cerebral cortex\nin the brain to handle different tasks in the same learning system. It is able\nto identify different tasks and solve them with different methods. In our\nimplementation, the Cortex Neural Network is able to process different\ncognitive tasks and perform reflection to get a higher accuracy. We provide a\nseries of experiments to examine the capability of the cortex architecture on\ntraditional neural networks. Our experiments proved its ability on the Cortex\nNeural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the\nsame time, which can promisingly reduce the loss by 40%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:33:47 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gao", "Liyao", ""]]}, {"id": "1804.03317", "submitter": "Yingqi Qu", "authors": "Yingqi Qu, Jie Liu, Liangyi Kang, Qinfeng Shi, Dan Ye", "title": "Question Answering over Freebase via Attentive RNN with Similarity\n  Matrix based CNN", "comments": "The experiments need to improve and add strategy for multi-relation\n  questions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge bases (KBs), question answering over\nknowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of\nthe existing KBQA methods follow so called encoder-compare framework. They map\nthe question and the KB facts to a common embedding space, in which the\nsimilarity between the question vector and the fact vectors can be conveniently\ncomputed. This, however, inevitably loses original words interaction\ninformation. To preserve more original information, we propose an attentive\nrecurrent neural network with similarity matrix based convolutional neural\nnetwork (AR-SMCNN) model, which is able to capture comprehensive hierarchical\ninformation utilizing the advantages of both RNN and CNN. We use RNN to capture\nsemantic-level correlation by its sequential modeling nature, and use an\nattention mechanism to keep track of the entities and relations simultaneously.\nMeanwhile, we use a similarity matrix based CNN with two-directions pooling to\nextract literal-level words interaction matching utilizing CNNs strength of\nmodeling spatial correlation among data. Moreover, we have developed a new\nheuristic extension method for entity detection, which significantly decreases\nthe effect of noise. Our method has outperformed the state-of-the-arts on\nSimpleQuestion benchmark in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:39:41 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 09:26:44 GMT"}, {"version": "v3", "created": "Sun, 27 May 2018 13:36:15 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Qu", "Yingqi", ""], ["Liu", "Jie", ""], ["Kang", "Liangyi", ""], ["Shi", "Qinfeng", ""], ["Ye", "Dan", ""]]}, {"id": "1804.03329", "submitter": "Albert Gu", "authors": "Christopher De Sa, Albert Gu, Christopher R\\'e, Frederic Sala", "title": "Representation Tradeoffs for Hyperbolic Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic embeddings offer excellent quality with few dimensions when\nembedding hierarchical data structures like synonym or type hierarchies. Given\na tree, we give a combinatorial construction that embeds the tree in hyperbolic\nspace with arbitrarily low distortion without using optimization. On WordNet,\nour combinatorial embedding obtains a mean-average-precision of 0.989 with only\ntwo dimensions, while Nickel et al.'s recent construction obtains 0.87 using\n200 dimensions. We provide upper and lower bounds that allow us to characterize\nthe precision-dimensionality tradeoff inherent in any hyperbolic embedding. To\nembed general metric spaces, we propose a hyperbolic generalization of\nmultidimensional scaling (h-MDS). We show how to perform exact recovery of\nhyperbolic points from distances, provide a perturbation analysis, and give a\nrecovery result that allows us to reduce dimensionality. The h-MDS approach\noffers consistently low distortion even with few dimensions across several\ndatasets. Finally, we extract lessons from the algorithms and theory above to\ndesign a PyTorch-based implementation that can handle incomplete information\nand is scalable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 03:39:16 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 04:11:36 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["De Sa", "Christopher", ""], ["Gu", "Albert", ""], ["R\u00e9", "Christopher", ""], ["Sala", "Frederic", ""]]}, {"id": "1804.03334", "submitter": "Patrick M. Pilarski", "authors": "Alex Kearney, Vivek Veeriah, Jaden B. Travnik, Richard S. Sutton,\n  Patrick M. Pilarski", "title": "TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic\n  Meta-descent", "comments": "Version as submitted to the 31st Conference on Neural Information\n  Processing Systems (NIPS 2017) on May 19, 2017. 9 pages, 5 figures. Extended\n  version in preparation for journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method for adapting the step-sizes of temporal\ndifference (TD) learning. The performance of TD methods often depends on well\nchosen step-sizes, yet few algorithms have been developed for setting the\nstep-size automatically for TD learning. An important limitation of current\nmethods is that they adapt a single step-size shared by all the weights of the\nlearning system. A vector step-size enables greater optimization by specifying\nparameters on a per-feature basis. Furthermore, adapting parameters at\ndifferent rates has the added benefit of being a simple form of representation\nlearning. We generalize Incremental Delta Bar Delta (IDBD)---a vectorized\nadaptive step-size method for supervised learning---to TD learning, which we\nname TIDBD. We demonstrate that TIDBD is able to find appropriate step-sizes in\nboth stationary and non-stationary prediction tasks, outperforming ordinary TD\nmethods and TD methods with scalar step-size adaptation; we demonstrate that it\ncan differentiate between features which are relevant and irrelevant for a\ngiven task, performing representation learning; and we show on a real-world\nrobot prediction task that TIDBD is able to outperform ordinary TD methods and\nTD methods augmented with AlphaBound and RMSprop.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 04:01:07 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Kearney", "Alex", ""], ["Veeriah", "Vivek", ""], ["Travnik", "Jaden B.", ""], ["Sutton", "Richard S.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1804.03346", "submitter": "Siddhartha Satpathi Mr", "authors": "Siddhartha Satpathi, Supratim Deb, R Srikant, and He Yan", "title": "Learning Latent Events from Network Message Logs", "comments": "To Appear in IEEE Transactions on Networking, Appeared in Workshop on\n  MiLeTS, SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of separating error messages generated in large\ndistributed data center networks into error events. In such networks, each\nerror event leads to a stream of messages generated by hardware and software\ncomponents affected by the event. These messages are stored in a giant message\nlog. We consider the unsupervised learning problem of identifying the\nsignatures of events that generated these messages; here, the signature of an\nerror event refers to the mixture of messages generated by the event. One of\nthe main contributions of the paper is a novel mapping of our problem which\ntransforms it into a problem of topic discovery in documents. Events in our\nproblem correspond to topics and messages in our problem correspond to words in\nthe topic discovery problem. However, there is no direct analog of documents.\nTherefore, we use a non-parametric change-point detection algorithm, which has\nlinear computational complexity in the number of messages, to divide the\nmessage log into smaller subsets called episodes, which serve as the\nequivalents of documents. After this mapping has been done, we use a well-known\nalgorithm for topic discovery, called LDA, to solve our problem. We\ntheoretically analyze the change-point detection algorithm, and show that it is\nconsistent and has low sample complexity. We also demonstrate the scalability\nof our algorithm on a real data set consisting of $97$ million messages\ncollected over a period of $15$ days, from a distributed data center network\nwhich supports the operations of a large wireless service provider.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 05:44:53 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 23:23:46 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 20:06:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Satpathi", "Siddhartha", ""], ["Deb", "Supratim", ""], ["Srikant", "R", ""], ["Yan", "He", ""]]}, {"id": "1804.03390", "submitter": "Georg Poier", "authors": "Georg Poier, David Schinagl, Horst Bischof", "title": "Learning Pose Specific Representations by Predicting Different Views", "comments": "CVPR 2018 (Spotlight); Project Page at\n  https://poier.github.io/PreView/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The labeled data required to learn pose estimation for articulated objects is\ndifficult to provide in the desired quantity, realism, density, and accuracy.\nTo address this issue, we develop a method to learn representations, which are\nvery specific for articulated poses, without the need for labeled training\ndata. We exploit the observation that the object pose of a known object is\npredictive for the appearance in any known view. That is, given only the pose\nand shape parameters of a hand, the hand's appearance from any viewpoint can be\napproximated. To exploit this observation, we train a model that -- given input\nfrom one view -- estimates a latent representation, which is trained to be\npredictive for the appearance of the object when captured from another\nviewpoint. Thus, the only necessary supervision is the second view. The\ntraining process of this model reveals an implicit pose representation in the\nlatent space. Importantly, at test time the pose representation can be inferred\nusing only a single view. In qualitative and quantitative experiments we show\nthat the learned representations capture detailed pose information. Moreover,\nwhen training the proposed method jointly with labeled and unlabeled data, it\nconsistently surpasses the performance of its fully supervised counterpart,\nwhile reducing the amount of needed labeled samples by at least one order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 08:22:23 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 15:02:46 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Poier", "Georg", ""], ["Schinagl", "David", ""], ["Bischof", "Horst", ""]]}, {"id": "1804.03393", "submitter": "Erik J Bekkers", "authors": "Erik J Bekkers, Maxime W Lafarge, Mitko Veta, Koen AJ Eppenhof, Josien\n  PW Pluim, Remco Duits", "title": "Roto-Translation Covariant Convolutional Networks for Medical Image\n  Analysis", "comments": "8 pages, 2 figures, 1 table, accepted at MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for rotation and translation covariant deep learning\nusing $SE(2)$ group convolutions. The group product of the special Euclidean\nmotion group $SE(2)$ describes how a concatenation of two roto-translations\nresults in a net roto-translation. We encode this geometric structure into\nconvolutional neural networks (CNNs) via $SE(2)$ group convolutional layers,\nwhich fit into the standard 2D CNN framework, and which allow to generically\ndeal with rotated input samples without the need for data augmentation.\n  We introduce three layers: a lifting layer which lifts a 2D (vector valued)\nimage to an $SE(2)$-image, i.e., 3D (vector valued) data whose domain is\n$SE(2)$; a group convolution layer from and to an $SE(2)$-image; and a\nprojection layer from an $SE(2)$-image to a 2D image. The lifting and group\nconvolution layers are $SE(2)$ covariant (the output roto-translates with the\ninput). The final projection layer, a maximum intensity projection over\nrotations, makes the full CNN rotation invariant.\n  We show with three different problems in histopathology, retinal imaging, and\nelectron microscopy that with the proposed group CNNs, state-of-the-art\nperformance can be achieved, without the need for data augmentation by rotation\nand with increased performance compared to standard CNNs that do rely on\naugmentation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 08:23:44 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 15:07:57 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 17:53:31 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Bekkers", "Erik J", ""], ["Lafarge", "Maxime W", ""], ["Veta", "Mitko", ""], ["Eppenhof", "Koen AJ", ""], ["Pluim", "Josien PW", ""], ["Duits", "Remco", ""]]}, {"id": "1804.03424", "submitter": "Yookoon Park", "authors": "Yookoon Park, Jaemin Cho and Gunhee Kim", "title": "A Hierarchical Latent Structure for Variational Conversation Modeling", "comments": "Published in NAACL 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) combined with hierarchical RNNs have emerged\nas a powerful framework for conversation modeling. However, they suffer from\nthe notorious degeneration problem, where the decoders learn to ignore latent\nvariables and reduce to vanilla RNNs. We empirically show that this degeneracy\noccurs mostly due to two reasons. First, the expressive power of hierarchical\nRNN decoders is often high enough to model the data using only its decoding\ndistributions without relying on the latent variables. Second, the conditional\nVAE structure whose generation process is conditioned on a context, makes the\nrange of training targets very sparse; that is, the RNN decoders can easily\noverfit to the training data ignoring the latent variables. To solve the\ndegeneration problem, we propose a novel model named Variational Hierarchical\nConversation RNNs (VHCR), involving two key ideas of (1) using a hierarchical\nstructure of latent variables, and (2) exploiting an utterance drop\nregularization. With evaluations on two datasets of Cornell Movie Dialog and\nUbuntu Dialog Corpus, we show that our VHCR successfully utilizes latent\nvariables and outperforms state-of-the-art models for conversation generation.\nMoreover, it can perform several new utterance control tasks, thanks to its\nhierarchical latent structure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:00:36 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 06:02:24 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Park", "Yookoon", ""], ["Cho", "Jaemin", ""], ["Kim", "Gunhee", ""]]}, {"id": "1804.03429", "submitter": "Chongxuan Li", "authors": "Chongxuan Li and Max Welling and Jun Zhu and Bo Zhang", "title": "Graphical Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model\nstructured data. Graphical-GAN conjoins the power of Bayesian networks on\ncompactly representing the dependency structures among random variables and\nthat of generative adversarial networks on learning expressive dependency\nfunctions. We introduce a structured recognition model to infer the posterior\ndistribution of latent variables given observations. We generalize the\nExpectation Propagation (EP) algorithm to learn the generative model and\nrecognition model jointly. Finally, we present two important instances of\nGraphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN),\nwhich can successfully learn the discrete and temporal structures on visual\ndatasets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:12:38 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 08:20:54 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Li", "Chongxuan", ""], ["Welling", "Max", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1804.03515", "submitter": "Philipp Probst", "authors": "Philipp Probst, Marvin Wright and Anne-Laure Boulesteix", "title": "Hyperparameters and Tuning Strategies for Random Forest", "comments": "19 pages, 2 figures", "journal-ref": "WIREs Data Mining Knowl Discov 2019", "doi": "10.1002/widm.1301", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random forest algorithm (RF) has several hyperparameters that have to be\nset by the user, e.g., the number of observations drawn randomly for each tree\nand whether they are drawn with or without replacement, the number of variables\ndrawn randomly for each split, the splitting rule, the minimum number of\nsamples that a node must contain and the number of trees. In this paper, we\nfirst provide a literature review on the parameters' influence on the\nprediction performance and on variable importance measures.\n  It is well known that in most cases RF works reasonably well with the default\nvalues of the hyperparameters specified in software packages. Nevertheless,\ntuning the hyperparameters can improve the performance of RF. In the second\npart of this paper, after a brief overview of tuning strategies we demonstrate\nthe application of one of the most established tuning strategies, model-based\noptimization (MBO). To make it easier to use, we provide the tuneRanger R\npackage that tunes RF with MBO automatically. In a benchmark study on several\ndatasets, we compare the prediction performance and runtime of tuneRanger with\nother tuning implementations in R and RF with default hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:30:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:40:17 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Probst", "Philipp", ""], ["Wright", "Marvin", ""], ["Boulesteix", "Anne-Laure", ""]]}, {"id": "1804.03578", "submitter": "Zihao Xiao", "authors": "Zihao Xiao, Jianfei Chen, Jun Zhu", "title": "Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip\n  Systems", "comments": "Accepted by AAAI-18, oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic topic models are popular unsupervised learning methods,\nincluding probabilistic latent semantic indexing (pLSI) and latent Dirichlet\nallocation (LDA). By now, their training is implemented on general purpose\ncomputers (GPCs), which are flexible in programming but energy-consuming.\nTowards low-energy implementations, this paper investigates their training on\nan emerging hardware technology called the neuromorphic multi-chip systems\n(NMSs). NMSs are very effective for a family of algorithms called spiking\nneural networks (SNNs). We present three SNNs to train topic models. The first\nSNN is a batch algorithm combining the conventional collapsed Gibbs sampling\n(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are\nonline algorithms targeting at both energy- and storage-limited environments.\nThe two online algorithms are equivalent with training LDA by using\nmaximum-a-posterior estimation and maximizing the semi-collapsed likelihood,\nrespectively. They use novel, tailored ordinary differential equations for\nstochastic optimization. We simulate the new algorithms and show that they are\ncomparable with the GPC algorithms, while being suitable for NMS\nimplementation. We also propose an extension to train pLSI and a method to\nprune the network to obey the limited fan-in of some NMSs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:01:50 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Xiao", "Zihao", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""]]}, {"id": "1804.03599", "submitter": "Christopher Burgess", "authors": "Christopher P. Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick\n  Watters, Guillaume Desjardins, Alexander Lerchner", "title": "Understanding disentangling in $\\beta$-VAE", "comments": "Presented at the 2017 NIPS Workshop on Learning Disentangled\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new intuitions and theoretical assessments of the emergence of\ndisentangled representation in variational autoencoders. Taking a\nrate-distortion theory perspective, we show the circumstances under which\nrepresentations aligned with the underlying generative factors of variation of\ndata emerge when optimising the modified ELBO bound in $\\beta$-VAE, as training\nprogresses. From these insights, we propose a modification to the training\nregime of $\\beta$-VAE, that progressively increases the information capacity of\nthe latent code during training. This modification facilitates the robust\nlearning of disentangled representations in $\\beta$-VAE, without the previous\ntrade-off in reconstruction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:48:18 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Burgess", "Christopher P.", ""], ["Higgins", "Irina", ""], ["Pal", "Arka", ""], ["Matthey", "Loic", ""], ["Watters", "Nick", ""], ["Desjardins", "Guillaume", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1804.03608", "submitter": "Tanmay Gupta", "authors": "Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, and Aniruddha\n  Kembhavi", "title": "Imagine This! Scripts to Compositions to Videos", "comments": "Supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagining a scene described in natural language with realistic layout and\nappearance of entities is the ultimate test of spatial, visual, and semantic\nworld knowledge. Towards this goal, we present the Composition, Retrieval, and\nFusion Network (CRAFT), a model capable of learning this knowledge from\nvideo-caption data and applying it while generating videos from novel captions.\nCRAFT explicitly predicts a temporal-layout of mentioned entities (characters\nand objects), retrieves spatio-temporal entity segments from a video database\nand fuses them to generate scene videos. Our contributions include sequential\ntraining of components of CRAFT while jointly modeling layout and appearances,\nand losses that encourage learning compositional representations for retrieval.\nWe evaluate CRAFT on semantic fidelity to caption, composition consistency, and\nvisual quality. CRAFT outperforms direct pixel generation approaches and\ngeneralizes well to unseen captions and to unseen video databases with no text\nannotations. We demonstrate CRAFT on FLINTSTONES, a new richly annotated\nvideo-caption dataset with over 25000 videos. For a glimpse of videos generated\nby CRAFT, see https://youtu.be/688Vv86n0z8.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:59:45 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gupta", "Tanmay", ""], ["Schwenk", "Dustin", ""], ["Farhadi", "Ali", ""], ["Hoiem", "Derek", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "1804.03615", "submitter": "Rong Zhu", "authors": "Rong Zhu and Jiming Jiang", "title": "Subsampled Optimization: Statistical Guarantees, Mean Squared Error\n  Approximation, and Sampling Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For optimization on large-scale data, exactly calculating its solution may be\ncomputationally difficulty because of the large size of the data. In this paper\nwe consider subsampled optimization for fast approximating the exact solution.\nIn this approach, one gets a surrogate dataset by sampling from the full data,\nand then obtains an approximate solution by solving the subsampled optimization\nbased on the surrogate. One main theoretical contributions are to provide the\nasymptotic properties of the approximate solution with respect to the exact\nsolution as statistical guarantees, and to rigorously derive an accurate\napproximation of the mean squared error (MSE) and an approximately unbiased MSE\nestimator. These results help us better diagnose the subsampled optimization in\nthe context that a confidence region on the exact solution is provided using\nthe approximate solution. The other consequence of our results is to propose an\noptimal sampling method, Hessian-based sampling, whose probabilities are\nproportional to the norms of Newton directions. Numerical experiments with\nleast-squares and logistic regression show promising performance, in line with\nour results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:18:10 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Zhu", "Rong", ""], ["Jiang", "Jiming", ""]]}, {"id": "1804.03629", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Masayoshi Tomizuka", "title": "Probabilistic Prediction of Vehicle Semantic Intention and Motion", "comments": "This paper has been submitted to the 2018 IEEE Intelligent Vehicles\n  (IV) Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the possible behaviors of traffic participants is an\nessential capability for future autonomous vehicles. The majority of current\nresearches fix the number of driving intentions by considering only a specific\nscenario. However, distinct driving environments usually contain various\npossible driving maneuvers. Therefore, a intention prediction method that can\nadapt to different traffic scenarios is needed. To further improve the overall\nvehicle prediction performance, motion information is usually incorporated with\nclassified intentions. As suggested in some literature, the methods that\ndirectly predict possible goal locations can achieve better performance for\nlong-term motion prediction than other approaches due to their automatic\nincorporation of environment constraints. Moreover, by obtaining the temporal\ninformation of the predicted destinations, the optimal trajectories for\npredicted vehicles as well as the desirable path for ego autonomous vehicle\ncould be easily generated. In this paper, we propose a Semantic-based Intention\nand Motion Prediction (SIMP) method, which can be adapted to any driving\nscenarios by using semantic-defined vehicle behaviors. It utilizes a\nprobabilistic framework based on deep neural network to estimate the\nintentions, final locations, and the corresponding time information for\nsurrounding vehicles. An exemplar real-world scenario was used to implement and\nexamine the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 17:05:53 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1804.03636", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and John Peebles", "title": "Testing Identity of Multidimensional Histograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of identity testing for multidimensional histogram\ndistributions. A distribution $p: D \\rightarrow \\mathbb{R}_+$, where $D\n\\subseteq \\mathbb{R}^d$, is called a $k$-histogram if there exists a partition\nof the domain into $k$ axis-aligned rectangles such that $p$ is constant within\neach such rectangle. Histograms are one of the most fundamental nonparametric\nfamilies of distributions and have been extensively studied in computer science\nand statistics. We give the first identity tester for this problem with {\\em\nsub-learning} sample complexity in any fixed dimension and a nearly-matching\nsample complexity lower bound.\n  In more detail, let $q$ be an unknown $d$-dimensional $k$-histogram\ndistribution in fixed dimension $d$, and $p$ be an explicitly given\n$d$-dimensional $k$-histogram. We want to correctly distinguish, with\nprobability at least $2/3$, between the case that $p = q$ versus $\\|p-q\\|_1\n\\geq \\epsilon$. We design an algorithm for this hypothesis testing problem with\nsample complexity $O((\\sqrt{k}/\\epsilon^2) 2^{d/2} \\log^{2.5 d}(k/\\epsilon))$\nthat runs in sample-polynomial time. Our algorithm is robust to model\nmisspecification, i.e., succeeds even if $q$ is only promised to be {\\em close}\nto a $k$-histogram. Moreover, for $k = 2^{\\Omega(d)}$, we show a sample\ncomplexity lower bound of $(\\sqrt{k}/\\epsilon^2) \\cdot \\Omega(\\log(k)/d)^{d-1}$\nwhen $d\\geq 2$. That is, for any fixed dimension $d$, our upper and lower\nbounds are nearly matching. Prior to our work, the sample complexity of the\n$d=1$ case was well-understood, but no algorithm with sub-learning sample\ncomplexity was known, even for $d=2$. Our new upper and lower bounds have\ninteresting conceptual implications regarding the relation between learning and\ntesting in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 17:28:47 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 02:42:51 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Peebles", "John", ""]]}, {"id": "1804.03707", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Yi Huang, and Ishanu Chattopadhyay", "title": "A Tamper-Free Semi-Universal Communication System for Deletion Channels", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reliable communication between two legitimate\nparties over deletion channels under an active eavesdropping (aka jamming)\nadversarial model. To this goal, we develop a theoretical framework based on\nprobabilistic finite-state automata to define novel encoding and decoding\nschemes that ensure small error probability in both message decoding as well as\ntamper detecting. We then experimentally verify the reliability and\ntamper-detection property of our scheme.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 16:13:33 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Huang", "Yi", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1804.03720", "submitter": "Alex Nichol", "authors": "Alex Nichol, Vicki Pfau, Christopher Hesse, Oleg Klimov, John Schulman", "title": "Gotta Learn Fast: A New Benchmark for Generalization in RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we present a new reinforcement learning (RL) benchmark based\non the Sonic the Hedgehog (TM) video game franchise. This benchmark is intended\nto measure the performance of transfer learning and few-shot learning\nalgorithms in the RL domain. We also present and evaluate some baseline\nalgorithms on the new benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 21:09:53 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 20:52:30 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Nichol", "Alex", ""], ["Pfau", "Vicki", ""], ["Hesse", "Christopher", ""], ["Klimov", "Oleg", ""], ["Schulman", "John", ""]]}, {"id": "1804.03728", "submitter": "Canyi Lu", "authors": "Canyi Lu, Jiashi Feng, Yudong Chen, Wei Liu, Zhouchen Lin, Shuicheng\n  Yan", "title": "Tensor Robust Principal Component Analysis with A New Tensor Nuclear\n  Norm", "comments": "arXiv admin note: text overlap with arXiv:1708.04181", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Tensor Robust Principal Component Analysis\n(TRPCA) problem, which aims to exactly recover the low-rank and sparse\ncomponents from their sum. Our model is based on the recently proposed\ntensor-tensor product (or t-product). Induced by the t-product, we first\nrigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor\naverage rank, and show that the tensor nuclear norm is the convex envelope of\nthe tensor average rank within the unit ball of the tensor spectral norm. These\ndefinitions, their relationships and properties are consistent with matrix\ncases. Equipped with the new tensor nuclear norm, we then solve the TRPCA\nproblem by solving a convex program and provide the theoretical guarantee for\nthe exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA\nas a special case. Numerical experiments verify our results, and the\napplications to image recovery and background modeling problems demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 21:29:30 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 04:49:41 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lu", "Canyi", ""], ["Feng", "Jiashi", ""], ["Chen", "Yudong", ""], ["Liu", "Wei", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1804.03740", "submitter": "Igor Fedorov", "authors": "Igor Fedorov, Bhaskar D. Rao", "title": "Multimodal Sparse Bayesian Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning dictionaries for multimodal\ndatasets, i.e. datasets collected from multiple data sources. We present an\nalgorithm called multimodal sparse Bayesian dictionary learning (MSBDL). MSBDL\nleverages information from all available data modalities through a joint\nsparsity constraint. The underlying framework offers a considerable amount of\nflexibility to practitioners and addresses many of the shortcomings of existing\nmultimodal dictionary learning approaches. In particular, the procedure\nincludes the automatic tuning of hyperparameters and is unique in that it\nallows the dictionaries for each data modality to have different cardinality, a\nsignificant feature in cases when the dimensionality of data differs across\nmodalities. MSBDL is scalable and can be used in supervised learning settings.\nTheoretical results relating to the convergence of MSBDL are presented and the\nnumerical results provide evidence of the superior performance of MSBDL on\nsynthetic and real datasets compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 22:27:21 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 00:30:44 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 01:54:44 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Fedorov", "Igor", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1804.03758", "submitter": "Chen Ma", "authors": "Chen Ma, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Representations for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 00:06:36 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Ma", "Chen", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.03761", "submitter": "Tatsunori Hashimoto", "authors": "Tatsunori B. Hashimoto, Steve Yadlowsky, John C. Duchi", "title": "Derivative free optimization via repeated classification", "comments": "At AISTATS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for minimizing a function using $n$ batched function\nvalue measurements at each of $T$ rounds by using classifiers to identify a\nfunction's sublevel set. We show that sufficiently accurate classifiers can\nachieve linear convergence rates, and show that the convergence rate is tied to\nthe difficulty of active learning sublevel sets. Further, we show that the\nbootstrap is a computationally efficient approximation to the necessary\nclassification scheme.\n  The end result is a computationally efficient derivative-free algorithm\nrequiring no tuning that consistently outperforms other approaches on\nsimulations, standard benchmarks, real-world DNA binding optimization, and\nairfoil design problems whenever batched function queries are natural.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 00:45:39 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Hashimoto", "Tatsunori B.", ""], ["Yadlowsky", "Steve", ""], ["Duchi", "John C.", ""]]}, {"id": "1804.03782", "submitter": "Sidi Lu", "authors": "Sidi Lu and Lantao Yu and Siyuan Feng and Yaoming Zhu and Weinan Zhang\n  and Yong Yu", "title": "CoT: Cooperative Training for Generative Modeling of Discrete Data", "comments": "Appearing as a Conference Paper on ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generative models of sequential discrete data. To\ntackle the exposure bias problem inherent in maximum likelihood estimation\n(MLE), generative adversarial networks (GANs) are introduced to penalize the\nunrealistic generated samples. To exploit the supervision signal from the\ndiscriminator, most previous models leverage REINFORCE to address the\nnon-differentiable problem of sequential discrete data. However, because of the\nunstable property of the training signal during the dynamic process of\nadversarial training, the effectiveness of REINFORCE, in this case, is hardly\nguaranteed. To deal with such a problem, we propose a novel approach called\nCooperative Training (CoT) to improve the training of sequence generative\nmodels. CoT transforms the min-max game of GANs into a joint maximization\nframework and manages to explicitly estimate and optimize Jensen-Shannon\ndivergence. Moreover, CoT works without the necessity of pre-training via MLE,\nwhich is crucial to the success of previous methods. In the experiments,\ncompared to existing state-of-the-art methods, CoT shows superior or at least\ncompetitive performance on sample quality, diversity, as well as training\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:10:55 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 05:38:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 04:44:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lu", "Sidi", ""], ["Yu", "Lantao", ""], ["Feng", "Siyuan", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03794", "submitter": "Yue Wang", "authors": "Yue Wang, Daniel Kifer, Jaewoo Lee", "title": "Differentially Private Confidence Intervals for Empirical Risk\n  Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of data mining with differential privacy produces results that\nare affected by two types of noise: sampling noise due to data collection and\nprivacy noise that is designed to prevent the reconstruction of sensitive\ninformation. In this paper, we consider the problem of designing confidence\nintervals for the parameters of a variety of differentially private machine\nlearning models. The algorithms can provide confidence intervals that satisfy\ndifferential privacy (as well as the more recently proposed concentrated\ndifferential privacy) and can be used with existing differentially private\nmechanisms that train models using objective perturbation and output\nperturbation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:18:17 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Wang", "Yue", ""], ["Kifer", "Daniel", ""], ["Lee", "Jaewoo", ""]]}, {"id": "1804.03797", "submitter": "Chen Zhang", "authors": "Chen Zhang, Hao Yan, Seungho Lee, Jianjun Shi", "title": "Dynamic Multivariate Functional Data Modeling via Sparse Subspace\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate functional data from a complex system are naturally\nhigh-dimensional and have complex cross-correlation structure. The complexity\nof data structure can be observed as that (1) some functions are strongly\ncorrelated with similar features, while some others may have almost no\ncross-correlations with quite diverse features; and (2) the cross-correlation\nstructure may also change over time due to the system evolution. With this\nregard, this paper presents a dynamic subspace learning method for multivariate\nfunctional data modeling. In particular, we consider different functions come\nfrom different subspaces, and only functions of the same subspace have\ncross-correlations with each other. The subspaces can be automatically\nformulated and learned by reformatting the problem as a sparse regression. By\nallowing but regularizing the regression change over time, we can describe the\ncross-correlation dynamics. The model can be efficiently estimated by the fast\niterative shrinkage-thresholding algorithm (FISTA), and the features of every\nsubspace can be extracted using the smooth multi-channel functional PCA.\nNumerical studies together with case studies demonstrate the efficiency and\napplicability of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:32:16 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Zhang", "Chen", ""], ["Yan", "Hao", ""], ["Lee", "Seungho", ""], ["Shi", "Jianjun", ""]]}, {"id": "1804.03811", "submitter": "Jilei Yang", "authors": "Jilei Yang, Jie Peng", "title": "Estimating Time-Varying Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study time-varying graphical models based on data measured\nover a temporal grid. Such models are motivated by the needs to describe and\nunderstand evolving interacting relationships among a set of random variables\nin many real applications, for instance the study of how stocks interact with\neach other and how such interactions change over time.\n  We propose a new model, LOcal Group Graphical Lasso Estimation (loggle),\nunder the assumption that the graph topology changes gradually over time.\nSpecifically, loggle uses a novel local group-lasso type penalty to efficiently\nincorporate information from neighboring time points and to impose structural\nsmoothness of the graphs. We implement an ADMM based algorithm to fit the\nloggle model. This algorithm utilizes blockwise fast computation and\npseudo-likelihood approximation to improve computational efficiency. An R\npackage loggle has also been developed.\n  We evaluate the performance of loggle by simulation experiments. We also\napply loggle to S&P 500 stock price data and demonstrate that loggle is able to\nreveal the interacting relationships among stocks and among industrial sectors\nin a time period that covers the recent global financial crisis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 04:54:56 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Yang", "Jilei", ""], ["Peng", "Jie", ""]]}, {"id": "1804.03836", "submitter": "Bamdev Mishra", "authors": "Anil R. Yelundur, Srinivasan H. Sengamedu and Bamdev Mishra", "title": "E-commerce Anomaly Detection: A Bayesian Semi-Supervised Tensor\n  Decomposition Approach using Natural Gradients", "comments": "Citations rendering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly Detection has several important applications. In this paper, our\nfocus is on detecting anomalies in seller-reviewer data using tensor\ndecomposition. While tensor-decomposition is mostly unsupervised, we formulate\nBayesian semi-supervised tensor decomposition to take advantage of sparse\nlabeled data. In addition, we use Polya-Gamma data augmentation for the\nsemi-supervised Bayesian tensor decomposition. Finally, we show that the\nP\\'olya-Gamma formulation simplifies calculation of the Fisher information\nmatrix for partial natural gradient learning. Our experimental results show\nthat our semi-supervised approach outperforms state of the art unsupervised\nbaselines. And that the partial natural gradient learning outperforms\nstochastic gradient learning and Online-EM with sufficient statistics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:55:06 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 18:15:42 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 08:47:20 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Yelundur", "Anil R.", ""], ["Sengamedu", "Srinivasan H.", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1804.03958", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba, Shie Mannor", "title": "Interdependent Gibbs Samplers", "comments": "Added a reference to a previous work which considered a very similar\n  algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling, as a model learning method, is known to produce the most\naccurate results available in a variety of domains, and is a de facto standard\nin these domains. Yet, it is also well known that Gibbs random walks usually\nhave bottlenecks, sometimes termed \"local maxima\", and thus samplers often\nreturn suboptimal solutions. In this paper we introduce a variation of the\nGibbs sampler which yields high likelihood solutions significantly more often\nthan the regular Gibbs sampler.\n  Specifically, we show that combining multiple samplers, with certain\ndependence (coupling) between them, results in higher likelihood solutions.\nThis side-steps the well known issue of identifiability, which has been the\nobstacle to combining samplers in previous work. We evaluate the approach on a\nLatent Dirichlet Allocation model, and also on HMM's, where precise computation\nof likelihoods and comparisons to the standard EM algorithm are possible.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 12:38:50 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 08:47:13 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""]]}, {"id": "1804.03980", "submitter": "Kris Cao", "authors": "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls,\n  Stephen Clark", "title": "Emergent Communication through Negotiation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:48:08 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Cao", "Kris", ""], ["Lazaridou", "Angeliki", ""], ["Lanctot", "Marc", ""], ["Leibo", "Joel Z", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03984", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls, Stephen Clark", "title": "Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input", "comments": "To appear at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:51:19 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Hermann", "Karl Moritz", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03987", "submitter": "Husheng Li", "authors": "Husheng Li", "title": "Analysis on the Nonlinear Dynamics of Deep Neural Networks: Topological\n  Entropy and Chaos", "comments": "17 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical explanation for deep neural network (DNN) is still an open\nproblem. In this paper DNN is considered as a discrete-time dynamical system\ndue to its layered structure. The complexity provided by the nonlinearity in\nthe dynamics is analyzed in terms of topological entropy and chaos\ncharacterized by Lyapunov exponents. The properties revealed for the dynamics\nof DNN are applied to analyze the corresponding capabilities of classification\nand generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:51:20 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 20:21:00 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 03:51:54 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Li", "Husheng", ""]]}, {"id": "1804.04012", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Lior Fox and Yonatan Loewenstein", "title": "DORA The Explorer: Directed Outreaching Reinforcement Action-Selection", "comments": "Final version for ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a fundamental aspect of Reinforcement Learning, typically\nimplemented using stochastic action-selection. Exploration, however, can be\nmore efficient if directed toward gaining new world knowledge. Visit-counters\nhave been proven useful both in practice and in theory for directed\nexploration. However, a major limitation of counters is their locality. While\nthere are a few model-based solutions to this shortcoming, a model-free\napproach is still missing. We propose $E$-values, a generalization of counters\nthat can be used to evaluate the propagating exploratory value over\nstate-action trajectories. We compare our approach to commonly used RL\ntechniques, and show that using $E$-values improves learning and performance\nover traditional counters. We also show how our method can be implemented with\nfunction approximation to efficiently learn continuous MDPs. We demonstrate\nthis by showing that our approach surpasses state of the art performance in the\nFreeway Atari 2600 game.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 14:21:53 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Choshen", "Leshem", ""], ["Fox", "Lior", ""], ["Loewenstein", "Yonatan", ""]]}, {"id": "1804.04031", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Sudarshan Raghunathan, Akshaya Annavajhala, Danil\n  Kirsanov, Eduardo de Leon, Eli Barzilay, Ilya Matiach, Joe Davison, Maureen\n  Busch, Miruna Oprescu, Ratan Sur, Roope Astala, Tong Wen, ChangYoung Park", "title": "Flexible and Scalable Deep Learning with MMLSpark", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 82 (2017) 11-22, 4th\n  International Conference on Predictive Applications and APIs", "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we detail a novel open source library, called MMLSpark, that\ncombines the flexible deep learning library Cognitive Toolkit, with the\ndistributed computing framework Apache Spark. To achieve this, we have\ncontributed Java Language bindings to the Cognitive Toolkit, and added several\nnew components to the Spark ecosystem. In addition, we also integrate the\npopular image processing library OpenCV with Spark, and present a tool for the\nautomated generation of PySpark wrappers from any SparkML estimator and use\nthis tool to expose all work to the PySpark ecosystem. Finally, we provide a\nlarge library of tools for working and developing within the Spark ecosystem.\nWe apply this work to the automated classification of Snow Leopards from camera\ntrap images, and provide an end to end solution for the non-profit conservation\norganization, the Snow Leopard Trust.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 14:55:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hamilton", "Mark", ""], ["Raghunathan", "Sudarshan", ""], ["Annavajhala", "Akshaya", ""], ["Kirsanov", "Danil", ""], ["de Leon", "Eduardo", ""], ["Barzilay", "Eli", ""], ["Matiach", "Ilya", ""], ["Davison", "Joe", ""], ["Busch", "Maureen", ""], ["Oprescu", "Miruna", ""], ["Sur", "Ratan", ""], ["Astala", "Roope", ""], ["Wen", "Tong", ""], ["Park", "ChangYoung", ""]]}, {"id": "1804.04048", "submitter": "Chao Gan", "authors": "Chao Gan, Ruida Zhou, Jing Yang and Cong Shen", "title": "Cost-Aware Learning and Optimization for Opportunistic Spectrum Access", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate cost-aware joint learning and optimization for\nmulti-channel opportunistic spectrum access in a cognitive radio system. We\ninvestigate a discrete time model where the time axis is partitioned into\nframes. Each frame consists of a sensing phase, followed by a transmission\nphase. During the sensing phase, the user is able to sense a subset of channels\nsequentially before it decides to use one of them in the following transmission\nphase. We assume the channel states alternate between busy and idle according\nto independent Bernoulli random processes from frame to frame. To capture the\ninherent uncertainty in channel sensing, we assume the reward of each\ntransmission when the channel is idle is a random variable. We also associate\nrandom costs with sensing and transmission actions. Our objective is to\nunderstand how the costs and reward of the actions would affect the optimal\nbehavior of the user in both offline and online settings, and design the\ncorresponding opportunistic spectrum access strategies to maximize the expected\ncumulative net reward (i.e., reward-minus-cost). We start with an offline\nsetting where the statistics of the channel status, costs and reward are known\nbeforehand. We show that the the optimal policy exhibits a recursive double\nthreshold structure, and the user needs to compare the channel statistics with\nthose thresholds sequentially in order to decide its actions. With such\ninsights, we then study the online setting, where the statistical information\nof the channels, costs and reward are unknown a priori. We judiciously balance\nexploration and exploitation, and show that the cumulative regret scales in\nO(log T). We also establish a matched lower bound, which implies that our\nonline algorithm is order-optimal. Simulation results corroborate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 15:28:07 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Gan", "Chao", ""], ["Zhou", "Ruida", ""], ["Yang", "Jing", ""], ["Shen", "Cong", ""]]}, {"id": "1804.04053", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Mohammad Ali Zamani, Cornelius Weber, Sven Magg, Stefan\n  Wermter", "title": "EmoRL: Continuous Acoustic Emotion Classification using Deep\n  Reinforcement Learning", "comments": "Accepted to the IEEE International Conference on Robotics and\n  Automation (ICRA'18), Brisbane, Australia, May 21-25, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustically expressed emotions can make communication with a robot more\nefficient. Detecting emotions like anger could provide a clue for the robot\nindicating unsafe/undesired situations. Recently, several deep neural\nnetwork-based models have been proposed which establish new state-of-the-art\nresults in affective state evaluation. These models typically start processing\nat the end of each utterance, which not only requires a mechanism to detect the\nend of an utterance but also makes it difficult to use them in a real-time\ncommunication scenario, e.g. human-robot interaction. We propose the EmoRL\nmodel that triggers an emotion classification as soon as it gains enough\nconfidence while listening to a person speaking. As a result, we minimize the\nneed for segmenting the audio signal for classification and achieve lower\nlatency as the audio signal is processed incrementally. The method is\ncompetitive with the accuracy of a strong baseline model, while allowing much\nearlier prediction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:21:11 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lakomkin", "Egor", ""], ["Zamani", "Mohammad Ali", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1804.04058", "submitter": "Rizwan Sadiq", "authors": "Rizwan Sadiq, Mohsin Khan", "title": "Analyzing Self-Driving Cars on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies users' perception regarding a controversial product,\nnamely self-driving (autonomous) cars. To find people's opinion regarding this\nnew technology, we used an annotated Twitter dataset, and extracted the topics\nin positive and negative tweets using an unsupervised, probabilistic model\nknown as topic modeling. We later used the topics, as well as linguist and\nTwitter specific features to classify the sentiment of the tweets. Regarding\nthe opinions, the result of our analysis shows that people are optimistic and\nexcited about the future technology, but at the same time they find it\ndangerous and not reliable. For the classification task, we found Twitter\nspecific features, such as hashtags as well as linguistic features such as\nemphatic words among top attributes in classifying the sentiment of the tweets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:31:44 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Sadiq", "Rizwan", ""], ["Khan", "Mohsin", ""]]}, {"id": "1804.04076", "submitter": "Faraz Saeedan", "authors": "Faraz Saeedan, Nicolas Weber, Michael Goesele, Stefan Roth", "title": "Detail-Preserving Pooling in Deep Networks", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most convolutional neural networks use some method for gradually downscaling\nthe size of the hidden layers. This is commonly referred to as pooling, and is\napplied to reduce the number of parameters, improve invariance to certain\ndistortions, and increase the receptive field size. Since pooling by nature is\na lossy process, it is crucial that each such layer maintains the portion of\nthe activations that is most important for the network's discriminability. Yet,\nsimple maximization or averaging over blocks, max or average pooling, or plain\ndownsampling in the form of strided convolutions are the standard. In this\npaper, we aim to leverage recent results on image downscaling for the purposes\nof deep learning. Inspired by the human visual system, which focuses on local\nspatial changes, we propose detail-preserving pooling (DPP), an adaptive\npooling method that magnifies spatial changes and preserves important\nstructural detail. Importantly, its parameters can be learned jointly with the\nrest of the network. We analyze some of its theoretical properties and show its\nempirical benefits on several datasets and networks, where DPP consistently\noutperforms previous pooling approaches.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 16:28:11 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Saeedan", "Faraz", ""], ["Weber", "Nicolas", ""], ["Goesele", "Michael", ""], ["Roth", "Stefan", ""]]}, {"id": "1804.04087", "submitter": "Marco Lippi", "authors": "Marco Lippi, Marcelo A Montemurro, Mirko Degli Esposti, Giampaolo\n  Cristadoro", "title": "Natural Language Statistical Features of LSTM-generated Texts", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2890970", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) networks have recently shown remarkable\nperformance in several tasks dealing with natural language generation, such as\nimage captioning or poetry composition. Yet, only few works have analyzed text\ngenerated by LSTMs in order to quantitatively evaluate to which extent such\nartificial texts resemble those generated by humans. We compared the\nstatistical structure of LSTM-generated language to that of written natural\nlanguage, and to those produced by Markov models of various orders. In\nparticular, we characterized the statistical structure of language by assessing\nword-frequency statistics, long-range correlations, and entropy measures. Our\nmain finding is that while both LSTM and Markov-generated texts can exhibit\nfeatures similar to real ones in their word-frequency statistics and entropy\nmeasures, LSTM-texts are shown to reproduce long-range correlations at scales\ncomparable to those found in natural language. Moreover, for LSTM networks a\ntemperature-like parameter controlling the generation process shows an optimal\nvalue---for which the produced texts are closest to real language---consistent\nacross all the different statistical features investigated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:17:36 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 09:14:28 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Lippi", "Marco", ""], ["Montemurro", "Marcelo A", ""], ["Esposti", "Mirko Degli", ""], ["Cristadoro", "Giampaolo", ""]]}, {"id": "1804.04118", "submitter": "Eshed Ohn-Bar", "authors": "Eshed Ohn-Bar and Kris Kitani and Chieko Asakawa", "title": "Personalized Dynamics Models for Adaptive Assistive Navigation Systems", "comments": "Oral Presentation in 2nd Conference on Robot Learning (CoRL, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an assistive system that guides visually impaired users through\nspeech and haptic feedback to their destination. Existing robotic and\nubiquitous navigation technologies (e.g., portable, ground, or wearable\nsystems) often operate in a generic, user-agnostic manner. However, to minimize\nconfusion and navigation errors, our real-world analysis reveals a crucial need\nto adapt the instructional guidance across different end-users with diverse\nmobility skills. To address this practical issue in scalable system design, we\npropose a novel model-based reinforcement learning framework for personalizing\nthe system-user interaction experience. When incrementally adapting the system\nto new users, we propose to use a weighted experts model for addressing\ndata-efficiency limitations in transfer learning with deep models. A real-world\ndataset of navigation by blind users is used to show that the proposed approach\nallows for (1) more accurate long-term human behavior prediction (up to 20\nseconds into the future) through improved reasoning over personal mobility\ncharacteristics, interaction with surrounding obstacles, and the current\nnavigation goal, and (2) quick adaptation at the onset of learning, when data\nis limited.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:55:00 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 12:20:33 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ohn-Bar", "Eshed", ""], ["Kitani", "Kris", ""], ["Asakawa", "Chieko", ""]]}, {"id": "1804.04159", "submitter": "Noah Apthorpe", "authors": "Rohan Doshi, Noah Apthorpe, Nick Feamster", "title": "Machine Learning DDoS Detection for Consumer Internet of Things Devices", "comments": "7 pages, 3 figures, 3 tables, appears in the 2018 Workshop on Deep\n  Learning and Security (DLS '18)", "journal-ref": null, "doi": "10.1109/SPW.2018.00013", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of Internet of Things (IoT) devices are connecting to\nthe Internet, yet many of these devices are fundamentally insecure, exposing\nthe Internet to a variety of attacks. Botnets such as Mirai have used insecure\nconsumer IoT devices to conduct distributed denial of service (DDoS) attacks on\ncritical Internet infrastructure. This motivates the development of new\ntechniques to automatically detect consumer IoT attack traffic. In this paper,\nwe demonstrate that using IoT-specific network behaviors (e.g. limited number\nof endpoints and regular time intervals between packets) to inform feature\nselection can result in high accuracy DDoS detection in IoT network traffic\nwith a variety of machine learning algorithms, including neural networks. These\nresults indicate that home gateway routers or other network middleboxes could\nautomatically detect local IoT device sources of DDoS attacks using low-cost\nmachine learning algorithms and traffic data that is flow-based and\nprotocol-agnostic.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 18:32:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Doshi", "Rohan", ""], ["Apthorpe", "Noah", ""], ["Feamster", "Nick", ""]]}, {"id": "1804.04168", "submitter": "JinGuo Liu", "authors": "Jin-Guo Liu and Lei Wang", "title": "Differentiable Learning of Quantum Circuit Born Machine", "comments": "9 pages, 7 figures, Github page for code\n  https://github.com/GiggleLiu/QuantumCircuitBornMachine", "journal-ref": "Phys. Rev. A 98, 062324 (2018)", "doi": "10.1103/PhysRevA.98.062324", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum circuit Born machines are generative models which represent the\nprobability distribution of classical dataset as quantum pure states.\nComputational complexity considerations of the quantum sampling problem suggest\nthat the quantum circuits exhibit stronger expressibility compared to classical\nneural networks. One can efficiently draw samples from the quantum circuits via\nprojective measurements on qubits. However, similar to the leading implicit\ngenerative models in deep learning, such as the generative adversarial\nnetworks, the quantum circuits cannot provide the likelihood of the generated\nsamples, which poses a challenge to the training. We devise an efficient\ngradient-based learning algorithm for the quantum circuit Born machine by\nminimizing the kerneled maximum mean discrepancy loss. We simulated generative\nmodeling of the Bars-and-Stripes dataset and Gaussian mixture distributions\nusing deep quantum circuits. Our experiments show the importance of circuit\ndepth and gradient-based optimization algorithm. The proposed learning\nalgorithm is runnable on near-term quantum device and can exhibit quantum\nadvantages for generative modeling.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:01:11 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Liu", "Jin-Guo", ""], ["Wang", "Lei", ""]]}, {"id": "1804.04171", "submitter": "Christoph H. Lampert", "authors": "R\\'emy Sun and Christoph H. Lampert", "title": "KS(conf ): A Light-Weight Test if a ConvNet Operates Outside of Its\n  Specifications", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-12939-2_18", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision systems for automatic image categorization have become\naccurate and reliable enough that they can run continuously for days or even\nyears as components of real-world commercial applications. A major open problem\nin this context, however, is quality control. Good classification performance\ncan only be expected if systems run under the specific conditions, in\nparticular data distributions, that they were trained for. Surprisingly, none\nof the currently used deep network architectures has a built-in functionality\nthat could detect if a network operates on data from a distribution that it was\nnot trained for and potentially trigger a warning to the human users. In this\nwork, we describe KS(conf), a procedure for detecting such outside of the\nspecifications operation. Building on statistical insights, its main step is\nthe applications of a classical Kolmogorov-Smirnov test to the distribution of\npredicted confidence values. We show by extensive experiments using ImageNet,\nAwA2 and DAVIS data on a variety of ConvNets architectures that KS(conf)\nreliably detects out-of-specs situations. It furthermore has a number of\nproperties that make it an excellent candidate for practical deployment: it is\neasy to implement, adds almost no overhead to the system, works with all\nnetworks, including pretrained ones, and requires no a priori knowledge about\nhow the data distribution could change.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:05:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sun", "R\u00e9my", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1804.04176", "submitter": "Zhiwei Xu", "authors": "Yonghong Tian, Zeyu Li, Zhiwei Xu, Xuying Meng, and Bing Zheng", "title": "Peeking the Impact of Points of Interests on Didi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the online car-hailing service, Didi, has emerged as a leader in\nthe sharing economy. Used by passengers and drivers extensive, it becomes\nincreasingly important for the car-hailing service providers to minimize the\nwaiting time of passengers and optimize the vehicle utilization, thus to\nimprove the overall user experience. Therefore, the supply-demand estimation is\nan indispensable ingredient of an efficient online car-hailing service. To\nimprove the accuracy of the estimation results, we analyze the implicit\nrelationships between the points of Interest (POI) and the supply-demand gap in\nthis paper. The different categories of POIs have positive or negative effects\non the estimation, we propose a POI selection scheme and incorporate it into\nXGBoost [1] to achieve more accurate estimation results. Our experiment\ndemonstrates our method provides more accurate estimation results and more\nstable estimation results than the existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 02:07:03 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Tian", "Yonghong", ""], ["Li", "Zeyu", ""], ["Xu", "Zhiwei", ""], ["Meng", "Xuying", ""], ["Zheng", "Bing", ""]]}, {"id": "1804.04205", "submitter": "Ziyi Zhao", "authors": "Ziyi Zhao, Krittaphat Pugdeethosapol, Sheng Lin, Zhe Li, Caiwen Ding,\n  Yanzhi Wang, Qinru Qiu", "title": "Learning Topics using Semantic Locality", "comments": "International Conference of Pattern Recognition (ICPR) in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:23:23 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhao", "Ziyi", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Lin", "Sheng", ""], ["Li", "Zhe", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""]]}, {"id": "1804.04206", "submitter": "Boheng Zhang", "authors": "Boheng Zhang, Shenglei Huang, Shaohan Hu", "title": "Multi-scale Neural Networks for Retinal Blood Vessels Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing supervised approaches didn't make use of the low-level features\nwhich are actually effective to this task. And another deficiency is that they\ndidn't consider the relation between pixels, which means effective features are\nnot extracted. In this paper, we proposed a novel convolutional neural network\nwhich make sufficient use of low-level features together with high-level\nfeatures and involves atrous convolution to get multi-scale features which\nshould be considered as effective features. Our model is tested on three\nstandard benchmarks - DRIVE, STARE, and CHASE databases. The results presents\nthat our model significantly outperforms existing approaches in terms of\naccuracy, sensitivity, specificity, the area under the ROC curve and the\nhighest prediction speed. Our work provides evidence of the power of wide and\ndeep neural networks in retinal blood vessels segmentation task which could be\napplied on other medical images tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:25:36 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhang", "Boheng", ""], ["Huang", "Shenglei", ""], ["Hu", "Shaohan", ""]]}, {"id": "1804.04212", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Florian Lesaint, Jimena Royo-Letelier", "title": "Word2Vec applied to Recommendation: Hyperparameters Matter", "comments": "This paper is published on the 12th ACM Conference on Recommender\n  Systems, Vancouver, Canada, 2nd-7th October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip-gram with negative sampling, a popular variant of Word2vec originally\ndesigned and tuned to create word embeddings for Natural Language Processing,\nhas been used to create item embeddings with successful applications in\nrecommendation. While these fields do not share the same type of data, neither\nevaluate on the same tasks, recommendation applications tend to use the same\nalready tuned hyperparameters values, even if optimal hyperparameters values\nare often known to be data and task dependent. We thus investigate the marginal\nimportance of each hyperparameter in a recommendation setting through large\nhyperparameter grid searches on various datasets. Results reveal that\noptimizing neglected hyperparameters, namely negative sampling distribution,\nnumber of epochs, subsampling parameter and window-size, significantly improves\nperformance on a recommendation task, and can increase it by an order of\nmagnitude. Importantly, we find that optimal hyperparameters configurations for\nNatural Language Processing tasks and Recommendation tasks are noticeably\ndifferent.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:37:35 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 19:30:18 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 15:16:08 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesaint", "Florian", ""], ["Royo-Letelier", "Jimena", ""]]}, {"id": "1804.04235", "submitter": "Noam Shazeer", "authors": "Noam Shazeer and Mitchell Stern", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:42:32 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Shazeer", "Noam", ""], ["Stern", "Mitchell", ""]]}, {"id": "1804.04241", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde and Ulas Bagci", "title": "Capsules for Object Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have shown remarkable results over the\nlast several years for a wide range of computer vision tasks. A new\narchitecture recently introduced by Sabour et al., referred to as a capsule\nnetworks with dynamic routing, has shown great initial results for digit\nrecognition and small image classification. The success of capsule networks\nlies in their ability to preserve more information about the input by replacing\nmax-pooling layers with convolutional strides and dynamic routing, allowing for\npreservation of part-whole relationships in the data. This preservation of the\ninput is demonstrated by reconstructing the input from the output capsule\nvectors. Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. We extend the idea of\nconvolutional capsules with locally-connected routing and propose the concept\nof deconvolutional capsules. Further, we extend the masked reconstruction to\nreconstruct the positive input class. The proposed\nconvolutional-deconvolutional capsule network, called SegCaps, shows strong\nresults for the task of object segmentation with substantial decrease in\nparameter space. As an example application, we applied the proposed SegCaps to\nsegment pathological lungs from low dose CT scans and compared its accuracy and\nefficiency with other U-Net-based architectures. SegCaps is able to handle\nlarge image sizes (512 x 512) as opposed to baseline capsules (typically less\nthan 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net\narchitecture by 95.4% while still providing a better segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:57:57 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["LaLonde", "Rodney", ""], ["Bagci", "Ulas", ""]]}, {"id": "1804.04272", "submitter": "Lars Ruthotto", "authors": "Lars Ruthotto and Eldad Haber", "title": "Deep Neural Networks Motivated by Partial Differential Equations", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) are indispensable for modeling many\nphysical phenomena and also commonly used for solving image processing tasks.\nIn the latter area, PDE-based approaches interpret image data as\ndiscretizations of multivariate functions and the output of image processing\nalgorithms as solutions to certain PDEs. Posing image processing problems in\nthe infinite dimensional setting provides powerful tools for their analysis and\nsolution. Over the last few decades, the reinterpretation of classical image\nprocessing problems through the PDE lens has been creating multiple celebrated\napproaches that benefit a vast area of tasks including image segmentation,\ndenoising, registration, and reconstruction.\n  In this paper, we establish a new PDE-interpretation of a class of deep\nconvolutional neural networks (CNN) that are commonly used to learn from\nspeech, image, and video data. Our interpretation includes convolution residual\nneural networks (ResNet), which are among the most promising approaches for\ntasks such as image classification having improved the state-of-the-art\nperformance in prestigious benchmark challenges. Despite their recent\nsuccesses, deep ResNets still face some critical challenges associated with\ntheir design, immense computational costs and memory requirements, and lack of\nunderstanding of their reasoning.\n  Guided by well-established PDE theory, we derive three new ResNet\narchitectures that fall into two new classes: parabolic and hyperbolic CNNs. We\ndemonstrate how PDE theory can provide new insights and algorithms for deep\nlearning and demonstrate the competitiveness of three new CNN architectures\nusing numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 01:40:55 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 21:51:10 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ruthotto", "Lars", ""], ["Haber", "Eldad", ""]]}, {"id": "1804.04299", "submitter": "Wai Hoh Tang", "authors": "Wai Hoh Tang and Adrian R\\\"ollin", "title": "Model identification for ARMA time series through convolutional neural\n  networks", "comments": "17 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use convolutional neural networks to address the problem of\nmodel identification for autoregressive moving average time series models. We\ncompare the performance of several neural network architectures, trained on\nsimulated time series, with likelihood based methods, in particular the Akaike\nand Bayesian information criteria. We find that our neural networks can\nsignificantly outperform these likelihood based methods in terms of accuracy\nand, by orders of magnitude, in terms of speed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 03:33:27 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 03:35:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Tang", "Wai Hoh", ""], ["R\u00f6llin", "Adrian", ""]]}, {"id": "1804.04310", "submitter": "Abiy Tasissa", "authors": "Abiy Tasissa, Rongjie Lai", "title": "Exact Reconstruction of Euclidean Distance Geometry Problem Using\n  Low-rank Matrix Completion", "comments": "28 pages, revised proof of Theorem 1, added proof of form of\n  $H^{-1}$, presentation improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean distance geometry problem arises in a wide variety of\napplications, from determining molecular conformations in computational\nchemistry to localization in sensor networks. When the distance information is\nincomplete, the problem can be formulated as a nuclear norm minimization\nproblem. In this paper, this minimization program is recast as a matrix\ncompletion problem of a low-rank $r$ Gram matrix with respect to a suitable\nbasis. The well known restricted isometry property can not be satisfied in this\nscenario. Instead, a dual basis approach is introduced to theoretically analyze\nthe reconstruction problem. If the Gram matrix satisfies certain coherence\nconditions with parameter $\\nu$, the main result shows that the underlying\nconfiguration of $n$ points can be recovered with very high probability from\n$O(nr\\nu\\log^{2}(n))$ uniformly random samples. Computationally, simple and\nfast algorithms are designed to solve the Euclidean distance geometry problem.\nNumerical tests on different three dimensional data and protein molecules\nvalidate effectiveness and efficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 04:28:06 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 19:33:50 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tasissa", "Abiy", ""], ["Lai", "Rongjie", ""]]}, {"id": "1804.04324", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Eiji Yamamoto, Takashi Nakao, Takuma Akimoto, Hayato\n  Saigo, Kazuya Okamura, Izumi Ojima, Georg Northoff, Hirokazu Hori", "title": "Local reservoir model for choice-based learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an physics.optics q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making based on behavioral and neural observations of living systems\nhas been extensively studied in brain science, psychology, and other\ndisciplines. Decision-making mechanisms have also been experimentally\nimplemented in physical processes, such as single photons and chaotic lasers.\nThe findings of these experiments suggest that there is a certain common basis\nin describing decision making, regardless of its physical realizations. In this\nstudy, we propose a local reservoir model to account for choice-based learning\n(CBL). CBL describes decision consistency as a phenomenon where making a\ncertain decision increases the possibility of making that same decision again\nlater, which has been intensively investigated in neuroscience, psychology,\netc. Our proposed model is inspired by the viewpoint that a decision is\naffected by its local environment, which is referred to as a local reservoir.\nIf the size of the local reservoir is large enough, consecutive decision making\nwill not be affected by previous decisions, thus showing lower degrees of\ndecision consistency in CBL. In contrast, if the size of the local reservoir\ndecreases, a biased distribution occurs within it, which leads to higher\ndegrees of decision consistency in CBL. In this study, an analytical approach\non local reservoirs is presented, as well as several numerical demonstrations.\nFurthermore, a physical architecture for CBL based on single photons is\ndiscussed, and the effects of local reservoirs is numerically demonstrated.\nDecision consistency in human decision-making tasks and in recruiting empirical\ndata are evaluated based on local reservoir. In summary, the proposed local\nreservoir model paves a path toward establishing a foundation for computational\nmechanisms and the systematic analysis of decision making on different levels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:35:14 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Naruse", "Makoto", ""], ["Yamamoto", "Eiji", ""], ["Nakao", "Takashi", ""], ["Akimoto", "Takuma", ""], ["Saigo", "Hayato", ""], ["Okamura", "Kazuya", ""], ["Ojima", "Izumi", ""], ["Northoff", "Georg", ""], ["Hori", "Hirokazu", ""]]}, {"id": "1804.04333", "submitter": "Mingming Gong", "authors": "Mingming Gong, Kun Zhang, Biwei Huang, Clark Glymour, Dacheng Tao,\n  Kayhan Batmanghelich", "title": "Causal Generative Domain Adaptation Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential problem in domain adaptation is to understand and make use of\ndistribution changes across domains. For this purpose, we first propose a\nflexible Generative Domain Adaptation Network (G-DAN) with specific latent\nvariables to capture changes in the generating process of features across\ndomains. By explicitly modeling the changes, one can even generate data in new\ndomains using the generating process with new values for the latent variables\nin G-DAN. In practice, the process to generate all features together may\ninvolve high-dimensional latent variables, requiring dealing with distributions\nin high dimensions and making it difficult to learn domain changes from few\nsource domains. Interestingly, by further making use of the causal\nrepresentation of joint distributions, we then decompose the joint distribution\ninto separate modules, each of which involves different low-dimensional latent\nvariables and can be learned separately, leading to a Causal G-DAN (CG-DAN).\nThis improves both statistical and computational efficiency of the learning\nprocedure. Finally, by matching the feature distribution in the target domain,\nwe can recover the target-domain joint distribution and derive the learning\nmachine for the target domain. We demonstrate the efficacy of both G-DAN and\nCG-DAN in domain generation and cross-domain prediction on both synthetic and\nreal data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 06:10:46 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 21:49:19 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 06:38:11 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Gong", "Mingming", ""], ["Zhang", "Kun", ""], ["Huang", "Biwei", ""], ["Glymour", "Clark", ""], ["Tao", "Dacheng", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1804.04368", "submitter": "Henry Gouk", "authors": "Henry Gouk, Eibe Frank, Bernhard Pfahringer, Michael J. Cree", "title": "Regularisation of Neural Networks by Enforcing Lipschitz Continuity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the effect of explicitly enforcing the Lipschitz continuity of\nneural networks with respect to their inputs. To this end, we provide a simple\ntechnique for computing an upper bound to the Lipschitz constant---for multiple\n$p$-norms---of a feed forward neural network composed of commonly used layer\ntypes. Our technique is then used to formulate training a neural network with a\nbounded Lipschitz constant as a constrained optimisation problem that can be\nsolved using projected stochastic gradient methods. Our evaluation study shows\nthat the performance of the resulting models exceeds that of models trained\nwith other common regularisers. We also provide evidence that the\nhyperparameters are intuitive to tune, demonstrate how the choice of norm for\ncomputing the Lipschitz constant impacts the resulting model, and show that the\nperformance gains provided by our method are particularly noticeable when only\na small amount of training data is available.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:18:30 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 16:53:04 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 16:47:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gouk", "Henry", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Cree", "Michael J.", ""]]}, {"id": "1804.04378", "submitter": "Philippe Wenk", "authors": "Philippe Wenk, Alkis Gotovos, Stefan Bauer, Nico Gorbach, Andreas\n  Krause and Joachim M. Buhmann", "title": "Fast Gaussian Process Based Gradient Matching for Parameter\n  Identification in Systems of Nonlinear ODEs", "comments": "accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter identification and comparison of dynamical systems is a challenging\ntask in many fields. Bayesian approaches based on Gaussian process regression\nover time-series data have been successfully applied to infer the parameters of\na dynamical system without explicitly solving it. While the benefits in\ncomputational cost are well established, a rigorous mathematical framework has\nbeen missing. We offer a novel interpretation which leads to a better\nunderstanding and improvements in state-of-the-art performance in terms of\naccuracy for nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:54:20 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 16:06:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wenk", "Philippe", ""], ["Gotovos", "Alkis", ""], ["Bauer", "Stefan", ""], ["Gorbach", "Nico", ""], ["Krause", "Andreas", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1804.04421", "submitter": "Bruno Ordozgoiti", "authors": "Bruno Ordozgoiti, Alberto Mozo, Jes\\'us Garc\\'ia L\\'opez de Lacalle", "title": "Regularized Greedy Column Subset Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Column Subset Selection Problem provides a natural framework for\nunsupervised feature selection. Despite being a hard combinatorial optimization\nproblem, there exist efficient algorithms that provide good approximations. The\ndrawback of the problem formulation is that it incorporates no form of\nregularization, and is therefore very sensitive to noise when presented with\nscarce data. In this paper we propose a regularized formulation of this\nproblem, and derive a correct greedy algorithm that is similar in efficiency to\nexisting greedy methods for the unregularized problem. We study its adequacy\nfor feature selection and propose suitable formulations. Additionally, we\nderive a lower bound for the error of the proposed problems. Through various\nnumerical experiments on real and synthetic data, we demonstrate the\nsignificantly increased robustness and stability of our method, as well as the\nimproved conditioning of its output, all while remaining efficient for\npractical use.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 10:56:44 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ordozgoiti", "Bruno", ""], ["Mozo", "Alberto", ""], ["de Lacalle", "Jes\u00fas Garc\u00eda L\u00f3pez", ""]]}, {"id": "1804.04435", "submitter": "Jiangchao Yao", "authors": "Jiangchao Yao, Ivor Tsang and Ya Zhang", "title": "Variational Composite Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the latent variable model is challenging in the presence of the\ncomplex data structure or the intractable latent variable. Previous variational\nautoencoders can be low effective due to the straightforward encoder-decoder\nstructure. In this paper, we propose a variational composite autoencoder to\nsidestep this issue by amortizing on top of the hierarchical latent variable\nmodel. The experimental results confirm the advantages of our model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:36:42 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Yao", "Jiangchao", ""], ["Tsang", "Ivor", ""], ["Zhang", "Ya", ""]]}, {"id": "1804.04438", "submitter": "Ari Morcos", "authors": "Avraham Ruderman, Neil C. Rabinowitz, Ari S. Morcos, Daniel Zoran", "title": "Pooling is neither necessary nor sufficient for appropriate deformation\n  stability in CNNs", "comments": "NIPS 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of our core assumptions about how neural networks operate remain\nempirically untested. One common assumption is that convolutional neural\nnetworks need to be stable to small translations and deformations to solve\nimage recognition tasks. For many years, this stability was baked into CNN\narchitectures by incorporating interleaved pooling layers. Recently, however,\ninterleaved pooling has largely been abandoned. This raises a number of\nquestions: Are our intuitions about deformation stability right at all? Is it\nimportant? Is pooling necessary for deformation invariance? If not, how is\ndeformation invariance achieved in its absence? In this work, we rigorously\ntest these questions, and find that deformation stability in convolutional\nnetworks is more nuanced than it first appears: (1) Deformation invariance is\nnot a binary property, but rather that different tasks require different\ndegrees of deformation stability at different layers. (2) Deformation stability\nis not a fixed property of a network and is heavily adjusted over the course of\ntraining, largely through the smoothness of the convolutional filters. (3)\nInterleaved pooling layers are neither necessary nor sufficient for achieving\nthe optimal form of deformation stability for natural image classification. (4)\nPooling confers too much deformation stability for image classification at\ninitialization, and during training, networks have to learn to counteract this\ninductive bias. Together, these findings provide new insights into the role of\ninterleaved pooling and deformation invariance in CNNs, and demonstrate the\nimportance of rigorous empirical testing of even our most basic assumptions\nabout the working of neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:44:05 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 13:03:50 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ruderman", "Avraham", ""], ["Rabinowitz", "Neil C.", ""], ["Morcos", "Ari S.", ""], ["Zoran", "Daniel", ""]]}, {"id": "1804.04440", "submitter": "Neerav Karani", "authors": "Lin Zhang, Neerav Karani, Christine Tanner, Ender Konukoglu", "title": "Temporal Interpolation via Motion Field Prediction", "comments": "Submitted to 1st Conference on Medical Imaging with Deep Learning\n  (MIDL 2018), Amsterdam, The Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Navigated 2D multi-slice dynamic Magnetic Resonance (MR) imaging enables high\ncontrast 4D MR imaging during free breathing and provides in-vivo observations\nfor treatment planning and guidance. Navigator slices are vital for\nretrospective stacking of 2D data slices in this method. However, they also\nprolong the acquisition sessions. Temporal interpolation of navigator slices an\nbe used to reduce the number of navigator acquisitions without degrading\nspecificity in stacking. In this work, we propose a convolutional neural\nnetwork (CNN) based method for temporal interpolation via motion field\nprediction. The proposed formulation incorporates the prior knowledge that a\nmotion field underlies changes in the image intensities over time. Previous\napproaches that interpolate directly in the intensity space are prone to\nproduce blurry images or even remove structures in the images. Our method\navoids such problems and faithfully preserves the information in the image.\nFurther, an important advantage of our formulation is that it provides an\nunsupervised estimation of bi-directional motion fields. We show that these\nmotion fields can be used to halve the number of registrations required during\n4D reconstruction, thus substantially reducing the reconstruction time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:44:55 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhang", "Lin", ""], ["Karani", "Neerav", ""], ["Tanner", "Christine", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1804.04448", "submitter": "Twan van Laarhoven", "authors": "Jeroen Manders, Twan van Laarhoven, Elena Marchiori", "title": "Adversarial Alignment of Class Prediction Uncertainties for Domain\n  Adaptation", "comments": "To appear in ICPRAM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unsupervised domain adaptation: given labelled examples from a\nsource domain and unlabelled examples from a related target domain, the goal is\nto infer the labels of target examples. Under the assumption that features from\npre-trained deep neural networks are transferable across related domains,\ndomain adaptation reduces to aligning source and target domain at class\nprediction uncertainty level. We tackle this problem by introducing a method\nbased on adversarial learning which forces the label uncertainty predictions on\nthe target domain to be indistinguishable from those on the source domain.\nPre-trained deep neural networks are used to generate deep features having high\ntransferability across related domains. We perform an extensive experimental\nanalysis of the proposed method over a wide set of publicly available\npre-trained deep neural networks. Results of our experiments on domain\nadaptation tasks for image classification show that class prediction\nuncertainty alignment with features extracted from pre-trained deep neural\nnetworks provides an efficient, robust and effective method for domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:56:42 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 20:13:07 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Manders", "Jeroen", ""], ["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1804.04452", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Constantin A. Rothkopf, Frank J\\\"akel", "title": "Solving Bongard Problems with a Visual Language and Pragmatic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 50 years ago Bongard introduced 100 visual concept learning\nproblems as a testbed for intelligent vision systems. These problems are now\nknown as Bongard problems. Although they are well known in the cognitive\nscience and AI communities only moderate progress has been made towards\nbuilding systems that can solve a substantial subset of them. In the system\npresented here, visual features are extracted through image processing and then\ntranslated into a symbolic visual vocabulary. We introduce a formal language\nthat allows representing complex visual concepts based on this vocabulary.\nUsing this language and Bayesian inference, complex visual concepts can be\ninduced from the examples that are provided in each Bongard problem. Contrary\nto other concept learning problems the examples from which concepts are induced\nare not random in Bongard problems, instead they are carefully chosen to\ncommunicate the concept, hence requiring pragmatic reasoning. Taking pragmatic\nreasoning into account we find good agreement between the concepts with high\nposterior probability and the solutions formulated by Bongard himself. While\nthis approach is far from solving all Bongard problems, it solves the biggest\nfraction yet.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:05:28 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Depeweg", "Stefan", ""], ["Rothkopf", "Constantin A.", ""], ["J\u00e4kel", "Frank", ""]]}, {"id": "1804.04458", "submitter": "Daniel Worrall", "authors": "Daniel Worrall and Gabriel Brostow", "title": "CubeNet: Equivariance to 3D Rotation and Translation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:14:18 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Worrall", "Daniel", ""], ["Brostow", "Gabriel", ""]]}, {"id": "1804.04503", "submitter": "Daniel Alabi", "authors": "Daniel Alabi, Nicole Immorlica, Adam Tauman Kalai", "title": "Unleashing Linear Optimizers for Group-Fair Learning and Optimization", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most systems and learning algorithms optimize average performance or average\nloss -- one reason being computational complexity. However, many objectives of\npractical interest are more complex than simply average loss. This arises, for\nexample, when balancing performance or loss with fairness across people. We\nprove that, from a computational perspective, optimizing arbitrary objectives\nthat take into account performance over a small number of groups is not\nsignificantly harder to optimize than average performance. Our main result is a\npolynomial-time reduction that uses a linear optimizer to optimize an arbitrary\n(Lipschitz continuous) function of performance over a (constant) number of\npossibly-overlapping groups. This includes fairness objectives over small\nnumbers of groups, and we further point out that other existing notions of\nfairness such as individual fairness can be cast as convex optimization and\nhence more standard convex techniques can be used. Beyond learning, our\napproach applies to multi-objective optimization, more generally.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:51:07 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 16:01:44 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Alabi", "Daniel", ""], ["Immorlica", "Nicole", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1804.04512", "submitter": "Baptiste Wicht", "authors": "Baptiste Wicht and Jean Hennebert and Andreas Fischer", "title": "DLL: A Blazing Fast Deep Neural Network Library", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning Library (DLL) is a new library for machine learning with deep\nneural networks that focuses on speed. It supports feed-forward neural networks\nsuch as fully-connected Artificial Neural Networks (ANNs) and Convolutional\nNeural Networks (CNNs). It also has very comprehensive support for Restricted\nBoltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this\nwork was to propose and evaluate novel software engineering strategies with\npotential to accelerate runtime for training and inference. Such strategies are\nmostly independent of the underlying deep learning algorithms. On three\ndifferent datasets and for four different neural network models, we compared\nDLL to five popular deep learning frameworks. Experimentally, it is shown that\nthe proposed framework is systematically and significantly faster on CPU and\nGPU. In terms of classification performance, similar accuracies as the other\nframeworks are reported.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:56:07 GMT"}], "update_date": "2018-04-15", "authors_parsed": [["Wicht", "Baptiste", ""], ["Hennebert", "Jean", ""], ["Fischer", "Andreas", ""]]}, {"id": "1804.04529", "submitter": "Panayotis Mertikopoulos", "authors": "E. Veronica Belmega, Panayotis Mertikopoulos, Romain Negrel, Luca\n  Sanguinetti", "title": "Online convex optimization and no-regret learning: Algorithms,\n  guarantees and applications", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by the enthusiasm surrounding the \"Big Data\" paradigm, the\nmathematical and algorithmic tools of online optimization have found widespread\nuse in problems where the trade-off between data exploration and exploitation\nplays a predominant role. This trade-off is of particular importance to several\nbranches and applications of signal processing, such as data mining,\nstatistical inference, multimedia indexing and wireless communications (to name\nbut a few). With this in mind, the aim of this tutorial paper is to provide a\ngentle introduction to online optimization and learning algorithms that are\nasymptotically optimal in hindsight - i.e., they approach the performance of a\nvirtual algorithm with unlimited computational power and full knowledge of the\nfuture, a property known as no-regret. Particular attention is devoted to\nidentifying the algorithms' theoretical performance guarantees and to establish\nlinks with classic optimization paradigms (both static and stochastic). To\nallow a better understanding of this toolbox, we provide several examples\nthroughout the tutorial ranging from metric learning to wireless resource\nallocation problems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 14:22:35 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Belmega", "E. Veronica", ""], ["Mertikopoulos", "Panayotis", ""], ["Negrel", "Romain", ""], ["Sanguinetti", "Luca", ""]]}, {"id": "1804.04566", "submitter": "Carlo Vittorio Cannistraci", "authors": "Carlo Vittorio Cannistraci and Alessandro Muscoloni", "title": "Latent Geometry Inspired Graph Dissimilarities Enhance Affinity\n  Propagation Community Detection in Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affinity propagation is one of the most effective unsupervised pattern\nrecognition algorithms for data clustering in high-dimensional feature space.\nHowever, the numerous attempts to test its performance for community detection\nin complex networks have been attaining results very far from the state of the\nart methods such as Infomap and Louvain. Yet, all these studies agreed that the\ncrucial problem is to convert the unweighted network topology in a\n'smart-enough' node dissimilarity matrix that is able to properly address the\nmessage passing procedure behind affinity propagation clustering. Here we\nintroduce a conceptual innovation and we discuss how to leverage network latent\ngeometry notions in order to design dissimilarity matrices for affinity\npropagation community detection. Our results demonstrate that the latent\ngeometry inspired dissimilarity measures we design bring affinity propagation\nto equal or outperform current state of the art methods for community\ndetection. These findings are solidly proven considering both synthetic\n'realistic' networks (with known ground-truth communities) and real networks\n(with community metadata), even when the data structure is corrupted by noise\nartificially induced by missing or spurious connectivity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 15:23:39 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 13:55:56 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Cannistraci", "Carlo Vittorio", ""], ["Muscoloni", "Alessandro", ""]]}, {"id": "1804.04577", "submitter": "Dimitri Bertsekas", "authors": "Dimitri P. Bertsekas", "title": "Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and\n  Some New Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss policy iteration methods for approximate solution of\na finite-state discounted Markov decision problem, with a focus on\nfeature-based aggregation methods and their connection with deep reinforcement\nlearning schemes. We introduce features of the states of the original problem,\nand we formulate a smaller \"aggregate\" Markov decision problem, whose states\nrelate to the features. We discuss properties and possible implementations of\nthis type of aggregation, including a new approach to approximate policy\niteration. In this approach the policy improvement operation combines\nfeature-based aggregation with feature construction using deep neural networks\nor other calculations. We argue that the cost function of a policy may be\napproximated much more accurately by the nonlinear function of the features\nprovided by aggregation, than by the linear function of the features provided\nby neural network-based reinforcement learning, thereby potentially leading to\nmore effective policy improvement.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 15:46:12 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 14:38:08 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 22:41:34 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Bertsekas", "Dimitri P.", ""]]}, {"id": "1804.04610", "submitter": "Jiajun Wu", "authors": "Xingyuan Sun, Jiajun Wu, Xiuming Zhang, Zhoutong Zhang, Chengkai\n  Zhang, Tianfan Xue, Joshua B. Tenenbaum, William T. Freeman", "title": "Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling", "comments": "CVPR 2018. The first two authors contributed equally to this work.\n  Project page: http://pix3d.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study 3D shape modeling from a single image and make contributions to it\nin three aspects. First, we present Pix3D, a large-scale benchmark of diverse\nimage-shape pairs with pixel-level 2D-3D alignment. Pix3D has wide applications\nin shape-related tasks including reconstruction, retrieval, viewpoint\nestimation, etc. Building such a large-scale dataset, however, is highly\nchallenging; existing datasets either contain only synthetic data, or lack\nprecise alignment between 2D images and 3D shapes, or only have a small number\nof images. Second, we calibrate the evaluation criteria for 3D shape\nreconstruction through behavioral studies, and use them to objectively and\nsystematically benchmark cutting-edge reconstruction algorithms on Pix3D.\nThird, we design a novel model that simultaneously performs 3D reconstruction\nand pose estimation; our multi-task learning approach achieves state-of-the-art\nperformance on both tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:30:39 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Sun", "Xingyuan", ""], ["Wu", "Jiajun", ""], ["Zhang", "Xiuming", ""], ["Zhang", "Zhoutong", ""], ["Zhang", "Chengkai", ""], ["Xue", "Tianfan", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""]]}, {"id": "1804.04612", "submitter": "Saksham Kukreja", "authors": "Saksham Kukreja", "title": "A Comprehensive Study on the Applications of Machine Learning for the\n  Medical Diagnosis and Prognosis of Asthma", "comments": "27 pages. arXiv admin note: text overlap with arXiv:1505.01345 by\n  other authors without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimated 300 million people worldwide suffer from asthma, and this number\nis expected to increase to 400 million by 2025. Approximately 250,000 people\ndie prematurely each year from asthma out of which, almost all deaths are\navoidable. Most of these deaths occur because the patients are unaware of their\nasthmatic morbidity. If detected early, asthmatic mortality rate can be reduced\nby 78%, provided that the patients carry appropriate medication for the same\nand/or are in lose vicinity to medical equipment like nebulizers. This study\nfocuses on the development and valuation of algorithms to diagnose asthma\nthrough symptom intensive questionary, clinical data and medical reports.\nMachine Learning Algorithms like Back-propagation model, Context Sensitive\nAuto-Associative Memory Neural Network Model, C4.5 Algorithm, Bayesian Network\nand Particle Swarm Optimization have been employed for the diagnosis of asthma\nand later a comparison is made between their respective prospects. All\nalgorithms received an accuracy of over 80%. However, the use of Auto\nAssociative Memory Model (on a layered Artificial Neural Network) displayed\nmuch better results. It reached to an accuracy of over 90% and an inconclusive\ndiagnosis rate of less than 1% when trained with adequate data. In the end,\nna\\\"ive mobile based applications were developed on Android and iOS that made\nuse of the self-training auto associative memory model to achieve an accuracy\nof nearly 94.2%.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 13:21:51 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Kukreja", "Saksham", ""]]}, {"id": "1804.04614", "submitter": "Amirhossein Javaheri", "authors": "Amirhossein Javaheri, Hadi Zayyani, Mario A. T. Figueiredo, Farrokh\n  Marvasti", "title": "Impulsive Noise Robust Sparse Recovery via Continuous Mixed Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of sparse signal recovery in the presence\nof additive impulsive noise. The heavytailed impulsive noise is well modelled\nwith stable distributions. Since there is no explicit formulation for the\nprobability density function of $S\\alpha S$ distribution, alternative\napproximations like Generalized Gaussian Distribution (GGD) are used which\nimpose $\\ell_p$-norm fidelity on the residual error. In this paper, we exploit\na Continuous Mixed Norm (CMN) for robust sparse recovery instead of\n$\\ell_p$-norm. We show that in blind conditions, i.e., in case where the\nparameters of noise distribution are unknown, incorporating CMN can lead to\nnear optimal recovery. We apply Alternating Direction Method of Multipliers\n(ADMM) for solving the problem induced by utilizing CMN for robust sparse\nrecovery. In this approach, CMN is replaced with a surrogate function and\nMajorization-Minimization technique is incorporated to solve the problem.\nSimulation results confirm the efficiency of the proposed method compared to\nsome recent algorithms in the literature for impulsive noise robust sparse\nrecovery.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:40:07 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Javaheri", "Amirhossein", ""], ["Zayyani", "Hadi", ""], ["Figueiredo", "Mario A. T.", ""], ["Marvasti", "Farrokh", ""]]}, {"id": "1804.04622", "submitter": "Jovana Mitrovic", "authors": "Jovana Mitrovic, Dino Sejdinovic, Yee Whye Teh", "title": "Causal Inference via Kernel Deviance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the causal structure among a set of variables is a fundamental\nproblem in many areas of science. In this paper, we propose Kernel Conditional\nDeviance for Causal Inference (KCDC) a fully nonparametric causal discovery\nmethod based on purely observational data. From a novel interpretation of the\nnotion of asymmetry between cause and effect, we derive a corresponding\nasymmetry measure using the framework of reproducing kernel Hilbert spaces.\nBased on this, we propose three decision rules for causal discovery. We\ndemonstrate the wide applicability of our method across a range of diverse\nsynthetic datasets. Furthermore, we test our method on real-world time series\ndata and the real-world benchmark dataset Tubingen Cause-Effect Pairs where we\noutperform existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:51:04 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Mitrovic", "Jovana", ""], ["Sejdinovic", "Dino", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1804.04640", "submitter": "Jaroslaw Zola", "authors": "Subhadeep Karan, Matthew Eichhorn, Blake Hurlburt, Grant Iraci,\n  Jaroslaw Zola", "title": "Fast Counting in Machine Learning Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose scalable methods to execute counting queries in machine learning\napplications. To achieve memory and computational efficiency, we abstract\ncounting queries and their context such that the counts can be aggregated as a\nstream. We demonstrate performance and scalability of the resulting approach on\nrandom queries, and through extensive experimentation using Bayesian networks\nlearning and association rule mining. Our methods significantly outperform\ncommonly used ADtrees and hash tables, and are practical alternatives for\nprocessing large-scale data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 17:34:41 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 02:35:55 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 20:01:56 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Karan", "Subhadeep", ""], ["Eichhorn", "Matthew", ""], ["Hurlburt", "Blake", ""], ["Iraci", "Grant", ""], ["Zola", "Jaroslaw", ""]]}, {"id": "1804.04651", "submitter": "Venkatasubramanian Viswanathan", "authors": "Zeeshan Ahmad, Tian Xie, Chinmay Maheshwari, Jeffrey C. Grossman,\n  Venkatasubramanian Viswanathan", "title": "Machine Learning Enabled Computational Screening of Inorganic Solid\n  Electrolytes for Dendrite Suppression with Li Metal Anode", "comments": "34 pages, 4 Figures, 3 Table, 7 pages of Supporting Information", "journal-ref": "ACS Cent. Sci., 2018, 4 (8), 996-1006", "doi": "10.1021/acscentsci.8b00229", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation batteries based on lithium (Li) metal anodes have been\nplagued by the dendritic electrodeposition of Li metal on the anode during\ncycling, resulting in short circuit and capacity loss. Suppression of dendritic\ngrowth through the use of solid electrolytes has emerged as one of the most\npromising strategies for enabling the use of Li metal anodes. We perform a\ncomputational screening of over 12,000 inorganic solids based on their ability\nto suppress dendrite initiation in contact with Li metal anode. Properties for\nmechanically isotropic and anisotropic interfaces that can be used in stability\ncriteria for determining the propensity of dendrite initiation are usually\nobtained from computationally expensive first-principles methods. In order to\nobtain a large dataset for screening, we use machine learning models to predict\nthe mechanical properties of several new solid electrolytes. We train a\nconvolutional neural network on the shear and bulk moduli purely on structural\nfeatures of the material. We use AdaBoost, Lasso and Bayesian ridge regression\nto train the elastic constants, where the choice of the model depended on the\nsize of the training data and the noise that it can handle. Our models give us\ndirect interpretability by revealing the dominant structural features affecting\nthe elastic constants. The stiffness is found to increase with a decrease in\nvolume per atom, increase in minimum anion-anion separation, and increase in\nsublattice (all but Li) packing fraction. Cross-validation/test performance\nsuggests our models generalize well. We predict over 20 mechanically\nanisotropic interfaces between Li metal and 6 solid electrolytes which can be\nused to suppress dendrite growth. Our screened candidates are generally soft\nand highly anisotropic, and present opportunities for simultaneously obtaining\ndendrite suppression and high ionic conductivity in solid electrolytes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 17:57:19 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Xie", "Tian", ""], ["Maheshwari", "Chinmay", ""], ["Grossman", "Jeffrey C.", ""], ["Viswanathan", "Venkatasubramanian", ""]]}, {"id": "1804.04656", "submitter": "Taco Cohen", "authors": "Marysia Winkels, Taco S. Cohen", "title": "3D G-CNNs for Pulmonary Nodule Detection", "comments": null, "journal-ref": "International conference on Medical Imaging with Deep Learning,\n  2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) require a large amount of annotated data\nto learn from, which is often difficult to obtain in the medical domain. In\nthis paper we show that the sample complexity of CNNs can be significantly\nimproved by using 3D roto-translation group convolutions (G-Convs) instead of\nthe more conventional translational convolutions. These 3D G-CNNs were applied\nto the problem of false positive reduction for pulmonary nodule detection, and\nproved to be substantially more effective in terms of performance, sensitivity\nto malignant nodules, and speed of convergence compared to a strong and\ncomparable baseline architecture with regular convolutions, data augmentation\nand a similar number of parameters. For every dataset size tested, the G-CNN\nachieved a FROC score close to the CNN trained on ten times more data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:02:36 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Winkels", "Marysia", ""], ["Cohen", "Taco S.", ""]]}, {"id": "1804.04659", "submitter": "Daning Cheng", "authors": "Cheng Daning, Xia Fen, Li Shigang, Zhang Yunquan", "title": "Asynch-SGBDT: Asynchronous Parallel Stochastic Gradient Boosting\n  Decision Tree based on Parameters Server", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In AI research and industry, machine learning is the most widely used tool.\nOne of the most important machine learning algorithms is Gradient Boosting\nDecision Tree, i.e. GBDT whose training process needs considerable\ncomputational resources and time. To shorten GBDT training time, many works\ntried to apply GBDT on Parameter Server. However, those GBDT algorithms are\nsynchronous parallel algorithms which fail to make full use of Parameter\nServer. In this paper, we examine the possibility of using asynchronous\nparallel methods to train GBDT model and name this algorithm as asynch-SGBDT\n(asynchronous parallel stochastic gradient boosting decision tree). Our\ntheoretical and experimental results indicate that the scalability of\nasynch-SGBDT is influenced by the sample diversity of datasets, sampling rate,\nstep length and the setting of GBDT tree. Experimental results also show\nasynch-SGBDT training process reaches a linear speedup in asynchronous parallel\nmanner when datasets and GBDT trees meet high scalability requirements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 14:06:05 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 04:26:26 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 01:57:44 GMT"}, {"version": "v4", "created": "Thu, 18 Jul 2019 06:50:05 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Daning", "Cheng", ""], ["Fen", "Xia", ""], ["Shigang", "Li", ""], ["Yunquan", "Zhang", ""]]}, {"id": "1804.04696", "submitter": "Shaojun Zhu", "authors": "Shaojun Zhu, David Surovik, Kostas E. Bekris and Abdeslam Boularias", "title": "Efficient Model Identification for Tensegrity Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to identify in a practical manner unknown physical\nparameters, such as mechanical models of actuated robot links, which are\ncritical in dynamical robotic tasks. Key features include the use of an\noff-the-shelf physics engine and the Bayesian optimization framework. The task\nbeing considered is locomotion with a high-dimensional, compliant Tensegrity\nrobot. A key insight, in this case, is the need to project the model\nidentification challenge into an appropriate lower dimensional space for\nefficiency. Comparisons with alternatives indicate that the proposed method can\nidentify the parameters more accurately within the given time budget, which\nalso results in more precise locomotion control.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 19:15:34 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Zhu", "Shaojun", ""], ["Surovik", "David", ""], ["Bekris", "Kostas E.", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "1804.04725", "submitter": "Khalique Newaz", "authors": "Khalique Newaz, Mahboobeh Ghalehnovi, Arash Rahnama, Panos J.\n  Antsaklis and Tijana Milenkovic", "title": "Network-based protein structural classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental determination of protein function is resource-consuming. As an\nalternative, computational prediction of protein function has received\nattention. In this context, protein structural classification (PSC) can help,\nby allowing for determining structural classes of currently unclassified\nproteins based on their features, and then relying on the fact that proteins\nwith similar structures have similar functions. Existing PSC approaches rely on\nsequence-based or direct 3-dimensional (3D) structure-based protein features.\nIn contrast, we first model 3D structures of proteins as protein structure\nnetworks (PSNs). Then, we use network-based features for PSC. We propose the\nuse of graphlets, state-of-the-art features in many research areas of network\nscience, in the task of PSC. Moreover, because graphlets can deal only with\nunweighted PSNs, and because accounting for edge weights when constructing PSNs\ncould improve PSC accuracy, we also propose a deep learning framework that\nautomatically learns network features from weighted PSNs. When evaluated on a\nlarge set of ~9,400 CATH and ~12,800 SCOP protein domains (spanning 36 PSN\nsets), our proposed approaches are superior to existing PSC approaches in terms\nof accuracy, with comparable running time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 20:55:26 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 01:54:52 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 17:56:40 GMT"}, {"version": "v4", "created": "Fri, 23 Aug 2019 17:03:07 GMT"}, {"version": "v5", "created": "Wed, 13 Nov 2019 17:06:14 GMT"}, {"version": "v6", "created": "Fri, 6 Mar 2020 23:28:32 GMT"}, {"version": "v7", "created": "Sun, 15 Mar 2020 18:48:27 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Newaz", "Khalique", ""], ["Ghalehnovi", "Mahboobeh", ""], ["Rahnama", "Arash", ""], ["Antsaklis", "Panos J.", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1804.04732", "submitter": "Xun Huang", "authors": "Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz", "title": "Multimodal Unsupervised Image-to-Image Translation", "comments": "Accepted by ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation is an important and challenging\nproblem in computer vision. Given an image in the source domain, the goal is to\nlearn the conditional distribution of corresponding images in the target\ndomain, without seeing any pairs of corresponding images. While this\nconditional distribution is inherently multimodal, existing approaches make an\noverly simplified assumption, modeling it as a deterministic one-to-one\nmapping. As a result, they fail to generate diverse outputs from a given source\ndomain image. To address this limitation, we propose a Multimodal Unsupervised\nImage-to-image Translation (MUNIT) framework. We assume that the image\nrepresentation can be decomposed into a content code that is domain-invariant,\nand a style code that captures domain-specific properties. To translate an\nimage to another domain, we recombine its content code with a random style code\nsampled from the style space of the target domain. We analyze the proposed\nframework and establish several theoretical results. Extensive experiments with\ncomparisons to the state-of-the-art approaches further demonstrates the\nadvantage of the proposed framework. Moreover, our framework allows users to\ncontrol the style of translation outputs by providing an example style image.\nCode and pretrained models are available at https://github.com/nvlabs/MUNIT\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 21:17:54 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 18:44:12 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Huang", "Xun", ""], ["Liu", "Ming-Yu", ""], ["Belongie", "Serge", ""], ["Kautz", "Jan", ""]]}, {"id": "1804.04758", "submitter": "Takuma Oda", "authors": "Takuma Oda and Carlee Joe-Wong", "title": "MOVI: A Model-Free Approach to Dynamic Fleet Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicle fleets, e.g., for ridesharing platforms and taxi companies,\ncan reduce passengers' waiting times by proactively dispatching vehicles to\nlocations where pickup requests are anticipated in the future. Yet it is\nunclear how to best do this: optimal dispatching requires optimizing over\nseveral sources of uncertainty, including vehicles' travel times to their\ndispatched locations, as well as coordinating between vehicles so that they do\nnot attempt to pick up the same passenger. While prior works have developed\nmodels for this uncertainty and used them to optimize dispatch policies, in\nthis work we introduce a model-free approach. Specifically, we propose MOVI, a\nDeep Q-network (DQN)-based framework that directly learns the optimal vehicle\ndispatch policy. Since DQNs scale poorly with a large number of possible\ndispatches, we streamline our DQN training and suppose that each individual\nvehicle independently learns its own optimal policy, ensuring scalability at\nthe cost of less coordination between vehicles. We then formulate a centralized\nreceding-horizon control (RHC) policy to compare with our DQN policies. To\ncompare these policies, we design and build MOVI as a large-scale realistic\nsimulator based on 15 million taxi trip records that simulates policy-agnostic\nresponses to dispatch decisions. We show that the DQN dispatch policy reduces\nthe number of unserviced requests by 76% compared to without dispatch and 20%\ncompared to the RHC approach, emphasizing the benefits of a model-free approach\nand suggesting that there is limited value to coordinating vehicle actions.\nThis finding may help to explain the success of ridesharing platforms, for\nwhich drivers make individual decisions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 00:54:22 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oda", "Takuma", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "1804.04760", "submitter": "Joobin Gharibshah", "authors": "Joobin Gharibshah, Evangelos E. Papalexakis, and Michalis Faloutsos", "title": "RIPEx: Extracting malicious IP addresses from security forums using\n  cross-forum learning", "comments": "12 pages, Accepted in n 22nd Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Is it possible to extract malicious IP addresses reported in security forums\nin an automatic way? This is the question at the heart of our work. We focus on\nsecurity forums, where security professionals and hackers share knowledge and\ninformation, and often report misbehaving IP addresses. So far, there have only\nbeen a few efforts to extract information from such security forums. We propose\nRIPEx, a systematic approach to identify and label IP addresses in security\nforums by utilizing a cross-forum learning method. In more detail, the\nchallenge is twofold: (a) identifying IP addresses from other numerical\nentities, such as software version numbers, and (b) classifying the IP address\nas benign or malicious. We propose an integrated solution that tackles both\nthese problems. A novelty of our approach is that it does not require training\ndata for each new forum. Our approach does knowledge transfer across forums: we\nuse a classifier from our source forums to identify seed information for\ntraining a classifier on the target forum. We evaluate our method using data\ncollected from five security forums with a total of 31K users and 542K posts.\nFirst, RIPEx can distinguish IP address from other numeric expressions with 95%\nprecision and above 93% recall on average. Second, RIPEx identifies malicious\nIP addresses with an average precision of 88% and over 78% recall, using our\ncross-forum learning. Our work is a first step towards harnessing the wealth of\nuseful information that can be found in security forums.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 01:08:42 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Gharibshah", "Joobin", ""], ["Papalexakis", "Evangelos E.", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "1804.04775", "submitter": "Connie Kou", "authors": "Connie Kou, Hwee Kuan Lee, Teck Khim Ng", "title": "A Compact Network Learning Model for Distribution Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the superior performance of deep learning in many applications,\nchallenges remain in the area of regression on function spaces. In particular,\nneural networks are unable to encode function inputs compactly as each node\nencodes just a real value. We propose a novel idea to address this shortcoming:\nto encode an entire function in a single network node. To that end, we design a\ncompact network representation that encodes and propagates functions in single\nnodes for the distribution regression task. Our proposed Distribution\nRegression Network (DRN) achieves higher prediction accuracies while being much\nmore compact and uses fewer parameters than traditional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 02:31:10 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 05:38:54 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 08:24:19 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kou", "Connie", ""], ["Lee", "Hwee Kuan", ""], ["Ng", "Teck Khim", ""]]}, {"id": "1804.04778", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Kaoru Hiramatsu, Kunio Kashino", "title": "Understanding Community Structure in Layered Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A layered neural network is now one of the most common choices for the\nprediction of high-dimensional practical data sets, where the relationship\nbetween input and output data is complex and cannot be represented well by\nsimple conventional models. Its effectiveness is shown in various tasks,\nhowever, the lack of interpretability of the trained result by a layered neural\nnetwork has limited its application area.\n  In our previous studies, we proposed methods for extracting a simplified\nglobal structure of a trained layered neural network by classifying the units\ninto communities according to their connection patterns with adjacent layers.\nThese methods provided us with knowledge about the strength of the relationship\nbetween communities from the existence of bundled connections, which are\ndetermined by threshold processing of the connection ratio between pairs of\ncommunities.\n  However, it has been difficult to understand the role of each community\nquantitatively by observing the modular structure. We could only know to which\nsets of the input and output dimensions each community was mainly connected, by\ntracing the bundled connections from the community to the input and output\nlayers. Another problem is that the finally obtained modular structure is\nchanged greatly depending on the setting of the threshold hyperparameter used\nfor determining bundled connections.\n  In this paper, we propose a new method for interpreting quantitatively the\nrole of each community in inference, by defining the effect of each input\ndimension on a community, and the effect of a community on each output\ndimension. We show experimentally that our proposed method can reveal the role\nof each part of a layered neural network by applying the neural networks to\nthree types of data sets, extracting communities from the trained network, and\napplying the proposed method to the community structure.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 03:10:00 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Hiramatsu", "Kaoru", ""], ["Kashino", "Kunio", ""]]}, {"id": "1804.04780", "submitter": "Bowei Xi", "authors": "Wutao Wei, Bowei Xi, Murat Kantarcioglu", "title": "Adversarial Clustering: A Grid Based Clustering Algorithm Against Active\n  Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays more and more data are gathered for detecting and preventing cyber\nattacks. In cyber security applications, data analytics techniques have to deal\nwith active adversaries that try to deceive the data analytics models and avoid\nbeing detected. The existence of such adversarial behavior motivates the\ndevelopment of robust and resilient adversarial learning techniques for various\ntasks. Most of the previous work focused on adversarial classification\ntechniques, which assumed the existence of a reasonably large amount of\ncarefully labeled data instances. However, in practice, labeling the data\ninstances often requires costly and time-consuming human expertise and becomes\na significant bottleneck. Meanwhile, a large number of unlabeled instances can\nalso be used to understand the adversaries' behavior. To address the above\nmentioned challenges, in this paper, we develop a novel grid based adversarial\nclustering algorithm. Our adversarial clustering algorithm is able to identify\nthe core normal regions, and to draw defensive walls around the centers of the\nnormal objects utilizing game theoretic ideas. Our algorithm also identifies\nsub-clusters of attack objects, the overlapping areas within clusters, and\noutliers which may be potential anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 04:06:37 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Wei", "Wutao", ""], ["Xi", "Bowei", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "1804.04791", "submitter": "Vishnu Menon", "authors": "Vishnu Menon, Sheetal Kalyani", "title": "Fast, Parameter free Outlier Identification for Robust PCA", "comments": "13 pages. Submitted to IEEE JSTSP Special Issue on Data Science:\n  Robust Subspace Learning and Tracking: Theory, Algorithms, and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust PCA, the problem of PCA in the presence of outliers has been\nextensively investigated in the last few years. Here we focus on Robust PCA in\nthe column sparse outlier model. The existing methods for column sparse outlier\nmodel assumes either the knowledge of the dimension of the lower dimensional\nsubspace or the fraction of outliers in the system. However in many\napplications knowledge of these parameters is not available. Motivated by this\nwe propose a parameter free outlier identification method for robust PCA which\na) does not require the knowledge of outlier fraction, b) does not require the\nknowledge of the dimension of the underlying subspace, c) is computationally\nsimple and fast. Further, analytical guarantees are derived for outlier\nidentification and the performance of the algorithm is compared with the\nexisting state of the art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 05:35:19 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Menon", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1804.04806", "submitter": "Yosuke Oyama", "authors": "Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka", "title": "{\\mu}-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching", "comments": "11 pages, 14 figures. Part of the content have been published in IPSJ\n  SIG Technical Report, Vol. 2017-HPC-162, No. 22, pp. 1-9, 2017. (DOI:\n  http://id.nii.ac.jp/1001/00184814)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\nin deep learning. Specifically, cuDNN implements several equivalent convolution\nalgorithms, whose performance and memory footprint may vary considerably,\ndepending on the layer dimensions. When an algorithm is automatically selected\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\nresorts to slower algorithms that fit the workspace size constraints. We\npresent {\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\nProgramming and Integer Linear Programming, {\\mu}-cuDNN enables faster\nalgorithms by decreasing the workspace requirements. At the same time,\n{\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\neffectiveness of {\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\nGPU. These results indicate that using micro-batches can seamlessly increase\nthe performance of deep learning, while maintaining the same memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 07:20:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oyama", "Yosuke", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1804.04849", "submitter": "Jos van der Westhuizen", "authors": "Jos van der Westhuizen and Joan Lasenby", "title": "The unreasonable effectiveness of the forget gate", "comments": "Corrected LSTM gradient derivations. Added link to code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the success of the gated recurrent unit, a natural question is whether\nall the gates of the long short-term memory (LSTM) network are necessary.\nPrevious research has shown that the forget gate is one of the most important\ngates in the LSTM. Here we show that a forget-gate-only version of the LSTM\nwith chrono-initialized biases, not only provides computational savings but\noutperforms the standard LSTM on multiple benchmark datasets and competes with\nsome of the best contemporary models. Our proposed network, the JANET, achieves\naccuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming the\nstandard LSTM which yields accuracies of 98.5% and 91%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 09:18:17 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 17:23:40 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 10:55:56 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["van der Westhuizen", "Jos", ""], ["Lasenby", "Joan", ""]]}, {"id": "1804.04878", "submitter": "Vikas Sindhwani", "authors": "Vikas Sindhwani, Stephen Tu and Mohi Khansari", "title": "Learning Contracting Vector Fields For Stable Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new non-parametric framework for learning incrementally stable\ndynamical systems x' = f(x) from a set of sampled trajectories. We construct a\nrich family of smooth vector fields induced by certain classes of matrix-valued\nkernels, whose equilibria are placed exactly at a desired set of locations and\nwhose local contraction and curvature properties at various points can be\nexplicitly controlled using convex optimization. With curl-free kernels, our\nframework may also be viewed as a mechanism to learn potential fields and\ngradient flows. We develop large-scale techniques using randomized kernel\napproximations in this context. We demonstrate our approach, called contracting\nvector fields (CVF), on imitation learning tasks involving complex\npoint-to-point human handwriting motions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 10:40:45 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Sindhwani", "Vikas", ""], ["Tu", "Stephen", ""], ["Khansari", "Mohi", ""]]}, {"id": "1804.04888", "submitter": "Minh Nghia Nguyen", "authors": "Minh-Nghia Nguyen and Ngo Anh Vien", "title": "Scalable and Interpretable One-class SVMs with Deep Learning and Random\n  Fourier features", "comments": "Accepted at European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class support vector machine (OC-SVM) for a long time has been one of the\nmost effective anomaly detection methods and extensively adopted in both\nresearch as well as industrial applications. The biggest issue for OC-SVM is\nyet the capability to operate with large and high-dimensional datasets due to\noptimization complexity. Those problems might be mitigated via dimensionality\nreduction techniques such as manifold learning or autoencoder. However,\nprevious work often treats representation learning and anomaly prediction\nseparately. In this paper, we propose autoencoder based one-class support\nvector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier\nfeatures to approximate the radial basis kernel, into deep learning context by\ncombining it with a representation learning architecture and jointly exploit\nstochastic gradient descent to obtain end-to-end training. Interestingly, this\nalso opens up the possible use of gradient-based attribution methods to explain\nthe decision making for anomaly detection, which has ever been challenging as a\nresult of the implicit mappings between the input space and the kernel space.\nTo the best of our knowledge, this is the first work to study the\ninterpretability of deep learning in anomaly detection. We evaluate our method\non a wide range of unsupervised anomaly detection tasks in which our end-to-end\ntraining architecture achieves a performance significantly better than the\nprevious work using separate training.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 11:24:33 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 09:15:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Nguyen", "Minh-Nghia", ""], ["Vien", "Ngo Anh", ""]]}, {"id": "1804.04918", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Peilin Zhao, Longfei Li, Jun Zhou, Xiaolong\n  Li", "title": "Distributed Collaborative Hashing and Its Applications in Ant Financial", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering, especially latent factor model, has been popularly\nused in personalized recommendation. Latent factor model aims to learn user and\nitem latent factors from user-item historic behaviors. To apply it into real\nbig data scenarios, efficiency becomes the first concern, including offline\nmodel training efficiency and online recommendation efficiency. In this paper,\nwe propose a Distributed Collaborative Hashing (DCH) model which can\nsignificantly improve both efficiencies. Specifically, we first propose a\ndistributed learning framework, following the state-of-the-art parameter server\nparadigm, to learn the offline collaborative model. Our model can be learnt\nefficiently by distributedly computing subgradients in minibatches on workers\nand updating model parameters on servers asynchronously. We then adopt hashing\ntechnique to speedup the online recommendation procedure. Recommendation can be\nquickly made through exploiting lookup hash tables. We conduct thorough\nexperiments on two real large-scale datasets. The experimental results\ndemonstrate that, comparing with the classic and state-of-the-art (distributed)\nlatent factor models, DCH has comparable performance in terms of recommendation\naccuracy but has both fast convergence speed in offline model training\nprocedure and realtime efficiency in online recommendation procedure.\nFurthermore, the encouraging performance of DCH is also shown for several\nreal-world applications in Ant Financial.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 12:37:51 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 03:21:25 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 03:52:47 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhao", "Peilin", ""], ["Li", "Longfei", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1804.04950", "submitter": "Huifeng Guo", "authors": "Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, and\n  Zhenhua Dong", "title": "DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction", "comments": "14 pages. arXiv admin note: text overlap with arXiv:1703.04247", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sophisticated feature interactions behind user behaviors is critical\nin maximizing CTR for recommender systems. Despite great progress, existing\nmethods have a strong bias towards low- or high-order interactions, or rely on\nexpertise feature engineering. In this paper, we show that it is possible to\nderive an end-to-end learning model that emphasizes both low- and high-order\nfeature interactions. The proposed framework, DeepFM, combines the power of\nfactorization machines for recommendation and deep learning for feature\nlearning in a new neural network architecture. Compared to the latest Wide &\nDeep model from Google, DeepFM has a shared raw feature input to both its\n\"wide\" and \"deep\" components, with no need of feature engineering besides raw\nfeatures. DeepFM, as a general learning framework, can incorporate various\nnetwork architectures in its deep component. In this paper, we study two\ninstances of DeepFM where its \"deep\" component is DNN and PNN respectively, for\nwhich we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are\nconducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the\nexisting models for CTR prediction, on both benchmark data and commercial data.\nWe conduct online A/B test in Huawei App Market, which reveals that DeepFM-D\nleads to more than 10% improvement of click-through rate in the production\nenvironment, compared to a well-engineered LR model. We also covered related\npractice in deploying our framework in Huawei App Market.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 01:12:13 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 13:39:20 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Ye", "Yunming", ""], ["Li", "Zhenguo", ""], ["He", "Xiuqiang", ""], ["Dong", "Zhenhua", ""]]}, {"id": "1804.04976", "submitter": "Daniele De Martini", "authors": "Mirto Musci, Daniele De Martini, Nicola Blago, Tullio Facchinetti and\n  Marco Piastra", "title": "Online Fall Detection using Recurrent Neural Networks", "comments": "6 pages, ICRA 2018", "journal-ref": null, "doi": "10.1109/TETC.2020.3027454", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintentional falls can cause severe injuries and even death, especially if\nno immediate assistance is given. The aim of Fall Detection Systems (FDSs) is\nto detect an occurring fall. This information can be used to trigger the\nnecessary assistance in case of injury. This can be done by using either\nambient-based sensors, e.g. cameras, or wearable devices. The aim of this work\nis to study the technical aspects of FDSs based on wearable devices and\nartificial intelligence techniques, in particular Deep Learning (DL), to\nimplement an effective algorithm for on-line fall detection. The proposed\nclassifier is based on a Recurrent Neural Network (RNN) model with underlying\nLong Short-Term Memory (LSTM) blocks. The method is tested on the publicly\navailable SisFall dataset, with extended annotation, and compared with the\nresults obtained by the SisFall authors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 14:58:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Musci", "Mirto", ""], ["De Martini", "Daniele", ""], ["Blago", "Nicola", ""], ["Facchinetti", "Tullio", ""], ["Piastra", "Marco", ""]]}, {"id": "1804.05002", "submitter": "Roman V\\'aclav\\'ik", "authors": "Roman V\\'aclav\\'ik, P\\v{r}emysl \\v{S}\\r{u}cha, Zden\\v{e}k Hanz\\'alek", "title": "Roster Evaluation Based on Classifiers for the Nurse Rostering Problem", "comments": null, "journal-ref": null, "doi": "10.1007/s10732-016-9314-9", "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personnel scheduling problem is a well-known NP-hard combinatorial\nproblem. Due to the complexity of this problem and the size of the real-world\ninstances, it is not possible to use exact methods, and thus heuristics,\nmeta-heuristics, or hyper-heuristics must be employed. The majority of\nheuristic approaches are based on iterative search, where the quality of\nintermediate solutions must be calculated. Unfortunately, this is\ncomputationally highly expensive because these problems have many constraints\nand some are very complex. In this study, we propose a machine learning\ntechnique as a tool to accelerate the evaluation phase in heuristic approaches.\nThe solution is based on a simple classifier, which is able to determine\nwhether the changed solution (more precisely, the changed part of the solution)\nis better than the original or not. This decision is made much faster than a\nstandard cost-oriented evaluation process. However, the classification process\ncannot guarantee 100% correctness. Therefore, our approach, which is\nillustrated using a tabu search algorithm in this study, includes a filtering\nmechanism, where the classifier rejects the majority of the potentially bad\nsolutions and the remaining solutions are then evaluated in a standard manner.\nWe also show how the boosting algorithms can improve the quality of the final\nsolution compared with a simple classifier. We verified our proposed approach\nand premises, based on standard and real-world benchmark instances, to\ndemonstrate the significant speedup obtained with comparable solution quality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 15:47:00 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["V\u00e1clav\u00edk", "Roman", ""], ["\u0160\u016fcha", "P\u0159emysl", ""], ["Hanz\u00e1lek", "Zden\u011bk", ""]]}, {"id": "1804.05012", "submitter": "Phil Long", "authors": "Peter L. Bartlett, Steven N. Evans and Philip M. Long", "title": "Representing smooth functions as compositions of near-identity functions\n  with implications for deep network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any smooth bi-Lipschitz $h$ can be represented exactly as a\ncomposition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close\nto the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is\nLipschitz, and the Lipschitz constant decreases inversely with the number $m$\nof functions composed. This implies that $h$ can be represented to any accuracy\nby a deep residual network whose nonlinear layers compute functions with a\nsmall Lipschitz constant. Next, we consider nonlinear regression with a\ncomposition of near-identity nonlinear maps. We show that, regarding Fr\\'echet\nderivatives with respect to the $h_1,...,h_m$, any critical point of a\nquadratic criterion in this near-identity region must be a global minimizer. In\ncontrast, if we consider derivatives with respect to parameters of a fixed-size\nresidual network with sigmoid activation functions, we show that there are\nnear-identity critical points that are suboptimal, even in the realizable case.\nInformally, this means that functional gradient methods for residual networks\ncannot get stuck at suboptimal critical points corresponding to near-identity\nlayers, whereas parametric gradient methods for sigmoidal residual networks\nsuffer from suboptimal critical points in the near-identity region.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:24:17 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 17:07:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Evans", "Steven N.", ""], ["Long", "Philip M.", ""]]}, {"id": "1804.05013", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Arya Mazumdar, Soumyabrata Pal and Barna Saha", "title": "Connectivity in Random Annulus Graphs and the Geometric Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new connectivity results for {\\em vertex-random graphs} or {\\em\nrandom annulus graphs} which are significant generalizations of random\ngeometric graphs. Random geometric graphs (RGG) are one of the most basic\nmodels of random graphs for spatial networks proposed by Gilbert in 1961,\nshortly after the introduction of the Erd\\H{o}s-R\\'{en}yi random graphs. They\nresemble social networks in many ways (e.g. by spontaneously creating cluster\nof nodes with high modularity). The connectivity properties of RGG have been\nstudied since its introduction, and analyzing them has been significantly\nharder than their Erd\\H{o}s-R\\'{en}yi counterparts due to correlated edge\nformation.\n  Our next contribution is in using the connectivity of random annulus graphs\nto provide necessary and sufficient conditions for efficient recovery of\ncommunities for {\\em the geometric block model} (GBM). The GBM is a\nprobabilistic model for community detection defined over an RGG in a similar\nspirit as the popular {\\em stochastic block model}, which is defined over an\nErd\\H{o}s-R\\'{en}yi random graph. The geometric block model inherits the\ntransitivity properties of RGGs and thus models communities better than a\nstochastic block model. However, analyzing them requires fresh perspectives as\nall prior tools fail due to correlation in edge formation. We provide a simple\nand efficient algorithm that can recover communities in GBM exactly with high\nprobability in the regime of connectivity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:49:00 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 14:06:34 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 22:12:05 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""], ["Saha", "Barna", ""]]}, {"id": "1804.05018", "submitter": "Sandro Pezzelle", "authors": "Sandro Pezzelle and Ionut-Teodor Sorodoc and Raffaella Bernardi", "title": "Comparatives, Quantifiers, Proportions: A Multi-Task Model for the\n  Learning of Quantities from Vision", "comments": "12 pages (references included). To appear in the Proceedings of\n  NAACL-HLT 2018", "journal-ref": "Proceedings of NAACL-HLT 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work investigates whether different quantification mechanisms\n(set comparison, vague quantification, and proportional estimation) can be\njointly learned from visual scenes by a multi-task computational model. The\nmotivation is that, in humans, these processes underlie the same cognitive,\nnon-symbolic ability, which allows an automatic estimation and comparison of\nset magnitudes. We show that when information about lower-complexity tasks is\navailable, the higher-level proportional task becomes more accurate than when\nperformed in isolation. Moreover, the multi-task model is able to generalize to\nunseen combinations of target/non-target objects. Consistently with behavioral\nevidence showing the interference of absolute number in the proportional task,\nthe multi-task model no longer works when asked to provide the number of target\nobjects in the scene.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:36:52 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Pezzelle", "Sandro", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Bernardi", "Raffaella", ""]]}, {"id": "1804.05020", "submitter": "Cody Wild", "authors": "Joshua Saxe, Richard Harang, Cody Wild, Hillary Sanders", "title": "A Deep Learning Approach to Fast, Format-Agnostic Detection of Malicious\n  Web Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious web content is a serious problem on the Internet today. In this\npaper we propose a deep learning approach to detecting malevolent web pages.\nWhile past work on web content detection has relied on syntactic parsing or on\nemulation of HTML and Javascript to extract features, our approach operates\ndirectly on a language-agnostic stream of tokens extracted directly from static\nHTML files with a simple regular expression. This makes it fast enough to\noperate in high-frequency data contexts like firewalls and web proxies, and\nallows it to avoid the attack surface exposure of complex parsing and emulation\ncode. Unlike well-known approaches such as bag-of-words models, which ignore\nspatial information, our neural network examines content at hierarchical\nspatial scales, allowing our model to capture locality and yielding superior\naccuracy compared to bag-of-words baselines. Our proposed architecture achieves\na 97.5% detection rate at a 0.1% false positive rate, and classifies\nsmall-batched web pages at a rate of over 100 per second on commodity hardware.\nThe speed and accuracy of our approach makes it appropriate for deployment to\nendpoints, firewalls, and web proxies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:39:24 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Saxe", "Joshua", ""], ["Harang", "Richard", ""], ["Wild", "Cody", ""], ["Sanders", "Hillary", ""]]}, {"id": "1804.05051", "submitter": "Suryoday Basak", "authors": "Mohammed Viquar, Suryoday Basak, Ariruna Dasgupta, Surbhi Agrawal,\n  Snehanshu Saha", "title": "Machine Learning in Astronomy: A Case Study in Quasar-Star\n  Classification", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results of various automated classification methods, based on\nmachine learning (ML), of objects from data releases 6 and 7 (DR6 and DR7) of\nthe Sloan Digital Sky Survey (SDSS), primarily distinguishing stars from\nquasars. We provide a careful scrutiny of approaches available in the\nliterature and have highlighted the pitfalls in those approaches based on the\nnature of data used for the study. The aim is to investigate the\nappropriateness of the application of certain ML methods. The manuscript argues\nconvincingly in favor of the efficacy of asymmetric AdaBoost to classify\nphotometric data. The paper presents a critical review of existing study and\nputs forward an application of asymmetric AdaBoost, as an offspring of that\nexercise.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 17:36:13 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Viquar", "Mohammed", ""], ["Basak", "Suryoday", ""], ["Dasgupta", "Ariruna", ""], ["Agrawal", "Surbhi", ""], ["Saha", "Snehanshu", ""]]}, {"id": "1804.05090", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chris Ding, Feiping Nie", "title": "Regularized Singular Value Decomposition and Application to Recommender\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular value decomposition (SVD) is the mathematical basis of principal\ncomponent analysis (PCA). Together, SVD and PCA are one of the most widely used\nmathematical formalism/decomposition in machine learning, data mining, pattern\nrecognition, artificial intelligence, computer vision, signal processing, etc.\nIn recent applications, regularization becomes an increasing trend. In this\npaper, we present a regularized SVD (RSVD), present an efficient computational\nalgorithm, and provide several theoretical analysis. We show that although RSVD\nis non-convex, it has a closed-form global optimal solution. Finally, we apply\nRSVD to the application of recommender system and experimental result show that\nRSVD outperforms SVD significantly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 18:54:30 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zheng", "Shuai", ""], ["Ding", "Chris", ""], ["Nie", "Feiping", ""]]}, {"id": "1804.05092", "submitter": "Saman Sadeghyan", "authors": "Saman Sadeghyan", "title": "A new robust feature selection method using variance-based sensitivity\n  analysis", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excluding irrelevant features in a pattern recognition task plays an\nimportant role in maintaining a simpler machine learning model and optimizing\nthe computational efficiency. Nowadays with the rise of large scale datasets,\nfeature selection is in great demand as it becomes a central issue when facing\nhigh-dimensional datasets. The present study provides a new measure of saliency\nfor features by employing a Sensitivity Analysis (SA) technique called the\nextended Fourier amplitude sensitivity test, and a well-trained Feedforward\nNeural Network (FNN) model, which ultimately leads to the selection of a\npromising optimal feature subset. Ideas of the paper are mainly demonstrated\nbased on adopting FNN model for feature selection in classification problems.\nBut in the end, a generalization framework is discussed in order to give\ninsights into the usage in regression problems as well as expressing how other\nfunction approximate models can be deployed. Effectiveness of the proposed\nmethod is verified by result analysis and data visualization for a series of\nexperiments over several well-known datasets drawn from UCI machine learning\nrepository.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:29:40 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Sadeghyan", "Saman", ""]]}, {"id": "1804.05120", "submitter": "Ibrahim Sobh", "authors": "Ibrahim M. Sobh, Nevin M. Darwish", "title": "Robust Dual View Deep Agent", "comments": "Proceeding of the 2nd International Sino-Egyptian Congress on\n  Agriculture, Veterinary Sciences and Engineering, 7-10 October 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent advance of machine learning using Deep Reinforcement\nLearning this paper proposes a modified architecture that produces more robust\nagents and speeds up the training process. Our architecture is based on\nAsynchronous Advantage Actor-Critic (A3C) algorithm where the total input\ndimensionality is halved by dividing the input into two independent streams. We\nuse ViZDoom, 3D world software that is based on the classical first person\nshooter video game, Doom, as a test case. The experiments show that in\ncomparison to single input agents, the proposed architecture succeeds to have\nthe same playing performance and shows more robust behavior, achieving\nsignificant reduction in the number of training parameters of almost 30%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 21:13:42 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 06:03:40 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Sobh", "Ibrahim M.", ""], ["Darwish", "Nevin M.", ""]]}, {"id": "1804.05146", "submitter": "Alejandro Schuler", "authors": "Alejandro Schuler, Michael Baiocchi, Robert Tibshirani, Nigam Shah", "title": "A comparison of methods for model selection when estimating individual\n  treatment effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners in medicine, business, political science, and other fields are\nincreasingly aware that decisions should be personalized to each patient,\ncustomer, or voter. A given treatment (e.g. a drug or advertisement) should be\nadministered only to those who will respond most positively, and certainly not\nto those who will be harmed by it. Individual-level treatment effects can be\nestimated with tools adapted from machine learning, but different models can\nyield contradictory estimates. Unlike risk prediction models, however,\ntreatment effect models cannot be easily evaluated against each other using a\nheld-out test set because the true treatment effect itself is never directly\nobserved. Besides outcome prediction accuracy, several metrics that can\nleverage held-out data to evaluate treatment effects models have been proposed,\nbut they are not widely used. We provide a didactic framework that elucidates\nthe relationships between the different approaches and compare them all using a\nvariety of simulations of both randomized and observational data. Our results\nshow that researchers estimating heterogenous treatment effects need not limit\nthemselves to a single model-fitting algorithm. Instead of relying on a single\nmethod, multiple models fit by a diverse set of algorithms should be evaluated\nagainst each other using an objective function learned from the validation set.\nThe model minimizing that objective should be used for estimating the\nindividual treatment effect for future individuals.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 01:28:47 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 20:38:50 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Schuler", "Alejandro", ""], ["Baiocchi", "Michael", ""], ["Tibshirani", "Robert", ""], ["Shah", "Nigam", ""]]}, {"id": "1804.05160", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Jinkun Chen and Ming Li", "title": "Exploring the Encoding Layer and Loss Function in End-to-End Speaker and\n  Language Recognition System", "comments": "Accepted for Speaker Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the encoding/pooling layer and loss function in the\nend-to-end speaker and language recognition system. First, a unified and\ninterpretable end-to-end system for both speaker and language recognition is\ndeveloped. It accepts variable-length input and produces an utterance level\nresult. In the end-to-end system, the encoding layer plays a role in\naggregating the variable-length input sequence into an utterance level\nrepresentation. Besides the basic temporal average pooling, we introduce a\nself-attentive pooling layer and a learnable dictionary encoding layer to get\nthe utterance level representation. In terms of loss function for open-set\nspeaker verification, to get more discriminative speaker embedding, center loss\nand angular softmax loss is introduced in the end-to-end system. Experimental\nresults on Voxceleb and NIST LRE 07 datasets show that the performance of\nend-to-end learning system could be significantly improved by the proposed\nencoding layer and loss function.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 03:52:46 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Cai", "Weicheng", ""], ["Chen", "Jinkun", ""], ["Li", "Ming", ""]]}, {"id": "1804.05170", "submitter": "Bin Li", "authors": "Bin Li, Yueheng Lan, Weisi Guo, Chenglin Zhao", "title": "Model-Free Information Extraction in Enriched Nonlinear Phase-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting anomalies and discovering driving signals is an essential component\nof scientific research and industrial practice. Often the underlying mechanism\nis highly complex, involving hidden evolving nonlinear dynamics and noise\ncontamination. When representative physical models and large labeled data sets\nare unavailable, as is the case with most real-world applications,\nmodel-dependent Bayesian approaches would yield misleading results, and most\nsupervised learning machines would also fail to reliably resolve the\nintricately evolving systems. Here, we propose an unsupervised machine-learning\napproach that operates in a well-constructed function space, whereby the\nevolving nonlinear dynamics are captured through a linear functional\nrepresentation determined by the Koopman operator. This breakthrough leverages\non the time-feature embedding and the ensuing reconstruction of a phase-space\nrepresentation of the dynamics, thereby permitting the reliable identification\nof critical global signatures from the whole trajectory. This dramatically\nimproves over commonly used static local features, which are vulnerable to\nunknown transitions or noise. Thanks to its data-driven nature, our method\nexcludes any prior models and training corpus. We benchmark the astonishing\naccuracy of our method on three diverse and challenging problems in: biology,\nmedicine, and engineering. In all cases, it outperforms existing\nstate-of-the-art methods. As a new unsupervised information processing\nparadigm, it is suitable for ubiquitous nonlinear dynamical systems or\nend-users with little expertise, which permits an unbiased excavation of\nunderlying working principles or intrinsic correlations submerged in unlabeled\ndata flows.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 05:58:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 02:16:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Li", "Bin", ""], ["Lan", "Yueheng", ""], ["Guo", "Weisi", ""], ["Zhao", "Chenglin", ""]]}, {"id": "1804.05195", "submitter": "Lin Shao", "authors": "Lin Shao, Parth Shah, Vikranth Dwaracherla, Jeannette Bohg", "title": "Motion-based Object Segmentation based on Dense RGB-D Scene Flow", "comments": "Accepted to IEEE Robotics and Automation Letters and selected by\n  IROS'18 Program Committee for presentation at the Conference", "journal-ref": null, "doi": "10.1109/LRA.2018.2856525", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two consecutive RGB-D images, we propose a model that estimates a dense\n3D motion field, also known as scene flow. We take advantage of the fact that\nin robot manipulation scenarios, scenes often consist of a set of rigidly\nmoving objects. Our model jointly estimates (i) the segmentation of the scene\ninto an unknown but finite number of objects, (ii) the motion trajectories of\nthese objects and (iii) the object scene flow. We employ an hourglass, deep\nneural network architecture. In the encoding stage, the RGB and depth images\nundergo spatial compression and correlation. In the decoding stage, the model\noutputs three images containing a per-pixel estimate of the corresponding\nobject center as well as object translation and rotation. This forms the basis\nfor inferring the object segmentation and final object scene flow. To evaluate\nour model, we generated a new and challenging, large-scale, synthetic dataset\nthat is specifically targeted at robotic manipulation: It contains a large\nnumber of scenes with a very diverse set of simultaneously moving 3D objects\nand is recorded with a simulated, static RGB-D camera. In quantitative\nexperiments, we show that we outperform state-of-the-art scene flow and\nmotion-segmentation methods on this data set. In qualitative experiments, we\nshow how our learned model transfers to challenging real-world scenes, visually\ngenerating better results than existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 09:33:40 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 08:49:35 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Shao", "Lin", ""], ["Shah", "Parth", ""], ["Dwaracherla", "Vikranth", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1804.05214", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran", "title": "Fast Optimal Bandwidth Selection for RBF Kernel using Reproducing Kernel\n  Hilbert Space Operators for Kernel Based Classifiers", "comments": "Submitted to IEEE GRSL", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel based methods have shown effective performance in many remote sensing\nclassification tasks. However their performance significantly depend on its\nhyper-parameters. The conventional technique to estimate the parameter comes\nwith high computational complexity. Thus, the objective of this letter is to\npropose an fast and efficient method to select the bandwidth parameter of the\nGaussian kernel in the kernel based classification methods. The proposed method\nis developed based on the operators in the reproducing kernel Hilbert space and\nit is evaluated on Support vector machines and PerTurbo classification method.\nExperiments conducted with hyperspectral datasets show that our proposed method\noutperforms the state-of-art method in terms in computational time and\nclassification performance.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 12:42:09 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""]]}, {"id": "1804.05251", "submitter": "Tian Guo", "authors": "Tian Guo, Tao Lin, Yao Lu", "title": "An interpretable LSTM neural network for autoregressive exogenous model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an interpretable LSTM recurrent neural network,\ni.e., multi-variable LSTM for time series with exogenous variables. Currently,\nwidely used attention mechanism in recurrent neural networks mostly focuses on\nthe temporal aspect of data and falls short of characterizing variable\nimportance. To this end, our multi-variable LSTM equipped with tensorized\nhidden states is developed to learn variable specific representations, which\ngive rise to both temporal and variable level attention. Preliminary\nexperiments demonstrate comparable prediction performance of multi-variable\nLSTM w.r.t. encoder-decoder based baselines. More interestingly, variable\nimportance in real datasets characterized by the variable attention is highly\nin line with that determined by statistical Granger causality test, which\nexhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end\nframework for both forecasting and knowledge discovery.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 17:33:46 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Guo", "Tian", ""], ["Lin", "Tao", ""], ["Lu", "Yao", ""]]}, {"id": "1804.05260", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Vincent Atanasov, Takanori Maehara, Ken-ichi\n  Kawarabayashi", "title": "ClassiNet -- Predicting Missing Features for Short-Text Classification", "comments": "Accepted to ACM TKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental problem in short-text classification is \\emph{feature\nsparseness} -- the lack of feature overlap between a trained model and a test\ninstance to be classified. We propose \\emph{ClassiNet} -- a network of\nclassifiers trained for predicting missing features in a given instance, to\novercome the feature sparseness problem. Using a set of unlabeled training\ninstances, we first learn binary classifiers as feature predictors for\npredicting whether a particular feature occurs in a given instance. Next, each\nfeature predictor is represented as a vertex $v_i$ in the ClassiNet where a\none-to-one correspondence exists between feature predictors and vertices. The\nweight of the directed edge $e_{ij}$ connecting a vertex $v_i$ to a vertex\n$v_j$ represents the conditional probability that given $v_i$ exists in an\ninstance, $v_j$ also exists in the same instance. We show that ClassiNets\ngeneralize word co-occurrence graphs by considering implicit co-occurrences\nbetween features. We extract numerous features from the trained ClassiNet to\novercome feature sparseness. In particular, for a given instance $\\vec{x}$, we\nfind similar features from ClassiNet that did not appear in $\\vec{x}$, and\nappend those features in the representation of $\\vec{x}$. Moreover, we propose\na method based on graph propagation to find features that are indirectly\nrelated to a given short-text. We evaluate ClassiNets on several benchmark\ndatasets for short-text classification. Our experimental results show that by\nusing ClassiNet, we can statistically significantly improve the accuracy in\nshort-text classification tasks, without having to use any external resources\nsuch as thesauri for finding related features.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 18:24:06 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bollegala", "Danushka", ""], ["Atanasov", "Vincent", ""], ["Maehara", "Takanori", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1804.05267", "submitter": "Marc Ortiz", "authors": "Marc Ortiz, Adri\\'an Cristal, Eduard Ayguad\\'e and Marc Casas", "title": "Low-Precision Floating-Point Schemes for Neural Network Training", "comments": "16 pages, 9 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of low-precision fixed-point arithmetic along with stochastic\nrounding has been proposed as a promising alternative to the commonly used\n32-bit floating point arithmetic to enhance training neural networks training\nin terms of performance and energy efficiency. In the first part of this paper,\nthe behaviour of the 12-bit fixed-point arithmetic when training a\nconvolutional neural network with the CIFAR-10 dataset is analysed, showing\nthat such arithmetic is not the most appropriate for the training phase. After\nthat, the paper presents and evaluates, under the same conditions, alternative\nlow-precision arithmetics, starting with the 12-bit floating-point arithmetic.\nThese two representations are then leveraged using local scaling in order to\nincrease accuracy and get closer to the baseline 32-bit floating-point\narithmetic. Finally, the paper introduces a simplified model in which both the\noutputs and the gradients of the neural networks are constrained to\npower-of-two values, just using 7 bits for their representation. The evaluation\ndemonstrates a minimal loss in accuracy for the proposed Power-of-Two neural\nnetwork, avoiding the use of multiplications and divisions and thereby,\nsignificantly reducing the training time as well as the energy consumption and\nmemory requirements during the training and inference phases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 19:10:07 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ortiz", "Marc", ""], ["Cristal", "Adri\u00e1n", ""], ["Ayguad\u00e9", "Eduard", ""], ["Casas", "Marc", ""]]}, {"id": "1804.05271", "submitter": "Shiqiang Wang", "authors": "Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung,\n  Christian Makaya, Ting He, Kevin Chan", "title": "Adaptive Federated Learning in Resource Constrained Edge Computing\n  Systems", "comments": "This version (excluding appendices) has been accepted for publication\n  in the IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging technologies and applications including Internet of Things (IoT),\nsocial networking, and crowd-sourcing generate large amounts of data at the\nnetwork edge. Machine learning models are often built from the collected data,\nto enable the detection, classification, and prediction of future events. Due\nto bandwidth, storage, and privacy concerns, it is often impractical to send\nall the data to a centralized location. In this paper, we consider the problem\nof learning model parameters from data distributed across multiple edge nodes,\nwithout sending raw data to a centralized place. Our focus is on a generic\nclass of machine learning models that are trained using gradient-descent based\napproaches. We analyze the convergence bound of distributed gradient descent\nfrom a theoretical point of view, based on which we propose a control algorithm\nthat determines the best trade-off between local update and global parameter\naggregation to minimize the loss function under a given resource budget. The\nperformance of the proposed algorithm is evaluated via extensive experiments\nwith real datasets, both on a networked prototype system and in a larger-scale\nsimulated environment. The experimentation results show that our proposed\napproach performs near to the optimum with various machine learning models and\ndifferent data distributions.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 20:21:48 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 21:24:35 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 03:42:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wang", "Shiqiang", ""], ["Tuor", "Tiffany", ""], ["Salonidis", "Theodoros", ""], ["Leung", "Kin K.", ""], ["Makaya", "Christian", ""], ["He", "Ting", ""], ["Chan", "Kevin", ""]]}, {"id": "1804.05283", "submitter": "Shiyong Ma", "authors": "Shiyong Ma, Zhen Zhang", "title": "OmicsMapNet: Transforming omics data to take advantage of Deep\n  Convolutional Neural Network for discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed OmicsMapNet approach to take advantage of existing deep leaning\nframeworks to analyze high-dimensional omics data as 2-dimensional images. The\nomics data of individual samples were first rearranged into 2D images in which\nmolecular features related in functions, ontologies, or other relationships\nwere organized in spatially adjacent and patterned locations. Deep learning\nneural networks were trained to classify the images. Molecular features\ninformative of classes of different phenotypes were subsequently identified. As\nan example, we used the KEGG BRITE database to rearrange RNA-Seq expression\ndata of TCGA diffuse glioma samples as treemaps to capture the functional\nhierarchical structure of genes in 2D images. Deep Convolutional Neural\nNetworks (CNN) were derived using tools from TensorFlow to learn the grade of\nTCGA LGG and GBM samples with relatively high accuracy. The most contributory\nfeatures in the trained CNN were confirmed in pathway analysis for their\nplausible functional involvement.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 22:22:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:46:16 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ma", "Shiyong", ""], ["Zhang", "Zhen", ""]]}, {"id": "1804.05296", "submitter": "Samuel Finlayson", "authors": "Samuel G. Finlayson, Hyung Won Chung, Isaac S. Kohane, Andrew L. Beam", "title": "Adversarial Attacks Against Medical Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of adversarial examples has raised concerns about the practical\ndeployment of deep learning systems. In this paper, we demonstrate that\nadversarial examples are capable of manipulating deep learning systems across\nthree clinical domains. For each of our representative medical deep learning\nclassifiers, both white and black box attacks were highly successful. Our\nmodels are representative of the current state of the art in medical computer\nvision and, in some cases, directly reflect architectures already seeing\ndeployment in real world clinical settings. In addition to the technical\ncontribution of our paper, we synthesize a large body of knowledge about the\nhealthcare system to argue that medicine may be uniquely susceptible to\nadversarial attacks, both in terms of monetary incentives and technical\nvulnerability. To this end, we outline the healthcare economy and the\nincentives it creates for fraud and provide concrete examples of how and why\nsuch attacks could be realistically carried out. We urge practitioners to be\naware of current vulnerabilities when deploying deep learning systems in\nclinical settings, and encourage the machine learning community to further\ninvestigate the domain-specific characteristics of medical learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 02:33:08 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 02:07:47 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 06:03:22 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Finlayson", "Samuel G.", ""], ["Chung", "Hyung Won", ""], ["Kohane", "Isaac S.", ""], ["Beam", "Andrew L.", ""]]}, {"id": "1804.05316", "submitter": "Shengdong Zhang", "authors": "Shengdong Zhang", "title": "From CDF to PDF --- A Density Estimation Method for High Dimensional\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CDF2PDF is a method of PDF estimation by approximating CDF. The original idea\nof it was previously proposed in [1] called SIC. However, SIC requires\nadditional hyper-parameter tunning, and no algorithms for computing higher\norder derivative from a trained NN are provided in [1]. CDF2PDF improves SIC by\navoiding the time-consuming hyper-parameter tuning part and enabling higher\norder derivative computation to be done in polynomial time. Experiments of this\nmethod for one-dimensional data shows promising results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 07:38:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zhang", "Shengdong", ""]]}, {"id": "1804.05320", "submitter": "Indrasis Chakraborty", "authors": "Indrasis Chakraborty, Rudrasis Chakraborty, Draguna Vrabie", "title": "Generative Adversarial Network based Autoencoder: Application to fault\n  detection problem for closed loop dynamical systems", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection problem for closed loop uncertain dynamical systems, is\ninvestigated in this paper, using different deep learning based methods.\nTraditional classifier based method does not perform well, because of the\ninherent difficulty of detecting system level faults for closed loop dynamical\nsystem. Specifically, acting controller in any closed loop dynamical system,\nworks to reduce the effect of system level faults. A novel Generative\nAdversarial based deep Autoencoder is designed to classify datasets under\nnormal and faulty operating conditions. This proposed network performs\nsignificantly well when compared to any available classifier based methods, and\nmoreover, does not require labeled fault incorporated datasets for training\npurpose. Finally, this aforementioned network's performance is tested on a high\ncomplexity building energy system dataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 08:28:15 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 03:21:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chakraborty", "Indrasis", ""], ["Chakraborty", "Rudrasis", ""], ["Vrabie", "Draguna", ""]]}, {"id": "1804.05345", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Igor Gilitschenski, Dan Feldman,\n  Daniela Rus", "title": "Data-Dependent Coresets for Compressing Neural Networks with\n  Applications to Generalization Bounds", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient coresets-based neural network compression algorithm\nthat sparsifies the parameters of a trained fully-connected neural network in a\nmanner that provably approximates the network's output. Our approach is based\non an importance sampling scheme that judiciously defines a sampling\ndistribution over the neural network parameters, and as a result, retains\nparameters of high importance while discarding redundant ones. We leverage a\nnovel, empirical notion of sensitivity and extend traditional coreset\nconstructions to the application of compressing parameters. Our theoretical\nanalysis establishes guarantees on the size and accuracy of the resulting\ncompressed network and gives rise to generalization bounds that may provide new\ninsights into the generalization properties of neural networks. We demonstrate\nthe practical effectiveness of our algorithm on a variety of neural network\nconfigurations and real-world data sets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 12:22:23 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 05:52:18 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 14:41:51 GMT"}, {"version": "v4", "created": "Wed, 5 Sep 2018 18:01:41 GMT"}, {"version": "v5", "created": "Wed, 20 Feb 2019 18:23:51 GMT"}, {"version": "v6", "created": "Sat, 18 May 2019 00:12:21 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Gilitschenski", "Igor", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "1804.05374", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Dmitriy Serdyuk, Yoshua Bengio", "title": "Twin Regularization for online speech recognition", "comments": "Accepted at INTESPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 15:52:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:00:03 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Serdyuk", "Dmitriy", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.05402", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "Approximating the covariance ellipsoid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore ways in which the covariance ellipsoid ${\\cal B}=\\{v \\in\n\\mathbb{R}^d : \\mathbb{E} <X,v>^2 \\leq 1\\}$ of a centred random vector $X$ in\n$\\mathbb{R}^d$ can be approximated by a simple set. The data one is given for\nconstructing the approximating set consists of $X_1,...,X_N$ that are\nindependent and distributed as $X$.\n  We present a general method that can be used to construct such approximations\nand implement it for two types of approximating sets. We first construct a\n(random) set ${\\cal K}$ defined by a union of intersections of slabs\n$H_{z,\\alpha}=\\{v \\in \\mathbb{R}^d : |<z,v>| \\leq \\alpha\\}$ (and therefore\n${\\cal K}$ is actually the output of a neural network with two hidden layers).\nThe slabs are generated using $X_1,...,X_N$, and under minimal assumptions on\n$X$ (e.g., $X$ can be heavy-tailed) it suffices that $N = c_1d\n\\eta^{-4}\\log(2/\\eta)$ to ensure that $(1-\\eta) {\\cal K} \\subset {\\cal B}\n\\subset (1+\\eta){\\cal K}$. In some cases (e.g., if $X$ is rotation invariant\nand has marginals that are well behaved in some weak sense), a smaller sample\nsize suffices: $N = c_1d\\eta^{-2}\\log(2/\\eta)$.\n  We then show that if the slabs are replaced by randomly generated ellipsoids\ndefined using $X_1,...,X_N$, the same degree of approximation is true when $N\n\\geq c_2d\\eta^{-2}\\log(2/\\eta)$.\n  The construction we use is based on the small-ball method.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 18:07:44 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "1804.05433", "submitter": "Nicole M\\\"ucke", "authors": "Nicole M\\\"ucke", "title": "Adaptivity for Regularized Kernel Methods by Lepskii's Principle", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.26552.24325", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of {\\it adaptivity} in the framework of reproducing\nkernel Hilbert space (RKHS) regression. More precisely, we analyze estimators\narising from a linear regularization scheme $g_\\lam$. In practical\napplications, an important task is to choose the regularization parameter\n$\\lam$ appropriately, i.e. based only on the given data and independently on\nunknown structural assumptions on the regression function. An attractive\napproach avoiding data-splitting is the {\\it Lepskii Principle} (LP), also\nknown as the {\\it Balancing Principle} is this setting. We show that a modified\nparameter choice based on (LP) is minimax optimal adaptive, up to\n$\\log\\log(n)$. A convenient result is the fact that balancing in $L^2(\\nu)-$\nnorm, which is easiest, automatically gives optimal balancing in all stronger\nnorms, interpolating between $L^2(\\nu)$ and the RKHS. An analogous result is\nopen for other classical approaches to data dependent choices of the\nregularization parameter, e.g. for Hold-Out.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:27:04 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["M\u00fccke", "Nicole", ""]]}, {"id": "1804.05454", "submitter": "Tony Jebara", "authors": "Tony Jebara", "title": "A refinement of Bennett's inequality with applications to portfolio\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG q-fin.PM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A refinement of Bennett's inequality is introduced which is strictly tighter\nthan the classical bound. The new bound establishes the convergence of the\naverage of independent random variables to its expected value. It also\ncarefully exploits information about the potentially heterogeneous mean,\nvariance, and ceiling of each random variable. The bound is strictly sharper in\nthe homogeneous setting and very often significantly sharper in the\nheterogeneous setting. The improved convergence rates are obtained by\nleveraging Lambert's W function. We apply the new bound in a portfolio\noptimization setting to allocate a budget across investments with heterogeneous\nreturns.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 00:11:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Jebara", "Tony", ""]]}, {"id": "1804.05464", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar and Lillian J. Ratliff and S. Shankar Sastry", "title": "On Gradient-Based Learning in Continuous Games", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science 2020 2:1, 103-131", "doi": "10.1137/18M1231298", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a general framework for competitive gradient-based learning that\nencompasses a wide breadth of multi-agent learning algorithms, and analyze the\nlimiting behavior of competitive gradient-based learning algorithms using\ndynamical systems theory. For both general-sum and potential games, we\ncharacterize a non-negligible subset of the local Nash equilibria that will be\navoided if each agent employs a gradient-based learning algorithm. We also shed\nlight on the issue of convergence to non-Nash strategies in general- and\nzero-sum games, which may have no relevance to the underlying game, and arise\nsolely due to the choice of algorithm. The existence and frequency of such\nstrategies may explain some of the difficulties encountered when using gradient\ndescent in zero-sum games as, e.g., in the training of generative adversarial\nnetworks. To reinforce the theoretical contributions, we provide empirical\nresults that highlight the frequency of linear quadratic dynamic games (a\nbenchmark for multi-agent reinforcement learning) that admit global Nash\nequilibria that are almost surely avoided by policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:14:17 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 03:54:44 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 18:26:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mazumdar", "Eric", ""], ["Ratliff", "Lillian J.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1804.05470", "submitter": "Anant Gupta", "authors": "Laura Graesser and Anant Gupta", "title": "Composable Unpaired Image to Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been remarkable recent work in unpaired image-to-image translation.\nHowever, they're restricted to translation on single pairs of distributions,\nwith some exceptions. In this study, we extend one of these works to a scalable\nmultidistribution translation mechanism. Our translation models not only\nconverts from one distribution to another but can be stacked to create\ncomposite translation functions. We show that this composite property makes it\npossible to generate images with characteristics not seen in the training set.\nWe also propose a decoupled training mechanism to train multiple distributions\nseparately, which we show, generates better samples than isolated joint\ntraining. Further, we do a qualitative and quantitative analysis to assess the\nplausibility of the samples. The code is made available at\nhttps://github.com/lgraesser/im2im2im.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:38:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Graesser", "Laura", ""], ["Gupta", "Anant", ""]]}, {"id": "1804.05474", "submitter": "Jonathan Shafer", "authors": "Ido Nachum, Jonathan Shafer, Amir Yehudayoff", "title": "A Direct Sum Result for the Information Complexity of Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many bits of information are required to PAC learn a class of hypotheses\nof VC dimension $d$? The mathematical setting we follow is that of Bassily et\nal. (2018), where the value of interest is the mutual information\n$\\mathrm{I}(S;A(S))$ between the input sample $S$ and the hypothesis outputted\nby the learning algorithm $A$. We introduce a class of functions of VC\ndimension $d$ over the domain $\\mathcal{X}$ with information complexity at\nleast $\\Omega\\left(d\\log \\log \\frac{|\\mathcal{X}|}{d}\\right)$ bits for any\nconsistent and proper algorithm (deterministic or random). Bassily et al.\nproved a similar (but quantitatively weaker) result for the case $d=1$.\n  The above result is in fact a special case of a more general phenomenon we\nexplore. We define the notion of information complexity of a given class of\nfunctions $\\mathcal{H}$. Intuitively, it is the minimum amount of information\nthat an algorithm for $\\mathcal{H}$ must retain about its input to ensure\nconsistency and properness. We prove a direct sum result for information\ncomplexity in this context; roughly speaking, the information complexity sums\nwhen combining several classes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:56:39 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Nachum", "Ido", ""], ["Shafer", "Jonathan", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1804.05482", "submitter": "Ignacio Ramirez", "authors": "Ignacio Ramirez", "title": "Binary Matrix Factorization via Dictionary Learning", "comments": "submitted for review to IEEE JSTSP on April 15th, 2018", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2875674", "report-no": null, "categories": "stat.ML cs.CV cs.IR cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Matrix factorization is a key tool in data analysis; its applications include\nrecommender systems, correlation analysis, signal processing, among others.\nBinary matrices are a particular case which has received significant attention\nfor over thirty years, especially within the field of data mining. Dictionary\nlearning refers to a family of methods for learning overcomplete basis (also\ncalled frames) in order to efficiently encode samples of a given type; this\narea, now also about twenty years old, was mostly developed within the signal\nprocessing field. In this work we propose two binary matrix factorization\nmethods based on a binary adaptation of the dictionary learning paradigm to\nbinary matrices. The proposed algorithms focus on speed and scalability; they\nwork with binary factors combined with bit-wise operations and a few auxiliary\ninteger ones. Furthermore, the methods are readily applicable to online binary\nmatrix factorization. Another important issue in matrix factorization is the\nchoice of rank for the factors; we address this model selection problem with an\nefficient method based on the Minimum Description Length principle. Our\npreliminary results show that the proposed methods are effective at producing\ninterpretable factorizations of various data types of different nature.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 02:36:24 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 01:13:05 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ramirez", "Ignacio", ""]]}, {"id": "1804.05484", "submitter": "Yao Lu", "authors": "Yao Lu, Mehrtash Harandi, Richard Hartley, Razvan Pascanu", "title": "Block Mean Approximation for Efficient Second Order Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced optimization algorithms such as Newton method and AdaGrad benefit\nfrom second order derivative or second order statistics to achieve better\ndescent directions and faster convergence rates. At their heart, such\nalgorithms need to compute the inverse or inverse square root of a matrix whose\nsize is quadratic of the dimensionality of the search space. For high\ndimensional search spaces, the matrix inversion or inversion of square root\nbecomes overwhelming which in turn demands for approximate methods. In this\nwork, we propose a new matrix approximation method which divides a matrix into\nblocks and represents each block by one or two numbers. The method allows\nefficient computation of matrix inverse and inverse square root. We apply our\nmethod to AdaGrad in training deep neural networks. Experiments show\nencouraging results compared to the diagonal approximation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 02:52:45 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 02:07:58 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 19:10:54 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Lu", "Yao", ""], ["Harandi", "Mehrtash", ""], ["Hartley", "Richard", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1804.05494", "submitter": "Niharika Gauraha", "authors": "Niharika Gauraha and Ola Spjuth", "title": "conformalClassification: A Conformal Prediction R Package for\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conformalClassification package implements Transductive Conformal\nPrediction (TCP) and Inductive Conformal Prediction (ICP) for classification\nproblems. Conformal Prediction (CP) is a framework that complements the\npredictions of machine learning algorithms with reliable measures of\nconfidence. TCP gives results with higher validity than ICP, however ICP is\ncomputationally faster than TCP. The package conformalClassification is built\nupon the random forest method, where votes of the random forest for each class\nare considered as the conformity scores for each data point. Although the main\naim of the conformalClassification package is to generate CP errors (p-values)\nfor classification problems, the package also implements various diagnostic\nmeasures such as deviation from validity, error rate, efficiency, observed\nfuzziness and calibration plots. In future releases, we plan to extend the\npackage to use other machine learning algorithms, (e.g. support vector\nmachines) for model fitting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 03:45:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gauraha", "Niharika", ""], ["Spjuth", "Ola", ""]]}, {"id": "1804.05497", "submitter": "Jongyoon Song", "authors": "Jaekoo Lee, Byunghan Lee, Jongyoon Song, Jaesik Yoon, Yongsik Lee,\n  Donghun Lee, Sungroh Yoon", "title": "Deep Learning on Key Performance Indicators for Predictive Maintenance\n  in SAP HANA", "comments": "This version withdrawn by arXiv administrators because the author did\n  not have the right to agree to our license at the time of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a new era of cloud and big data, Database Management Systems (DBMSs)\nhave become more crucial in numerous enterprise business applications in all\nthe industries. Accordingly, the importance of their proactive and preventive\nmaintenance has also increased. However, detecting problems by predefined rules\nor stochastic modeling has limitations, particularly when analyzing the data on\nhigh-dimensional Key Performance Indicators (KPIs) from a DBMS. In recent\nyears, Deep Learning (DL) has opened new opportunities for this complex\nanalysis. In this paper, we present two complementary DL approaches to detect\nanomalies in SAP HANA. A temporal learning approach is used to detect abnormal\npatterns based on unlabeled historical data, whereas a spatial learning\napproach is used to classify known anomalies based on labeled data. We\nimplement a system in SAP HANA integrated with Google TensorFlow. The\nexperimental results with real-world data confirm the effectiveness of the\nsystem and models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 03:55:42 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lee", "Jaekoo", ""], ["Lee", "Byunghan", ""], ["Song", "Jongyoon", ""], ["Yoon", "Jaesik", ""], ["Lee", "Yongsik", ""], ["Lee", "Donghun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1804.05515", "submitter": "Hongyu Xu", "authors": "Hongyu Xu, Zhangyang Wang, Haichuan Yang, Ding Liu and Ji Liu", "title": "Learning Simple Thresholded Features with Sparse Support Recovery", "comments": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thresholded feature has recently emerged as an extremely efficient, yet\nrough empirical approximation, of the time-consuming sparse coding inference\nprocess. Such an approximation has not yet been rigorously examined, and\nstandard dictionaries often lead to non-optimal performance when used for\ncomputing thresholded features. In this paper, we first present two theoretical\nrecovery guarantees for the thresholded feature to exactly recover the nonzero\nsupport of the sparse code. Motivated by them, we then formulate the Dictionary\nLearning for Thresholded Features (DLTF) model, which learns an optimized\ndictionary for applying the thresholded feature. In particular, for the $(k,\n2)$ norm involved, a novel proximal operator with log-linear time complexity\n$O(m\\log m)$ is derived. We evaluate the performance of DLTF on a vast range of\nsynthetic and real-data tasks, where DLTF demonstrates remarkable efficiency,\neffectiveness and robustness in all experiments. In addition, we briefly\ndiscuss the potential link between DLTF and deep learning building blocks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 06:20:55 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:10:17 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Xu", "Hongyu", ""], ["Wang", "Zhangyang", ""], ["Yang", "Haichuan", ""], ["Liu", "Ding", ""], ["Liu", "Ji", ""]]}, {"id": "1804.05544", "submitter": "Arvind Kumar Shekar", "authors": "Arvind Kumar Shekar, Cl\\'audio Rebelo de S\\'a, Hugo Ferreira, Carlos\n  Soares", "title": "Building robust prediction models for defective sensor data using\n  Artificial Neural Networks", "comments": "16 pages, 7 figures. Currently under review. This research has\n  obtained funding from the Electronic Components and Systems for European\n  Leadership (ECSEL) Joint Undertaking, the framework programme for research\n  and innovation Horizon 2020 (2014-2020) under grant agreement number\n  662189-MANTIS-2014-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the health of components in complex dynamic systems such as an\nautomobile poses numerous challenges. The primary aim of such predictive\nsystems is to use the high-dimensional data acquired from different sensors and\npredict the state-of-health of a particular component, e.g., brake pad. The\nclassical approach involves selecting a smaller set of relevant sensor signals\nusing feature selection and using them to train a machine learning algorithm.\nHowever, this fails to address two prominent problems: (1) sensors are\nsusceptible to failure when exposed to extreme conditions over a long periods\nof time; (2) sensors are electrical devices that can be affected by noise or\nelectrical interference. Using the failed and noisy sensor signals as inputs\nlargely reduce the prediction accuracy. To tackle this problem, it is\nadvantageous to use the information from all sensor signals, so that the\nfailure of one sensor can be compensated by another. In this work, we propose\nan Artificial Neural Network (ANN) based framework to exploit the information\nfrom a large number of signals. Secondly, our framework introduces a data\naugmentation approach to perform accurate predictions in spite of noisy\nsignals. The plausibility of our framework is validated on real life industrial\napplication from Robert Bosch GmbH.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 08:25:02 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Shekar", "Arvind Kumar", ""], ["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Ferreira", "Hugo", ""], ["Soares", "Carlos", ""]]}, {"id": "1804.05567", "submitter": "Dmitry Babichev", "authors": "Dmitry Babichev, Francis Bach", "title": "Constant Step Size Stochastic Gradient Descent for Probabilistic\n  Modeling", "comments": "Published in Proc. UAI 2018, was accepted as oral presentation Camera\n  ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient methods enable learning probabilistic models from large\namounts of data. While large step-sizes (learning rates) have shown to be best\nfor least-squares (e.g., Gaussian noise) once combined with parameter\naveraging, these are not leading to convergent algorithms in general. In this\npaper, we consider generalized linear models, that is, conditional models based\non exponential families. We propose averaging moment parameters instead of\nnatural parameters for constant-step-size stochastic gradient descent. For\nfinite-dimensional models, we show that this can sometimes (and surprisingly)\nlead to better predictions than the best linear model. For infinite-dimensional\nmodels, we show that it always converges to optimal predictions, while\naveraging natural parameters never does. We illustrate our findings with\nsimulations on synthetic data and classical benchmarks with many observations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 09:32:13 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 12:56:07 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Babichev", "Dmitry", ""], ["Bach", "Francis", ""]]}, {"id": "1804.05589", "submitter": "Vural Aksakalli", "authors": "Zeren D. Yenice, Niranjan Adhikari, Yong Kai Wong, Vural Aksakalli,\n  Alev Taskin Gumus, Babak Abbasi", "title": "SPSA-FSR: Simultaneous Perturbation Stochastic Approximation for Feature\n  Selection and Ranking", "comments": "The methodology introduced in this manuscript, both for feature\n  selection and feature ranking, has been implemented as the \"spFSR\" R package", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript presents the following: (1) an improved version of the Binary\nSimultaneous Perturbation Stochastic Approximation (SPSA) Method for feature\nselection in machine learning (Aksakalli and Malekipirbazari, Pattern\nRecognition Letters, Vol. 75, 2016) based on non-monotone iteration gains\ncomputed via the Barzilai and Borwein (BB) method, (2) its adaptation for\nfeature ranking, and (3) comparison against popular methods on public benchmark\ndatasets. The improved method, which we call SPSA-FSR, dramatically reduces the\nnumber of iterations required for convergence without impacting solution\nquality. SPSA-FSR can be used for feature ranking and feature selection both\nfor classification and regression problems. After a review of the current\nstate-of-the-art, we discuss our improvements in detail and present three sets\nof computational experiments: (1) comparison of SPSA-FS as a (wrapper) feature\nselection method against sequential methods as well as genetic algorithms, (2)\ncomparison of SPSA-FS as a feature ranking method in a classification setting\nagainst random forest importance, chi-squared, and information main methods,\nand (3) comparison of SPSA-FS as a feature ranking method in a regression\nsetting against minimum redundancy maximum relevance (MRMR), RELIEF, and linear\ncorrelation methods. The number of features in the datasets we use range from a\nfew dozens to a few thousands. Our results indicate that SPSA-FS converges to a\ngood feature set in no more than 100 iterations and therefore it is quite fast\nfor a wrapper method. SPSA-FS also outperforms popular feature selection as\nwell as feature ranking methods in majority of test cases, sometimes by a large\nmargin, and it stands as a promising new feature selection and ranking method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 10:13:54 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Yenice", "Zeren D.", ""], ["Adhikari", "Niranjan", ""], ["Wong", "Yong Kai", ""], ["Aksakalli", "Vural", ""], ["Gumus", "Alev Taskin", ""], ["Abbasi", "Babak", ""]]}, {"id": "1804.05714", "submitter": "Cunxi Yu", "authors": "Cunxi Yu and Houping Xiao and Giovanni De Micheli", "title": "Developing Synthesis Flows Without Human Knowledge", "comments": "To appear in 2018 55th Design Automation Conference (DAC'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design flows are the explicit combinations of design transformations,\nprimarily involved in synthesis, placement and routing processes, to accomplish\nthe design of Integrated Circuits (ICs) and System-on-Chip (SoC). Mostly, the\nflows are developed based on the knowledge of the experts. However, due to the\nlarge search space of design flows and the increasing design complexity,\ndeveloping Intellectual Property (IP)-specific synthesis flows providing high\nQuality of Result (QoR) is extremely challenging. This work presents a fully\nautonomous framework that artificially produces design-specific synthesis flows\nwithout human guidance and baseline flows, using Convolutional Neural Network\n(CNN). The demonstrations are made by successfully designing logic synthesis\nflows of three large scaled designs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 14:56:09 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 12:53:41 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 15:55:49 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Yu", "Cunxi", ""], ["Xiao", "Houping", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "1804.05753", "submitter": "Taylor Pospisil", "authors": "Taylor Pospisil and Ann B. Lee", "title": "RFCDE: Random Forests for Conditional Density Estimation", "comments": "Fix URL in Arxiv abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests is a common non-parametric regression technique which performs\nwell for mixed-type data and irrelevant covariates, while being robust to\nmonotonic variable transformations. Existing random forest implementations\ntarget regression or classification. We introduce the RFCDE package for fitting\nrandom forest models optimized for nonparametric conditional density\nestimation, including joint densities for multiple responses. This enables\nanalysis of conditional probability distributions which is useful for\npropagating uncertainty and of joint distributions that describe relationships\nbetween multiple responses and covariates. RFCDE is released under the MIT\nopen-source license and can be accessed at https://github.com/tpospisi/rfcde .\nBoth R and Python versions, which call a common C++ library, are available.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 15:47:07 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 21:36:57 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Pospisil", "Taylor", ""], ["Lee", "Ann B.", ""]]}, {"id": "1804.05774", "submitter": "Sergio Ram\\'irez-Gallego", "authors": "Sergio Ram\\'irez-Gallego and Salvador Garc\\'ia and Ning Xiong and\n  Francisco Herrera", "title": "BELIEF: A distance-based redundancy-proof feature selection method for\n  Big Data", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Big Data era, data reduction methods are highly demanded\ngiven its ability to simplify huge data, and ease complex learning processes.\nConcretely, algorithms that are able to filter relevant dimensions from a set\nof millions are of huge importance. Although effective, these techniques suffer\nfrom the \"scalability\" curse as well.\n  In this work, we propose a distributed feature weighting algorithm, which is\nable to rank millions of features in parallel using large samples. This method,\ninspired by the well-known RELIEF algorithm, introduces a novel redundancy\nelimination measure that provides similar schemes to those based on entropy at\na much lower cost. It also allows smooth scale up when more instances are\ndemanded in feature estimations. Empirical tests performed on our method show\nits estimation ability in manifold huge sets --both in number of features and\ninstances--, as well as its simplified runtime cost (specially, at the\nredundancy detection step).\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 16:23:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ram\u00edrez-Gallego", "Sergio", ""], ["Garc\u00eda", "Salvador", ""], ["Xiong", "Ning", ""], ["Herrera", "Francisco", ""]]}, {"id": "1804.05805", "submitter": "Wenjie Ruan", "authors": "Wenjie Ruan, Min Wu, Youcheng Sun, Xiaowei Huang, Daniel Kroening,\n  Marta Kwiatkowska", "title": "Global Robustness Evaluation of Deep Neural Networks with Provable\n  Guarantees for the $L_0$ Norm", "comments": "42 Pages, Github: https://github.com/TrustAI/L0-TRE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep neural networks (DNNs) in safety- or security-critical\nsystems requires provable guarantees on their correct behaviour. A common\nrequirement is robustness to adversarial perturbations in a neighbourhood\naround an input. In this paper we focus on the $L_0$ norm and aim to compute,\nfor a trained DNN and an input, the maximal radius of a safe norm ball around\nthe input within which there are no adversarial examples. Then we define global\nrobustness as an expectation of the maximal safe radius over a test data set.\nWe first show that the problem is NP-hard, and then propose an approximate\napproach to iteratively compute lower and upper bounds on the network's\nrobustness. The approach is \\emph{anytime}, i.e., it returns intermediate\nbounds and robustness estimates that are gradually, but strictly, improved as\nthe computation proceeds; \\emph{tensor-based}, i.e., the computation is\nconducted over a set of inputs simultaneously, instead of one by one, to enable\nefficient GPU computation; and has \\emph{provable guarantees}, i.e., both the\nbounds and the robustness estimates can converge to their optimal values.\nFinally, we demonstrate the utility of the proposed approach in practice to\ncompute tight bounds by applying and adapting the anytime algorithm to a set of\nchallenging problems, including global robustness evaluation, competitive $L_0$\nattacks, test case generation for DNNs, and local robustness evaluation on\nlarge-scale ImageNet DNNs. We release the code of all case studies via GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:24:51 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 16:57:22 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ruan", "Wenjie", ""], ["Wu", "Min", ""], ["Sun", "Youcheng", ""], ["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1804.05806", "submitter": "Linh Le", "authors": "Linh Le, Ying Xie", "title": "Deep Embedding Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel supervised learning method that is called\nDeep Embedding Kernel (DEK). DEK combines the advantages of deep learning and\nkernel methods in a unified framework. More specifically, DEK is a learnable\nkernel represented by a newly designed deep architecture. Compared with\npre-defined kernels, this kernel can be explicitly trained to map data to an\noptimized high-level feature space where data may have favorable features\ntoward the application. Compared with typical deep learning using SoftMax or\nlogistic regression as the top layer, DEK is expected to be more generalizable\nto new data. Experimental results show that DEK has superior performance than\ntypical machine learning methods in identity detection, classification,\nregression, dimension reduction, and transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:25:24 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Le", "Linh", ""], ["Xie", "Ying", ""]]}, {"id": "1804.05810", "submitter": "Shang-Tse Chen", "authors": "Shang-Tse Chen, Cory Cornelius, Jason Martin, Duen Horng Chau", "title": "ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object\n  Detector", "comments": null, "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases, pp. 52-68, 2018", "doi": "10.1007/978-3-030-10925-7_4", "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the ability to directly manipulate image pixels in the digital input\nspace, an adversary can easily generate imperceptible perturbations to fool a\nDeep Neural Network (DNN) image classifier, as demonstrated in prior work. In\nthis work, we propose ShapeShifter, an attack that tackles the more challenging\nproblem of crafting physical adversarial perturbations to fool image-based\nobject detectors like Faster R-CNN. Attacking an object detector is more\ndifficult than attacking an image classifier, as it needs to mislead the\nclassification results in multiple bounding boxes with different scales.\nExtending the digital attack to the physical world adds another layer of\ndifficulty, because it requires the perturbation to be robust enough to survive\nreal-world distortions due to different viewing distances and angles, lighting\nconditions, and camera limitations. We show that the Expectation over\nTransformation technique, which was originally proposed to enhance the\nrobustness of adversarial perturbations in image classification, can be\nsuccessfully adapted to the object detection setting. ShapeShifter can generate\nadversarially perturbed stop signs that are consistently mis-detected by Faster\nR-CNN as other objects, posing a potential threat to autonomous vehicles and\nother safety-critical computer vision systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:29:43 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 02:22:39 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 03:41:44 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Shang-Tse", ""], ["Cornelius", "Cory", ""], ["Martin", "Jason", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1804.05816", "submitter": "Tanay Kumar Saha", "authors": "Tanay Kumar Saha and Thomas Williams and Mohammad Al Hasan and Shafiq\n  Joty and Nicholas K. Varberg", "title": "Models for Capturing Temporal Smoothness in Evolving Networks for\n  Learning Latent Representation of Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a dynamic network, the neighborhood of the vertices evolve across\ndifferent temporal snapshots of the network. Accurate modeling of this temporal\nevolution can help solve complex tasks involving real-life social and\ninteraction networks. However, existing models for learning latent\nrepresentation are inadequate for obtaining the representation vectors of the\nvertices for different time-stamps of a dynamic network in a meaningful way. In\nthis paper, we propose latent representation learning models for dynamic\nnetworks which overcome the above limitation by considering two different kinds\nof temporal smoothness: (i) retrofitted, and (ii) linear transformation. The\nretrofitted model tracks the representation vector of a vertex over time,\nfacilitating vertex-based temporal analysis of a network. On the other hand,\nlinear transformation based model provides a smooth transition operator which\nmaps the representation vectors of all vertices from one temporal snapshot to\nthe next (unobserved) snapshot-this facilitates prediction of the state of a\nnetwork in a future time-stamp. We validate the performance of our proposed\nmodels by employing them for solving the temporal link prediction task.\nExperiments on 9 real-life networks from various domains validate that the\nproposed models are significantly better than the existing models for\npredicting the dynamics of an evolving network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:40:02 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Saha", "Tanay Kumar", ""], ["Williams", "Thomas", ""], ["Hasan", "Mohammad Al", ""], ["Joty", "Shafiq", ""], ["Varberg", "Nicholas K.", ""]]}, {"id": "1804.05834", "submitter": "Xiaolin Wang", "authors": "Xiaolin Wang", "title": "CytonRL: an Efficient Reinforcement Learning Open-source Toolkit\n  Implemented in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an open-source enforcement learning toolkit named CytonRL\n(https://github.com/arthurxlw/cytonRL). The toolkit implements four recent\nadvanced deep Q-learning algorithms from scratch using C++ and NVIDIA's\nGPU-accelerated libraries. The code is simple and elegant, owing to an\nopen-source general-purpose neural network library named CytonLib. Benchmark\nshows that the toolkit achieves competitive performances on the popular Atari\ngame of Breakout.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 23:17:07 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Wang", "Xiaolin", ""]]}, {"id": "1804.05837", "submitter": "Jiatao Jiang", "authors": "Jiatao Jiang, Chunyan Xu, Zhen Cui, Tong Zhang, Wenming Zheng, Jian\n  Yang", "title": "Walk-Steered Convolution for Graph Classification", "comments": "13 pages, 6 figures, 3 tables", "journal-ref": null, "doi": "10.1109/tnnls.2019.2956095", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a fundamental but challenging issue for numerous\nreal-world applications. Despite recent great progress in image/video\nclassification, convolutional neural networks (CNNs) cannot yet cater to graphs\nwell because of graphical non-Euclidean topology. In this work, we propose a\nwalk-steered convolutional (WSC) network to assemble the essential success of\nstandard convolutional neural networks as well as the powerful representation\nability of random walk. Instead of deterministic neighbor searching used in\nprevious graphical CNNs, we construct multi-scale walk fields (a.k.a. local\nreceptive fields) with random walk paths to depict subgraph structures and\nadvocate graph scalability. To express the internal variations of a walk field,\nGaussian mixture models are introduced to encode principal components of walk\npaths therein. As an analogy to a standard convolution kernel on image,\nGaussian models implicitly coordinate those unordered vertices/nodes and edges\nin a local receptive field after projecting to the gradient space of Gaussian\nparameters. We further stack graph coarsening upon Gaussian encoding by using\ndynamic clustering, such that high-level semantics of graph can be well learned\nlike the conventional pooling on image. The experimental results on several\npublic datasets demonstrate the superiority of our proposed WSC method over\nmany state-of-the-arts for graph classification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 11:32:06 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 13:17:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Jiang", "Jiatao", ""], ["Xu", "Chunyan", ""], ["Cui", "Zhen", ""], ["Zhang", "Tong", ""], ["Zheng", "Wenming", ""], ["Yang", "Jian", ""]]}, {"id": "1804.05839", "submitter": "Jason (Jinquan) Dai", "authors": "Jason Dai, Yiheng Wang, Xin Qiu, Ding Ding, Yao Zhang, Yanzhang Wang,\n  Xianyan Jia, Cherry Zhang, Yan Wan, Zhichao Li, Jiao Wang, Shengsheng Huang,\n  Zhongyuan Wu, Yang Wang, Yuhao Yang, Bowen She, Dongjie Shi, Qi Lu, Kai\n  Huang, Guoqiong Song", "title": "BigDL: A Distributed Deep Learning Framework for Big Data", "comments": "In ACM Symposium of Cloud Computing conference (SoCC) 2019", "journal-ref": null, "doi": "10.1145/3357223.3362707", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents BigDL (a distributed deep learning framework for Apache\nSpark), which has been used by a variety of users in the industry for building\ndeep learning applications on production big data platforms. It allows deep\nlearning applications to run on the Apache Hadoop/Spark cluster so as to\ndirectly process the production data, and as a part of the end-to-end data\nanalysis pipeline for deployment and management. Unlike existing deep learning\nframeworks, BigDL implements distributed, data parallel training directly on\ntop of the functional compute model (with copy-on-write and coarse-grained\noperations) of Spark. We also share real-world experience and \"war stories\" of\nusers that have adopted BigDL to address their challenges(i.e., how to easily\nbuild end-to-end data analysis and deep learning pipelines for their production\ndata).\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 12:04:03 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 03:21:14 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 02:57:37 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 13:12:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Dai", "Jason", ""], ["Wang", "Yiheng", ""], ["Qiu", "Xin", ""], ["Ding", "Ding", ""], ["Zhang", "Yao", ""], ["Wang", "Yanzhang", ""], ["Jia", "Xianyan", ""], ["Zhang", "Cherry", ""], ["Wan", "Yan", ""], ["Li", "Zhichao", ""], ["Wang", "Jiao", ""], ["Huang", "Shengsheng", ""], ["Wu", "Zhongyuan", ""], ["Wang", "Yang", ""], ["Yang", "Yuhao", ""], ["She", "Bowen", ""], ["Shi", "Dongjie", ""], ["Lu", "Qi", ""], ["Huang", "Kai", ""], ["Song", "Guoqiong", ""]]}, {"id": "1804.05862", "submitter": "Wenda Zhou", "authors": "Wenda Zhou and Victor Veitch and Morgane Austern and Ryan P. Adams and\n  Peter Orbanz", "title": "Non-Vacuous Generalization Bounds at the ImageNet Scale: A PAC-Bayesian\n  Compression Approach", "comments": "16 pages, 1 figure. Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are highly overparameterized, with capacity to\nsubstantially overfit to training data. Nevertheless, these networks often\ngeneralize well in practice. It has also been observed that trained networks\ncan often be \"compressed\" to much smaller representations. The purpose of this\npaper is to connect these two empirical observations. Our main technical result\nis a generalization bound for compressed networks based on the compressed size.\nCombined with off-the-shelf compression algorithms, the bound leads to state of\nthe art generalization guarantees; in particular, we provide the first\nnon-vacuous generalization guarantees for realistic architectures applied to\nthe ImageNet classification problem. As additional evidence connecting\ncompression and generalization, we show that compressibility of models that\ntend to overfit is limited: We establish an absolute limit on expected\ncompressibility as a function of expected generalization error, where the\nexpectations are over the random choice of training examples. The bounds are\ncomplemented by empirical results that show an increase in overfitting implies\nan increase in the number of bits required to describe a trained network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 18:01:12 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 17:27:12 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 02:37:14 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhou", "Wenda", ""], ["Veitch", "Victor", ""], ["Austern", "Morgane", ""], ["Adams", "Ryan P.", ""], ["Orbanz", "Peter", ""]]}, {"id": "1804.05922", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W. Cohen, Ruslan\n  Salakhutdinov", "title": "Neural Models for Reasoning over Multiple Mentions using Coreference", "comments": "NAACL 2018 (Short Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in NLP require aggregating information from multiple mentions\nof the same entity which may be far apart in the text. Existing Recurrent\nNeural Network (RNN) layers are biased towards short-term dependencies and\nhence not suited to such tasks. We present a recurrent layer which is instead\nbiased towards coreferent dependencies. The layer uses coreference annotations\nextracted from an external system to connect entity mentions belonging to the\nsame cluster. Incorporating this layer into a state-of-the-art reading\ncomprehension model improves performance on three datasets -- Wikihop, LAMBADA\nand the bAbi AI tasks -- with large gains when training data is scarce.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:07:44 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Jin", "Qiao", ""], ["Yang", "Zhilin", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1804.05929", "submitter": "Fang Liu", "authors": "Fang Liu, Sinong Wang, Swapna Buccapatnam and Ness Shroff", "title": "UCBoost: A Boosting Approach to Tame Complexity and Optimality for\n  Stochastic Bandits", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the open problem of finding low-complexity\nnear-optimal multi-armed bandit algorithms for sequential decision making\nproblems. Existing bandit algorithms are either sub-optimal and computationally\nsimple (e.g., UCB1) or optimal and computationally complex (e.g., kl-UCB). We\npropose a boosting approach to Upper Confidence Bound based algorithms for\nstochastic bandits, that we call UCBoost. Specifically, we propose two types of\nUCBoost algorithms. We show that UCBoost($D$) enjoys $O(1)$ complexity for each\narm per round as well as regret guarantee that is $1/e$-close to that of the\nkl-UCB algorithm. We propose an approximation-based UCBoost algorithm,\nUCBoost($\\epsilon$), that enjoys a regret guarantee $\\epsilon$-close to that of\nkl-UCB as well as $O(\\log(1/\\epsilon))$ complexity for each arm per round.\nHence, our algorithms provide practitioners a practical way to trade optimality\nwith computational complexity. Finally, we present numerical results which show\nthat UCBoost($\\epsilon$) can achieve the same regret performance as the\nstandard kl-UCB while incurring only $1\\%$ of the computational cost of kl-UCB.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:44:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Liu", "Fang", ""], ["Wang", "Sinong", ""], ["Buccapatnam", "Swapna", ""], ["Shroff", "Ness", ""]]}, {"id": "1804.05965", "submitter": "Henry Gouk", "authors": "Henry Gouk, Bernhard Pfahringer, Eibe Frank, Michael Cree", "title": "MaxGain: Regularisation of Neural Networks by Constraining Activation\n  Magnitudes", "comments": "Accepted at ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective regularisation of neural networks is essential to combat\noverfitting due to the large number of parameters involved. We present an\nempirical analogue to the Lipschitz constant of a feed-forward neural network,\nwhich we refer to as the maximum gain. We hypothesise that constraining the\ngain of a network will have a regularising effect, similar to how constraining\nthe Lipschitz constant of a network has been shown to improve generalisation. A\nsimple algorithm is provided that involves rescaling the weight matrix of each\nlayer after each parameter update. We conduct a series of studies on common\nbenchmark datasets, and also a novel dataset that we introduce to enable easier\nsignificance testing for experiments using convolutional networks. Performance\non these datasets compares favourably with other common regularisation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 22:43:41 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 06:39:43 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Gouk", "Henry", ""], ["Pfahringer", "Bernhard", ""], ["Frank", "Eibe", ""], ["Cree", "Michael", ""]]}, {"id": "1804.05981", "submitter": "Siwei Lyu", "authors": "Siwei Lyu and Yiming Ying", "title": "A Univariate Bound of Area Under ROC", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Area under ROC (AUC) is an important metric for binary classification and\nbipartite ranking problems. However, it is difficult to directly optimizing AUC\nas a learning objective, so most existing algorithms are based on optimizing a\nsurrogate loss to AUC. One significant drawback of these surrogate losses is\nthat they require pairwise comparisons among training data, which leads to slow\nrunning time and increasing local storage for online learning. In this work, we\ndescribe a new surrogate loss based on a reformulation of the AUC risk, which\ndoes not require pairwise comparison but rankings of the predictions. We\nfurther show that the ranking operation can be avoided, and the learning\nobjective obtained based on this surrogate enjoys linear complexity in time and\nstorage. We perform experiments to demonstrate the effectiveness of the online\nand batch algorithms for AUC optimization based on the proposed surrogate loss.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 23:33:09 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 14:29:13 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Lyu", "Siwei", ""], ["Ying", "Yiming", ""]]}, {"id": "1804.06021", "submitter": "Yasin Abbasi-Yadkori", "authors": "Yasin Abbasi-Yadkori, Nevena Lazic, Csaba Szepesvari", "title": "Model-Free Linear Quadratic Control via Reduction to Expert Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free approaches for reinforcement learning (RL) and continuous control\nfind policies based only on past states and rewards, without fitting a model of\nthe system dynamics. They are appealing as they are general purpose and easy to\nimplement; however, they also come with fewer theoretical guarantees than\nmodel-based RL. In this work, we present a new model-free algorithm for\ncontrolling linear quadratic (LQ) systems, and show that its regret scales as\n$O(T^{\\xi+2/3})$ for any small $\\xi>0$ if time horizon satisfies $T>C^{1/\\xi}$\nfor a constant $C$. The algorithm is based on a reduction of control of Markov\ndecision processes to an expert prediction problem. In practice, it corresponds\nto a variant of policy iteration with forced exploration, where the policy in\neach phase is greedy with respect to the average of all previous value\nfunctions. This is the first model-free algorithm for adaptive control of LQ\nsystems that provably achieves sublinear regret and has a polynomial\ncomputation cost. Empirically, our algorithm dramatically outperforms standard\npolicy iteration, but performs worse than a model-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 02:52:38 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 17:50:23 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 19:50:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Lazic", "Nevena", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1804.06027", "submitter": "Longfei Li", "authors": "Longfei Li, Peilin Zhao, Jun Zhou, Xiaolong Li", "title": "A Boosting Framework of Factorization Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Factorization Machines (FM) has become more and more popular for\nrecommendation systems, due to its effectiveness in finding informative\ninteractions between features. Usually, the weights for the interactions is\nlearnt as a low rank weight matrix, which is formulated as an inner product of\ntwo low rank matrices. This low rank can help improve the generalization\nability of Factorization Machines. However, to choose the rank properly, it\nusually needs to run the algorithm for many times using different ranks, which\nclearly is inefficient for some large-scale datasets. To alleviate this issue,\nwe propose an Adaptive Boosting framework of Factorization Machines (AdaFM),\nwhich can adaptively search for proper ranks for different datasets without\nre-training. Instead of using a fixed rank for FM, the proposed algorithm will\nadaptively gradually increases its rank according to its performance until the\nperformance does not grow, using boosting strategy. To verify the performance\nof our proposed framework, we conduct an extensive set of experiments on many\nreal-world datasets. Encouraging empirical results shows that the proposed\nalgorithms are generally more effective than state-of-the-art other\nFactorization Machines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:23:40 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Li", "Longfei", ""], ["Zhao", "Peilin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1804.06062", "submitter": "Alok Singh", "authors": "Alok Singh, Eric Stephan, Malachi Schram, Ilkay Altintas", "title": "Deep Learning on Operational Facility Data Related to Large-Scale\n  Distributed Area Scientific Workflows", "comments": null, "journal-ref": "2017 IEEE 13th International Conference on e-Science, 2017, pp.\n  586 to 591", "doi": "10.1109/eScience.2017.94", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed computing platforms provide a robust mechanism to perform\nlarge-scale computations by splitting the task and data among multiple\nlocations, possibly located thousands of miles apart geographically. Although\nsuch distribution of resources can lead to benefits, it also comes with its\nassociated problems such as rampant duplication of file transfers increasing\ncongestion, long job completion times, unexpected site crashing, suboptimal\ndata transfer rates, unpredictable reliability in a time range, and suboptimal\nusage of storage elements. In addition, each sub-system becomes a potential\nfailure node that can trigger system wide disruptions. In this vision paper, we\noutline our approach to leveraging Deep Learning algorithms to discover\nsolutions to unique problems that arise in a system with computational\ninfrastructure that is spread over a wide area. The presented vision, motivated\nby a real scientific use case from Belle II experiments, is to develop\nmultilayer neural networks to tackle forecasting, anomaly detection and\noptimization challenges in a complex and distributed data movement environment.\nThrough this vision based on Deep Learning principles, we aim to achieve\nreduced congestion events, faster file transfer rates, and enhanced site\nreliability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 06:29:56 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:43:16 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Singh", "Alok", ""], ["Stephan", "Eric", ""], ["Schram", "Malachi", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1804.06095", "submitter": "Rachelle Rivero", "authors": "Rachelle Rivero and Tsuyoshi Kato", "title": "Parametric Models for Mutual Kernel Matrix Completion", "comments": "8 pages, 1 figure, 1 table", "journal-ref": null, "doi": "10.1587/transinf.2018EDP7139", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies utilize multiple kernel learning to deal with incomplete-data\nproblem. In this study, we introduce new methods that do not only complete\nmultiple incomplete kernel matrices simultaneously, but also allow control of\nthe flexibility of the model by parameterizing the model matrix. By imposing\nrestrictions on the model covariance, overfitting of the data is avoided. A\nlimitation of kernel matrix estimations done via optimization of an objective\nfunction is that the positive definiteness of the result is not guaranteed. In\nview of this limitation, our proposed methods employ the LogDet divergence,\nwhich ensures the positive definiteness of the resulting inferred kernel\nmatrix. We empirically show that our proposed restricted covariance models,\nemployed with LogDet divergence, yield significant improvements in the\ngeneralization performance of previous completion methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:08:05 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Rivero", "Rachelle", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "1804.06114", "submitter": "Cong Chen", "authors": "Cong Chen, Kim Batselier, Ching-Yun Ko and Ngai Wong", "title": "A Support Tensor Train Machine", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing interest in extending traditional vector-based machine\nlearning techniques to their tensor forms. An example is the support tensor\nmachine (STM) that utilizes a rank-one tensor to capture the data structure,\nthereby alleviating the overfitting and curse of dimensionality problems in the\nconventional support vector machine (SVM). However, the expressive power of a\nrank-one tensor is restrictive for many real-world data. To overcome this\nlimitation, we introduce a support tensor train machine (STTM) by replacing the\nrank-one tensor in an STM with a tensor train. Experiments validate and confirm\nthe superiority of an STTM over the SVM and STM.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:59:13 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Chen", "Cong", ""], ["Batselier", "Kim", ""], ["Ko", "Ching-Yun", ""], ["Wong", "Ngai", ""]]}, {"id": "1804.06188", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Steven Schockaert", "title": "VC-Dimension Based Generalization Bounds for Relational Learning", "comments": "Longer version of paper accepted at ECML PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of relational learning, the available data can be seen\nas a sample from a larger relational structure (e.g. we may be given a small\nfragment from some social network). In this paper we are particularly concerned\nwith scenarios in which we can assume that (i) the domain elements appearing in\nthe given sample have been uniformly sampled without replacement from the\n(unknown) full domain and (ii) the sample is complete for these domain elements\n(i.e. it is the full substructure induced by these elements). Within this\nsetting, we study bounds on the error of sufficient statistics of relational\nmodels that are estimated on the available data. As our main result, we prove a\nbound based on a variant of the Vapnik-Chervonenkis dimension which is suitable\nfor relational data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:09:02 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 13:14:25 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Schockaert", "Steven", ""]]}, {"id": "1804.06207", "submitter": "Luis Moreira-Matias Dr.", "authors": "Jihed Khiari, Luis Moreira-Matias, Ammar Shaker, Bernard Zenko, Saso\n  Dzeroski", "title": "MetaBags: Bagged Meta-Decision Trees for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles are popular methods for solving practical supervised learning\nproblems. They reduce the risk of having underperforming models in\nproduction-grade software. Although critical, methods for learning\nheterogeneous regression ensembles have not been proposed at large scale,\nwhereas in classical ML literature, stacking, cascading and voting are mostly\nrestricted to classification problems. Regression poses distinct learning\nchallenges that may result in poor performance, even when using well\nestablished homogeneous ensemble schemas such as bagging or boosting.\n  In this paper, we introduce MetaBags, a novel, practically useful stacking\nframework for regression. MetaBags is a meta-learning algorithm that learns a\nset of meta-decision trees designed to select one base model (i.e. expert) for\neach query, and focuses on inductive bias reduction. A set of meta-decision\ntrees are learned using different types of meta-features, specially created for\nthis purpose - to then be bagged at meta-level. This procedure is designed to\nlearn a model with a fair bias-variance trade-off, and its improvement over\nbase model performance is correlated with the prediction diversity of different\nexperts on specific input space subregions. The proposed method and\nmeta-features are designed in such a way that they enable good predictive\nperformance even in subregions of space which are not adequately represented in\nthe available training data.\n  An exhaustive empirical testing of the method was performed, evaluating both\ngeneralization error and scalability of the approach on synthetic, open and\nreal-world application datasets. The obtained results show that our method\nsignificantly outperforms existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:51:52 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Khiari", "Jihed", ""], ["Moreira-Matias", "Luis", ""], ["Shaker", "Ammar", ""], ["Zenko", "Bernard", ""], ["Dzeroski", "Saso", ""]]}, {"id": "1804.06216", "submitter": "Aleksander Wieczorek", "authors": "Aleksander Wieczorek and Mario Wieser and Damian Murezzan and Volker\n  Roth", "title": "Learning Sparse Latent Representations with the Deep Copula Information\n  Bottleneck", "comments": "Published as a conference paper at ICLR 2018. Aleksander Wieczorek\n  and Mario Wieser contributed equally to this work", "journal-ref": "Conference track - ICLR 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models are powerful tools for representation learning.\nIn this paper, we adopt the deep information bottleneck model, identify its\nshortcomings and propose a model that circumvents them. To this end, we apply a\ncopula transformation which, by restoring the invariance properties of the\ninformation bottleneck method, leads to disentanglement of the features in the\nlatent space. Building on that, we show how this transformation translates to\nsparsity of the latent space in the new model. We evaluate our method on\nartificial and real data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:09:19 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 12:10:32 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Wieczorek", "Aleksander", ""], ["Wieser", "Mario", ""], ["Murezzan", "Damian", ""], ["Roth", "Volker", ""]]}, {"id": "1804.06218", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Hierarchical correlation reconstruction with missing data, for example\n  for biology-inspired neuron", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning often needs to model density from a multidimensional data\nsample, including correlations between coordinates. Additionally, we often have\nmissing data case: that data points can miss values for some of coordinates.\nThis article adapts rapid parametric density estimation approach for this\npurpose: modelling density as a linear combination of orthonormal functions,\nfor which $L^2$ optimization says that (independently) estimated coefficient\nfor a given function is just average over the sample of value of this function.\nHierarchical correlation reconstruction first models probability density for\neach separate coordinate using all its appearances in data sample, then adds\ncorrections from independently modelled pairwise correlations using all samples\nhaving both coordinates, and so on independently adding correlations for\ngrowing numbers of variables using often decreasing evidence in data sample. A\nbasic application of such modelled multidimensional density can be imputation\nof missing coordinates: by inserting known coordinates to the density, and\ntaking expected values for the missing coordinates, or even their entire joint\nprobability distribution. Presented method can be compared with cascade\ncorrelations approach, offering several advantages in flexibility and accuracy.\nIt can be also used as artificial neuron: maximizing prediction capabilities\nfor only local behavior - modelling and predicting local connections.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:10:09 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 11:38:01 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 12:08:48 GMT"}, {"version": "v4", "created": "Sun, 27 May 2018 15:54:32 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1804.06223", "submitter": "Scott Lee", "authors": "Scott H Lee, Matthew J Maenner, Charles M Heilig", "title": "A Comparison of Machine Learning Algorithms for the Surveillance of\n  Autism Spectrum Disorder", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0222907", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Centers for Disease Control and Prevention (CDC) coordinates a\nlabor-intensive process to measure the prevalence of autism spectrum disorder\n(ASD) among children in the United States. Random forests methods have shown\npromise in speeding up this process, but they lag behind human classification\naccuracy by about 5%. We explore whether more recently available document\nclassification algorithms can close this gap. We applied 8 supervised learning\nalgorithms to predict whether children meet the case definition for ASD based\nsolely on the words in their evaluations. We compared the algorithms'\nperformance across 10 random train-test splits of the data, using\nclassification accuracy, F1 score, and number of positive calls to evaluate\ntheir potential use for surveillance. Across the 10 train-test cycles, the\nrandom forest and support vector machine with Naive Bayes features (NB-SVM)\neach achieved slightly more than 87% mean accuracy. The NB-SVM produced\nsignificantly more false negatives than false positives (P = 0.027), but the\nrandom forest did not, making its prevalence estimates very close to the true\nprevalence in the data. The best-performing neural network performed similarly\nto the random forest on both measures. The random forest performed as well as\nmore recently available models like the NB-SVM and the neural network, and it\nalso produced good prevalence estimates. NB-SVM may not be a good candidate for\nuse in a fully-automated surveillance workflow due to increased false\nnegatives. More sophisticated algorithms, like hierarchical convolutional\nneural networks, may not be feasible to train due to characteristics of the\ndata. Current algorithms might perform better if the data are abstracted and\nprocessed differently and if they take into account information about the\nchildren in addition to their evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:24:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 11:47:22 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 14:08:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Lee", "Scott H", ""], ["Maenner", "Matthew J", ""], ["Heilig", "Charles M", ""]]}, {"id": "1804.06234", "submitter": "Ran Zhao", "authors": "Qidi Peng, Nan Rao, Ran Zhao", "title": "Cluster Analysis on Locally Asymptotically Self-similar Processes with\n  Known Number of Clusters", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.09049", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct cluster analysis on a class of locally asymptotically self-similar\nstochastic processes, which includes multifractional Brownian motion as a\nrepresentative. When the true number of clusters is supposed to be known, a new\ncovariance-based dissimilarity measure is introduced, from which we obtain the\napproximately asymptotically consistent clustering algorithms. In simulation\nstudies, clustering data sampled from multifractional Brownian motions with\ndistinct functional Hurst parameters illustrates the approximated asymptotic\nconsistency of the proposed algorithms. Clustering global financial markets'\nequity indexes returns and sovereign CDS spreads provides a successful real\nworld application.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 23:09:12 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 17:42:24 GMT"}, {"version": "v3", "created": "Wed, 22 Aug 2018 23:44:34 GMT"}, {"version": "v4", "created": "Sun, 4 Nov 2018 05:48:08 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2020 05:05:33 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2020 06:02:12 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Peng", "Qidi", ""], ["Rao", "Nan", ""], ["Zhao", "Ran", ""]]}, {"id": "1804.06262", "submitter": "Casimiro Adays Curbelo Monta\\~nez", "authors": "Casimiro A. Curbelo Monta\\~nez, Paul Fergus, Carl Chalmers and Jade\n  Hind", "title": "Analysis of Extremely Obese Individuals Using Deep Learning Stacked\n  Autoencoders and Genome-Wide Genetic Data", "comments": "13 pages, 4 figures, 13 equations, 2 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aetiology of polygenic obesity is multifactorial, which indicates that\nlife-style and environmental factors may influence multiples genes to aggravate\nthis disorder. Several low-risk single nucleotide polymorphisms (SNPs) have\nbeen associated with BMI. However, identified loci only explain a small\nproportion of the variation ob-served for this phenotype. The linear nature of\ngenome wide association studies (GWAS) used to identify associations between\ngenetic variants and the phenotype have had limited success in explaining the\nheritability variation of BMI and shown low predictive capacity in\nclassification studies. GWAS ignores the epistatic interactions that less\nsignificant variants have on the phenotypic outcome. In this paper we utilise a\nnovel deep learning-based methodology to reduce the high dimensional space in\nGWAS and find epistatic interactions between SNPs for classification purposes.\nSNPs were filtered based on the effects associations have with BMI. Since\nBonferroni adjustment for multiple testing is highly conservative, an important\nproportion of SNPs involved in SNP-SNP interactions are ignored. Therefore,\nonly SNPs with p-values < 1x10-2 were considered for subsequent epistasis\nanalysis using stacked auto encoders (SAE). This allows the nonlinearity\npresent in SNP-SNP interactions to be discovered through progressively smaller\nhidden layer units and to initialise a multi-layer feedforward artificial\nneural network (ANN) classifier. The classifier is fine-tuned to classify\nextremely obese and non-obese individuals. The best results were obtained with\n2000 compressed units (SE=0.949153, SP=0.933014, Gini=0.949936,\nLo-gloss=0.1956, AUC=0.97497 and MSE=0.054057). Using 50 compressed units it\nwas possible to achieve (SE=0.785311, SP=0.799043, Gini=0.703566,\nLogloss=0.476864, AUC=0.85178 and MSE=0.156315).\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 15:25:14 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 10:24:59 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Monta\u00f1ez", "Casimiro A. Curbelo", ""], ["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Hind", "Jade", ""]]}, {"id": "1804.06300", "submitter": "Yunbo Wang", "authors": "Yunbo Wang, Zhifeng Gao, Mingsheng Long, Jianmin Wang, Philip S. Yu", "title": "PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in\n  Spatiotemporal Predictive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PredRNN++, an improved recurrent network for video predictive\nlearning. In pursuit of a greater spatiotemporal modeling capability, our\napproach increases the transition depth between adjacent states by leveraging a\nnovel recurrent unit, which is named Causal LSTM for re-organizing the spatial\nand temporal memories in a cascaded mechanism. However, there is still a\ndilemma in video predictive learning: increasingly deep-in-time models have\nbeen designed for capturing complex variations, while introducing more\ndifficulties in the gradient back-propagation. To alleviate this undesirable\neffect, we propose a Gradient Highway architecture, which provides alternative\nshorter routes for gradient flows from outputs back to long-range inputs. This\narchitecture works seamlessly with causal LSTMs, enabling PredRNN++ to capture\nshort-term and long-term dependencies adaptively. We assess our model on both\nsynthetic and real video datasets, showing its ability to ease the vanishing\ngradient problem and yield state-of-the-art prediction results even in a\ndifficult objects occlusion scenario.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 14:52:19 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 02:17:17 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wang", "Yunbo", ""], ["Gao", "Zhifeng", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1804.06309", "submitter": "Xin Li", "authors": "Pengfei Zhu, Xin Li, Pascal Poupart, Guanghui Miao", "title": "On Improving Deep Reinforcement Learning for POMDPs", "comments": "We are the authors of \"On Improving Deep Reinforcement Learning for\n  POMDPs\", identifier of which is arXiv:1704.07978. Last week, I wanted to\n  update the article with new version but created a new submission which\n  identifier is 1804.06309 by mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) recently emerged as one of the most\ncompetitive approaches for learning in sequential decision making problems with\nfully observable environments, e.g., computer Go. However, very little work has\nbeen done in deep RL to handle partially observable environments. We propose a\nnew architecture called Action-specific Deep Recurrent Q-Network (ADRQN) to\nenhance learning performance in partially observable domains. Actions are\nencoded by a fully connected layer and coupled with a convolutional observation\nto form an action-observation pair. The time series of action-observation pairs\nare then integrated by an LSTM layer that learns latent states based on which a\nfully connected layer computes Q-values as in conventional Deep Q-Networks\n(DQNs). We demonstrate the effectiveness of our new architecture in several\npartially observable domains, including flickering Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:08:36 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 13:15:51 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zhu", "Pengfei", ""], ["Li", "Xin", ""], ["Poupart", "Pascal", ""], ["Miao", "Guanghui", ""]]}, {"id": "1804.06352", "submitter": "J\\\"org Bachmann", "authors": "J\\\"org P. Bachmann and Johann-Christoph Freytag", "title": "High Dimensional Time Series Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multidimensional time series are sequences of real valued vectors. They occur\nin different areas, for example handwritten characters, GPS tracking, and\ngestures of modern virtual reality motion controllers. Within these areas, a\ncommon task is to search for similar time series. Dynamic Time Warping (DTW) is\na common distance function to compare two time series. The Edit Distance with\nReal Penalty (ERP) and the Dog Keeper Distance (DK) are two more distance\nfunctions on time series. Their behaviour has been analyzed on 1-dimensional\ntime series. However, it is not easy to evaluate their behaviour in relation to\ngrowing dimensionality. For this reason we propose two new data synthesizers\ngenerating multidimensional time series. The first synthesizer extends the well\nknown cylinder-bell-funnel (CBF) dataset to multidimensional time series. Here,\neach time series has an arbitrary type (cylinder, bell, or funnel) in each\ndimension, thus for $d$-dimensional time series there are $3^{d}$ different\nclasses. The second synthesizer (RAM) creates time series with ideas adapted\nfrom Brownian motions which is a common model of movement in physics. Finally,\nwe evaluate the applicability of a 1-nearest neighbor classifier using DTW on\ndatasets generated by our synthesizers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 16:24:14 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 15:46:52 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 06:46:24 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bachmann", "J\u00f6rg P.", ""], ["Freytag", "Johann-Christoph", ""]]}, {"id": "1804.06378", "submitter": "Hamed Sarvari", "authors": "Hamed Sarvari, Carlotta Domeniconi, Giovanni Stilo", "title": "Graph-based Selective Outlier Ensembles", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble technique is characterized by the mechanism that generates the\ncomponents and by the mechanism that combines them. A common way to achieve the\nconsensus is to enable each component to equally participate in the aggregation\nprocess. A problem with this approach is that poor components are likely to\nnegatively affect the quality of the consensus result. To address this issue,\nalternatives have been explored in the literature to build selective classifier\nand cluster ensembles, where only a subset of the components contributes to the\ncomputation of the consensus. Of the family of ensemble methods, outlier\nensembles are the least studied. Only recently, the selection problem for\noutlier ensembles has been discussed. In this work we define a new graph-based\nclass of ranking selection methods. A method in this class is characterized by\ntwo main steps: (1) Mapping the rankings onto a graph structure; and (2) Mining\nthe resulting graph to identify a subset of rankings. We define a specific\ninstance of the graph-based ranking selection class. Specifically, we map the\nproblem of selecting ensemble components onto a mining problem in a graph. An\nextensive evaluation was conducted on a variety of heterogeneous data and\nmethods. Our empirical results show that our approach outperforms\nstate-of-the-art selective outlier ensemble techniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 17:11:23 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Sarvari", "Hamed", ""], ["Domeniconi", "Carlotta", ""], ["Stilo", "Giovanni", ""]]}, {"id": "1804.06451", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Reward Reinforced Summarization with Saliency and Entailment", "comments": "NAACL 2018 (9 pages; added human evaluation and more analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization is the task of compressing and rewriting a\nlong document into a short summary while maintaining saliency, directed logical\nentailment, and non-redundancy. In this work, we address these three important\naspects of a good summary via a reinforcement learning approach with two novel\nreward functions: ROUGESal and Entail, on top of a coverage-based baseline. The\nROUGESal reward modifies the ROUGE metric by up-weighting the salient\nphrases/words detected via a keyphrase classifier. The Entail reward gives high\n(length-normalized) scores to logically-entailed summaries using an entailment\nclassifier. Further, we show superior performance improvement when these\nrewards are combined with traditional metric (ROUGE) based rewards, via our\nnovel and effective multi-reward approach of optimizing multiple rewards\nsimultaneously in alternate mini-batches. Our method achieves the new\nstate-of-the-art results (including human evaluation) on the CNN/Daily Mail\ndataset as well as strong improvements in a test-only transfer setup on\nDUC-2002.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:39:26 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:45:28 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06459", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Junhyuk Oh, Satinder Singh", "title": "On Learning Intrinsic Rewards for Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision making tasks, it is challenging to design reward\nfunctions that help an RL agent efficiently learn behavior that is considered\ngood by the agent designer. A number of different formulations of the\nreward-design problem, or close variants thereof, have been proposed in the\nliterature. In this paper we build on the Optimal Rewards Framework of Singh\net.al. that defines the optimal intrinsic reward function as one that when used\nby an RL agent achieves behavior that optimizes the task-specifying or\nextrinsic reward function. Previous work in this framework has shown how good\nintrinsic reward functions can be learned for lookahead search based planning\nagents. Whether it is possible to learn intrinsic reward functions for learning\nagents remains an open problem. In this paper we derive a novel algorithm for\nlearning intrinsic rewards for policy-gradient based learning agents. We\ncompare the performance of an augmented agent that uses our algorithm to\nprovide additive intrinsic rewards to an A2C-based policy learner (for Atari\ngames) and a PPO-based policy learner (for Mujoco domains) with a baseline\nagent that uses the same policy learners but with only extrinsic rewards. Our\nresults show improved performance on most but not all of the domains.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:04:09 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 17:50:24 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Zheng", "Zeyu", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""]]}, {"id": "1804.06461", "submitter": "Gang Chen", "authors": "Gang Chen and Yiming Peng and Mengjie Zhang", "title": "An Adaptive Clipping Approach for Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently proximal policy optimization (PPO) algorithms have been\nproposed as first-order optimization methods for effective reinforcement\nlearning. While PPO is inspired by the same learning theory that justifies\ntrust region policy optimization (TRPO), PPO substantially simplifies algorithm\ndesign and improves data efficiency by performing multiple epochs of\n\\emph{clipped policy optimization} from sampled data. Although clipping in PPO\nstands for an important new mechanism for efficient and reliable policy update,\nit may fail to adaptively improve learning performance in accordance with the\nimportance of each sampled state. To address this issue, a new surrogate\nlearning objective featuring an adaptive clipping mechanism is proposed in this\npaper, enabling us to develop a new algorithm, known as PPO-$\\lambda$.\nPPO-$\\lambda$ optimizes policies repeatedly based on a theoretical target for\nadaptive policy improvement. Meanwhile, destructively large policy update can\nbe effectively prevented through both clipping and adaptive control of a\nhyperparameter $\\lambda$ in PPO-$\\lambda$, ensuring high learning reliability.\nPPO-$\\lambda$ enjoys the same simple and efficient design as PPO. Empirically\non several Atari game playing tasks and benchmark control tasks, PPO-$\\lambda$\nalso achieved clearly better performance than PPO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:24:27 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Chen", "Gang", ""], ["Peng", "Yiming", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1804.06481", "submitter": "Yao Zhou", "authors": "Yao Zhou, Arun Reddy Nelakurthi, Jingrui He", "title": "Unlearn What You Have Learned: Adaptive Crowd Teaching with\n  Exponentially Decayed Memory Learners", "comments": "10 pages, KDD 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for large amount of labeled data, crowdsourcing\nhas been used in many large-scale data mining applications. However, most\nexisting works in crowdsourcing mainly focus on label inference and incentive\ndesign. In this paper, we address a different problem of adaptive crowd\nteaching, which is a sub-area of machine teaching in the context of\ncrowdsourcing. Compared with machines, human beings are extremely good at\nlearning a specific target concept (e.g., classifying the images into given\ncategories) and they can also easily transfer the learned concepts into similar\nlearning tasks. Therefore, a more effective way of utilizing crowdsourcing is\nby supervising the crowd to label in the form of teaching. In order to perform\nthe teaching and expertise estimation simultaneously, we propose an adaptive\nteaching framework named JEDI to construct the personalized optimal teaching\nset for the crowdsourcing workers. In JEDI teaching, the teacher assumes that\neach learner has an exponentially decayed memory. Furthermore, it ensures\ncomprehensiveness in the learning process by carefully balancing teaching\ndiversity and learner's accurate learning in terms of teaching usefulness.\nFinally, we validate the effectiveness and efficacy of JEDI teaching in\ncomparison with the state-of-the-art techniques on multiple data sets with both\nsynthetic learners and real crowdsourcing workers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 22:02:02 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 19:01:46 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Zhou", "Yao", ""], ["Nelakurthi", "Arun Reddy", ""], ["He", "Jingrui", ""]]}, {"id": "1804.06498", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani, Vishal M. Patel", "title": "Deep Multimodal Subspace Clustering Networks", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, vol. 12, no.\n  6, pp. 1601-1614, Dec. 2018", "doi": "10.1109/JSTSP.2018.2875385", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present convolutional neural network (CNN) based approaches for\nunsupervised multimodal subspace clustering. The proposed framework consists of\nthree main stages - multimodal encoder, self-expressive layer, and multimodal\ndecoder. The encoder takes multimodal data as input and fuses them to a latent\nspace representation. The self-expressive layer is responsible for enforcing\nthe self-expressiveness property and acquiring an affinity matrix corresponding\nto the data points. The decoder reconstructs the original input data. The\nnetwork uses the distance between the decoder's reconstruction and the original\ninput in its training. We investigate early, late and intermediate fusion\ntechniques and propose three different encoders corresponding to them for\nspatial fusion. The self-expressive layers and multimodal decoders are\nessentially the same for different spatial fusion-based approaches. In addition\nto various spatial fusion-based methods, an affinity fusion-based network is\nalso proposed in which the self-expressive layer corresponding to different\nmodalities is enforced to be the same. Extensive experiments on three datasets\nshow that the proposed methods significantly outperform the state-of-the-art\nmultimodal subspace clustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:04:33 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 21:53:14 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 20:19:14 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1804.06500", "submitter": "Andrew Cotter", "authors": "Andrew Cotter, Heinrich Jiang, Karthik Sridharan", "title": "Two-Player Games for Efficient Non-Convex Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, constrained optimization has become increasingly relevant to\nthe machine learning community, with applications including Neyman-Pearson\nclassification, robust optimization, and fair machine learning. A natural\napproach to constrained optimization is to optimize the Lagrangian, but this is\nnot guaranteed to work in the non-convex setting, and, if using a first-order\nmethod, cannot cope with non-differentiable constraints (e.g. constraints on\nrates or proportions).\n  The Lagrangian can be interpreted as a two-player game played between a\nplayer who seeks to optimize over the model parameters, and a player who wishes\nto maximize over the Lagrange multipliers. We propose a non-zero-sum variant of\nthe Lagrangian formulation that can cope with non-differentiable--even\ndiscontinuous--constraints, which we call the \"proxy-Lagrangian\". The first\nplayer minimizes external regret in terms of easy-to-optimize \"proxy\nconstraints\", while the second player enforces the original constraints by\nminimizing swap regret.\n  For this new formulation, as for the Lagrangian in the non-convex setting,\nthe result is a stochastic classifier. For both the proxy-Lagrangian and\nLagrangian formulations, however, we prove that this classifier, instead of\nhaving unbounded size, can be taken to be a distribution over no more than m+1\nmodels (where m is the number of constraints). This is a significant\nimprovement in practical terms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:13:28 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 20:54:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cotter", "Andrew", ""], ["Jiang", "Heinrich", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1804.06508", "submitter": "Kartik Hegde", "authors": "Kartik Hegde, Jiyong Yu, Rohit Agrawal, Mengjia Yan, Michael Pellauer,\n  Christopher W. Fletcher", "title": "UCNN: Exploiting Computational Reuse in Deep Neural Networks via Weight\n  Repetition", "comments": "Appears in the proceedings of the 45th International Symposium on\n  Computer Architecture~(ISCA), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have begun to permeate all corners of\nelectronic society (from voice recognition to scene generation) due to their\nhigh accuracy and machine efficiency per operation. At their core, CNN\ncomputations are made up of multi-dimensional dot products between weight and\ninput vectors. This paper studies how weight repetition ---when the same weight\noccurs multiple times in or across weight vectors--- can be exploited to save\nenergy and improve performance during CNN inference. This generalizes a popular\nline of work to improve efficiency from CNN weight sparsity, as reducing\ncomputation due to repeated zero weights is a special case of reducing\ncomputation due to repeated weights.\n  To exploit weight repetition, this paper proposes a new CNN accelerator\ncalled the Unique Weight CNN Accelerator (UCNN). UCNN uses weight repetition to\nreuse CNN sub-computations (e.g., dot products) and to reduce CNN model size\nwhen stored in off-chip DRAM ---both of which save energy. UCNN further\nimproves performance by exploiting sparsity in weights. We evaluate UCNN with\nan accelerator-level cycle and energy model and with an RTL implementation of\nthe UCNN processing element. On three contemporary CNNs, UCNN improves\nthroughput-normalized energy consumption by 1.2x - 4x, relative to a similarly\nprovisioned baseline accelerator that uses Eyeriss-style sparsity\noptimizations. At the same time, the UCNN processing element adds only 17-24%\narea overhead relative to the same baseline.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:11:38 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Hegde", "Kartik", ""], ["Yu", "Jiyong", ""], ["Agrawal", "Rohit", ""], ["Yan", "Mengjia", ""], ["Pellauer", "Michael", ""], ["Fletcher", "Christopher W.", ""]]}, {"id": "1804.06511", "submitter": "Thomas Keller", "authors": "T. Anderson Keller, Sharath Nittur Sridhar, Xin Wang", "title": "Fast Weight Long Short-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associative memory using fast weights is a short-term memory mechanism that\nsubstantially improves the memory capacity and time scale of recurrent neural\nnetworks (RNNs). As recent studies introduced fast weights only to regular\nRNNs, it is unknown whether fast weight memory is beneficial to gated RNNs. In\nthis work, we report a significant synergy between long short-term memory\n(LSTM) networks and fast weight associative memories. We show that this\ncombination, in learning associative retrieval tasks, results in much faster\ntraining and lower test error, a performance boost most prominent at high\nmemory task difficulties.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:20:28 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Keller", "T. Anderson", ""], ["Sridhar", "Sharath Nittur", ""], ["Wang", "Xin", ""]]}, {"id": "1804.06518", "submitter": "Holakou Rahmanian", "authors": "Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, Holakou Rahmanian,\n  Manfred K. Warmuth", "title": "Online Non-Additive Path Learning under Full and Partial Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online path learning with non-additive gains, which\nis a central problem appearing in several applications, including ensemble\nstructured prediction. We present new online algorithms for path learning with\nnon-additive count-based gains for the three settings of full information,\nsemi-bandit and full bandit with very favorable regret guarantees. A key\ncomponent of our algorithms is the definition and computation of an\nintermediate context-dependent automaton that enables us to use existing\nalgorithms designed for additive gains. We further apply our methods to the\nimportant application of ensemble structured prediction. Finally, beyond\ncount-based gains, we give an efficient implementation of the EXP3 algorithm\nfor the full bandit setting with an arbitrary (non-additive) gain.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:53:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 09:15:28 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 07:30:16 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 02:17:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Cortes", "Corinna", ""], ["Kuznetsov", "Vitaly", ""], ["Mohri", "Mehryar", ""], ["Rahmanian", "Holakou", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1804.06537", "submitter": "Shujian Yu", "authors": "Shujian Yu, Kristoffer Wickstr{\\o}m, Robert Jenssen, Jose C. Principe", "title": "Understanding Convolutional Neural Networks with Information Theory: An\n  Initial Exploration", "comments": "Paper accepted by IEEE Transactions on Neural Networks and Learning\n  Systems (TNNLS). Code for 1) estimating information quantities, 2) plotting\n  the information plane, and 3) selecting convolutional filters, is available\n  from (MATLAB)\n  https://drive.google.com/drive/folders/1DJYshWIiijKWrFKrztW9FgTzGfMV3D8M?usp=sharing\n  or (Python) https://github.com/Wickstrom/InfExperiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matrix-based Renyi's \\alpha-entropy functional and its multivariate\nextension were recently developed in terms of the normalized eigenspectrum of a\nHermitian matrix of the projected data in a reproducing kernel Hilbert space\n(RKHS). However, the utility and possible applications of these new estimators\nare rather new and mostly unknown to practitioners. In this paper, we first\nshow that our estimators enable straightforward measurement of information flow\nin realistic convolutional neural networks (CNN) without any approximation.\nThen, we introduce the partial information decomposition (PID) framework and\ndevelop three quantities to analyze the synergy and redundancy in convolutional\nlayer representations. Our results validate two fundamental data processing\ninequalities and reveal some fundamental properties concerning the training of\nCNN.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 03:16:17 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 05:25:38 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 05:55:51 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 16:46:11 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2020 19:15:06 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Yu", "Shujian", ""], ["Wickstr\u00f8m", "Kristoffer", ""], ["Jenssen", "Robert", ""], ["Principe", "Jose C.", ""]]}, {"id": "1804.06546", "submitter": "Markus Beissinger", "authors": "Markus Beissinger", "title": "Deep Generative Networks For Sequence Prediction", "comments": "University of Pennsylvania Computer Science Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates unsupervised time series representation learning for\nsequence prediction problems, i.e. generating nice-looking input samples given\na previous history, for high dimensional input sequences by decoupling the\nstatic input representation from the recurrent sequence representation. We\nintroduce three models based on Generative Stochastic Networks (GSN) for\nunsupervised sequence learning and prediction. Experimental results for these\nthree models are presented on pixels of sequential handwritten digit (MNIST)\ndata, videos of low-resolution bouncing balls, and motion capture data. The\nmain contribution of this thesis is to provide evidence that GSNs are a viable\nframework to learn useful representations of complex sequential input data, and\nto suggest a new framework for deep generative models to learn complex\nsequences by decoupling static input representations from dynamic time\ndependency representations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 04:28:09 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Beissinger", "Markus", ""]]}, {"id": "1804.06561", "submitter": "Song Mei", "authors": "Song Mei, Andrea Montanari, Phan-Minh Nguyen", "title": "A Mean Field View of the Landscape of Two-Layers Neural Networks", "comments": "103 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layer neural networks are among the most powerful models in machine\nlearning, yet the fundamental reasons for this success defy mathematical\nunderstanding. Learning a neural network requires to optimize a non-convex\nhigh-dimensional objective (risk function), a problem which is usually attacked\nusing stochastic gradient descent (SGD). Does SGD converge to a global optimum\nof the risk or only to a local optimum? In the first case, does this happen\nbecause local minima are absent, or because SGD somehow avoids them? In the\nsecond, why do local minima reached by SGD have good generalization properties?\n  In this paper we consider a simple case, namely two-layers neural networks,\nand prove that -in a suitable scaling limit- SGD dynamics is captured by a\ncertain non-linear partial differential equation (PDE) that we call\ndistributional dynamics (DD). We then consider several specific examples, and\nshow how DD can be used to prove convergence of SGD to networks with nearly\nideal generalization error. This description allows to 'average-out' some of\nthe complexities of the landscape of neural networks, and can be used to prove\na general convergence result for noisy SGD.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 05:31:45 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:21:23 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Mei", "Song", ""], ["Montanari", "Andrea", ""], ["Nguyen", "Phan-Minh", ""]]}, {"id": "1804.06620", "submitter": "Giuseppe Casalicchio", "authors": "Giuseppe Casalicchio, Christoph Molnar, Bernd Bischl", "title": "Visualizing the Feature Importance for Black Box Models", "comments": "To Appear in Machine Learning and Knowledge Discovery in Databases:\n  European Conference, ECML PKDD 2018, Dublin, Ireland, September 10 to 14,\n  2018, Proceedings, Part I", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2018. Lecture Notes in Computer Science, vol 11051", "doi": "10.1007/978-3-030-10925-7_40", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a large amount of model-agnostic methods to improve the\ntransparency, trustability and interpretability of machine learning models have\nbeen developed. We introduce local feature importance as a local version of a\nrecent model-agnostic global feature importance method. Based on local feature\nimportance, we propose two visual tools: partial importance (PI) and individual\nconditional importance (ICI) plots which visualize how changes in a feature\naffect the model performance on average, as well as for individual\nobservations. Our proposed methods are related to partial dependence (PD) and\nindividual conditional expectation (ICE) plots, but visualize the expected\n(conditional) feature importance instead of the expected (conditional)\nprediction. Furthermore, we show that averaging ICI curves across observations\nyields a PI curve, and integrating the PI curve with respect to the\ndistribution of the considered feature results in the global feature\nimportance. Another contribution of our paper is the Shapley feature\nimportance, which fairly distributes the overall performance of a model among\nthe features according to the marginal contributions and which can be used to\ncompare the feature importance across different models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:35:38 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 14:30:25 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 15:54:54 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Casalicchio", "Giuseppe", ""], ["Molnar", "Christoph", ""], ["Bischl", "Bernd", ""]]}, {"id": "1804.06673", "submitter": "Markus Heinonen", "authors": "Markus Heinonen, Maria Osmala, Henrik Mannerstr\\\"om, Janne Wallenius,\n  Samuel Kaski, Juho Rousu, Harri L\\\"ahdesm\\\"aki", "title": "Bayesian Metabolic Flux Analysis reveals intracellular flux couplings", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolic flux balance analyses are a standard tool in analysing metabolic\nreaction rates compatible with measurements, steady-state and the metabolic\nreaction network stoichiometry. Flux analysis methods commonly place\nunrealistic assumptions on fluxes due to the convenience of formulating the\nproblem as a linear programming model, and most methods ignore the notable\nuncertainty in flux estimates. We introduce a novel paradigm of Bayesian\nmetabolic flux analysis that models the reactions of the whole genome-scale\ncellular system in probabilistic terms, and can infer the full flux vector\ndistribution of genome-scale metabolic systems based on exchange and\nintracellular (e.g. 13C) flux measurements, steady-state assumptions, and\ntarget function assumptions. The Bayesian model couples all fluxes jointly\ntogether in a simple truncated multivariate posterior distribution, which\nreveals informative flux couplings. Our model is a plug-in replacement to\nconventional metabolic balance methods, such as flux balance analysis (FBA).\nOur experiments indicate that we can characterise the genome-scale flux\ncovariances, reveal flux couplings, and determine more intracellular unobserved\nfluxes in C. acetobutylicum from 13C data than flux variability analysis. The\nCOBRA compatible software is available at github.com/markusheinonen/bamfa\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:19:34 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Heinonen", "Markus", ""], ["Osmala", "Maria", ""], ["Mannerstr\u00f6m", "Henrik", ""], ["Wallenius", "Janne", ""], ["Kaski", "Samuel", ""], ["Rousu", "Juho", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1804.06679", "submitter": "Bernhard C. Geiger", "authors": "Rana Ali Amjad and Kairen Liu and Bernhard C. Geiger", "title": "Understanding Neural Networks and Individual Neuron Importance via\n  Information-Ordered Cumulative Ablation", "comments": "12 pages; accepted for publication in IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:29:24 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 11:35:26 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 06:52:01 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 15:28:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Amjad", "Rana Ali", ""], ["Liu", "Kairen", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1804.06739", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Are ResNets Provably Better than Linear Predictors?", "comments": "Comparison to previous arXiv version: Minor changes to incorporate\n  comments of NIPS 2018 reviewers (main results are unaffected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A residual network (or ResNet) is a standard deep neural net architecture,\nwith state-of-the-art performance across numerous applications. The main\npremise of ResNets is that they allow the training of each layer to focus on\nfitting just the residual of the previous layer's output and the target output.\nThus, we should expect that the trained network is no worse than what we can\nobtain if we remove the residual layers and train a shallower network instead.\nHowever, due to the non-convexity of the optimization problem, it is not at all\nclear that ResNets indeed achieve this behavior, rather than getting stuck at\nsome arbitrarily poor local minimum. In this paper, we rigorously prove that\narbitrarily deep, nonlinear residual units indeed exhibit this behavior, in the\nsense that the optimization landscape contains no local minima with value above\nwhat can be obtained with a linear predictor (namely a 1-layer network).\nNotably, we show this under minimal or no assumptions on the precise network\narchitecture, data distribution, or loss function used. We also provide a\nquantitative analysis of approximate stationary points for this problem.\nFinally, we show that with a certain tweak to the architecture, training the\nnetwork with standard stochastic gradient descent achieves an objective value\nclose or better than any linear predictor.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:06:15 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 16:10:51 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 10:58:10 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 10:30:26 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1804.06755", "submitter": "Mathieu Guillame-Bert", "authors": "Mathieu Guillame-Bert and Olivier Teytaud", "title": "Exact Distributed Training: Random Forest with Billions of Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exact distributed algorithm to train Random Forest models as\nwell as other decision forest models without relying on approximating best\nsplit search. We explain the proposed algorithm and compare it to related\napproaches for various complexity measures (time, ram, disk, and network\ncomplexity analysis). We report its running performances on artificial and\nreal-world datasets of up to 18 billions examples. This figure is several\norders of magnitude larger than datasets tackled in the existing literature.\nFinally, we empirically show that Random Forest benefits from being trained on\nmore data, even in the case of already gigantic datasets. Given a dataset with\n17.3B examples with 82 features (3 numerical, other categorical with high\narity), our implementation trains a tree in 22h.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:20:53 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Guillame-Bert", "Mathieu", ""], ["Teytaud", "Olivier", ""]]}, {"id": "1804.06769", "submitter": "Herbert Hu", "authors": "Guangneng Hu, Yu Zhang, Qiang Yang", "title": "CoNet: Collaborative Cross Networks for Cross-Domain Recommendation", "comments": "Deep transfer learning for recommender systems", "journal-ref": "CIKM 2018", "doi": "10.1145/3269206.3271684", "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cross-domain recommendation technique is an effective way of alleviating\nthe data sparse issue in recommender systems by leveraging the knowledge from\nrelevant domains. Transfer learning is a class of algorithms underlying these\ntechniques. In this paper, we propose a novel transfer learning approach for\ncross-domain recommendation by using neural networks as the base model. In\ncontrast to the matrix factorization based cross-domain techniques, our method\nis deep transfer learning, which can learn complex user-item interaction\nrelationships. We assume that hidden layers in two base networks are connected\nby cross mappings, leading to the collaborative cross networks (CoNet). CoNet\nenables dual knowledge transfer across domains by introducing cross connections\nfrom one base network to another and vice versa. CoNet is achieved in\nmulti-layer feedforward networks by adding dual connections and joint loss\nfunctions, which can be trained efficiently by back-propagation. The proposed\nmodel is thoroughly evaluated on two large real-world datasets. It outperforms\nbaselines by relative improvements of 7.84\\% in NDCG. We demonstrate the\nnecessity of adaptively selecting representations to transfer. Our model can\nreduce tens of thousands training examples comparing with non-transfer methods\nand still has the competitive performance with them.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:48:21 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 17:12:11 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 14:00:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.06776", "submitter": "Aya Abdelsalam Ismail", "authors": "Aya Abdelsalam Ismail, Timothy Wood and H\\'ector Corrada Bravo", "title": "Improving Long-Horizon Forecasts with Expectation-Biased LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art forecasting methods using Recurrent Neural Net- works (RNN)\nbased on Long-Short Term Memory (LSTM) cells have shown exceptional performance\ntargeting short-horizon forecasts, e.g given a set of predictor features,\nforecast a target value for the next few time steps in the future. However, in\nmany applica- tions, the performance of these methods decays as the forecasting\nhorizon extends beyond these few time steps. This paper aims to explore the\nchallenges of long-horizon forecasting using LSTM networks. Here, we illustrate\nthe long-horizon forecasting problem in datasets from neuroscience and energy\nsupply management. We then propose expectation-biasing, an approach motivated\nby the literature of Dynamic Belief Networks, as a solution to improve\nlong-horizon forecasting using LSTMs. We propose two LSTM ar- chitectures along\nwith two methods for expectation biasing that significantly outperforms\nstandard practice.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 15:05:44 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Ismail", "Aya Abdelsalam", ""], ["Wood", "Timothy", ""], ["Bravo", "H\u00e9ctor Corrada", ""]]}, {"id": "1804.06802", "submitter": "Binxin Ru", "authors": "Diego Granziol, Binxin Ru, Stefan Zohren, Xiaowen Dong, Michael\n  Osborne, Stephen Roberts", "title": "Entropic Spectral Learning for Large-Scale Graphs", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph spectra have been successfully used to classify network types, compute\nthe similarity between graphs, and determine the number of communities in a\nnetwork. For large graphs, where an eigen-decomposition is infeasible,\niterative moment matched approximations to the spectra and kernel smoothing are\ntypically used. We show that the underlying moment information is lost when\nusing kernel smoothing. We further propose a spectral density approximation\nbased on the method of Maximum Entropy, for which we develop a new algorithm.\nThis method matches moments exactly and is everywhere positive. We demonstrate\nits effectiveness and superiority over existing approaches in learning graph\nspectra, via experiments on both synthetic networks, such as the\nErd\\H{o}s-R\\'{e}nyi and Barab\\'{a}si-Albert random graphs, and real-world\nnetworks, such as the social networks for Orkut, YouTube, and Amazon from the\nSNAP dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 16:23:10 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 00:09:52 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Granziol", "Diego", ""], ["Ru", "Binxin", ""], ["Zohren", "Stefan", ""], ["Dong", "Xiaowen", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1804.06819", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen and Pierre-Yves Oudeyer", "title": "Active choice of teachers, learning strategies and goals for a socially\n  guided intrinsic motivation learner", "comments": null, "journal-ref": "Paladyn, Springer Verlag, 2012, 3 (3), pp.136-146", "doi": "10.2478/s13230-013-0110-z", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an active learning architecture that allows a robot to actively\nlearn which data collection strategy is most efficient for acquiring motor\nskills to achieve multiple outcomes, and generalise over its experience to\nachieve new outcomes. The robot explores its environment both via interactive\nlearning and goal-babbling. It learns at the same time when, who and what to\nactively imitate from several available teachers, and learns when not to use\nsocial guidance but use active goal-oriented self-exploration. This is\nformalised in the framework of life-long strategic learning. The proposed\narchitecture, called Socially Guided Intrinsic Motivation with Active Choice of\nTeacher and Strategy (SGIM-ACTS), relies on hierarchical active decisions of\nwhat and how to learn driven by empirical evaluation of learning progress for\neach learning strategy. We illustrate with an experiment where a simulated\nrobot learns to control its arm for realising two kinds of different outcomes.\nIt has to choose actively and hierarchically at each learning episode: 1) what\nto learn: which outcome is most interesting to select as a goal to focus on for\ngoal-directed exploration; 2) how to learn: which data collection strategy to\nuse among self-exploration, mimicry and emulation; 3) once he has decided when\nand what to imitate by choosing mimicry or emulation, then he has to choose who\nto imitate, from a set of different teachers. We show that SGIM-ACTS learns\nsignificantly more efficiently than using single learning strategies, and\ncoherently selects the best strategy with respect to the chosen outcome, taking\nadvantage of the available teachers (with different levels of skills).\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 17:11:29 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nguyen", "Sao Mai", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1804.06872", "submitter": "Bo Han", "authors": "Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor\n  Tsang, Masashi Sugiyama", "title": "Co-teaching: Robust Training of Deep Neural Networks with Extremely\n  Noisy Labels", "comments": "NIPS 2018 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with noisy labels is practically challenging, as the capacity\nof deep models is so high that they can totally memorize these noisy labels\nsooner or later during training. Nonetheless, recent studies on the\nmemorization effects of deep neural networks show that they would first\nmemorize training data of clean labels and then those of noisy labels.\nTherefore in this paper, we propose a new deep learning paradigm called\nCo-teaching for combating with noisy labels. Namely, we train two deep neural\nnetworks simultaneously, and let them teach each other given every mini-batch:\nfirstly, each network feeds forward all data and selects some data of possibly\nclean labels; secondly, two networks communicate with each other what data in\nthis mini-batch should be used for training; finally, each network back\npropagates the data selected by its peer network and updates itself. Empirical\nresults on noisy versions of MNIST, CIFAR-10 and CIFAR-100 demonstrate that\nCo-teaching is much superior to the state-of-the-art methods in the robustness\nof trained deep models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:42:31 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 13:37:50 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 09:14:05 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Han", "Bo", ""], ["Yao", "Quanming", ""], ["Yu", "Xingrui", ""], ["Niu", "Gang", ""], ["Xu", "Miao", ""], ["Hu", "Weihua", ""], ["Tsang", "Ivor", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1804.06893", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Oriol Vinyals and Remi Munos and Samy Bengio", "title": "A Study on Overfitting in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent years have witnessed significant progresses in deep Reinforcement\nLearning (RL). Empowered with large scale neural networks, carefully designed\narchitectures, novel training algorithms and massively parallel computing\ndevices, researchers are able to attack many challenging RL problems. However,\nin machine learning, more training power comes with a potential risk of more\noverfitting. As deep RL techniques are being applied to critical problems such\nas healthcare and finance, it is important to understand the generalization\nbehaviors of the trained agents. In this paper, we conduct a systematic study\nof standard RL agents and find that they could overfit in various ways.\nMoreover, overfitting could happen \"robustly\": commonly used techniques in RL\nthat add stochasticity do not necessarily prevent or detect overfitting. In\nparticular, the same agents and learning algorithms could have drastically\ndifferent test performance, even when all of them achieve optimal rewards\nduring training. The observations call for more principled and careful\nevaluation protocols in RL. We conclude with a general discussion on\noverfitting in RL and a study of the generalization behaviors from the\nperspective of inductive bias.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:49:13 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:49:52 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Vinyals", "Oriol", ""], ["Munos", "Remi", ""], ["Bengio", "Samy", ""]]}, {"id": "1804.06896", "submitter": "Lu Duan", "authors": "Lu Duan, Haoyuan Hu, Yu Qian, Yu Gong, Xiaodong Zhang, Yinghui Xu,\n  Jiangwen Wei", "title": "A Multi-task Selected Learning Approach for Solving 3D Flexible Bin\n  Packing Problem", "comments": "8 pages, 34figures. arXiv admin note: text overlap with\n  arXiv:1708.05930", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 3D flexible bin packing problem (3D-FBPP) arises from the process of\nwarehouse packing in e-commerce. An online customer's order usually contains\nseveral items and needs to be packed as a whole before shipping. In particular,\n5% of tens of millions of packages are using plastic wrapping as outer\npackaging every day, which brings pressure on the plastic surface minimization\nto save traditional logistics costs. Because of the huge practical\nsignificance, we focus on the issue of packing cuboid-shaped items orthogonally\ninto a least-surface-area bin. The existing heuristic methods for classic 3D\nbin packing don't work well for this particular NP-hard problem and designing a\ngood problem-specific heuristic is non-trivial. In this paper, rather than\ndesigning heuristics, we propose a novel multi-task framework based on Selected\nLearning to learn a heuristic-like policy that generates the sequence and\norientations of items to be packed simultaneously. Through comprehensive\nexperiments on a large scale real-world transaction order dataset and online AB\ntests, we show: 1) our selected learning method trades off the imbalance and\ncorrelation among the tasks and significantly outperforms the single task\nPointer Network and the multi-task network without selected learning; 2) our\nmethod obtains an average 5.47% cost reduction than the well-designed greedy\nalgorithm which is previously used in our online production system.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:00:42 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 02:52:27 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 06:20:39 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Duan", "Lu", ""], ["Hu", "Haoyuan", ""], ["Qian", "Yu", ""], ["Gong", "Yu", ""], ["Zhang", "Xiaodong", ""], ["Xu", "Yinghui", ""], ["Wei", "Jiangwen", ""]]}, {"id": "1804.06909", "submitter": "John Moore", "authors": "John Moore, Joel Pfeiffer, Kai Wei, Rishabh Iyer, Denis Charles, Ran\n  Gilad-Bachrach, Levi Boyles, Eren Manavoglu", "title": "Modeling and Simultaneously Removing Bias via Adversarial Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world systems, the predictions of deployed Machine Learned models\naffect the training data available to build subsequent models. This introduces\na bias in the training data that needs to be addressed. Existing solutions to\nthis problem attempt to resolve the problem by either casting this in the\nreinforcement learning framework or by quantifying the bias and re-weighting\nthe loss functions. In this work, we develop a novel Adversarial Neural Network\n(ANN) model, an alternative approach which creates a representation of the data\nthat is invariant to the bias. We take the Paid Search auction as our working\nexample and ad display position features as the confounding features for this\nsetting. We show the success of this approach empirically on both synthetic\ndata as well as real world paid search auction data from a major search engine.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 20:33:37 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Moore", "John", ""], ["Pfeiffer", "Joel", ""], ["Wei", "Kai", ""], ["Iyer", "Rishabh", ""], ["Charles", "Denis", ""], ["Gilad-Bachrach", "Ran", ""], ["Boyles", "Levi", ""], ["Manavoglu", "Eren", ""]]}, {"id": "1804.06943", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Dayvid V. R. Oliveira, George D. C. Cavalcanti, Thyago N. Porpino,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "K-Nearest Oracles Borderline Dynamic Classifier Ensemble Selection", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489737", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Ensemble Selection (DES) techniques aim to select locally competent\nclassifiers for the classification of each new test sample. Most DES techniques\nestimate the competence of classifiers using a given criterion over the region\nof competence of the test sample (its the nearest neighbors in the validation\nset). The K-Nearest Oracles Eliminate (KNORA-E) DES selects all classifiers\nthat correctly classify all samples in the region of competence of the test\nsample, if such classifier exists, otherwise, it removes from the region of\ncompetence the sample that is furthest from the test sample, and the process\nrepeats. When the region of competence has samples of different classes,\nKNORA-E can reduce the region of competence in such a way that only samples of\na single class remain in the region of competence, leading to the selection of\nlocally incompetent classifiers that classify all samples in the region of\ncompetence as being from the same class. In this paper, we propose two DES\ntechniques: K-Nearest Oracles Borderline (KNORA-B) and K-Nearest Oracles\nBorderline Imbalanced (KNORA-BI). KNORA-B is a DES technique based on KNORA-E\nthat reduces the region of competence but maintains at least one sample from\neach class that is in the original region of competence. KNORA-BI is a\nvariation of KNORA-B for imbalance datasets that reduces the region of\ncompetence but maintains at least one minority class sample if there is any in\nthe original region of competence. Experiments are conducted comparing the\nproposed techniques with 19 DES techniques from the literature using 40\ndatasets. The results show that the proposed techniques achieved interesting\nresults, with KNORA-BI outperforming state-of-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 23:11:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Oliveira", "Dayvid V. R.", ""], ["Cavalcanti", "George D. C.", ""], ["Porpino", "Thyago N.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.06952", "submitter": "Cl\\'ement Canonne", "authors": "Jayadev Acharya and Cl\\'ement L. Canonne and Himanshu Tyagi", "title": "Distributed Simulation and Distributed Inference", "comments": "This work is superseded by the more recent \"Inference under\n  Information Constraints II: Communication Constraints and Shared Randomness\"\n  (arXiv:1905.08302), by the same authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent samples from an unknown probability distribution $\\bf p$ on a\ndomain of size $k$ are distributed across $n$ players, with each player holding\none sample. Each player can communicate $\\ell$ bits to a central referee in a\nsimultaneous message passing model of communication to help the referee infer a\nproperty of the unknown $\\bf p$. What is the least number of players for\ninference required in the communication-starved setting of $\\ell<\\log k$? We\nbegin by exploring a general \"simulate-and-infer\" strategy for such inference\nproblems where the center simulates the desired number of samples from the\nunknown distribution and applies standard inference algorithms for the\ncollocated setting. Our first result shows that for $\\ell<\\log k$ perfect\nsimulation of even a single sample is not possible. Nonetheless, we present a\nLas Vegas algorithm that simulates a single sample from the unknown\ndistribution using $O(k/2^\\ell)$ samples in expectation. As an immediate\ncorollary, we get that simulate-and-infer attains the optimal sample complexity\nof $\\Theta(k^2/2^\\ell\\epsilon^2)$ for learning the unknown distribution to\ntotal variation distance $\\epsilon$. For the prototypical testing problem of\nidentity testing, simulate-and-infer works with $O(k^{3/2}/2^\\ell\\epsilon^2)$\nsamples, a requirement that seems to be inherent for all communication\nprotocols not using any additional resources. Interestingly, we can break this\nbarrier using public coins. Specifically, we exhibit a public-coin\ncommunication protocol that performs identity testing using\n$O(k/\\sqrt{2^\\ell}\\epsilon^2)$ samples. Furthermore, we show that this is\noptimal up to constant factors. Our theoretically sample-optimal protocol is\neasy to implement in practice. Our proof of lower bound entails showing a\ncontraction in $\\chi^2$ distance of product distributions due to communication\nconstraints and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 00:34:15 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 23:17:06 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 05:27:10 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1804.06964", "submitter": "Siyu Huang", "authors": "Siyu Huang, Xi Li, Zhi-Qi Cheng, Zhongfei Zhang, Alexander Hauptmann", "title": "GNAS: A Greedy Neural Architecture Search Method for Multi-Attribute\n  Learning", "comments": "ACM MM 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in deep multi-attribute learning is to effectively discover the\ninter-attribute correlation structures. Typically, the conventional deep\nmulti-attribute learning approaches follow the pipeline of manually designing\nthe network architectures based on task-specific expertise prior knowledge and\ncareful network tunings, leading to the inflexibility for various complicated\nscenarios in practice. Motivated by addressing this problem, we propose an\nefficient greedy neural architecture search approach (GNAS) to automatically\ndiscover the optimal tree-like deep architecture for multi-attribute learning.\nIn a greedy manner, GNAS divides the optimization of global architecture into\nthe optimizations of individual connections step by step. By iteratively\nupdating the local architectures, the global tree-like architecture gets\nconverged where the bottom layers are shared across relevant attributes and the\nbranches in top layers more encode attribute-specific features. Experiments on\nthree benchmark multi-attribute datasets show the effectiveness and compactness\nof neural architectures derived by GNAS, and also demonstrate the efficiency of\nGNAS in searching neural architectures.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 01:29:00 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 21:45:17 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Huang", "Siyu", ""], ["Li", "Xi", ""], ["Cheng", "Zhi-Qi", ""], ["Zhang", "Zhongfei", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1804.07010", "submitter": "Maziar Raissi", "authors": "Maziar Raissi", "title": "Forward-Backward Stochastic Neural Networks: Deep Learning of\n  High-dimensional Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY math.AP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical numerical methods for solving partial differential equations suffer\nfrom the curse dimensionality mainly due to their reliance on meticulously\ngenerated spatio-temporal grids. Inspired by modern deep learning based\ntechniques for solving forward and inverse problems associated with partial\ndifferential equations, we circumvent the tyranny of numerical discretization\nby devising an algorithm that is scalable to high-dimensions. In particular, we\napproximate the unknown solution by a deep neural network which essentially\nenables us to benefit from the merits of automatic differentiation. To train\nthe aforementioned neural network we leverage the well-known connection between\nhigh-dimensional partial differential equations and forward-backward stochastic\ndifferential equations. In fact, independent realizations of a standard\nBrownian motion will act as training data. We test the effectiveness of our\napproach for a couple of benchmark problems spanning a number of scientific\ndomains including Black-Scholes-Barenblatt and Hamilton-Jacobi-Bellman\nequations, both in 100-dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:30:45 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Raissi", "Maziar", ""]]}, {"id": "1804.07045", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia", "title": "Semantic Adversarial Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fueled by massive amounts of data, models produced by machine-learning (ML)\nalgorithms, especially deep neural networks, are being used in diverse domains\nwhere trustworthiness is a concern, including automotive systems, finance,\nhealth care, natural language processing, and malware detection. Of particular\nconcern is the use of ML algorithms in cyber-physical systems (CPS), such as\nself-driving cars and aviation, where an adversary can cause serious\nconsequences. However, existing approaches to generating adversarial examples\nand devising robust ML algorithms mostly ignore the semantics and context of\nthe overall system containing the ML component. For example, in an autonomous\nvehicle using deep learning for perception, not every adversarial example for\nthe neural network might lead to a harmful consequence. Moreover, one may want\nto prioritize the search for adversarial examples towards those that\nsignificantly modify the desired semantics of the overall system. Along the\nsame lines, existing algorithms for constructing robust ML algorithms ignore\nthe specification of the overall system. In this paper, we argue that the\nsemantics and specification of the overall system has a crucial role to play in\nthis line of research. We present preliminary research results that support\nthis claim.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:15:58 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 18:14:19 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Jha", "Somesh", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1804.07059", "submitter": "Kaushalya Madhawa Mr", "authors": "Kaushalya Madhawa, Tsuyoshi Murata", "title": "Exploring Partially Observed Networks with Nonparametric Bandits", "comments": "15 pages, 6 figures, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks such as social and communication networks are too large\nto be observed entirely. Such networks are often partially observed such that\nnetwork size, network topology, and nodes of the original network are unknown.\nIn this paper we formalize the Adaptive Graph Exploring problem. We assume that\nwe are given an incomplete snapshot of a large network and additional nodes can\nbe discovered by querying nodes in the currently observed network. The goal of\nthis problem is to maximize the number of observed nodes within a given query\nbudget. Querying which set of nodes maximizes the size of the observed network?\nWe formulate this problem as an exploration-exploitation problem and propose a\nnovel nonparametric multi-arm bandit (MAB) algorithm for identifying which\nnodes to be queried. Our contributions include: (1) $i$KNN-UCB, a novel\nnonparametric MAB algorithm, applies $k$-nearest neighbor UCB to the setting\nwhen the arms are presented in a vector space, (2) provide theoretical\nguarantee that $i$KNN-UCB algorithm has sublinear regret, and (3) applying\n$i$KNN-UCB algorithm on synthetic networks and real-world networks from\ndifferent domains, we show that our method discovers up to 40% more nodes\ncompared to existing baselines.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:57:34 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Madhawa", "Kaushalya", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "1804.07090", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Varun Kanade, Philip H. S. Torr, Puneet K. Dokania", "title": "Robustness via Deep Low-Rank Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of the dimensionality of the representations\nlearned in Deep Neural Networks (DNNs) on their robustness to input\nperturbations, both adversarial and random. To achieve low dimensionality of\nlearned representations, we propose an easy-to-use, end-to-end trainable,\nlow-rank regularizer (LR) that can be applied to any intermediate layer\nrepresentation of a DNN. This regularizer forces the feature representations to\n(mostly) lie in a low-dimensional linear subspace. We perform a wide range of\nexperiments that demonstrate that the LR indeed induces low rank on the\nrepresentations, while providing modest improvements to accuracy as an added\nbenefit. Furthermore, the learned features make the trained model significantly\nmore robust to input perturbations such as Gaussian and adversarial noise (even\nwithout adversarial training). Lastly, the low-dimensionality means that the\nlearned features are highly compressible; thus discriminative features of the\ndata can be stored using very little memory. Our experiments indicate that\nmodels trained using the LR learn robust classifiers by discovering subspaces\nthat avoid non-robust features. Algorithmically, the LR is scalable, generic,\nand straightforward to implement into existing deep learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:17:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 09:58:25 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 07:37:02 GMT"}, {"version": "v4", "created": "Thu, 21 Mar 2019 14:56:14 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 17:37:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Sanyal", "Amartya", ""], ["Kanade", "Varun", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1804.07091", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Erik Rodner, Yanira Guanche Garcia, Joachim Denzler", "title": "Detecting Regions of Maximal Divergence for Spatio-Temporal Anomaly\n  Detection", "comments": "Accepted by TPAMI. Examples and code:\n  https://cvjena.github.io/libmaxdiv/", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 41, no. 5, pp. 1088-1101, 1 May 2019", "doi": "10.1109/TPAMI.2018.2823766", "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of anomalies in space- and time-varying measurements is\nan important tool in several fields, e.g., fraud detection, climate analysis,\nor healthcare monitoring. We present an algorithm for detecting anomalous\nregions in multivariate spatio-temporal time-series, which allows for spotting\nthe interesting parts in large amounts of data, including video and text data.\nIn opposition to existing techniques for detecting isolated anomalous data\npoints, we propose the \"Maximally Divergent Intervals\" (MDI) framework for\nunsupervised detection of coherent spatial regions and time intervals\ncharacterized by a high Kullback-Leibler divergence compared with all other\ndata given. In this regard, we define an unbiased Kullback-Leibler divergence\nthat allows for ranking regions of different size and show how to enable the\nalgorithm to run on large-scale data sets in reasonable time using an interval\nproposal technique. Experiments on both synthetic and real data from various\ndomains, such as climate analysis, video surveillance, and text forensics,\ndemonstrate that our method is widely applicable and a valuable tool for\nfinding interesting events in different types of data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:23:07 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 07:23:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Rodner", "Erik", ""], ["Garcia", "Yanira Guanche", ""], ["Denzler", "Joachim", ""]]}, {"id": "1804.07098", "submitter": "Wouter Bulten", "authors": "Wouter Bulten, Geert Litjens", "title": "Unsupervised Prostate Cancer Detection on H&E using Convolutional\n  Adversarial Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised method using self-clustering convolutional\nadversarial autoencoders to classify prostate tissue as tumor or non-tumor\nwithout any labeled training data. The clustering method is integrated into the\ntraining of the autoencoder and requires only little post-processing. Our\nnetwork trains on hematoxylin and eosin (H&E) input patches and we tested two\ndifferent reconstruction targets, H&E and immunohistochemistry (IHC). We show\nthat antibody-driven feature learning using IHC helps the network to learn\nrelevant features for the clustering task. Our network achieves a F1 score of\n0.62 using only a small set of validation labels to assign classes to clusters.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:40:23 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bulten", "Wouter", ""], ["Litjens", "Geert", ""]]}, {"id": "1804.07101", "submitter": "Karin Schnass", "authors": "Marie Christine Pali, Karin Schnass", "title": "Dictionary learning -- from local towards global and adaptive", "comments": "11 figures, 5 pages per figure including pseudocode", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the convergence behaviour of dictionary learning via the\nIterative Thresholding and K-residual Means (ITKrM) algorithm. On one hand it\nis proved that ITKrM is a contraction under much more relaxed conditions than\npreviously necessary. On the other hand it is shown that there seem to exist\nstable fixed points that do not correspond to the generating dictionary, which\ncan be characterised as very coherent. Based on an analysis of the residuals\nusing these bad dictionaries, replacing coherent atoms with carefully designed\nreplacement candidates is proposed. In experiments on synthetic data this\noutperforms random or no replacement and always leads to full dictionary\nrecovery. Finally the question how to learn dictionaries without knowledge of\nthe correct dictionary size and sparsity level is addressed. Decoupling the\nreplacement strategy of coherent or unused atoms into pruning and adding, and\nslowly carefully increasing the sparsity level, leads to an adaptive version of\nITKrM. In several experiments this adaptive dictionary learning algorithm is\nshown to recover a generating dictionary from randomly initialised dictionaries\nof various sizes on synthetic data and to learn meaningful dictionaries on\nimage data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:51:14 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 12:03:28 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 11:34:37 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Pali", "Marie Christine", ""], ["Schnass", "Karin", ""]]}, {"id": "1804.07134", "submitter": "Gilles Kratzer", "authors": "Gilles Kratzer and Reinhard Furrer", "title": "varrank: an R package for variable ranking based on mutual information\n  with applications to observed systemic datasets", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the R package varrank. It has a flexible\nimplementation of heuristic approaches which perform variable ranking based on\nmutual information. The package is particularly suitable for exploring\nmultivariate datasets requiring a holistic analysis. The core functionality is\na general implementation of the minimum redundancy maximum relevance (mRMRe)\nmodel. This approach is based on information theory metrics. It is compatible\nwith discrete and continuous data which are discretised using a large choice of\npossible rules. The two main problems that can be addressed by this package are\nthe selection of the most representative variables for modeling a collection of\nvariables of interest, i.e., dimension reduction, and variable ranking with\nrespect to a set of variables of interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:12:03 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kratzer", "Gilles", ""], ["Furrer", "Reinhard", ""]]}, {"id": "1804.07144", "submitter": "Deepika Singh", "authors": "Deepika Singh, Erinc Merdivan, Ismini Psychoula, Johannes Kropf, Sten\n  Hanke, Matthieu Geist and Andreas Holzinger", "title": "Human Activity Recognition using Recurrent Neural Networks", "comments": null, "journal-ref": "International Cross-Domain Conference for Machine Learning and\n  Knowledge Extraction: CD-MAKE 2017", "doi": "10.1007/978-3-319-66808-6_18", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition using smart home sensors is one of the bases of\nubiquitous computing in smart environments and a topic undergoing intense\nresearch in the field of ambient assisted living. The increasingly large amount\nof data sets calls for machine learning methods. In this paper, we introduce a\ndeep learning model that learns to classify human activities without using any\nprior knowledge. For this purpose, a Long Short Term Memory (LSTM) Recurrent\nNeural Network was applied to three real world smart home datasets. The results\nof these experiments show that the proposed approach outperforms the existing\nones in terms of accuracy and performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:20:09 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Singh", "Deepika", ""], ["Merdivan", "Erinc", ""], ["Psychoula", "Ismini", ""], ["Kropf", "Johannes", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1804.07152", "submitter": "Liu Weiyi", "authors": "Weiyi Liu, Zhining Liu, Toyotaro Suzumura, Guangmin Hu", "title": "Scalable attribute-aware network embedding with locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding attributes for nodes to network embedding helps to improve the ability\nof the learned joint representation to depict features from topology and\nattributes simultaneously. Recent research on the joint embedding has exhibited\na promising performance on a variety of tasks by jointly embedding the two\nspaces. However, due to the indispensable requirement of globality based\ninformation, present approaches contain a flaw of in-scalability. Here we\npropose \\emph{SANE}, a scalable attribute-aware network embedding algorithm\nwith locality, to learn the joint representation from topology and attributes.\nBy enforcing the alignment of a local linear relationship between each node and\nits K-nearest neighbors in topology and attribute space, the joint embedding\nrepresentations are more informative comparing with a single representation\nfrom topology or attributes alone. And we argue that the locality in\n\\emph{SANE} is the key to learning the joint representation at scale. By using\nseveral real-world networks from diverse domains, We demonstrate the efficacy\nof \\emph{SANE} in performance and scalability aspect. Overall, for performance\non label classification, SANE successfully reaches up to the highest F1-score\non most datasets, and even closer to the baseline method that needs label\ninformation as extra inputs, compared with other state-of-the-art joint\nrepresentation algorithms. What's more, \\emph{SANE} has an up to 71.4\\%\nperformance gain compared with the single topology-based algorithm. For\nscalability, we have demonstrated the linearly time complexity of \\emph{SANE}.\nIn addition, we intuitively observe that when the network size scales to\n100,000 nodes, the \"learning joint embedding\" step of \\emph{SANE} only takes\n$\\approx10$ seconds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:59:50 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 00:40:08 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Weiyi", ""], ["Liu", "Zhining", ""], ["Suzumura", "Toyotaro", ""], ["Hu", "Guangmin", ""]]}, {"id": "1804.07155", "submitter": "Ludmila Kuncheva", "authors": "Ludmila I. Kuncheva, \\'Alvar Arnaiz-Gonz\\'alez, Jos\\'e-Francisco\n  D\\'iez-Pastor, and Iain A. D. Gunn", "title": "Instance Selection Improves Geometric Mean Accuracy: A Study on\n  Imbalanced Data Classification", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural way of handling imbalanced data is to attempt to equalise the class\nfrequencies and train the classifier of choice on balanced data. For two-class\nimbalanced problems, the classification success is typically measured by the\ngeometric mean (GM) of the true positive and true negative rates. Here we prove\nthat GM can be improved upon by instance selection, and give the theoretical\nconditions for such an improvement. We demonstrate that GM is non-monotonic\nwith respect to the number of retained instances, which discourages systematic\ninstance selection. We also show that balancing the distribution frequencies is\ninferior to a direct maximisation of GM. To verify our theoretical findings, we\ncarried out an experimental study of 12 instance selection methods for\nimbalanced data, using 66 standard benchmark data sets. The results reveal\npossible room for new instance selection methods for imbalanced data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:32:50 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kuncheva", "Ludmila I.", ""], ["Arnaiz-Gonz\u00e1lez", "\u00c1lvar", ""], ["D\u00edez-Pastor", "Jos\u00e9-Francisco", ""], ["Gunn", "Iain A. D.", ""]]}, {"id": "1804.07169", "submitter": "Magda Gregorova", "authors": "Magda Gregorov\\'a, Jason Ramapuram, Alexandros Kalousis, St\\'ephane\n  Marchand-Maillet", "title": "Large-scale Nonlinear Variable Selection via Kernel Random Features", "comments": "Final version for proceedings of ECML/PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for input variable selection in nonlinear regression.\nThe method is embedded into a kernel regression machine that can model general\nnonlinear functions, not being a priori limited to additive models. This is the\nfirst kernel-based variable selection method applicable to large datasets. It\nsidesteps the typical poor scaling properties of kernel methods by mapping the\ninputs into a relatively low-dimensional space of random features. The\nalgorithm discovers the variables relevant for the regression task together\nwith learning the prediction model through learning the appropriate nonlinear\nrandom feature maps. We demonstrate the outstanding performance of our method\non a set of large-scale synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:51:45 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 08:27:25 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Gregorov\u00e1", "Magda", ""], ["Ramapuram", "Jason", ""], ["Kalousis", "Alexandros", ""], ["Marchand-Maillet", "St\u00e9phane", ""]]}, {"id": "1804.07193", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Dipendra Misra, Michael L. Littman", "title": "Lipschitz Continuity in Model-based Reinforcement Learning", "comments": "Accepted for the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the impact of learning Lipschitz continuous models in the context\nof model-based reinforcement learning. We provide a novel bound on multi-step\nprediction error of Lipschitz models where we quantify the error using the\nWasserstein metric. We go on to prove an error bound for the value-function\nestimate arising from Lipschitz models and show that the estimated value\nfunction is itself Lipschitz. We conclude with empirical results that show the\nbenefits of controlling the Lipschitz constant of neural-network models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:29:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 04:02:26 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 12:40:44 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Asadi", "Kavosh", ""], ["Misra", "Dipendra", ""], ["Littman", "Michael L.", ""]]}, {"id": "1804.07209", "submitter": "Marco Ciccone", "authors": "Marco Ciccone, Marco Gallieri, Jonathan Masci, Christian Osendorfer,\n  Faustino Gomez", "title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential\n  Equations", "comments": "NeurIPS 2018 (updated version): new results and proof on incremental\n  stability for ReLU case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Non-Autonomous Input-Output Stable Network(NAIS-Net), a\nvery deep architecture where each stacked processing block is derived from a\ntime-invariant non-autonomous dynamical system. Non-autonomy is implemented by\nskip connections from the block input to each of the unrolled processing stages\nand allows stability to be enforced so that blocks can be unrolled adaptively\nto a pattern-dependent processing depth. NAIS-Net induces non-trivial,\nLipschitz input-output maps, even for an infinite unroll length. We prove that\nthe network is globally asymptotically stable so that for every initial\ncondition there is exactly one input-dependent equilibrium assuming $tanh$\nunits, and incrementally stable for ReL units. An efficient implementation that\nenforces the stability under derived conditions for both fully-connected and\nconvolutional layers is also presented. Experimental results show how NAIS-Net\nexhibits stability in practice, yielding a significant reduction in\ngeneralization gap compared to ResNets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:07:14 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 10:34:05 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 03:59:39 GMT"}, {"version": "v4", "created": "Fri, 21 May 2021 16:03:38 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ciccone", "Marco", ""], ["Gallieri", "Marco", ""], ["Masci", "Jonathan", ""], ["Osendorfer", "Christian", ""], ["Gomez", "Faustino", ""]]}, {"id": "1804.07237", "submitter": "Jiamiao Xu", "authors": "Jiamiao Xu, Shujian Yu, Xinge You, Mengjun Leng, Xiao-Yuan Jing and C.\n  L. Philip Chen", "title": "Multi-view Hybrid Embedding: A Divide-and-Conquer Approach", "comments": "This paper has been accepted by IEEE Transactions on Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel cross-view classification algorithm where the gallery and\nprobe data come from different views. A popular approach to tackle this problem\nis the multi-view subspace learning (MvSL) that aims to learn a latent subspace\nshared by multi-view data. Despite promising results obtained on some\napplications, the performance of existing methods deteriorates dramatically\nwhen the multi-view data is sampled from nonlinear manifolds or suffers from\nheavy outliers. To circumvent this drawback, motivated by the\nDivide-and-Conquer strategy, we propose Multi-view Hybrid Embedding (MvHE), a\nunique method of dividing the problem of cross-view classification into three\nsubproblems and building one model for each subproblem. Specifically, the first\nmodel is designed to remove view discrepancy, whereas the second and third\nmodels attempt to discover the intrinsic nonlinear structure and to increase\ndiscriminability in intra-view and inter-view samples respectively. The kernel\nextension is conducted to further boost the representation power of MvHE.\nExtensive experiments are conducted on four benchmark datasets. Our methods\ndemonstrate overwhelming advantages against the state-of-the-art MvSL based\ncross-view classification approaches in terms of classification accuracy and\nrobustness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:38:15 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 10:46:35 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Xu", "Jiamiao", ""], ["Yu", "Shujian", ""], ["You", "Xinge", ""], ["Leng", "Mengjun", ""], ["Jing", "Xiao-Yuan", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "1804.07240", "submitter": "Mustafa Mohamad", "authors": "Mustafa A. Mohamad, Themistoklis P. Sapsis", "title": "A sequential sampling strategy for extreme event statistics in nonlinear\n  dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for the evaluation of extreme event statistics associated\nwith nonlinear dynamical systems, using a small number of samples. From an\ninitial dataset of design points, we formulate a sequential strategy that\nprovides the 'next-best' data point (set of parameters) that when evaluated\nresults in improved estimates of the probability density function (pdf) for a\nscalar quantity of interest. The approach utilizes Gaussian process regression\nto perform Bayesian inference on the parameter-to-observation map describing\nthe quantity of interest. We then approximate the desired pdf along with\nuncertainty bounds utilizing the posterior distribution of the inferred map.\nThe 'next-best' design point is sequentially determined through an optimization\nprocedure that selects the point in parameter space that maximally reduces\nuncertainty between the estimated bounds of the pdf prediction. Since the\noptimization process utilizes only information from the inferred map it has\nminimal computational cost. Moreover, the special form of the metric emphasizes\nthe tails of the pdf. The method is practical for systems where the\ndimensionality of the parameter space is of moderate size, i.e. order O(10). We\napply the method to estimate the extreme event statistics for a very\nhigh-dimensional system with millions of degrees of freedom: an offshore\nplatform subjected to three-dimensional irregular waves. It is demonstrated\nthat the developed approach can accurately determine the extreme event\nstatistics using limited number of samples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:48:17 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Mohamad", "Mustafa A.", ""], ["Sapsis", "Themistoklis P.", ""]]}, {"id": "1804.07265", "submitter": "Te Han", "authors": "Te Han, Chao Liu, Wenguang Yang and Dongxiang Jiang", "title": "Deep Transfer Network with Joint Distribution Adaptation: A New\n  Intelligent Fault Diagnosis Framework for Industry Application", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.isatra.2019.08.012", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, an increasing popularity of deep learning model for\nintelligent condition monitoring and diagnosis as well as prognostics used for\nmechanical systems and structures has been observed. In the previous studies,\nhowever, a major assumption accepted by default, is that the training and\ntesting data are taking from same feature distribution. Unfortunately, this\nassumption is mostly invalid in real application, resulting in a certain lack\nof applicability for the traditional diagnosis approaches. Inspired by the idea\nof transfer learning that leverages the knowledge learnt from rich labeled data\nin source domain to facilitate diagnosing a new but similar target task, a new\nintelligent fault diagnosis framework, i.e., deep transfer network (DTN), which\ngeneralizes deep learning model to domain adaptation scenario, is proposed in\nthis paper. By extending the marginal distribution adaptation (MDA) to joint\ndistribution adaptation (JDA), the proposed framework can exploit the\ndiscrimination structures associated with the labeled data in source domain to\nadapt the conditional distribution of unlabeled target data, and thus guarantee\na more accurate distribution matching. Extensive empirical evaluations on three\nfault datasets validate the applicability and practicability of DTN, while\nachieving many state-of-the-art transfer results in terms of diverse operating\nconditions, fault severities and fault types.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 01:52:52 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Han", "Te", ""], ["Liu", "Chao", ""], ["Yang", "Wenguang", ""], ["Jiang", "Dongxiang", ""]]}, {"id": "1804.07269", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen, Pierre-Yves Oudeyer", "title": "Socially Guided Intrinsic Motivation for Robot Learning of Motor Skills", "comments": null, "journal-ref": "Autonomous Robots, Springer Verlag, 2014, 36 (3), pp.273-294", "doi": "10.1007/s10514-013-9339-y", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technical approach to robot learning of motor skills\nwhich combines active intrinsically motivated learning with imitation learning.\nOur architecture, called SGIM-D, allows efficient learning of high-dimensional\ncontinuous sensorimotor inverse models in robots, and in particular learns\ndistributions of parameterised motor policies that solve a corresponding\ndistribution of parameterised goals/tasks. This is made possible by the\ntechnical integration of imitation learning techniques within an algorithm for\nlearning inverse models that relies on active goal babbling. After reviewing\nsocial learning and intrinsic motivation approaches to action learning, we\ndescribe the general framework of our algorithm, before detailing its\narchitecture. In an experiment where a robot arm has to learn to use a flexible\nfishing line , we illustrate that SGIM-D efficiently combines the advantages of\nsocial learning and intrinsic motivation and benefits from human demonstration\nproperties to learn how to produce varied outcomes in the environment, while\ndeveloping more precise control policies in large spaces.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:47:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nguyen", "Sao Mai", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1804.07270", "submitter": "Xingzhang Ren", "authors": "Xingzhang Ren, Chen Long, Leilei Zhang, Ye Wei, Dongdong Du, Jingxi\n  Liang, Shikun Zhang, Weiping Li", "title": "A Dynamic Boosted Ensemble Learning Method Based on Random Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic boosted ensemble learning method based on random forest\n(DBRF), a novel ensemble algorithm that incorporates the notion of hard example\nmining into Random Forest (RF) and thus combines the high accuracy of Boosting\nalgorithm with the strong generalization of Bagging algorithm. Specifically, we\npropose to measure the quality of each leaf node of every decision tree in the\nrandom forest to determine hard examples. By iteratively training and then\nremoving easy examples from training data, we evolve the random forest to focus\non hard examples dynamically so as to learn decision boundaries better. Data\ncan be cascaded through these random forests learned in each iteration in\nsequence to generate predictions, thus making RF deep. We also propose to use\nevolution mechanism and smart iteration mechanism to improve the performance of\nthe model. DBRF outperforms RF on three UCI datasets and achieved\nstate-of-the-art results compared to other deep models. Moreover, we show that\nDBRF is also a new way of sampling and can be very useful when learning from\nimbalanced data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:55:21 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 14:55:36 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 16:19:36 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Ren", "Xingzhang", ""], ["Long", "Chen", ""], ["Zhang", "Leilei", ""], ["Wei", "Ye", ""], ["Du", "Dongdong", ""], ["Liang", "Jingxi", ""], ["Zhang", "Shikun", ""], ["Li", "Weiping", ""]]}, {"id": "1804.07275", "submitter": "Yuhong Guo", "authors": "Meng Ye and Yuhong Guo", "title": "Deep Triplet Ranking Networks for One-Shot Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the breakthroughs achieved by deep learning models in conventional\nsupervised learning scenarios, their dependence on sufficient labeled training\ndata in each class prevents effective applications of these deep models in\nsituations where labeled training instances for a subset of novel classes are\nvery sparse -- in the extreme case only one instance is available for each\nclass. To tackle this natural and important challenge, one-shot learning, which\naims to exploit a set of well labeled base classes to build classifiers for the\nnew target classes that have only one observed instance per class, has recently\nreceived increasing attention from the research community. In this paper we\npropose a novel end-to-end deep triplet ranking network to perform one-shot\nlearning. The proposed approach learns class universal image embeddings on the\nwell labeled base classes under a triplet ranking loss, such that the instances\nfrom new classes can be categorized based on their similarity with the one-shot\ninstances in the learned embedding space. Moreover, our approach can naturally\nincorporate the available one-shot instances from the new classes into the\nembedding learning process to improve the triplet ranking model. We conduct\nexperiments on two popular datasets for one-shot learning. The results show the\nproposed approach achieves better performance than the state-of-the- art\ncomparison methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:57:52 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Ye", "Meng", ""], ["Guo", "Yuhong", ""]]}, {"id": "1804.07300", "submitter": "Nikhil Kotecha", "authors": "Nikhil Kotecha and Paul Young", "title": "Generating Music using an LSTM Network", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of music needs to have the ability to recall past details and have a\nclear, coherent understanding of musical structure. Detailed in the paper is a\nneural network architecture that predicts and generates polyphonic music\naligned with musical rules. The probabilistic model presented is a Bi-axial\nLSTM trained with a kernel reminiscent of a convolutional kernel. When analyzed\nquantitatively and qualitatively, this approach performs well in composing\npolyphonic music. Link to the code is provided.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 21:14:00 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Kotecha", "Nikhil", ""], ["Young", "Paul", ""]]}, {"id": "1804.07323", "submitter": "Ekaterina Tolstaya", "authors": "Alec Koppel, Ekaterina Tolstaya, Ethan Stump, Alejandro Ribeiro", "title": "Nonparametric Stochastic Compositional Gradient Descent for Q-Learning\n  in Continuous Markov Decision Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov Decision Problems defined over continuous state and action\nspaces, where an autonomous agent seeks to learn a map from its states to\nactions so as to maximize its long-term discounted accumulation of rewards. We\naddress this problem by considering Bellman's optimality equation defined over\naction-value functions, which we reformulate into a nested non-convex\nstochastic optimization problem defined over a Reproducing Kernel Hilbert Space\n(RKHS). We develop a functional generalization of stochastic quasi-gradient\nmethod to solve it, which, owing to the structure of the RKHS, admits a\nparameterization in terms of scalar weights and past state-action pairs which\ngrows proportionately with the algorithm iteration index. To ameliorate this\ncomplexity explosion, we apply Kernel Orthogonal Matching Pursuit to the\nsequence of kernel weights and dictionaries, which yields a controllable error\nin the descent direction of the underlying optimization method. We prove that\nthe resulting algorithm, called KQ-Learning, converges with probability 1 to a\nstationary point of this problem, yielding a fixed point of the Bellman\noptimality operator under the hypothesis that it belongs to the RKHS. Under\nconstant learning rates, we further obtain convergence to a small Bellman error\nthat depends on the chosen learning rates. Numerical evaluation on the\nContinuous Mountain Car and Inverted Pendulum tasks yields convergent\nparsimonious learned action-value functions, policies that are competitive with\nthe state of the art, and exhibit reliable, reproducible learning behavior.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:24:18 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Koppel", "Alec", ""], ["Tolstaya", "Ekaterina", ""], ["Stump", "Ethan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1804.07344", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog", "title": "Effects of sampling skewness of the importance-weighted risk estimator\n  on model selection", "comments": "Conference paper, 6 pages, 5 figures", "journal-ref": "24th International Conference on Pattern Recognition (ICPR),\n  Beijing, 2018, pp. 1468 - 1473", "doi": "10.1109/ICPR.2018.8546186", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance-weighting is a popular and well-researched technique for dealing\nwith sample selection bias and covariate shift. It has desirable\ncharacteristics such as unbiasedness, consistency and low computational\ncomplexity. However, weighting can have a detrimental effect on an estimator as\nwell. In this work, we empirically show that the sampling distribution of an\nimportance-weighted estimator can be skewed. For sample selection bias\nsettings, and for small sample sizes, the importance-weighted risk estimator\nproduces overestimates for datasets in the body of the sampling distribution,\ni.e. the majority of cases, and large underestimates for data sets in the tail\nof the sampling distribution. These over- and underestimates of the risk lead\nto suboptimal regularization parameters when used for importance-weighted\nvalidation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:23:06 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""]]}, {"id": "1804.07347", "submitter": "Bharath Bhushan Damodaran", "authors": "Chippy Jayaprakash, Bharath Bhushan Damodaran, Sowmya V and K P Soman", "title": "Randomized ICA and LDA Dimensionality Reduction Methods for\n  Hyperspectral Image Classification", "comments": "Submitted IEEE JSTARS", "journal-ref": "J. of Applied Remote Sensing, 14(3), 036507 (2020)", "doi": "10.1117/1.JRS.14.036507", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimensionality reduction is an important step in processing the hyperspectral\nimages (HSI) to overcome the curse of dimensionality problem. Linear\ndimensionality reduction methods such as Independent component analysis (ICA)\nand Linear discriminant analysis (LDA) are commonly employed to reduce the\ndimensionality of HSI. These methods fail to capture non-linear dependency in\nthe HSI data, as data lies in the nonlinear manifold. To handle this, nonlinear\ntransformation techniques based on kernel methods were introduced for\ndimensionality reduction of HSI. However, the kernel methods involve cubic\ncomputational complexity while computing the kernel matrix, and thus its\npotential cannot be explored when the number of pixels (samples) are large. In\nliterature a fewer number of pixels are randomly selected to partial to\novercome this issue, however this sub-optimal strategy might neglect important\ninformation in the HSI. In this paper, we propose randomized solutions to the\nICA and LDA dimensionality reduction methods using Random Fourier features, and\nwe label them as RFFICA and RFFLDA. Our proposed method overcomes the\nscalability issue and to handle the non-linearities present in the data more\nefficiently. Experiments conducted with two real-world hyperspectral datasets\ndemonstrates that our proposed randomized methods outperform the conventional\nkernel ICA and kernel LDA in terms overall, per-class accuracies and\ncomputational time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:36:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Jayaprakash", "Chippy", ""], ["Damodaran", "Bharath Bhushan", ""], ["V", "Sowmya", ""], ["Soman", "K P", ""]]}, {"id": "1804.07351", "submitter": "Seong Jae Hwang", "authors": "Seong Jae Hwang, Ronak Mehta, Hyunwoo J. Kim, Vikas Singh", "title": "Sampling-free Uncertainty Estimation in Gated Recurrent Units with\n  Exponential Families", "comments": "Version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a concerted effort to derive mechanisms in vision and\nmachine learning systems to offer uncertainty estimates of the predictions they\nmake. Clearly, there are enormous benefits to a system that is not only\naccurate but also has a sense for when it is not sure. Existing proposals\ncenter around Bayesian interpretations of modern deep architectures -- these\nare effective but can often be computationally demanding. We show how classical\nideas in the literature on exponential families on probabilistic networks\nprovide an excellent starting point to derive uncertainty estimates in Gated\nRecurrent Units (GRU). Our proposal directly quantifies uncertainty\ndeterministically, without the need for costly sampling-based estimation. We\ndemonstrate how our model can be used to quantitatively and qualitatively\nmeasure uncertainty in unsupervised image sequence prediction. To our\nknowledge, this is the first result describing sampling-free uncertainty\nestimation for powerful sequential models such as GRUs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:40:47 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 20:00:32 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hwang", "Seong Jae", ""], ["Mehta", "Ronak", ""], ["Kim", "Hyunwoo J.", ""], ["Singh", "Vikas", ""]]}, {"id": "1804.07353", "submitter": "Yuqian Zhou", "authors": "Yuqian Zhou, Kuangxiao Gu, Thomas Huang", "title": "Unsupervised Representation Adversarial Learning Network: from\n  Reconstruction to Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good representation for arbitrarily complicated data should have the\ncapability of semantic generation, clustering and reconstruction. Previous\nresearch has already achieved impressive performance on either one. This paper\naims at learning a disentangled representation effective for all of them in an\nunsupervised way. To achieve all the three tasks together, we learn the forward\nand inverse mapping between data and representation on the basis of a symmetric\nadversarial process. In theory, we minimize the upper bound of the two\nconditional entropy loss between the latent variables and the observations\ntogether to achieve the cycle consistency. The newly proposed RepGAN is tested\non MNIST, fashionMNIST, CelebA, and SVHN datasets to perform unsupervised\nclassification, generation and reconstruction tasks. The result demonstrates\nthat RepGAN is able to learn a useful and competitive representation. To the\nauthor's knowledge, our work is the first one to achieve both a high\nunsupervised classification accuracy and low reconstruction error on MNIST.\nCodes are available at https://github.com/yzhouas/RepGAN-tensorflow.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:42:22 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 16:44:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhou", "Yuqian", ""], ["Gu", "Kuangxiao", ""], ["Huang", "Thomas", ""]]}, {"id": "1804.07405", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim, Ethan Vizitei, Varun Ganapathi", "title": "GritNet: Student Performance Prediction with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student performance prediction - where a machine forecasts the future\nperformance of students as they interact with online coursework - is a\nchallenging problem. Reliable early-stage predictions of a student's future\nperformance could be critical to facilitate timely educational interventions\nduring a course. However, very few prior studies have explored this problem\nfrom a deep learning perspective. In this paper, we recast the student\nperformance prediction problem as a sequential event prediction problem and\npropose a new deep learning based algorithm, termed GritNet, which builds upon\nthe bidirectional long short term memory (BLSTM). Our results, from real\nUdacity students' graduation predictions, show that the GritNet not only\nconsistently outperforms the standard logistic-regression based method, but\nthat improvements are substantially pronounced in the first few weeks when\naccurate predictions are most challenging.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:35:04 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Vizitei", "Ethan", ""], ["Ganapathi", "Varun", ""]]}, {"id": "1804.07419", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Felipe N. Walmsley, George D. C. Cavalcanti, Dayvid V. R. Oliveira,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "An Ensemble Generation Method Based on Instance Hardness", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489269", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, ensemble methods have been receiving a great deal of\nattention. Techniques such as Bagging and Boosting have been successfully\napplied to a variety of problems. Nevertheless, such techniques are still\nsusceptible to the effects of noise and outliers in the training data. We\npropose a new method for the generation of pools of classifiers based on\nBagging, in which the probability of an instance being selected during the\nresampling process is inversely proportional to its instance hardness, which\ncan be understood as the likelihood of an instance being misclassified,\nregardless of the choice of classifier. The goal of the proposed method is to\nremove noisy data without sacrificing the hard instances which are likely to be\nfound on class boundaries. We evaluate the performance of the method in\nnineteen public data sets, and compare it to the performance of the Bagging and\nRandom Subspace algorithms. Our experiments show that in high noise scenarios\nthe accuracy of our method is significantly better than that of Bagging.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 01:29:47 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 07:18:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Walmsley", "Felipe N.", ""], ["Cavalcanti", "George D. C.", ""], ["Oliveira", "Dayvid V. R.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.07433", "submitter": "Gaurav Thakur", "authors": "Gagan Choudhury, David Lynch, Gaurav Thakur and Simon Tse", "title": "Two Use Cases of Machine Learning for SDN-Enabled IP/Optical Networks:\n  Traffic Matrix Prediction and Optical Path Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two applications of machine learning in the context of IP/Optical\nnetworks. The first one allows agile management of resources at a core\nIP/Optical network by using machine learning for short-term and long-term\nprediction of traffic flows and joint global optimization of IP and optical\nlayers using colorless/directionless (CD) flexible ROADMs. Multilayer\ncoordination allows for significant cost savings, flexible new services to meet\ndynamic capacity needs, and improved robustness by being able to proactively\nadapt to new traffic patterns and network conditions. The second application is\nimportant as we migrate our metro networks to Open ROADM networks, to allow\nphysical routing without the need for detailed knowledge of optical parameters.\nWe discuss a proof-of-concept study, where detailed performance data for\nwavelengths on a current flexible ROADM network is used for machine learning to\npredict the optical performance of each wavelength. Both applications can be\nefficiently implemented by using a SDN (Software Defined Network) controller.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 02:43:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 12:54:48 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Choudhury", "Gagan", ""], ["Lynch", "David", ""], ["Thakur", "Gaurav", ""], ["Tse", "Simon", ""]]}, {"id": "1804.07481", "submitter": "Fabrizio Carcillo", "authors": "Fabirzio Carcillo, Yann-A\\\"el Le Borgne, Olivier Caelen and Gianluca\n  Bontempi", "title": "Streaming Active Learning Strategies for Real-Life Credit Card Fraud\n  Detection: Assessment and Visualization", "comments": null, "journal-ref": "International Journal of Data Science and Analytics 2018", "doi": "10.1007/s41060-018-0116-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit card fraud detection is a very challenging problem because of the\nspecific nature of transaction data and the labeling process. The transaction\ndata is peculiar because they are obtained in a streaming fashion, they are\nstrongly imbalanced and prone to non-stationarity. The labeling is the outcome\nof an active learning process, as every day human investigators contact only a\nsmall number of cardholders (associated to the riskiest transactions) and\nobtain the class (fraud or genuine) of the related transactions. An adequate\nselection of the set of cardholders is therefore crucial for an efficient fraud\ndetection process. In this paper, we present a number of active learning\nstrategies and we investigate their fraud detection accuracies. We compare\ndifferent criteria (supervised, semi-supervised and unsupervised) to query\nunlabeled transactions. Finally, we highlight the existence of an\nexploitation/exploration trade-off for active learning in the context of fraud\ndetection, which has so far been overlooked in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:03:52 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Carcillo", "Fabirzio", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Caelen", "Olivier", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "1804.07573", "submitter": "Sheng Chen", "authors": "Sheng Chen, Yang Liu, Xiang Gao, Zhen Han", "title": "MobileFaceNets: Efficient CNNs for Accurate Real-Time Face Verification\n  on Mobile Devices", "comments": "Accepted as a conference paper at CCBR 2018. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of extremely efficient CNN models, MobileFaceNets, which\nuse less than 1 million parameters and are specifically tailored for\nhigh-accuracy real-time face verification on mobile and embedded devices. We\nfirst make a simple analysis on the weakness of common mobile networks for face\nverification. The weakness has been well overcome by our specifically designed\nMobileFaceNets. Under the same experimental conditions, our MobileFaceNets\nachieve significantly superior accuracy as well as more than 2 times actual\nspeedup over MobileNetV2. After trained by ArcFace loss on the refined\nMS-Celeb-1M, our single MobileFaceNet of 4.0MB size achieves 99.55% accuracy on\nLFW and 92.59% TAR@FAR1e-6 on MegaFace, which is even comparable to\nstate-of-the-art big CNN models of hundreds MB size. The fastest one of\nMobileFaceNets has an actual inference time of 18 milliseconds on a mobile\nphone. For face verification, MobileFaceNets achieve significantly improved\nefficiency over previous state-of-the-art mobile CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:18:57 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 13:20:46 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 02:38:01 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 02:50:58 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Chen", "Sheng", ""], ["Liu", "Yang", ""], ["Gao", "Xiang", ""], ["Han", "Zhen", ""]]}, {"id": "1804.07580", "submitter": "Andrei Zinovyev Dr.", "authors": "Luca Albergante, Evgeny M. Mirkes, Huidong Chen, Alexis Martin, Louis\n  Faure, Emmanuel Barillot, Luca Pinello, Alexander N. Gorban, Andrei Zinovyev", "title": "Robust And Scalable Learning Of Complex Dataset Topologies Via Elpigraph", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large datasets represented by multidimensional data point clouds often\npossess non-trivial distributions with branching trajectories and excluded\nregions, with the recent single-cell transcriptomic studies of developing\nembryo being notable examples. Reducing the complexity and producing compact\nand interpretable representations of such data remains a challenging task. Most\nof the existing computational methods are based on exploring the local data\npoint neighbourhood relations, a step that can perform poorly in the case of\nmultidimensional and noisy data. Here we present ElPiGraph, a scalable and\nrobust method for approximation of datasets with complex structures which does\nnot require computing the complete data distance matrix or the data point\nneighbourhood graph. This method is able to withstand high levels of noise and\nis capable of approximating complex topologies via principal graph ensembles\nthat can be combined into a consensus principal graph. ElPiGraph deals\nefficiently with large and complex datasets in various fields from biology,\nwhere it can be used to infer gene dynamics from single-cell RNA-Seq, to\nastronomy, where it can be used to explore complex structures in the\ndistribution of galaxies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:45:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 11:19:23 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Albergante", "Luca", ""], ["Mirkes", "Evgeny M.", ""], ["Chen", "Huidong", ""], ["Martin", "Alexis", ""], ["Faure", "Louis", ""], ["Barillot", "Emmanuel", ""], ["Pinello", "Luca", ""], ["Gorban", "Alexander N.", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "1804.07612", "submitter": "Dominic Masters", "authors": "Dominic Masters and Carlo Luschi", "title": "Revisiting Small Batch Training for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network training is typically based on mini-batch\nstochastic gradient optimization. While the use of large mini-batches increases\nthe available computational parallelism, small batch training has been shown to\nprovide improved generalization performance and allows a significantly smaller\nmemory footprint, which might also be exploited to improve machine throughput.\n  In this paper, we review common assumptions on learning rate scaling and\ntraining duration, as a basis for an experimental comparison of test\nperformance for different mini-batch sizes. We adopt a learning rate that\ncorresponds to a constant average weight update per gradient calculation (i.e.,\nper unit cost of computation), and point out that this results in a variance of\nthe weight updates that increases linearly with the mini-batch size $m$.\n  The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet\ndatasets show that increasing the mini-batch size progressively reduces the\nrange of learning rates that provide stable convergence and acceptable test\nperformance. On the other hand, small mini-batch sizes provide more up-to-date\ngradient calculations, which yields more stable and reliable training. The best\nperformance has been consistently obtained for mini-batch sizes between $m = 2$\nand $m = 32$, which contrasts with recent work advocating the use of mini-batch\nsizes in the thousands.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 13:44:12 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Masters", "Dominic", ""], ["Luschi", "Carlo", ""]]}, {"id": "1804.07633", "submitter": "Ammar Daskin", "authors": "Ammar Daskin", "title": "A Simple Quantum Neural Net with a Periodic Activation Function", "comments": "a discussion session is added. 5 pages, conference paper. To appear\n  in The 2018 IEEE International Conference on Systems, Man, and Cybernetics\n  (SMC2018)", "journal-ref": null, "doi": "10.1109/SMC.2018.00491", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple neural net that requires only $O(nlog_2k)$\nnumber of qubits and $O(nk)$ quantum gates: Here, $n$ is the number of input\nparameters, and $k$ is the number of weights applied to these parameters in the\nproposed neural net. We describe the network in terms of a quantum circuit, and\nthen draw its equivalent classical neural net which involves $O(k^n)$ nodes in\nthe hidden layer. Then, we show that the network uses a periodic activation\nfunction of cosine values of the linear combinations of the inputs and weights.\nThe backpropagation is described through the gradient descent, and then iris\nand breast cancer datasets are used for the simulations. The numerical results\nindicate the network can be used in machine learning problems and it may\nprovide exponential speedup over the same structured classical neural net.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 14:16:49 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 14:44:02 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 08:55:39 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Daskin", "Ammar", ""]]}, {"id": "1804.07645", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu and Elena Mocanu", "title": "One-Shot Learning using Mixture of Variational Autoencoders: a\n  Generalization Learning approach", "comments": null, "journal-ref": "17th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2018)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, even if it is very successful nowadays, traditionally needs\nvery large amounts of labeled data to perform excellent on the classification\ntask. In an attempt to solve this problem, the one-shot learning paradigm,\nwhich makes use of just one labeled sample per class and prior knowledge,\nbecomes increasingly important. In this paper, we propose a new one-shot\nlearning method, dubbed MoVAE (Mixture of Variational AutoEncoders), to perform\nclassification. Complementary to prior studies, MoVAE represents a shift of\nparadigm in comparison with the usual one-shot learning methods, as it does not\nuse any prior knowledge. Instead, it starts from zero knowledge and one labeled\nsample per class. Afterward, by using unlabeled data and the generalization\nlearning concept (in a way, more as humans do), it is capable to gradually\nimprove by itself its performance. Even more, if there are no unlabeled data\navailable MoVAE can still perform well in one-shot learning classification. We\ndemonstrate empirically the efficiency of our proposed approach on three\ndatasets, i.e. the handwritten digits (MNIST), fashion products\n(Fashion-MNIST), and handwritten characters (Omniglot), showing that MoVAE\noutperforms state-of-the-art one-shot learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 22:00:20 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Mocanu", "Elena", ""]]}, {"id": "1804.07669", "submitter": "Yanwei Cui", "authors": "Yanwei Cui, Rogatien Tobossi, Olivia Vigouroux", "title": "Modelling customer online behaviours with neural networks: applications\n  to conversion prediction and advertising retargeting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply neural networks into digital marketing world for the\npurpose of better targeting the potential customers. To do so, we model the\ncustomer online behaviours using dedicated neural network architectures.\nStarting from user searched keywords in a search engine to the landing page and\ndifferent following pages, until the user left the site, we model the whole\nvisited journey with a Recurrent Neural Network (RNN), together with\nConvolution Neural Networks (CNN) that can take into account of the semantic\nmeaning of user searched keywords and different visited page names. With such\nmodel, we use Monte Carlo simulation to estimate the conversion rates of each\npotential customer in the future visiting. We believe our concept and the\npreliminary promising results in this paper enable the use of largely available\ncustomer online behaviours data for advanced digital marketing analysis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:23:12 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Cui", "Yanwei", ""], ["Tobossi", "Rogatien", ""], ["Vigouroux", "Olivia", ""]]}, {"id": "1804.07672", "submitter": "Youngjoo Seo", "authors": "Youngjoo Seo, Manuel Morante, Yannis Kopsinis and Sergios Theodoridis", "title": "Unsupervised learning of the brain connectivity dynamic using residual\n  D-net", "comments": "10 pages, 5 figueres and 3 tables, under review in MIDL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel unsupervised learning method to learn the\nbrain dynamics using a deep learning architecture named residual D-net. As it\nis often the case in medical research, in contrast to typical deep learning\ntasks, the size of the resting-state functional Magnetic Resonance Image\n(rs-fMRI) datasets for training is limited. Thus, the available data should be\nvery efficiently used to learn the complex patterns underneath the brain\nconnectivity dynamics. To address this issue, we use residual connections to\nalleviate the training complexity through recurrent multi-scale representation.\nWe conduct two classification tasks to differentiate early and late stage Mild\nCognitive Impairment (MCI) from Normal healthy Control (NC) subjects. The\nexperiments verify that our proposed residual D-net indeed learns the brain\nconnectivity dynamics, leading to significantly higher classification accuracy\ncompared to previously published techniques.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:25:56 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:32:58 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Seo", "Youngjoo", ""], ["Morante", "Manuel", ""], ["Kopsinis", "Yannis", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "1804.07729", "submitter": "Tandri Gauksson", "authors": "Rima Alaifari, Giovanni S. Alberti and Tandri Gauksson", "title": "ADef: an Iterative Algorithm to Construct Adversarial Deformations", "comments": "ICLR 2019 conference paper. 25 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have proven to be a powerful tool for many\nrecognition and classification tasks, their stability properties are still not\nwell understood. In the past, image classifiers have been shown to be\nvulnerable to so-called adversarial attacks, which are created by additively\nperturbing the correctly classified image. In this paper, we propose the ADef\nalgorithm to construct a different kind of adversarial attack created by\niteratively applying small deformations to the image, found through a gradient\ndescent step. We demonstrate our results on MNIST with convolutional neural\nnetworks and on ImageNet with Inception-v3 and ResNet-101.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:11:06 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 17:25:10 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 15:42:59 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Alaifari", "Rima", ""], ["Alberti", "Giovanni S.", ""], ["Gauksson", "Tandri", ""]]}, {"id": "1804.07745", "submitter": "Armand Joulin", "authors": "Armand Joulin, Piotr Bojanowski, Tomas Mikolov, Herve Jegou, Edouard\n  Grave", "title": "Loss in Translation: Learning Bilingual Word Mapping with a Retrieval\n  Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous word representations learned separately on distinct languages can\nbe aligned so that their words become comparable in a common space. Existing\nworks typically solve a least-square regression problem to learn a rotation\naligning a small bilingual lexicon, and use a retrieval criterion for\ninference. In this paper, we propose an unified formulation that directly\noptimizes a retrieval criterion in an end-to-end fashion. Our experiments on\nstandard benchmarks show that our approach outperforms the state of the art on\nword translation, with the biggest improvements observed for distant language\npairs such as English-Chinese.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:41:15 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 09:02:40 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 11:52:08 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Joulin", "Armand", ""], ["Bojanowski", "Piotr", ""], ["Mikolov", "Tomas", ""], ["Jegou", "Herve", ""], ["Grave", "Edouard", ""]]}, {"id": "1804.07757", "submitter": "Shuangtao Li", "authors": "Shuangtao Li, Yuanke Chen, Yanlin Peng, Lin Bai", "title": "Learning More Robust Features with Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, it has been found that neural networks can be easily fooled\nby adversarial examples, which is a potential safety hazard in some\nsafety-critical applications. Many researchers have proposed various method to\nmake neural networks more robust to white-box adversarial attacks, but an\neffective method have not been found so far. In this short paper, we focus on\nthe robustness of the features learned by neural networks. We show that the\nfeatures learned by neural networks are not robust, and find that the\nrobustness of the learned features is closely related to the resistance against\nadversarial examples of neural networks. We also find that adversarial training\nagainst fast gradients sign method (FGSM) does not make the leaned features\nvery robust, even if it can make the trained networks very resistant to FGSM\nattack. Then we propose a method, which can be seen as an extension of\nadversarial training, to train neural networks to learn more robust features.\nWe perform experiments on MNIST and CIFAR-10 to evaluate our method, and the\nexperiment results show that this method greatly improves the robustness of the\nlearned features and the resistance to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 05:07:14 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Li", "Shuangtao", ""], ["Chen", "Yuanke", ""], ["Peng", "Yanlin", ""], ["Bai", "Lin", ""]]}, {"id": "1804.07758", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Elektra Kypridemou", "title": "Mapping Images to Psychological Similarity Spaces Using Neural Networks", "comments": "Accepted to AIC 2018 (http://aic2018.pa.icar.cnr.it/), see\n  http://ceur-ws.org/Vol-2418/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive framework of conceptual spaces bridges the gap between symbolic\nand subsymbolic AI by proposing an intermediate conceptual layer where\nknowledge is represented geometrically. There are two main approaches for\nobtaining the dimensions of this conceptual similarity space: using similarity\nratings from psychological experiments and using machine learning techniques.\nIn this paper, we propose a combination of both approaches by using\npsychologically derived similarity ratings to constrain the machine learning\nprocess. This way, a mapping from stimuli to conceptual spaces can be learned\nthat is both supported by psychological data and allows generalization to\nunseen stimuli. The results of a first feasibility study support our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:29:05 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 07:54:46 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["Kypridemou", "Elektra", ""]]}, {"id": "1804.07759", "submitter": "Gengyu Lyu", "authors": "Gengyu Lyu, Songhe Feng, Congyang Lang", "title": "A Self-paced Regularization Framework for Partial-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label learning (PLL) aims to solve the problem where each training\ninstance is associated with a set of candidate labels, one of which is the\ncorrect label. Most PLL algorithms try to disambiguate the candidate label set,\nby either simply treating each candidate label equally or iteratively\nidentifying the true label. Nonetheless, existing algorithms usually treat all\nlabels and instances equally, and the complexities of both labels and instances\nare not taken into consideration during the learning stage. Inspired by the\nsuccessful application of self-paced learning strategy in machine learning\nfield, we integrate the self-paced regime into the partial label learning\nframework and propose a novel Self-Paced Partial-Label Learning (SP-PLL)\nalgorithm, which could control the learning process to alleviate the problem by\nranking the priorities of the training examples together with their candidate\nlabels during each learning iteration. Extensive experiments and comparisons\nwith other baseline methods demonstrate the effectiveness and robustness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:04:32 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 08:49:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Lyu", "Gengyu", ""], ["Feng", "Songhe", ""], ["Lang", "Congyang", ""]]}, {"id": "1804.07768", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza and Daniel Krefl", "title": "Sampling the Riemann-Theta Boltzmann Machine", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the visible sector probability density function of the\nRiemann-Theta Boltzmann machine corresponds to a gaussian mixture model\nconsisting of an infinite number of component multi-variate gaussians. The\nweights of the mixture are given by a discrete multi-variate gaussian over the\nhidden state space. This allows us to sample the visible sector density\nfunction in a straight-forward manner. Furthermore, we show that the visible\nsector probability density function possesses an affine transform property,\nsimilar to the multi-variate gaussian density.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:00:02 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:38:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Carrazza", "Stefano", ""], ["Krefl", "Daniel", ""]]}, {"id": "1804.07779", "submitter": "Daoming Lyu", "authors": "Fangkai Yang, Daoming Lyu, Bo Liu, Steven Gustafson", "title": "PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement\n  Learning for Robust Decision-Making", "comments": "conference version accepted by IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and symbolic planning have both been used to build\nintelligent autonomous agents. Reinforcement learning relies on learning from\ninteractions with real world, which often requires an unfeasibly large amount\nof experience. Symbolic planning relies on manually crafted symbolic knowledge,\nwhich may not be robust to domain uncertainties and changes. In this paper we\npresent a unified framework {\\em PEORL} that integrates symbolic planning with\nhierarchical reinforcement learning (HRL) to cope with decision-making in a\ndynamic environment with uncertainties.\n  Symbolic plans are used to guide the agent's task execution and learning, and\nthe learned experience is fed back to symbolic knowledge to improve planning.\nThis method leads to rapid policy search and robust symbolic plans in complex\ndomains. The framework is tested on benchmark domains of HRL.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:16:43 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 16:46:13 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 20:38:43 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Yang", "Fangkai", ""], ["Lyu", "Daoming", ""], ["Liu", "Bo", ""], ["Gustafson", "Steven", ""]]}, {"id": "1804.07789", "submitter": "Anirban Laha", "authors": "Preksha Nema, Shreyas Shetty, Parag Jain, Anirban Laha, Karthik\n  Sankaranarayanan, Mitesh M. Khapra", "title": "Generating Descriptions from Structured Data Using a Bifocal Attention\n  Mechanism and Gated Orthogonalization", "comments": "Accepted in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the task of generating natural language\ndescriptions from a structured table of facts containing fields (such as\nnationality, occupation, etc) and values (such as Indian, actor, director,\netc). One simple choice is to treat the table as a sequence of fields and\nvalues and then use a standard seq2seq model for this task. However, such a\nmodel is too generic and does not exploit task-specific characteristics. For\nexample, while generating descriptions from a table, a human would attend to\ninformation at two levels: (i) the fields (macro level) and (ii) the values\nwithin the field (micro level). Further, a human would continue attending to a\nfield for a few timesteps till all the information from that field has been\nrendered and then never return back to this field (because there is nothing\nleft to say about it). To capture this behavior we use (i) a fused bifocal\nattention mechanism which exploits and combines this micro and macro level\ninformation and (ii) a gated orthogonalization mechanism which tries to ensure\nthat a field is remembered for a few time steps and then forgotten. We\nexperiment with a recently released dataset which contains fact tables about\npeople and their corresponding one line biographical descriptions in English.\nIn addition, we also introduce two similar datasets for French and German. Our\nexperiments show that the proposed model gives 21% relative improvement over a\nrecently proposed state of the art method and 10% relative improvement over\nbasic seq2seq models. The code and the datasets developed as a part of this\nwork are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:30:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nema", "Preksha", ""], ["Shetty", "Shreyas", ""], ["Jain", "Parag", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1804.07795", "submitter": "Dmitriy Drusvyatskiy", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Sham Kakade, Jason D. Lee", "title": "Stochastic subgradient method converges on tame functions", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the question: what convergence guarantees does the\nstochastic subgradient method have in the absence of smoothness and convexity?\nWe prove that the stochastic subgradient method, on any semialgebraic locally\nLipschitz function, produces limit points that are all first-order stationary.\nMore generally, our result applies to any function with a Whitney stratifiable\ngraph. In particular, this work endows the stochastic subgradient method, and\nits proximal extension, with rigorous convergence guarantees for a wide class\nof problems arising in data science---including all popular deep learning\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:52:52 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 02:28:45 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 00:29:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Kakade", "Sham", ""], ["Lee", "Jason D.", ""]]}, {"id": "1804.07802", "submitter": "Eunhyeok Park", "authors": "Eunhyeok Park, Sungjoo Yoo, Peter Vajda", "title": "Value-aware Quantization for Training and Inference of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel value-aware quantization which applies aggressively\nreduced precision to the majority of data while separately handling a small\namount of large data in high precision, which reduces total quantization errors\nunder very low precision. We present new techniques to apply the proposed\nquantization to training and inference. The experiments show that our method\nwith 3-bit activations (with 2% of large ones) can give the same training\naccuracy as full-precision one while offering significant (41.6% and 53.7%)\nreductions in the memory cost of activations in ResNet-152 and Inception-v3\ncompared with the state-of-the-art method. Our experiments also show that deep\nnetworks such as Inception-v3, ResNet-101 and DenseNet-121 can be quantized for\ninference with 4-bit weights and activations (with 1% 16-bit data) within 1%\ntop-1 accuracy drop.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 19:13:37 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""], ["Vajda", "Peter", ""]]}, {"id": "1804.07824", "submitter": "Yan Xu", "authors": "Patrick Koch, Oleg Golovidov, Steven Gardner, Brett Wujek, Joshua\n  Griffin, Yan Xu", "title": "Autotune: A Derivative-free Optimization Framework for Hyperparameter\n  Tuning", "comments": "10 Pages, 9 figures, accept by KDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3219837", "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications often require hyperparameter tuning. The\nhyperparameters usually drive both the efficiency of the model training process\nand the resulting model quality. For hyperparameter tuning, machine learning\nalgorithms are complex black-boxes. This creates a class of challenging\noptimization problems, whose objective functions tend to be nonsmooth,\ndiscontinuous, unpredictably varying in computational expense, and include\ncontinuous, categorical, and/or integer variables. Further, function\nevaluations can fail for a variety of reasons including numerical difficulties\nor hardware failures. Additionally, not all hyperparameter value combinations\nare compatible, which creates so called hidden constraints. Robust and\nefficient optimization algorithms are needed for hyperparameter tuning. In this\npaper we present an automated parallel derivative-free optimization framework\ncalled \\textbf{Autotune}, which combines a number of specialized sampling and\nsearch methods that are very effective in tuning machine learning models\ndespite these challenges. Autotune provides significantly improved models over\nusing default hyperparameter settings with minimal user interaction on\nreal-world applications. Given the inherent expense of training numerous\ncandidate models, we demonstrate the effectiveness of Autotune's search methods\nand the efficient distributed and parallel paradigms for training and tuning\nmodels, and also discuss the resource trade-offs associated with the ability to\nboth distribute the training process and parallelize the tuning process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 20:56:33 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 18:20:17 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Koch", "Patrick", ""], ["Golovidov", "Oleg", ""], ["Gardner", "Steven", ""], ["Wujek", "Brett", ""], ["Griffin", "Joshua", ""], ["Xu", "Yan", ""]]}, {"id": "1804.07837", "submitter": "Zhiyuan Li", "authors": "Elad Hazan, Wei Hu, Yuanzhi Li, Zhiyuan Li", "title": "Online Improper Learning with an Approximation Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the question of reducing online learning to approximate\noptimization of the offline problem. In this setting, we give two algorithms\nwith near-optimal performance in the full information setting: they guarantee\noptimal regret and require only poly-logarithmically many calls to the\napproximation oracle per iteration. Furthermore, these algorithms apply to the\nmore general improper learning problems. In the bandit setting, our algorithm\nalso significantly improves the best previously known oracle complexity while\nmaintaining the same regret.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:46:06 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Hazan", "Elad", ""], ["Hu", "Wei", ""], ["Li", "Yuanzhi", ""], ["Li", "Zhiyuan", ""]]}, {"id": "1804.07846", "submitter": "Edward Collier", "authors": "Edward Collier, Robert DiBiano, Supratik Mukhopadhyay", "title": "CactusNets: Layer Applicability as a Metric for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained over large datasets learn features that are both\ngeneric to the whole dataset, and specific to individual classes in the\ndataset. Learned features tend towards generic in the lower layers and specific\nin the higher layers of a network. Methods like fine-tuning are made possible\nbecause of the ability for one filter to apply to multiple target classes. Much\nlike the human brain this behavior, can also be used to cluster and separate\nclasses. However, to the best of our knowledge there is no metric for how\napplicable learned features are to specific classes. In this paper we propose a\ndefinition and metric for measuring the applicability of learned features to\nindividual classes, and use this applicability metric to estimate input\napplicability and produce a new method of unsupervised learning we call the\nCactusNet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 22:05:27 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Collier", "Edward", ""], ["DiBiano", "Robert", ""], ["Mukhopadhyay", "Supratik", ""]]}, {"id": "1804.07855", "submitter": "Xiujun Li", "authors": "Da Tang and Xiujun Li and Jianfeng Gao and Chong Wang and Lihong Li\n  and Tony Jebara", "title": "Subgoal Discovery for Hierarchical Dialogue Policy Learning", "comments": "11 pages, 6 figures, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents to engage in complex goal-oriented dialogues is challenging\npartly because the main learning signals are very sparse in long conversations.\nIn this paper, we propose a divide-and-conquer approach that discovers and\nexploits the hidden structure of the task to enable efficient policy learning.\nFirst, given successful example dialogues, we propose the Subgoal Discovery\nNetwork (SDN) to divide a complex goal-oriented task into a set of simpler\nsubgoals in an unsupervised fashion. We then use these subgoals to learn a\nmulti-level policy by hierarchical reinforcement learning. We demonstrate our\nmethod by building a dialogue agent for the composite task of travel planning.\nExperiments with simulated and real users show that our approach performs\ncompetitively against a state-of-the-art method that requires human-defined\nsubgoals. Moreover, we show that the learned subgoals are often human\ncomprehensible.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:06:44 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 22:20:26 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 22:46:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Tang", "Da", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Wang", "Chong", ""], ["Li", "Lihong", ""], ["Jebara", "Tony", ""]]}, {"id": "1804.07870", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "Gradient Masking Causes CLEVER to Overestimate Adversarial Perturbation\n  Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in research on adversarial examples is that vulnerability to\nadversarial examples is usually measured by running attack algorithms. Because\nthe attack algorithms are not optimal, the attack algorithms are prone to\noverestimating the size of perturbation needed to fool the target model. In\nother words, the attack-based methodology provides an upper-bound on the size\nof a perturbation that will fool the model, but security guarantees require a\nlower bound. CLEVER is a proposed scoring method to estimate a lower bound.\nUnfortunately, an estimate of a bound is not a bound. In this report, we show\nthat gradient masking, a common problem that causes attack methodologies to\nprovide only a very loose upper bound, causes CLEVER to overestimate the size\nof perturbation needed to fool the model. In other words, CLEVER does not\nresolve the key problem with the attack-based methodology, because it fails to\nprovide a lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 00:38:33 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1804.07882", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Hiba H. Zakane, Robert Sabourin and George D. C.\n  Cavalcanti", "title": "Dynamic Ensemble Selection VS K-NN: why and when Dynamic Selection\n  obtains higher classification performance?", "comments": "Paper published on IPTA 2017", "journal-ref": null, "doi": "10.1109/IPTA.2017.8310100", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple classifier systems focus on the combination of classifiers to obtain\nbetter performance than a single robust one. These systems unfold three major\nphases: pool generation, selection and integration. One of the most promising\nMCS approaches is Dynamic Selection (DS), which relies on finding the most\ncompetent classifier or ensemble of classifiers to predict each test sample.\nThe majority of the DS techniques are based on the K-Nearest Neighbors (K-NN)\ndefinition, and the quality of the neighborhood has a huge impact on the\nperformance of DS methods. In this paper, we perform an analysis comparing the\nclassification results of DS techniques and the K-NN classifier under different\nconditions. Experiments are performed on 18 state-of-the-art DS techniques over\n30 classification datasets and results show that DS methods present a\nsignificant boost in classification accuracy even though they use the same\nneighborhood as the K-NN. The reasons behind the outperformance of DS\ntechniques over the K-NN classifier reside in the fact that DS techniques can\ndeal with samples with a high degree of instance hardness (samples that are\nlocated close to the decision border) as opposed to the K-NN. In this paper,\nnot only we explain why DS techniques achieve higher classification performance\nthan the K-NN but also when DS should be used.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 03:15:25 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Zakane", "Hiba H.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1804.07891", "submitter": "Tien Cuong Bui", "authors": "Tien-Cuong Bui, Van-Duc Le, Sang-Kyun Cha", "title": "A Deep Learning Approach for Forecasting Air Pollution in South Korea\n  Using LSTM", "comments": "6 pages, 5 figures, conference paper, Seoul & Daegu air quality\n  datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tackling air pollution is an imperative problem in South Korea, especially in\nurban areas, over the last few years. More specially, South Korea has joined\nthe ranks of the world's most polluted countries alongside with other Asian\ncapitals, such as Beijing or Delhi. Much research is being conducted in\nenvironmental science to evaluate the dangerous impact of particulate matters\non public health. Besides that, deterministic models of air pollutant behavior\nare also generated; however, this is both complex and often inaccurate. On the\ncontrary, deep recurrent neural network reveals potent potential on forecasting\nout-comes of time-series data and has become more prevalent. This paper uses\nRecurrent Neural Network (RNN) with Long Short-Term Memory units as a framework\nfor leveraging knowledge from time-series data of air pollution and\nmeteorological information in Daegu, Seoul, Beijing, and Shenyang.\nAdditionally, we use encoder-decoder model, which is similar to machine\ncomprehension problems, as a crucial part of our prediction machine. Finally,\nwe investigate the prediction accuracy of various configurations. Our\nexperiments prevent the efficiency of integrating multiple layers of RNN on\nprediction model when forecasting far timesteps ahead. This research is a\nsignificant motivation for not only continuing researching on urban air quality\nbut also help the government leverage that insight to enact beneficial policies\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 05:07:47 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 01:24:44 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 13:45:12 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Bui", "Tien-Cuong", ""], ["Le", "Van-Duc", ""], ["Cha", "Sang-Kyun", ""]]}, {"id": "1804.07931", "submitter": "Liqin Zhao", "authors": "Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu,\n  Kun Gai", "title": "Entire Space Multi-Task Model: An Effective Approach for Estimating\n  Post-Click Conversion Rate", "comments": "accept by SIGIR-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating post-click conversion rate (CVR) accurately is crucial for ranking\nsystems in industrial applications such as recommendation and advertising.\nConventional CVR modeling applies popular deep learning methods and achieves\nstate-of-the-art performance. However it encounters several task-specific\nproblems in practice, making CVR modeling challenging. For example,\nconventional CVR models are trained with samples of clicked impressions while\nutilized to make inference on the entire space with samples of all impressions.\nThis causes a sample selection bias problem. Besides, there exists an extreme\ndata sparsity problem, making the model fitting rather difficult. In this\npaper, we model CVR in a brand-new perspective by making good use of sequential\npattern of user actions, i.e., impression -> click -> conversion. The proposed\nEntire Space Multi-task Model (ESMM) can eliminate the two problems\nsimultaneously by i) modeling CVR directly over the entire space, ii) employing\na feature representation transfer learning strategy. Experiments on dataset\ngathered from Taobao's recommender system demonstrate that ESMM significantly\noutperforms competitive methods. We also release a sampling version of this\ndataset to enable future research. To the best of our knowledge, this is the\nfirst public dataset which contains samples with sequential dependence of click\nand conversion labels for CVR modeling.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 09:59:29 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 12:54:14 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Ma", "Xiao", ""], ["Zhao", "Liqin", ""], ["Huang", "Guan", ""], ["Wang", "Zhi", ""], ["Hu", "Zelin", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1804.07933", "submitter": "Battista Biggio", "authors": "Huang Xiao, Battista Biggio, Gavin Brown, Giorgio Fumera, Claudia\n  Eckert, Fabio Roli", "title": "Is feature selection secure against training data poisoning?", "comments": null, "journal-ref": "Proc. of the 32nd ICML, Lille, France, 2015. JMLR: W&CP vol. 37", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in adversarial settings is becoming an important task for\napplication domains where attackers may inject malicious data into the training\nset to subvert normal operation of data-driven technologies. Feature selection\nhas been widely used in machine learning for security applications to improve\ngeneralization and computational efficiency, although it is not clear whether\nits use may be beneficial or even counterproductive when training data are\npoisoned by intelligent attackers. In this work, we shed light on this issue by\nproviding a framework to investigate the robustness of popular feature\nselection methods, including LASSO, ridge regression and the elastic net. Our\nresults on malware detection show that feature selection methods can be\nsignificantly compromised under attack (we can reduce LASSO to almost random\nchoices of feature sets by careful insertion of less than 5% poisoned training\nsamples), highlighting the need for specific countermeasures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 10:18:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Xiao", "Huang", ""], ["Biggio", "Battista", ""], ["Brown", "Gavin", ""], ["Fumera", "Giorgio", ""], ["Eckert", "Claudia", ""], ["Roli", "Fabio", ""]]}, {"id": "1804.07944", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Charles Sutton", "title": "Variational Inference In Pachinko Allocation Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pachinko Allocation Machine (PAM) is a deep topic model that allows\nrepresenting rich correlation structures among topics by a directed acyclic\ngraph over topics. Because of the flexibility of the model, however,\napproximate inference is very difficult. Perhaps for this reason, only a small\nnumber of potential PAM architectures have been explored in the literature. In\nthis paper we present an efficient and flexible amortized variational inference\nmethod for PAM, using a deep inference network to parameterize the approximate\nposterior distribution in a manner similar to the variational autoencoder. Our\ninference method produces more coherent topics than state-of-art inference\nmethods for PAM while being an order of magnitude faster, which allows\nexploration of a wider range of PAM architectures than have previously been\nstudied.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:12:25 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Srivastava", "Akash", ""], ["Sutton", "Charles", ""]]}, {"id": "1804.08003", "submitter": "Aven Samareh", "authors": "Aven Samareh and Mahshid Salemi Parizi", "title": "Stability of the Stochastic Gradient Method for an Approximated Large\n  Scale Kernel Machine", "comments": "Submitted to Journal of Signal Processing Systems (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we measured the stability of stochastic gradient method (SGM)\nfor learning an approximated Fourier primal support vector machine. The\nstability of an algorithm is considered by measuring the generalization error\nin terms of the absolute difference between the test and the training error.\nOur problem is to learn an approximated kernel function using random Fourier\nfeatures for a binary classification problem via online convex optimization\nsettings. For a convex, Lipschitz continuous and smooth loss function, given\nreasonable number of iterations stochastic gradient method is stable. We showed\nthat with a high probability SGM generalizes well for an approximated kernel\nunder given assumptions.We empirically verified the theoretical findings for\ndifferent parameters using several data sets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 17:50:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Samareh", "Aven", ""], ["Parizi", "Mahshid Salemi", ""]]}, {"id": "1804.08066", "submitter": "Guoxin Cui", "authors": "Guoxin Cui, Jun Xu, Wei Zeng, Yanyan Lan, Jiafeng Guo, Xueqi Cheng", "title": "MQGrad: Reinforcement Learning of Gradient Quantization in Parameter\n  Server", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most significant bottleneck in training large scale machine\nlearning models on parameter server (PS) is the communication overhead, because\nit needs to frequently exchange the model gradients between the workers and\nservers during the training iterations. Gradient quantization has been proposed\nas an effective approach to reducing the communication volume. One key issue in\ngradient quantization is setting the number of bits for quantizing the\ngradients. Small number of bits can significantly reduce the communication\noverhead while hurts the gradient accuracies, and vise versa. An ideal\nquantization method would dynamically balance the communication overhead and\nmodel accuracy, through adjusting the number bits according to the knowledge\nlearned from the immediate past training iterations. Existing methods, however,\nquantize the gradients either with fixed number of bits, or with predefined\nheuristic rules. In this paper we propose a novel adaptive quantization method\nwithin the framework of reinforcement learning. The method, referred to as\nMQGrad, formalizes the selection of quantization bits as actions in a Markov\ndecision process (MDP) where the MDP states records the information collected\nfrom the past optimization iterations (e.g., the sequence of the loss function\nvalues). During the training iterations of a machine learning algorithm, MQGrad\ncontinuously updates the MDP state according to the changes of the loss\nfunction. Based on the information, MDP learns to select the optimal actions\n(number of bits) to quantize the gradients. Experimental results based on a\nbenchmark dataset showed that MQGrad can accelerate the learning of a large\nscale deep neural network while keeping its prediction accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 04:04:33 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Cui", "Guoxin", ""], ["Xu", "Jun", ""], ["Zeng", "Wei", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1804.08071", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang,\n  James M. Rehg, Le Song", "title": "Decoupled Networks", "comments": "CVPR 2018 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inner product-based convolution has been a central component of convolutional\nneural networks (CNNs) and the key to learning visual representations. Inspired\nby the observation that CNN-learned features are naturally decoupled with the\nnorm of features corresponding to the intra-class variation and the angle\ncorresponding to the semantic difference, we propose a generic decoupled\nlearning framework which models the intra-class variation and semantic\ndifference independently. Specifically, we first reparametrize the inner\nproduct to a decoupled form and then generalize it to the decoupled convolution\noperator which serves as the building block of our decoupled networks. We\npresent several effective instances of the decoupled convolution operator. Each\ndecoupled operator is well motivated and has an intuitive geometric\ninterpretation. Based on these decoupled operators, we further propose to\ndirectly learn the operator from data. Extensive experiments show that such\ndecoupled reparameterization renders significant performance gain with easier\nconvergence and stronger robustness.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 05:26:08 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Liu", "Weiyang", ""], ["Liu", "Zhen", ""], ["Yu", "Zhiding", ""], ["Dai", "Bo", ""], ["Lin", "Rongmei", ""], ["Wang", "Yisen", ""], ["Rehg", "James M.", ""], ["Song", "Le", ""]]}, {"id": "1804.08130", "submitter": "Nikolaos Freris", "authors": "Saif Eddin Jabari, Nikolaos M. Freris, and Deepthi Mary Dilip", "title": "Sparse Travel Time Estimation from Streaming Data", "comments": null, "journal-ref": "Transportation Science 2019", "doi": "10.1287/trsc.2019.0920", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two shortcomings in online travel time estimation methods for\ncongested urban traffic. The first shortcoming is related to the determination\nof the number of mixture modes, which can change dynamically, within day and\nfrom day to day. The second shortcoming is the wide-spread use of Gaussian\nprobability densities as mixture components. Gaussian densities fail to capture\nthe positive skew in travel time distributions and, consequently, large numbers\nof mixture components are needed for reasonable fitting accuracy when applied\nas mixture components. They also assign positive probabilities to negative\ntravel times. To address these issues, this paper derives a mixture\ndistribution with Gamma component densities, which are asymmetric and supported\non the positive numbers. We use sparse estimation techniques to ensure\nparsimonious models and propose a generalization of Gamma mixture densities\nusing Mittag-Leffler functions, which provides enhanced fitting flexibility and\nimproved parsimony. In order to accommodate within-day variability and allow\nfor online implementation of the proposed methodology (i.e., fast computations\non streaming travel time data), we introduce a recursive algorithm which\nefficiently updates the fitted distribution whenever new data become available.\nExperimental results using real-world travel time data illustrate the efficacy\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 16:21:02 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 18:12:51 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 22:48:34 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 15:45:18 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jabari", "Saif Eddin", ""], ["Freris", "Nikolaos M.", ""], ["Dilip", "Deepthi Mary", ""]]}, {"id": "1804.08219", "submitter": "Dicong Qiu", "authors": "Dicong Qiu and Karthik Paga", "title": "Adaptive Performance Assessment For Drivers Through Behavioral Advantage", "comments": "10 pages, 3 figures. Appeared in the Proceedings of the 1st Hackauton\n  Machine Learning Hackathon (Hackauton 2018), Pittsburgh, United States, 2018.\n  First Place Winner (Fuel Efficiency Problem); Most Innovative Prize", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential positive impact of autonomous driving and driver assistance\ntechnolo- gies have been a major impetus over the last decade. On the flip\nside, it has been a challenging problem to analyze the performance of human\ndrivers or autonomous driving agents quantitatively. In this work, we propose a\ngeneric method that compares the performance of drivers or autonomous driving\nagents even if the environmental conditions are different, by using the driver\nbehavioral advantage instead of absolute metrics, which efficiently removes the\nenvironmental factors. A concrete application of the method is also presented,\nwhere the performance of more than 100 truck drivers was evaluated and ranked\nin terms of fuel efficiency, covering more than 90,000 trips spanning an\naverage of 300 miles in a variety of driving conditions and environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:57:30 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 17:04:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Qiu", "Dicong", ""], ["Paga", "Karthik", ""]]}, {"id": "1804.08233", "submitter": "Yang Liu", "authors": "Yang Liu, Qiang Qu and Chao Gao", "title": "N-fold Superposition: Improving Neural Networks by Reducing the Noise in\n  Feature Maps", "comments": "7 pages, 5 figures, submitted to ICALIP 2018", "journal-ref": "2018 International Conference on Audio, Language and Image\n  Processing (ICALIP), Shanghai, 2018, pp. 450-456", "doi": "10.1109/ICALIP.2018.8455505", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the use of Fully Connected (FC) layer limits the performance of\nConvolutional Neural Networks (CNNs), this paper develops a method to improve\nthe coupling between the convolution layer and the FC layer by reducing the\nnoise in Feature Maps (FMs). Our approach is divided into three steps. Firstly,\nwe separate all the FMs into n blocks equally. Then, the weighted summation of\nFMs at the same position in all blocks constitutes a new block of FMs. Finally,\nwe replicate this new block into n copies and concatenate them as the input to\nthe FC layer. This sharing of FMs could reduce the noise in them apparently and\navert the impact by a particular FM on the specific part weight of hidden\nlayers, hence preventing the network from overfitting to some extent. Using the\nFermat Lemma, we prove that this method could make the global minima value\nrange of the loss function wider, by which makes it easier for neural networks\nto converge and accelerates the convergence process. This method does not\nsignificantly increase the amounts of network parameters (only a few more\ncoefficients added), and the experiments demonstrate that this method could\nincrease the convergence speed and improve the classification performance of\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 03:03:13 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 00:29:29 GMT"}, {"version": "v3", "created": "Thu, 3 May 2018 08:04:34 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Liu", "Yang", ""], ["Qu", "Qiang", ""], ["Gao", "Chao", ""]]}, {"id": "1804.08261", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Yongfeng Huang, Yiran Jiang, Yuxi Sun, Yu-Jin Zhan,\n  Pengcheng Luo", "title": "Clinical Assistant Diagnosis for Electronic Medical Record Based on\n  Convolutional Neural Network", "comments": "9 pages, 4 figures, Accepted by Scientific Reports", "journal-ref": null, "doi": "10.1038/s41598-018-24389-w", "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically extracting useful information from electronic medical records\nalong with conducting disease diagnoses is a promising task for both clinical\ndecision support(CDS) and neural language processing(NLP). Most of the existing\nsystems are based on artificially constructed knowledge bases, and then\nauxiliary diagnosis is done by rule matching. In this study, we present a\nclinical intelligent decision approach based on Convolutional Neural\nNetworks(CNN), which can automatically extract high-level semantic information\nof electronic medical records and then perform automatic diagnosis without\nartificial construction of rules or knowledge bases. We use collected 18,590\ncopies of the real-world clinical electronic medical records to train and test\nthe proposed model. Experimental results show that the proposed model can\nachieve 98.67\\% accuracy and 96.02\\% recall, which strongly supports that using\nconvolutional neural network to automatically learn high-level semantic\nfeatures of electronic medical records and then conduct assist diagnosis is\nfeasible and effective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 06:52:13 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yang", "Zhongliang", ""], ["Huang", "Yongfeng", ""], ["Jiang", "Yiran", ""], ["Sun", "Yuxi", ""], ["Zhan", "Yu-Jin", ""], ["Luo", "Pengcheng", ""]]}, {"id": "1804.08302", "submitter": "Boitumelo Ruf", "authors": "Boitumelo Ruf, Laurenz Thiel, Martin Weinmann", "title": "Deep cross-domain building extraction for selective depth estimation\n  from oblique aerial imagery", "comments": "Accepted in the ISPRS Annals of the Photogrammetry, Remote Sensing\n  and Spatial Information Science", "journal-ref": "ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., IV-1,\n  125-132, 2018", "doi": "10.5194/isprs-annals-IV-1-125-2018", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the technological advancements of aerial imagery and accurate 3d\nreconstruction of urban environments, more and more attention has been paid to\nthe automated analyses of urban areas. In our work, we examine two important\naspects that allow live analysis of building structures in city models given\noblique aerial imagery, namely automatic building extraction with convolutional\nneural networks (CNNs) and selective real-time depth estimation from aerial\nimagery. We use transfer learning to train the Faster R-CNN method for\nreal-time deep object detection, by combining a large ground-based dataset for\nurban scene understanding with a smaller number of images from an aerial\ndataset. We achieve an average precision (AP) of about 80% for the task of\nbuilding extraction on a selected evaluation dataset. Our evaluation focuses on\nboth dataset-specific learning and transfer learning. Furthermore, we present\nan algorithm that allows for multi-view depth estimation from aerial imagery in\nreal-time. We adopt the semi-global matching (SGM) optimization strategy to\npreserve sharp edges at object boundaries. In combination with the Faster\nR-CNN, it allows a selective reconstruction of buildings, identified with\nregions of interest (RoIs), from oblique aerial imagery.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:22:55 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 07:49:31 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 20:24:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ruf", "Boitumelo", ""], ["Thiel", "Laurenz", ""], ["Weinmann", "Martin", ""]]}, {"id": "1804.08328", "submitter": "Amir Zamir", "authors": "Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra\n  Malik, Silvio Savarese", "title": "Taskonomy: Disentangling Task Transfer Learning", "comments": "CVPR 2018 (Oral). See project website and live demos at\n  http://taskonomy.vision/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do visual tasks have a relationship, or are they unrelated? For instance,\ncould having surface normals simplify estimating the depth of an image?\nIntuition answers these questions positively, implying existence of a structure\namong visual tasks. Knowing this structure has notable values; it is the\nconcept underlying transfer learning and provides a principled way for\nidentifying redundancies across tasks, e.g., to seamlessly reuse supervision\namong related tasks or solve many tasks in one system without piling up the\ncomplexity.\n  We proposes a fully computational approach for modeling the structure of\nspace of visual tasks. This is done via finding (first and higher-order)\ntransfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\nand semantic tasks in a latent space. The product is a computational taxonomic\nmap for task transfer learning. We study the consequences of this structure,\ne.g. nontrivial emerged relationships, and exploit them to reduce the demand\nfor labeled data. For example, we show that the total number of labeled\ndatapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\n(compared to training independently) while keeping the performance nearly the\nsame. We provide a set of tools for computing and probing this taxonomical\nstructure including a solver that users can employ to devise efficient\nsupervision policies for their use cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 10:46:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zamir", "Amir", ""], ["Sax", "Alexander", ""], ["Shen", "William", ""], ["Guibas", "Leonidas", ""], ["Malik", "Jitendra", ""], ["Savarese", "Silvio", ""]]}, {"id": "1804.08333", "submitter": "Takayuki Nishio", "authors": "Takayuki Nishio, Ryo Yonetani", "title": "Client Selection for Federated Learning with Heterogeneous Resources in\n  Mobile Edge", "comments": null, "journal-ref": "Proc. IEEE ICC 2019, Shanghai, China, May 2019", "doi": "10.1109/ICC.2019.8761315", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We envision a mobile edge computing (MEC) framework for machine learning (ML)\ntechnologies, which leverages distributed client data and computation resources\nfor training high-performance ML models while preserving client privacy. Toward\nthis future goal, this work aims to extend Federated Learning (FL), a\ndecentralized learning framework that enables privacy-preserving training of\nmodels, to work with heterogeneous clients in a practical cellular network. The\nFL protocol iteratively asks random clients to download a trainable model from\na server, update it with own data, and upload the updated model to the server,\nwhile asking the server to aggregate multiple client updates to further improve\nthe model. While clients in this protocol are free from disclosing own private\ndata, the overall training process can become inefficient when some clients are\nwith limited computational resources (i.e. requiring longer update time) or\nunder poor wireless channel conditions (longer upload time). Our new FL\nprotocol, which we refer to as FedCS, mitigates this problem and performs FL\nefficiently while actively managing clients based on their resource conditions.\nSpecifically, FedCS solves a client selection problem with resource\nconstraints, which allows the server to aggregate as many client updates as\npossible and to accelerate performance improvement in ML models. We conducted\nan experimental evaluation using publicly-available large-scale image datasets\nto train deep neural networks on MEC environment simulations. The experimental\nresults show that FedCS is able to complete its training process in a\nsignificantly shorter time compared to the original FL protocol.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:08:41 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 09:25:08 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Nishio", "Takayuki", ""], ["Yonetani", "Ryo", ""]]}, {"id": "1804.08369", "submitter": "K\\'aroly Zsolnai-Feh\\'er", "authors": "K\\'aroly Zsolnai-Feh\\'er, Peter Wonka and Michael Wimmer", "title": "Gaussian Material Synthesis", "comments": "Supplementary data and source code:\n  https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/", "journal-ref": "ACM Transactions on Graphics (SIGGRAPH 2018) 37 (4)", "doi": "10.1145/3197517.3201307", "report-no": "Zsolnai18", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a learning-based system for rapid mass-scale material synthesis\nthat is useful for novice and expert users alike. The user preferences are\nlearned via Gaussian Process Regression and can be easily sampled for new\nrecommendations. Typically, each recommendation takes 40-60 seconds to render\nwith global illumination, which makes this process impracticable for real-world\nworkflows. Our neural network eliminates this bottleneck by providing\nhigh-quality image predictions in real time, after which it is possible to pick\nthe desired materials from a gallery and assign them to a scene in an intuitive\nmanner. Workflow timings against Disney's \"principled\" shader reveal that our\nsystem scales well with the number of sought materials, thus empowering even\nnovice users to generate hundreds of high-quality material models without any\nexpertise in material modeling. Similarly, expert users experience a\nsignificant decrease in the total modeling time when populating a scene with\nmaterials. Furthermore, our proposed solution also offers controllable\nrecommendations and a novel latent space variant generation step to enable the\nreal-time fine-tuning of materials without requiring any domain expertise.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:33:59 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Zsolnai-Feh\u00e9r", "K\u00e1roly", ""], ["Wonka", "Peter", ""], ["Wimmer", "Michael", ""]]}, {"id": "1804.08376", "submitter": "Tomas Iesmantas", "authors": "Tomas Iesmantas and Robertas Alzbutas", "title": "Convolutional capsule network for classification of breast cancer\n  histology images", "comments": "Submitted to ICIAR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatization of the diagnosis of any kind of disease is of great importance\nand it's gaining speed as more and more deep learning solutions are applied to\ndifferent problems. One of such computer aided systems could be a decision\nsupport too able to accurately differentiate between different types of breast\ncancer histological images - normal tissue or carcinoma. In this paper authors\npresent a deep learning solution, based on convolutional capsule network for\nclassification of four types of images of breast tissue biopsy when hematoxylin\nand eusin staining is applied. The cross-validation accuracy was achieved to be\n0.87 with equaly high sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:48:49 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Iesmantas", "Tomas", ""], ["Alzbutas", "Robertas", ""]]}, {"id": "1804.08396", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Jun-Seok Oh", "title": "Path Planning in Support of Smart Mobility Applications using Generative\n  Adversarial Networks", "comments": "8 pages, submitted to IEEE SmartData-2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes and evaluates the use of Generative Adversarial Networks\n(GANs) for path planning in support of smart mobility applications such as\nindoor and outdoor navigation applications, individualized wayfinding for\npeople with disabilities (e.g., vision impairments, physical disabilities,\netc.), path planning for evacuations, robotic navigations, and path planning\nfor autonomous vehicles. We propose an architecture based on GANs to recommend\naccurate and reliable paths for navigation applications. The proposed system\ncan use crowd-sourced data to learn the trajectories and infer new ones. The\nsystem provides users with generated paths that help them navigate from their\nlocal environment to reach a desired location. As a use case, we experimented\nwith the proposed method in support of a wayfinding application in an indoor\nenvironment. Our experiments assert that the generated paths are correct and\nreliable. The accuracy of the classification task for the generated paths is up\nto 99% and the quality of the generated paths has a mean opinion score of 89%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:21:31 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Oh", "Jun-Seok", ""]]}, {"id": "1804.08416", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Ting Liu, Shengda Jin, and Xiliang Luo", "title": "Learn and Pick Right Nodes to Offload", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task offloading is a promising technology to exploit the benefits of fog\ncomputing. An effective task offloading strategy is needed to utilize the\ncomputational resources efficiently. In this paper, we endeavor to seek an\nonline task offloading strategy to minimize the long-term latency. In\nparticular, we formulate a stochastic programming problem, where the\nexpectations of the system parameters change abruptly at unknown time instants.\nMeanwhile, we consider the fact that the queried nodes can only feed back the\nprocessing results after finishing the tasks. We then put forward an effective\nalgorithm to solve this challenging stochastic programming under the\nnon-stationary bandit model. We further prove that our proposed algorithm is\nasymptotically optimal in a non-stationary fog-enabled network. Numerical\nsimulations are carried out to corroborate our designs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 05:18:09 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 11:49:29 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Liu", "Ting", ""], ["Jin", "Shengda", ""], ["Luo", "Xiliang", ""]]}, {"id": "1804.08420", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhongzhi Yu, Chuchu Fan, Dan Roth", "title": "Exploiting Partially Annotated Data for Temporal Relation Extraction", "comments": "[Final Version] short paper accepted by *SEM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating temporal relations (TempRel) between events described in natural\nlanguage is known to be labor intensive, partly because the total number of\nTempRels is quadratic in the number of events. As a result, only a small number\nof documents are typically annotated, limiting the coverage of various\nlexical/semantic phenomena. In order to improve existing approaches, one\npossibility is to make use of the readily available, partially annotated data\n(P as in partial) that cover more documents. However, missing annotations in P\nare known to hurt, rather than help, existing systems. This work is a case\nstudy in exploring various usages of P for TempRel extraction. Results show\nthat despite missing annotations, P is still a useful supervision signal for\nthis task within a constrained bootstrapping learning framework. The system\ndescribed in this system is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 21:33:00 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 02:31:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ning", "Qiang", ""], ["Yu", "Zhongzhi", ""], ["Fan", "Chuchu", ""], ["Roth", "Dan", ""]]}, {"id": "1804.08450", "submitter": "Dawei Yang", "authors": "Lei Huang, Dawei Yang, Bo Lang, Jia Deng", "title": "Decorrelated Batch Normalization", "comments": "Accepted to CVPR 2018. Code available at\n  https://github.com/umich-vl/DecorrelatedBN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is capable of accelerating the training of deep\nmodels by centering and scaling activations within mini-batches. In this work,\nwe propose Decorrelated Batch Normalization (DBN), which not just centers and\nscales activations but whitens them. We explore multiple whitening techniques,\nand find that PCA whitening causes a problem we call stochastic axis swapping,\nwhich is detrimental to learning. We show that ZCA whitening does not suffer\nfrom this problem, permitting successful learning. DBN retains the desirable\nqualities of BN and further improves BN's optimization efficiency and\ngeneralization ability. We design comprehensive experiments to show that DBN\ncan improve the performance of BN on multilayer perceptrons and convolutional\nneural networks. Furthermore, we consistently improve the accuracy of residual\nnetworks on CIFAR-10, CIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:06:50 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Huang", "Lei", ""], ["Yang", "Dawei", ""], ["Lang", "Bo", ""], ["Deng", "Jia", ""]]}, {"id": "1804.08454", "submitter": "Akilesh Badrinaaraayanan", "authors": "Akilesh B, Abhishek Sinha, Mausoom Sarkar, Balaji Krishnamurthy", "title": "Attention Based Natural Language Grounding by Navigating Virtual\n  Environment", "comments": "Accepted at WACV 2019. Also at NeurIPS 2017 workshop on\n  Visually-Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of grounding language by training an\nagent to follow a set of natural language instructions and navigate to a target\nobject in an environment. The agent receives visual information through raw\npixels and a natural language instruction telling what task needs to be\nachieved and is trained in an end-to-end way. We develop an attention mechanism\nfor multi-modal fusion of visual and textual modalities that allows the agent\nto learn to complete the task and achieve language grounding. Our experimental\nresults show that our attention mechanism outperforms the existing multi-modal\nfusion mechanisms proposed for both 2D and 3D environments in order to solve\nthe above-mentioned task in terms of both speed and success rate. We show that\nthe learnt textual representations are semantically meaningful as they follow\nvector arithmetic in the embedding space. The effectiveness of our attention\napproach over the contemporary fusion mechanisms is also highlighted from the\ntextual embeddings learnt by the different approaches. We also show that our\nmodel generalizes effectively to unseen scenarios and exhibit zero-shot\ngeneralization capabilities both in 2D and 3D environments. The code for our 2D\nenvironment as well as the models that we developed for both 2D and 3D are\navailable at https://github.com/rl-lang-grounding/rl-lang-ground.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:11:17 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 19:00:54 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["B", "Akilesh", ""], ["Sinha", "Abhishek", ""], ["Sarkar", "Mausoom", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1804.08497", "submitter": "Rana Hanocka", "authors": "Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman\n  and Daniel Cohen-Or", "title": "ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning", "comments": "To be presented at SIGGRAPH Asia 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of aligning a pair of shapes is a fundamental operation in\ncomputer graphics. Traditional approaches rely heavily on matching\ncorresponding points or features to guide the alignment, a paradigm that\nfalters when significant shape portions are missing. These techniques generally\ndo not incorporate prior knowledge about expected shape characteristics, which\ncan help compensate for any misleading cues left by inaccuracies exhibited in\nthe input shapes. We present an approach based on a deep neural network,\nleveraging shape datasets to learn a shape-aware prior for source-to-target\nalignment that is robust to shape incompleteness. In the absence of ground\ntruth alignments for supervision, we train a network on the task of shape\nalignment using incomplete shapes generated from full shapes for\nself-supervision. Our network, called ALIGNet, is trained to warp complete\nsource shapes to incomplete targets, as if the target shapes were complete,\nthus essentially rendering the alignment partial-shape agnostic. We aim for the\nnetwork to develop specialized expertise over the common characteristics of the\nshapes in each dataset, thereby achieving a higher-level understanding of the\nexpected shape space to which a local approach would be oblivious. We constrain\nALIGNet through an anisotropic total variation identity regularization to\npromote piecewise smooth deformation fields, facilitating both partial-shape\nagnosticism and post-deformation applications. We demonstrate that ALIGNet\nlearns to align geometrically distinct shapes, and is able to infer plausible\nmappings even when the target shape is significantly incomplete. We show that\nour network learns the common expected characteristics of shape collections,\nwithout over-fitting or memorization, enabling it to produce plausible\ndeformations on unseen data during test time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 15:17:26 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:26:39 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Hanocka", "Rana", ""], ["Fish", "Noa", ""], ["Wang", "Zhenhua", ""], ["Giryes", "Raja", ""], ["Fleishman", "Shachar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1804.08501", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Dropping Networks for Transfer Learning", "comments": "9 pages, 3 figures Updated because the original table of results was\n  in the wrong order", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many tasks in natural language understanding require learning relationships\nbetween two sequences for various tasks such as natural language inference,\nparaphrasing and entailment. These aforementioned tasks are similar in nature,\nyet they are often modeled individually. Knowledge transfer can be effective\nfor closely related tasks. However, transferring all knowledge, some of which\nirrelevant for a target task, can lead to sub-optimal results due to\n\\textit{negative} transfer. Hence, this paper focuses on the transferability of\nboth instances and parameters across natural language understanding tasks by\nproposing an ensemble-based transfer learning method. \\newline The primary\ncontribution of this paper is the combination of both \\textit{Dropout} and\n\\textit{Bagging} for improved transferability in neural networks, referred to\nas \\textit{Dropping} herein. We present a straightforward yet novel approach\nfor incorporating source \\textit{Dropping} Networks to a target task for\nfew-shot learning that mitigates \\textit{negative} transfer. This is achieved\nby using a decaying parameter chosen according to the slope changes of a\nsmoothed spline error curve at sub-intervals during training. We compare the\nproposed approach against hard parameter sharing and soft parameter sharing\ntransfer methods in the few-shot learning case. We also compare against models\nthat are fully trained on the target task in the standard supervised learning\nsetup. The aforementioned adjustment leads to improved transfer learning\nperformance and comparable results to the current state of the art only using a\nfraction of the data from the target task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 15:22:26 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 21:11:31 GMT"}, {"version": "v3", "created": "Sun, 16 Sep 2018 14:42:40 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1804.08529", "submitter": "Vishaal Munusamy Kabilan", "authors": "Vishaal Munusamy Kabilan, Brandon Morris, Anh Nguyen", "title": "VectorDefense: Vectorization as a Defense to Adversarial Examples", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training deep neural networks on images represented as grids of pixels has\nbrought to light an interesting phenomenon known as adversarial examples.\nInspired by how humans reconstruct abstract concepts, we attempt to codify the\ninput bitmap image into a set of compact, interpretable elements to avoid being\nfooled by the adversarial structures. We take the first step in this direction\nby experimenting with image vectorization as an input transformation step to\nmap the adversarial examples back into the natural manifold of MNIST\nhandwritten digits. We compare our method vs. state-of-the-art input\ntransformations and further discuss the trade-offs between a hand-designed and\na learned transformation defense.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:04:55 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kabilan", "Vishaal Munusamy", ""], ["Morris", "Brandon", ""], ["Nguyen", "Anh", ""]]}, {"id": "1804.08562", "submitter": "Edouard Delasalles", "authors": "Ali Ziat, Edouard Delasalles, Ludovic Denoyer, Patrick Gallinari", "title": "Spatio-Temporal Neural Networks for Space-Time Series Forecasting and\n  Relations Discovery", "comments": "accepted by: ICDM 2018 - IEEE International Conference on Data Mining\n  series (ICDM)", "journal-ref": "2017 IEEE International Conference on Data Mining (ICDM), New\n  Orleans, LA, 2017, pp. 705-714", "doi": "10.1109/ICDM.2017.80", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dynamical spatio-temporal model formalized as a recurrent\nneural network for forecasting time series of spatial processes, i.e. series of\nobservations sharing temporal and spatial dependencies. The model learns these\ndependencies through a structured latent dynamical component, while a decoder\npredicts the observations from the latent representations. We consider several\nvariants of this model, corresponding to different prior hypothesis about the\nspatial relations between the series. The model is evaluated and compared to\nstate-of-the-art baselines, on a variety of forecasting problems representative\nof different application areas: epidemiology, geo-spatial statistics and\ncar-traffic prediction. Besides these evaluations, we also describe experiments\nshowing the ability of this approach to extract relevant spatial relations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:56:25 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Ziat", "Ali", ""], ["Delasalles", "Edouard", ""], ["Denoyer", "Ludovic", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1804.08597", "submitter": "Artur Garcez", "authors": "Artur d'Avila Garcez and Aimore Resende Riquetti Dutra and Eduardo\n  Alonso", "title": "Towards Symbolic Reinforcement Learning with Common Sense", "comments": "15 pages, 13 figures, 26 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (deep RL) has made several breakthroughs in\nrecent years in applications ranging from complex control tasks in unmanned\nvehicles to game playing. Despite their success, deep RL still lacks several\nimportant capacities of human intelligence, such as transfer learning,\nabstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)\nseeks to incorporate such capacities to deep Q-networks (DQN) by learning a\nrelevant symbolic representation prior to using Q-learning. In this paper, we\npropose a novel extension of DSRL, which we call Symbolic Reinforcement\nLearning with Common Sense (SRL+CS), offering a better balance between\ngeneralization and specialization, inspired by principles of common sense when\nassigning rewards and aggregating Q-values. Experiments reported in this paper\nshow that SRL+CS learns consistently faster than Q-learning and DSRL, achieving\nalso a higher accuracy. In the hardest case, where agents were trained in a\ndeterministic environment and tested in a random environment, SRL+CS achieves\nnearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To\nthe best of our knowledge, this is the first case of near perfect zero-shot\ntransfer learning using Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:44:29 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Garcez", "Artur d'Avila", ""], ["Dutra", "Aimore Resende Riquetti", ""], ["Alonso", "Eduardo", ""]]}, {"id": "1804.08603", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi and Aravindan Vijayaraghavan", "title": "Towards Learning Sparsely Used Dictionaries with Arbitrary Supports", "comments": "72 pages, fixed minor typos, and added a new reference in related\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is a popular approach for inferring a hidden basis or\ndictionary in which data has a sparse representation. Data generated from the\ndictionary A (an n by m matrix, with m > n in the over-complete setting) is\ngiven by Y = AX where X is a matrix whose columns have supports chosen from a\ndistribution over k-sparse vectors, and the non-zero values chosen from a\nsymmetric distribution. Given Y, the goal is to recover A and X in polynomial\ntime. Existing algorithms give polytime guarantees for recovering incoherent\ndictionaries, under strong distributional assumptions both on the supports of\nthe columns of X, and on the values of the non-zero entries. In this work, we\nstudy the following question: Can we design efficient algorithms for recovering\ndictionaries when the supports of the columns of X are arbitrary?\n  To address this question while circumventing the issue of\nnon-identifiability, we study a natural semirandom model for dictionary\nlearning where there are a large number of samples $y=Ax$ with arbitrary\nk-sparse supports for x, along with a few samples where the sparse supports are\nchosen uniformly at random. While the few samples with random supports ensures\nidentifiability, the support distribution can look almost arbitrary in\naggregate. Hence existing algorithmic techniques seem to break down as they\nmake strong assumptions on the supports.\n  Our main contribution is a new polynomial time algorithm for learning\nincoherent over-complete dictionaries that works under the semirandom model.\nAdditionally the same algorithm provides polynomial time guarantees in new\nparameter regimes when the supports are fully random. Finally using these\ntechniques, we also identify a minimal set of conditions on the supports under\nwhich the dictionary can be (information theoretically) recovered from\npolynomial samples for almost linear sparsity, i.e., $k=\\tilde{O}(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:57:33 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 15:27:40 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1804.08606", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian\n  Chen, Yide Shentu, Evan Shelhamer, Jitendra Malik, Alexei A. Efros, Trevor\n  Darrell", "title": "Zero-Shot Visual Imitation", "comments": "Oral presentation at ICLR 2018. Website at\n  https://pathak22.github.io/zeroshot-imitation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant paradigm for imitation learning relies on strong\nsupervision of expert actions to learn both 'what' and 'how' to imitate. We\npursue an alternative paradigm wherein an agent first explores the world\nwithout any expert supervision and then distills its experience into a\ngoal-conditioned skill policy with a novel forward consistency loss. In our\nframework, the role of the expert is only to communicate the goals (i.e., what\nto imitate) during inference. The learned policy is then employed to mimic the\nexpert (i.e., how to imitate) after seeing just a sequence of images\ndemonstrating the desired task. Our method is 'zero-shot' in the sense that the\nagent never has access to expert actions during training or for the task\ndemonstration at inference. We evaluate our zero-shot imitator in two\nreal-world settings: complex rope manipulation with a Baxter robot and\nnavigation in previously unseen office environments with a TurtleBot. Through\nfurther experiments in VizDoom simulation, we provide evidence that better\nmechanisms for exploration lead to learning a more capable policy which in turn\nimproves end task performance. Videos, models, and more details are available\nat https://pathak22.github.io/zeroshot-imitation/\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:26 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Pathak", "Deepak", ""], ["Mahmoudieh", "Parsa", ""], ["Luo", "Guanghao", ""], ["Agrawal", "Pulkit", ""], ["Chen", "Dian", ""], ["Shentu", "Yide", ""], ["Shelhamer", "Evan", ""], ["Malik", "Jitendra", ""], ["Efros", "Alexei A.", ""], ["Darrell", "Trevor", ""]]}, {"id": "1804.08607", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Adi Makmal, Hans J. Briegel", "title": "Benchmarking projective simulation in navigation problems", "comments": "8 pages, 10 figures", "journal-ref": "IEEE Access 6, 64639 (2018)", "doi": "10.1109/ACCESS.2018.2876494", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projective simulation (PS) is a model for intelligent agents with a\ndeliberation capacity that is based on episodic memory. The model has been\nshown to provide a flexible framework for constructing reinforcement-learning\nagents, and it allows for quantum mechanical generalization, which leads to a\nspeed-up in deliberation time. PS agents have been applied successfully in the\ncontext of complex skill learning in robotics, and in the design of\nstate-of-the-art quantum experiments. In this paper, we study the performance\nof projective simulation in two benchmarking problems in navigation, namely the\ngrid world and the mountain car problem. The performance of PS is compared to\nstandard tabular reinforcement learning approaches, Q-learning and SARSA. Our\ncomparison demonstrates that the performance of PS and standard learning\napproaches are qualitatively and quantitatively similar, while it is much\neasier to choose optimal model parameters in case of projective simulation,\nwith a reduced computational effort of one to two orders of magnitude. Our\nresults show that the projective simulation model stands out for its simplicity\nin terms of the number of model parameters, which makes it simple to set up the\nlearning agent in unknown task environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:27 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Makmal", "Adi", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1804.08613", "submitter": "Yinghua Zhang", "authors": "Yinghua Zhang, Yu Zhang and Qiang Yang", "title": "Parameter Transfer Unit for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameters in deep neural networks which are trained on large-scale databases\ncan generalize across multiple domains, which is referred as \"transferability\".\nUnfortunately, the transferability is usually defined as discrete states and it\ndiffers with domains and network architectures. Existing works usually\nheuristically apply parameter-sharing or fine-tuning, and there is no\nprincipled approach to learn a parameter transfer strategy. To address the gap,\na parameter transfer unit (PTU) is proposed in this paper. The PTU learns a\nfine-grained nonlinear combination of activations from both the source and the\ntarget domain networks, and subsumes hand-crafted discrete transfer states. In\nthe PTU, the transferability is controlled by two gates which are artificial\nneurons and can be learned from data. The PTU is a general and flexible module\nwhich can be used in both CNNs and RNNs. Experiments are conducted with various\nnetwork architectures and multiple transfer domain pairs. Results demonstrate\nthe effectiveness of the PTU as it outperforms heuristic parameter-sharing and\nfine-tuning in most settings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 07:25:32 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Zhang", "Yinghua", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.08615", "submitter": "Qing-Yong Wang", "authors": "Liang-Yong Xia, Qing-Yong Wang", "title": "QSAR Classification Modeling for Bioactivity of Molecular Structure via\n  SPL-Logsum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative structure-activity relationship (QSAR) modelling is effective\n'bridge' to search the reliable relationship related bioactivity to molecular\nstructure. A QSAR classification model contains a lager number of redundant,\nnoisy and irrelevant descriptors. To address this problem, various of methods\nhave been proposed for descriptor selection. Generally, they can be grouped\ninto three categories: filters, wrappers, and embedded methods. Regularization\nmethod is an important embedded technology, which can be used for continuous\nshrinkage and automatic descriptors selection. In recent years, the interest of\nresearchers in the application of regularization techniques is increasing in\ndescriptors selection , such as, logistic regression(LR) with $L_1$ penalty. In\nthis paper, we proposed a novel descriptor selection method based on self-paced\nlearning(SPL) with Logsum penalized LR for predicting the bioactivity of\nmolecular structure. SPL inspired by the learning process of humans and animals\nthat gradually learns from easy samples(smaller losses) to hard samples(bigger\nlosses) samples into training and Logsum regularization has capacity to select\nfew meaningful and significant molecular descriptors, respectively.\nExperimental results on simulation and three public QSAR datasets show that our\nproposed SPL-Logsum method outperforms other commonly used sparse methods in\nterms of classification performance and model interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:46:27 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 04:00:01 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Xia", "Liang-Yong", ""], ["Wang", "Qing-Yong", ""]]}, {"id": "1804.08617", "submitter": "Matthew W. Hoffman", "authors": "Gabriel Barth-Maron, Matthew W. Hoffman, David Budden, Will Dabney,\n  Dan Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, Timothy Lillicrap", "title": "Distributed Distributional Deterministic Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adopts the very successful distributional perspective on\nreinforcement learning and adapts it to the continuous control setting. We\ncombine this within a distributed framework for off-policy learning in order to\ndevelop what we call the Distributed Distributional Deep Deterministic Policy\nGradient algorithm, D4PG. We also combine this technique with a number of\nadditional, simple improvements such as the use of $N$-step returns and\nprioritized experience replay. Experimentally we examine the contribution of\neach of these individual components, and show how they interact, as well as\ntheir combined contributions. Our results show that across a wide variety of\nsimple control tasks, difficult manipulation tasks, and a set of hard\nobstacle-based locomotion tasks the D4PG algorithm achieves state of the art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:57:21 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Barth-Maron", "Gabriel", ""], ["Hoffman", "Matthew W.", ""], ["Budden", "David", ""], ["Dabney", "Will", ""], ["Horgan", "Dan", ""], ["TB", "Dhruva", ""], ["Muldal", "Alistair", ""], ["Heess", "Nicolas", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.08619", "submitter": "Weichao Li", "authors": "Weichao Li, Fuxian Huang, Xi Li, Gang Pan and Fei Wu", "title": "State Distribution-aware Sampling for Deep Q-learning", "comments": "this paper has been submitted to neural processing letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical and challenging problem in reinforcement learning is how to learn\nthe state-action value function from the experience replay buffer and\nsimultaneously keep sample efficiency and faster convergence to a high quality\nsolution. In prior works, transitions are uniformly sampled at random from the\nreplay buffer or sampled based on their priority measured by\ntemporal-difference (TD) error. However, these approaches do not fully take\ninto consideration the intrinsic characteristics of transition distribution in\nthe state space and could result in redundant and unnecessary TD updates,\nslowing down the convergence of the learning procedure. To overcome this\nproblem, we propose a novel state distribution-aware sampling method to balance\nthe replay times for transitions with skew distribution, which takes into\naccount both the occurrence frequencies of transitions and the uncertainty of\nstate-action values. Consequently, our approach could reduce the unnecessary TD\nupdates and increase the TD updates for state-action value with more\nuncertainty, making the experience replay more effective and efficient.\nExtensive experiments are conducted on both classic control tasks and Atari\n2600 games based on OpenAI gym platform and the experimental results\ndemonstrate the effectiveness of our approach in comparison with the standard\nDQN approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:22:22 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Weichao", ""], ["Huang", "Fuxian", ""], ["Li", "Xi", ""], ["Pan", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1804.08641", "submitter": "Pierre-Luc Dallaire-Demers", "authors": "Pierre-Luc Dallaire-Demers and Nathan Killoran", "title": "Quantum generative adversarial networks", "comments": "10 pages, 8 figures", "journal-ref": "Phys. Rev. A 98, 012324 (2018)", "doi": "10.1103/PhysRevA.98.012324", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning is expected to be one of the first potential\ngeneral-purpose applications of near-term quantum devices. A major recent\nbreakthrough in classical machine learning is the notion of generative\nadversarial training, where the gradients of a discriminator model are used to\ntrain a separate generative model. In this work and a companion paper, we\nextend adversarial training to the quantum domain and show how to construct\ngenerative adversarial networks using quantum circuits. Furthermore, we also\nshow how to compute gradients -- a key element in generative adversarial\nnetwork training -- using another quantum circuit. We give an example of a\nsimple practical circuit ansatz to parametrize quantum machine learning models\nand perform a simple numerical experiment to demonstrate that quantum\ngenerative adversarial networks can be trained successfully.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:02:03 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 22:22:53 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Dallaire-Demers", "Pierre-Luc", ""], ["Killoran", "Nathan", ""]]}, {"id": "1804.08646", "submitter": "Beau Coker", "authors": "Beau Coker, Cynthia Rudin, Gary King", "title": "A Theory of Statistical Inference for Ensuring the Robustness of\n  Scientific Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference is the process of using facts we know to learn about facts we do\nnot know. A theory of inference gives assumptions necessary to get from the\nformer to the latter, along with a definition for and summary of the resulting\nuncertainty. Any one theory of inference is neither right nor wrong, but merely\nan axiom that may or may not be useful. Each of the many diverse theories of\ninference can be valuable for certain applications. However, no existing theory\nof inference addresses the tendency to choose, from the range of plausible data\nanalysis specifications consistent with prior evidence, those that\ninadvertently favor one's own hypotheses. Since the biases from these choices\nare a growing concern across scientific fields, and in a sense the reason the\nscientific community was invented in the first place, we introduce a new theory\nof inference designed to address this critical problem. We introduce hacking\nintervals, which are the range of a summary statistic one may obtain given a\nclass of possible endogenous manipulations of the data. Hacking intervals\nrequire no appeal to hypothetical data sets drawn from imaginary\nsuperpopulations. A scientific result with a small hacking interval is more\nrobust to researcher manipulation than one with a larger interval, and is often\neasier to interpret than a classical confidence interval. Some versions of\nhacking intervals turn out to be equivalent to classical confidence intervals,\nwhich means they may also provide a more intuitive and potentially more useful\ninterpretation of classical confidence intervals.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:13:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 02:28:23 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Coker", "Beau", ""], ["Rudin", "Cynthia", ""], ["King", "Gary", ""]]}, {"id": "1804.08682", "submitter": "Charles Fisher", "authors": "Charles K. Fisher, Aaron M. Smith, Jonathan R. Walsh", "title": "Boltzmann Encoded Adversarial Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines (RBMs) are a class of generative neural network\nthat are typically trained to maximize a log-likelihood objective function. We\nargue that likelihood-based training strategies may fail because the objective\ndoes not sufficiently penalize models that place a high probability in regions\nwhere the training data distribution has low probability. To overcome this\nproblem, we introduce Boltzmann Encoded Adversarial Machines (BEAMs). A BEAM is\nan RBM trained against an adversary that uses the hidden layer activations of\nthe RBM to discriminate between the training data and the probability\ndistribution generated by the model. We present experiments demonstrating that\nBEAMs outperform RBMs and GANs on multiple benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:50:13 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Fisher", "Charles K.", ""], ["Smith", "Aaron M.", ""], ["Walsh", "Jonathan R.", ""]]}, {"id": "1804.08685", "submitter": "Daniele Cortesi", "authors": "Andrea Asperti, Daniele Cortesi, Francesco Sovrano", "title": "Crawling in Rogue's dungeons with (partitioned) A3C", "comments": "Accepted at the Fourth International Conference on Machine Learning,\n  Optimization, and Data Science (LOD 2018)", "journal-ref": null, "doi": "10.1007/978-3-030-13709-0_22", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rogue is a famous dungeon-crawling video-game of the 80ies, the ancestor of\nits gender. Rogue-like games are known for the necessity to explore partially\nobservable and always different randomly-generated labyrinths, preventing any\nform of level replay. As such, they serve as a very natural and challenging\ntask for reinforcement learning, requiring the acquisition of complex,\nnon-reactive behaviors involving memory and planning. In this article we show\nhow, exploiting a version of A3C partitioned on different situations, the agent\nis able to reach the stairs and descend to the next level in 98% of cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:59:51 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 08:39:04 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 15:38:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Asperti", "Andrea", ""], ["Cortesi", "Daniele", ""], ["Sovrano", "Francesco", ""]]}, {"id": "1804.08711", "submitter": "Aydogan Ozcan", "authors": "Xing Lin, Yair Rivenson, Nezih T. Yardimci, Muhammed Veli, Mona\n  Jarrahi and Aydogan Ozcan", "title": "All-Optical Machine Learning Using Diffractive Deep Neural Networks", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": "10.1126/science.aat8084", "report-no": null, "categories": "cs.NE cs.LG physics.comp-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an all-optical Diffractive Deep Neural Network (D2NN)\narchitecture that can learn to implement various functions after deep\nlearning-based design of passive diffractive layers that work collectively. We\nexperimentally demonstrated the success of this framework by creating\n3D-printed D2NNs that learned to implement handwritten digit classification and\nthe function of an imaging lens at terahertz spectrum. With the existing\nplethora of 3D-printing and other lithographic fabrication methods as well as\nspatial-light-modulators, this all-optical deep learning framework can perform,\nat the speed of light, various complex functions that computer-based neural\nnetworks can implement, and will find applications in all-optical image\nanalysis, feature detection and object classification, also enabling new camera\ndesigns and optical components that can learn to perform unique tasks using\nD2NNs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 05:27:34 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 06:44:08 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lin", "Xing", ""], ["Rivenson", "Yair", ""], ["Yardimci", "Nezih T.", ""], ["Veli", "Muhammed", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1804.08750", "submitter": "Aditya Chindhade", "authors": "Aditya Chindhade, Abhijeet Alshi, Aakash Bhatia, Kedar Dabhadkar,\n  Pranav Sivadas Menon", "title": "A machine learning model for identifying cyclic alternating patterns in\n  the sleeping brain", "comments": "Presented at HackAuton, Auton Lab, Carnegie Mellon University.\n  Problem credits: Philips", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is a method to record the electrical signals in\nthe brain. Recognizing the EEG patterns in the sleeping brain gives insights\ninto the understanding of sleeping disorders. The dataset under consideration\ncontains EEG data points associated with various physiological conditions. This\nstudy attempts to generalize the detection of particular patterns associated\nwith the Non-Rapid Eye Movement (NREM) sleep cycle of the brain using a machine\nlearning model. The proposed model uses additional feature engineering to\nincorporate sequential information for training a classifier to predict the\noccurrence of Cyclic Alternating Pattern (CAP) sequences in the sleep cycle,\nwhich are often associated with sleep disorders.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:29:56 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Chindhade", "Aditya", ""], ["Alshi", "Abhijeet", ""], ["Bhatia", "Aakash", ""], ["Dabhadkar", "Kedar", ""], ["Menon", "Pranav Sivadas", ""]]}, {"id": "1804.08774", "submitter": "Vachik Dave", "authors": "Vachik S. Dave, Baichuan Zhang, Pin-Yu Chen and Mohammad Al Hasan", "title": "Neural-Brane: Neural Bayesian Personalized Ranking for Attributed\n  Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding methodologies, which learn a distributed vector\nrepresentation for each vertex in a network, have attracted considerable\ninterest in recent years. Existing works have demonstrated that vertex\nrepresentation learned through an embedding method provides superior\nperformance in many real-world applications, such as node classification, link\nprediction, and community detection. However, most of the existing methods for\nnetwork embedding only utilize topological information of a vertex, ignoring a\nrich set of nodal attributes (such as, user profiles of an online social\nnetwork, or textual contents of a citation network), which is abundant in all\nreal-life networks. A joint network embedding that takes into account both\nattributional and relational information entails a complete network information\nand could further enrich the learned vector representations. In this work, we\npresent Neural-Brane, a novel Neural Bayesian Personalized Ranking based\nAttributed Network Embedding. For a given network, Neural-Brane extracts latent\nfeature representation of its vertices using a designed neural network model\nthat unifies network topological information and nodal attributes; Besides, it\nutilizes Bayesian personalized ranking objective, which exploits the proximity\nordering between a similar node-pair and a dissimilar node-pair. We evaluate\nthe quality of vertex embedding produced by Neural-Brane by solving the node\nclassification and clustering tasks on four real-world datasets. Experimental\nresults demonstrate the superiority of our proposed method over the\nstate-of-the-art existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 23:01:50 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 22:52:03 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Dave", "Vachik S.", ""], ["Zhang", "Baichuan", ""], ["Chen", "Pin-Yu", ""], ["Hasan", "Mohammad Al", ""]]}, {"id": "1804.08778", "submitter": "Ishai Rosenberg", "authors": "Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, and Lior Rokach", "title": "Query-Efficient Black-Box Attack Against Sequence-Based Malware\n  Classifiers", "comments": "Accepted as a conference paper at ACSAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a generic, query-efficient black-box attack against\nAPI call-based machine learning malware classifiers. We generate adversarial\nexamples by modifying the malware's API call sequences and non-sequential\nfeatures (printable strings), and these adversarial examples will be\nmisclassified by the target malware classifier without affecting the malware's\nfunctionality. In contrast to previous studies, our attack minimizes the number\nof malware classifier queries required. In addition, in our attack, the\nattacker must only know the class predicted by the malware classifier; attacker\nknowledge of the malware classifier's confidence score is optional. We evaluate\nthe attack effectiveness when attacks are performed against a variety of\nmalware classifier architectures, including recurrent neural network (RNN)\nvariants, deep neural networks, support vector machines, and gradient boosted\ndecision trees. Our attack success rate is around 98% when the classifier's\nconfidence score is known and 64% when just the classifier's predicted class is\nknown. We implement four state-of-the-art query-efficient attacks and show that\nour attack requires fewer queries and less knowledge about the attacked model's\narchitecture than other existing query-efficient attacks, making it practical\nfor attacking cloud-based malware classifiers at a minimal cost.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 23:31:09 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 11:29:11 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 18:25:48 GMT"}, {"version": "v4", "created": "Fri, 23 Nov 2018 09:59:04 GMT"}, {"version": "v5", "created": "Mon, 29 Apr 2019 23:21:25 GMT"}, {"version": "v6", "created": "Sat, 24 Aug 2019 00:43:18 GMT"}, {"version": "v7", "created": "Sat, 3 Oct 2020 10:19:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Rosenberg", "Ishai", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""], ["Rokach", "Lior", ""]]}, {"id": "1804.08794", "submitter": "Arezoo Rajabi", "authors": "Mahdieh Abbasi, Arezoo Rajabi, Christian Gagn\\'e and Rakesh B. Bobba", "title": "Towards Dependable Deep Convolutional Neural Networks (CNNs) with\n  Out-distribution Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection and rejection of adversarial examples in security sensitive and\nsafety-critical systems using deep CNNs is essential. In this paper, we propose\nan approach to augment CNNs with out-distribution learning in order to reduce\nmisclassification rate by rejecting adversarial examples. We empirically show\nthat our augmented CNNs can either reject or classify correctly most\nadversarial examples generated using well-known methods ( >95% for MNIST and\n>75% for CIFAR-10 on average). Furthermore, we achieve this without requiring\nto train using any specific type of adversarial examples and without\nsacrificing the accuracy of models on clean samples significantly (< 4%).\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 00:54:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 06:58:28 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Rajabi", "Arezoo", ""], ["Gagn\u00e9", "Christian", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "1804.08796", "submitter": "Theja Tulabandhula", "authors": "Mehrnaz Amjadi and Theja Tulabandhula", "title": "Block-Structure Based Time-Series Models For Graph Sequences", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the computational and statistical trade-off for modeling single\ngraphs, for instance, using block models is relatively well understood,\nextending such results to sequences of graphs has proven to be difficult. In\nthis work, we take a step in this direction by proposing two models for graph\nsequences that capture: (a) link persistence between nodes across time, and (b)\ncommunity persistence of each node across time. In the first model, we assume\nthat the latent community of each node does not change over time, and in the\nsecond model we relax this assumption suitably. For both of these proposed\nmodels, we provide statistically and computationally efficient inference\nalgorithms, whose unique feature is that they leverage community detection\nmethods that work on single graphs. We also provide experimental results\nvalidating the suitability of our models and methods on synthetic and real\ninstances.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:14:16 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 16:34:31 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Amjadi", "Mehrnaz", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1804.08806", "submitter": "Charilaos Kanatsoulis", "authors": "Charilaos I. Kanatsoulis, Xiao Fu, Nicholas D. Sidiropoulos, Mingyi\n  Hong", "title": "Structured SUMCOR Multiview Canonical Correlation Analysis for\n  Large-Scale Data", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2878544", "report-no": null, "categories": "cs.LG cs.IR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sum-of-correlations (SUMCOR) formulation of generalized canonical\ncorrelation analysis (GCCA) seeks highly correlated low-dimensional\nrepresentations of different views via maximizing pairwise latent similarity of\nthe views. SUMCOR is considered arguably the most natural extension of\nclassical two-view CCA to the multiview case, and thus has numerous\napplications in signal processing and data analytics. Recent work has proposed\neffective algorithms for handling the SUMCOR problem at very large scale.\nHowever, the existing scalable algorithms cannot incorporate structural\nregularization and prior information -- which are critical for good performance\nin real-world applications. In this work, we propose a new computational\nframework for large-scale SUMCOR GCCA that can easily incorporate a suite of\nstructural regularizers which are frequently used in data analytics. The\nupdates of the proposed algorithm are lightweight and the memory complexity is\nalso low. In addition, the proposed algorithm can be readily implemented in a\nparallel fashion. We show that the proposed algorithm converges to a\nKarush-Kuhn-Tucker (KKT) point of the regularized SUMCOR problem. Judiciously\ndesigned simulations and real-data experiments are employed to demonstrate the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:47:55 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Kanatsoulis", "Charilaos I.", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Hong", "Mingyi", ""]]}, {"id": "1804.08833", "submitter": "Suchismit Mahapatra", "authors": "Suchismit Mahapatra, Varun Chandola", "title": "Learning Manifolds from Non-stationary Streaming Data", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming adaptations of manifold learning based dimensionality reduction\nmethods, such as Isomap, are based on the assumption that a small initial batch\nof observations is enough for exact learning of the manifold, while remaining\nstreaming data instances can be cheaply mapped to this manifold. However, there\nare no theoretical results to show that this core assumption is valid.\nMoreover, such methods typically assume that the underlying data distribution\nis stationary. Such methods are not equipped to detect, or handle, sudden\nchanges or gradual drifts in the distribution that may occur when the data is\nstreaming. We present theoretical results to show that the quality of a\nmanifold asymptotically converges as the size of data increases. We then show\nthat a Gaussian Process Regression (GPR) model, that uses a manifold-specific\nkernel function and is trained on an initial batch of sufficient size, can\nclosely approximate the state-of-art streaming Isomap algorithms. The\npredictive variance obtained from the GPR prediction is then shown to be an\neffective detector of changes in the underlying data distribution. Results on\nseveral synthetic and real data sets show that the resulting algorithm can\neffectively learn lower dimensional representation of high dimensional data in\na streaming setting, while identifying shifts in the generative distribution.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 03:59:48 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 22:25:12 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 19:38:30 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Mahapatra", "Suchismit", ""], ["Chandola", "Varun", ""]]}, {"id": "1804.08838", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Heerad Farkhoor, Rosanne Liu, Jason Yosinski", "title": "Measuring the Intrinsic Dimension of Objective Landscapes", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recently trained neural networks employ large numbers of parameters to\nachieve good performance. One may intuitively use the number of parameters\nrequired as a rough gauge of the difficulty of a problem. But how accurate are\nsuch notions? How many parameters are really needed? In this paper we attempt\nto answer this question by training networks not in their native parameter\nspace, but instead in a smaller, randomly oriented subspace. We slowly increase\nthe dimension of this subspace, note at which dimension solutions first appear,\nand define this to be the intrinsic dimension of the objective landscape. The\napproach is simple to implement, computationally tractable, and produces\nseveral suggestive conclusions. Many problems have smaller intrinsic dimensions\nthan one might suspect, and the intrinsic dimension for a given dataset varies\nlittle across a family of models with vastly different sizes. This latter\nresult has the profound implication that once a parameter space is large enough\nto solve a problem, extra parameters serve directly to increase the\ndimensionality of the solution manifold. Intrinsic dimension allows some\nquantitative comparison of problem difficulty across supervised, reinforcement,\nand other types of learning where we conclude, for example, that solving the\ninverted pendulum problem is 100 times easier than classifying digits from\nMNIST, and playing Atari Pong from pixels is about as hard as classifying\nCIFAR-10. In addition to providing new cartography of the objective landscapes\nwandered by parameterized models, the method is a simple technique for\nconstructively obtaining an upper bound on the minimum description length of a\nsolution. A byproduct of this construction is a simple approach for compressing\nnetworks, in some cases by more than 100 times.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 04:29:10 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Chunyuan", ""], ["Farkhoor", "Heerad", ""], ["Liu", "Rosanne", ""], ["Yosinski", "Jason", ""]]}, {"id": "1804.08902", "submitter": "Ran Ben Basat", "authors": "Ran Ben Basat, Maayan Goldstein, Itai Segall", "title": "Learning Software Constraints via Installation Attempts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems are expected to be secure and contain all the latest\nfeatures, even when new versions of software are released multiple times an\nhour. Each system may include many interacting packages. The problem of\ninstalling multiple dependent packages has been extensively studied in the\npast, yielding some promising solutions that work well in practice. However,\nthese assume that the developers declare all the dependencies and conflicts\nbetween the packages. Oftentimes, the entire repository structure may not be\nknown upfront, for example when packages are developed by different vendors. In\nthis paper, we present algorithms for learning dependencies, conflicts and\ndefective packages from installation attempts. Our algorithms use combinatorial\ndata structures to generate queries that test installations and discover the\nentire dependency structure. A query that the algorithms make corresponds to\ntrying to install a subset of packages and getting a Boolean feedback on\nwhether all constraints were satisfied in this subset. Our goal is to minimize\nthe query complexity of the algorithms. We prove lower and upper bounds on the\nnumber of queries that these algorithms require to make for different settings\nof the problem.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 08:49:00 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 16:13:19 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Basat", "Ran Ben", ""], ["Goldstein", "Maayan", ""], ["Segall", "Itai", ""]]}, {"id": "1804.08951", "submitter": "Peiyuan Liao", "authors": "Peiyuan Liao", "title": "Deep Neural Network Based Subspace Learning of Robotic Manipulator\n  Workspace Mapping", "comments": "12 pages, 12 figures, accepted for presentation at ICCAIRO 2018", "journal-ref": null, "doi": "10.1109/ICCAIRO.2018.00027", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The manipulator workspace mapping is an important problem in robotics and has\nattracted significant attention in the community. However, most of the\npre-existing algorithms have expensive time complexity due to the reliance on\nsophisticated kinematic equations. To solve this problem, this paper introduces\nsubspace learning (SL), a variant of subspace embedding, where a set of robot\nand scope parameters is mapped to the corresponding workspace by a deep neural\nnetwork (DNN). Trained on a large dataset of around $\\mathbf{6\\times 10^4}$\nsamples obtained from a MATLAB$^\\circledR$ implementation of a classical method\nand sampling of designed uniform distributions, the experiments demonstrate\nthat the embedding significantly reduces run-time from $\\mathbf{5.23 \\times\n10^3}$ s of traditional discretization method to $\\mathbf{0.224}$ s, with high\naccuracies (average F-measure is $\\mathbf{0.9665}$ with batch gradient descent\nand resilient backpropagation).\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 10:57:10 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 02:24:17 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liao", "Peiyuan", ""]]}, {"id": "1804.09028", "submitter": "Einat Kermany", "authors": "Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour and\n  Alon Jacovi", "title": "Estimate and Replace: A Novel Approach to Integrating Deep Neural\n  Networks with Existing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing applications include a huge amount of knowledge that is out of reach\nfor deep neural networks. This paper presents a novel approach for integrating\ncalls to existing applications into deep learning architectures. Using this\napproach, we estimate each application's functionality with an estimator, which\nis implemented as a deep neural network (DNN). The estimator is then embedded\ninto a base network that we direct into complying with the application's\ninterface during an end-to-end optimization process. At inference time, we\nreplace each estimator with its existing application counterpart and let the\nbase network solve the task by interacting with the existing application. Using\nthis 'Estimate and Replace' method, we were able to train a DNN end-to-end with\nless data and outperformed a matching DNN that did not interact with the\nexternal application.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:40:09 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hadash", "Guy", ""], ["Kermany", "Einat", ""], ["Carmeli", "Boaz", ""], ["Lavi", "Ofer", ""], ["Kour", "George", ""], ["Jacovi", "Alon", ""]]}, {"id": "1804.09046", "submitter": "Felix M. Riese", "authors": "Sina Keller and Felix M. Riese and Johanna St\\\"otzer and Philipp M.\n  Maier and Stefan Hinz", "title": "Developing a machine learning framework for estimating soil moisture\n  with VNIR hyperspectral data", "comments": "Accepted at ISPRS TC I Midterm Symposium Karlsruhe (October 2018)", "journal-ref": "ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., IV-1,\n  101-108, 2018", "doi": "10.5194/isprs-annals-IV-1-101-2018", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the potential of estimating the soil-moisture\ncontent based on VNIR hyperspectral data combined with LWIR data. Measurements\nfrom a multi-sensor field campaign represent the benchmark dataset which\ncontains measured hyperspectral, LWIR, and soil-moisture data conducted on\ngrassland site. We introduce a regression framework with three steps consisting\nof feature selection, preprocessing, and well-chosen regression models. The\nlatter are mainly supervised machine learning models. An exception are the\nself-organizing maps which combine unsupervised and supervised learning. We\nanalyze the impact of the distinct preprocessing methods on the regression\nresults. Of all regression models, the extremely randomized trees model without\npreprocessing provides the best estimation performance. Our results reveal the\npotential of the respective regression framework combined with the VNIR\nhyperspectral data to estimate soil moisture measured under real-world\nconditions. In conclusion, the results of this paper provide a basis for\nfurther improvements in different research directions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:52:35 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 12:15:49 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 11:14:41 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 10:40:59 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Keller", "Sina", ""], ["Riese", "Felix M.", ""], ["St\u00f6tzer", "Johanna", ""], ["Maier", "Philipp M.", ""], ["Hinz", "Stefan", ""]]}, {"id": "1804.09060", "submitter": "Dacheng Tao", "authors": "Jingwei Zhang, Tongliang Liu, Dacheng Tao", "title": "An Information-Theoretic View for Deep Learning", "comments": "Add details in the proof of Theorem 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has transformed computer vision, natural language processing,\nand speech recognition\\cite{badrinarayanan2017segnet, dong2016image,\nren2017faster, ji20133d}. However, two critical questions remain obscure: (1)\nwhy do deep neural networks generalize better than shallow networks; and (2)\ndoes it always hold that a deeper network leads to better performance?\nSpecifically, letting $L$ be the number of convolutional and pooling layers in\na deep neural network, and $n$ be the size of the training sample, we derive an\nupper bound on the expected generalization error for this network, i.e.,\n  \\begin{eqnarray*}\n  \\mathbb{E}[R(W)-R_S(W)] \\leq\n\\exp{\\left(-\\frac{L}{2}\\log{\\frac{1}{\\eta}}\\right)}\\sqrt{\\frac{2\\sigma^2}{n}I(S,W)\n}\n  \\end{eqnarray*} where $\\sigma >0$ is a constant depending on the loss\nfunction, $0<\\eta<1$ is a constant depending on the information loss for each\nconvolutional or pooling layer, and $I(S, W)$ is the mutual information between\nthe training sample $S$ and the output hypothesis $W$. This upper bound shows\nthat as the number of convolutional and pooling layers $L$ increases in the\nnetwork, the expected generalization error will decrease exponentially to zero.\nLayers with strict information loss, such as the convolutional layers, reduce\nthe generalization error for the whole network; this answers the first\nquestion. However, algorithms with zero expected generalization error does not\nimply a small test error or $\\mathbb{E}[R(W)]$. This is because\n$\\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost\nas the number of layers increases. This suggests that the claim `the deeper the\nbetter' is conditioned on a small training error or $\\mathbb{E}[R_S(W)]$.\nFinally, we show that deep learning satisfies a weak notion of stability and\nthe sample complexity of deep neural networks will decrease as $L$ increases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 14:13:19 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 09:27:38 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 09:40:26 GMT"}, {"version": "v4", "created": "Mon, 28 May 2018 12:58:28 GMT"}, {"version": "v5", "created": "Wed, 30 May 2018 11:57:48 GMT"}, {"version": "v6", "created": "Thu, 31 May 2018 13:04:59 GMT"}, {"version": "v7", "created": "Tue, 5 Jun 2018 01:57:20 GMT"}, {"version": "v8", "created": "Tue, 2 Oct 2018 12:49:32 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Zhang", "Jingwei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1804.09081", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Jan Hendrik Metzen, Frank Hutter", "title": "Efficient Multi-objective Neural Architecture Search via Lamarckian\n  Evolution", "comments": "Published as a conference paper at ICLR, International Conference on\n  Learning Representations, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search aims at automatically finding neural architectures\nthat are competitive with architectures designed by human experts. While recent\napproaches have achieved state-of-the-art predictive performance for image\nrecognition, they are problematic under resource constraints for two reasons:\n(1)the neural architectures found are solely optimized for high predictive\nperformance, without penalizing excessive resource consumption, (2) most\narchitecture search methods require vast computational resources. We address\nthe first shortcoming by proposing LEMONADE, an evolutionary algorithm for\nmulti-objective architecture search that allows approximating the entire\nPareto-front of architectures under multiple objectives, such as predictive\nperformance and number of parameters, in a single run of the method. We address\nthe second shortcoming by proposing a Lamarckian inheritance mechanism for\nLEMONADE which generates children networks that are warmstarted with the\npredictive performance of their trained parents. This is accomplished by using\n(approximate) network morphism operators for generating children. The\ncombination of these two contributions allows finding models that are on par or\neven outperform both hand-crafted as well as automatically-designed networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:01:07 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 14:40:54 GMT"}, {"version": "v3", "created": "Sat, 22 Dec 2018 14:01:47 GMT"}, {"version": "v4", "created": "Tue, 26 Feb 2019 16:06:36 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Elsken", "Thomas", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "1804.09088", "submitter": "Evangelos Papalexakis", "authors": "Gisel Bastidas Guacho, Sara Abdali, Neil Shah, Evangelos E.\n  Papalexakis", "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:13:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Guacho", "Gisel Bastidas", ""], ["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1804.09133", "submitter": "Zhiguang Wang", "authors": "Mehul Parsana, Krishna Poola, Yajun Wang, Zhiguang Wang", "title": "Improving Native Ads CTR Prediction by Large Scale Event Embedding and\n  Recurrent Networks", "comments": "This version has some language error, and the authors all agree to\n  withdraw it at the moment to further edit and update with some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click through rate (CTR) prediction is very important for Native\nadvertisement but also hard as there is no direct query intent. In this paper\nwe propose a large-scale event embedding scheme to encode the each user\nbrowsing event by training a Siamese network with weak supervision on the\nusers' consecutive events. The CTR prediction problem is modeled as a\nsupervised recurrent neural network, which naturally model the user history as\na sequence of events. Our proposed recurrent models utilizing pretrained event\nembedding vectors and an attention layer to model the user history. Our\nexperiments demonstrate that our model significantly outperforms the baseline\nand some variants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 16:50:54 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 07:30:11 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Parsana", "Mehul", ""], ["Poola", "Krishna", ""], ["Wang", "Yajun", ""], ["Wang", "Zhiguang", ""]]}, {"id": "1804.09148", "submitter": "Diego Saldana", "authors": "Diego Saldana Miranda", "title": "Automated Detection of Adverse Drug Reactions in the Biomedical\n  Literature Using Convolutional Neural Networks and Biomedical Word Embeddings", "comments": "Accepted as conference paper at SwissText 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the biomedical literature for cases of Adverse Drug Reactions\n(ADRs) is a critically important and time consuming task in pharmacovigilance.\nThe development of computer assisted approaches to aid this process in\ndifferent forms has been the subject of many recent works. One particular area\nthat has shown promise is the use of Deep Neural Networks, in particular,\nConvolutional Neural Networks (CNNs), for the detection of ADR relevant\nsentences. Using token-level convolutions and general purpose word embeddings,\nthis architecture has shown good performance relative to more traditional\nmodels as well as Long Short Term Memory (LSTM) models. In this work, we\nevaluate and compare two different CNN architectures using the ADE corpus. In\naddition, we show that by de-duplicating the ADR relevant sentences, we can\ngreatly reduce overoptimism in the classification results. Finally, we evaluate\nthe use of word embeddings specifically developed for biomedical text and show\nthat they lead to a better performance in this task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:18:01 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Miranda", "Diego Saldana", ""]]}, {"id": "1804.09154", "submitter": "Pier Luca Lanzi", "authors": "Edoardo Giacomello and Pier Luca Lanzi and Daniele Loiacono", "title": "DOOM Level Generation using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied Generative Adversarial Networks (GANs) to learn a model of DOOM\nlevels from human-designed content. Initially, we analysed the levels and\nextracted several topological features. Then, for each level, we extracted a\nset of images identifying the occupied area, the height map, the walls, and the\nposition of game objects. We trained two GANs: one using plain level images,\none using both the images and some of the features extracted during the\npreliminary analysis. We used the two networks to generate new levels and\ncompared the results to assess whether the network trained using also the\ntopological features could generate levels more similar to human-designed ones.\nOur results show that GANs can capture intrinsic structure of DOOM levels and\nappears to be a promising approach to level generation in first person shooter\ngames.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:20:52 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Giacomello", "Edoardo", ""], ["Lanzi", "Pier Luca", ""], ["Loiacono", "Daniele", ""]]}, {"id": "1804.09160", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhu Chen, Yuan-Fang Wang, William Yang Wang", "title": "No Metrics Are Perfect: Adversarial Reward Learning for Visual\n  Storytelling", "comments": "ACL 2018. 15 pages, 10 figures, 4 tables, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though impressive results have been achieved in visual captioning, the task\nof generating abstract stories from photo streams is still a little-tapped\nproblem. Different from captions, stories have more expressive language styles\nand contain many imaginary concepts that do not appear in the images. Thus it\nposes challenges to behavioral cloning algorithms. Furthermore, due to the\nlimitations of automatic metrics on evaluating story quality, reinforcement\nlearning methods with hand-crafted rewards also face difficulties in gaining an\noverall performance boost. Therefore, we propose an Adversarial REward Learning\n(AREL) framework to learn an implicit reward function from human\ndemonstrations, and then optimize policy search with the learned reward\nfunction. Though automatic eval- uation indicates slight performance boost over\nstate-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation\nshows that our approach achieves significant improvement in generating more\nhuman-like stories than SOTA systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:41:24 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:15:14 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Xin", ""], ["Chen", "Wenhu", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.09170", "submitter": "Avital Oliver", "authors": "Avital Oliver, Augustus Odena, Colin Raffel, Ekin D. Cubuk and Ian J.\n  Goodfellow", "title": "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms", "comments": null, "journal-ref": "NeurIPS 2018 Proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) provides a powerful framework for leveraging\nunlabeled data when labels are limited or expensive to obtain. SSL algorithms\nbased on deep neural networks have recently proven successful on standard\nbenchmark tasks. However, we argue that these benchmarks fail to address many\nissues that these algorithms would face in real-world applications. After\ncreating a unified reimplementation of various widely-used SSL techniques, we\ntest them in a suite of experiments designed to address these issues. We find\nthat the performance of simple baselines which do not use unlabeled data is\noften underreported, that SSL methods differ in sensitivity to the amount of\nlabeled and unlabeled data, and that performance can degrade substantially when\nthe unlabeled dataset contains out-of-class examples. To help guide SSL\nresearch towards real-world applicability, we make our unified reimplemention\nand evaluation platform publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:54:44 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 22:39:26 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 17:36:40 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 11:48:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Oliver", "Avital", ""], ["Odena", "Augustus", ""], ["Raffel", "Colin", ""], ["Cubuk", "Ekin D.", ""], ["Goodfellow", "Ian J.", ""]]}, {"id": "1804.09217", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Akshay Soni, Chinmay Hegde", "title": "On Learning Sparsely Used Dictionaries from Incomplete Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing algorithms for dictionary learning assume that all entries of\nthe (high-dimensional) input data are fully observed. However, in several\npractical applications (such as hyper-spectral imaging or blood glucose\nmonitoring), only an incomplete fraction of the data entries may be available.\nFor incomplete settings, no provably correct and polynomial-time algorithm has\nbeen reported in the dictionary learning literature. In this paper, we provide\nprovable approaches for learning - from incomplete samples - a family of\ndictionaries whose atoms have sufficiently \"spread-out\" mass. First, we propose\na descent-style iterative algorithm that linearly converges to the true\ndictionary when provided a sufficiently coarse initial estimate. Second, we\npropose an initialization algorithm that utilizes a small number of extra fully\nobserved samples to produce such a coarse initial estimate. Finally, we\ntheoretically analyze their performance and provide asymptotic statistical and\ncomputational guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 19:06:50 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Soni", "Akshay", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1804.09238", "submitter": "Haitian Sun", "authors": "Haitian Sun, William W. Cohen, Lidong Bing", "title": "Semi-Supervised Learning with Declaratively Specified Entropy\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for declaratively specifying strategies for\nsemi-supervised learning (SSL). The proposed method can be used to specify\nensembles of semi-supervised learning, as well as agreement constraints and\nentropic regularization constraints between these learners, and can be used to\nmodel both well-known heuristics such as co-training and novel domain-specific\nheuristics. In addition to representing individual SSL heuristics, we show that\nmultiple heuristics can also be automatically combined using Bayesian\noptimization methods. We show consistent improvements on a suite of\nwell-studied SSL benchmarks, including a new state-of-the-art result on a\ndifficult relation extraction task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 20:19:09 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 04:22:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sun", "Haitian", ""], ["Cohen", "William W.", ""], ["Bing", "Lidong", ""]]}, {"id": "1804.09253", "submitter": "Kevin Kuo", "authors": "Kevin Kuo", "title": "DeepTriangle: A Deep Learning Approach to Loss Reserving", "comments": "Published version available at https://www.mdpi.com/2227-9091/7/3/97", "journal-ref": "Risks 2019, 7(3), 97", "doi": "10.3390/risks7030097", "report-no": null, "categories": "stat.AP cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for loss reserving based on deep neural networks.\nThe approach allows for joint modeling of paid losses and claims outstanding,\nand incorporation of heterogeneous inputs. We validate the models on loss\nreserving data across lines of business, and show that they improve on the\npredictive accuracy of existing stochastic methods. The models require minimal\nfeature engineering and expert input, and can be automated to produce forecasts\nmore frequently than manual workflows.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 20:47:04 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:35:59 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 19:04:15 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 17:12:04 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kuo", "Kevin", ""]]}, {"id": "1804.09288", "submitter": "Anurag Kumar", "authors": "Ankit Shah, Anurag Kumar, Alexander G. Hauptmann, Bhiksha Raj", "title": "A Closer Look at Weak Label Learning for Audio Events", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio content analysis in terms of sound events is an important research\nproblem for a variety of applications. Recently, the development of weak\nlabeling approaches for audio or sound event detection (AED) and availability\nof large scale weakly labeled dataset have finally opened up the possibility of\nlarge scale AED. However, a deeper understanding of how weak labels affect the\nlearning for sound events is still missing from literature. In this work, we\nfirst describe a CNN based approach for weakly supervised training of audio\nevents. The approach follows some basic design principle desirable in a\nlearning method relying on weakly labeled audio. We then describe important\ncharacteristics, which naturally arise in weakly supervised learning of sound\nevents. We show how these aspects of weak labels affect the generalization of\nmodels. More specifically, we study how characteristics such as label density\nand corruption of labels affects weakly supervised training for audio events.\nWe also study the feasibility of directly obtaining weak labeled data from the\nweb without any manual label and compare it with a dataset which has been\nmanually labeled. The analysis and understanding of these factors should be\ntaken into picture in the development of future weak label learning methods.\nAudioset, a large scale weakly labeled dataset for sound events is used in our\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 23:04:35 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Shah", "Ankit", ""], ["Kumar", "Anurag", ""], ["Hauptmann", "Alexander G.", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1804.09314", "submitter": "Jingyu He", "authors": "Guanhao Feng, Jingyu He, Nicholas G. Polson", "title": "Deep Learning for Predicting Asset Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning searches for nonlinear factors for predicting asset returns.\nPredictability is achieved via multiple layers of composite factors as opposed\nto additive ones. Viewed in this way, asset pricing studies can be revisited\nusing multi-layer deep learners, such as rectified linear units (ReLU) or\nlong-short-term-memory (LSTM) for time-series effects. State-of-the-art\nalgorithms including stochastic gradient descent (SGD), TensorFlow and dropout\ndesign provide imple- mentation and efficient factor exploration. To illustrate\nour methodology, we revisit the equity market risk premium dataset of Welch and\nGoyal (2008). We find the existence of nonlinear factors which explain\npredictability of returns, in particular at the extremes of the characteristic\nspace. Finally, we conclude with directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 01:52:34 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 14:50:14 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Feng", "Guanhao", ""], ["He", "Jingyu", ""], ["Polson", "Nicholas G.", ""]]}, {"id": "1804.09331", "submitter": "William La Cava", "authors": "Patryk Orzechowski, William La Cava, Jason H. Moore", "title": "Where are we now? A large benchmark study of recent symbolic regression\n  methods", "comments": "8 pages, 4 figures. GECCO 2018", "journal-ref": null, "doi": "10.1145/3205455.3205539", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a broad benchmarking of recent genetic programming\napproaches to symbolic regression in the context of state of the art machine\nlearning approaches. We use a set of nearly 100 regression benchmark problems\nculled from open source repositories across the web. We conduct a rigorous\nbenchmarking of four recent symbolic regression approaches as well as nine\nmachine learning approaches from scikit-learn. The results suggest that\nsymbolic regression performs strongly compared to state-of-the-art gradient\nboosting algorithms, although in terms of running times is among the slowest of\nthe available methodologies. We discuss the results in detail and point to\nfuture research directions that may allow symbolic regression to gain wider\nadoption in the machine learning community.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 02:58:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 15:32:40 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Orzechowski", "Patryk", ""], ["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "1804.09348", "submitter": "Toshihisa Tanaka", "authors": "Tomoya Wada, Kosuke Fukumori, Toshihisa Tanaka, and Simone Fiori", "title": "Generalized Gaussian Kernel Adaptive Filtering", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0237654", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper proposes generalized Gaussian kernel adaptive filtering,\nwhere the kernel parameters are adaptive and data-driven. The Gaussian kernel\nis parametrized by a center vector and a symmetric positive definite (SPD)\nprecision matrix, which is regarded as a generalization of the scalar width\nparameter. These parameters are adaptively updated on the basis of a proposed\nleast-square-type rule to minimize the estimation error. The main contribution\nof this paper is to establish update rules for precision matrices on the SPD\nmanifold in order to keep their symmetric positive-definiteness. Different from\nconventional kernel adaptive filters, the proposed regressor is a superposition\nof Gaussian kernels with all different parameters, which makes such regressor\nmore flexible. The kernel adaptive filtering algorithm is established together\nwith a l1-regularized least squares to avoid overfitting and the increase of\ndimensionality of the dictionary. Experimental results confirm the validity of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 04:55:56 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wada", "Tomoya", ""], ["Fukumori", "Kosuke", ""], ["Tanaka", "Toshihisa", ""], ["Fiori", "Simone", ""]]}, {"id": "1804.09364", "submitter": "Matthias M\\\"uller", "authors": "Matthias M\\\"uller, Alexey Dosovitskiy, Bernard Ghanem, Vladlen Koltun", "title": "Driving Policy Transfer via Modularity and Abstraction", "comments": "Accepted at Conference on Robotic Learning (CoRL'18)\n  http://proceedings.mlr.press/v87/mueller18a.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end approaches to autonomous driving have high sample complexity and\nare difficult to scale to realistic urban driving. Simulation can help\nend-to-end driving systems by providing a cheap, safe, and diverse training\nenvironment. Yet training driving policies in simulation brings up the problem\nof transferring such policies to the real world. We present an approach to\ntransferring driving policies from simulation to reality via modularity and\nabstraction. Our approach is inspired by classic driving systems and aims to\ncombine the benefits of modular architectures and end-to-end deep learning\napproaches. The key idea is to encapsulate the driving policy such that it is\nnot directly exposed to raw perceptual input or low-level vehicle dynamics. We\nevaluate the presented approach in simulated urban environments and in the real\nworld. In particular, we transfer a driving policy trained in simulation to a\n1/5-scale robotic truck that is deployed in a variety of conditions, with no\nfinetuning, on two continents. The supplementary video can be viewed at\nhttps://youtu.be/BrMDJqI6H5U\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 06:20:12 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 00:06:52 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 15:42:35 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["M\u00fcller", "Matthias", ""], ["Dosovitskiy", "Alexey", ""], ["Ghanem", "Bernard", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1804.09399", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Convolutional Generative Adversarial Networks with Binary Neurons for\n  Polyphonic Music Generation", "comments": "A preliminary version of this paper appeared in ISMIR 2018. In this\n  version, we added an appendix to provide figures of sample results and\n  remarks on the end-to-end models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown recently that deep convolutional generative adversarial\nnetworks (GANs) can learn to generate music in the form of piano-rolls, which\nrepresent music by binary-valued time-pitch matrices. However, existing models\ncan only generate real-valued piano-rolls and require further post-processing,\nsuch as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final\nbinary-valued results. In this paper, we study whether we can have a\nconvolutional GAN model that directly creates binary-valued piano-rolls by\nusing binary neurons. Specifically, we propose to append to the generator an\nadditional refiner network, which uses binary neurons at the output layer. The\nwhole network is trained in two stages. Firstly, the generator and the\ndiscriminator are pretrained. Then, the refiner network is trained along with\nthe discriminator to learn to binarize the real-valued piano-rolls the\npretrained generator creates. Experimental results show that using binary\nneurons instead of HT or BS indeed leads to better results in a number of\nobjective measures. Moreover, deterministic binary neurons perform better than\nstochastic ones in both objective measures and a subjective test. The source\ncode, training data and audio examples of the generated results can be found at\nhttps://salu133445.github.io/bmusegan/ .\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:35:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 16:13:12 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 15:08:20 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1804.09400", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicolas Duchateau, Nicholas Ayache", "title": "3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning\n  with Spatial Propagation", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method based on deep learning to perform cardiac segmentation on\nshort axis MRI image stacks iteratively from the top slice (around the base) to\nthe bottom slice (around the apex). At each iteration, a novel variant of U-net\nis applied to propagate the segmentation of a slice to the adjacent slice below\nit. In other words, the prediction of a segmentation of a slice is dependent\nupon the already existing segmentation of an adjacent slice. 3D-consistency is\nhence explicitly enforced. The method is trained on a large database of 3078\ncases from UK Biobank. It is then tested on 756 different cases from UK Biobank\nand three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with\n30 cases, RVSC with 16 cases). Results comparable or even better than the\nstate-of-the-art in terms of distance measures are achieved. They also\nemphasize the assets of our method, namely enhanced spatial consistency\n(currently neither considered nor achieved by the state-of-the-art), and the\ngeneralization ability to unseen cases even from other databases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:39:36 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Duchateau", "Nicolas", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1804.09401", "submitter": "Marco Fraccaro", "authors": "Marco Fraccaro, Danilo Jimenez Rezende, Yori Zwols, Alexander Pritzel,\n  S. M. Ali Eslami, Fabio Viola", "title": "Generative Temporal Models with Spatial Memory for Partially Observed\n  Environments", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning, generative and temporal models of\nenvironments can be leveraged to boost agent performance, either by tuning the\nagent's representations during training or via use as part of an explicit\nplanning mechanism. However, their application in practice has been limited to\nsimplistic environments, due to the difficulty of training such models in\nlarger, potentially partially-observed and 3D environments. In this work we\nintroduce a novel action-conditioned generative model of such challenging\nenvironments. The model features a non-parametric spatial memory system in\nwhich we store learned, disentangled representations of the environment.\nLow-dimensional spatial updates are computed using a state-space model that\nmakes use of knowledge on the prior dynamics of the moving agent, and\nhigh-dimensional visual observations are modelled with a Variational\nAuto-Encoder. The result is a scalable architecture capable of performing\ncoherent predictions over hundreds of time steps across a range of partially\nobserved 2D and 3D environments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:40:37 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 15:17:22 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Fraccaro", "Marco", ""], ["Rezende", "Danilo Jimenez", ""], ["Zwols", "Yori", ""], ["Pritzel", "Alexander", ""], ["Eslami", "S. M. Ali", ""], ["Viola", "Fabio", ""]]}, {"id": "1804.09458", "submitter": "Spyros Gidaris", "authors": "Spyros Gidaris and Nikos Komodakis", "title": "Dynamic Few-Shot Visual Learning without Forgetting", "comments": "Accepted at CVPR 2018. Code and models will be published on:\n  https://github.com/gidariss/FewShotWithoutForgetting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human visual system has the remarkably ability to be able to effortlessly\nlearn novel concepts from only a few examples. Mimicking the same behavior on\nmachine learning vision systems is an interesting and very challenging research\nproblem with many practical advantages on real world vision applications. In\nthis context, the goal of our work is to devise a few-shot visual learning\nsystem that during test time it will be able to efficiently learn novel\ncategories from only a few training data while at the same time it will not\nforget the initial categories on which it was trained (here called base\ncategories). To achieve that goal we propose (a) to extend an object\nrecognition system with an attention based few-shot classification weight\ngenerator, and (b) to redesign the classifier of a ConvNet model as the cosine\nsimilarity function between feature representations and classification weight\nvectors. The latter, apart from unifying the recognition of both novel and base\ncategories, it also leads to feature representations that generalize better on\n\"unseen\" categories. We extensively evaluate our approach on Mini-ImageNet\nwhere we manage to improve the prior state-of-the-art on few-shot recognition\n(i.e., we achieve 56.20% and 73.00% on the 1-shot and 5-shot settings\nrespectively) while at the same time we do not sacrifice any accuracy on the\nbase categories, which is a characteristic that most prior approaches lack.\nFinally, we apply our approach on the recently introduced few-shot benchmark of\nBharath and Girshick [4] where we also achieve state-of-the-art results. The\ncode and models of our paper will be published on:\nhttps://github.com/gidariss/FewShotWithoutForgetting\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 09:57:10 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Gidaris", "Spyros", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1804.09461", "submitter": "Huan Wang", "authors": "Huan Wang, Qiming Zhang, Yuehai Wang, Yu Lu, Haoji Hu", "title": "Structured Pruning for Efficient ConvNets via Incremental Regularization", "comments": "IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter pruning is a promising approach for CNN compression and\nacceleration by eliminating redundant model parameters with tolerable\nperformance degrade. Despite its effectiveness, existing regularization-based\nparameter pruning methods usually drive weights towards zero with large and\nconstant regularization factors, which neglects the fragility of the\nexpressiveness of CNNs, and thus calls for a more gentle regularization scheme\nso that the networks can adapt during pruning. To achieve this, we propose a\nnew and novel regularization-based pruning method, named IncReg, to\nincrementally assign different regularization factors to different weights\nbased on their relative importance. Empirical analysis on CIFAR-10 dataset\nverifies the merits of IncReg. Further extensive experiments with popular CNNs\non CIFAR-10 and ImageNet datasets show that IncReg achieves comparable to even\nbetter results compared with state-of-the-arts. Our source codes and trained\nmodels are available here: https://github.com/mingsun-tse/caffe_increg.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 09:59:45 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 03:09:41 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wang", "Huan", ""], ["Zhang", "Qiming", ""], ["Wang", "Yuehai", ""], ["Lu", "Yu", ""], ["Hu", "Haoji", ""]]}, {"id": "1804.09497", "submitter": "Cedric Fevotte", "authors": "C\\'edric F\\'evotte and Matthieu Kowalski", "title": "Estimation with Low-Rank Time-Frequency Synthesis Models", "comments": null, "journal-ref": "C. F\\'evotte and M. Kowalski. Estimation with low-rank\n  time-frequency synthesis models. IEEE Transactions on Signal Processing,\n  66(15):4121-4132, Aug. 2018", "doi": "10.1109/TSP.2018.2844159", "report-no": null, "categories": "eess.SP cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art signal decomposition techniques rely on a low-rank\nfactorization of a time-frequency (t-f) transform. In particular, nonnegative\nmatrix factorization (NMF) of the spectrogram has been considered in many audio\napplications. This is an analysis approach in the sense that the factorization\nis applied to the squared magnitude of the analysis coefficients returned by\nthe t-f transform. In this paper we instead propose a synthesis approach, where\nlow-rankness is imposed to the synthesis coefficients of the data signal over a\ngiven t-f dictionary (such as a Gabor frame). As such we offer a novel modeling\nparadigm that bridges t-f synthesis modeling and traditional analysis-based NMF\napproaches. The proposed generative model allows in turn to design more\nsophisticated multi-layer representations that can efficiently capture diverse\nforms of structure. Additionally, the generative modeling allows to exploit t-f\nlow-rankness for compressive sensing. We present efficient iterative shrinkage\nalgorithms to perform estimation in the proposed models and illustrate the\ncapabilities of the new modeling paradigm over audio signal processing\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 12:03:25 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 13:41:25 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["F\u00e9votte", "C\u00e9dric", ""], ["Kowalski", "Matthieu", ""]]}, {"id": "1804.09502", "submitter": "Zejian Li", "authors": "Zejian Li, Yongchuan Tang, Yongxing He", "title": "Unsupervised Disentangled Representation Learning with Analogical\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the disentangled representation of interpretable generative factors\nof data is one of the foundations to allow artificial intelligence to think\nlike people. In this paper, we propose the analogical training strategy for the\nunsupervised disentangled representation learning in generative models. The\nanalogy is one of the typical cognitive processes, and our proposed strategy is\nbased on the observation that sample pairs in which one is different from the\nother in one specific generative factor show the same analogical relation.\nThus, the generator is trained to generate sample pairs from which a designed\nclassifier can identify the underlying analogical relation. In addition, we\npropose a disentanglement metric called the subspace score, which is inspired\nby subspace learning methods and does not require supervised information.\nExperiments show that our proposed training strategy allows the generative\nmodels to find the disentangled factors, and that our methods can give\ncompetitive performances as compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 12:09:01 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Li", "Zejian", ""], ["Tang", "Yongchuan", ""], ["He", "Yongxing", ""]]}, {"id": "1804.09530", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Barbara Plank", "title": "Strong Baselines for Neural Semi-supervised Learning under Domain Shift", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel neural models have been proposed in recent years for learning under\ndomain shift. Most models, however, only evaluate on a single task, on\nproprietary datasets, or compare to weak baselines, which makes comparison of\nmodels difficult. In this paper, we re-evaluate classic general-purpose\nbootstrapping approaches in the context of neural networks under domain shifts\nvs. recent neural approaches and propose a novel multi-task tri-training method\nthat reduces the time and space complexity of classic tri-training. Extensive\nexperiments on two benchmarks are negative: while our novel method establishes\na new state-of-the-art for sentiment analysis, it does not fare consistently\nthe best. More importantly, we arrive at the somewhat surprising conclusion\nthat classic tri-training, with some additions, outperforms the state of the\nart. We conclude that classic approaches constitute an important and strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 13:06:29 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ruder", "Sebastian", ""], ["Plank", "Barbara", ""]]}, {"id": "1804.09534", "submitter": "Umar Iqbal", "authors": "Umar Iqbal, Pavlo Molchanov, Thomas Breuel, Juergen Gall, Jan Kautz", "title": "Hand Pose Estimation via Latent 2.5D Heatmap Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the 3D pose of a hand is an essential part of human-computer\ninteraction. Estimating 3D pose using depth or multi-view sensors has become\neasier with recent advances in computer vision, however, regressing pose from a\nsingle RGB image is much less straightforward. The main difficulty arises from\nthe fact that 3D pose requires some form of depth estimates, which are\nambiguous given only an RGB image. In this paper we propose a new method for 3D\nhand pose estimation from a monocular image through a novel 2.5D pose\nrepresentation. Our new representation estimates pose up to a scaling factor,\nwhich can be estimated additionally if a prior of the hand size is given. We\nimplicitly learn depth maps and heatmap distributions with a novel CNN\narchitecture. Our system achieves the state-of-the-art estimation of 2D and 3D\nhand pose on several challenging datasets in presence of severe occlusions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 13:16:26 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Iqbal", "Umar", ""], ["Molchanov", "Pavlo", ""], ["Breuel", "Thomas", ""], ["Gall", "Juergen", ""], ["Kautz", "Jan", ""]]}, {"id": "1804.09541", "submitter": "Adams Wei Yu", "authors": "Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen,\n  Mohammad Norouzi, Quoc V. Le", "title": "QANet: Combining Local Convolution with Global Self-Attention for\n  Reading Comprehension", "comments": "Published as full paper in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end machine reading and question answering (Q\\&A) models are\nprimarily based on recurrent neural networks (RNNs) with attention. Despite\ntheir success, these models are often slow for both training and inference due\nto the sequential nature of RNNs. We propose a new Q\\&A architecture called\nQANet, which does not require recurrent networks: Its encoder consists\nexclusively of convolution and self-attention, where convolution models local\ninteractions and self-attention models global interactions. On the SQuAD\ndataset, our model is 3x to 13x faster in training and 4x to 9x faster in\ninference, while achieving equivalent accuracy to recurrent models. The\nspeed-up gain allows us to train the model with much more data. We hence\ncombine our model with data generated by backtranslation from a neural machine\ntranslation model. On the SQuAD dataset, our single model, trained with\naugmented data, achieves 84.6 F1 score on the test set, which is significantly\nbetter than the best published F1 score of 81.8.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:33:43 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Yu", "Adams Wei", ""], ["Dohan", "David", ""], ["Luong", "Minh-Thang", ""], ["Zhao", "Rui", ""], ["Chen", "Kai", ""], ["Norouzi", "Mohammad", ""], ["Le", "Quoc V.", ""]]}, {"id": "1804.09554", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Hamed Hassani and Amin Karbasi", "title": "Stochastic Conditional Gradient Methods: From Convex Minimization to\n  Submodular Maximization", "comments": "arXiv admin note: text overlap with arXiv:1711.01660", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers stochastic optimization problems for a large class of\nobjective functions, including convex and continuous submodular. Stochastic\nproximal gradient methods have been widely used to solve such problems;\nhowever, their applicability remains limited when the problem dimension is\nlarge and the projection onto a convex set is costly. Instead, stochastic\nconditional gradient methods are proposed as an alternative solution relying on\n(i) Approximating gradients via a simple averaging technique requiring a single\nstochastic gradient evaluation per iteration; (ii) Solving a linear program to\ncompute the descent/ascent direction. The averaging technique reduces the noise\nof gradient approximations as time progresses, and replacing projection step in\nproximal methods by a linear program lowers the computational complexity of\neach iteration. We show that under convexity and smoothness assumptions, our\nproposed method converges to the optimal objective function value at a\nsublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous\nDR-submodular function and subject to a general convex body constraint, we\nprove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with\n$O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the\nknown hardness results and closes the gap between deterministic and stochastic\ncontinuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$\nguarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the\nobjective function is continuous DR-submodular but non-monotone and the\nconstraint set is down-closed. By using stochastic continuous optimization as\nan interface, we provide the first $(1-1/e)$ tight approximation guarantee for\nmaximizing a monotone but stochastic submodular set function subject to a\nmatroid constraint and $(1/e)$ approximation guarantee for the non-monotone\ncase.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:52:29 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:40:07 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1804.09558", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Armand Vilalta, Dario Garcia-Gasulla, Ulises\n  Cort\\'es, Eduard Ayguad\\'e, Jesus Labarta", "title": "A Visual Distance for WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:34:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:17:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jesus", ""]]}, {"id": "1804.09597", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "On The Complexity of Sparse Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the computational complexity of sparse label\npropagation which has been proposed recently for processing network structured\ndata. Sparse label propagation amounts to a convex optimization problem and\nmight be considered as an extension of basis pursuit from sparse vectors to\nnetwork structured datasets. Using a standard first-order oracle model, we\ncharacterize the number of iterations for sparse label propagation to achieve a\nprescribed accuracy. In particular, we derive an upper bound on the number of\niterations required to achieve a certain accuracy and show that this upper\nbound is sharp for datasets having a chain structure (e.g., time series).\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 14:33:34 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:16:09 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1804.09604", "submitter": "Ankita Mangal", "authors": "Ankita Mangal, Elizabeth A. Holm", "title": "A comparative study of feature selection methods for stress hotspot\n  classification in materials", "comments": "under review in Integrating Materials and Manufacturing Innovation", "journal-ref": null, "doi": "10.1007/s40192-018-0109-8", "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The first step in constructing a machine learning model is defining the\nfeatures of the data set that can be used for optimal learning. In this work we\ndiscuss feature selection methods, which can be used to build better models, as\nwell as achieve model interpretability. We applied these methods in the context\nof stress hotspot classification problem, to determine what microstructural\ncharacteristics can cause stress to build up in certain grains during uniaxial\ntensile deformation. The results show how some feature selection techniques are\nbiased and demonstrate a preferred technique to get feature rankings for\nphysical interpretations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:26:09 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Mangal", "Ankita", ""], ["Holm", "Elizabeth A.", ""]]}, {"id": "1804.09605", "submitter": "Kevin Schlegel", "authors": "Kevin Schlegel", "title": "When is there a Representer Theorem? Nondifferentiable Regularisers and\n  Banach spaces", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general regularised interpolation problem for learning a\nparameter vector from data. The well known representer theorem says that under\ncertain conditions on the regulariser there exists a solution in the linear\nspan of the data points. This is the core of kernel methods in machine learning\nas it makes the problem computationally tractable. Necessary and sufficient\nconditions for differentiable regularisers on Hilbert spaces to admit a\nrepresenter theorem have been proved. We extend those results to\nnondifferentiable regularisers on uniformly convex and uniformly smooth Banach\nspaces. This gives a (more) complete answer to the question when there is a\nrepresenter theorem. We then note that for regularised interpolation in fact\nthe solution is determined by the function space alone and independent of the\nregulariser, making the extension to Banach spaces even more valuable.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 14:47:25 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Schlegel", "Kevin", ""]]}, {"id": "1804.09619", "submitter": "Ravdeep Pasricha", "authors": "Ravdeep Pasricha, Ekta Gujral, Evangelos E. Papalexakis", "title": "Identifying and Alleviating Concept Drift in Streaming Tensor\n  Decomposition", "comments": "16 Pages, Accepted at ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions are used in various data mining applications from\nsocial network to medical applications and are extremely useful in discovering\nlatent structures or concepts in the data. Many real-world applications are\ndynamic in nature and so are their data. To deal with this dynamic nature of\ndata, there exist a variety of online tensor decomposition algorithms. A\ncentral assumption in all those algorithms is that the number of latent\nconcepts remains fixed throughout the entire stream. However, this need not be\nthe case. Every incoming batch in the stream may have a different number of\nlatent concepts, and the difference in latent concepts from one tensor batch to\nanother can provide insights into how our findings in a particular application\nbehave and deviate over time. In this paper, we define \"concept\" and \"concept\ndrift\" in the context of streaming tensor decomposition, as the manifestation\nof the variability of latent concepts throughout the stream. Furthermore, we\nintroduce SeekAndDestroy, an algorithm that detects concept drift in streaming\ntensor decomposition and is able to produce results robust to that drift. To\nthe best of our knowledge, this is the first work that investigates concept\ndrift in streaming tensor decomposition. We extensively evaluate SeekAndDestroy\non synthetic datasets, which exhibit a wide variety of realistic drift. Our\nexperiments demonstrate the effectiveness of SeekAndDestroy, both in the\ndetection of concept drift and in the alleviation of its effects, producing\nresults with similar quality to decomposing the entire tensor in one shot.\nAdditionally, in real datasets, SeekAndDestroy outperforms other streaming\nbaselines, while discovering novel useful components.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:17:58 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 01:07:33 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Pasricha", "Ravdeep", ""], ["Gujral", "Ekta", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1804.09629", "submitter": "Koulik Khamaru", "authors": "Koulik Khamaru, Martin J. Wainwright", "title": "Convergence guarantees for a class of non-convex and non-smooth\n  optimization problems", "comments": "50 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding critical points of functions that are\nnon-convex and non-smooth. Studying a fairly broad class of such problems, we\nanalyze the behavior of three gradient-based methods (gradient descent,\nproximal update, and Frank-Wolfe update). For each of these methods, we\nestablish rates of convergence for general problems, and also prove faster\nrates for continuous sub-analytic functions. We also show that our algorithms\ncan escape strict saddle points for a class of non-smooth functions, thereby\ngeneralizing known results for smooth functions. Our analysis leads to a\nsimplification of the popular CCCP algorithm, used for optimizing functions\nthat can be written as a difference of two convex functions. Our simplified\nalgorithm retains all the convergence properties of CCCP, along with a\nsignificantly lower cost per iteration. We illustrate our methods and theory\nvia applications to the problems of best subset selection, robust estimation,\nmixture density estimation, and shape-from-shading reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:31:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Khamaru", "Koulik", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1804.09699", "submitter": "Huan Zhang", "authors": "Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh,\n  Duane Boning, Inderjit S. Dhillon, Luca Daniel", "title": "Towards Fast Computation of Certified Robustness for ReLU Networks", "comments": "Tsui-Wei Weng and Huan Zhang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying the robustness property of a general Rectified Linear Unit (ReLU)\nnetwork is an NP-complete problem [Katz, Barrett, Dill, Julian and Kochenderfer\nCAV17]. Although finding the exact minimum adversarial distortion is hard,\ngiving a certified lower bound of the minimum distortion is possible. Current\navailable methods of computing such a bound are either time-consuming or\ndelivering low quality bounds that are too loose to be useful. In this paper,\nwe exploit the special structure of ReLU networks and provide two\ncomputationally efficient algorithms Fast-Lin and Fast-Lip that are able to\ncertify non-trivial lower bounds of minimum distortions, by bounding the ReLU\nunits with appropriate linear functions Fast-Lin, or by bounding the local\nLipschitz constant Fast-Lip. Experiments show that (1) our proposed methods\ndeliver bounds close to (the gap is 2-3X) exact minimum distortion found by\nReluplex in small MNIST networks while our algorithms are more than 10,000\ntimes faster; (2) our methods deliver similar quality of bounds (the gap is\nwithin 35% and usually around 10%; sometimes our bounds are even better) for\nlarger networks compared to the methods based on solving linear programming\nproblems but our algorithms are 33-14,000 times faster; (3) our method is\ncapable of solving large MNIST and CIFAR networks up to 7 layers with more than\n10,000 neurons within tens of seconds on a single CPU core.\n  In addition, we show that, in fact, there is no polynomial time algorithm\nthat can approximately find the minimum $\\ell_1$ adversarial distortion of a\nReLU network with a $0.99\\ln n$ approximation ratio unless\n$\\mathsf{NP}$=$\\mathsf{P}$, where $n$ is the number of neurons in the network.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 17:47:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 20:50:00 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 21:48:37 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2018 08:25:08 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Song", "Zhao", ""], ["Hsieh", "Cho-Jui", ""], ["Boning", "Duane", ""], ["Dhillon", "Inderjit S.", ""], ["Daniel", "Luca", ""]]}, {"id": "1804.09713", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar, Ramon Sanabria and Florian Metze", "title": "End-to-End Multimodal Speech Recognition", "comments": "5 pages, 5 figures, Accepted at IEEE International Conference on\n  Acoustics, Speech and Signal Processing 2018 (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcription or sub-titling of open-domain videos is still a challenging\ndomain for Automatic Speech Recognition (ASR) due to the data's challenging\nacoustics, variable signal processing and the essentially unrestricted domain\nof the data. In previous work, we have shown that the visual channel --\nspecifically object and scene features -- can help to adapt the acoustic model\n(AM) and language model (LM) of a recognizer, and we are now expanding this\nwork to end-to-end approaches. In the case of a Connectionist Temporal\nClassification (CTC)-based approach, we retain the separation of AM and LM,\nwhile for a sequence-to-sequence (S2S) approach, both information sources are\nadapted together, in a single model. This paper also analyzes the behavior of\nCTC and S2S models on noisy video data (How-To corpus), and compares it to\nresults on the clean Wall Street Journal (WSJ) corpus, providing insight into\nthe robustness of both approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:54:06 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Palaskar", "Shruti", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""]]}, {"id": "1804.09770", "submitter": "Namita Lokare", "authors": "Namita Lokare, Jorge Silva, Ilknur Kaynar Kabul", "title": "RULLS: Randomized Union of Locally Linear Subspaces for Feature\n  Engineering", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering plays an important role in the success of a machine\nlearning model. Most of the effort in training a model goes into data\npreparation and choosing the right representation. In this paper, we propose a\nrobust feature engineering method, Randomized Union of Locally Linear Subspaces\n(RULLS). We generate sparse, non-negative, and rotation invariant features in\nan unsupervised fashion. RULLS aggregates features from a random union of\nsubspaces by describing each point using globally chosen landmarks. These\nlandmarks serve as anchor points for choosing subspaces. Our method provides a\nway to select features that are relevant in the neighborhood around these\nchosen landmarks. Distances from each data point to $k$ closest landmarks are\nencoded in the feature matrix. The final feature representation is a union of\nfeatures from all chosen subspaces.\n  The effectiveness of our algorithm is shown on various real-world datasets\nfor tasks such as clustering and classification of raw data and in the presence\nof noise. We compare our method with existing feature generation methods.\nResults show a high performance of our method on both classification and\nclustering tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 19:37:55 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Lokare", "Namita", ""], ["Silva", "Jorge", ""], ["Kabul", "Ilknur Kaynar", ""]]}, {"id": "1804.09784", "submitter": "Jianzhong Wang", "authors": "Jianzhong Wang", "title": "Mathematical Analysis on Out-of-Sample Extensions", "comments": "18 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X=\\mathbf{X}\\cup\\mathbf{Z}$ be a data set in $\\mathbb{R}^D$, where\n$\\mathbf{X}$ is the training set and $\\mathbf{Z}$ is the test one. Many\nunsupervised learning algorithms based on kernel methods have been developed to\nprovide dimensionality reduction (DR) embedding for a given training set $\\Phi:\n\\mathbf{X} \\to \\mathbb{R}^d$ ( $d\\ll D$) that maps the high-dimensional data\n$\\mathbf{X}$ to its low-dimensional feature representation\n$\\mathbf{Y}=\\Phi(\\mathbf{X})$. However, these algorithms do not\nstraightforwardly produce DR of the test set $\\mathbf{Z}$. An out-of-sample\nextension method provides DR of $\\mathbf{Z}$ using an extension of the existent\nembedding $\\Phi$, instead of re-computing the DR embedding for the whole set\n$X$. Among various out-of-sample DR extension methods, those based on\nNystr\\\"{o}m approximation are very attractive. Many papers have developed such\nout-of-extension algorithms and shown their validity by numerical experiments.\nHowever, the mathematical theory for the DR extension still need further\nconsideration. Utilizing the reproducing kernel Hilbert space (RKHS) theory,\nthis paper develops a preliminary mathematical analysis on the out-of-sample DR\nextension operators. It treats an out-of-sample DR extension operator as an\nextension of the identity on the RKHS defined on $\\mathbf{X}$. Then the\nNystr\\\"{o}m-type DR extension turns out to be an orthogonal projection. In the\npaper, we also present the conditions for the exact DR extension and give the\nestimate for the error of the extension.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:20:52 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Wang", "Jianzhong", ""]]}, {"id": "1804.09788", "submitter": "Aviad Aberdam", "authors": "Aviad Aberdam, Jeremias Sulam, and Michael Elad", "title": "Multi-Layer Sparse Coding: The Holistic Way", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed multi-layer sparse model has raised insightful\nconnections between sparse representations and convolutional neural networks\n(CNN). In its original conception, this model was restricted to a cascade of\nconvolutional synthesis representations. In this paper, we start by addressing\na more general model, revealing interesting ties to fully connected networks.\nWe then show that this multi-layer construction admits a brand new\ninterpretation in a unique symbiosis between synthesis and analysis models:\nwhile the deepest layer indeed provides a synthesis representation, the\nmid-layers decompositions provide an analysis counterpart. This new perspective\nexposes the suboptimality of previously proposed pursuit approaches, as they do\nnot fully leverage all the information comprised in the model constraints.\nArmed with this understanding, we address fundamental theoretical issues,\nrevisiting previous analysis and expanding it. Motivated by the limitations of\nprevious algorithms, we then propose an integrated - holistic - alternative\nthat estimates all representations in the model simultaneously, and analyze all\nthese different schemes under stochastic noise assumptions. Inspired by the\nsynthesis-analysis duality, we further present a Holistic Pursuit algorithm,\nwhich alternates between synthesis and analysis sparse coding steps, eventually\nsolving for the entire model as a whole, with provable improved performance.\nFinally, we present numerical results that demonstrate the practical advantages\nof our approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 20:19:48 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 13:08:29 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Aberdam", "Aviad", ""], ["Sulam", "Jeremias", ""], ["Elad", "Michael", ""]]}, {"id": "1804.09808", "submitter": "Paolo Frasconi", "authors": "Tijn Borghuis, Alessandro Tibo, Simone Conforti, Luca Canciello,\n  Lorenzo Brusci, Paolo Frasconi", "title": "Off the Beaten Track: Using Deep Learning to Interpolate Between Music\n  Genres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system based on deep learning that generates drum patterns in\nthe electronic dance music domain. Experimental results reveal that generated\npatterns can be employed to produce musically sound and creative transitions\nbetween different genres, and that the process of generation is of interest to\npractitioners in the field.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:39:39 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 16:56:08 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Borghuis", "Tijn", ""], ["Tibo", "Alessandro", ""], ["Conforti", "Simone", ""], ["Canciello", "Luca", ""], ["Brusci", "Lorenzo", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1804.09812", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Diego Klabjan", "title": "Improved Classification Based on Deep Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For better classification generative models are used to initialize the model\nand model features before training a classifier. Typically it is needed to\nsolve separate unsupervised and supervised learning problems. Generative\nrestricted Boltzmann machines and deep belief networks are widely used for\nunsupervised learning. We developed several supervised models based on DBN in\norder to improve this two-phase strategy. Modifying the loss function to\naccount for expectation with respect to the underlying generative model,\nintroducing weight bounds, and multi-level programming are applied in model\ndevelopment. The proposed models capture both unsupervised and supervised\nobjectives effectively. The computational study verifies that our models\nperform better than the two-phase training approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:53:55 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 04:08:38 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Koo", "Jaehoon", ""], ["Klabjan", "Diego", ""]]}, {"id": "1804.09813", "submitter": "Thibaut Vidal", "authors": "Daniel Gribel, Thibaut Vidal", "title": "HG-means: A scalable hybrid genetic algorithm for minimum sum-of-squares\n  clustering", "comments": "22 pages", "journal-ref": null, "doi": "10.1016/j.patcog.2018.12.022", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum sum-of-squares clustering (MSSC) is a widely used clustering model,\nof which the popular K-means algorithm constitutes a local minimizer. It is\nwell known that the solutions of K-means can be arbitrarily distant from the\ntrue MSSC global optimum, and dozens of alternative heuristics have been\nproposed for this problem. However, no other algorithm has been predominantly\nadopted in the literature. This may be related to differences of computational\neffort, or to the assumption that a near-optimal solution of the MSSC has only\na marginal impact on clustering validity. In this article, we dispute this\nbelief. We introduce an efficient population-based metaheuristic that uses\nK-means as a local search in combination with problem-tailored crossover,\nmutation, and diversification operators. This algorithm can be interpreted as a\nmulti-start K-means, in which the initial center positions are carefully\nsampled based on the search history. The approach is scalable and accurate,\noutperforming all recent state-of-the-art algorithms for MSSC in terms of\nsolution quality, measured by the depth of local minima. This enhanced accuracy\nleads to clusters which are significantly closer to the ground truth than those\nof other algorithms, for overlapping Gaussian-mixture datasets with a large\nnumber of features. Therefore, improved global optimization methods appear to\nbe essential to better exploit the MSSC model in high dimension.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:54:21 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 23:27:51 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Gribel", "Daniel", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1804.09816", "submitter": "Alexander Cloninger", "authors": "Alexander Cloninger, Stefan Steinerberger", "title": "On the Dual Geometry of Laplacian Eigenfunctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.AP math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the geometry of Laplacian eigenfunctions $-\\Delta \\phi = \\lambda\n\\phi$ on compact manifolds $(M,g)$ and combinatorial graphs $G=(V,E)$. The\n'dual' geometry of Laplacian eigenfunctions is well understood on\n$\\mathbb{T}^d$ (identified with $\\mathbb{Z}^d$) and $\\mathbb{R}^n$ (which is\nself-dual). The dual geometry is of tremendous role in various fields of pure\nand applied mathematics. The purpose of our paper is to point out a notion of\nsimilarity between eigenfunctions that allows to reconstruct that geometry. Our\nmeasure of 'similarity' $ \\alpha(\\phi_{\\lambda}, \\phi_{\\mu})$ between\neigenfunctions $\\phi_{\\lambda}$ and $\\phi_{\\mu}$ is given by a global average\nof local correlations $$ \\alpha(\\phi_{\\lambda}, \\phi_{\\mu})^2 = \\|\n\\phi_{\\lambda} \\phi_{\\mu} \\|_{L^2}^{-2}\\int_{M}{ \\left( \\int_{M}{ p(t,x,y)(\n\\phi_{\\lambda}(y) - \\phi_{\\lambda}(x))( \\phi_{\\mu}(y) - \\phi_{\\mu}(x)) dy}\n\\right)^2 dx},$$ where $p(t,x,y)$ is the classical heat kernel and $e^{-t\n\\lambda} + e^{-t \\mu} = 1$. This notion recovers all classical notions of\nduality but is equally applicable to other (rough) geometries and graphs; many\nnumerical examples in different continuous and discrete settings illustrate the\nresult.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:02:54 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Cloninger", "Alexander", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "1804.09843", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun and Andrew Gordon Wilson", "title": "Hierarchical Density Order Embeddings", "comments": "Published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing words with probability densities rather than point vectors,\nprobabilistic word embeddings can capture rich and interpretable semantic\ninformation and uncertainty. The uncertainty information can be particularly\nmeaningful in capturing entailment relationships -- whereby general words such\nas \"entity\" correspond to broad distributions that encompass more specific\nwords such as \"animal\" or \"instrument\". We introduce density order embeddings,\nwhich learn hierarchical representations through encapsulation of probability\ndensities. In particular, we propose simple yet effective loss functions and\ndistance metrics, as well as graph-based schemes to select negative samples to\nbetter learn hierarchical density representations. Our approach provides\nstate-of-the-art performance on the WordNet hypernym relationship prediction\ntask and the challenging HyperLex lexical entailment dataset -- while retaining\na rich and interpretable density representation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 00:43:49 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1804.09858", "submitter": "Zhou Honggang", "authors": "Honggang Zhou and Yunchun Li and Hailong Yang and Wei Li and Jie Jia", "title": "Generative Model for Heterogeneous Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models (GMs) such as Generative Adversary Network (GAN) and\nVariational Auto-Encoder (VAE) have thrived these years and achieved high\nquality results in generating new samples. Especially in Computer Vision, GMs\nhave been used in image inpainting, denoising and completion, which can be\ntreated as the inference from observed pixels to corrupted pixels. However,\nimages are hierarchically structured which are quite different from many\nreal-world inference scenarios with non-hierarchical features. These inference\nscenarios contain heterogeneous stochastic variables and irregular mutual\ndependences. Traditionally they are modeled by Bayesian Network (BN). However,\nthe learning and inference of BN model are NP-hard thus the number of\nstochastic variables in BN is highly constrained. In this paper, we adapt\ntypical GMs to enable heterogeneous learning and inference in polynomial\ntime.We also propose an extended autoregressive (EAR) model and an EAR with\nadversary loss (EARA) model and give theoretical results on their\neffectiveness. Experiments on several BN datasets show that our proposed EAR\nmodel achieves the best performance in most cases compared to other GMs. Except\nfor black box analysis, we've also done a serial of experiments on Markov\nborder inference of GMs for white box analysis and give theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:28:34 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Zhou", "Honggang", ""], ["Li", "Yunchun", ""], ["Yang", "Hailong", ""], ["Li", "Wei", ""], ["Jia", "Jie", ""]]}, {"id": "1804.09859", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Competitive Learning Enriches Learning Representation and Accelerates\n  the Fine-tuning of CNNs", "comments": "Appeared at NIPS 2017 Workshop: Deep Learning: Bridging Theory and\n  Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the integration of competitive learning into\nconvolutional neural networks (CNNs) to improve the representation learning and\nefficiency of fine-tuning. Conventional CNNs use back propagation learning, and\nit enables powerful representation learning by a discrimination task. However,\nit requires huge amount of labeled data, and acquisition of labeled data is\nmuch harder than that of unlabeled data. Thus, efficient use of unlabeled data\nis getting crucial for DNNs. To address the problem, we introduce unsupervised\ncompetitive learning into the convolutional layer, and utilize unlabeled data\nfor effective representation learning. The results of validation experiments\nusing a toy model demonstrated that strong representation learning effectively\nextracted bases of images into convolutional filters using unlabeled data, and\naccelerated the speed of the fine-tuning of subsequent supervised back\npropagation learning. The leverage was more apparent when the number of filters\nwas sufficiently large, and, in such a case, the error rate steeply decreased\nin the initial phase of fine-tuning. Thus, the proposed method enlarged the\nnumber of filters in CNNs, and enabled a more detailed and generalized\nrepresentation. It could provide a possibility of not only deep but broad\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:28:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "1804.09882", "submitter": "Guillaume Jourjon", "authors": "Jathushan Rajasegaran and Suranga Seneviratne and Guillaume Jourjon", "title": "A Neural Embeddings Approach for Detecting Mobile Counterfeit Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfeit apps impersonate existing popular apps in attempts to misguide\nusers to install them for various reasons such as collecting personal\ninformation, spreading malware, or simply to increase their advertisement\nrevenue. Many counterfeits can be identified once installed, however even a\ntech-savvy user may struggle to detect them before installation as app icons\nand descriptions can be quite similar to the original app. To this end, this\npaper proposes to use neural embeddings generated by state-of-the-art\nconvolutional neural networks (CNNs) to measure the similarity between images.\nOur results show that for the problem of counterfeit detection a novel approach\nof using style embeddings given by the Gram matrix of CNN filter responses\noutperforms baseline methods such as content embeddings and SIFT features. We\nshow that further performance increases can be achieved by combining style\nembeddings with content embeddings. We present an analysis of approximately 1.2\nmillion apps from Google Play Store and identify a set of potential\ncounterfeits for top-1,000 apps. Under a conservative assumption, we were able\nto find 139 apps that contain malware in a set of 6,880 apps that showed high\nvisual similarity to one of the top-1,000 apps in Google Play Store.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 03:58:50 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Rajasegaran", "Jathushan", ""], ["Seneviratne", "Suranga", ""], ["Jourjon", "Guillaume", ""]]}, {"id": "1804.09893", "submitter": "Haim Avron", "authors": "Haim Avron, Michael Kapralov, Cameron Musco, Christopher Musco, Ameya\n  Velingker, Amir Zandieh", "title": "Random Fourier Features for Kernel Ridge Regression: Approximation\n  Bounds and Statistical Guarantees", "comments": "An extended abstract of this work appears in the Proceedings of the\n  34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features is one of the most popular techniques for scaling up\nkernel methods, such as kernel ridge regression. However, despite impressive\nempirical results, the statistical properties of random Fourier features are\nstill not well understood. In this paper we take steps toward filling this gap.\nSpecifically, we approach random Fourier features from a spectral matrix\napproximation point of view, give tight bounds on the number of Fourier\nfeatures required to achieve a spectral approximation, and show how spectral\nmatrix approximation bounds imply statistical guarantees for kernel ridge\nregression.\n  Qualitatively, our results are twofold: on the one hand, we show that random\nFourier feature approximation can provably speed up kernel ridge regression\nunder reasonable assumptions. At the same time, we show that the method is\nsuboptimal, and sampling from a modified distribution in Fourier space, given\nby the leverage function of the kernel, yields provably better performance. We\nstudy this optimal sampling distribution for the Gaussian kernel, achieving a\nnearly complete characterization for the case of low-dimensional bounded\ndatasets. Based on this characterization, we propose an efficient sampling\nscheme with guarantees superior to random Fourier features in this regime.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 05:34:25 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 09:17:40 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Avron", "Haim", ""], ["Kapralov", "Michael", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Velingker", "Ameya", ""], ["Zandieh", "Amir", ""]]}, {"id": "1804.09904", "submitter": "Kohei Miyaguchi", "authors": "Kohei Miyaguchi, Kenji Yamanishi", "title": "High-dimensional Penalty Selection via Minimum Description Length\n  Principle", "comments": "Preprint before review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of penalty selection of regularization on the basis of\nthe minimum description length (MDL) principle. In particular, we consider that\nthe design space of the penalty function is high-dimensional. In this\nsituation, the luckiness-normalized-maximum-likelihood(LNML)-minimization\napproach is favorable, because LNML quantifies the goodness of regularized\nmodels with any forms of penalty functions in view of the minimum description\nlength principle, and guides us to a good penalty function through the\nhigh-dimensional space. However, the minimization of LNML entails two major\nchallenges: 1) the computation of the normalizing factor of LNML and 2) its\nminimization in high-dimensional spaces. In this paper, we present a novel\nregularization selection method (MDL-RS), in which a tight upper bound of LNML\n(uLNML) is minimized with local convergence guarantee. Our main contribution is\nthe derivation of uLNML, which is a uniform-gap upper bound of LNML in an\nanalytic expression. This solves the above challenges in an approximate manner\nbecause it allows us to accurately approximate LNML and then efficiently\nminimize it. The experimental results show that MDL-RS improves the\ngeneralization performance of regularized estimates specifically when the model\nhas redundant parameters.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 06:22:01 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Miyaguchi", "Kohei", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1804.10001", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama, Takashi Imamichi, Haruki Imai, Rudy Raymond", "title": "Profile-guided memory optimization for deep neural networks", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen deep neural networks (DNNs) becoming wider and deeper\nto achieve better performance in many applications of AI. Such DNNs however\nrequire huge amounts of memory to store weights and intermediate results (e.g.,\nactivations, feature maps, etc.) in propagation. This requirement makes it\ndifficult to run the DNNs on devices with limited, hard-to-extend memory,\ndegrades the running time performance, and restricts the design of network\nmodels. We address this challenge by developing a novel profile-guided memory\noptimization to efficiently and quickly allocate memory blocks during the\npropagation in DNNs. The optimization utilizes a simple and fast heuristic\nalgorithm based on the two-dimensional rectangle packing problem. Experimenting\nwith well-known neural network models, we confirm that our method not only\nreduces the memory consumption by up to $49.5\\%$ but also accelerates training\nand inference by up to a factor of four thanks to the rapidity of the memory\nallocation and the ability to use larger mini-batch sizes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 11:42:39 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Sekiyama", "Taro", ""], ["Imamichi", "Takashi", ""], ["Imai", "Haruki", ""], ["Raymond", "Rudy", ""]]}, {"id": "1804.10023", "submitter": "Iker Be\\~naran", "authors": "Iker Be\\~naran-Mu\\~noz, Jer\\'onimo Hern\\'andez-Gonz\\'alez and Aritz\n  P\\'erez", "title": "Candidate Labeling for Crowd Learning", "comments": "7 pages, 3 figures, to be published", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become very popular among the machine learning community as\na way to obtain labels that allow a ground truth to be estimated for a given\ndataset. In most of the approaches that use crowdsourced labels, annotators are\nasked to provide, for each presented instance, a single class label. Such a\nrequest could be inefficient, that is, considering that the labelers may not be\nexperts, that way to proceed could fail to take real advantage of the knowledge\nof the labelers. In this paper, the use of candidate labeling for crowd\nlearning is proposed, where the annotators may provide more than a single label\nper instance to try not to miss the real label. The main hypothesis is that, by\nallowing candidate labeling, knowledge can be extracted from the labelers more\nefficiently by than in the standard crowd learning scenario. Empirical evidence\nwhich supports that hypothesis is presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:47:52 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 13:44:56 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Be\u00f1aran-Mu\u00f1oz", "Iker", ""], ["Hern\u00e1ndez-Gonz\u00e1lez", "Jer\u00f3nimo", ""], ["P\u00e9rez", "Aritz", ""]]}, {"id": "1804.10025", "submitter": "Anton Kocheturov", "authors": "Anton Kocheturov, Petar Momcilovic, Azra Bihorac, Panos M. Pardalos", "title": "Extended Vertical Lists for Temporal Pattern Mining from Multivariate\n  Time Series", "comments": "16 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Pattern Mining (TPM) is the problem of mining predictive complex\ntemporal patterns from multivariate time series in a supervised setting. We\ndevelop a new method called the Fast Temporal Pattern Mining with Extended\nVertical Lists. This method utilizes an extension of the Apriori property which\nrequires a more complex pattern to appear within records only at places where\nall of its subpatterns are detected as well. The approach is based on a novel\ndata structure called the Extended Vertical List that tracks positions of the\nfirst state of the pattern inside records. Extensive computational results\nindicate that the new method performs significantly faster than the previous\nversion of the algorithm for TMP. However, the speed-up comes at the expense of\nmemory usage.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:49:26 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Kocheturov", "Anton", ""], ["Momcilovic", "Petar", ""], ["Bihorac", "Azra", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "1804.10028", "submitter": "John Klein", "authors": "John Klein, Mahmoud Albardan, Benjamin Guedj and Olivier Colot", "title": "Decentralized learning with budgeted network load using Gaussian copulas\n  and classifier ensembles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_26", "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a network of learners which address the same classification task\nbut must learn from different data sets. The learners cannot share data but\ninstead share their models. Models are shared only one time so as to preserve\nthe network load. We introduce DELCO (standing for Decentralized Ensemble\nLearning with COpulas), a new approach allowing to aggregate the predictions of\nthe classifiers trained by each learner. The proposed method aggregates the\nbase classifiers using a probabilistic model relying on Gaussian copulas.\nExperiments on logistic regressor ensembles demonstrate competing accuracy and\nincreased robustness in case of dependent classifiers. A companion python\nimplementation can be downloaded at https://github.com/john-klein/DELCO\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:53:58 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:33:39 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 07:38:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Klein", "John", ""], ["Albardan", "Mahmoud", ""], ["Guedj", "Benjamin", ""], ["Colot", "Olivier", ""]]}, {"id": "1804.10070", "submitter": "Brian McFee", "authors": "Brian McFee, Justin Salamon, Juan Pablo Bello", "title": "Adaptive pooling operators for weakly labeled sound event detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound event detection (SED) methods are tasked with labeling segments of\naudio recordings by the presence of active sound sources. SED is typically\nposed as a supervised machine learning problem, requiring strong annotations\nfor the presence or absence of each sound source at every time instant within\nthe recording. However, strong annotations of this type are both labor- and\ncost-intensive for human annotators to produce, which limits the practical\nscalability of SED methods.\n  In this work, we treat SED as a multiple instance learning (MIL) problem,\nwhere training labels are static over a short excerpt, indicating the presence\nor absence of sound sources but not their temporal locality. The models,\nhowever, must still produce temporally dynamic predictions, which must be\naggregated (pooled) when comparing against static labels during training. To\nfacilitate this aggregation, we develop a family of adaptive pooling\noperators---referred to as auto-pool---which smoothly interpolate between\ncommon pooling operators, such as min-, max-, or average-pooling, and\nautomatically adapt to the characteristics of the sound sources in question. We\nevaluate the proposed pooling operators on three datasets, and demonstrate that\nin each case, the proposed methods outperform non-adaptive pooling operators\nfor static prediction, and nearly match the performance of models trained with\nstrong, dynamic annotations. The proposed method is evaluated in conjunction\nwith convolutional neural networks, but can be readily applied to any\ndifferentiable model for time-series label prediction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 14:01:12 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 16:35:17 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["McFee", "Brian", ""], ["Salamon", "Justin", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1804.10085", "submitter": "Philipp Gassert", "authors": "Winfried Lohmiller, Philipp Gassert, Jean-Jacques Slotine", "title": "Notes on stable learning with piecewise-linear basis functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss technical results on learning function approximations using\npiecewise-linear basis functions, and analyze their stability and convergence\nusing nonlinear contraction theory.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 09:27:46 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Lohmiller", "Winfried", ""], ["Gassert", "Philipp", ""], ["Slotine", "Jean-Jacques", ""]]}, {"id": "1804.10109", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Quantized Compressive K-Means", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2847908", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent framework of compressive statistical learning aims at designing\ntractable learning algorithms that use only a heavily compressed\nrepresentation-or sketch-of massive datasets. Compressive K-Means (CKM) is such\na method: it estimates the centroids of data clusters from pooled, non-linear,\nrandom signatures of the learning examples. While this approach significantly\nreduces computational time on very large datasets, its digital implementation\nwastes acquisition resources because the learning examples are compressed only\nafter the sensing stage. The present work generalizes the sketching procedure\ninitially defined in Compressive K-Means to a large class of periodic\nnonlinearities including hardware-friendly implementations that compressively\nacquire entire datasets. This idea is exemplified in a Quantized Compressive\nK-Means procedure, a variant of CKM that leverages 1-bit universal quantization\n(i.e. retaining the least significant bit of a standard uniform quantizer) as\nthe periodic sketch nonlinearity. Trading for this resource-efficient signature\n(standard in most acquisition schemes) has almost no impact on the clustering\nperformances, as illustrated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 15:24:42 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:46:54 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "1804.10140", "submitter": "Lili Su", "authors": "Lili Su and Jiaming Xu", "title": "Securing Distributed Gradient Descent in High Dimensional Statistical\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unreliable distributed learning systems wherein the training data\nis kept confidential by external workers, and the learner has to interact\nclosely with those workers to train a model. In particular, we assume that\nthere exists a system adversary that can adaptively compromise some workers;\nthe compromised workers deviate from their local designed specifications by\nsending out arbitrarily malicious messages.\n  We assume in each communication round, up to $q$ out of the $m$ workers\nsuffer Byzantine faults. Each worker keeps a local sample of size $n$ and the\ntotal sample size is $N=nm$. We propose a secured variant of the gradient\ndescent method that can tolerate up to a constant fraction of Byzantine\nworkers, i.e., $q/m = O(1)$. Moreover, we show the statistical estimation error\nof the iterates converges in $O(\\log N)$ rounds to $O(\\sqrt{q/N} +\n\\sqrt{d/N})$, where $d$ is the model dimension. As long as $q=O(d)$, our\nproposed algorithm achieves the optimal error rate $O(\\sqrt{d/N})$. Our results\nare obtained under some technical assumptions. Specifically, we assume\nstrongly-convex population risk. Nevertheless, the empirical risk (sample\nversion) is allowed to be non-convex. The core of our method is to robustly\naggregate the gradients computed by the workers based on the filtering\nprocedure proposed by Steinhardt et al. On the technical front, deviating from\nthe existing literature on robustly estimating a finite-dimensional mean\nvector, we establish a {\\em uniform} concentration of the sample covariance\nmatrix of gradients, and show that the aggregated gradient, as a function of\nmodel parameter, converges uniformly to the true gradient function. To get a\nnear-optimal uniform concentration bound, we develop a new matrix concentration\ninequality, which might be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 16:09:51 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 19:25:25 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 17:21:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Su", "Lili", ""], ["Xu", "Jiaming", ""]]}, {"id": "1804.10168", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac and Jeffrey S. Rosenthal", "title": "BEST : A decision tree algorithm that handles missing values", "comments": "To appear in Computational Statistics", "journal-ref": "Computational Statistics 2020", "doi": "10.1007/s00180-020-00987-z", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is the development of a new decision tree\nalgorithm. The proposed approach allows users to guide the algorithm through\nthe data partitioning process. We believe this feature has many applications\nbut in this paper we demonstrate how to utilize this algorithm to analyse data\nsets containing missing values. We tested our algorithm against simulated data\nsets with various missing data structures and a real data set. The results\ndemonstrate that this new classification procedure efficiently handles missing\nvalues and produces results that are slightly more accurate and more\ninterpretable than most common procedures without any imputations or\npre-processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 16:53:05 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 20:42:53 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 17:33:17 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 16:56:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1804.10188", "submitter": "Sahil Garg", "authors": "Sahil Garg, Irina Rish, Guillermo Cecchi, Palash Goyal, Sarik\n  Ghazarian, Shuyang Gao, Greg Ver Steeg, Aram Galstyan", "title": "Modeling Psychotherapy Dialogues with Kernelized Hashcode\n  Representations: A Nonparametric Information-Theoretic Approach", "comments": "Response generative based model added, along with human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel dialogue modeling framework, the first-ever nonparametric\nkernel functions based approach for dialogue modeling, which learns kernelized\nhashcodes as compressed text representations; unlike traditional deep learning\nmodels, it handles well relatively small datasets, while also scaling to large\nones. We also derive a novel lower bound on mutual information, used as a\nmodel-selection criterion favoring representations with better alignment\nbetween the utterances of participants in a collaborative dialogue setting, as\nwell as higher predictability of the generated responses. As demonstrated on\nthree real-life datasets, including prominently psychotherapy sessions, the\nproposed approach significantly outperforms several state-of-art neural network\nbased dialogue systems, both in terms of computational efficiency, reducing\ntraining time from days or weeks to hours, and the response quality, achieving\nan order of magnitude improvement over competitors in frequency of being chosen\nas the best model by human evaluators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:39:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 03:58:19 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 14:54:22 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 15:23:28 GMT"}, {"version": "v6", "created": "Fri, 8 Mar 2019 02:16:21 GMT"}, {"version": "v7", "created": "Mon, 9 Sep 2019 19:43:38 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garg", "Sahil", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Goyal", "Palash", ""], ["Ghazarian", "Sarik", ""], ["Gao", "Shuyang", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1804.10200", "submitter": "Y Cooper", "authors": "Y Cooper", "title": "The loss landscape of overparameterized neural networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore some mathematical features of the loss landscape of\noverparameterized neural networks. A priori one might imagine that the loss\nfunction looks like a typical function from $\\mathbb{R}^n$ to $\\mathbb{R}$ - in\nparticular, nonconvex, with discrete global minima. In this paper, we prove\nthat in at least one important way, the loss function of an overparameterized\nneural network does not look like a typical function. If a neural net has $n$\nparameters and is trained on $d$ data points, with $n>d$, we show that the\nlocus $M$ of global minima of $L$ is usually not discrete, but rather an $n-d$\ndimensional submanifold of $\\mathbb{R}^n$. In practice, neural nets commonly\nhave orders of magnitude more parameters than data points, so this observation\nimplies that $M$ is typically a very high-dimensional subset of $\\mathbb{R}^n$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:58:45 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Cooper", "Y", ""]]}, {"id": "1804.10204", "submitter": "Jonathan Le Roux", "authors": "Zhong-Qiu Wang, Jonathan Le Roux, DeLiang Wang, John R. Hershey", "title": "End-to-End Speech Separation with Unfolded Iterative Phase\n  Reconstruction", "comments": "Submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an end-to-end approach for single-channel\nspeaker-independent multi-speaker speech separation, where time-frequency (T-F)\nmasking, the short-time Fourier transform (STFT), and its inverse are\nrepresented as layers within a deep network. Previous approaches, rather than\ncomputing a loss on the reconstructed signal, used a surrogate loss based on\nthe target STFT magnitudes. This ignores reconstruction error introduced by\nphase inconsistency. In our approach, the loss function is directly defined on\nthe reconstructed signals, which are optimized for best separation. In\naddition, we train through unfolded iterations of a phase reconstruction\nalgorithm, represented as a series of STFT and inverse STFT layers. While mask\nvalues are typically limited to lie between zero and one for approaches using\nthe mixture phase for reconstruction, this limitation is less relevant if the\nestimated magnitudes are to be used together with phase reconstruction. We thus\npropose several novel activation functions for the output layer of the T-F\nmasking, to allow mask values beyond one. On the publicly-available wsj0-2mix\ndataset, our approach achieves state-of-the-art 12.6 dB scale-invariant\nsignal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new\npossibilities for deep learning based phase reconstruction and representing a\nfundamental progress towards solving the notoriously-hard cocktail party\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 13:14:22 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Wang", "Zhong-Qiu", ""], ["Roux", "Jonathan Le", ""], ["Wang", "DeLiang", ""], ["Hershey", "John R.", ""]]}, {"id": "1804.10223", "submitter": "Jeff Pool", "authors": "Feiwen Zhu, Jeff Pool, Michael Andersch, Jeremy Appleyard, Fung Xie", "title": "Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful tools for solving\nsequence-based problems, but their efficacy and execution time are dependent on\nthe size of the network. Following recent work in simplifying these networks\nwith model pruning and a novel mapping of work onto GPUs, we design an\nefficient implementation for sparse RNNs. We investigate several optimizations\nand tradeoffs: Lamport timestamps, wide memory loads, and a bank-aware weight\nlayout. With these optimizations, we achieve speedups of over 6x over the next\nbest algorithm for a hidden layer of size 2304, batch size of 4, and a density\nof 30%. Further, our technique allows for models of over 5x the size to fit on\na GPU for a speedup of 2x, enabling larger networks to help advance the\nstate-of-the-art. We perform case studies on NMT and speech recognition tasks\nin the appendix, accelerating their recurrent layers by up to 3x.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 18:18:57 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Zhu", "Feiwen", ""], ["Pool", "Jeff", ""], ["Andersch", "Michael", ""], ["Appleyard", "Jeremy", ""], ["Xie", "Fung", ""]]}, {"id": "1804.10253", "submitter": "Elad Plaut", "authors": "Elad Plaut", "title": "From Principal Subspaces to Principal Components with Linear\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autoencoder is an effective unsupervised learning model which is widely\nused in deep learning. It is well known that an autoencoder with a single\nfully-connected hidden layer, a linear activation function and a squared error\ncost function trains weights that span the same subspace as the one spanned by\nthe principal component loading vectors, but that they are not identical to the\nloading vectors. In this paper, we show how to recover the loading vectors from\nthe autoencoder weights.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 19:28:02 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 20:23:27 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 19:02:12 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Plaut", "Elad", ""]]}, {"id": "1804.10266", "submitter": "Greg Ongie", "authors": "Greg Ongie, Daniel Pimentel-Alarc\\'on, Laura Balzano, Rebecca Willett,\n  Robert D. Nowak", "title": "Tensor Methods for Nonlinear Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the low-rank matrix completion (LRMC) problem, the low-rank assumption\nmeans that the columns (or rows) of the matrix to be completed are points on a\nlow-dimensional linear algebraic variety. This paper extends this thinking to\ncases where the columns are points on a low-dimensional nonlinear algebraic\nvariety, a problem we call Low Algebraic Dimension Matrix Completion (LADMC).\nMatrices whose columns belong to a union of subspaces are an important special\ncase. We propose a LADMC algorithm that leverages existing LRMC methods on a\ntensorized representation of the data. For example, a second-order tensorized\nrepresentation is formed by taking the Kronecker product of each column with\nitself, and we consider higher order tensorizations as well. This approach will\nsucceed in many cases where traditional LRMC is guaranteed to fail because the\ndata are low-rank in the tensorized representation but not in the original\nrepresentation. We provide a formal mathematical justification for the success\nof our method. In particular, we give bounds of the rank of these data in the\ntensorized representation, and we prove sampling requirements to guarantee\nuniqueness of the solution. We also provide experimental results showing that\nthe new approach outperforms existing state-of-the-art methods for matrix\ncompletion under a union of subspaces model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 20:00:42 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:45:52 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 22:03:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ongie", "Greg", ""], ["Pimentel-Alarc\u00f3n", "Daniel", ""], ["Balzano", "Laura", ""], ["Willett", "Rebecca", ""], ["Nowak", "Robert D.", ""]]}, {"id": "1804.10272", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Qian Yu, Ying Nian Wu", "title": "Network Transplanting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a new task, i.e., transplanting a\ncategory-and-task-specific neural network to a generic, modular network without\nstrong supervision. We design an functionally interpretable structure for the\ngeneric network. Like building LEGO blocks, we teach the generic network a new\ncategory by directly transplanting the module corresponding to the category\nfrom a pre-trained network with a few or even without sample annotations. Our\nmethod incrementally adds new categories to the generic network but does not\naffect representations of existing categories. In this way, our method breaks\nthe typical bottleneck of learning a net for massive tasks and categories, i.e.\nthe requirement of collecting samples for all tasks and categories at the same\ntime before the learning begins. Thus, we use a new distillation algorithm,\nnamely back-distillation, to overcome specific challenges of network\ntransplanting. Our method without training samples even outperformed the\nbaseline with 100 training samples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 20:25:36 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 05:18:29 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Yu", "Qian", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1804.10273", "submitter": "Daniel Reem", "authors": "Daniel Reem, Simeon Reich, Alvaro De Pierro", "title": "A telescoping Bregmanian proximal gradient method without the global\n  Lipschitz continuity assumption", "comments": "Journal of Optimization Theory and Applications (JOTA): accepted for\n  publication; very minor modifications; this version contains full proofs and\n  alphabetically ordered list of references (in contrast with the journal\n  version)", "journal-ref": "J. Optim. Theory. Appl. 182 (2019), 851--884", "doi": "10.1007/s10957-019-01509-8", "report-no": null, "categories": "math.OC cs.LG math.FA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of minimization of the sum of two convex functions has various\ntheoretical and real-world applications. One of the popular methods for solving\nthis problem is the proximal gradient method (proximal forward-backward\nalgorithm). A very common assumption in the use of this method is that the\ngradient of the smooth term is globally Lipschitz continuous. However, this\nassumption is not always satisfied in practice, thus casting a limitation on\nthe method. In this paper, we discuss, in a wide class of finite and\ninfinite-dimensional spaces, a new variant of the proximal gradient method\nwhich does not impose the above-mentioned global Lipschitz continuity\nassumption. A key contribution of the method is the dependence of the iterative\nsteps on a certain telescopic decomposition of the constraint set into subsets.\nMoreover, we use a Bregman divergence in the proximal forward-backward\noperation. Under certain practical conditions, a non-asymptotic rate of\nconvergence (that is, in the function values) is established, as well as the\nweak convergence of the whole sequence to a minimizer. We also obtain a few\nauxiliary results of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 17:20:58 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 22:13:44 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 20:58:27 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 11:11:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Reem", "Daniel", ""], ["Reich", "Simeon", ""], ["De Pierro", "Alvaro", ""]]}, {"id": "1804.10279", "submitter": "Sahil Garg", "authors": "Sahil Garg, Amarjeet Singh, Fabio Ramos", "title": "Adaptive Sensing for Learning Nonstationary Environment Models", "comments": "ArXiv version of the paper written in 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most environmental phenomena, such as wind profiles, ozone concentration and\nsunlight distribution under a forest canopy, exhibit nonstationary dynamics\ni.e. phenomenon variation change depending on the location and time of\noccurrence. Non-stationary dynamics pose both theoretical and practical\nchallenges to statistical machine learning algorithms aiming to accurately\ncapture the complexities governing the evolution of such processes. In this\npaper, we address the sampling aspects of the problem of learning nonstationary\nspatio-temporal models, and propose an efficient yet simple algorithm - LISAL.\nThe core idea in LISAL is to learn two models using Gaussian processes (GPs)\nwherein the first is a nonstationary GP directly modeling the phenomenon. The\nsecond model uses a stationary GP representing a latent space corresponding to\nchanges in dynamics, or the nonstationarity characteristics of the first model.\nLISAL involves adaptively sampling the latent space dynamics using information\ntheory quantities to reduce the computational cost during the learning phase.\nThe relevance of LISAL is extensively validated using multiple real world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 21:23:25 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Singh", "Amarjeet", ""], ["Ramos", "Fabio", ""]]}, {"id": "1804.10299", "submitter": "Hafiz Imtiaz", "authors": "Hafiz Imtiaz and Anand D. Sarwate", "title": "Distributed Differentially-Private Algorithms for Matrix and Tensor\n  Factorization", "comments": "39 pages, in review for publication", "journal-ref": "IEEE Journal of Selected Topics in Signal Proessing 2018", "doi": "10.1109/JSTSP.2018.2877842", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many signal processing and machine learning applications, datasets\ncontaining private information are held at different locations, requiring the\ndevelopment of distributed privacy-preserving algorithms. Tensor and matrix\nfactorizations are key components of many processing pipelines. In the\ndistributed setting, differentially private algorithms suffer because they\nintroduce noise to guarantee privacy. This paper designs new and improved\ndistributed and differentially private algorithms for two popular matrix and\ntensor factorization methods: principal component analysis (PCA) and orthogonal\ntensor decomposition (OTD). The new algorithms employ a correlated noise design\nscheme to alleviate the effects of noise and can achieve the same noise level\nas the centralized scenario. Experiments on synthetic and real data illustrate\nthe regimes in which the correlated noise allows performance matching with the\ncentralized setting, outperforming previous methods and demonstrating that\nmeaningful utility is possible while guaranteeing differential privacy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 22:40:35 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Imtiaz", "Hafiz", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1804.10318", "submitter": "Sahil Garg", "authors": "Sahil Garg", "title": "Efficiently Learning Nonstationary Gaussian Processes for Real World\n  Impact", "comments": "Draft is not suitable for public view at present. It requires\n  significant additions of experiment results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real world phenomena such as sunlight distribution under a forest\ncanopy, minerals concentration, stock valuation, exhibit nonstationary dynamics\ni.e. phenomenon variation changes depending on the locality. Nonstationary\ndynamics pose both theoretical and practical challenges to statistical machine\nlearning algorithms that aim to accurately capture the complexities governing\nthe evolution of such processes. Typically the nonstationary dynamics are\nmodeled using nonstationary Gaussian Process models (NGPS) that employ local\nlatent dynamics parameterization to correspondingly model the nonstationary\nreal observable dynamics. Recently, an approach based on most likely induced\nlatent dynamics representation attracted research community's attention for a\nwhile. The approach could not be employed for large scale real world\napplications because learning a most likely latent dynamics representation\ninvolves maximization of marginal likelihood of the observed real dynamics that\nbecomes intractable as the number of induced latent points grows with problem\nsize. We have established a direct relationship between informativeness of the\ninduced latent dynamics and the marginal likelihood of the observed real\ndynamics. This opens up the possibility of maximizing marginal likelihood of\nobserved real dynamics indirectly by near optimally maximizing entropy or\nmutual information gain on the induced latent dynamics using greedy algorithms.\nTherefore, for an efficient yet accurate inference, we propose to build an\ninduced latent dynamics representation using a novel algorithm LISAL that\nadaptively maximizes entropy or mutual information on the induced latent\ndynamics and marginal likelihood of observed real dynamics in an iterative\nmanner. The relevance of LISAL is validated using real world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 01:25:41 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 01:07:07 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 09:29:20 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Garg", "Sahil", ""]]}, {"id": "1804.10322", "submitter": "Eric Plourde", "authors": "Marc-Antoine Moinnereau, Thomas Brienne, Simon Brodeur, Jean Rouat,\n  Kevin Whittingstall and Eric Plourde", "title": "Classification of auditory stimuli from EEG signals with a regulated\n  recurrent neural network reservoir", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of electroencephalogram (EEG) as the main input signal in\nbrain-machine interfaces has been widely proposed due to the non-invasive\nnature of the EEG. Here we are specifically interested in interfaces that\nextract information from the auditory system and more specifically in the task\nof classifying heard speech from EEGs. To do so, we propose to limit the\npreprocessing of the EEGs and use machine learning approaches to automatically\nextract their meaningful characteristics. More specifically, we use a regulated\nrecurrent neural network (RNN) reservoir, which has been shown to outperform\nclassic machine learning approaches when applied to several different\nbio-signals, and we compare it with a deep neural network approach. Moreover,\nwe also investigate the classification performance as a function of the number\nof EEG electrodes. A set of 8 subjects were presented randomly with 3 different\nauditory stimuli (English vowels a, i and u). We obtained an excellent\nclassification rate of 83.2% with the RNN when considering all 64 electrodes. A\nrate of 81.7% was achieved with only 10 electrodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 02:10:29 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Moinnereau", "Marc-Antoine", ""], ["Brienne", "Thomas", ""], ["Brodeur", "Simon", ""], ["Rouat", "Jean", ""], ["Whittingstall", "Kevin", ""], ["Plourde", "Eric", ""]]}, {"id": "1804.10328", "submitter": "Yichen Chen", "authors": "Yichen Chen, Lihong Li, Mengdi Wang", "title": "Scalable Bilinear $\\pi$ Learning Using State and Action Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate linear programming (ALP) represents one of the major algorithmic\nfamilies to solve large-scale Markov decision processes (MDP). In this work, we\nstudy a primal-dual formulation of the ALP, and develop a scalable, model-free\nalgorithm called bilinear $\\pi$ learning for reinforcement learning when a\nsampling oracle is provided. This algorithm enjoys a number of advantages.\nFirst, it adopts (bi)linear models to represent the high-dimensional value\nfunction and state-action distributions, using given state and action features.\nIts run-time complexity depends on the number of features, not the size of the\nunderlying MDPs. Second, it operates in a fully online fashion without having\nto store any sample, thus having minimal memory footprint. Third, we prove that\nit is sample-efficient, solving for the optimal policy to high precision with a\nsample complexity linear in the dimension of the parameter space.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 02:32:18 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Yichen", ""], ["Li", "Lihong", ""], ["Wang", "Mengdi", ""]]}, {"id": "1804.10388", "submitter": "Elias Alevizos", "authors": "Elias Alevizos, Alexander Artikis, Georgios Paliouras", "title": "Event Forecasting with Pattern Markov Chains", "comments": null, "journal-ref": null, "doi": "10.1145/3093742.3093920", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for online probabilistic event forecasting. We assume\nthat a user is interested in detecting and forecasting event patterns, given in\nthe form of regular expressions. Our system can consume streams of events and\nforecast when the pattern is expected to be fully matched. As more events are\nconsumed, the system revises its forecasts to reflect possible changes in the\nstate of the pattern. The framework of Pattern Markov Chains is used in order\nto learn a probabilistic model for the pattern, with which forecasts with\nguaranteed precision may be produced, in the form of intervals within which a\nfull match is expected. Experimental results from real-world datasets are shown\nand the quality of the produced forecasts is explored, using both precision\nscores and two other metrics: spread, which refers to the \"focusing resolution\"\nof a forecast (interval length), and distance, which captures how early a\nforecast is reported.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 08:33:12 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Alevizos", "Elias", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1804.10390", "submitter": "Masanori Onishi", "authors": "Masanori Onishi, Takeshi Ise", "title": "Automatic classification of trees using a UAV onboard camera and deep\n  learning", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic classification of trees using remotely sensed data has been a dream\nof many scientists and land use managers. Recently, Unmanned aerial vehicles\n(UAV) has been expected to be an easy-to-use, cost-effective tool for remote\nsensing of forests, and deep learning has attracted attention for its ability\nconcerning machine vision. In this study, using a commercially available UAV\nand a publicly available package for deep learning, we constructed a machine\nvision system for the automatic classification of trees. In our method, we\nsegmented a UAV photography image of forest into individual tree crowns and\ncarried out object-based deep learning. As a result, the system was able to\nclassify 7 tree types at 89.0% accuracy. This performance is notable because we\nonly used basic RGB images from a standard UAV. In contrast, most of previous\nstudies used expensive hardware such as multispectral imagers to improve the\nperformance. This result means that our method has the potential to classify\nindividual trees in a cost-effective manner. This can be a usable tool for many\nforest researchers and managements.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 08:38:22 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Onishi", "Masanori", ""], ["Ise", "Takeshi", ""]]}, {"id": "1804.10454", "submitter": "Andreas Meinel", "authors": "Andreas Meinel, Henrich Kolkhorst, Michael Tangermann", "title": "Mining within-trial oscillatory brain dynamics to address the\n  variability of optimized spatial filters", "comments": null, "journal-ref": null, "doi": "10.1109/TNSRE.2019.2894914", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven spatial filtering algorithms optimize scores such as the contrast\nbetween two conditions to extract oscillatory brain signal components. Most\nmachine learning approaches for filter estimation, however, disregard\nwithin-trial temporal dynamics and are extremely sensitive to changes in\ntraining data and involved hyperparameters. This leads to highly variable\nsolutions and impedes the selection of a suitable candidate for,\ne.g.,~neurotechnological applications. Fostering component introspection, we\npropose to embrace this variability by condensing the functional signatures of\na large set of oscillatory components into homogeneous clusters, each\nrepresenting specific within-trial envelope dynamics.\n  The proposed method is exemplified by and evaluated on a complex hand force\ntask with a rich within-trial structure. Based on electroencephalography data\nof 18 healthy subjects, we found that the components' distinct temporal\nenvelope dynamics are highly subject-specific. On average, we obtained seven\nclusters per subject, which were strictly confined regarding their underlying\nfrequency bands. As the analysis method is not limited to a specific spatial\nfiltering algorithm, it could be utilized for a wide range of\nneurotechnological applications, e.g., to select and monitor functionally\nrelevant features for brain-computer interface protocols in stroke\nrehabilitation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:56:04 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 11:39:50 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Meinel", "Andreas", ""], ["Kolkhorst", "Henrich", ""], ["Tangermann", "Michael", ""]]}, {"id": "1804.10488", "submitter": "Shuai Li", "authors": "Shuai Li, Yasin Abbasi-Yadkori, Branislav Kveton, S. Muthukrishnan,\n  Vishwa Vinay, Zheng Wen", "title": "Offline Evaluation of Ranking Policies with Click Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many web systems rank and present a list of items to users, from recommender\nsystems to search and advertising. An important problem in practice is to\nevaluate new ranking policies offline and optimize them before they are\ndeployed. We address this problem by proposing evaluation algorithms for\nestimating the expected number of clicks on ranked lists from historical logged\ndata. The existing algorithms are not guaranteed to be statistically efficient\nin our problem because the number of recommended lists can grow exponentially\nwith their length. To overcome this challenge, we use models of user\ninteraction with the list of items, the so-called click models, to construct\nestimators that learn statistically efficiently. We analyze our estimators and\nprove that they are more efficient than the estimators that do not use the\nstructure of the click model, under the assumption that the click model holds.\nWe evaluate our estimators in a series of experiments on a real-world dataset\nand show that they consistently outperform prior estimators.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:19:34 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 18:15:29 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Li", "Shuai", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Kveton", "Branislav", ""], ["Muthukrishnan", "S.", ""], ["Vinay", "Vishwa", ""], ["Wen", "Zheng", ""]]}, {"id": "1804.10500", "submitter": "Xi Chen", "authors": "Xi Chen, Ali Ghadirzadeh, John Folkesson and Patric Jensfelt", "title": "Deep Reinforcement Learning to Acquire Navigation Skills for\n  Wheel-Legged Robots in Complex Environments", "comments": "Submitted to IROS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robot navigation in complex and dynamic environments is a challenging\nbut important problem. Reinforcement learning approaches fail to solve these\ntasks efficiently due to reward sparsities, temporal complexities and\nhigh-dimensionality of sensorimotor spaces which are inherent in such problems.\nWe present a novel approach to train action policies to acquire navigation\nskills for wheel-legged robots using deep reinforcement learning. The policy\nmaps height-map image observations to motor commands to navigate to a target\nposition while avoiding obstacles. We propose to acquire the multifaceted\nnavigation skill by learning and exploiting a number of manageable navigation\nbehaviors. We also introduce a domain randomization technique to improve the\nversatility of the training samples. We demonstrate experimentally a\nsignificant improvement in terms of data-efficiency, success rate, robustness\nagainst irrelevant sensory data, and also the quality of the maneuver skills.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:40:20 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Xi", ""], ["Ghadirzadeh", "Ali", ""], ["Folkesson", "John", ""], ["Jensfelt", "Patric", ""]]}, {"id": "1804.10520", "submitter": "Matthew England Dr", "authors": "Zongyan Huang, Matthew England, David Wilson, James H. Davenport, and\n  Lawrence C. Paulson", "title": "Using Machine Learning to Improve Cylindrical Algebraic Decomposition", "comments": "arXiv admin note: text overlap with arXiv:1608.04219, arXiv:1404.6369", "journal-ref": "Mathematics in Computer Science, 13:4, pp. 461 - 488, Springer,\n  2019", "doi": "10.1007/s11786-019-00394-8", "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cylindrical Algebraic Decomposition (CAD) is a key tool in computational\nalgebraic geometry, best known as a procedure to enable Quantifier Elimination\nover real-closed fields. However, it has a worst case complexity doubly\nexponential in the size of the input, which is often encountered in practice.\nIt has been observed that for many problems a change in algorithm settings or\nproblem formulation can cause huge differences in runtime costs, changing\nproblem instances from intractable to easy. A number of heuristics have been\ndeveloped to help with such choices, but the complicated nature of the\ngeometric relationships involved means these are imperfect and can sometimes\nmake poor choices. We investigate the use of machine learning (specifically\nsupport vector machines) to make such choices instead.\n  Machine learning is the process of fitting a computer model to a complex\nfunction based on properties learned from measured data. In this paper we apply\nit in two case studies: the first to select between heuristics for choosing a\nCAD variable ordering; the second to identify when a CAD problem instance would\nbenefit from Groebner Basis preconditioning. These appear to be the first such\napplications of machine learning to Symbolic Computation. We demonstrate in\nboth cases that the machine learned choice outperforms human developed\nheuristics.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:56:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Huang", "Zongyan", ""], ["England", "Matthew", ""], ["Wilson", "David", ""], ["Davenport", "James H.", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "1804.10535", "submitter": "Sahil Garg", "authors": "Sahil Garg and Amarjeet Singh and Fabio Ramos", "title": "Learning Non-Stationary Space-Time Models for Environmental Monitoring", "comments": "AAAI-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary aspects of sustainable development involves accurate\nunderstanding and modeling of environmental phenomena. Many of these phenomena\nexhibit variations in both space and time and it is imperative to develop a\ndeeper understanding of techniques that can model space-time dynamics\naccurately. In this paper we propose NOSTILL-GP - NOn-stationary Space TIme\nvariable Latent Length scale GP, a generic non-stationary, spatio-temporal\nGaussian Process (GP) model. We present several strategies, for efficient\ntraining of our model, necessary for real-world applicability. Extensive\nempirical validation is performed using three real-world environmental\nmonitoring datasets, with diverse dynamics across space and time. Results from\nthe experiments clearly demonstrate general applicability and effectiveness of\nour approach for applications in environmental monitoring.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:45:11 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Singh", "Amarjeet", ""], ["Ramos", "Fabio", ""]]}, {"id": "1804.10544", "submitter": "Sahil Garg", "authors": "Sahil Garg and Nora Ayanian", "title": "Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a\n  Small Team of Robots", "comments": "Robotics Science and Systems, 2014 (RSS-14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a solution for persistent monitoring of real-world\nstochastic phenomena, where the underlying covariance structure changes sharply\nacross time, using a small number of mobile robot sensors. We propose an\nadaptive solution for the problem where stochastic real-world dynamics are\nmodeled as a Gaussian Process (GP). The belief on the underlying covariance\nstructure is learned from recently observed dynamics as a Gaussian Mixture (GM)\nin the low-dimensional hyper-parameters space of the GP and adapted across time\nusing Sequential Monte Carlo methods. Each robot samples a belief point from\nthe GM and locally optimizes a set of informative regions by greedy\nmaximization of the submodular entropy function. The key contributions of this\npaper are threefold: adapting the belief on the covariance using Markov Chain\nMonte Carlo (MCMC) sampling such that particles survive even under sharp\ncovariance changes across time; exploiting the belief to transform the problem\nof entropy maximization into a decentralized one; and developing an\napproximation algorithm to maximize entropy on a set of informative regions in\nthe continuous space. We illustrate the application of the proposed solution\nthrough extensive simulations using an artificial dataset and multiple real\ndatasets from fixed sensor deployments, and compare it to three competing\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:55:38 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Ayanian", "Nora", ""]]}, {"id": "1804.10574", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Qian Yang, Heng Huang", "title": "Decoupled Parallel Backpropagation with Convergence Guarantee", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation algorithm is indispensable for the training of feedforward\nneural networks. It requires propagating error gradients sequentially from the\noutput layer all the way back to the input layer. The backward locking in\nbackpropagation algorithm constrains us from updating network layers in\nparallel and fully leveraging the computing resources. Recently, several\nalgorithms have been proposed for breaking the backward locking. However, their\nperformances degrade seriously when networks are deep. In this paper, we\npropose decoupled parallel backpropagation algorithm for deep learning\noptimization with convergence guarantee. Firstly, we decouple the\nbackpropagation algorithm using delayed gradients, and show that the backward\nlocking is removed when we split the networks into multiple modules. Then, we\nutilize decoupled parallel backpropagation in two stochastic methods and prove\nthat our method guarantees convergence to critical points for the non-convex\nproblem. Finally, we perform experiments for training deep convolutional neural\nnetworks on benchmark datasets. The experimental results not only confirm our\ntheoretical analysis, but also demonstrate that the proposed method can achieve\nsignificant speedup without loss of accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:05:26 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 07:32:15 GMT"}, {"version": "v3", "created": "Sat, 21 Jul 2018 17:02:49 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Yang", "Qian", ""], ["Huang", "Heng", ""]]}, {"id": "1804.10587", "submitter": "Sebastian Bock", "authors": "Sebastian Bock, Josef Goppold, Martin Wei{\\ss}", "title": "An improvement of the convergence proof of the ADAM-Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common way to train neural networks is the Backpropagation. This algorithm\nincludes a gradient descent method, which needs an adaptive step size. In the\narea of neural networks, the ADAM-Optimizer is one of the most popular adaptive\nstep size methods. It was invented in \\cite{Kingma.2015} by Kingma and Ba. The\n$5865$ citations in only three years shows additionally the importance of the\ngiven paper. We discovered that the given convergence proof of the optimizer\ncontains some mistakes, so that the proof will be wrong. In this paper we give\nan improvement to the convergence proof of the ADAM-Optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:53:51 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Bock", "Sebastian", ""], ["Goppold", "Josef", ""], ["Wei\u00df", "Martin", ""]]}, {"id": "1804.10653", "submitter": "Maxim Panov", "authors": "Ivan Nazarov, Boris Shirokikh, Maria Burkina, Gennady Fedonin and\n  Maxim Panov", "title": "Sparse Group Inductive Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of matrix completion with side information\n(\\textit{inductive matrix completion}). In real-world applications many\nside-channel features are typically non-informative making feature selection an\nimportant part of the problem. We incorporate feature selection into inductive\nmatrix completion by proposing a matrix factorization framework with\ngroup-lasso regularization on side feature parameter matrices. We demonstrate,\nthat the theoretical sample complexity for the proposed method is much lower\ncompared to its competitors in sparse problems, and propose an efficient\noptimization algorithm for the resulting low-rank matrix completion problem\nwith sparsifying regularizers. Experiments on synthetic and real-world datasets\nshow that the proposed approach outperforms other methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 19:16:46 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 17:31:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Nazarov", "Ivan", ""], ["Shirokikh", "Boris", ""], ["Burkina", "Maria", ""], ["Fedonin", "Gennady", ""], ["Panov", "Maxim", ""]]}, {"id": "1804.10689", "submitter": "Amy Zhang", "authors": "Amy Zhang, Harsh Satija and Joelle Pineau", "title": "Decoupling Dynamics and Reward for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning (RL) methods can successfully learn single\ntasks but often generalize poorly to modest perturbations in task domain or\ntraining procedure. In this work, we present a decoupled learning strategy for\nRL that creates a shared representation space where knowledge can be robustly\ntransferred. We separate learning the task representation, the forward\ndynamics, the inverse dynamics and the reward function of the domain, and show\nthat this decoupling improves performance within the task, transfers well to\nchanges in dynamics and reward, and can be effectively used for online\nplanning. Empirical results show good performance in both continuous and\ndiscrete RL domains.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:16:40 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 02:02:28 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Amy", ""], ["Satija", "Harsh", ""], ["Pineau", "Joelle", ""]]}, {"id": "1804.10690", "submitter": "Yao Hengshuai", "authors": "Donglai Zhu, Hengshuai Yao, Bei Jiang, Peng Yu", "title": "Negative Log Likelihood Ratio Loss for Deep Neural Network\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural network, the cross-entropy loss function is commonly used for\nclassification. Minimizing cross-entropy is equivalent to maximizing likelihood\nunder assumptions of uniform feature and class distributions. It belongs to\ngenerative training criteria which does not directly discriminate correct class\nfrom competing classes. We propose a discriminative loss function with negative\nlog likelihood ratio between correct and competing classes. It significantly\noutperforms the cross-entropy loss on the CIFAR-10 image classification task.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:24:59 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhu", "Donglai", ""], ["Yao", "Hengshuai", ""], ["Jiang", "Bei", ""], ["Yu", "Peng", ""]]}, {"id": "1804.10742", "submitter": "Igor Gitman", "authors": "Igor Gitman, Jieshi Chen, Eric Lei, Artur Dubrawski", "title": "Novel Prediction Techniques Based on Clusterwise Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore different regression models based on Clusterwise\nLinear Regression (CLR). CLR aims to find the partition of the data into $k$\nclusters, such that linear regressions fitted to each of the clusters minimize\noverall mean squared error on the whole data. The main obstacle preventing to\nuse found regression models for prediction on the unseen test points is the\nabsence of a reasonable way to obtain CLR cluster labels when the values of\ntarget variable are unknown. In this paper we propose two novel approaches on\nhow to solve this problem. The first approach, predictive CLR builds a separate\nclassification model to predict test CLR labels. The second approach,\nconstrained CLR utilizes a set of user-specified constraints that enforce\ncertain points to go to the same clusters. Assuming the constraint values are\nknown for the test points, they can be directly used to assign CLR labels. We\nevaluate these two approaches on three UCI ML datasets as well as on a large\ncorpus of health insurance claims. We show that both of the proposed algorithms\nsignificantly improve over the known CLR-based regression methods. Moreover,\npredictive CLR consistently outperforms linear regression and random forest,\nand shows comparable performance to support vector regression on UCI ML\ndatasets. The constrained CLR approach achieves the best performance on the\nhealth insurance dataset, while enjoying only $\\approx 20$ times increased\ncomputational time over linear regression.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 05:07:42 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Gitman", "Igor", ""], ["Chen", "Jieshi", ""], ["Lei", "Eric", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1804.10745", "submitter": "Vihari Piratla Mr.", "authors": "Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha\n  Chaudhuri, Preethi Jyothi, Sunita Sarawagi", "title": "Generalizing Across Domains via Cross-Gradient Training", "comments": "The first two authors contributed equally; Accepted at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CROSSGRAD, a method to use multi-domain training data to learn a\nclassifier that generalizes to new domains. CROSSGRAD does not need an\nadaptation phase via labeled or unlabeled data, or domain features in the new\ndomain. Most existing domain adaptation methods attempt to erase domain signals\nusing techniques like domain adversarial training. In contrast, CROSSGRAD is\nfree to use domain signals for predicting labels, if it can prevent overfitting\non training domains. We conceptualize the task in a Bayesian setting, in which\na sampling step is implemented as data augmentation, based on domain-guided\nperturbations of input instances. CROSSGRAD parallelly trains a label and a\ndomain classifier on examples perturbed by loss gradients of each other's\nobjectives. This enables us to directly perturb inputs, without separating and\nre-mixing domain signals while making various distributional assumptions.\nEmpirical evaluation on three different applications where this setting is\nnatural establishes that (1) domain-guided perturbation provides consistently\nbetter generalization to unseen domains, compared to generic instance\nperturbation methods, and that (2) data augmentation is a more stable and\naccurate method than domain adversarial training.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 05:20:53 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 05:51:52 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Shankar", "Shiv", ""], ["Piratla", "Vihari", ""], ["Chakrabarti", "Soumen", ""], ["Chaudhuri", "Siddhartha", ""], ["Jyothi", "Preethi", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1804.10776", "submitter": "Anees Kazi", "authors": "Anees Kazi, Shadi Albarqouni, Karsten Kortuem, Nassir Navab", "title": "Multi Layered-Parallel Graph Convolutional Network (ML-PGCN) for Disease\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural data from Electronic Health Records as complementary information\nto imaging data for disease prediction. We incorporate novel weighting layer\ninto the Graph Convolutional Networks, which weights every element of\nstructural data by exploring its relation to the underlying disease. We\ndemonstrate the superiority of our developed technique in terms of\ncomputational speed and obtained encouraging results where our method\noutperforms the state-of-the-art methods when applied to two publicly available\ndatasets ABIDE and Chest X-ray in terms of relative performance for the\naccuracy of prediction by 5.31 % and 8.15 % and for the area under the ROC\ncurve by 4.96 % and 10.36 % respectively. Additionally, the model is\nlightweight, fast and easily trainable.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 09:50:21 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kazi", "Anees", ""], ["Albarqouni", "Shadi", ""], ["Kortuem", "Karsten", ""], ["Navab", "Nassir", ""]]}, {"id": "1804.10801", "submitter": "Chong Zhang", "authors": "Chong Zhang, Kay Chen Tan, Haizhou Li, and Geok Soon Hong", "title": "A Cost-Sensitive Deep Belief Network for Imbalanced Classification", "comments": "13 pages, 9 figures, accepted by IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imbalanced data with a skewed class distribution are common in many\nreal-world applications. Deep Belief Network (DBN) is a machine learning\ntechnique that is effective in classification tasks. However, conventional DBN\ndoes not work well for imbalanced data classification because it assumes equal\ncosts for each class. To deal with this problem, cost-sensitive approaches\nassign different misclassification costs for different classes without\ndisrupting the true data sample distributions. However, due to lack of prior\nknowledge, the misclassification costs are usually unknown and hard to choose\nin practice. Moreover, it has not been well studied as to how cost-sensitive\nlearning could improve DBN performance on imbalanced data problems. This paper\nproposes an evolutionary cost-sensitive deep belief network (ECS-DBN) for\nimbalanced classification. ECS-DBN uses adaptive differential evolution to\noptimize the misclassification costs based on training data, that presents an\neffective approach to incorporating the evaluation measure (i.e. G-mean) into\nthe objective function. We first optimize the misclassification costs, then\napply them to deep belief network. Adaptive differential evolution optimization\nis implemented as the optimization algorithm that automatically updates its\ncorresponding parameters without the need of prior domain knowledge. The\nexperiments have shown that the proposed approach consistently outperforms the\nstate-of-the-art on both benchmark datasets and real-world dataset for fault\ndiagnosis in tool condition monitoring.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 13:31:45 GMT"}, {"version": "v2", "created": "Sat, 5 May 2018 04:19:23 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zhang", "Chong", ""], ["Tan", "Kay Chen", ""], ["Li", "Haizhou", ""], ["Hong", "Geok Soon", ""]]}, {"id": "1804.10821", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "On Convergence of Moments for Approximating Processes and Applications\n  to Surrogate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study critera for a pair $ (\\{ X_n \\} $, $ \\{ Y_n \\}) $ of approximating\nprocesses which guarantee closeness of moments by generalizing known results\nfor the special case that $ Y_n = Y $ for all $n$ and $ X_n $ converges to $Y$\nin probability. This problem especially arises when working with surrogate\nmodels, e.g. to enrich observed data by simulated data, where the surrogates\n$Y_n$'s are constructed to justify that they approximate the $ X_n $'s.\n  The results of this paper deal with sequences of random variables. Since this\nframework does not cover many applications where surrogate models such as deep\nneural networks are used to approximate more general stochastic processes, we\nextend the results to the more general framework of random fields of stochastic\nprocesses. This framework especially covers image data and sequences of images.\nWe show that uniform integrability is sufficient, and this holds even for the\ncase of processes provided they satisfy a weak stationarity condition.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 15:36:56 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1804.10827", "submitter": "Apoorv Vikram Singh", "authors": "Amit Deshpande, Anand Louis, Apoorv Vikram Singh", "title": "On Euclidean $k$-Means Clustering with $\\alpha$-Center Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-means clustering is NP-hard in the worst case but previous work has shown\nefficient algorithms assuming the optimal $k$-means clusters are \\emph{stable}\nunder additive or multiplicative perturbation of data. This has two caveats.\nFirst, we do not know how to efficiently verify this property of optimal\nsolutions that are NP-hard to compute in the first place. Second, the stability\nassumptions required for polynomial time $k$-means algorithms are often\nunreasonable when compared to the ground-truth clusters in real-world data. A\nconsequence of multiplicative perturbation resilience is \\emph{center\nproximity}, that is, every point is closer to the center of its own cluster\nthan the center of any other cluster, by some multiplicative factor $\\alpha >\n1$.\n  We study the problem of minimizing the Euclidean $k$-means objective only\nover clusterings that satisfy $\\alpha$-center proximity. We give a simple\nalgorithm to find the optimal $\\alpha$-center-proximal $k$-means clustering in\nrunning time exponential in $k$ and $1/(\\alpha - 1)$ but linear in the number\nof points and the dimension. We define an analogous $\\alpha$-center proximity\ncondition for outliers, and give similar algorithmic guarantees for $k$-means\nwith outliers and $\\alpha$-center proximity. On the hardness side we show that\nfor any $\\alpha' > 1$, there exists an $\\alpha \\leq \\alpha'$, $(\\alpha >1)$,\nand an $\\varepsilon_0 > 0$ such that minimizing the $k$-means objective over\nclusterings that satisfy $\\alpha$-center proximity is NP-hard to approximate\nwithin a multiplicative $(1+\\varepsilon_0)$ factor.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 16:17:15 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 13:09:19 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 12:49:55 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Deshpande", "Amit", ""], ["Louis", "Anand", ""], ["Singh", "Apoorv Vikram", ""]]}, {"id": "1804.10834", "submitter": "Sridhar Mahadevan", "authors": "Sridhar Mahadevan and Bamdev Mishra and Shalini Ghosh", "title": "A Unified Framework for Domain Adaptation using Metric Learning on\n  Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for domain adaptation, whereby both geometric\nand statistical differences between a labeled source domain and unlabeled\ntarget domain can be integrated by exploiting the curved Riemannian geometry of\nstatistical manifolds. Our approach is based on formulating transfer from\nsource to target as a problem of geometric mean metric learning on manifolds.\nSpecifically, we exploit the curved Riemannian manifold geometry of symmetric\npositive definite (SPD) covariance matrices. We exploit a simple but important\nobservation that as the space of covariance matrices is both a Riemannian space\nas well as a homogeneous space, the shortest path geodesic between two\ncovariances on the manifold can be computed analytically. Statistics on the SPD\nmatrix manifold, such as the geometric mean of two matrices can be reduced to\nsolving the well-known Riccati equation. We show how the Ricatti-based solution\ncan be constrained to not only reduce the statistical differences between the\nsource and target domains, such as aligning second order covariances and\nminimizing the maximum mean discrepancy, but also the underlying geometry of\nthe source and target domains using diffusions on the underlying source and\ntarget manifolds. A key strength of our proposed approach is that it enables\nintegrating multiple sources of variation between source and target in a\nunified way, by reducing the combined objective function to a nested set of\nRicatti equations where the solution can be represented by a cascaded series of\ngeometric mean computations. In addition to showing the theoretical optimality\nof our solution, we present detailed experiments using standard transfer\nlearning testbeds from computer vision comparing our proposed algorithms to\npast work in domain adaptation, showing improved results over a large variety\nof previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 17:41:27 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Mahadevan", "Sridhar", ""], ["Mishra", "Bamdev", ""], ["Ghosh", "Shalini", ""]]}, {"id": "1804.10839", "submitter": "Jefferson Hern\\'andez Enrique", "authors": "Jefferson Hernandez and Andres G. Abad", "title": "Learning from multivariate discrete sequential data using a restricted\n  Boltzmann machine model", "comments": "6 pages, 3 figures, Accepted as conference paper in IEEE-COLCACI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A restricted Boltzmann machine (RBM) is a generative neural-network model\nwith many novel applications such as collaborative filtering and acoustic\nmodeling. An RBM lacks the capacity to retain memory, making it inappropriate\nfor dynamic data modeling as in time-series analysis. In this paper we address\nthis issue by proposing the p-RBM model, a generalization of the regular RBM\nmodel, capable of retaining memory of p past states. We further show how to\ntrain the p-RBM model using contrastive divergence and test our model on the\nproblem of predicting the stock market direction considering 100 stocks of the\nNASDAQ-100 index. Obtained results show that the p-RBM offer promising\nprediction potential.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 18:38:27 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hernandez", "Jefferson", ""], ["Abad", "Andres G.", ""]]}, {"id": "1804.10846", "submitter": "Miguel Hernan", "authors": "Miguel A. Hern\\'an, John Hsu, Brian Healy", "title": "Data science is science's second chance to get causal inference right: A\n  classification of data science tasks", "comments": null, "journal-ref": "Chance 32(1):42-49 (2019)", "doi": "10.1080/09332480.2019.1579578", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observational data is the goal of many data analyses in\nthe health and social sciences. However, academic statistics has often frowned\nupon data analyses with a causal objective. The introduction of the term \"data\nscience\" provides a historic opportunity to redefine data analysis in such a\nway that it naturally accommodates causal inference from observational data.\nLike others before, we organize the scientific contributions of data science\ninto three classes of tasks: Description, prediction, and counterfactual\nprediction (which includes causal inference). An explicit classification of\ndata science tasks is necessary to discuss the data, assumptions, and analytics\nrequired to successfully accomplish each task. We argue that a failure to\nadequately describe the role of subject-matter expert knowledge in data\nanalysis is a source of widespread misunderstandings about data science.\nSpecifically, causal analyses typically require not only good data and\nalgorithms, but also domain expert knowledge. We discuss the implications for\nthe use of data science to guide decision-making in the real world and to train\ndata scientists.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 20:23:45 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 00:24:09 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 03:25:08 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 10:26:31 GMT"}, {"version": "v5", "created": "Tue, 9 Oct 2018 19:01:23 GMT"}, {"version": "v6", "created": "Sun, 7 Apr 2019 03:10:51 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Hern\u00e1n", "Miguel A.", ""], ["Hsu", "John", ""], ["Healy", "Brian", ""]]}, {"id": "1804.10850", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Cao Xiao, Jiayu Zhou, Fei Wang", "title": "Drug Similarity Integration Through Attentive Multi-view Graph\n  Auto-Encoders", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug similarity has been studied to support downstream clinical tasks such as\ninferring novel properties of drugs (e.g. side effects, indications,\ninteractions) from known properties. The growing availability of new types of\ndrug features brings the opportunity of learning a more comprehensive and\naccurate drug similarity that represents the full spectrum of underlying drug\nrelations. However, it is challenging to integrate these heterogeneous, noisy,\nnonlinear-related information to learn accurate similarity measures especially\nwhen labels are scarce. Moreover, there is a trade-off between accuracy and\ninterpretability. In this paper, we propose to learn accurate and interpretable\nsimilarity measures from multiple types of drug features. In particular, we\nmodel the integration using multi-view graph auto-encoders, and add attentive\nmechanism to determine the weights for each view with respect to corresponding\ntasks and features for better interpretability. Our model has flexible design\nfor both semi-supervised and unsupervised settings. Experimental results\ndemonstrated significant predictive accuracy improvement. Case studies also\nshowed better model capacity (e.g. embed node features) and interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 22:14:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ma", "Tengfei", ""], ["Xiao", "Cao", ""], ["Zhou", "Jiayu", ""], ["Wang", "Fei", ""]]}, {"id": "1804.10885", "submitter": "Haiyang Wang", "authors": "Haiyang Wang, Yong Tang, Ziyang Jia, Fei Ye", "title": "Dense Adaptive Cascade Forest: A Self Adaptive Deep Ensemble for\n  Classification Problems", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches have shown that deep forest ensemble achieves a\nconsiderable increase in classification accuracy compared with the general\nensemble learning methods, especially when the training set is small. In this\npaper, we take advantage of deep forest ensemble and introduce the Dense\nAdaptive Cascade Forest (daForest). Our model has a better performance than the\noriginal Cascade Forest with three major features: first, we apply SAMME.R\nboosting algorithm to improve the performance of the model. It guarantees the\nimprovement as the number of layers increases. Second, our model connects each\nlayer to the subsequent ones in a feed-forward fashion, which enhances the\ncapability of the model to resist performance degeneration. Third, we add a\nhyper-parameters optimization layer before the first classification layer,\nmaking our model spend less time to set up and find the optimal\nhyper-parameters. Experimental results show that daForest performs\nsignificantly well, and in some cases, even outperforms neural networks and\nachieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 07:46:22 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 07:22:59 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 16:42:32 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 16:54:01 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 06:24:39 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wang", "Haiyang", ""], ["Tang", "Yong", ""], ["Jia", "Ziyang", ""], ["Ye", "Fei", ""]]}, {"id": "1804.10905", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani, and Vasile Palade", "title": "An Investigation on Support Vector Clustering for Big Data in Quantum\n  Paradigm", "comments": null, "journal-ref": "Quantum Information Processing volume 19, Article number: 108\n  (2020)", "doi": "10.1007/s11128-020-2606-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector clustering algorithm is a well-known clustering algorithm\nbased on support vector machines using Gaussian or polynomial kernels. The\nclassical support vector clustering algorithm works well in general, but its\nperformance degrades when applied on big data. In this paper, we have\ninvestigated the performance of support vector clustering algorithm implemented\nin a quantum paradigm for possible run-time improvements. We have developed and\nanalyzed a quantum version of the support vector clustering algorithm. The\nproposed approach is based on the quantum support vector machine and quantum\nkernels (i.e., Gaussian and polynomial). The proposed quantum version of the\nSVM clustering method demonstrates a significant speed-up gain on the overall\nrun-time complexity as compared to the classical counterpart.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 11:09:40 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 12:42:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "1804.10942", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, HyungSeok Song, Yung Yi", "title": "Learning Data Dependency with Communication Cost", "comments": "33 pages, to appear at MobiHoc'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of recovering a graph that represents\nthe statistical data dependency among nodes for a set of data samples generated\nby nodes, which provides the basic structure to perform an inference task, such\nas MAP (maximum a posteriori). This problem is referred to as structure\nlearning. When nodes are spatially separated in different locations, running an\ninference algorithm requires a non-negligible amount of message passing,\nincurring some communication cost. We inevitably have the trade-off between the\naccuracy of structure learning and the cost we need to pay to perform a given\nmessage-passing based inference task because the learnt edge structures of data\ndependency and physical connectivity graph are often highly different. In this\npaper, we formalize this trade-off in an optimization problem which outputs the\ndata dependency graph that jointly considers learning accuracy and\nmessage-passing costs. We focus on a distributed MAP as the target inference\ntask, and consider two different implementations, ASYNC-MAP and SYNC-MAP that\nhave different message-passing mechanisms and thus different cost structures.\nIn ASYNC- MAP, we propose a polynomial time learning algorithm that is optimal,\nmotivated by the problem of finding a maximum weight spanning tree. In\nSYNC-MAP, we first prove that it is NP-hard and propose a greedy heuristic. For\nboth implementations, we then quantify how the probability that the resulting\ndata graphs from those learning algorithms differ from the ideal data graph\ndecays as the number of data samples grows, using the large deviation\nprinciple, where the decaying rate is characterized by some topological\nstructures of both original data dependency and physical connectivity graphs as\nwell as the degree of the trade-off. We validate our theoretical findings\nthrough extensive simulations, which confirms that it has a good match.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 14:34:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Jang", "Hyeryung", ""], ["Song", "HyungSeok", ""], ["Yi", "Yung", ""]]}, {"id": "1804.10961", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Ming Yu and Karthikeyan Natesan Ramamurthy and Addie Thompson and\n  Aur\\'elie Lozano", "title": "Simultaneous Parameter Learning and Bi-Clustering for Multi-Response\n  Models", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-response and multitask regression models, where the\nparameter matrix to be estimated is expected to have an unknown grouping\nstructure. The groupings can be along tasks, or features, or both, the last one\nindicating a bi-cluster or \"checkerboard\" structure. Discovering this grouping\nstructure along with parameter inference makes sense in several applications,\nsuch as multi-response Genome-Wide Association Studies. This additional\nstructure can not only can be leveraged for more accurate parameter estimation,\nbut it also provides valuable information on the underlying data mechanisms\n(e.g. relationships among genotypes and phenotypes in GWAS). In this paper, we\npropose two formulations to simultaneously learn the parameter matrix and its\ngroup structures, based on convex regularization penalties. We present\noptimization approaches to solve the resulting problems and provide numerical\nconvergence guarantees. Our approaches are validated on extensive simulations\nand real datasets concerning phenotypes and genotypes of plant varieties.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 16:37:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Yu", "Ming", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Thompson", "Addie", ""], ["Lozano", "Aur\u00e9lie", ""]]}, {"id": "1804.10969", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Eli Schwartz, Evgenii Zheltonozhskii, Natan Liss, Raja\n  Giryes, Alex M. Bronstein, Avi Mendelson", "title": "UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3444943", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel method for neural network quantization that emulates a\nnon-uniform $k$-quantile quantizer, which adapts to the distribution of the\nquantized parameters. Our approach provides a novel alternative to the existing\nuniform quantization techniques for neural networks. We suggest to compare the\nresults as a function of the bit-operations (BOPS) performed, assuming a\nlook-up table availability for the non-uniform case. In this setup, we show the\nadvantages of our strategy in the low computational budget regime. While the\nproposed solution is harder to implement in hardware, we believe it sets a\nbasis for new alternatives to neural networks quantization.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 17:38:20 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:11:25 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 20:19:13 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Baskin", "Chaim", ""], ["Schwartz", "Eli", ""], ["Zheltonozhskii", "Evgenii", ""], ["Liss", "Natan", ""], ["Giryes", "Raja", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1804.10974", "submitter": "Zihang Dai", "authors": "Zihang Dai, Qizhe Xie, Eduard Hovy", "title": "From Credit Assignment to Entropy Regularization: Two New Algorithms for\n  Neural Sequence Prediction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we study the credit assignment problem in reward augmented\nmaximum likelihood (RAML) learning, and establish a theoretical equivalence\nbetween the token-level counterpart of RAML and the entropy regularized\nreinforcement learning. Inspired by the connection, we propose two sequence\nprediction algorithms, one extending RAML with fine-grained credit assignment\nand the other improving Actor-Critic with a systematic entropy regularization.\nOn two benchmark datasets, we show the proposed algorithms outperform RAML and\nActor-Critic respectively, providing new alternatives to sequence prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 18:27:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dai", "Zihang", ""], ["Xie", "Qizhe", ""], ["Hovy", "Eduard", ""]]}, {"id": "1804.10988", "submitter": "Michael Blot", "authors": "Michael Blot, Thomas Robert, Nicolas Thome, Matthieu Cord", "title": "SHADE: Information Based Regularization for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is a big issue for training deep neural networks. In this\npaper, we propose a new information-theory-based regularization scheme named\nSHADE for SHAnnon DEcay. The originality of the approach is to define a prior\nbased on conditional entropy, which explicitly decouples the learning of\ninvariant representations in the regularizer and the learning of correlations\nbetween inputs and labels in the data fitting term. Our second contribution is\nto derive a stochastic version of the regularizer compatible with deep\nlearning, resulting in a tractable training scheme. We empirically validate the\nefficiency of our approach to improve classification performances compared to\ncommon regularization schemes on several standard architectures.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 20:32:23 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 14:08:23 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 14:12:02 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:14:08 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Blot", "Michael", ""], ["Robert", "Thomas", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.10992", "submitter": "Qifeng Chen", "authors": "Xiaojuan Qi, Qifeng Chen, Jiaya Jia, and Vladlen Koltun", "title": "Semi-parametric Image Synthesis", "comments": "Published at the Conference on Computer Vision and Pattern\n  Recognition (CVPR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semi-parametric approach to photographic image synthesis from\nsemantic layouts. The approach combines the complementary strengths of\nparametric and nonparametric techniques. The nonparametric component is a\nmemory bank of image segments constructed from a training set of images. Given\na novel semantic layout at test time, the memory bank is used to retrieve\nphotographic references that are provided as source material to a deep network.\nThe synthesis is performed by a deep network that draws on the provided\nphotographic material. Experiments on multiple semantic segmentation datasets\nshow that the presented approach yields considerably more realistic images than\nrecent purely parametric techniques. The results are shown in the supplementary\nvideo at https://youtu.be/U4Q98lenGLQ\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 21:20:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Qi", "Xiaojuan", ""], ["Chen", "Qifeng", ""], ["Jia", "Jiaya", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1804.11021", "submitter": "Kiran Karra", "authors": "Kiran Karra, Lamine Mili", "title": "On the Effect of Suboptimal Estimation of Mutual Information in Feature\n  Selection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new property of estimators of the strength of\nstatistical association, which helps characterize how well an estimator will\nperform in scenarios where dependencies between continuous and discrete random\nvariables need to be rank ordered. The new property, termed the estimator\nresponse curve, is easily computable and provides a marginal distribution\nagnostic way to assess an estimator's performance. It overcomes notable\ndrawbacks of current metrics of assessment, including statistical power, bias,\nand consistency. We utilize the estimator response curve to test various\nmeasures of the strength of association that satisfy the data processing\ninequality (DPI), and show that the CIM estimator's performance compares\nfavorably to kNN, vME, AP, and H_{MI} estimators of mutual information. The\nestimators which were identified to be suboptimal, according to the estimator\nresponse curve, perform worse than the more optimal estimators when tested with\nreal-world data from four different areas of science, all with varying\ndimensionalities and sizes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 02:05:52 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 21:46:42 GMT"}, {"version": "v3", "created": "Sat, 9 Jan 2021 19:36:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Karra", "Kiran", ""], ["Mili", "Lamine", ""]]}, {"id": "1804.11062", "submitter": "Shujun Bi", "authors": "Yulan Liu, Shujun Bi and Shaohua Pan", "title": "Equivalent Lipschitz surrogates for zero-norm and rank optimization\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a mechanism to produce equivalent Lipschitz surrogates\nfor zero-norm and rank optimization problems by means of the global exact\npenalty for their equivalent mathematical programs with an equilibrium\nconstraint (MPECs). Specifically, we reformulate these combinatorial problems\nas equivalent MPECs by the variational characterization of the zero-norm and\nrank function, show that their penalized problems, yielded by moving the\nequilibrium constraint into the objective, are the global exact penalization,\nand obtain the equivalent Lipschitz surrogates by eliminating the dual variable\nin the global exact penalty. These surrogates, including the popular SCAD\nfunction in statistics, are also difference of two convex functions (D.C.) if\nthe function and constraint set involved in zero-norm and rank optimization\nproblems are convex. We illustrate an application by designing a multi-stage\nconvex relaxation approach to the rank plus zero-norm regularized minimization\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 06:57:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Yulan", ""], ["Bi", "Shujun", ""], ["Pan", "Shaohua", ""]]}, {"id": "1804.11067", "submitter": "Trung Ngo Trong", "authors": "Trung Ngo Trong and Ville Hautam\\\"aki and Kristiina Jokinen", "title": "Staircase Network: structural language identification via hierarchical\n  attentive units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 07:55:55 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""], ["Jokinen", "Kristiina", ""]]}, {"id": "1804.11130", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf", "title": "Competitive Training of Mixtures of Independent Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in causal modeling posits that the data is generated by a\nset of independent mechanisms, and algorithms should aim to recover this\nstructure. Standard unsupervised learning, however, is often concerned with\ntraining a single model to capture the overall distribution or aspects thereof.\nInspired by clustering approaches, we consider mixtures of implicit generative\nmodels that ``disentangle'' the independent generative mechanisms underlying\nthe data. Relying on an additional set of discriminators, we propose a\ncompetitive training procedure in which the models only need to capture the\nportion of the data distribution from which they can produce realistic samples.\nAs a by-product, each model is simpler and faster to train. We empirically show\nthat our approach splits the training distribution in a sensible way and\nincreases the quality of the generated samples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:41:48 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:06:42 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 08:29:20 GMT"}, {"version": "v4", "created": "Sun, 3 Mar 2019 11:20:02 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Locatello", "Francesco", ""], ["Vincent", "Damien", ""], ["Tolstikhin", "Ilya", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1804.11135", "submitter": "Thulasi Tholeti", "authors": "Thulasi Tholeti, Vishnu Raj, Sheetal Kalyani", "title": "A Centralized Multi-stage Non-parametric Learning Algorithm for\n  Opportunistic Spectrum Access", "comments": "9 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the ever-increasing demand in wireless spectrum, Cognitive Radio\n(CR) was introduced as a technique to attain high spectral efficiency. As the\nnumber of secondary users (SUs) connecting to the cognitive radio network is on\nthe rise, there is an imminent need for centralized algorithms that provide\nhigh throughput and energy efficiency of the SUs while ensuring minimum\ninterference to the licensed users. In this work, we propose a multi-stage\nalgorithm that - 1) effectively assigns the available channel to the SUs, 2)\nemploys a non-parametric learning framework to estimate the primary traffic\ndistribution to minimize sensing, and 3) proposes an adaptive framework to\nensure that the collision to the primary user is below the specified threshold.\nWe provide comprehensive empirical validation of the method with other\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:52:13 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 12:18:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tholeti", "Thulasi", ""], ["Raj", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1804.11177", "submitter": "Qianqian Xu", "authors": "Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Qingming Huang, and Yuan Yao", "title": "From Social to Individuals: a Parsimonious Path of Multi-level Models\n  for Crowdsourced Preference Aggregation", "comments": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence as a regular paper. arXiv admin note: substantial text overlap\n  with arXiv:1607.03401", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In crowdsourced preference aggregation, it is often assumed that all the\nannotators are subject to a common preference or social utility function which\ngenerates their comparison behaviors in experiments. However, in reality\nannotators are subject to variations due to multi-criteria, abnormal, or a\nmixture of such behaviors. In this paper, we propose a parsimonious\nmixed-effects model, which takes into account both the fixed effect that the\nmajority of annotators follows a common linear utility model, and the random\neffect that some annotators might deviate from the common significantly and\nexhibit strongly personalized preferences. The key algorithm in this paper\nestablishes a dynamic path from the social utility to individual variations,\nwith different levels of sparsity on personalization. The algorithm is based on\nthe Linearized Bregman Iterations, which leads to easy parallel implementations\nto meet the need of large-scale data analysis. In this unified framework, three\nkinds of random utility models are presented, including the basic linear model\nwith L2 loss, Bradley-Terry model, and Thurstone-Mosteller model. The validity\nof these multi-level models are supported by experiments with both simulated\nand real-world datasets, which shows that the parsimonious multi-level models\nexhibit improvements in both interpretability and predictive precision compared\nwith traditional HodgeRank.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 03:56:22 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Xu", "Qianqian", ""], ["Xiong", "Jiechao", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""], ["Yao", "Yuan", ""]]}, {"id": "1804.11188", "submitter": "Corentin Tallec", "authors": "Corentin Tallec, Yann Ollivier", "title": "Can recurrent neural networks warp time?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful recurrent models such as long short-term memories (LSTMs) and\ngated recurrent units (GRUs) use ad hoc gating mechanisms. Empirically these\nmodels have been found to improve the learning of medium to long term temporal\ndependencies and to help with vanishing gradient issues. We prove that\nlearnable gates in a recurrent model formally provide quasi- invariance to\ngeneral time transformations in the input data. We recover part of the LSTM\narchitecture from a simple axiomatic approach. This result leads to a new way\nof initializing gate biases in LSTMs and GRUs. Ex- perimentally, this new\nchrono initialization is shown to greatly improve learning of long term\ndependencies, with minimal implementation effort.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:17:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Tallec", "Corentin", ""], ["Ollivier", "Yann", ""]]}, {"id": "1804.11195", "submitter": "Samir Farooq", "authors": "Samir Farooq, Samuel J. Weisenthal, Melissa Trayhan, Robert J. White,\n  Kristen Bush, Peter R. Mariuz, Martin S. Zand", "title": "Revealing patterns in HIV viral load data and classifying patients via a\n  novel machine learning cluster summarization method", "comments": "17 page paper with additional 10 pages of references and\n  supplementary material. 7 figures and 9 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  HIV RNA viral load (VL) is an important outcome variable in studies of HIV\ninfected persons. There exists only a handful of methods which classify\npatients by viral load patterns. Most methods place limits on the use of viral\nload measurements, are often specific to a particular study design, and do not\naccount for complex, temporal variation. To address this issue, we propose a\nset of four unambiguous computable characteristics (features) of time-varying\nHIV viral load patterns, along with a novel centroid-based classification\nalgorithm, which we use to classify a population of 1,576 HIV positive clinic\npatients into one of five different viral load patterns (clusters) often found\nin the literature: durably suppressed viral load (DSVL), sustained low viral\nload (SLVL), sustained high viral load (SHVL), high viral load suppression\n(HVLS), and rebounding viral load (RVL). The centroid algorithm summarizes\nthese clusters in terms of their centroids and radii. We show that this allows\nnew viral load patterns to be assigned pattern membership based on the distance\nfrom the centroid relative to its radius, which we term radial normalization\nclassification. This method has the benefit of providing an objective and\nquantitative method to assign viral load pattern membership with a concise and\ninterpretable model that aids clinical decision making. This method also\nfacilitates meta-analyses by providing computably distinct HIV categories.\nFinally we propose that this novel centroid algorithm could also be useful in\nthe areas of cluster comparison for outcomes research and data reduction in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:40:03 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Farooq", "Samir", ""], ["Weisenthal", "Samuel J.", ""], ["Trayhan", "Melissa", ""], ["White", "Robert J.", ""], ["Bush", "Kristen", ""], ["Mariuz", "Peter R.", ""], ["Zand", "Martin S.", ""]]}, {"id": "1804.11214", "submitter": "Yiming Xu", "authors": "Yiming Xu, Diego Klabjan", "title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural\n  Networks and Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-Nearest Neighbors is one of the most fundamental but effective\nclassification models. In this paper, we propose two families of models built\non a sequence to sequence model and a memory network model to mimic the\nk-Nearest Neighbors model, which generate a sequence of labels, a sequence of\nout-of-sample feature vectors and a final label for classification, and thus\nthey could also function as oversamplers. We also propose 'out-of-core'\nversions of our models which assume that only a small portion of data can be\nloaded into memory. Computational experiments show that our models on\nstructured datasets outperform k-Nearest Neighbors, a feed-forward neural\nnetwork, XGBoost, lightGBM, random forest and a memory network, due to the fact\nthat our models must produce additional output and not just the label. On image\nand text datasets, the performance of our model is close to many\nstate-of-the-art deep models. As an oversampler on imbalanced datasets, the\nsequence to sequence kNN model often outperforms Synthetic Minority\nOver-sampling Technique and Adaptive Synthetic Sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:13:29 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 19:19:19 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 19:31:51 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 00:16:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Xu", "Yiming", ""], ["Klabjan", "Diego", ""]]}, {"id": "1804.11237", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Deep learning improved by biological activation functions", "comments": "11 pages, 4 figures. 18/05/2018: 9 pages, 5 figures. Eq. 1 corrected.\n  Changed name of biological activation functions. Weight initialisation\n  simplified: experiments repeated, all figures changed, overall results\n  unchanged, Methods shortened, Appendix removed. Added new Results section for\n  new experiments on CIFAR 10/100 data. Extended arguments in Discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `Biologically inspired' activation functions, such as the logistic sigmoid,\nhave been instrumental in the historical advancement of machine learning.\nHowever in the field of deep learning, they have been largely displaced by\nrectified linear units (ReLU) or similar functions, such as its exponential\nlinear unit (ELU) variant, to mitigate the effects of vanishing gradients\nassociated with error back-propagation. The logistic sigmoid however does not\nrepresent the true input-output relation in neuronal cells under physiological\nconditions. Here, bionodal root unit (BRU) activation functions are introduced,\nexhibiting input-output non-linearities that are substantially more\nbiologically plausible since their functional form is based on known\nbiophysical properties of neuronal cells.\n  In order to evaluate the learning performance of BRU activations, deep\nnetworks are constructed with identical architectures except differing in their\ntransfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked\nauto-encoders, and convolutional networks are used to test supervised and\nunsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons\nof learning performance, quantified using loss and error measurements,\ndemonstrate that bionodal networks both train faster than their ReLU and ELU\ncounterparts and result in the best generalised models even in the absence of\nformal regularisation. These results therefore suggest that revisiting the\ndetailed properties of biological neurones and their circuitry might prove\ninvaluable in the field of deep learning for the future.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 10:20:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 08:59:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "1804.11238", "submitter": "Mohammad Al-Rubaie", "authors": "Mohammad Al-Rubaie, J. Morris Chang", "title": "Privacy Preserving Machine Learning: Threats and Solutions", "comments": "PPML Overview, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For privacy concerns to be addressed adequately in current machine learning\nsystems, the knowledge gap between the machine learning and privacy communities\nmust be bridged. This article aims to provide an introduction to the\nintersection of both fields with special emphasis on the techniques used to\nprotect the data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:10:31 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Al-Rubaie", "Mohammad", ""], ["Chang", "J. Morris", ""]]}, {"id": "1804.11239", "submitter": "Caiwen Ding", "authors": "Caiwen Ding, Ao Ren, Geng Yuan, Xiaolong Ma, Jiayu Li, Ning Liu, Bo\n  Yuan, Yanzhi Wang", "title": "Structured Weight Matrices-Based Hardware Accelerators in Deep Neural\n  Networks: FPGAs and ASICs", "comments": "6 pages, 7 figures, GLSVLSI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both industry and academia have extensively investigated hardware\naccelerations. In this work, to address the increasing demands in computational\ncapability and memory requirement, we propose structured weight matrices\n(SWM)-based compression techniques for both \\emph{field programmable gate\narray} (FPGA) and \\emph{application-specific integrated circuit} (ASIC)\nimplementations. In algorithm part, SWM-based framework adopts block-circulant\nmatrices to achieve a fine-grained tradeoff between accuracy and compression\nratio. The SWM-based technique can reduce computational complexity from\nO($n^2$) to O($n\\log n$) and storage complexity from O($n^2$) to O($n$) for\neach layer and both training and inference phases. For FPGA implementations on\ndeep convolutional neural networks (DCNNs), we achieve at least 152X and 72X\nimprovement in performance and energy efficiency, respectively using the\nSWM-based framework, compared with the baseline of IBM TrueNorth processor\nunder same accuracy constraints using the data set of MNIST, SVHN, and\nCIFAR-10. For FPGA implementations on long short term memory (LSTM) networks,\nthe proposed SWM-based LSTM can achieve up to 21X enhancement in performance\nand 33.5X gains in energy efficiency compared with the baseline accelerator.\nFor ASIC implementations, the SWM-based ASIC design exhibits impressive\nadvantages in terms of power, throughput, and energy efficiency. Experimental\nresults indicate that this method is greatly suitable for applying DNNs onto\nboth FPGAs and mobile/IoT devices.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:57:54 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ding", "Caiwen", ""], ["Ren", "Ao", ""], ["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Li", "Jiayu", ""], ["Liu", "Ning", ""], ["Yuan", "Bo", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1804.11258", "submitter": "Xipeng Qiu", "authors": "Zhan Shi, Xinchi Chen, Xipeng Qiu, Xuanjing Huang", "title": "Toward Diverse Text Generation with Inverse Reinforcement Learning", "comments": "7 pages, IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is a crucial task in NLP. Recently, several adversarial\ngenerative models have been proposed to improve the exposure bias problem in\ntext generation. Though these models gain great success, they still suffer from\nthe problems of reward sparsity and mode collapse. In order to address these\ntwo problems, in this paper, we employ inverse reinforcement learning (IRL) for\ntext generation. Specifically, the IRL framework learns a reward function on\ntraining data, and then an optimal policy to maximum the expected total reward.\nSimilar to the adversarial models, the reward and policy function in IRL are\noptimized alternately. Our method has two advantages: (1) the reward function\ncan produce more dense reward signals. (2) the generation policy, trained by\n\"entropy regularized\" policy gradient, encourages to generate more diversified\ntexts. Experiment results demonstrate that our proposed method can generate\nhigher quality texts than the previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:04:21 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 10:19:42 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 06:04:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Shi", "Zhan", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1804.11259", "submitter": "Jessica Schrouff", "authors": "Jessica Schrouff and Janaina Mourao-Miranda", "title": "Interpreting weight maps in terms of cognitive or clinical neuroscience:\n  nonsense?", "comments": "conference article", "journal-ref": "2018 International Workshop on Pattern Recognition in Neuroimaging\n  (PRNI), Singapore, Singapore, 2018, pp. 1-4", "doi": "10.1109/PRNI.2018.8423944", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since machine learning models have been applied to neuroimaging data,\nresearchers have drawn conclusions from the derived weight maps. In particular,\nweight maps of classifiers between two conditions are often described as a\nproxy for the underlying signal differences between the conditions. Recent\nstudies have however suggested that such weight maps could not reliably recover\nthe source of the neural signals and even led to false positives (FP). In this\nwork, we used semi-simulated data from ElectroCorticoGraphy (ECoG) to\ninvestigate how the signal-to-noise ratio and sparsity of the neural signal\naffect the similarity between signal and weights. We show that not all cases\nproduce FP and that it is unlikely for FP features to have a high weight in\nmost cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:06:35 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Schrouff", "Jessica", ""], ["Mourao-Miranda", "Janaina", ""]]}, {"id": "1804.11271", "submitter": "Alexander Matthews", "authors": "Alexander G. de G. Matthews, Mark Rowland, Jiri Hron, Richard E.\n  Turner, Zoubin Ghahramani", "title": "Gaussian Process Behaviour in Wide Deep Neural Networks", "comments": "This work substantially extends the work of Matthews et al. (2018)\n  published at the International Conference on Learning Representations (ICLR)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst deep neural networks have shown great empirical success, there is\nstill much work to be done to understand their theoretical properties. In this\npaper, we study the relationship between random, wide, fully connected,\nfeedforward networks with more than one hidden layer and Gaussian processes\nwith a recursive kernel definition. We show that, under broad conditions, as we\nmake the architecture increasingly wide, the implied random function converges\nin distribution to a Gaussian process, formalising and extending existing\nresults by Neal (1996) to deep networks. To evaluate convergence rates\nempirically, we use maximum mean discrepancy. We then compare finite Bayesian\ndeep networks from the literature to Gaussian processes in terms of the key\npredictive quantities of interest, finding that in some cases the agreement can\nbe very close. We discuss the desirability of Gaussian process behaviour and\nreview non-Gaussian alternative models from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:21:23 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:51:32 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Matthews", "Alexander G. de G.", ""], ["Rowland", "Mark", ""], ["Hron", "Jiri", ""], ["Turner", "Richard E.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1804.11284", "submitter": "Pingfan Tang", "authors": "Jeff M. Phillips, Pingfan Tang", "title": "Simple Distances for Trajectories via Landmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new class of distances for objects including lines, hyperplanes,\nand trajectories, based on the distance to a set of landmarks. These distances\neasily and interpretably map objects to a Euclidean space, are simple to\ncompute, and perform well in data analysis tasks. For trajectories, they match\nand in some cases significantly out-perform all state-of-the-art other metrics,\ncan effortlessly be used in k-means clustering, and directly plugged into\napproximate nearest neighbor approaches which immediately out-perform the best\nrecent advances in trajectory similarity search by several orders of magnitude.\nThese distances do not require a geometry distorting dual (common in the line\nor halfspace case) or complicated alignment (common in trajectory case). We\nshow reasonable and often simple conditions under which these distances are\nmetrics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:54:23 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 03:11:35 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 01:02:09 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tang", "Pingfan", ""]]}, {"id": "1804.11285", "submitter": "Ludwig Schmidt", "authors": "Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar and\n  Aleksander M\\k{a}dry", "title": "Adversarially Robust Generalization Requires More Data", "comments": "Small changes for biblatex compatibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often susceptible to adversarial perturbations of\ntheir inputs. Even small perturbations can cause state-of-the-art classifiers\nwith high \"standard\" accuracy to produce an incorrect prediction with high\nconfidence. To better understand this phenomenon, we study adversarially robust\nlearning from the viewpoint of generalization. We show that already in a simple\nnatural data model, the sample complexity of robust learning can be\nsignificantly larger than that of \"standard\" learning. This gap is information\ntheoretic and holds irrespective of the training algorithm or the model family.\nWe complement our theoretical results with experiments on popular image\nclassification datasets and show that a similar gap exists here as well. We\npostulate that the difficulty of training robust classifiers stems, at least\npartially, from this inherently larger sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:55:59 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 05:24:33 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Schmidt", "Ludwig", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Talwar", "Kunal", ""], ["M\u0105dry", "Aleksander", ""]]}, {"id": "1804.11297", "submitter": "Rachid Riad", "authors": "Rachid Riad, Corentin Dancette, Julien Karadayi, Neil Zeghidour,\n  Thomas Schatz, Emmanuel Dupoux", "title": "Sampling strategies in Siamese Networks for unsupervised speech\n  representation learning", "comments": "Conference paper at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have investigated siamese network architectures for learning\ninvariant speech representations using same-different side information at the\nword level. Here we investigate systematically an often ignored component of\nsiamese networks: the sampling procedure (how pairs of same vs. different\ntokens are selected). We show that sampling strategies taking into account\nZipf's Law, the distribution of speakers and the proportions of same and\ndifferent pairs of words significantly impact the performance of the network.\nIn particular, we show that word frequency compression improves learning across\na large range of variations in number of training pairs. This effect does not\napply to the same extent to the fully unsupervised setting, where the pairs of\nsame-different words are obtained by spoken term discovery. We apply these\nresults to pairs of words discovered using an unsupervised algorithm and show\nan improvement on state-of-the-art in unsupervised representation learning\nusing siamese networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 16:19:51 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 14:17:38 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Riad", "Rachid", ""], ["Dancette", "Corentin", ""], ["Karadayi", "Julien", ""], ["Zeghidour", "Neil", ""], ["Schatz", "Thomas", ""], ["Dupoux", "Emmanuel", ""]]}]