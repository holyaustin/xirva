[{"id": "1111.0024", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Divya Jyoti, M. Mani Roja", "title": "Text-Independent Speaker Recognition for Low SNR Environments with\n  Encryption", "comments": "Biometrics, Pattern Recognition, Security, Speaker Individuality,\n  Text-independence, Pitch Extraction, Voice Recognition, Autocorrelation;\n  Published by Foundation of Computer Science, New York, USA", "journal-ref": "International Journal of Computer Applications 31(10):43-50, 2011", "doi": "10.5120/3864-5394", "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition systems are commonly designed to authenticate users at the access\ncontrol levels of a system. A number of voice recognition methods have been\ndeveloped using a pitch estimation process which are very vulnerable in low\nSignal to Noise Ratio (SNR) environments thus, these programs fail to provide\nthe desired level of accuracy and robustness. Also, most text independent\nspeaker recognition programs are incapable of coping with unauthorized attempts\nto gain access by tampering with the samples or reference database. The\nproposed text-independent voice recognition system makes use of multilevel\ncryptography to preserve data integrity while in transit or storage. Encryption\nand decryption follow a transform based approach layered with pseudorandom\nnoise addition whereas for pitch detection, a modified version of the\nautocorrelation pitch extraction algorithm is used. The experimental results\nshow that the proposed algorithm can decrypt the signal under test with\nexponentially reducing Mean Square Error over an increasing range of SNR.\nFurther, it outperforms the conventional algorithms in actual identification\ntasks even in noisy environments. The recognition rate thus obtained using the\nproposed method is compared with other conventional methods used for speaker\nidentification.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2011 20:31:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chadha", "Aman", ""], ["Jyoti", "Divya", ""], ["Roja", "M. Mani", ""]]}, {"id": "1111.0034", "submitter": "Jianshu Chen", "authors": "Jianshu Chen, Ali H. Sayed", "title": "Diffusion Adaptation Strategies for Distributed Optimization and\n  Learning over Networks", "comments": "34 pages, 6 figures, to appear in IEEE Transactions on Signal\n  Processing, 2012", "journal-ref": null, "doi": "10.1109/TSP.2012.2198470", "report-no": null, "categories": "math.OC cs.IT cs.LG cs.SI math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adaptive diffusion mechanism to optimize a global cost function\nin a distributed manner over a network of nodes. The cost function is assumed\nto consist of a collection of individual components. Diffusion adaptation\nallows the nodes to cooperate and diffuse information in real-time; it also\nhelps alleviate the effects of stochastic gradient noise and measurement noise\nthrough a continuous learning process. We analyze the mean-square-error\nperformance of the algorithm in some detail, including its transient and\nsteady-state behavior. We also apply the diffusion algorithm to two problems:\ndistributed estimation with sparse parameters and distributed localization.\nCompared to well-studied incremental methods, diffusion methods do not require\nthe use of a cyclic path over the nodes and are robust to node and link\nfailure. Diffusion methods also endow networks with adaptation abilities that\nenable the individual nodes to continue learning even when the cost function\nchanges with time. Examples involving such dynamic cost functions with moving\ntargets are common in the context of biological networks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2011 21:16:40 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2012 02:06:49 GMT"}, {"version": "v3", "created": "Sat, 12 May 2012 23:35:40 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Chen", "Jianshu", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1111.0352", "submitter": "Brian Kulis", "authors": "Brian Kulis and Michael I. Jordan", "title": "Revisiting k-means: New Algorithms via Bayesian Nonparametrics", "comments": "14 pages. Updated based on the corresponding ICML paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian models offer great flexibility for clustering\napplications---Bayesian nonparametrics can be used for modeling infinite\nmixtures, and hierarchical Bayesian models can be utilized for sharing clusters\nacross multiple data sets. For the most part, such flexibility is lacking in\nclassical clustering methods such as k-means. In this paper, we revisit the\nk-means clustering algorithm from a Bayesian nonparametric viewpoint. Inspired\nby the asymptotic connection between k-means and mixtures of Gaussians, we show\nthat a Gibbs sampling algorithm for the Dirichlet process mixture approaches a\nhard clustering algorithm in the limit, and further that the resulting\nalgorithm monotonically minimizes an elegant underlying k-means-like clustering\nobjective that includes a penalty for the number of clusters. We generalize\nthis analysis to the case of clustering multiple data sets through a similar\nasymptotic argument with the hierarchical Dirichlet process. We also discuss\nfurther extensions that highlight the benefits of our analysis: i) a spectral\nrelaxation involving thresholded eigenvectors, and ii) a normalized cut graph\nclustering algorithm that does not fix the number of clusters in the graph.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 00:09:18 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2012 15:05:55 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Kulis", "Brian", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1111.0432", "submitter": "Sangkyun Lee", "authors": "Sangkyun Lee and Stephen J. Wright", "title": "Approximate Stochastic Subgradient Estimation Training for Support\n  Vector Machines", "comments": "An extended version of the ICPRAM 2012 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subgradient algorithms for training support vector machines have been quite\nsuccessful for solving large-scale and online learning problems. However, they\nhave been restricted to linear kernels and strongly convex formulations. This\npaper describes efficient subgradient approaches without such limitations. Our\napproaches make use of randomized low-dimensional approximations to nonlinear\nkernels, and minimization of a reduced primal formulation using an algorithm\nbased on robust stochastic approximation, which do not require strong\nconvexity. Experiments illustrate that our approaches produce solutions of\ncomparable prediction accuracy with the solutions acquired from existing SVM\nsolvers, but often in much shorter time. We also suggest efficient prediction\nschemes that depend only on the dimension of kernel approximation, not on the\nnumber of support vectors.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 09:24:26 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2011 13:33:27 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Lee", "Sangkyun", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1111.0712", "submitter": "Pannagadatta Shivaswamy", "authors": "Pannagadatta K. Shivaswamy and Thorsten Joachims", "title": "Online Learning with Preference Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new online learning model for learning with preference feedback.\nThe model is especially suited for applications like web search and recommender\nsystems, where preference data is readily available from implicit user feedback\n(e.g. clicks). In particular, at each time step a potentially structured object\n(e.g. a ranking) is presented to the user in response to a context (e.g.\nquery), providing him or her with some unobserved amount of utility. As\nfeedback the algorithm receives an improved object that would have provided\nhigher utility. We propose a learning algorithm with provable regret bounds for\nthis online learning setting and demonstrate its effectiveness on a web-search\napplication. The new learning model also applies to many other interactive\nlearning problems and admits several interesting extensions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 01:58:45 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Shivaswamy", "Pannagadatta K.", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1111.0952", "submitter": "Ankur Moitra", "authors": "Sanjeev Arora, Rong Ge, Ravi Kannan, Ankur Moitra", "title": "Computing a Nonnegative Matrix Factorization -- Provably", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Nonnegative Matrix Factorization (NMF) problem we are given an $n\n\\times m$ nonnegative matrix $M$ and an integer $r > 0$. Our goal is to express\n$M$ as $A W$ where $A$ and $W$ are nonnegative matrices of size $n \\times r$\nand $r \\times m$ respectively. In some applications, it makes sense to ask\ninstead for the product $AW$ to approximate $M$ -- i.e. (approximately)\nminimize $\\norm{M - AW}_F$ where $\\norm{}_F$ denotes the Frobenius norm; we\nrefer to this as Approximate NMF. This problem has a rich history spanning\nquantum mechanics, probability theory, data analysis, polyhedral combinatorics,\ncommunication complexity, demography, chemometrics, etc. In the past decade NMF\nhas become enormously popular in machine learning, where $A$ and $W$ are\ncomputed using a variety of local search heuristics. Vavasis proved that this\nproblem is NP-complete. We initiate a study of when this problem is solvable in\npolynomial time:\n  1. We give a polynomial-time algorithm for exact and approximate NMF for\nevery constant $r$. Indeed NMF is most interesting in applications precisely\nwhen $r$ is small.\n  2. We complement this with a hardness result, that if exact NMF can be solved\nin time $(nm)^{o(r)}$, 3-SAT has a sub-exponential time algorithm. This rules\nout substantial improvements to the above algorithm.\n  3. We give an algorithm that runs in time polynomial in $n$, $m$ and $r$\nunder the separablity condition identified by Donoho and Stodden in 2003. The\nalgorithm may be practical since it is simple and noise tolerant (under benign\nassumptions). Separability is believed to hold in many practical settings.\n  To the best of our knowledge, this last result is the first example of a\npolynomial-time algorithm that provably works under a non-trivial condition on\nthe input and we believe that this will be an interesting and important\ndirection for future work.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 19:15:56 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Kannan", "Ravi", ""], ["Moitra", "Ankur", ""]]}, {"id": "1111.1124", "submitter": "Devorah Kletenik", "authors": "Lisa Hellerstein, Devorah Kletenik, Linda Sellie and Rocco Servedio", "title": "Tight Bounds on Proper Equivalence Query Learning of DNF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new structural lemma for partial Boolean functions $f$, which we\ncall the seed lemma for DNF. Using the lemma, we give the first subexponential\nalgorithm for proper learning of DNF in Angluin's Equivalence Query (EQ) model.\nThe algorithm has time and query complexity $2^{(\\tilde{O}{\\sqrt{n}})}$, which\nis optimal. We also give a new result on certificates for DNF-size, a simple\nalgorithm for properly PAC-learning DNF, and new results on EQ-learning $\\log\nn$-term DNF and decision trees.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 13:33:24 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Hellerstein", "Lisa", ""], ["Kletenik", "Devorah", ""], ["Sellie", "Linda", ""], ["Servedio", "Rocco", ""]]}, {"id": "1111.1136", "submitter": "Dan Garber", "authors": "Dan Garber, Elad Hazan", "title": "Universal MMSE Filtering With Logarithmic Adaptive Regret", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online estimation of a real-valued signal\ncorrupted by oblivious zero-mean noise using linear estimators. The estimator\nis required to iteratively predict the underlying signal based on the current\nand several last noisy observations, and its performance is measured by the\nmean-square-error. We describe and analyze an algorithm for this task which: 1.\nAchieves logarithmic adaptive regret against the best linear filter in\nhindsight. This bound is assyptotically tight, and resolves the question of\nMoon and Weissman [1]. 2. Runs in linear time in terms of the number of filter\ncoefficients. Previous constructions required at least quadratic time.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 14:18:31 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 21:16:59 GMT"}], "update_date": "2011-11-16", "authors_parsed": [["Garber", "Dan", ""], ["Hazan", "Elad", ""]]}, {"id": "1111.1315", "submitter": "Yuyang Wang", "authors": "Yuyang Wang, Roni Khardon, Pavlos Protopapas", "title": "Nonparametric Bayesian Estimation of Periodic Functions", "comments": null, "journal-ref": null, "doi": "10.1088/0004-637X/756/1/67", "report-no": null, "categories": "cs.LG astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world problems exhibit patterns that have periodic behavior. For\nexample, in astrophysics, periodic variable stars play a pivotal role in\nunderstanding our universe. An important step when analyzing data from such\nprocesses is the problem of identifying the period: estimating the period of a\nperiodic function based on noisy observations made at irregularly spaced time\npoints. This problem is still a difficult challenge despite extensive study in\ndifferent disciplines. The paper makes several contributions toward solving\nthis problem. First, we present a nonparametric Bayesian model for period\nfinding, based on Gaussian Processes (GP), that does not make strong\nassumptions on the shape of the periodic function. As our experiments\ndemonstrate, the new model leads to significantly better results in period\nestimation when the target function is non-sinusoidal. Second, we develop a new\nalgorithm for parameter optimization for GP which is useful when the likelihood\nfunction is very sensitive to the setting of the hyper-parameters with numerous\nlocal minima, as in the case of period estimation. The algorithm combines\ngradient optimization with grid search and incorporates several mechanisms to\novercome the high complexity of inference with GP. Third, we develop a novel\napproach for using domain knowledge, in the form of a probabilistic generative\nmodel, and incorporate it into the period estimation algorithm. Experimental\nresults on astrophysics data validate our approach showing significant\nimprovement over the state of the art in this domain.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2011 14:27:11 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2012 02:23:33 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Wang", "Yuyang", ""], ["Khardon", "Roni", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1111.1386", "submitter": "Avihai Mejer", "authors": "Avihai Mejer and Koby Crammer", "title": "Confidence Estimation in Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured classification tasks such as sequence labeling and dependency\nparsing have seen much interest by the Natural Language Processing and the\nmachine learning communities. Several online learning algorithms were adapted\nfor structured tasks such as Perceptron, Passive- Aggressive and the recently\nintroduced Confidence-Weighted learning . These online algorithms are easy to\nimplement, fast to train and yield state-of-the-art performance. However,\nunlike probabilistic models like Hidden Markov Model and Conditional random\nfields, these methods generate models that output merely a prediction with no\nadditional information regarding confidence in the correctness of the output.\nIn this work we fill the gap proposing few alternatives to compute the\nconfidence in the output of non-probabilistic algorithms.We show how to compute\nconfidence estimates in the prediction such that the confidence reflects the\nprobability that the word is labeled correctly. We then show how to use our\nmethods to detect mislabeled words, trade recall for precision and active\nlearning. We evaluate our methods on four noun-phrase chunking and named entity\nrecognition sequence labeling tasks, and on dependency parsing for 14\nlanguages.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 08:43:21 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Mejer", "Avihai", ""], ["Crammer", "Koby", ""]]}, {"id": "1111.1418", "submitter": "Larry Wasserman", "authors": "Jing Lei, James Robins and Larry Wasserman", "title": "Efficient Nonparametric Conformal Prediction Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate and extend the conformal prediction method due to\nVovk,Gammerman and Shafer (2005) to construct nonparametric prediction regions.\nThese regions have guaranteed distribution free, finite sample coverage,\nwithout any assumptions on the distribution or the bandwidth. Explicit\nconvergence rates of the loss function are established for such regions under\nstandard regularity conditions. Approximations for simplifying implementation\nand data driven bandwidth selection methods are also discussed. The theoretical\nproperties of our method are demonstrated through simulations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 13:34:10 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Lei", "Jing", ""], ["Robins", "James", ""], ["Wasserman", "Larry", ""]]}, {"id": "1111.1422", "submitter": "Steve Hanneke", "authors": "Maria-Florina Balcan and Steve Hanneke", "title": "Robust Interactive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and study a generalization of the standard\nactive-learning model where a more general type of query, class conditional\nquery, is allowed. Such queries have been quite useful in applications, but\nhave been lacking theoretical understanding. In this work, we characterize the\npower of such queries under two well-known noise models. We give nearly tight\nupper and lower bounds on the number of queries needed to learn both for the\ngeneral agnostic setting and for the bounded noise model. We further show that\nour methods can be made adaptive to the (unknown) noise rate, with only\nnegligible loss in query complexity.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 14:01:14 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Hanneke", "Steve", ""]]}, {"id": "1111.1784", "submitter": "Ravi Ganti", "authors": "Ravi Ganti and Alexander Gray", "title": "UPAL: Unbiased Pool Based Active Learning", "comments": "20 pages, 4 figures, 2 tables, a few minor typos were corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of pool based active learning, and\nprovide an algorithm, called UPAL, that works by minimizing the unbiased\nestimator of the risk of a hypothesis in a given hypothesis space. For the\nspace of linear classifiers and the squared loss we show that UPAL is\nequivalent to an exponentially weighted average forecaster. Exploiting some\nrecent results regarding the spectra of random matrices allows us to establish\nconsistency of UPAL when the true hypothesis is a linear hypothesis. Empirical\ncomparison with an active learner implementation in Vowpal Wabbit, and a\npreviously proposed pool based active learner implementation show good\nempirical performance and better scalability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 02:41:48 GMT"}, {"version": "v2", "created": "Sun, 13 Nov 2011 17:28:34 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["Ganti", "Ravi", ""], ["Gray", "Alexander", ""]]}, {"id": "1111.1797", "submitter": "Shipra Agrawal", "authors": "Shipra Agrawal, Navin Goyal", "title": "Analysis of Thompson Sampling for the multi-armed bandit problem", "comments": "This version corrects some minor errors, and reorganizes some content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit problem is a popular model for studying\nexploration/exploitation trade-off in sequential decision problems. Many\nalgorithms are now available for this well-studied problem. One of the earliest\nalgorithms, given by W. R. Thompson, dates back to 1933. This algorithm,\nreferred to as Thompson Sampling, is a natural Bayesian algorithm. The basic\nidea is to choose an arm to play according to its probability of being the best\narm. Thompson Sampling algorithm has experimentally been shown to be close to\noptimal. In addition, it is efficient to implement and exhibits several\ndesirable properties such as small regret for delayed feedback. However,\ntheoretical understanding of this algorithm was quite limited. In this paper,\nfor the first time, we show that Thompson Sampling algorithm achieves\nlogarithmic expected regret for the multi-armed bandit problem. More precisely,\nfor the two-armed bandit problem, the expected regret in time $T$ is\n$O(\\frac{\\ln T}{\\Delta} + \\frac{1}{\\Delta^3})$. And, for the $N$-armed bandit\nproblem, the expected regret in time $T$ is $O([(\\sum_{i=2}^N\n\\frac{1}{\\Delta_i^2})^2] \\ln T)$. Our bounds are optimal but for the dependence\non $\\Delta_i$ and the constant factors in big-Oh.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 04:27:01 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2011 08:27:25 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2012 10:43:05 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Agrawal", "Shipra", ""], ["Goyal", "Navin", ""]]}, {"id": "1111.2092", "submitter": "Sanmay Das", "authors": "Sanmay Das, Allen Lavoie, and Malik Magdon-Ismail", "title": "Pushing Your Point of View: Behavioral Measures of Manipulation in\n  Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a major source for information on virtually any topic, Wikipedia serves an\nimportant role in public dissemination and consumption of knowledge. As a\nresult, it presents tremendous potential for people to promulgate their own\npoints of view; such efforts may be more subtle than typical vandalism. In this\npaper, we introduce new behavioral metrics to quantify the level of controversy\nassociated with a particular user: a Controversy Score (C-Score) based on the\namount of attention the user focuses on controversial pages, and a Clustered\nControversy Score (CC-Score) that also takes into account topical clustering.\nWe show that both these measures are useful for identifying people who try to\n\"push\" their points of view, by showing that they are good predictors of which\neditors get blocked. The metrics can be used to triage potential POV pushers.\nWe apply this idea to a dataset of users who requested promotion to\nadministrator status and easily identify some editors who significantly changed\ntheir behavior upon becoming administrators. At the same time, such behavior is\nnot rampant. Those who are promoted to administrator status tend to have more\nstable behavior than comparable groups of prolific editors. This suggests that\nthe Adminship process works well, and that the Wikipedia community is not\noverwhelmed by users who become administrators to promote their own points of\nview.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 03:22:16 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Das", "Sanmay", ""], ["Lavoie", "Allen", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1111.2111", "submitter": "Song Liu Mr", "authors": "Song Liu, Peter Flach, Nello Cristianini", "title": "Generic Multiplicative Methods for Implementing Machine Learning\n  Algorithms on MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a generic model for multiplicative algorithms\nwhich is suitable for the MapReduce parallel programming paradigm. We implement\nthree typical machine learning algorithms to demonstrate how similarity\ncomparison, gradient descent, power method and other classic learning\ntechniques fit this model well. Two versions of large-scale matrix\nmultiplication are discussed in this paper, and different methods are developed\nfor both cases with regard to their unique computational characteristics and\nproblem settings. In contrast to earlier research, we focus on fundamental\nlinear algebra techniques that establish a generic approach for a range of\nalgorithms, rather than specific ways of scaling up algorithms one at a time.\nExperiments show promising results when evaluated on both speedup and accuracy.\nCompared with a standard implementation with computational complexity $O(m^3)$\nin the worst case, the large-scale matrix multiplication experiments prove our\ndesign is considerably more efficient and maintains a good speedup as the\nnumber of cores increases. Algorithm-specific experiments also produce\nencouraging results on runtime performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 06:39:17 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2011 02:08:47 GMT"}], "update_date": "2011-12-05", "authors_parsed": [["Liu", "Song", ""], ["Flach", "Peter", ""], ["Cristianini", "Nello", ""]]}, {"id": "1111.2221", "submitter": "Weishan Dong", "authors": "Weishan Dong, Tianshi Chen, Peter Tino, and Xin Yao", "title": "Scaling Up Estimation of Distribution Algorithms For Continuous\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Estimation of Distribution Algorithms (EDA) were proposed, many\nattempts have been made to improve EDAs' performance in the context of global\noptimization. So far, the studies or applications of multivariate probabilistic\nmodel based continuous EDAs are still restricted to rather low dimensional\nproblems (smaller than 100D). Traditional EDAs have difficulties in solving\nhigher dimensional problems because of the curse of dimensionality and their\nrapidly increasing computational cost. However, scaling up continuous EDAs for\nhigher dimensional optimization is still necessary, which is supported by the\ndistinctive feature of EDAs: Because a probabilistic model is explicitly\nestimated, from the learnt model one can discover useful properties or features\nof the problem. Besides obtaining a good solution, understanding of the problem\nstructure can be of great benefit, especially for black box optimization. We\npropose a novel EDA framework with Model Complexity Control (EDA-MCC) to scale\nup EDAs. By using Weakly dependent variable Identification (WI) and Subspace\nModeling (SM), EDA-MCC shows significantly better performance than traditional\nEDAs on high dimensional problems. Moreover, the computational cost and the\nrequirement of large population sizes can be reduced in EDA-MCC. In addition to\nbeing able to find a good solution, EDA-MCC can also produce a useful problem\nstructure characterization. EDA-MCC is the first successful instance of\nmultivariate model based EDAs that can be effectively applied a general class\nof up to 500D problems. It also outperforms some newly developed algorithms\ndesigned specifically for large scale optimization. In order to understand the\nstrength and weakness of EDA-MCC, we have carried out extensive computational\nstudies of EDA-MCC. Our results have revealed when EDA-MCC is likely to\noutperform others on what kind of benchmark functions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 14:44:58 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Dong", "Weishan", ""], ["Chen", "Tianshi", ""], ["Tino", "Peter", ""], ["Yao", "Xin", ""]]}, {"id": "1111.2262", "submitter": "Tianbao Yang", "authors": "Rong Jin, Tianbao Yang, Mehrdad Mahdavi, Yu-Feng Li, Zhi-Hua Zhou", "title": "Improved Bound for the Nystrom's Method and its Application to Kernel\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1109/TIT.2013.2271378", "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two approaches for analyzing the approximation error bound for the\nNystr\\\"{o}m method, one based on the concentration inequality of integral\noperator, and one based on the compressive sensing theory. We show that the\napproximation error, measured in the spectral norm, can be improved from\n$O(N/\\sqrt{m})$ to $O(N/m^{1 - \\rho})$ in the case of large eigengap, where $N$\nis the total number of data points, $m$ is the number of sampled data points,\nand $\\rho \\in (0, 1/2)$ is a positive constant that characterizes the eigengap.\nWhen the eigenvalues of the kernel matrix follow a $p$-power law, our analysis\nbased on compressive sensing theory further improves the bound to $O(N/m^{p -\n1})$ under an incoherence assumption, which explains why the Nystr\\\"{o}m method\nworks well for kernel matrix with skewed eigenvalues. We present a kernel\nclassification approach based on the Nystr\\\"{o}m method and derive its\ngeneralization performance using the improved bound. We show that when the\neigenvalues of kernel matrix follow a $p$-power law, we can reduce the number\nof support vectors to $N^{2p/(p^2 - 1)}$, a number less than $N$ when $p >\n1+\\sqrt{2}$, without seriously sacrificing its generalization performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 16:34:55 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2011 20:53:23 GMT"}, {"version": "v3", "created": "Tue, 1 May 2012 02:22:26 GMT"}, {"version": "v4", "created": "Tue, 24 Jul 2012 18:34:52 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Jin", "Rong", ""], ["Yang", "Tianbao", ""], ["Mahdavi", "Mehrdad", ""], ["Li", "Yu-Feng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1111.2664", "submitter": "Rafael Frongillo", "authors": "Jacob Abernethy and Rafael M. Frongillo", "title": "A Collaborative Mechanism for Crowdsourcing Prediction Problems", "comments": "Full version of the extended abstract which appeared in NIPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning competitions such as the Netflix Prize have proven\nreasonably successful as a method of \"crowdsourcing\" prediction tasks. But\nthese competitions have a number of weaknesses, particularly in the incentive\nstructure they create for the participants. We propose a new approach, called a\nCrowdsourced Learning Mechanism, in which participants collaboratively \"learn\"\na hypothesis for a given prediction task. The approach draws heavily from the\nconcept of a prediction market, where traders bet on the likelihood of a future\nevent. In our framework, the mechanism continues to publish the current\nhypothesis, and participants can modify this hypothesis by wagering on an\nupdate. The critical incentive property is that a participant will profit an\namount that scales according to how much her update improves performance on a\nreleased test set.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 05:09:33 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Abernethy", "Jacob", ""], ["Frongillo", "Rafael M.", ""]]}, {"id": "1111.2948", "submitter": "Marcos Domingues", "authors": "Marcos A. Domingues, Alipio Mario Jorge, Carlos Soares", "title": "Using Contextual Information as Virtual Items on Top-N Recommender\n  Systems", "comments": "Workshop on Context-Aware Recommender Systems (CARS'09) in\n  conjunction with the 3rd ACM Conference on Recommender Systems (RecSys'09)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, recommender systems for the Web deal with applications that\nhave two dimensions, users and items. Based on access logs that relate these\ndimensions, a recommendation model can be built and used to identify a set of N\nitems that will be of interest to a certain user. In this paper we propose a\nmethod to complement the information in the access logs with contextual\ninformation without changing the recommendation algorithm. The method consists\nin representing context as virtual items. We empirically test this method with\ntwo top-N recommender systems, an item-based collaborative filtering technique\nand association rules, on three data sets. The results show that our method is\nable to take advantage of the context (new dimensions) when it is informative.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2011 17:53:10 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2011 10:20:57 GMT"}], "update_date": "2011-11-16", "authors_parsed": [["Domingues", "Marcos A.", ""], ["Jorge", "Alipio Mario", ""], ["Soares", "Carlos", ""]]}, {"id": "1111.3735", "submitter": "Gabriel Synnaeve", "authors": "Gabriel Synnaeve (LIG, LPPA), Pierre Bessi\\`ere (LIG, LPPA)", "title": "A Bayesian Model for Plan Recognition in RTS Games applied to StarCraft", "comments": "7 pages; Artificial Intelligence and Interactive Digital\n  Entertainment Conference (AIIDE 2011), Palo Alto : \\'Etats-Unis (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of keyhole (unobtrusive) plan recognition is central to adaptive\ngame AI. \"Tech trees\" or \"build trees\" are the core of real-time strategy (RTS)\ngame strategic (long term) planning. This paper presents a generic and simple\nBayesian model for RTS build tree prediction from noisy observations, which\nparameters are learned from replays (game logs). This unsupervised machine\nlearning approach involves minimal work for the game developers as it leverage\nplayers' data (com- mon in RTS). We applied it to StarCraft1 and showed that it\nyields high quality and robust predictions, that can feed an adaptive AI.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 09:26:14 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["Synnaeve", "Gabriel", "", "LIG, LPPA"], ["Bessi\u00e8re", "Pierre", "", "LIG, LPPA"]]}, {"id": "1111.3846", "submitter": "Marcus Hutter", "authors": "Tor Lattimore and Marcus Hutter", "title": "No Free Lunch versus Occam's Razor in Supervised Learning", "comments": "16 LaTeX pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The No Free Lunch theorems are often used to argue that domain specific\nknowledge is required to design successful algorithms. We use algorithmic\ninformation theory to argue the case for a universal bias allowing an algorithm\nto succeed in all interesting problem domains. Additionally, we give a new\nalgorithm for off-line classification, inspired by Solomonoff induction, with\ngood performance on all structured problems under reasonable assumptions. This\nincludes a proof of the efficacy of the well-known heuristic of randomly\nselecting training data in the hope of reducing misclassification rates.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 16:06:57 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["Lattimore", "Tor", ""], ["Hutter", "Marcus", ""]]}, {"id": "1111.3866", "submitter": "Emmanuel Vazquez", "authors": "Emmanuel Vazquez and Julien Bect", "title": "Sequential search based on kriging: convergence analysis of some\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\FF$ be a set of real-valued functions on a set $\\XX$ and let $S:\\FF \\to\n\\GG$ be an arbitrary mapping. We consider the problem of making inference about\n$S(f)$, with $f\\in\\FF$ unknown, from a finite set of pointwise evaluations of\n$f$. We are mainly interested in the problems of approximation and\noptimization. In this article, we make a brief review of results concerning\naverage error bounds of Bayesian search methods that use a random process prior\nabout $f$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 16:46:48 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["Vazquez", "Emmanuel", ""], ["Bect", "Julien", ""]]}, {"id": "1111.4246", "submitter": "Matthew Hoffman", "authors": "Matthew D. Hoffman and Andrew Gelman", "title": "The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian\n  Monte Carlo", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm\nthat avoids the random walk behavior and sensitivity to correlated parameters\nthat plague many MCMC methods by taking a series of steps informed by\nfirst-order gradient information. These features allow it to converge to\nhigh-dimensional target distributions much more quickly than simpler methods\nsuch as random walk Metropolis or Gibbs sampling. However, HMC's performance is\nhighly sensitive to two user-specified parameters: a step size {\\epsilon} and a\ndesired number of steps L. In particular, if L is too small then the algorithm\nexhibits undesirable random walk behavior, while if L is too large the\nalgorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an\nextension to HMC that eliminates the need to set a number of steps L. NUTS uses\na recursive algorithm to build a set of likely candidate points that spans a\nwide swath of the target distribution, stopping automatically when it starts to\ndouble back and retrace its steps. Empirically, NUTS perform at least as\nefficiently as and sometimes more efficiently than a well tuned standard HMC\nmethod, without requiring user intervention or costly tuning runs. We also\nderive a method for adapting the step size parameter {\\epsilon} on the fly\nbased on primal-dual averaging. NUTS can thus be used with no hand-tuning at\nall. NUTS is also suitable for applications such as BUGS-style automatic\ninference engines that require efficient \"turnkey\" sampling algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 00:39:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hoffman", "Matthew D.", ""], ["Gelman", "Andrew", ""]]}, {"id": "1111.4460", "submitter": "Chong Jiang", "authors": "Chong Jiang and R. Srikant", "title": "Parametrized Stochastic Multi-armed Bandits with Binary Rewards", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of multi-armed bandits with a large,\npossibly infinite number of correlated arms. We assume that the arms have\nBernoulli distributed rewards, independent across time, where the probabilities\nof success are parametrized by known attribute vectors for each arm, as well as\nan unknown preference vector, each of dimension $n$. For this model, we seek an\nalgorithm with a total regret that is sub-linear in time and independent of the\nnumber of arms. We present such an algorithm, which we call the Two-Phase\nAlgorithm, and analyze its performance. We show upper bounds on the total\nregret which applies uniformly in time, for both the finite and infinite arm\ncases. The asymptotics of the finite arm bound show that for any $f \\in\n\\omega(\\log(T))$, the total regret can be made to be $O(n \\cdot f(T))$. In the\ninfinite arm case, the total regret is $O(\\sqrt{n^3 T})$.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 19:23:47 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Jiang", "Chong", ""], ["Srikant", "R.", ""]]}, {"id": "1111.4470", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb and Aryeh Kontorovich and Robert Krauthgamer", "title": "Efficient Regression in Metric Spaces via Approximate Lipschitz\n  Extension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for performing efficient regression in general metric\nspaces. Roughly speaking, our regressor predicts the value at a new point by\ncomputing a Lipschitz extension --- the smoothest function consistent with the\nobserved data --- after performing structural risk minimization to avoid\noverfitting. We obtain finite-sample risk bounds with minimal structural and\nnoise assumptions, and a natural speed-precision tradeoff. The offline\n(learning) and online (prediction) stages can be solved by convex programming,\nbut this naive approach has runtime complexity $O(n^3)$, which is prohibitive\nfor large datasets. We design instead a regression algorithm whose speed and\ngeneralization performance depend on the intrinsic dimension of the data, to\nwhich the algorithm adapts. While our main innovation is algorithmic, the\nstatistical results may also be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 20:32:33 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 17:06:29 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 07:56:53 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1111.4541", "submitter": "Lu Dang Khoa Nguyen", "authors": "Nguyen Lu Dang Khoa and Sanjay Chawla", "title": "Large Scale Spectral Clustering Using Approximate Commute Time Embedding", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-33492-4_4", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a novel clustering method which can detect complex\nshapes of data clusters. However, it requires the eigen decomposition of the\ngraph Laplacian matrix, which is proportion to $O(n^3)$ and thus is not\nsuitable for large scale systems. Recently, many methods have been proposed to\naccelerate the computational time of spectral clustering. These approximate\nmethods usually involve sampling techniques by which a lot information of the\noriginal data may be lost. In this work, we propose a fast and accurate\nspectral clustering approach using an approximate commute time embedding, which\nis similar to the spectral embedding. The method does not require using any\nsampling technique and computing any eigenvector at all. Instead it uses random\nprojection and a linear time solver to find the approximate embedding. The\nexperiments in several synthetic and real datasets show that the proposed\napproach has better clustering quality and is faster than the state-of-the-art\napproximate spectral clustering methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2011 08:39:34 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 04:19:56 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Khoa", "Nguyen Lu Dang", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1111.4802", "submitter": "Emmanuel Vazquez", "authors": "Romain Benassi and Julien Bect and Emmanuel Vazquez", "title": "Bayesian optimization using sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a real-valued continuous function $f$\nusing a Bayesian approach, where the evaluations of $f$ are chosen sequentially\nby combining prior information about $f$, which is described by a random\nprocess model, and past evaluation results. The main difficulty with this\napproach is to be able to compute the posterior distributions of quantities of\ninterest which are used to choose evaluation points. In this article, we decide\nto use a Sequential Monte Carlo (SMC) approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 09:47:51 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Benassi", "Romain", ""], ["Bect", "Julien", ""], ["Vazquez", "Emmanuel", ""]]}, {"id": "1111.5280", "submitter": "Silv\\`ere Bonnabel", "authors": "Silvere Bonnabel", "title": "Stochastic gradient descent on Riemannian manifolds", "comments": "A slightly shorter version has been published in IEEE Transactions\n  Automatic Control", "journal-ref": "IEEE Transactions on Automatic Control, Vol 58 (9), pages 2217 -\n  2229, Sept 2013", "doi": "10.1109/TAC.2013.2254619", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent is a simple approach to find the local minima of\na cost function whose evaluations are corrupted by noise. In this paper, we\ndevelop a procedure extending stochastic gradient descent algorithms to the\ncase where the function is defined on a Riemannian manifold. We prove that, as\nin the Euclidian case, the gradient descent algorithm converges to a critical\npoint of the cost function. The algorithm has numerous potential applications,\nand is illustrated here by four examples. In particular a novel gossip\nalgorithm on the set of covariance matrices is derived and tested numerically.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 18:41:12 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2012 16:08:29 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2013 10:41:46 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2013 11:56:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bonnabel", "Silvere", ""]]}, {"id": "1111.5479", "submitter": "Rahul Mazumder", "authors": "Rahul Mazumder, Trevor Hastie", "title": "The Graphical Lasso: New Insights and Alternatives", "comments": "This is a revised version of our previous manuscript with the same\n  name ArXiv id: http://arxiv.org/abs/1111.5479", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graphical lasso \\citep{FHT2007a} is an algorithm for learning the\nstructure in an undirected Gaussian graphical model, using $\\ell_1$\nregularization to control the number of zeros in the precision matrix\n${\\B\\Theta}={\\B\\Sigma}^{-1}$ \\citep{BGA2008,yuan_lin_07}. The {\\texttt R}\npackage \\GL\\ \\citep{FHT2007a} is popular, fast, and allows one to efficiently\nbuild a path of models for different values of the tuning parameter.\nConvergence of \\GL\\ can be tricky; the converged precision matrix might not be\nthe inverse of the estimated covariance, and occasionally it fails to converge\nwith warm starts. In this paper we explain this behavior, and propose new\nalgorithms that appear to outperform \\GL.\n  By studying the \"normal equations\" we see that, \\GL\\ is solving the {\\em\ndual} of the graphical lasso penalized likelihood, by block coordinate ascent;\na result which can also be found in \\cite{BGA2008}.\n  In this dual, the target of estimation is $\\B\\Sigma$, the covariance matrix,\nrather than the precision matrix $\\B\\Theta$. We propose similar primal\nalgorithms \\PGL\\ and \\DPGL, that also operate by block-coordinate descent,\nwhere $\\B\\Theta$ is the optimization target. We study all of these algorithms,\nand in particular different approaches to solving their coordinate\nsub-problems. We conclude that \\DPGL\\ is superior from several points of view.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 12:47:50 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 23:11:40 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Mazumder", "Rahul", ""], ["Hastie", "Trevor", ""]]}, {"id": "1111.5648", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Falsification and future performance", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We information-theoretically reformulate two measures of capacity from\nstatistical learning theory: empirical VC-entropy and empirical Rademacher\ncomplexity. We show these capacity measures count the number of hypotheses\nabout a dataset that a learning algorithm falsifies when it finds the\nclassifier in its repertoire minimizing empirical risk. It then follows from\nthat the future performance of predictors on unseen data is controlled in part\nby how many hypotheses the learner falsifies. As a corollary we show that\nempirical VC-entropy quantifies the message length of the true hypothesis in\nthe optimal code of a particular probability distribution, the so-called actual\nrepertoire.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 23:25:57 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1111.6082", "submitter": "Mehrdad Mahdavi", "authors": "Mehrdad Mahdavi, Rong Jin, Tianbao Yang", "title": "Trading Regret for Efficiency: Online Convex Optimization with Long Term\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a framework for solving constrained online convex\noptimization problem. Our motivation stems from the observation that most\nalgorithms proposed for online convex optimization require a projection onto\nthe convex set $\\mathcal{K}$ from which the decisions are made. While for\nsimple shapes (e.g. Euclidean ball) the projection is straightforward, for\narbitrary complex sets this is the main computational challenge and may be\ninefficient in practice. In this paper, we consider an alternative online\nconvex optimization problem. Instead of requiring decisions belong to\n$\\mathcal{K}$ for all rounds, we only require that the constraints which define\nthe set $\\mathcal{K}$ be satisfied in the long run. We show that our framework\ncan be utilized to solve a relaxed version of online learning with side\nconstraints addressed in \\cite{DBLP:conf/colt/MannorT06} and\n\\cite{DBLP:conf/aaai/KvetonYTM08}. By turning the problem into an online\nconvex-concave optimization problem, we propose an efficient algorithm which\nachieves $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret bound and\n$\\tilde{\\mathcal{O}}(T^{3/4})$ bound for the violation of constraints. Then we\nmodify the algorithm in order to guarantee that the constraints are satisfied\nin the long run. This gain is achieved at the price of getting\n$\\tilde{\\mathcal{O}}(T^{3/4})$ regret bound. Our second algorithm is based on\nthe Mirror Prox method \\citep{nemirovski-2005-prox} to solve variational\ninequalities which achieves $\\tilde{\\mathcal{\\mathcal{O}}}(T^{2/3})$ bound for\nboth regret and the violation of constraints when the domain $\\K$ can be\ndescribed by a finite number of linear constraints. Finally, we extend the\nresult to the setting where we only have partial access to the convex set\n$\\mathcal{K}$ and propose a multipoint bandit feedback algorithm with the same\nbounds in expectation as our first algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 18:51:29 GMT"}, {"version": "v2", "created": "Wed, 9 May 2012 15:21:25 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2012 22:02:49 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Mahdavi", "Mehrdad", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "1111.6201", "submitter": "Yi-Hao Kao", "authors": "Yi-Hao Kao and Benjamin Van Roy", "title": "Learning a Factor Model via Regularized PCA", "comments": null, "journal-ref": "Machine Learning, Volume 91, Number 3, pp. 279-303 (2013)", "doi": "10.1007/s10994-013-5345-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a linear factor model. We propose a\nregularized form of principal component analysis (PCA) and demonstrate through\nexperiments with synthetic and real data the superiority of resulting estimates\nto those produced by pre-existing factor analysis approaches. We also establish\ntheoretical results that explain how our algorithm corrects the biases induced\nby conventional approaches. An important feature of our algorithm is that its\ncomputational requirements are similar to those of PCA, which enjoys wide use\nin large part due to its efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2011 23:36:40 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2012 21:50:49 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2012 20:52:14 GMT"}, {"version": "v4", "created": "Sun, 24 Feb 2013 05:01:59 GMT"}], "update_date": "2013-05-31", "authors_parsed": [["Kao", "Yi-Hao", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1111.6214", "submitter": "Adel Javanmard", "authors": "Morteza Ibrahimi, Adel Javanmard, Yashodhan Kanoria and Andrea\n  Montanari", "title": "Robust Max-Product Belief Propagation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing a graph-structured objective function\nunder \\emph{adversarial} uncertainty. This problem can be modeled as a\ntwo-persons zero-sum game between an Engineer and Nature. The Engineer controls\na subset of the variables (nodes in the graph), and tries to assign their\nvalues to maximize an objective function. Nature controls the complementary\nsubset of variables and tries to minimize the same objective. This setting\nencompasses estimation and optimization problems under model uncertainty, and\nstrategic problems with a graph structure. Von Neumann's minimax theorem\nguarantees the existence of a (minimax) pair of randomized strategies that\nprovide optimal robustness for each player against its adversary.\n  We prove several structural properties of this strategy pair in the case of\ngraph-structured payoff function. In particular, the randomized minimax\nstrategies (distributions over variable assignments) can be chosen in such a\nway to satisfy the Markov property with respect to the graph. This\nsignificantly reduces the problem dimensionality. Finally we introduce a\nmessage passing algorithm to solve this minimax problem. The algorithm\ngeneralizes max-product belief propagation to this new domain.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 02:02:53 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Ibrahimi", "Morteza", ""], ["Javanmard", "Adel", ""], ["Kanoria", "Yashodhan", ""], ["Montanari", "Andrea", ""]]}, {"id": "1111.6337", "submitter": "Tianbao Yang", "authors": "Tianbao Yang, Mehrdad Mahdavi, Rong Jin, Shenghuo Zhu", "title": "Regret Bound by Variation for Online Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In citep{Hazan-2008-extract}, the authors showed that the regret of online\nlinear optimization can be bounded by the total variation of the cost vectors.\nIn this paper, we extend this result to general online convex optimization. We\nfirst analyze the limitations of the algorithm in \\citep{Hazan-2008-extract}\nwhen applied it to online convex optimization. We then present two algorithms\nfor online convex optimization whose regrets are bounded by the variation of\ncost functions. We finally consider the bandit setting, and present a\nrandomized algorithm for online bandit convex optimization with a\nvariation-based regret bound. We show that the regret bound for online bandit\nconvex optimization is optimal when the variation of cost functions is\nindependent of the number of trials.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 03:50:18 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 14:05:49 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2012 21:56:31 GMT"}, {"version": "v4", "created": "Thu, 14 Jun 2012 01:40:01 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Yang", "Tianbao", ""], ["Mahdavi", "Mehrdad", ""], ["Jin", "Rong", ""], ["Zhu", "Shenghuo", ""]]}, {"id": "1111.6453", "submitter": "Francis Bach", "authors": "Francis Bach (LIENS, INRIA Paris - Rocquencourt)", "title": "Learning with Submodular Functions: A Convex Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are relevant to machine learning for at least two\nreasons: (1) some problems may be expressed directly as the optimization of\nsubmodular functions and (2) the lovasz extension of submodular functions\nprovides a useful set of regularization functions for supervised and\nunsupervised learning. In this monograph, we present the theory of submodular\nfunctions from a convex analysis perspective, presenting tight links between\ncertain polyhedra, combinatorial optimization and convex optimization problems.\nIn particular, we show how submodular function minimization is equivalent to\nsolving a wide variety of convex optimization problems. This allows the\nderivation of new efficient algorithms for approximate and exact submodular\nfunction minimization with theoretical guarantees and good practical\nperformance. By listing many examples of submodular functions, we review\nvarious applications to machine learning, such as clustering, experimental\ndesign, sensor placement, graphical model structure learning or subset\nselection, as well as a family of structured sparsity-inducing norms that can\nbe derived and used from submodular functions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 14:45:01 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2013 07:22:08 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Bach", "Francis", "", "LIENS, INRIA Paris - Rocquencourt"]]}, {"id": "1111.6473", "submitter": "Antti Airola", "authors": "Willem Waegeman, Tapio Pahikkala, Antti Airola, Tapio Salakoski,\n  Michiel Stock, Bernard De Baets", "title": "A kernel-based framework for learning graded relations from data", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": "10.1109/TFUZZ.2012.2194151", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by a large number of potential applications in areas like\nbioinformatics, information retrieval and social network analysis, the problem\nsetting of inferring relations between pairs of data objects has recently been\ninvestigated quite intensively in the machine learning community. To this end,\ncurrent approaches typically consider datasets containing crisp relations, so\nthat standard classification methods can be adopted. However, relations between\nobjects like similarities and preferences are often expressed in a graded\nmanner in real-world applications. A general kernel-based framework for\nlearning relations from data is introduced here. It extends existing approaches\nbecause both crisp and graded relations are considered, and it unifies existing\napproaches because different types of graded relations can be modeled,\nincluding symmetric and reciprocal relations. This framework establishes\nimportant links between recent developments in fuzzy set theory and machine\nlearning. Its usefulness is demonstrated through various experiments on\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 15:28:53 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Waegeman", "Willem", ""], ["Pahikkala", "Tapio", ""], ["Airola", "Antti", ""], ["Salakoski", "Tapio", ""], ["Stock", "Michiel", ""], ["De Baets", "Bernard", ""]]}, {"id": "1111.6842", "submitter": "Aaron Roth", "authors": "Avrim Blum and Aaron Roth", "title": "Fast Private Data Release Algorithms for Sparse Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of accurately answering large classes of statistical\nqueries while preserving differential privacy. Previous approaches to this\nproblem have either been very general but have not had run-time polynomial in\nthe size of the database, have applied only to very limited classes of queries,\nor have relaxed the notion of worst-case error guarantees. In this paper we\nconsider the large class of sparse queries, which take non-zero values on only\npolynomially many universe elements. We give efficient query release algorithms\nfor this class, in both the interactive and the non-interactive setting. Our\nalgorithms also achieve better accuracy bounds than previous general techniques\ndo when applied to sparse queries: our bounds are independent of the universe\nsize. In fact, even the runtime of our interactive mechanism is independent of\nthe universe size, and so can be implemented in the \"infinite universe\" model\nin which no finite universe need be specified by the data curator.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 15:23:08 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Blum", "Avrim", ""], ["Roth", "Aaron", ""]]}, {"id": "1111.6857", "submitter": "Nicholas Timme", "authors": "Nicholas Timme, Wesley Alford, Benjamin Flecker, and John M. Beggs", "title": "Multivariate information measures: an experimentalist's perspective", "comments": "Manuscript (15 pages, 3 figures, 8 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory is widely accepted as a powerful tool for analyzing\ncomplex systems and it has been applied in many disciplines. Recently, some\ncentral components of information theory - multivariate information measures -\nhave found expanded use in the study of several phenomena. These information\nmeasures differ in subtle yet significant ways. Here, we will review the\ninformation theory behind each measure, as well as examine the differences\nbetween these measures by applying them to several simple model systems. In\naddition to these systems, we will illustrate the usefulness of the information\nmeasures by analyzing neural spiking data from a dissociated culture through\nearly stages of its development. We hope that this work will aid other\nresearchers as they seek the best multivariate information measure for their\nspecific research goals and system. Finally, we have made software available\nonline which allows the user to calculate all of the information measures\ndiscussed within this paper.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 18:03:04 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 16:08:00 GMT"}, {"version": "v3", "created": "Thu, 31 May 2012 17:18:58 GMT"}, {"version": "v4", "created": "Wed, 25 Jul 2012 13:57:00 GMT"}, {"version": "v5", "created": "Wed, 29 Aug 2012 15:23:09 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Timme", "Nicholas", ""], ["Alford", "Wesley", ""], ["Flecker", "Benjamin", ""], ["Beggs", "John M.", ""]]}, {"id": "1111.6925", "submitter": "Yang Zhou", "authors": "Yang Zhou", "title": "Structure Learning of Probabilistic Graphical Models: A Comprehensive\n  Survey", "comments": "survey on structure learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models combine the graph theory and probability\ntheory to give a multivariate statistical modeling. They provide a unified\ndescription of uncertainty using probability and complexity using the graphical\nmodel. Especially, graphical models provide the following several useful\nproperties:\n  - Graphical models provide a simple and intuitive interpretation of the\nstructures of probabilistic models. On the other hand, they can be used to\ndesign and motivate new models.\n  - Graphical models provide additional insights into the properties of the\nmodel, including the conditional independence properties.\n  - Complex computations which are required to perform inference and learning\nin sophisticated models can be expressed in terms of graphical manipulations,\nin which the underlying mathematical expressions are carried along implicitly.\n  The graphical models have been applied to a large number of fields, including\nbioinformatics, social science, control theory, image processing, marketing\nanalysis, among others. However, structure learning for graphical models\nremains an open challenge, since one must cope with a combinatorial search over\nthe space of all possible structures.\n  In this paper, we present a comprehensive survey of the existing structure\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 18:33:01 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Zhou", "Yang", ""]]}, {"id": "1111.6937", "submitter": "Matteo Riondato", "authors": "Matteo Riondato and Eli Upfal", "title": "Efficient Discovery of Association Rules and Frequent Itemsets through\n  Sampling with Tight Performance Guarantees", "comments": "19 pages, 7 figures. A shorter version of this paper appeared in the\n  proceedings of ECML PKDD 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tasks of extracting (top-$K$) Frequent Itemsets (FI's) and Association\nRules (AR's) are fundamental primitives in data mining and database\napplications. Exact algorithms for these problems exist and are widely used,\nbut their running time is hindered by the need of scanning the entire dataset,\npossibly multiple times. High quality approximations of FI's and AR's are\nsufficient for most practical uses, and a number of recent works explored the\napplication of sampling for fast discovery of approximate solutions to the\nproblems. However, these works do not provide satisfactory performance\nguarantees on the quality of the approximation, due to the difficulty of\nbounding the probability of under- or over-sampling any one of an unknown\nnumber of frequent itemsets. In this work we circumvent this issue by applying\nthe statistical concept of \\emph{Vapnik-Chervonenkis (VC) dimension} to develop\na novel technique for providing tight bounds on the sample size that guarantees\napproximation within user-specified parameters. Our technique applies both to\nabsolute and to relative approximations of (top-$K$) FI's and AR's. The\nresulting sample size is linearly dependent on the VC-dimension of a range\nspace associated with the dataset to be mined. The main theoretical\ncontribution of this work is a proof that the VC-dimension of this range space\nis upper bounded by an easy-to-compute characteristic quantity of the dataset\nwhich we call \\emph{d-index}, and is the maximum integer $d$ such that the\ndataset contains at least $d$ transactions of length at least $d$ such that no\none of them is a superset of or equal to another. We show that this bound is\nstrict for a large class of datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 19:11:50 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 14:45:50 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2012 02:39:09 GMT"}, {"version": "v4", "created": "Thu, 21 Jun 2012 12:56:59 GMT"}, {"version": "v5", "created": "Mon, 10 Dec 2012 20:07:02 GMT"}, {"version": "v6", "created": "Fri, 22 Feb 2013 14:32:31 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Riondato", "Matteo", ""], ["Upfal", "Eli", ""]]}, {"id": "1111.7219", "submitter": "Anteo Smerieri", "authors": "Yvan Paquot, Fran\\c{c}ois Duport, Anteo Smerieri, Joni Dambre,\n  Benjamin Schrauwen, Marc Haelterman and Serge Massar", "title": "Optoelectronic Reservoir Computing", "comments": "Contains main paper and two Supplementary Materials", "journal-ref": "Scientific Reports 2, Article number: 287, (2012)", "doi": "10.1038/srep00287", "report-no": null, "categories": "cs.ET cs.LG cs.NE nlin.CD physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a recently introduced, highly efficient bio-inspired\napproach for processing time dependent data. The basic scheme of reservoir\ncomputing consists of a non linear recurrent dynamical system coupled to a\nsingle input layer and a single output layer. Within these constraints many\nimplementations are possible. Here we report an opto-electronic implementation\nof reservoir computing based on a recently proposed architecture consisting of\na single non linear node and a delay line. Our implementation is sufficiently\nfast for real time information processing. We illustrate its performance on\ntasks of practical importance such as nonlinear channel equalization and speech\nrecognition, and obtain results comparable to state of the art digital\nimplementations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 15:50:58 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Paquot", "Yvan", ""], ["Duport", "Fran\u00e7ois", ""], ["Smerieri", "Anteo", ""], ["Dambre", "Joni", ""], ["Schrauwen", "Benjamin", ""], ["Haelterman", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "1111.7295", "submitter": "Prateek Jain", "authors": "Raajay Viswanathan, Prateek Jain, Srivatsan Laxman, Arvind Arasu", "title": "A Learning Framework for Self-Tuning Histograms", "comments": "Submitted to VLDB-2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating self-tuning histograms\nusing query workloads. To this end, we propose a general learning theoretic\nformulation. Specifically, we use query feedback from a workload as training\ndata to estimate a histogram with a small memory footprint that minimizes the\nexpected error on future queries. Our formulation provides a framework in which\ndifferent approaches can be studied and developed. We first study the simple\nclass of equi-width histograms and present a learning algorithm, EquiHist, that\nis competitive in many settings. We also provide formal guarantees for\nequi-width histograms that highlight scenarios in which equi-width histograms\ncan be expected to succeed or fail. We then go beyond equi-width histograms and\npresent a novel learning algorithm, SpHist, for estimating general histograms.\nHere we use Haar wavelets to reduce the problem of learning histograms to that\nof learning a sparse vector. Both algorithms have multiple advantages over\nexisting methods: 1) simple and scalable extensions to multi-dimensional data,\n2) scalability with number of histogram buckets and size of query feedback, 3)\nnatural extensions to incorporate new feedback and handle database updates. We\ndemonstrate these advantages over the current state-of-the-art, ISOMER, through\ndetailed experiments on real and synthetic data. In particular, we show that\nSpHist obtains up to 50% less error than ISOMER on real-world multi-dimensional\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 20:17:29 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2011 16:01:50 GMT"}], "update_date": "2011-12-05", "authors_parsed": [["Viswanathan", "Raajay", ""], ["Jain", "Prateek", ""], ["Laxman", "Srivatsan", ""], ["Arasu", "Arvind", ""]]}]