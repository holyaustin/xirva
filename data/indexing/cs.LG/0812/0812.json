[{"id": "0812.0382", "submitter": "Andrea Vattani", "authors": "Andrea Vattani", "title": "k-means requires exponentially many iterations even in the plane", "comments": "Submitted to SoCG 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means algorithm is a well-known method for partitioning n points that\nlie in the d-dimensional space into k clusters. Its main features are\nsimplicity and speed in practice. Theoretically, however, the best known upper\nbound on its running time (i.e. O(n^{kd})) can be exponential in the number of\npoints. Recently, Arthur and Vassilvitskii [3] showed a super-polynomial\nworst-case analysis, improving the best known lower bound from \\Omega(n) to\n2^{\\Omega(\\sqrt{n})} with a construction in d=\\Omega(\\sqrt{n}) dimensions. In\n[3] they also conjectured the existence of superpolynomial lower bounds for any\nd >= 2.\n  Our contribution is twofold: we prove this conjecture and we improve the\nlower bound, by presenting a simple construction in the plane that leads to the\nexponential lower bound 2^{\\Omega(n)}.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2008 22:55:39 GMT"}], "update_date": "2008-12-03", "authors_parsed": [["Vattani", "Andrea", ""]]}, {"id": "0812.0389", "submitter": "Stefanie Jegelka", "authors": "Stefanie Jegelka, Suvrit Sra, Arindam Banerjee", "title": "Approximation Algorithms for Bregman Co-clustering and Tensor Clustering", "comments": "18 pages; improved metric case", "journal-ref": "short version in ALT 2009", "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years powerful generalizations to the Euclidean k-means\nproblem have been made, such as Bregman clustering [7], co-clustering (i.e.,\nsimultaneous clustering of rows and columns of an input matrix) [9,18], and\ntensor clustering [8,34]. Like k-means, these more general problems also suffer\nfrom the NP-hardness of the associated optimization. Researchers have developed\napproximation algorithms of varying degrees of sophistication for k-means,\nk-medians, and more recently also for Bregman clustering [2]. However, there\nseem to be no approximation algorithms for Bregman co- and tensor clustering.\nIn this paper we derive the first (to our knowledge) guaranteed methods for\nthese increasingly important clustering settings. Going beyond Bregman\ndivergences, we also prove an approximation factor for tensor clustering with\narbitrary separable metrics. Through extensive experiments we evaluate the\ncharacteristics of our method, and show that it also has practical impact.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2008 23:17:35 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2009 12:40:18 GMT"}, {"version": "v3", "created": "Fri, 15 May 2009 22:23:02 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2009 15:50:32 GMT"}], "update_date": "2009-11-09", "authors_parsed": [["Jegelka", "Stefanie", ""], ["Sra", "Suvrit", ""], ["Banerjee", "Arindam", ""]]}, {"id": "0812.0743", "submitter": "Qiang Li", "authors": "Qiang Li, Yan He, Jing-ping Jiang", "title": "A Novel Clustering Algorithm Based on Quantum Games", "comments": "19 pages, 5 figures, 5 tables", "journal-ref": "2009 J. Phys. A: Math. Theor. 42 445303", "doi": "10.1088/1751-8113/42/44/445303", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GT cs.MA cs.NE quant-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum game with the problem of data\nclustering, and then develop a quantum-game-based clustering algorithm, in\nwhich data points in a dataset are considered as players who can make decisions\nand implement quantum strategies in quantum games. After each round of a\nquantum game, each player's expected payoff is calculated. Later, he uses a\nlink-removing-and-rewiring (LRR) function to change his neighbors and adjust\nthe strength of links connecting to them in order to maximize his payoff.\nFurther, algorithms are discussed and analyzed in two cases of strategies, two\npayoff matrixes and two LRR functions. Consequently, the simulation results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms have fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2008 15:46:03 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2009 09:10:36 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Li", "Qiang", ""], ["He", "Yan", ""], ["Jiang", "Jing-ping", ""]]}, {"id": "0812.0933", "submitter": "Adam Kalai", "authors": "Adam Tauman Kalai and Shang-Hua Teng", "title": "Decision trees are PAC-learnable from most product distributions: a\n  smoothed analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of PAC-learning decision trees, i.e., learning a\ndecision tree over the n-dimensional hypercube from independent random labeled\nexamples. Despite significant effort, no polynomial-time algorithm is known for\nlearning polynomial-sized decision trees (even trees of any super-constant\nsize), even when examples are assumed to be drawn from the uniform distribution\non {0,1}^n. We give an algorithm that learns arbitrary polynomial-sized\ndecision trees for {\\em most product distributions}. In particular, consider a\nrandom product distribution where the bias of each bit is chosen independently\nand uniformly from, say, [.49,.51]. Then with high probability over the\nparameters of the product distribution and the random examples drawn from it,\nthe algorithm will learn any tree. More generally, in the spirit of smoothed\nanalysis, we consider an arbitrary product distribution whose parameters are\nspecified only up to a [-c,c] accuracy (perturbation), for an arbitrarily small\npositive constant c.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2008 13:34:26 GMT"}], "update_date": "2008-12-05", "authors_parsed": [["Kalai", "Adam Tauman", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "0812.1029", "submitter": "Alaa Abi Haidar", "authors": "Alaa Abi-Haidar, Jasleen Kaur, Ana G. Maguitman, Predrag Radivojac,\n  Andreas Retchsteiner, Karin Verspoor, Zhiping Wang, Luis M. Rocha", "title": "Uncovering protein interaction in abstracts and text using a novel\n  linear model and word proximity networks", "comments": null, "journal-ref": "Genome Biology 2008, 9(Suppl 2):S11", "doi": "10.1186/gb-2008-9-s2-s11", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated in three of the protein-protein interaction subtasks of the\nSecond BioCreative Challenge: classification of abstracts relevant for\nprotein-protein interaction (IAS), discovery of protein pairs (IPS) and text\npassages characterizing protein interaction (ISS) in full text documents. We\napproached the abstract classification task with a novel, lightweight linear\nmodel inspired by spam-detection techniques, as well as an uncertainty-based\nintegration scheme. We also used a Support Vector Machine and the Singular\nValue Decomposition on the same features for comparison purposes. Our approach\nto the full text subtasks (protein pair and passage identification) includes a\nfeature expansion method based on word-proximity networks. Our approach to the\nabstract classification task (IAS) was among the top submissions for this task\nin terms of the measures of performance used in the challenge evaluation\n(accuracy, F-score and AUC). We also report on a web-tool we produced using our\napproach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Our\napproach to the full text tasks resulted in one of the highest recall rates as\nwell as mean reciprocal rank of correct passages. Our approach to abstract\nclassification shows that a simple linear model, using relatively few features,\nis capable of generalizing and uncovering the conceptual nature of\nprotein-protein interaction from the bibliome. Since the novel approach is\nbased on a very lightweight linear model, it can be easily ported and applied\nto similar problems. In full text problems, the expansion of word features with\nword-proximity networks is shown to be useful, though the need for some\nimprovements is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2008 21:37:35 GMT"}], "update_date": "2008-12-08", "authors_parsed": [["Abi-Haidar", "Alaa", ""], ["Kaur", "Jasleen", ""], ["Maguitman", "Ana G.", ""], ["Radivojac", "Predrag", ""], ["Retchsteiner", "Andreas", ""], ["Verspoor", "Karin", ""], ["Wang", "Zhiping", ""], ["Rocha", "Luis M.", ""]]}, {"id": "0812.1244", "submitter": "Fangwen Fu", "authors": "Fangwen Fu, Mihaela van der Schaar", "title": "Decomposition Principles and Online Learning in Cross-Layer Optimization\n  for Delay-Sensitive Applications", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general cross-layer optimization framework in\nwhich we explicitly consider both the heterogeneous and dynamically changing\ncharacteristics of delay-sensitive applications and the underlying time-varying\nnetwork conditions. We consider both the independently decodable data units\n(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured\nby a directed acyclic graph (DAG). We first formulate the cross-layer design as\na non-linear constrained optimization problem by assuming complete knowledge of\nthe application characteristics and the underlying network conditions. The\nconstrained cross-layer optimization is decomposed into several cross-layer\noptimization subproblems for each DU and two master problems. The proposed\ndecomposition method determines the necessary message exchanges between layers\nfor achieving the optimal cross-layer solution. However, the attributes (e.g.\ndistortion impact, delay deadline etc) of future DUs as well as the network\nconditions are often unknown in the considered real-time applications. The\nimpact of current cross-layer actions on the future DUs can be characterized by\na state-value function in the Markov decision process (MDP) framework. Based on\nthe dynamic programming solution to the MDP, we develop a low-complexity\ncross-layer optimization algorithm using online learning for each DU\ntransmission. This online algorithm can be implemented in real-time in order to\ncope with unknown source characteristics, network dynamics and resource\nconstraints. Our numerical results demonstrate the efficiency of the proposed\nonline algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2008 23:14:41 GMT"}], "update_date": "2008-12-09", "authors_parsed": [["Fu", "Fangwen", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "0812.1357", "submitter": "Qiang Li", "authors": "Qiang Li, Yan He, Jing-ping Jiang", "title": "A Novel Clustering Algorithm Based on Quantum Random Walk", "comments": "14 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum random walk (QRW) with the\nproblem of data clustering, and develop two clustering algorithms based on the\none dimensional QRW. Then, the probability distributions on the positions\ninduced by QRW in these algorithms are investigated, which also indicates the\npossibility of obtaining better results. Consequently, the experimental results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms are of fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Dec 2008 15:22:27 GMT"}], "update_date": "2008-12-09", "authors_parsed": [["Li", "Qiang", ""], ["He", "Yan", ""], ["Jiang", "Jing-ping", ""]]}, {"id": "0812.1869", "submitter": "Francis Bach", "authors": "Francis Bach (INRIA Rocquencourt), Julien Mairal (INRIA Rocquencourt),\n  Jean Ponce (INRIA Rocquencourt)", "title": "Convex Sparse Matrix Factorizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convex formulation of dictionary learning for sparse signal\ndecomposition. Convexity is obtained by replacing the usual explicit upper\nbound on the dictionary size by a convex rank-reducing term similar to the\ntrace norm. In particular, our formulation introduces an explicit trade-off\nbetween size and sparsity of the decomposition of rectangular matrices. Using a\nlarge set of synthetic examples, we compare the estimation abilities of the\nconvex and non-convex approaches, showing that while the convex formulation has\na single local minimum, this may lead in some cases to performance which is\ninferior to the local minima of the non-convex formulation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2008 09:00:40 GMT"}], "update_date": "2008-12-11", "authors_parsed": [["Bach", "Francis", "", "INRIA Rocquencourt"], ["Mairal", "Julien", "", "INRIA Rocquencourt"], ["Ponce", "Jean", "", "INRIA Rocquencourt"]]}, {"id": "0812.2291", "submitter": "Aleksandrs Slivkins", "authors": "Moshe Babaioff, Yogeshwer Sharma, Aleksandrs Slivkins", "title": "Characterizing Truthful Multi-Armed Bandit Mechanisms", "comments": "This is the full version of a conference paper published in ACM EC\n  2009. This revision is re-focused to emphasize the results that do not rely\n  on the \"IIA assumption\" (see the paper for the definition)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-round auction setting motivated by pay-per-click auctions\nfor Internet advertising. In each round the auctioneer selects an advertiser\nand shows her ad, which is then either clicked or not. An advertiser derives\nvalue from clicks; the value of a click is her private information. Initially,\nneither the auctioneer nor the advertisers have any information about the\nlikelihood of clicks on the advertisements. The auctioneer's goal is to design\na (dominant strategies) truthful mechanism that (approximately) maximizes the\nsocial welfare.\n  If the advertisers bid their true private values, our problem is equivalent\nto the \"multi-armed bandit problem\", and thus can be viewed as a strategic\nversion of the latter. In particular, for both problems the quality of an\nalgorithm can be characterized by \"regret\", the difference in social welfare\nbetween the algorithm and the benchmark which always selects the same \"best\"\nadvertisement. We investigate how the design of multi-armed bandit algorithms\nis affected by the restriction that the resulting mechanism must be truthful.\nWe find that truthful mechanisms have certain strong structural properties --\nessentially, they must separate exploration from exploitation -- and they incur\nmuch higher regret than the optimal multi-armed bandit algorithms. Moreover, we\nprovide a truthful mechanism which (essentially) matches our lower bound on\nregret.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2008 04:13:01 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2009 01:56:08 GMT"}, {"version": "v3", "created": "Fri, 20 Feb 2009 18:10:47 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2009 02:21:56 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2009 00:17:44 GMT"}, {"version": "v6", "created": "Tue, 15 May 2012 22:57:53 GMT"}, {"version": "v7", "created": "Mon, 3 Jun 2013 21:03:36 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Babaioff", "Moshe", ""], ["Sharma", "Yogeshwer", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "0812.2574", "submitter": "SeyyedMajid Valiollahzadeh", "authors": "Seyyed Majid Valiollahzadeh, Abolghasem Sayadiyan, Mohammad Nazari", "title": "Feature Selection By KDDA For SVM-Based MultiView Face Recognition", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "IEEE SETIT 2007", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications such as face recognition that deal with high-dimensional data\nneed a mapping technique that introduces representation of low-dimensional\nfeatures with enhanced discriminatory power and a proper classifier, able to\nclassify those complex features. Most of traditional Linear Discriminant\nAnalysis suffer from the disadvantage that their optimality criteria are not\ndirectly related to the classification ability of the obtained feature\nrepresentation. Moreover, their classification accuracy is affected by the\n\"small sample size\" problem which is often encountered in FR tasks. In this\nshort paper, we combine nonlinear kernel based mapping of data called KDDA with\nSupport Vector machine classifier to deal with both of the shortcomings in an\nefficient and cost effective manner. The proposed here method is compared, in\nterms of classification accuracy, to other commonly used FR methods on UMIST\nface database. Results indicate that the performance of the proposed method is\noverall superior to those of traditional FR approaches, such as the Eigenfaces,\nFisherfaces, and D-LDA methods and traditional linear classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2008 19:09:03 GMT"}], "update_date": "2008-12-16", "authors_parsed": [["Valiollahzadeh", "Seyyed Majid", ""], ["Sayadiyan", "Abolghasem", ""], ["Nazari", "Mohammad", ""]]}, {"id": "0812.2575", "submitter": "SeyyedMajid Valiollahzadeh", "authors": "Seyyed Majid Valiollahzadeh, Abolghasem Sayadiyan, Mohammad Nazari", "title": "Face Detection Using Adaboosted SVM-Based Component Classifier", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": "ICEIS Portugal 2007", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Adaboost has been widely used to improve the accuracy of any given\nlearning algorithm. In this paper we focus on designing an algorithm to employ\ncombination of Adaboost with Support Vector Machine as weak component\nclassifiers to be used in Face Detection Task. To obtain a set of effective\nSVM-weaklearner Classifier, this algorithm adaptively adjusts the kernel\nparameter in SVM instead of using a fixed one. Proposed combination outperforms\nin generalization in comparison with SVM on imbalanced classification problem.\nThe proposed here method is compared, in terms of classification accuracy, to\nother commonly used Adaboost methods, such as Decision Trees and Neural\nNetworks, on CMU+MIT face database. Results indicate that the performance of\nthe proposed method is overall superior to previous Adaboost approaches.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2008 19:14:53 GMT"}], "update_date": "2008-12-16", "authors_parsed": [["Valiollahzadeh", "Seyyed Majid", ""], ["Sayadiyan", "Abolghasem", ""], ["Nazari", "Mohammad", ""]]}, {"id": "0812.3145", "submitter": "Todd Young", "authors": "Erik Boczko, Andrew DiLullo and Todd Young", "title": "Binary Classification Based on Potentials", "comments": "5 pages, 2 figures. Presented at the Ohio Collaborative Conference on\n  Bioinformatics (OCCBIO) June 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and computationally trivial method for binary\nclassification based on the evaluation of potential functions. We demonstrate\nthat despite the conceptual and computational simplicity of the method its\nperformance can match or exceed that of standard Support Vector Machine\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2008 20:41:06 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2008 21:05:28 GMT"}], "update_date": "2008-12-17", "authors_parsed": [["Boczko", "Erik", ""], ["DiLullo", "Andrew", ""], ["Young", "Todd", ""]]}, {"id": "0812.3147", "submitter": "Todd Young", "authors": "Erik M. Boczko, Todd Young, Minhui Zie, and Di Wu", "title": "Comparison of Binary Classification Based on Signed Distance Functions\n  with Support Vector Machines", "comments": "5 pages, 4 figures. Presented at the Ohio Collaborative Conference on\n  Bioinformatics (OCCBIO), June 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of a simple signed distance function (SDF)\nbased method by direct comparison with standard SVM packages, as well as\nK-nearest neighbor and RBFN methods. We present experimental results comparing\nthe SDF approach with other classifiers on both synthetic geometric problems\nand five benchmark clinical microarray data sets. On both geometric problems\nand microarray data sets, the non-optimized SDF based classifiers perform just\nas well or slightly better than well-developed, standard SVM methods. These\nresults demonstrate the potential accuracy of SDF-based methods on some types\nof problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2008 20:58:24 GMT"}], "update_date": "2008-12-17", "authors_parsed": [["Boczko", "Erik M.", ""], ["Young", "Todd", ""], ["Zie", "Minhui", ""], ["Wu", "Di", ""]]}, {"id": "0812.3429", "submitter": "Dmitry Gavinsky", "authors": "Dmitry Gavinsky", "title": "Quantum Predictive Learning and Communication Complexity with Single\n  Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new model of quantum learning that we call Predictive Quantum\n(PQ). This is a quantum analogue of PAC, where during the testing phase the\nstudent is only required to answer a polynomial number of testing queries.\n  We demonstrate a relational concept class that is efficiently learnable in\nPQ, while in any \"reasonable\" classical model exponential amount of training\ndata would be required. This is the first unconditional separation between\nquantum and classical learning.\n  We show that our separation is the best possible in several ways; in\nparticular, there is no analogous result for a functional class, as well as for\nseveral weaker versions of quantum learning. In order to demonstrate tightness\nof our separation we consider a special case of one-way communication that we\ncall single-input mode, where Bob receives no input. Somewhat surprisingly,\nthis setting becomes nontrivial when relational communication tasks are\nconsidered. In particular, any problem with two-sided input can be transformed\ninto a single-input relational problem of equal classical one-way cost. We show\nthat the situation is different in the quantum case, where the same\ntransformation can make the communication complexity exponentially larger. This\nhappens if and only if the original problem has exponential gap between quantum\nand classical one-way communication costs. We believe that these auxiliary\nresults might be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2008 22:46:18 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2010 05:06:20 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2012 03:31:18 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Gavinsky", "Dmitry", ""]]}, {"id": "0812.3465", "submitter": "Paat Rusmevichientong", "authors": "Paat Rusmevichientong and John N. Tsitsiklis", "title": "Linearly Parameterized Bandits", "comments": "40 pages; updated results and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bandit problems involving a large (possibly infinite) collection\nof arms, in which the expected reward of each arm is a linear function of an\n$r$-dimensional random vector $\\mathbf{Z} \\in \\mathbb{R}^r$, where $r \\geq 2$.\nThe objective is to minimize the cumulative regret and Bayes risk. When the set\nof arms corresponds to the unit sphere, we prove that the regret and Bayes risk\nis of order $\\Theta(r \\sqrt{T})$, by establishing a lower bound for an\narbitrary policy, and showing that a matching upper bound is obtained through a\npolicy that alternates between exploration and exploitation phases. The\nphase-based policy is also shown to be effective if the set of arms satisfies a\nstrong convexity condition. For the case of a general set of arms, we describe\na near-optimal policy whose regret and Bayes risk admit upper bounds of the\nform $O(r \\sqrt{T} \\log^{3/2} T)$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2008 07:59:33 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2010 15:54:49 GMT"}], "update_date": "2010-02-24", "authors_parsed": [["Rusmevichientong", "Paat", ""], ["Tsitsiklis", "John N.", ""]]}, {"id": "0812.4044", "submitter": "John Langford", "authors": "Alina Beygelzimer and John Langford", "title": "The Offset Tree for Learning with Partial Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an algorithm, called the Offset Tree, for learning to make\ndecisions in situations where the payoff of only one choice is observed, rather\nthan all choices. The algorithm reduces this setting to binary classification,\nallowing one to reuse of any existing, fully supervised binary classification\nalgorithm in this partial information setting. We show that the Offset Tree is\nan optimal reduction to binary classification. In particular, it has regret at\nmost $(k-1)$ times the regret of the binary classifier it uses (where $k$ is\nthe number of choices), and no reduction to binary classification can do\nbetter. This reduction is also computationally optimal, both at training and\ntest time, requiring just $O(\\log_2 k)$ work to train on an example or make a\nprediction.\n  Experiments with the Offset Tree show that it generally performs better than\nseveral alternative approaches.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2008 17:45:27 GMT"}, {"version": "v2", "created": "Sat, 7 Feb 2009 01:48:33 GMT"}, {"version": "v3", "created": "Sun, 3 Apr 2016 21:41:38 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Beygelzimer", "Alina", ""], ["Langford", "John", ""]]}, {"id": "0812.4235", "submitter": "Francesco Dinuzzo", "authors": "Francesco Dinuzzo, Gianluigi Pillonetto, Giuseppe De Nicolao", "title": "Client-server multi-task learning from distributed datasets", "comments": null, "journal-ref": null, "doi": "10.1109/TNN.2010.2095882", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A client-server architecture to simultaneously solve multiple learning tasks\nfrom distributed datasets is described. In such architecture, each client is\nassociated with an individual learning task and the associated dataset of\nexamples. The goal of the architecture is to perform information fusion from\nmultiple datasets while preserving privacy of individual data. The role of the\nserver is to collect data in real-time from the clients and codify the\ninformation in a common database. The information coded in this database can be\nused by all the clients to solve their individual learning task, so that each\nclient can exploit the informative content of all the datasets without actually\nhaving access to private data of others. The proposed algorithmic framework,\nbased on regularization theory and kernel methods, uses a suitable class of\nmixed effect kernels. The new method is illustrated through a simulated music\nrecommendation system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2008 16:34:39 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2010 15:37:43 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Dinuzzo", "Francesco", ""], ["Pillonetto", "Gianluigi", ""], ["De Nicolao", "Giuseppe", ""]]}, {"id": "0812.4446", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "The Latent Relation Mapping Engine: Algorithm and Experiments", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": "Journal of Artificial Intelligence Research, (2008), 33, 615-655", "doi": "10.1613/jair.2693", "report-no": "NRC-50738", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI researchers and cognitive scientists have argued that analogy is the\ncore of cognition. The most influential work on computational modeling of\nanalogy-making is Structure Mapping Theory (SMT) and its implementation in the\nStructure Mapping Engine (SME). A limitation of SME is the requirement for\ncomplex hand-coded representations. We introduce the Latent Relation Mapping\nEngine (LRME), which combines ideas from SME and Latent Relational Analysis\n(LRA) in order to remove the requirement for hand-coded representations. LRME\nbuilds analogical mappings between lists of words, using a large corpus of raw\ntext to automatically discover the semantic relations among the words. We\nevaluate LRME on a set of twenty analogical mapping problems, ten based on\nscientific analogies and ten based on common metaphors. LRME achieves\nhuman-level performance on the twenty problems. We compare LRME with a variety\nof alternative approaches and find that they are not able to reach the same\nlevel of performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2008 20:08:53 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}, {"id": "0812.4580", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Feature Markov Decision Processes", "comments": "7 pages", "journal-ref": "Proc. 2nd Conf. on Artificial General Intelligence (AGI 2009)\n  pages 61-66", "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose intelligent learning agents cycle through (complex,non-MDP)\nsequences of observations, actions, and rewards. On the other hand,\nreinforcement learning is well-developed for small finite state Markov Decision\nProcesses (MDPs). So far it is an art performed by human designers to extract\nthe right state representation out of the bare observations, i.e. to reduce the\nagent setup to the MDP framework. Before we can think of mechanizing this\nsearch for suitable MDPs, we need a formal objective criterion. The main\ncontribution of this article is to develop such a criterion. I also integrate\nthe various parts into one learning algorithm. Extensions to more realistic\ndynamic Bayesian networks are developed in a companion article.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2008 00:27:22 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "0812.4581", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Feature Dynamic Bayesian Networks", "comments": "7 pages", "journal-ref": "Proc. 2nd Conf. on Artificial General Intelligence (AGI 2009)\n  pages 67-73", "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Markov Decision Processes (PhiMDPs) are well-suited for learning\nagents in general environments. Nevertheless, unstructured (Phi)MDPs are\nlimited to relatively simple environments. Structured MDPs like Dynamic\nBayesian Networks (DBNs) are used for large-scale real-world problems. In this\narticle I extend PhiMDP to PhiDBN. The primary contribution is to derive a cost\ncriterion that allows to automatically extract the most relevant features from\nthe environment, leading to the \"best\" DBN representation. I discuss all\nbuilding blocks required for a complete general learning algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2008 00:32:45 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "0812.4952", "submitter": "John Langford", "authors": "Alina Beygelzimer, Sanjoy Dasgupta, and John Langford", "title": "Importance Weighted Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical and statistically consistent scheme for actively\nlearning binary classifiers under general loss functions. Our algorithm uses\nimportance weighting to correct sampling bias, and by controlling the variance,\nwe are able to give rigorous label complexity bounds for the learning process.\nExperiments on passively labeled data show that this approach reduces the label\ncomplexity required to achieve good predictive performance on many learning\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2008 18:29:08 GMT"}, {"version": "v2", "created": "Fri, 6 Feb 2009 20:56:24 GMT"}, {"version": "v3", "created": "Thu, 7 May 2009 13:14:45 GMT"}, {"version": "v4", "created": "Wed, 20 May 2009 17:40:23 GMT"}], "update_date": "2009-05-20", "authors_parsed": [["Beygelzimer", "Alina", ""], ["Dasgupta", "Sanjoy", ""], ["Langford", "John", ""]]}, {"id": "0812.5032", "submitter": "Qiang Li", "authors": "Qiang Li, Yan He, Jing-ping Jiang", "title": "A New Clustering Algorithm Based Upon Flocking On Complex Network", "comments": "18 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We have proposed a model based upon flocking on a complex network, and then\ndeveloped two clustering algorithms on the basis of it. In the algorithms,\nfirstly a \\textit{k}-nearest neighbor (knn) graph as a weighted and directed\ngraph is produced among all data points in a dataset each of which is regarded\nas an agent who can move in space, and then a time-varying complex network is\ncreated by adding long-range links for each data point. Furthermore, each data\npoint is not only acted by its \\textit{k} nearest neighbors but also \\textit{r}\nlong-range neighbors through fields established in space by them together, so\nit will take a step along the direction of the vector sum of all fields. It is\nmore important that these long-range links provides some hidden information for\neach data point when it moves and at the same time accelerate its speed\nconverging to a center. As they move in space according to the proposed model,\ndata points that belong to the same class are located at a same position\ngradually, whereas those that belong to different classes are away from one\nanother. Consequently, the experimental results have demonstrated that data\npoints in datasets are clustered reasonably and efficiently, and the rates of\nconvergence of clustering algorithms are fast enough. Moreover, the comparison\nwith other algorithms also provides an indication of the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2008 08:30:27 GMT"}], "update_date": "2008-12-31", "authors_parsed": [["Li", "Qiang", ""], ["He", "Yan", ""], ["Jiang", "Jing-ping", ""]]}, {"id": "0812.5064", "submitter": "Qiang Li", "authors": "Qiang Li, Zhuo Chen, Yan He, Jing-ping Jiang", "title": "A Novel Clustering Algorithm Based Upon Games on Evolving Network", "comments": "17 pages, 5 figures, 3 tables", "journal-ref": "Expert Systems with Applications, 2010", "doi": "10.1016/j.eswa.2010.02.050", "report-no": null, "categories": "cs.LG cs.CV cs.GT nlin.AO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper introduces a model based upon games on an evolving network, and\ndevelops three clustering algorithms according to it. In the clustering\nalgorithms, data points for clustering are regarded as players who can make\ndecisions in games. On the network describing relationships among data points,\nan edge-removing-and-rewiring (ERR) function is employed to explore in a\nneighborhood of a data point, which removes edges connecting to neighbors with\nsmall payoffs, and creates new edges to neighbors with larger payoffs. As such,\nthe connections among data points vary over time. During the evolution of\nnetwork, some strategies are spread in the network. As a consequence, clusters\nare formed automatically, in which data points with the same evolutionarily\nstable strategy are collected as a cluster, so the number of evolutionarily\nstable strategies indicates the number of clusters. Moreover, the experimental\nresults have demonstrated that data points in datasets are clustered reasonably\nand efficiently, and the comparison with other algorithms also provides an\nindication of the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2008 13:22:31 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2010 13:30:08 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Li", "Qiang", ""], ["Chen", "Zhuo", ""], ["He", "Yan", ""], ["Jiang", "Jing-ping", ""]]}]